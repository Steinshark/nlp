so i thought we'd do a sort of rather long video on a short topic in that we'd have a look at compression we've done some videos in the past dave railsworth's done some on bits of it huffman encoding as a w mike's done some on jpeg but i thought we'd just do a sort of general overview about compression well okay the best place to start is to actually think about what we're trying to solve think about the problem we're trying to solve we're going to start off with some data and i shall represent this over here with a file so we've got some data and we're wanting to send it so we've got a copy of the data or storing a copy of the data somewhere else so we've got the date here and we want to send it somewhere else let's talk about sending it we may just be storing on a disk so it takes up less space but we'll talk about sending it just to keep it simple and what we want to do when we're compressing it is take it and we're going to run it through a black box which we'll call the compressor and i'm just going to write compress because i've drawn the box too small and compressor wouldn't fit in and that's going to give us a series of bits ones and zeros that represent that data and the aim is is the number of bits here is less than the number of bits we started with so that this is going to be smaller than this and then we can take that through a decompressor and for orthogonality i should write decompress here and then that will convert it back into the original data so that's what we're aiming to do with compression we're trying to take some data and represent it as a smaller amount of data less bits now immediately there's two things that will strike from that one we're not going to be able to represent every file here in less bits we can prove that mathematically if if this if we had eight bits here representing this data that means is 2 to the eight possible combinations 256. if we're going to store it in less bits that means this must be seven bits i'm just going to say this but is it fewer bits your name is not dave brailles just checking yeah it should be fair you know so we've got two to the eight combinations here that means it's 256 possible things here if this is in fewer or less bits then we must have seven six five four three two one or potentially zero but then we won't be able to distinguish it so we can cross that one out bits here this is 256. this is going to be 128 128 this will be 64. that's 192. that'll be 32 that's 224. that's 16 that's 240. i hope you're checking my math speakers that's now 248 so if we add all them up we end up with actually if we're using fewer bits then it's only 254 possible things that we can represent using fewer bits so we can prove that we're not going to be able to compress everything down to being something smaller there's going to be some things which will compress to things that are being bigger at which point it's not worth compressing it so we can ignore that what we're aiming to do is design a system where most of the data we actually care about will become smaller because there are some things for example if we're compressing a text file we could probably generate a text file that would compress to be bigger so it gets expands rather than compresses when we run it through the compression algorithm but it would probably be a pathological case that wouldn't actually represent any real text so we wouldn't probably be worried about it but you cannot generate a compression algorithm that compressed that can compress everything it's just not possible and we can prove that very easily as we just did actually you can define randomness as being an uncompressible stream so that's the first thing the second thing is if we're going to be compressing things we're going to be taking information out and so that means that there needs to be some redundancy in the original data there needs to be something in there that we can throw away without losing the information that's in there we can throw something away here when we represent it in the compressed stream and then we can recreate it here so there's something in here which is represented that actually we can represent in a different way and still recreate it the other interesting thing is that often when you look at compression algorithms so if you look at something like mpeg or h.264 they will define this part of it they'll define the bit stream and they'll define the decompressor they're not interested in how the compressor works because you can change and this is particularly important for lossy compression things we can class compress it into two types lossless compressors the bits we put in are the bits we get out one for one zero for zero everything we put in we get out in exactly the same order with elastic compression algorithm we get something that's similar but it's not necessarily identical think of it like a photocopier you put some kind of photocopy you photocopy it looks identical but you might get the odd bit of noise that's slightly different exactly the same thing we can get the meaning across and get the information across but we don't get exactly the same bits and that's fine for certain things images video sound but for other things computer code we definitely want to compress it so we get exactly the same bits across the afternoon side are you doing a loss you want or a lossless one we'll concentrate on lossless mainly today we'll talk a bit about lossy but generally if you're doing losses you're making decisions which throw more information away that you can't recreate but actually wasn't describing something in the original data that was that important an example of that background behind me is nicely out of focus it's still moving around because the walls and computer science do that sean's actually on a tripod but it's all the walls and background that are waving around in this place but it's nicely out of focus so actually there's less information there and if we throw some of it away it's it's redundant it's not actually encoding anything because it's already blurred and we wouldn't miss it but we regenerate the original thing in most cases if you're really editing this and you're producing things and you're going to be pressing a lot then the errors that are introduced with lossly compression can build up and you perhaps you want to not do that and keep the data but certainly for transmitting it over youtube then we can let it sort of be similar but not exactly the same you won't notice it because you're looking at me rather than the background which is really really odd i'd be looking at the background and not at me but then each of their own so what we're trying to do is take the data let's go back to what we're talking about and compress it down to a smaller number of bits and as we said we could perhaps think about this these compressed bits as being instructions for the decompressor on how to recreate the data that we've got so how do we go about doing this well one thing that helps to think about this is actually to break it down into two stages get rid of that velocity compression throw it away and it's gone when we think about data we're actually thinking about two things we have a model for that data how we describe it and we also have an encoding for that data how do we encode that into bits now let's think about that in an easy way let's think about some text so i've got bananagrams here which one is hopefully brought in other text-based games are available london 2012 edition which i think we got cheap because it was after 2012. there's one on the floor here i've got an s we've got a blank there we go space we've got any others let's see if we can find there we are any star trek fans in the room will recognize that immediately and so that's our model that we're going to represent the text as a series of characters and then they will represent them one after the other in the way that we'd write the words okay so that's our model series of characters one after the other if we wanted a blank we could pop that afterwards we'd have that and then we could perhaps have another word that follows it there we are s u n go for the name of a computer there we are and so on so that's how we'd write that trill space sum we'd build that up and we could build everything up afterwards so that's our model for the day today we've got a series of characters and they're represented one follows another to build up the data now we could then represent that with an encoding and the classic one that we use here is ascii or utf-8 or unicode to do that and with that you take each character we'll use ascii and we'll represent them with a number so the t that will become 84. vr will become 82 if i can count backwards i i've got the ascii set up on the computer so we can represent that as a series of 8-bit numbers and then we can convert them into binary the bit eight bits so we've got how many counts we've got one two three four five six seven eight nine nine times eight that's 72 different numbers so we've got 72 bits so this would take up 72 bits there we are but how could we compress it well if you can watch the video that dave did on huffman encoding or else they're w encoding you could take into account the fact that some of these letters are more likely to occur in english than others so what we can do is use the fact that these letters occur in the english text at different frequencies so t is the second most common letter to occur in english text e being the most common so we can say well actually because this is going to be more common rather than using eight bits to represent it we'll use two or three bits and because you i think no because which one was it yeah because you in this is going to be the least common we might use eight bits or maybe even nine or ten bits to represent that the model's the same but we've changed the encoding and we would use less bits to do that so that's what i aim to do by encoding the ones that occur more frequently with less bits and the ones that occur less frequency with more bits even though we perhaps take up more bits to represent than we would on their own we take up less space overall so the file gets smaller but we do trade something off because the encoding we have here is nice for programs to work with we know each character is going to be one byte long if it's asking if you get to ugfa it's not quite the same but on ascii there is one by long so each character we can sort of skip ahead to the next one or to the third one very easily as soon as we start spinning up to variable length with different numbers of bits we have to process it in order and effectively what you're going to do is convert it back to the normal encoding to ascii encoding so that we can use it so we can change the encoding to make the files smaller but that's not the only thing we can do we can also change the model we use to describe the data and we talked about that briefly earlier when we talked about how the background is out of focus here and that's how jpeg work which mike's done a video in that rather than representing the image of a series of pixels we represent the image as the frequencies that make up those series of pixels and because if you do that and you read it out in the right order and watch mike's video on that you actually find that most images which are like this there'll be some areas a bit of my face and the hair in where you are using lots of high frequency data to represent the hair and so on but the background which is all blurred because sean's got a nice depth of field on his camera is blurred so there's no high frequency content so by switching it from just the amplitude of each pixel which is what we'd normally use into the frequency domain we can throw away data in the background because it's not actually there and store the data in the foreground where it is actually there and we end up with a smaller file now on the way to that the model we would use here to represent that file is actually gets bigger so when we move from the sort of pixel domain that we've used to to the frequency domain we end up having to use 10 12 bits 16 bits to represent those frequencies but then when we can cross it encode it using an encoding system we end up with something that ends up smaller so we sort of change the model which may be counterintuitive and make things slightly bigger for a bit but it means that the way we're representing the data means it's easier to not have to encode that redundancy we talked about earlier and so when you're designing a compression algorithm you both need to think about well how am i going to encode the bits but also how am i going to model the data and that even applies for something as simple as text one of the easiest ways that you can gain some compression and we can see this if we had a sequence of characters that looked a bit like this people probably guess exactly where we're going with this already so if we had a string like this pathological example then one of the easiest ways we can press this is actually to say well actually we've got one two three four five six a's a followed by one two three four five e rather than taking up 11 characters we now only take up four or four bytes you probably want to represent it slightly different but if we change the model and to actually say last time we're going to describe it not as aaa but we're going to describe the number of letters we've got okay so we've got six a's followed by five e's it takes up less space then we can encode that is this a model change is it an encoding change interesting question it can get blurred which one you're actually doing at so we'll ignore that before now the problem with this of course if you've got something like trill sun that we had before you end up with ill it's one t one r one i two l one space one s one u one n it gets massively bigger this sort of encoding what's commonly referred to as room length encoding sort of way of describing data works when you've got a lot of ice long runs it was brilliantly for sort of images where you've got pixels are all the same something like png you can use this quite well but for something like text where things change every character pretty much it doesn't work that well but there are ways you can get around it so perhaps one way you could vary this is say well actually you can exploit the fact that if you know how the decompressor works and you describe and you define the compressor and the decompressor to work in similar ways you could for example say well what i'll do is i will say if i've seen three a's the next symbol that comes along tells me how many more there are so in this case i would send it as a a a one two three and then there's three more and then i'll send it as e-e-e and two more so we've now got one two three four five six seven eight which is better than the 11 we had before but for something like trill sun that would actually still get sent as nine characters and we don't need to actually send any information because we define the decompressor and the compressor to work in the same way of course if we end up with ume then what you end up with is it being encoded as aaa0 eee08a0 which is now instead of it being nine characters it would end up as 12 characters so it's got bigger again so there's always oh well swings and roundabouts with this thing how much room it's got left so now the sender knows if i don't want to overwhelm that computer i'm only going to send he got slightly dimmer when we got to visco and then slightly brighter again when we got to this row and we might find that but basically if you've got a savings