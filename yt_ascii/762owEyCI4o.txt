so okay good afternoon everyone and welcome to my talk about minimal logging i'm thankful for the organizers to let me open this b track here on meeting c++ 2023 with my presentation so my name is kunon and i'm from belgium and i'm currently working for the vila group and this may be a name that is not too familiar to you but we're a textile machine manufacturer from belgium which started as just a family company for weaving machines but now has grown to a very big company which has all kind of textile machines so that's why we call it like that so i'm leading a team working on embedded software there so to make sure that the operator can choose the carpet which he wants to make and if you're lucky or if we have done our work correctly this is an example of a weaving machine then you start off with like a almost almost 40,000 bobbins of yarn and then at the end with the jackard here on top that produce all the complex patterns you get end up with a a carpet and actually there's a fairly decent chance that the carpet we have our feet on now is actually produced on one of our machines so that is quite nice to to note before that i worked at nikon mology which is a company that makes measurement software and i like to mention it here because also some of the ids that i will present originated there some more background perhaps i studied mathematical engineering and if i'm looking back i can see that my first contact with c++ was in 2003 where i did an implementation of the discrete fore transform but for understandable reasons i'm not going to show that code here today now instead i want to focus on logging and then some of the adventures i had with that so just to set things clear some examples of typical log statements our codebase uses cute so there you can have this kind of statement where you have a that has some delay where you have some primitives like debug and warning and so on where you can stream some data too and the nice thing is that this automatically adds a new line at the end so your code is not riddled with new lines or std end lines or whatever and also these streaming operators make it really convenient to use it with all the types that are present in cute it adds quotes to strings it adds the spacing where necessary there's some decoration for the for the typical types and so on so it's really easy for a developer to write this this these log statements there's also the possibility to log your or to categorize your logging so you can can define different categories of logging and at startup you can even choose which ones are active and which ones aren't that's really useful because by default you can put most of them off and if you realize that there's an issue at a customer specifically on that machine you can turn on specific extra debugging logging or something similar also for the output there's a pleora of options to format this you can add the file the line the method of course the time st and so on so that's really really quite flexible and easy to use but even if you're not using cute or any other framework with the standard template library you already have enough to do it so you can for example define here a a log macro and use the same formatting options which you have or similar formatting options to also create a nice output to include the line function and so on you can use the pre-process cessor micros of course and also end up with an output that is fairly similar but with c++ 20 there's now the source location feature where you can write this without a macro and actually use this trick or this common pattern where you have a function which takes an additional optional argument which you default to uh sd source location current which then once you do the logging at the bottom gets instantiated at that location note that this is this requires compiler support because well i wouldn't know how to write this function and that's something you really need the compiler's help in to get this up and running so some examples of of log statements actually when i was investigating some timing issue on the on the machine i noticed that if i added one extra log statement the entire behavior changed so i had a some kind of timing issue and it went completely away when i added one more logging statement so that was really surprising to me at least at that point in time so i went and and started investigating what is what is the what is the impact of of this logging so looking at just a generic case of logging and a boolean an integer and a floating point i ended up with a measurement of cute being this amount of time and sdo stream taking that amount of time so at first you might think okay cute is faster we should surely use cute for that but that's only the average we have to do some more statistics on that and if we look at the aror bounds then you can clearly see that the all although the io stream solution is a bit slower it is much more repeatable so it's using this method it will create a more predictable overhead to your log statements so that's the reason why you always need to do some statistics on on there to make sure that well you get something that is repeatable that's a lesson i learned from the metrology side of course i intentionally did not put any numbers here but to put it into context let's look at what it takes to create the current time so that's an operation any log has to do to to be able to print out when this happened and then you see that this is quite a big difference so in an ideal case you would prefer to end up somewhere to the more to the left instead of the these quite large results so what is what else is at play here what else is causing this large discrepancy between these two measurements and well i i think there are three sources of overhead one being formatting so uh printing out or converting data types to strings is really something that can take up some time and also log files notoriously are very verbose having thousands of machines in the fields at customer sites that all produce log files if you have to analyze an issue and go through tons of those lock fils it's really you notice how much suboptimal things are loged things that are not necessary are repeated too many times so there's log files are quite non ideal in that sense and also because so much is locked i think it puts additional strain on the memory system which can also cause some of the slowdowns i might might even slow down your your software itself so adding some log statement into a hot loop somewhere might really mess up your performance this is also confirmed by u a developers conference presentation of 2016 where apple some apple engineers talked about this and proposed a different solution but so i really want to reduce the amount of overheads and the actual spoiler here the blue bar is the performance of what i'm going to present here so that should be interesting i hope so minimal logging i previous gave this i previously gave this stock in an users group meeting where i went into well use live coding to present the entire framework or well framework is a large name or a large term because the resulting code only is 200 lines so that's really feasible for a live coding but as i feel that i can present the ids better with slides i'm not going to do this here but i want to uh give a hint of what i used to make this live coding really well well that really helped me in the live coding and that was to ensure correctness i of course write unit tests so i have a set here of unit test on the top right of the things that i want really wanted to well that that the framework should be able to do at the end of the of the presentation and of course i want this to compile and run even if my implementation of the logger is just this so to do this i end up with some kind of boiler plate which if and we have to fill in something if a feature if this feature is available you do the first branch and if it's not available you just fail the test so in c plus+ 20 there's a really nice way to write this you can say if con exper requires if the if this so the the provided logger has the trace method available you can do the trace and and verify the results if not then you just fail the test so this is certainly not something new for c++ 20 this is a well-known pattern actually the auto already revealed that this is an an template so as i understand it the because the template is instantiated by your compiler it's not necessary that all the code inside of it actually would compile in a standalone setting so that's the substitution failure is not an error pattern which is now quite a lot abbreviated because of the use of auto and the conex for requires so i thought that was a really nice pattern which i wanted to share with you as well so i'll leave this this out for the remainder of the presentation just not to clutter the slides too much but that was a trick i really used and helped me to end up with the right solution at the end of the presentation before but so logging i really went down to the basics my father always told me you have to be a bit lazy not in the sense that you have to give all the work away to someone else but to be critical about what you're doing and look for opportunities to do l and achieve the same results so with that in mind i set out to to find what is the minimum we can log to to still get the same results and the same fidelity of of log logging so the first is when so you needed some kind of time stamp you need to know where in the code something was locked and then finally also there's a what that was logged with additional parameters or uh arguments and states of that point in the application so let's start off with the point in time so what we typic typically do is just print a time stamp but come to think of it and as al also mentioned in the keynote this morning doing calculations with calendars and times and so on time zones and and so can be very difficult and therefore also costly so if with every line you're logging you're doing this calculation over and over again i think that's really a waste so starting off with c c kronos library you can do i think something else which is interesting so we start off with the high resolution clock taking the well the highest accuracy we can get and let's say we record our time unit in ncs then relative to some apoc we can record the you the the the time that has elapsed since then then we put this inside a record which will be our basic unit of logging so every log statement will correspond to one record further on so notice that there's no formatting here so we just query some kind of clock and then store the value there's no time zone issues there's no possibility for leap seconds and all the things that can happen with times and also we get much more data in a much more compact format so the thing on the left was already 24 byes with just millisecond resolution the solution here with the with the clock type is only 8 bytes and has nond resolution so that's really a difference in both formatting and also in verbosity you will be able to lock a lot more of these time stamps relative to printed out text format time stamps so how do we continue with our logger then it will be fairly straightforward we make a template with a trace function and this trace function will just take this record with the current time and added to some kind of circular buffer this circular buffer is also nothing special it is basically a fixed capacity array which i mentioned here on the bottom fixed allocation fixed capacity and heap stack allocated sorry because we want to avoid any memory expenses it's allocated before your critical part which you want to instrument and which you want to measure so therefore having reallocations or anything which happen at a fairly unpredictable rate is really not beneficial for the for the accuracy of the results there's also here the mention of the size so it's fixed and i chose it to be a power of two just to get rid of a modul operation which you would have to guarantee the circular part of the of the of the buffer and then we have an append method which is basically a copy of this record into the buffer so there's no formatting there it's just taking the binary data of the record and putting inside putting it inside of of the buffer with that we can have a look at our first unit test which basically instantiates this logger does a trace then sleep or anything else which would be relevant to measure in time and then you can add another trace and this is actually the online part of the of the or or this represents the online part of your program so the thing that you really want to optimize for efficiency and make sure that all all the sources of overhead are not disturbing that because this is a unit test it's all in the same same method but that's the the distinction we have to make between the online and the offline part so then we can collect this data from the logger and verify that there are two records in there and we can u do any calculations we want based on the time difference between the two log statements so that already gives us in almost most system an 8 byte integer the timing information which is a a good start the second part in the wear is a little more involved but we will go through it step by step and it it all started the first time i opened a debugger put a break point and then the the the debugger stops and it tells you exactly you're now in this file at this line in this method and i thought wait i i didn't tell you i didn't tell that i didn't program any of that in in my source code so how does it know that so it's already it it knows where you are it knows all the details so actually why would you add add another or use any means to add the function name into your program the debugger already knows it so even though we have in the source location in now or the the pre-processor macros why would you add additional strings to your program that that that was really something that was puzzling me also in general i think we should be cautious when logging strings if you can convey the same information with just an integer or an enum or some other data type that is more compact than a string that's certainly something that could be preferred so how does the deburger knows it well that's because he he has access to the the to the the address the instruction pointer which is on 64 bits is of course 8 bytes and by using the debug information that is part of a a debug build by default you will be able to resolve this address back to the the to the name of the function the file and line so all this kind of information is is automatically encoded in the debug information so what what should we do now should we just include debug information with all our builds or also the release builds certainly not so there we can follow the workflow that is typically used in u crash dump analysis so let's have a small interm medzo there so in that scenario you have your normal program you attribute with a crash handler which in case something goes wrong will do necessary things to collect information so on top of that also in our release builds we will add the debug information which can be quite large and that's why we are not going to ship that seeing a factor 10 increase in program size or binary size is not uncommon so that's really something we don't want to ship with our products but there's also some more reasons because if you would share this information that's actually an an a risk for people that are have have other plans with your software because if you can locate a certain proprietary code or anything using the debug information that makes it really much more easy to reverse engineer your software also if you give away the location of some kind of software check or security check that's also making it really straightforward for someone for an adversary to to know where to look to sabotage it so now instead we're going to keep this debug information within the company make an a good archive of that because we will really need it later so if at a customer a crash happens it's not always easy to reproduce it so it's invaluable to have a crash dump most of the time which production machines they will just reboot the machine uh and start producing again because well it's a production environment you need to create a product so it's really invaluable to have crash dumps so what we do is the crash handler will write a file which contains all the necessary information to to analyze what happened at this crash so and then combining this with the symbol archive we can translate the the addresses which are just which are don't mention anything in the crash d itself and can be translated back to a full call stack with function names and so on something developer really needs of course needs to evaluate what what went wrong so i think there's a lot to learn here and we can certainly use some of the things in our loging framework so we'll keep most of it and as mentioned before the debugger knows all this information because it's based on the instruction pointer so what if instead of logging file function line and so on instead we just write instruction pointers that is the that was the idea i set out to work on this and uh i try to make this work so these instruction points are quite small so yeah and these afterwards if you receive the log file from the customer you can again use the symbol archive and the symbol information to translate it back into files lines and so on so this lo minimal log as i have called it is very efficient in and in terms of space it's not a repeated string over and over again it's it's just a minimal information i think that's why this presentation is called minimal logging and it also avoids some of the risks that are typically present if you use normal text plain text logging and they are also similar to what we had with with the debug information there's an intellectual risk if you give away too much of the details of your software in a log file someone with enough time and enough knowledge can try to reverse engineer and see what is going on there so that's really something you want to avoid and also if you have would have have would have a developer which writes a really useful debugging line stating very clearly what is wrong and and what the results should be this might also give away some of the of the details which you don't want so by keeping all this information based on symbols which remain inside of your company you can really protect against that so with these instruction pointers alone there's not much you can do unless you start looking at the assembly of course so this seems to seems to be promising let's have a look what we can do to retrieve this instruction pointer and what type are we going to give that well that's it's just another pointer so we can use the unsigned int pointer type for that which is the which clearly which is useful because because it matches your platform so 32bit or 64-bit it doesn't matter it will be the correct type so this makes it easy to write and then to get the instruction pointer actually that's a register in your cpu it's used all the time by the cpu so it's readily available and it can be accessed quite quickly so it requires some inline assembly which is dependent on the architecture you're working on but all in all it might look scary but it's just copying the data from an a regist register that is already accessed quite frequently into a variable and then returning this compare this to retrieving some string which is located in a totally different part of your binary it's it's a a different or a difference in in magnitude i think there's only one problem here with this approach and that is if you do it that way you will get an instruction pointer which is inside the instruction pointer function of course so that's not too helpful if you want to determine where this function was called so there starts our dance with the compiler to convince it to do the correct inlining and so on so if we attributed with an always in line in production code we will be guaranteed or uh it's very likely that this will be inlined and that we will get an instruction pointer at the location where this method is called this might seem a bit odd but you can compare it to the to source location current where your compiler also already had to do some tricks to make sure that this is evaluated at the at the correct side because it's it's doing something in a method and it has to know where it was called so that's already something special as well a a first try i in in the first try i used the compiler extension or the compiler method built in return address but that is not the the thing we want because that tells you where the code will return to after the function and not where it came from so in that sense in some cases you would end up with a wrong wrong address so how do we add this instruction pointer we can we can just take our record and add it in there it's very fairly easy to do that and then our trace method just gets extended to not only query the current time but also take the instruction pointer at that point and of course here we again have the same issue if we do it like that we will always get the instruction pointer in the trace method which is not ideal so we have to do another request to the compiler to inline it so with that you can see that the second unit test already succeeded or passed and let's have a look at that test so we instantiate again a logger we call this trace method and there ends our online part afterwards we can collect the data again and verify that it is nothing more than just the size of our time representation and the size of our instruction pointer so in most cases this will just be 16 bytes and with that feeding it into our model which is aware of the symbol archive we can actually query or check that the records in there are valid and that the function name resolves to the name of the test function in this case so even with this limited amount of data using the symbols we can retrieve all the necessary information this also includes of course the the line and the number uh yeah the line and the function no the line and the file which is also of course can be derived by the instruction pointer so that's our second unit test let's have a look at the third one where we have an example of a simple nested case where we have a first function that does a trace then calls a second function which itself also uh adds the trace point and then we return and do the second trace in the first function so the data that will come out of this is again just three times some represent representation of time and instruction pointer and if we look at the results if we would resolve it again in the same same fashion as before we get not the correct results and that is again another case where we have to convince the compiler not to inline all the things because well the code on left is so easy that if you turn on any optimizations it will just inline everything and yeah then your test is no longer interesting or doesn't work anymore so with that we already know where we have loged anything of course just knowing the location is a good start but we want to add some state some more information so and with that we can move on to the third part the what and for that we can just extend the record to include additional arguments so while we have a record and a trace function we can easily create a templated record which has an additional argument t here and make an overload of the trace function which will also accept an argument and then in the same fashion we will just construct the record and dump it to our circular buffer um as i mentioned before you can't use this with any type of course if you pass it a string it will just log the the pointer which points to the string it will not copy the contents of course so that's a limitation but i think as mentioned before we should think twice before logging strings another clear advantage of this is that this is binary data so if you log a double to this in this way you will get the full double precision there's no data loss there a while ago i did some tests and printed out the results with insufficient accuracy then i had to redo the entire test just after changing the format to include more digits in my end results so that was really embarrassing so that's something that can also be avoided here by just using the binary data and then you could actually do the formatting offline separate from the logging and independent of that so but now we get a data stream in our logger which is which can vary depending on the arguments that are logged so what is still missing is a way to identify the type of argument that was logged and there are several ways you could go about this you could use this some kind of name mangling scheme or some kind of structure which encodes this this information but i think i found a quite nifty way of doing this and to get there we have to realize that actually this trace method consists of two parts that's being the instruction getting the instruction pointer that's why we inline them this method and the remainder which just adds the record to the to the circular buffer so because this gets in lined there's no mention of of of the trace function so we lose all the information of the template that was present here so instead we can split it up in two parts so we have a outer trace function which just does the instruction pointer bit and gets in lined so that it's it's really the call side of this trace function and then we can add a second part a trace inner method which is not in lined and uh where we do the remainder of course this alone doesn't change anything but what we can do now and that's the one of the main tricks here is we can call this instruction pointer method again because once we get into this bottom function this trace inner we still know the the the type information of the template that was pa there so if we will be resolving this in second instruction pointer we will be able to see okay this was a trace call which was called with a boolean this was called with an integer with a wait an an unsigned integer that's still wrong that's another surprise i came across during this adventure and for that we have to realize that this this circular buffer append is is nothing more than just copying data so if we look at this boolean that will be a record t which has one byte for the argument and the integer and unsigned integer will actually be both the same eight bytes for this data type so our clever compiler just saw unsigned in or unsigned in or int it doesn't matter for me the implementation and the remainder of what is done in this this aent method is uh irrelevant i will just reuse that so that's why we get twice resolve this to trace inner int instead of an unsigned so to counter that we're back to our dance with a compiler we have to ask it politely to not reuse the implementation of this function this really increased my out for the compiler because i didn't expect the compiler to do that so by adding this used statement we now get we correctly resolve the the third one to be a trace call which was done with an unsigned integer so and that's actually the the hardest part of this talk with that we actually fix all but one of our unit tests the last one is about multiple arguments so what we can do there is is of course the variadic template ex extension and extend our record t with something that looks like a a tupple and add some s's and some dots in the correct places to end up with a vartic template which can take an arbitrary amount of arguments the remainder of the codes code is the same we still use a second instruction pointer to encode the the data or the types of the data that were locked and all in all it's just pushing this data into the circular buffer it's really interesting to see the the resulting assembly if you look at this after the compiler optimized it because all these thing all these abstractions with the records and the topple and so on this all gets abstracted away or optimized away and it's really nice code it's taking the clock copying it taking some instruction pointers and copying it there's in in no case this record t is actually instantiated as such so also from a memory point of view it's really efficient so with that we can actually already summarize what i've called minimal logging so we've split logging up into two parts being the online part where we want to have a very performant logging framework which does not include any of the formatting overhead is very condensed so you can pack a lot of information into a single log file and it's also really memory efficient and an offline part where we can do all the the more expensive parts of the of the processing so we did this by creating a circular buffer which in it in itself just contains an integer representing the time an unsigned integer representing the location where the trace call was done and then also a second instruction pointer in the function that in this trace inner function which we will need later this is then followed by one or more arguments which are just in binary data after your circular after the other data so once you're out of your performance critical part of the code you you could write this circular buffer to file and do an offline analysis with that so in there you can decode this data again to include actual time stamps in the time zones and the all the information and detail you want you can use the symbol information to retrieve the file line and function using the symbol information we can also get back the the types of the arguments that were passed to the trace function and with that we can decode the optional arguments so this actually already gives us all the information to write again a full text log but i think it's we should move on from purely text based logging to something else because once you have this in in a model you can present it in a much more more advanced way to in in some kind of viewer where you can do filtering where you can do change the formatting and so on so there's a lot of opportunities there to work with the log files in a in a much easier way than then having to decode text based log files and with that we're through the slides so if there's any questions i i'll happily try to answer them there's some bonus material if we would have if we have time that i can go through but i'll first open it for questions so the question is how do you evolve viewer and like how do you deal with old logs i understand that you have a set of types you support the cing which are like primitive types you never extend them with your like custom structures or something like this because i understand so when you get this like function pointer to the actual implementation you like take a function string and from there you get template parameter of a type that is actually decoded and then you do the string rendering or so that like my point is like how do you evolve this so let's say you add new structure to log and then it was not present in previous format or like vice versa like how does it how does it happen from the online part it doesn't change anything but indeed if you add custom types to your logging you will have to implement it also in the what i called here the log model to be be able to decode and and and do the interpretation of that data indeed so and second thing did you like look at the like projects like spd log which are like doing the you know logging outside of hot path through well they use also like shared memory like just memory queue but do it in a second like in a logger thread just of loading it from a hot pass from the yes i i've saw that but i really wanted to focus on this instruction pointer and see with what was the fewest amount of information we could lock to still be able to retrieve all the details soon and the last the last question so couldn't you like use the variant and use one bite to encode type instead of function pointer of eight bytes for the you know just take the type index from a list to encode it which argument is supplied stuff like this that's also an possibility but i wanted to have something which is was really independent of the number of arguments ah right yeah and that's why i i right it's it's it's indeed eight bytes for to determine if it's an integer or bull is perhaps a lot but it extends quite nicely if you have more aggreement or more types but good question thank you yes thanks for the talk first question do we have published a library somewhere where not yet no i plan on doing that but there's some other things at home that with a recent daughter but yeah that's surely a plan so if you're interested in that please drop me a line and i will uh notify you when this is available in github or anything yeah okay second question is going a bit deeper if you use the instruction pointer are you not getting trouble with address randomization so if your binary is loaded by the operating system it will get a random address and i would guess the instruction pointer will only give you the random address which is not enough to decipher the deb information i guess yes actually you need to load you need in indeed need to know the load address of your binaries so you also have to i didn't mention this here because this goes perhaps in too much detail but you also need to know the relative address to where you were loaded this is the same if you would want to support shared libraries and so on for each of the binaries you need to know the load address because also the symbol information is always relative to the load address so that's that's some additional information of course you need but as this is mostly bookkeeping i try to minimize this in the this talk but indeed that's surely the case thank you thank you for the talk it's very clever i notice when you call the get instruction pointer a second time to indirectly get with kinds of arguments with you're logging have you experimented with instead passing in the address of the trace in a member function that you are calling i have not that's a good idea that's something i could try yeah thank you yeah hi thanks for your talk was very informative you showed the timings in the beginning and i was wondering have you considered consider the effects of logging to file versus logging to standard out versus maybe just logging to some ui widget in there or do you know how much of it would affect there that's a good question and that's the reason i didn't put any numbers on that slide i just wanted to give some hand waving idea of the the the scale of things and the amount of time that is taken by some of the loging but indeed writing to a file or writing to a a standard out might give different results but that's something and the second point that i had was you were now trying to remove as you put on your slide trying to remove all the verbosity from your logs you might have in an application like industrial machining you want to show some kind of lock information also to a user on screen or in a in a command line output i don't know object xy is broken please replace or whatever would you split this then off into a separate logging mechanism or how would this interfere or not interfere with this because i guess yes for debug logs this makes a whole lot of sense but for user logs you want to keep the verbosity to kind of tell them what what's there yes this is really intended for logging which only is relevant for developers so if you want you still need to provide sufficient feedback of course for your operators so that they don't that they know still know what is going on because u that's indeed then i would split it up in user logging and developer logging and and handle these separately so even though the user logging might then be slightly slower or it it might still give sufficient feedback yeah indeed okay thanks thank you hi so i had a question regarding the inline and no inline attributes that we used so if i understood it correctly if i understand it correctly the compiler can just like choose to ignore those as well and do unl lining when it shouldn't and don't not do un lining when we ask it to so do you have any strategies to at least like detect that or how to handle that because we might not notice it when we are compiling the code and much later when we see the logs it might become a bit like yeah that's that's a very good point indeed the it's you it's you ask the compiler politely to do this but it's sure not not guaranteed that's why i have unit test because i run them with the same compiler in the same environment as uh my production code would be and there i didn't detect any of these things but so then you'll have to write unit test for this for every function you are trying to use it for right because it might the unit test might work for this function the one you wrote in the unit test but in the real world the production code that part might be in lined or not inlined right yeah that's that's true but then again if you're logging in something that gets inlined perhaps yeah yeah indeed that's that's that's a fair point it's something it would be nice if if we could detect that or at least get a warning if the compiler didn't inline it even though we asked that's and yeah on the same note like so we are telling the compiler to not inline something which might affect performance as well right yes okay but then we have to kind of be just aware i asked it not to in line in the in the unit test just to get a with the with the nested functions just to get a simple example yeah you wouldn't do this in production code because in production code then you'll have to use no in line everywhere right wherever you want to measure this because otherwise if it inline that function then your instructor pointer would be just pointing to a different function yes inde so essentially every line like everything you need in your code now will need to be no in line right unoptimized unoptimized essentially which is yeah yeah that's not ideal indeed okay that's a good point i should think about how we can yeah okay thank you thank you yeah actually my question was very similar so i did something similar before also and in my experience the aggressive inlining makes a problem there so from what i understood is you just lock the information there is a bool and it's like true and it's crucial to find the code place mhm to make sense out of it right yeah and so when the compiler is inlining actually this function which is logging then you will get it just somewhere else so yeah you multiple things on the same line so the the the optimization basically spoils it a bit so as he said you would have to make it only sensible in an unoptimized build and that's not production yeah that's something in a in a in a bigger context i didn't think about yet or have have no sufficient experience it yet so that's a yeah okay thank you maybe there's still time to add show some of my bonus slides there's one nice advantage of having a of of doing this logging this way is well we if we have to look back at the crash dum workflow because the crash dump already contains your stack to be able to reproduce the call stack by walking the stack frames it actually also contains the the lock up to that crash so from your crash dump you can with some tricks retrieve the circular buffer which was used to store the logging information so with that you could end up with the exact uh logging which is present up to that point so that's a nice thing also what i thought about for future extensions is working with literals because if your program is full of logging fixed strings there's no point in doing that it's just wasting space so if there would be a way to detect these literals you could actually not log them and then have tooling which in the offline phase just reads them and add as the literals again so that way you can save in the log size by not logging the things which are just clearly present in the code and don't need to be logged the third slide i i still have here is about shared librar so that was the question before symbols are always relative to the load address so you can that's also something that you have to take into into account and you can just use the the the the the load address to figure out these things and that's the same way as crash dums do it they just store the load address for each of the binaries so it can be determined okay this instruction pointer is in this range so it belongs to this binary and then the last thing i'm going to mention is that this also this logging way of logging also gives you information about the version of your software this can be done in the same way again as crash dums there you also store some kind of built id of your binaries so because this is used for storing your symbols and matching those you can also again find out which version of your software was used for the logging now it's sometimes difficult to find out especially if machines are running for a very long time to find which version was this again so that's also an advantage because the symbols have to match the the the log file you can that way also determine which version this was so that's based on this built id which is built in okay with that i'd like to thank you for coming to my talk and i hope you have a great conference thank you