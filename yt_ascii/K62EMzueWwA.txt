so i thought today we would look at the topic of optimization it's one thing that's it's been around in computer science for years and i'm not talking about the mathematical optimization that people do but i'm talking about making your code optimal that might sound like i've defined optimization in terms of itself and actually there's there's a point there and so the a says optimization is the action or process of making the best of something also the action or process of rendering optimal the state or condition of being optimal and that is really what we're going to be talking about today is how can we make our computer programs when we write programs the best computer program but there's a question we have to ask first what are we trying to optimize for what are we trying to make it the best of do we want it to be as fast as possible or do we want to make it use the minimal amount of memory in which case we're optimizing for memory size or these days we might even want to consider are we optimizing for power usage if we're running on something like a mobile phone or a battery powered laptop we may want to write our software so it uses as little power as possible at the expense of speed or memory usage when we optimize something we're going to have to choose whether we're more interested in the speed that it takes to execute or whether we're more interested in the amount of memory usage or the power usage so how do we go about optimizing our software well the first thing to say is that we don't no that's simple end the video we don't i may be joking there but probably the most helpful statement ever said about optimization with don can in a paper many years ago and he said premature optimization is the root of all evil and actually i think that makes a really good point there's no point optimizing a bit of code if it's not going to give us a benefit when the program runs overall so really we don't want to optimize our program at all we just want to sit and write our program and get a version that works not worrying about the optimization that's the first thing you want to do when writing software writing optimized software just get a version that works works because then you can use tools to sort of instrument that and actually find out well which bits are being slow where does the program spend most of its time can i ask a question yep is it not better to sort of design it properly in the first place and specify i mean we're taking that as red that actually you'll have designed the software and even if you are again the same thing when you come to actually implement it you don't want to try and implement an optimized version straight away whatever your design is you would take that implement it and then see which bits need optimizing we can spend ages optimizing a bit of code because we think it's an interesting problem to try and optimize it and we can produce a really nice solution only to find that that piece of code is called once at the start of the program and so we've managed to shave off a tenth of a second off a piece of code that's called once probably while the person who was running the software had gone to make a cup of coffee so they never noticed all that work you'd put in so we write the program first and then we see whether it's taking too long to execute or it uses too much memory for the environment we want to run it in or it's using too much power we can use other tools profilers various other tools that are available to run the program test what's happening as it's running see which parts of the program are using the most time or using the most memory and then we focus our attention in terms of optimizing them looking at those parts of the program so we don't go into this blindly and just think right let's have some fun let's go in and optimize this program this function looks interesting let's rewrite that we find out which parts of our program are what we call the hotspots and we start looking at those to try and optimize them so first of all don't even bother thinking about the optimum way to implement it just get the program working and get something that you can test and you know that the program does what you want to do then test it to see which parts of it are need optimizing a lot of computer programs are compiled and the compiler does some optimization for you so is it something you need to do optimizing code so that's that's a really great question question yes and no so i mean these days i mean if you gone back 40 years compilers were terrible if you take written a programing c and compiled it the chances are that the code it would produced would not be as good particularly on a pc or home computer at the time as a good programmer could have written in raw assembler and so people would go and rewrite it in assembler or optimize it because they could get better code that way these days the technology of compilers has moved on a lot they all have an optimizing step that you can enable when you're compiling your code in gcc for example you put the minus o minus capital o flag with various parameters to specify what type of optimization you want there and it will take your code and produce assembly code or machine code that is as optimal as the compiler can produce it and that's great and again you should do that before you try and optimize it yourself but you can often find that actually there are situations where if you think about what the program's doing you can probably come up with a better solution than even the optimizing compiler can but you need to know where where that's worth doing and that involves knowing what it is your code needs to do so for example if you've got a program which takes three days to execute and you can shave a nanc off every iteration of a loop it's doing that may well not make that much of a difference on the other hand if you're writing a game and you've got your screen being redrawn at 120 144 frames per second shaving a couple of nanc off each iteration of a loop drawing the graphics on screen or something actually may benefit because it might mean you can draw one it in one frame rather than taking two frames to draw things on the screen so again you want to know what are the requirements of the program how is it being used before you start making optimizations and i'm tending to talk more about speed here but the same is true as if you're optimizing for power or if you're optimiz optimizing for memory usage as well you've got to make the same decision we'll concentrate on optimizing for speed because that's what people have tended to do in the past the best way to optimize your program is to make sure it's using the right algorithm you can use some sort of tips and tricks and techniques that you can find in books like michael ab brush's the zen of code optimization looking at how you could optimize programs to run on the 386 486 and the penum which shows how old it is are the principles still the same though so the principles are the same or the sort of things to look at but obviously the cpus have all changed and that's when it comes to optimizing for spee that's one of the issues what may make your program run faster on one cpu isn't necessarily the same thing for another cpu today we'll concentrate on the other side of optimization what people tend to think of more as optimization which tends to be the sort of tricks you'll find talked of in books like that in web pages talking about how to optimize things which is just looking at you've written code can you write it in a way that runs faster by just changing the instructions of a bit and doing the same sort of thing but making a few changes to that now to do that i'm going to write a very simple program which copies a block of memory so it's going to take in a pointer to some memory void star and we'll say that's the destination and we're going to take in a pointer to the source and we're going to take in the number of bytes to copy and the way that we could write this is we could set up a pointer internally to a bite we don't know what it is so we'll just keep call it unsigned it doesn't really matter for this and i'm not going to put the cast in just because it'll annoy people on youtube but we can assume that that's put in i'm writing pseudo code here we'll set up another pointer to point to the source and then we'll set up a counter i which we'll set to equal zero and we'll say while i is less than n that there we're going to set p++ equal q++ make that a point otherwise it won't work properly and then we will increment i so that's a very very simple memory copy program we copy one bite from the source which is what the star uses that's really bite from the source increment q and we'll write it to the destination and increment p so we then move on to point to the next bite and we just go around that loop until we've copied n bytes from there so that reads the bite there there and this one writes a bite do you are you writing before you're reading there or am i jumping the gun no so this code's fine it'll read it because we've got the equals here it'll know that it's got to evaluate the thing on the right before it can read it and we're we're incrementing p and q there so let's have a look at this program and see if there's a way we could use some of the sort of tricks that people have tended to think about when they refer to optimizing things that we could apply to this let's move away from c and look at this in sort of a machine code representation we'll see what's actually happening here i'm going to use arm because it's sort of relatively straightforward so we'll say r0 contains the destination and we can say r1 these are just registers these just have the values in we can say we move into r2 z we're then going to load a bite into r3 from the address in r0 we'll add one soorry in r1 there we'll add one to r1 to move on to the next bite so we're we're doing exactly the same but we're sort of seeing the steps that are involved in a bit more detail and we then we'll store the bite in r3 into r0 and we'll add one to r0 like so this is what effectively the c compiler would generate for this if you were to write it out and then we'd have a compare instruction here that compares r2 with r3 that should have been r4 there there we are it's much easier writing this on the computer we also need to add r two with one here to count that we'll compare them and we'll say while it is less than we will loop around so we'll go back around to loop which we will label here so now we can see the individual things that are happening we're loading a bite from memory from the address r1 we're incrementing r1 we're adding one to it we're storing it in the address in r0 we're incrementing that we're incrementing the number we've counted and we're comparing them and each time around we go the loop we'll go around this loop however many btes we've got there let's see how many instructions it's going to take to copy one bite so that's basically the bit in the loop we'll ignore the setup cost here cuz that's going to happen once it's going to be a negligible cost unless we're actually only copying zero bytes in which case it'll take time we should probably also have a branch to the condition here just so that we actually can cope with the case when it's zero so how many instructions we copy per per bite well basically it's 1 2 3 4 5 6 seven instructions so our basic implementation is going to take seven instructions per bite so can we speed this up by speeding up we want to take less instructions per bite well okay there's some very simple things we can do we can get rid of two instructions straight away so we can get rid of that instruction because the arm cpu provides us with a instruction that will automatically add one to the value of r1 so we can get that for free if we know what our cpu provides us and this is something that the compiler would do to optimize the code we're not doing anything yet that the compiler wouldn't do behind the scenes anyway it would spot that and take it away we can do exactly the same thing here we can take that instruction there away and we're now only doing five instructions per vite so just by knowing our cpu a bit better we can remove two instructions and that saves whatever percentage that is it's what it's 5 over 7 more than a quarter more than a quarter that's 25% faster already just by knowing our cpu a bit better and of course this is something the compiler would do but we're still taking five instructions to copy one bite can we improve on that at all well let's think about what we're actually doing we are copying one bite at a time but could we copy more than one bite at a time well the arm cpu along with most cpus is quite capable of copying a single bite from memory or copying four bytes from memory think about it in terms of an analogy if you have a pile of books you have to take from one side of the room to the other if you carry one book at a time it'll take you longer than if you carry four books at a time exactly the same thing here if we copy more information each time then we'll have to take less time to do it so let's see how we could do that so we got the same thing r0 points to the destination r1 points to the source r2 is our counter and then r3 is the number of bytes to copy so the first thing we need to do differently this time is that we've still got the number of bytes to copy but we're now going to be copying four bytes at a time so we need to divide r3 by four so we can do that either by writing a divide routine but because it's a power of two we can do that very quickly by just shifting it to places to the right in binary which will divide it by four so we can do that on the arm cpu like so and i'm going to use a different register here asr by 2 so this is divide by 4 now why do we need to divide by four so we only need to do a quarter of the number of iterations around the loop because each time we're copying four bytes in each time so we need to divide it by four except there's a problem we're doing integer division what's 7 divided by four oh okay yeah so we're going to have a problem with odd numbers so we're going to have a problem with odd numbers or numbers which aren't a multiple of four so we can test with the the number is wholly divisible by four and if it is we can just copy it using this method if it isn't we can copy it using this method and then copy the remaining one two or three bytes that we need to to finish off copying it now that's fine as long as we're not copying one two or three bytes because then we've got all the overhead of testing for it so that's again something you perhaps want to know about your program if you're copying lots of small bits you probably don't want to use this optimized routine because it would actually end up being slower again you need to know about how your program works to optimize it to make it run more efficiently and then we set up r4 like that then what do we do well we set up r2 again as before comma zero set to be zero jump to our condition we're going to have our loop again so we're going to load in this time we're going to load in 32 bits so we haven't got the b there for bite we're going to put that into r5 then we're going to take that from r1 this time though we're going to add on four at the end cuz we've copied with four bytes and so we want to step on to the next four bytes likewise we're then going to store that back no b again into the address at r0 because we want to copy four bytes each time so we add on four rest of the code is the same we compare r2 with r4 this time because that contains the division by four if it's less than we jump back to loop and this is where our conditional is there so this time we still take one two three hang on why do we have four before and i've missed out the add instruction there we are add r2 comma r2a hash one so this time we've still got five instructions one 2 3 4 five but we will execute them five instructions now per four bytes rather than per bite so this time we'll execute these five instructions a quarter of the number of times that we had to here so here we're doing it five per b here we're doing it five per four bytes plus the setup cost we're ignoring the setup cost so just making a simple change like that can make our program it's only taking a quarter of the speed and again this is something that the compiler may well spot actually modern compilers can sort of make these optimizations now that works well for something as simple as this because actually we're using a sort of simple example but actually we can take this further you can use what something is called loop and rolling and this is great if you know exactly how many times you want to copy something so rather than just copying four bytes at a time now in reality there are instructions and copy more than four bytes at a time on most cpus we'll ignore them for now the same approach can take what we could do instead is have our loop look like this load into r5 from r1 poed there so we load in four bytes and then we store those four bytes okay there's no change there but then what we do is we load in another four bytes and then we store another four bytes here and we keep doing this to make our loop have more iterations in it but they're explicitly unrolled so the loop now here we would copy eight bytes and if we were to loop around there we'd copy eight bytes or we could say make it do 16 bytes or 32 bytes and that would mean that the cost per 32 bytes would be lower because we wouldn't have to keep testing whether we come to the end of the loop or not we could sort of gain a speed up then so what we're trying to do is reduce the number of instructions we're executing per bite of memory that we copied so unrolling the loop can make things faster now the problems you get interesting problems is that gets too big it then doesn't fit into your cpu cache and so we start to slow your program down so finding out what size works well really is dependent on what cpu you're using and what you're doing but the important thing is that don't do this until you actually know where you need to do it and there are places that you need to look at it with this example we just looked at one way that we could speed up by changing the code there are other approaches that you can take to optimizing your program that do similar things or different things so you can by changing the way you store your data in a program make your program run faster it seems counterintuitive and we'll look at it in another video probably but if you change the order in which your data stored then you can make it much quicker to access the data for certain types of operations and as i said if you really want to get some speed increases these sort of tips and tricks are good for things like a memory copy routine which gets called a lot in a lot of different places and you want it to be as fast as possible but they're probably not the tricks you want to spend your time on in your sort of everyday program unless you really need the speed there for example if you're writing a video decompression algorithm or something as part of a game then perhaps yes you do want to do the sort of loop and rolling because it needs to be fast it needs to get the data within a certain limited amount of time so that they can display each video frame on screen at the right time so if you look at the code for ffmpeg you will see these techniques being applied there to make it as fast as possible on whatever cpu it's running but for most programs finding the right algorithm will give you a far better benefit in terms of speed again i'm optimizing everything to the hilt test and so we'll run speed test back so our binary search is working now what would have happened is someone implemented this based on some textbook it works fine they considered their job done for the day and they went home right