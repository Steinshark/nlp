hello and welcome. i'm james murphy. in this video, we're talking about which dataclass solution is best for your situation. i already have a whole video explaining what dataclasses are. but for those of you that haven't seen that video yet, here's the gist. throughout the process of writing code, you often create classes that are basically just containers for pieces of data that you've collected. it's a good thing to make these containers because they can really help people understand the meaning of your code. take a look at this simple init function. all i want to do is store an int of float in a string. but here, you can see that n, f and s are repeated three times for each of them. this is already more repetition than i'd like. and it's only going to get worse if i want to add things like a hash function or a compare function to this class. dataclasses help me get rid of all that boilerplate. here's the same class. notice that there's nothing repeated in the definition of the class. i only have n, f, s and their type hints once. but this built-in dataclass decorator isn't the only solution that offers similar functionality. we're going to look at the different features that each solution has. and then also compare how fast they are and how much memory they use. if you're looking for the classic no frills dependency free solution for most cases, then just stick with the built-in dataclass. in my last video, the only reservation that i had about using the built-in dataclass decorator was that it didn't support slots. well, i'm using python 3.10. so, now it's just this easy in order to use slots instead of an instance dictionary. the first really good alternative to dataclass is attrs. sometimes attrs is a little bit more verbose than dataclasses. but it also comes with a little bit more functionality. in addition to supporting everything that dataclasses support including slots, attrs also supports variable conversions, data validation and default factories specifically for mutable arguments. here i specify a converter which is just int. so, anything you pass in, it'll pass into int before storing it. there are a bunch of built-in validators like checking if something is an instance of the right type at runtime. and you can specify default arguments and default factories for mutable things. even though you see me using dataclasses in most of my videos, i actually use attrs more in real life. attrs just has that little bit of extra flexibility that can make a big difference in a real project. the next three alternatives are just based off of tuples. whenever i talk about dataclasses, i always get people asking: why can't i just store this information in a tuple? well, of course you can, if you want your object to be treated like a tuple all the time. tuples are printed in a sensible way by default. and they're really fast and they're really memory efficient. if you just want to store three pieces of data, then a tuple is a good choice. if you want to make your code just a little bit more readable so you don't have to access everything by index, you can use a namedtuple. a namedtuple from the collections library is a tuple. it's a tuple that gives names to each of its elements. and that means that in addition to accessing things by index, you can also access them by name. this is a huge win for readability. but this syntax for creating the class is a little bit cumbersome not easy to read. and there's also no types mentioned here. if you want the exact same thing as a namedtuple but also with static type information available, then you should use namedtuple from the typing library. this namedtuple is a thin wrapper around the other one. it's still a tuple and it still behaves exactly the same as the other one. the benefit though is that this way of defining the class is much easier to read and it also leaves a space for the type hints. if you care about static typing at all, then you should always prefer this namedtuple over the other one. the main drawbacks to using any of these dataclasses that are based off of tuples is that they are based off of tuples. tuples are immutable. so, you can't change any of the elements after a tuple is created. you'd have to make a copy of the tuple with a different value in one of the slots. that means, you basically have to pay the cost of an instance creation every time you want to change something. the other main reservation you should have about using these tuples is type safety. you're not going to get any kind of error if you try to mix this kind of tuple and a raw untyped tuple even if you do operations that semantically might not make sense like using plus or less than. this is somewhat mitigated if you're actually doing static type checking. but you should still be aware. i might as well include dict in here because this is what a lot of beginners do. there's no type safety or even type information at all. and accessing things by string is really really error prone. i know it's really convenient to write something like this especially for testing or the first time that you're looking at a problem. but in my experience, using a dictionary this way is too error prone for my level of comfort. if this structure of having an n, f and s is something that's going to be used many times throughout your application and not just confined to a single function, then you should really be using a class. a very slight upgrade in readability from a dictionary is to use a simplenamespace. simplenamespace is just like object except it allows you to set attributes on it at runtime, whereas object doesn't its use is primarily to avoid this anti-pattern where you just create a class for the sake of creating an empty class that you can put attributes on. and by popular demand, the last choice that we'll be looking at is pydantic. now originally, i wasn't even going to talk about this. but in my dataclasses video, i got a ton of comments about pydantic. pydantic is a very opinionated library built for doing a specific task: parsing by default, pydantic will try to convert things into these types when you construct this object or set an attribute. and it will check those types at runtime. one of the common problems that you get when you're parsing data is that the data you're reading might not be valid or it might not be in the right format. so, converting things at runtime and checking types and checking conversions at runtime makes a lot of sense for the specific task of parsing. however, doing all of this at runtime is a huge waste of resources, both time and memory, if parsing is not your goal. if this data structure of an int, float and a string is something that's internal to my application and my application is primarily responsible for creating these data structures and modifying them and doing whatever with them, then it would be a huge waste of resources to do runtime checking. it would be better and probably even easier to do static type checking and to catch any type errors before the program even runs. so, in my mind, i don't really see pydantic models as an alternative to dataclasses. they serve a very different and specific purpose. if you are doing parsing, like potentially parsing json from a web api, then pydantic is a great choice. it's very good at what it does. it's just not a general purpose thing. and we're going to see that performance hit in the graphs that are coming up. okay, time to take a step back and look at the overall picture. first up, speed. how long does it take to create an instance, how long does it take to access an attribute on the instance and how long does it take to set an attribute? these are the creation times for each of the different classes in nanoseconds. so, these are all very small. however, you can see pydantic is losing by a lot because it's doing this runtime checking. that's a huge price to pay. so, let's go ahead and zoom in on all the rest of the things. there's a little bit of variability. but there's two pretty clear winners. obviously, the built-in tuple and built-in dictionary get preferential treatment in the language. tuple and dict are written primarily in c. everything else has to go through python. that means tuple gets to sit nicely around 30 nanoseconds. and everything else is taking about 300. if you care about this difference in performance, then you might need to be writing a c extension or just using c directly. so, if you're programming in python, i'd say that all of these should be good choices as long as each one has the features that you're looking for. alright, let's look at getattr and setattr. the first thing you should notice is that the getattr and setattr times are much less than the instance creation times. but that doesn't mean that you shouldn't worry about them. we often get and set attributes of a single object many many times. so, these little times can add up. here's the picture for getting attributes. basically, everything takes the same amount of time except simplenamespace and pydantic. it's a similar story for setting attributes. let's go ahead and zoom in so that pydantic isn't dominating everything. here, everything that's mutable, of course, is taking about the same amount of time. you can still choose to use an immutable thing even if you want to make changes to the objects. just remember that if you do that, then whenever you want to make a change, then you actually pay the creation cost not the setattr cost. that's because you basically have to create a new object that has to change data in it. so, unless the changes that you're making are extremely infrequent or if you're using a raw tuple whose creation time is just that low, then you should probably just prefer to use something that's mutable in the first place. on to memory usage. everything is in bytes and lower is better. everything that used less than 200 bytes is something that is tuple or slots based. everything that took more than 200 bytes used an instance dictionary. if you're programming in python, you're probably not too memory constrained. but if you're really creating a lot of objects, sometimes it can be useful to save a factor of two. this is a big place where attrs and data classes shine. you can choose to use slots if you want to conserve that extra memory or you can choose to have the convenience of an instance dictionary. finally, here's the feature matrix to help you decide which one is right for you. in my opinion, the best overall choice is attrs. the most convenient choice is dataclass. and the best choice for record like data is the capital namedtuple. of course, if your task is specifically parsing, then use pydantic. that's all i've got. thank you for watching.