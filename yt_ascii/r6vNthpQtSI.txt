okay so what is it we're going to talk about we're going to talk about parsing it's essentially the process of recognizing the shape of a particular input string and the process of parsing comes about it's not only a domain it's something from computer science but also comes from linguistics and can be generally used as a synonym to recognition or understanding some concept and computer science is more to do with and specifically in programming language is is it's more to do with a specific component inside of what we call a compiler a compiler is essentially a translator that translates one language the language of the programmer into a systems language so a compiler needs to be able to handle inputs and have outputs the compiler translates these handles these two so you have an input that is a string any sort of text data usually the first part in the compiler the basic stuff that a compiler should do is essentially parse the input and here the string let's say for example needs to be able to be analyzed and this has several steps in order to handle the string in the best way for the system you have lexical analysis of the string so say you have a given [music] multiplication 50 times 10 equals 500 and this is a string first what it's going to have to do is lexical analysis and here there's a particular reference to how how humans can actually understand information a computational interpretation of how we understand it would be to like analyze each term so like you have at the sentence my dad is coming home and you classify those into verbs adverts nouns etc what the parser does essentially is do lexical analysis which essentially means creating tokens tokens are each of the elements on the string so like 50 the multiplication sign 10 equals 500 the result and it needs to be able to do this because end of the day the string goes through a syntactical analysis the tokens create some sort of data representation and this data representation in order to be able to be translated it needs to be put through syntactical analysis this is the part that's really interesting because in syntactical analysis means in humans as well as in computers that you understand the string understand the sentence let's put it that way why is this important because semantics meaning the actual outcome what it means to understand a sentence comes out of syntax and syntactical analysis is basically done through a reference to context-free or any kind of grammar really context-free grammars usually meaning that if someone speaks to you in french and you don't understand french or don't have that module in your head you won't be able to parse it so that data representation will will have some sort of representation will be like a sentence you can understand it through the sent the be in a sentence but you won't be able to extract any kind of semantic content from the from the syntax of strings you can say they are letters you can say they are words you can say it is the sentence you can say it must have some content obviously with humans there's some ambiguity as they have like like they can say this is a door this is a door and you have the human pointing towards a door so and but it's saying in french hence you can do some active inference there and like make sense however it doesn't it doesn't mean that you are understanding the semantic content and this is all a part of compilers at the end of the day the compiler does a semantic analysis after it's checked that the string conforms to the grammar inside of the system and that's what parsing it the thing about compilers and parsers etc and the difference between i guess comp humans is that while we can certainly take an computational angle and interpret our humans as essentially computers and there are some similarities between how humans understand these things and how computers do there's a crucial sense in which humans can tolerate ambiguity can tolerate pragmatics can't tolerate different kinds of situations where informational content can be inferred but in the case of computers ambiguity becomes a matter of insecurity and that insecurity and not properly parsing inputs because someone someone didn't design a specific parser to understand a given string based on the grammar that creates a lot of vectors of attack for let's call them black hat actors because there are there are many ways in which a parsing error and a a a fundamental error in recognition of the string actually can create some pretty big errors buffer buffer overflows and exploit programming the the more the most systematic way of thinking about this is essentially you can create buffer overflows with this but you can also create what is called a weir machine and i think we can go into that as well but it's a it's a fundamental mistake in not thinking through parsers enough as a specific an important part of compilers and in a specific way in which computers handle that ambiguity that may prove to be insecure now i've got the token so i can load a value in add the value for my merger into it and store it back and hand the token and now i've got the token again i can load something into it into my register add something onto it throw it back and pass the token on and i've got it so i can load the value in add the value for my register store it back