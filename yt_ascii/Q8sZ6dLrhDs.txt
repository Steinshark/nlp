every day orbiting satellites send down thousands of terabytes of remote sensing data that's great but how can we interpret and analyze all this data there are crowdsourcing efforts online like openstreetmap which has been around since 2004 and has 5 million volunteers yet despite all those volunteers there remains completeness and quality issues and even in urgent conditions human mapping analysis takes time in 2017 5000 volunteers worked to map out puerto rico's roads and buildings after hurricane maria despite this the effort still took a month but in recent years powerful artificial intelligence techniques have emerged to do this remote sensing analysis at scale in this video i want to talk about the increasingly bigger role that artificial intelligence and deep learning in particular is playing in satellite imagery and remote sensing we all know that getting into innovative technologies early might lead to big money so it's no wonder that microsoft recently announced a 10 billion investment into ai but they're not the only financial backers top wall street firms are desperate to unlock new sources of growth and some developing markets that are just starting to hit the mainstream are their cream of the crop in fact there's one fintech platform based in new york city's financial district whose performance has been so strong thus far that cnbc the wall street journal cnn and more are raving about it masterworks has unlocked the potential of contemporary art a 1.7 trillion alternative asset class previously only available to billionaires but with masterworks everyday investors can enter this potentially lucrative market for thousands not millions why art for one contemporary art has outpaced the s p 500 by 131 percent over the last 26 years and while traditional investments like stocks and bonds were getting crushed in 2022 masterworks investors realized nine returns ranging from nine percent to 36 percent putting tens of millions of dollars right into their pockets in fact demand is so high masterworks offerings can sell out in minutes so join over six hundred and seventeen thousand people including many asian armory viewers by claiming you're free no obligation account now at the link in the description thanks to masterworks for sponsoring the channel in 1959 a year after the united states first achieved space flight the cia launched the corona program its goal was to develop a photographic satellite capable of replacing the u2 spy plane then in 1960 a soviet rocket shot down said u2's spy aircraft flying 25 kilometers above the surface pilot gary powers was subsequently imprisoned in the soviet union for several years this political kerfuffle accelerated development on optical satellite surveillance technology aided along by subsequent advancements in computer processing power and analytical photogrammetry from the moon program the first civilian remote sensing applications were related to the weather starting in 1960 tyros and his successor nimbus helped develop meteorological knowledge of our earth regularly supplying images of global coverage then in 1972 the u.s publicly released the first satellite images from its landsat program this program essentially founds the remote sensing industry as we know it today with various real world impacts mapping forest fires oil spills land cover agriculture maritime travel and water quality monitoring other countries have since started their own programs like the eu's copernicus project and china's gaofen project not to mention all the satellite imagery being produced by private companies like maxar as well so now there is an immense wealth of remote sensing data available to people looking for it what is it about remote sensing data that makes machine learning techniques so valuable first of all there is a whole lot of it the copernicus project sentinel 2 a and b satellites produce 9.54 terabytes of data each day this amount is accelerating as other companies enter the space this data is not only available in very large volume but also very large variety there are so many angles that we can look at first we can get it in a variety of spectrums so not just visible light but infrared uv etc this is referred to as spectral resolution for instance there are remote sensing systems that actively bounce radio waves off the surface for insights essentially radar these techniques work regardless of the weather and helped map the surface of venus remote sensing data is also available in a broad variety of detail with pixel sizes ranging from 100 kilometers to one centimeter this is referred to as spatial resolution remote sensing data is also widely available in a broad variety of times or the intervals between which the images are taken this is referred to as temporal resolution the finer the temporal resolution the more times the satellite visits and images the location new research in ai and machine learning for the remote sensing industry is moving very quickly across the entire value chain remote sensing image data is processed analyzed and utilized in a series of steps a pipeline it is like how your iphone processes the digital image data of a selfie and same as with modern computational photography researchers are applying machine learning and deep learning techniques throughout this pipeline to unlock far more value at the very start is the task of acquiring the remote sensing image data itself this means getting it from the satellite uav or whatever system you used after that we have the processing these are steps taken to improve the data's quality what does that mean a simple example is cloud masking clouds mess up satellite images they not only block our view of things but also cast shadows that mess with resolution and cause data analytics errors therefore researchers have created deep learning algorithms to automatically flag clouded areas extracting the non-clouded areas for use further down the pipeline one of the most closely studied processing steps however involves improving the image data's spatial resolution most publicly available satellite images are limited to certain pixel resolutions this can either be for hardware limitations relating to the satellite ccd sensors or data transmission for instance or financial limitations a satellite can easily cost nearly a billion dollars all in or regulatory reasons which include national security issues these lower resolutions interfere with our ability to run other steps further down the line like object detection change detection and image classification things we will talk about more down the line for instance objects like cars might only be something like 10 pixels across in a satellite image which causes problems if there are a bunch of them densely clustered together so we need more pixels neural networks can be used to algorithmically derive higher resolution images from lower resolution ones a technique referred to as super resolution super resolution is a classical problem in computer vision with two general approaches single and multi-frame let us talk about single frame first the first publication to propose a deep learning approach to single-frame super resolution came out in 2014. super resolution convolutional neural network or srcnn these are trained using a training set of low and high resolution images they fill in pixels lost from the low resolution image with the assumption that this unknown patch of pixels will probably look the same as some other previous patch of pixels in the training set these tools aren't unique i use a newer network based tool called topaz gigapixel to upscale images but satellite imagery have challenges different from other types of images for instance scale since satellites take very wide range photos the image contains multiple scales within a single frame secondly satellite images don't have good texture data because of their low spatial resolutions and data compression techniques this makes it hard to quote unquote identify the scene to illustrate if you are upscaling by a factor of 4 for each pixel in the original image we need to generate 15 new pixels if the original pixel covered a 4 meter by 4 meter plot then each of the 15 pixels generated by the ai have to show a 1 meter by 1 meter plot that represents a whole lot of detail that the ai has to essentially make up and most models are not ready to accurately do that so many super resolution techniques instead focused on enhancing corners edges and identifiable objects research has shown that running the super resolution image techniques can improve the performance of an object detection model by nearly 40 percent a pretty significant improvement if you think about it we really are going models on top of models as i mentioned earlier there is a second way to produce higher resolution images multi-frame super resolution which sometimes overlaps with a technique called image fusion in my previous video about mobile phone image processing we talked about how modern phone processors do something called image stacking cameras take image data from before and after we hit the button and lace them together to get a better overall image we do this for satellite images too in a method called pan sharpening satellite sensors often take the same images and different light spectrums we can merge those together to create a single high resolution color image and sharpening itself has been around for a while and does not require deep learning per se but neural networks have been employed to improve the quality of the final outcome image fusion can also do more than just make better looking images one recent interesting example involves the use of a neural network to annotate modern satellite imagery with details from old digitally scanned historical maps now that we have processed the data we can go about running analysis on it this is where we apply various techniques to extract thematic or object information about the scene this is a massive field and we cannot hope to get all of it however i'm going to try to compile all the greatest hits object detection object extraction land use cover classification and change detection let us start with object detection and extraction object detection involves the ai finding instances of an object within an image for instance ships and bridges usually it tags these items with a bounding box object extraction is harder than detection the goal is to isolate the object from the image like a road or lake this requires the ai to know the item's pixel boundaries a box is not enough neural networks have made big contributions to these object problems we use satellite imagery to track blooms of sargassum seaweed in the ocean these blooms can wash ashore causing issues the trouble with classifying these blooms is that sargassum blooms take the form of clumps mats and rafts from space these can look super small indeed if you use the data of certain satellites like modis for instance the detection threshold is 0.2 percent of a pixel this means that traditional classifiers miss a lot of sargassum combining deep learning with higher resolution imagery has been able to improve the extraction accuracy to 95 percent a leap ahead of the previous classifiers 86 accuracy and then there are roads they deserve their own section automated road detection and extraction can be incredibly useful in emergency situations so to know where cars can or cannot go but they also present a tricky technical problem first roads look very different depending on where you're looking a model trained on road data from the city of las vegas in the united states won't work all that well on image data covering the city of cartom in the sudan secondly rode satellite images suffer from image variations due to trees coverage shadows so nearby buildings and all sorts of weather and ground conditions not to mention that cars drive on roads and their image data can mess things up too third we need to know more about a road than just the fact that it is there how many lanes does it have is it drivable is it damaged neural networks work better than other existing methods with variant advantages and disadvantages depending on the specific type of neural network used however they still fall short of human manual methods due to the problem's complexity and a lack of good training data researchers have released data sets like deep globe as a way to further help train and produce better ways to accurately locate and extract the hundreds and thousands of kilometers of roads in our world in the same realm of the road extraction problem is the problem of understanding how land is being used is this land forest meadow water farmland or urban neighborhood this stuff has immense benefits for instance identifying parcels of farmland in mountainous areas is hugely cost saving and insightful on the outcomes of economic policies but again we suffer from the same shortcomings despite crowd-sourced efforts it is hard to find large well-annotated data sets most annotated areas are small maybe 10 kilometers or so worse yet the annotations are not consistent with one another what might be savannah or open shrub land in one data set might be classified as wooded grassland or tree cover slash mixed leaf type in another gosh worse worse yet since the world is so varied models trained on one area's data sets are not easily transferable to other locations scaling up to larger areas is challenging that being said there has been some good work done with neural networks covering larger areas neural networks can look at aggregations of 5x5 up to 64 by 64 pixels for classification at a medium range they are fairly good at this range however the downside of this is that we have issues of over slash under segmentation in other words the boundaries between the classifications are not super accurate remember each of these pixels cover a few square meters by themselves a satellite can only visit a scene once during its orbit around the earth remember temporal resolution this is a fundamental limitation and that is fine most of the time things are not going to change what we want to know is what actually does change this is called change detection tracking state changes or differences in a scene over different times change detection has many useful applications we can use it to track deforestation or agricultural growth or assess the impacts of natural disasters like earthquakes hurricanes forest fires and so on or we can use it to discover new military installations or track the movements of the enemy on the battlefield early approaches to the change detection problem were pixel based in other words comparing the pixels between the two time spans and noting their literal changes what makes this hard is that not all change is useful or relevant to the situation for instance cloud fog or dust moving across the scene is quote-unquote change in the literal sense but does not matter the deep learning approach consists of two steps it first stacks two images together and takes the differences the trained neural network then chooses the differences it believes to be actual relevant changes the useful applications of this technology are virtually limitless i talked about how we can use ai to rapidly generate accurate maps of usable roads after a natural disaster or how we can track farmland parcels in remote areas to evaluate the performance of an economic policy or using nighttime satellite imagery to track light use has a proxy for economic growth there is a really great paper from the world bank that estimates the relationship between light growth and economic growth saying that a one percent change in gdp is associated with a 1.55 percent change in nighttime lights one big influence has been the open source community people have used powerful open source machine learning tools to analyze publicly available image data from programs like landsat there are a multitude of projects that analyze satellite imagery to count oil tanks trees ships and boats cars planes and utilities animals too i absolutely love this one project that talks about using satellite imagery to detect and count walrus populations on a more serious note these techniques have done incredible work during the recent crisis in ukraine generating actionable intelligence for fighters on both sides knowing what the enemy is doing and where they are is very important and ai has had a huge role to play in that going forward one of the big challenges for the remote sensing ai industry is figuring out how to process and analyze this data without the need for large annotated data sets this is referred to as semi-supervised or unsupervised learning with all the data coming in nowadays from various sources processing it all at scale will require as little human involvement as possible more automated end-to-end pipelines need to be developed and finally there is the question of hardware deep learning models for remote sensing can have millions of parameters requiring rather advanced ai accelerators the unlimited possibilities of ai in the remote sensing world make leading edge ai hardware and the techniques to produce them even more important than it was before it's an astounding advantage all right everyone that's it for tonight thanks for watching subscribe to the channel sign up for the newsletter and i'll see you guys next time