so what this talk is about so first of all somebody told me that you're supposed to put up a link to your slides and then speak it out loud so this is tinyurl.com dy meet cpp 2023 right it should open from the phone fine so now if i see you on your phone i will assume you're very intensely looking at your slides all right so i appreciate you tired by like stay with me raise your hand if you at least in part write c++ for performance yeah so this looks like you know substantial percentage of the room like almost everybody we give up so much for performance like garbage collector is nice like it's slow but it's nice like we cannot check array accesses like everybody else panicking right core dumps i hate core dumps but all of those things are there for performance and simd as a technology i appreciate don't know most of you don't know what it is is kind of the same way it gives you very serious performance improvements at the price of your comfort like hiring people is worse than c++ and c++ was already hard right all those things so raise your hand if you wrote any cimd this is much more than i expected this is very cool all right like please tell me afterwards what did you do but i suspect you didn't do this stuff because it's a bit weird that's not what usually people do we're going to do mcmp copy if set intersection and sort right so the thing is that algorithms are very different and i'm just going to explain algorithms this is kind of the closest you can get to a college course on algorithms except like on cd and dance in an hour so it tends to be pretty difficult if you can ask me questions and you you don't understand you can shout i will try to answer and if we don't make it through everything who cares like it's not a marathon i know what to come okay let's do mcmp so mcmp right two arrays can you see my corser perfect two arrays we need to compare them return like you know less equal greater is there a c+ plus standard algorithm we could use if we wanted to write this ourselves there are two i know of anybody stood equal not quite because it justs your bull there are two what how would you implement st equal internally with which algorithm mismatch yes that's one the other one is c++ 21 it's called lexic graphical compare freeway so now you know all right so what we talking talk about mismatch and mismatch at least in code will do something like this so you take a bite from each array and you compare them one after another right then you look at this and like can you make this faster who can make this faster okay yo so eight bytes at a time you can do eight bytes at a time exactly i'm going to assume that's what you said like all right so you could do eight bytes at a time right and theory comparing eight bytes should be the same instruction as comparing like one well almost the same instruction as comparing one bytes except you do eight times the number of els right okay there are a couple of like nasty things about it like your pointers are not aligned you have to do unaligned loads there is like a tail there that is annoying that is less than eight by the way in c++ it's a bit small but you do unaligned loads with m cpi okay you copy from the pointer to the integer and will do the right thing all right who thinks that if this was beneficial compiler would do it for you five six i don't know like very few people ah you don't trust me very much and don't trust your compiler you're correct everybody else the compiler doesn't do it for you so this is stand that mismatch for chars this is whatever i wrote within 64s does anybody like there are two reasons why compila didn't do it none of them good and can guess okay yo i didn't quite hear the i don't think so because you don't write so the answer was alas sync i don't think so because you don't write anything anywhere so it shouldn't be a problem anybody else okay so think about this like the way that mis much would be written it would be written while we don't reach the end end right or while we didn't find the mismatch so it's not quite equivalent to loading eight bytes at a time because it may be possible that you just said i have a million elements but you interrupted the second one and that's it right and you don't actually have the million elements the mismatch has more guarantees as a standard library function so they could do it that's the first reason and second reason there is not a way to do it like there is function called sn cmp right which has exactly the same properties like you compare strings until certain size and that function is vectorized i'm not going to explain how you can ask me afterwards but so the compiler could do it even in this restrictions anyways this is standard mcmp and standard mcmp yeah you practically cannot see it somewhere it's 32 times faster more than 32 times faster than our standard mismatch right and it's about four point something times faster than in 64s and why it's actually not not that smart there are smart people wrote this and i did some really clever things but for most part they do the same thing we did within 64s only they know that on my machine you can use 32 byte registers and that way you get 32 times speed up right cool so what we're going to do today is we're going to learn how to write this kind of code right okay so ah i didn't mentioned so this techniques where you use one instruction to process multiple pieces of data is called syn instruction multiple data that is simd right and this big registers that are specifically designed for it are called simd registers we're going to access them through e library there are many different ways it's a library it's on github it's boost licensed it's developed by j fu jean la prest and me however like we don't care really about the library today right if you want to learn about the library there's a talk online called simd and c++ 20 if of a new era right and we we just care about algorithms anything that generates you see the algorithm should do something like that and in the library there is a if algo mismatch which ideally should do what what we wanted here let's see how it performs so this is n64s this is standard mcmp and this is if alis much is a little bit slower than mim cmp like because they write specifically mcmp they did more tricks that i didn't do here however this is x86 on m1 if miss much beating standard mcmp substantially on this benchmark and i know why and i'm super proud of that i can tell you afterwards if you want to know all right so kind of like seems like if miss if mis much is the correct thing right i mentioned a little bit like on this machine on that machine thing is that when you compile something you have default target right you compile for some like fairly old computer right to in order to run your binary everywhere and that old computer doesn't really have all the sd ition you would like to use so in order to take full advantage of sd you need to compile your code correctly i'm not going to explain how i'm just going to show you it's important right so this is eal mis match without just all free and this is compiled correctly for that machine and it's a 2x difference right so both of them beat in 64 because we know more about that default machine but still okay so let's look inside mismatch and inside the if mis much you'll find f diff with the zip which is very cool we're really proud of that even the rangers libraries it took insane amount of effort to make this work but that's not quite helpful as far as algorithm is concerned so let's assume that we're going to write this by hand so okay can you somewhat see it all right coc so what we we're writing here is this code that will compare two really big registers right so first we need we so we accept two pointers right this is where we're going to take our really big registers from and first we need a type for a register in if this is called if wide right and so this on my machine will be 32 byte register okay i'm going to load a 32 by register from both pointers right this is our starting to compare those 32 mites then we're going to compare them for equality so in many sd libraries even included operator equal not equal are overloaded to return you not just one boolean but like a bunch of booleans so here we return the special type logical and this is like 32 boolean values does it make sense cool right and then we call something think called first true which will compute the position so okay let's have a look at example right so 0 1 2 3 0 923 right the second element with index one is true right in this case first true will return us one right if there was nothing there it will return us a null opt cool all right so most of the time we will not find anything like imagine you mis much you go and you compare they all equal you go to the next one compare they all equal right so in this case there is no much and we just go to the next register otherwise we need to compute like okay so this was one so we will adjust to the place where they mismatched and return that okay there was a mismatch i'll give you a second to look at this in case you can you can ask me a question if you want to perfect i will assume not everybody's asleep does much h does much is much is a bitfield m much is optional pt optional integer right so if you have a position like let's have a look at how first through works i will show that in a second okay but hopefully if this question still stands please do ask me so i'm going to explain how first through is implemented under the hood because it's kind of important for understanding how sd works there's a caveat that sv there's rmsv very fancy new extensions those are very different and there f to doesn't work like this okay so this is our logical logical is usually some special cd register right representing 32 bulls in our case and we want the first position position of the first true which is this right okay so on many platforms there is a special instruction that says any are there any truth at all right and if there and this is our null opt case right we can check oh was there a much no go to the next 32 b otherwise what we do is we construct something in if we call top bits so this is a simd register and this is an integer right where it's a bit mask where each each integer represents kind of like true or false by bit hopefully makes sense the only caveat is that to be efficient it's not always one bit but we pretend on the interface that it is one bit right sometimes there be two or four but all right so if this is an integer and this is an element you want position of the element you want how do i get it quiz anybody sorry pop count is the number of set but you are very close this sc forward in stand c++ standard it's called count trailing zeros right so this is little indian integer this is like so this is a first zero this is the second zero this is like so we want to count that this is standard count trailing zeros we know at least about this okay so okay all right so yeah and i'm just i'm just going to show you this for for the sake of the code just so so this is the assembly that function compiled to let me make this quick bigger i know right and so this is top bits construction like this function so on e86 there isn't really any that we use so we just always construct top bits with this this together becomes an any well this together becomes an any right and this is bit scan for what we talk about so this is like the whole first through becomes like free instructions if you didn't understand this is fine it's just showing co instructions okay there is a standard proposal that you may be heard of of standard sim so let's have a look how what we do in if compares to what they do they have different philosophy but you can algorithms will will map fairly well so what we call wide they call standard sd what we call load they have a method called copy from what how logical they called standard cd mask they have the same not equal operator and finally what we call first through they split into two functions one is called any of the other is called reduce mean index right and it requires that any office ch so they split office i'm perfectly fine with this except i think that reduc mean index is a completely awful name all right so if this kind of mismatch happens mcp kind of makes sense this we're going to go to copy if unless you want to ask me about mcmp like how it tails is completely outside of the scope for this i'm happy to talk about that all right so copy if right like the first time i heard about copy if it kind of like completely buffed me because copy makes sense like you take a big register you load your store right how do you copy if there is this notion of compress in cd programming right it kind of looks like this so you have a register and you have a musk and then you take all the selected elements and you kind of push them to the front so the reason i call this notion of compress and not like a compress function is because sometimes this is horribly inefficient right to do exactly this so instead in if we have a bunch of different functions that all have the word compress in the name and that you use for different scenarios where would you you would use this instead the one we want here is something called compressed copy so i have an input array a musk and an output array and now what i do is i take the selected elements and write them together to the output and then it will return where it stopped so if you had this function who thinks they can write a copy if okay i have a few hands right now think about it you load the register you you test it okay you get the predicate and you do compress copy okay there are a bunch of variations to compress copy one important one is safe unsafe so what unsafe says is that it can write a little bit of garbage on the end right so basically it's going to like move elements in your register around and then it really wants to write the whole register which means that there is some elements that were not selected written to the end the second variation is sparse dense basically do you expect a lot of matches or not yeah like sometimes you want like just one element per register or something or two on average all right let's talk for a second about the interface of copy if so this is the interface of standard copy if first last output return and output iterator does anybody see a problem for us i'll highlight it so the output iterator means that you don't know how much space you have which means you can never use unsafe compressed copy you always have to do safe and that is very slow right so in eve everything is ranges based and then there's like you know input range output range and now i know i can write the whole output range and i can use unsafe compress like there is a little bit of a check because of this for safety now which obviously we all hate i'm working really hard to remove the last safety check from there no worries all right there's a bit of a problem right so imagine you have a million elements and you copy them into an array of two elements right like okay you would expect that at some point you fill in the two elements and then you would like to stop right so it will stop but you want to do something with those two elements and continue so you would like to know where did you stop in the first array unfortunately i couldn't make that work like just just this is just hard so for now just no luck by the way i talked to bryce about this at some point bryce liba who led the parallel thinking the standard committee because they have standard ands now and i looked at that i'm like how are you doing standard ands and the idea there is standard tek is allowed to allocate so what it would do is it would allocate you a buffer copy if there and then you copy to the output you know not amazing but it will give you some speed ups all right let's talk about how compressed copy is implemented there are two versions in e library fundamentally one is sort of pure cd where we just throw a bunch of like complicated sd instructions in it and this is way too much to explain here so i'll just give some main points right so on some very fancy platforms you have instructions so ix 512 some have sp have some our main implementation is based on the work of the teof flower user acit with really tiny lookup tables if you have bmi 2 and it's well implemented peter cardz proposed a really good solutions that we use does anybody know peter cardz by the way like the name on st overflow like he answers yeah i see one hand peter two perfect peter cardz is amazing person who answers like every xh6 question on stack overflow it's insane and finally there's a switch and shuffle solution proposed by zason we use a different switch and shuffle solution but we still acknowledge has contribution all right the second implementation i will explain here and it's sd scaler this works remarkably well for sparse output when you have like very few mat we have the input we have the register we have the mask let's construct our top bits and let's effectively do first through right so count trailing zeros and then we copy the first selected okay now the clear the last selected bit do another first through do another copy so this is a loop where we go through all the selected elements using count trailing zeros if you have one or two mattress this is very good i'll show you in a second so this is independently what proposed by peter cardz and ar all right benchmarks so this is standard copy if benchmark no elements are copied all of the elements are copied half the elements are copied okay this is a sparse so this is the second one that i show you cd scaler which has bit scans and you can see that it performs really well when you have very few matches so in 5% for example it will give me here three and a half times speed up compared to the scala baseline right same computer same machine three and a half times speed up of copy and this is a bmi2 cdcd solution it you see it performs very well everywhere and it gives me like whatever three times speed up here question looking at this graph of just standard copy if do you you see anything weird okay yeah you copy more but give me a second if you copy if what will be the worst case you copy zero elements half the elements all the elements half right but here is not half here it is half right so this is shorts basically what happens with with shorts i have twice as many elements in the same size and my processor can no longer remember all the branches so the branch predictor starts messing it up right and when the branches branch mispredict happen the sim diversion gives you more than 10 x speed up because it doesn't really have any branches all right this this m1 on m1 the spar didn't really work but the sd sd solution gives me what four times speed up and this is m1 shorts i just thought it's really cute that it draws an m on m1 all right so what about the cd proposal well they have this function called compress right i explains that it's kind of not ideal for some platforms so they think that they maybe can be able to optimize some of this stuff but the worst case scenario is basically you will have to know whether or not you can use compress by the time you get this the processor will be much faster much better much newer so hopefully you will more you will have compress actually shipping okay actually how we doing on time let's do sort first sort is like qes and set intersection does anybody have a question about copy if i can answer that size of the elements you copying what do i mean like ins versus shorts versus so that's a very good question generally speaking with simd like the size the the performance depends on the register size so if you have let's say 16 bytes you can put there four integers or eight shorts generally speaking it means that the speed up for shorts will be twice as big because you can do eight shorts at a time and not and four ins at time for specifically copy if you will end up in a situation of for chars you cannot do 32 times you can do only 16 times like was the way i wrote it on my machine okay cool so let's do sort unfortunately i did not implement sort like it is i haven't gotten there yet it's a lot of work but other people did here everything i read on the subject i'm not going to name everybody but i'm going to name like specific people i take explicitly from all right the key building block to sorting an array is to be able to sort one register the first time i saw this idea came from like a blog called a question of sorts by seven degrees of freedom which i thought was keute and this kind of how it works i'm going to explain how you sort two elements and then i'm going to say and then and we sort the register okay all right so this is my register it's not sorted and five frame step one i'm going to shuffle the elements around like shuffle is a operation where you take the elements in your register and you move them around here i'm just swapping adjacent elements so i have five free became free5 now i'm going to do min and max min and max are both ver like between two registers right you take element from here element from here min element from here element from here min countes fre fre 5 five make sense cool oh sorry and then i'm going to do something known as a blend where i take it's a mixing of two registers together here i take one element from here one element from here this way i got the register sort two elements register and it turns out that shuffle minmax and blend are enough to sort any cmg register it's just a bit again too much to explain here if you want to know how to do it there are a couple of keyword words you want to look for so sorting networks and specifically everybody use bonic sort this one i have implementation of and i still don't understand it like it's very confusing it is it is so non non obvious all right but works well okay so now who can say me there are three functions that build up a quick sort who can name them like partition it's the second one in my my list so i'm not going to show it yet p selection partition and the third one no insertion sword so quick sort doesn't make sense beyond certain sides so when they go to like 16 elements or something they do insertion sort every implementation does something like that so okay this last one let's see how we can build all of those right so this last one is fairly simple so what if we partition up to a register size and then we sort the register right and then you have like small sorted component of like eight elements and then you sort the eight elements the whole register sort make sense cool let's talk about p selection is there a way that somebody sees that you can use sorting over register to help you with pavot selection you need one pavot to be clear okay somebody name me p p algorithm something first element fantastic doesn't help sort here like but anything else well these new random element right but most of them are like medium of three medium of five like so medium five is a different one but you select some number of elements you select the medium between them right and you can do selecting the medium with sim dort so let's see how that look this code i took from x86 s ort library like the top contributor seems to be raak develop very sorry if he's not actually the most important contributor but he was seems like the most commit at the time i looked all right so this is what they do in intel so they select elements with equal step right through the array then they do something called gazer where they load all of those elements together into one simd register and finally they sort and this is your medium value i want to talk about this gazer thingy if if what i'm sorry yeah i want to talk about gazer the first time i saw gazer i was like this is the answer to all of my problems i'm going to write just everything with gaza it seems like super powerful instruction the problem is it's slow and there's no magic to it right it's is either there is an instruction or they do one by one into array and then load that there's nothing there and basically regardless of how it's implemented you have to do the loads right well whatever you can do two loads at the same time on xh6 right so you will have to do that those loads no grace but here i i had never been able to use gazer to speed up anything so far i know some other people have but here it pivot is kind of not the most computationally expensive so it's fine all right so now partition partition is tricky i take this from sorry all i take this from this goes to 11 block by dan shor i believe his nickname is damage boys that's easier to google all right this what they do so let's take a register from each side of our array and just throw them away somewhere like we're just going to store them on a stack whatever we just want some space we don't care about the values now we're going to take take an a register we're going to load it and we're going to sort it and then using first through we can find the first position where the pivot would fit right you compare everything about the p you you find first true so this way we just partitioned a register right everything here is less than p everything here is greater than p now to be clear this is not in amazing way to partition register on many platforms you can do some compress like tricks to do partition but for the general purpose of something really weak that can be not bad all right now what we do is we take this partition register and this is our space like so this is two registers wor of space this one register worth of space let's write it into both sides and then we're just going to say everything be before this is sorted partitioned everything after here is partitioned as well and this is whatever this is free space this is free space so we can try to continue algorithm by selecting a register here because what what will happen we have enough space for register here we will have enough space for register here all right have a think for a sec because i know this this is this is probably the most difficult one like you have a space you sort the register you put in two sides boom you have some partitioned you will have enough space if you load the register from one of the sites okay if you kind of didn't understand at this point it's fine so yeah i don't have the benchmarks i don't have this implemented but just some numbers say 10 x some num say 17x i don't know like the measuring sort is notoriously hard but clearly there is something there i think the intel s disort is now in numai all so how are we doing 30 20 we we'll we can do like most of set intersection tell me when it's five so we can take the questions or whatever all right we might not do the numbers but we can do so all right so and turns out during my practice runs that not everybody is very intimately familiar with all the standard algorithms and they cannot tell me out of the box what that intersection is it's all i have to explain so set intersection is one of the merge algorithms it take two arrays and do merge like thingy specifically it looks for equal element so you take element from here equal element from here compare them and the smallest one at once when you find the equal element you write that to the output all right if you have that can be duplicates like it's just ar race sorted ar ras but duplicates are allowed the standard defines very well what happens with duplicates we will not we'll just relax that requirement so and then you go further and finally get the second one all right so there are two implementations of set intersection one is simd scaler look look something like this so you have the first array and ideally it should be smaller array than the second one and you have a second array now what we will do is we'll take one element from the first array and we'll take a register from the second array right and then what i will do is i will take this element and write it into every element of this register this is sometimes known as broadcast because i wrote one value into everything and then we compare this register against this register so think about it like in this scaler version you compare element against element right here we kind of been optimistic we will compare one element what if we compare it against first second third boom right all of them and then maybe if all of them are less we can just advance right by the register size and if not all of them well let's test for equality and then we will test one against many for equality right if the if if equality is true we have to copy to the output boom we found the intersection and we advance the first element array okay i see some nodding i really appreciate you nodding this is really nice all right the second one is harder it's from this paper faster than native alternative for 66 vp2 intersect instructions by g mia scaners kind of looks like this we have two arrays and this time we kind of don't care if they're the same size or not it's fine what we do is we take a register from each of the arrays and then we do really expensive operation called has equal in which compares each element from the first register for equality against each element of the second register and then what we do is we do compress copy so what that did us is basically we intersected the two registers now we need to advance how can we advance well okay let's look at this element like the last element in the first register and let's try to find it in the first in the second register right so any matches for things after it cannot be here that's for sure so we can advance f to here right because anything here cannot be matched to anything here same thing we do in reverse so for take this element look in the other uhhuh okay that's not a question yeah it's a bit tricky thing about this what is really nice is that even if you have very intersected arrays you guaranteed to advance quite a bit if you don't have duplicates you can try to prove that you advanced by a lot but okay let's talk about has equal in so it's actually like there there was the alternative to vp2 intersection stru there's an instruction to do it on like6 but we i don't have it and in the papers they don't suggest to do it they suggest to do very silly thing so you have first register and you have a second register okay let's compare them against this and then let's rotate this register so that way i can compare against you know against the first element against the second element and against all four elements like each one this seems like a lot right like just just whatever instructions but think about it so this is not always a rotate to be optimal but it's always one instruction right almost like as good as it gets right so this is equality and this is or like ideally this is port five this like you know whatever part zero part one so in theory if everything works out you can do three of those in one cycle which is like which means that you should do like the number of cycles you have in the register elements which is pretty good in fact in the paper because they target like really fancy instructions they merge these two into one instruction by being really clever okay so how we do 10 minutes let's do set let's do benchmarks 20 how it was 20 20 minutes all right so this is a set intersection benchmark like just standard one on the left it intersects small array with a big array right so this is 5% of all elements 95% of the elements here is half and half the number of elements stays constant the dist the difference is branch prediction right now this is let's do this one so this is a simd simd version right so sd sd version is about one and a half times better on the left and whatever four point something times faster on the right and the simd scaler version which was really simple is actually ridiculously good this is 20 times speed up on the left right almost 20 like whatever crazy and this is again even in the situation where i would not expect a good speed up where there say same size it still gives me like four and a half which is also very nice okay this is m1 on m1 the sd sd approach didn't work but the sd scal approach still gives us a really good speed up this is 10x right this is two and a half all right in defense of the people wrote the paper right so i'm target on m1 we have a 16 by cd register on x86 this6 i have a 32 by sd register you can see that here it performs relatively better i suspect this is a dependency that the bigger register size you have the better the sdcd approach would perform they target 64 bit byte registers so they should maybe have another layer of speed up over this okay all right do you have questions about sort s section or sort it's also co no all right so i really appreciate people who work with me so z falco and jant la like they work with me on the eve library and all the amazing people who share their research online and i can look at it and finally you can find the library on g hub you can find the slides again tinyurl.com dy mecpp 2023 i did a similar talk with different algorithms called my first simd i cover sten find reduce in in inclusive scan and remove and there's a talk about the library cd and c++ 20 if of a new era and finally on slack on cpp l slack who is on cp l slack i see one person you should be on cpp lenss log it's a just type cpp lenss log into google and we'll find it like it's a really cool place they have a simd channel which is very low volume with very smart people who will answer things and you know low volume until i'm renting but so that's it for me if you have any questions i'm happy to answer [applause] one question to more system architecture rather than now the software side if i would use simd operations m on a hyperthreaded hardware would this become a shared resource then because i probably only have one simd per core or po per cpu so my my hypothesis would be disabling hyperthreading would remove like the shared resource of the simd so i can i can try to answer that to the best of my understanding of this caveats applied that not the really hardware hardware expert all right so with hyper so your cpu core can do four instructions per cyo right like if you have really fancy maybe more like i i just always count as four so if you can do for instruction you can do like two editions right two sd editions or whatever one shuffle right how much do hyper threads fight for those resources i would not expect that to be any different from scaler curve right people definitely use hyperring or not use hyperring but all depends on whether or not they can get up to 3 point something something instructions per per core in something like a compression yes you can like smart people wrote really good compressions or encodings right they will get to up to four and their hyping will be a disaster something which is memory bound hyping is life saer like so i would not expect any simply specific issues here okay thank you how did the cach sizes on your machines compared to your testing data set for your benchmarks everything fits into that for okay did you do any benchmarks with memory bound data for for n for this no like so it is true the the the thing is that the simd code has this problem which is basically it's not really problem but you do whatever with regular code you do eight bytes at a time here you do 32 bytes at a time right you exhaust your cash much faster buer so there actually there's a paper by alexander stepanov where what they do is they do some really fancy compression i didn't read the paper i just read the up star but they did real fancy compression to kind of trade off compute for just speed of loading data from memory right but just it's not that you couldn't predict a cach misses just couldn't load data fast enough yeah so it is true that sometimes you will be memory bound and seemd will not help here like i don't know but as far as benchmarking goes it's also i'm trying to benchmark an algorithm and everything else is kind of additive to that so yeah i don't i don't think that would give me much soorry okay regarding multicore and simd instructions do you have any experience with the frequency scaling implications of simd instructions he it's a question about frequency scaling that's that's som like a remarkable thing that everybody of okay let me tell about frequency scaling if we have time so your cpu have something known as power i learned this last week i'm repeating what i heard the your cpu has something know as power license right on x86 on amd you have just i don't know if they have power license they don't have this issue and i don't know anything about that so you you you have a power license power license goes like normal integ operations as float operations and that includes ix 32 by integer operations and then you go 62 by float operations 64 by 62 by float operations and 64 byte integer operations and then you go into 64 by fl operations what doesn't matter point is that by default you run at of normal floats so 16 byte floats 32 byte in right everything here is 32 by ins we would not have experienced any issues unless you have high frequency trader and you do something very clever that i don't know like so all of your standard sd functions like standard lipy functions will be so if you call sterland it will be c2 by like just well right so when you switch what happens so you your cpu cannot just run those instructions it has to switch the power l license and there's a protocol so it has to request a new power license while it request it runs at really low frequency gets the restriction pops up to the new frequency right runs for a bit there then it will like then you know after while you don't execute those fancy instructions you'll be like okay maybe i can switch back so it drops again requests a power license and comes back up that was at least the story for for a while i don't know maybe they say that the new intels are better at this than they they they used to be all right so basically what happens you use one instruction that just kind of didn't matter and then all of a sudden your cpu frequency drops that's one of the big problems with 64 byte instructions on top of other things so generally speaking as as a rule of thumb you want to use 64 bytes on x86 only for really big compan computations right like again caveat here not i never worked at intel i like don't necessarily know everything okay you mentioned something about making sure to compile the code correctly yeah would you be able to elaborate a bit on that so well the the 64-bit one would be the one so there is a in even it's a complete mess i'll fix that but generally speaking there is a flag that you pass to both tocc and clank i don't remember but you can control the simd wids so it doesn't go to 64 bit because by default something like you know transform transform right or transform reduce will be autov vectorized and sometimes i see z vectorized with 64bit instruction so maybe compile introduces that problem for you as a flag you want to compile with a specific architecture in mind so just march it's very good for somebody like me who has a server right and i just compile for that servers or like whatever i have three different servers and was also compiled it's bad for people who have to ship code to people right like i he i talk to i don't remember his name is a game dev person okay so and he says that you know that people really complain but they have like we we old processors with some really really fancy gpus like and they really expect the game to run very well so what what they do instead there is they do dynamic dispatch they try to determine at run time which instruction you have or which instruction you have and then they select with something like if this is fairly hard to do the our suggested solution and that solution that's popular in this indust is you do dls so you take your kernels or whatever was expensive things you put them into some special thing you compile that as dls and then at run time you load the corre one in if library there is an example of how to do that with cake that's my kind of for general answer but just march cool thank you