what's the best database to use on your next project well as many senior devs will know the correct and completely unbiased answer is it depends depends on what you're using it for it depends on what kind of performance you need and for which balance of tasks it depends on your team's experience what are you expecting them to already know and what's worth learning as you go it depends and while that's true it depends it's always true it's not terribly helpful is it it doesn't give you a map to navigate the decision by and it's especially hard when that map would be full of so many different kinds of database all vying for your attention these days so i thought we'd spare we'd spend an episode of developer voices exploring the landscape going on a recce of the current state of the database world trying to figure out where everything lies and i brought a friend of mine ben stopford he has worked on designing databases he's helped build database companies around new technology and new ideas he's even written a book on how you join multiple databases together across an organization i really can't think of anyone better to be our guide and our cartographer as we make this map so if you're using or choosing a database or you're wondering if in hindsight you made the right decision join us for a walk i'm your host chris jenkins this is developer voices and today's voice is ben stopford [music] joined today by ben stopford ben how you doing man hey great to see you chris good to see you in your new house in new garden judging from the background that's right yes and we moved out to the country moved out to the country to contemplate databases and technology in general absolutely perfect so i i have told several people in the past that you're one of those people that has thought really deeply about a specific field and really has a better grasp than almost anyone i know of that field in practical terms and your field is databases so the question i have right i've got lots of questions about where we find ourselves in the database world and i'm thinking back through history and it's like databases they were really ad hoc for a while and then edgar cod came along in the 70s with a theory of relational databases and just defined the landscape for about 30 years stop me if i'm saying anything untrue here and then we hit like the internet age and everything just explodes and goes nuts and i want you to try and help us understand why and what the constraints are and how we navigate so many databases yeah there's definitely a lot of them definitely a lot of them yes i mean that's like that's like a huge topic i mean i think what we like that you know the starting point is yeah the relational area kind of took a long you know i felt a long time to mature and has been pretty dominant is it is still around it's just it has evolved also though i mean you know the databases the relational databases of the the 1980s the 1990s are still relatively you know relatively simplistic in comparison with most of the ones that we see today so i think there's been a kind of evolution in you know nosql in analytics and and in the relational world and actually importantly in practice the way that you actually go about using a database but yeah the the landscapes definitely got yeah a lot broader and open sources definitely help with that so if you think about it there was always always this kind of well for most of the sort of 1980s 1990s and sort of the early 2000s the database market was an oligopoly it was you know there were a small number of big vendors that dominated the space yeah and the barrier to entry was like really high nobody was ever going to come in like the amount of time it takes to build like a a new relational database the investment is is gigantic so you know there was basically microsoft we basically bought cybrace there's oracle and you know the yeah they kind of pretty much dominated the market and still do to a certain extent but then you know the the the the open source world kind of helped along with this like internet trends or the birth of the internet because what that really did was it was a bit of an innovator's dilemma problem there was a emerging category of users that wanted kind of into needed to build internet scale software they had you know a problem they had to solve that you couldn't really solve with a relational database not because it was relational but really just because it wasn't built to scale in certain ways and you could build a simpler database that would solve that problem and you know a lot of those types of things came out so that was already what the new sequel movement was about it was about scale it was about introducing sharding much simpler query models not because you necessarily wanted to simpler query model but just because you know if you if you've got an internet scale problem you're going to pick the solution that can actually solve the bulk of it even if it means you have to work a little bit harder and then i kind of what you've seen since then is i would say sort of this kind of two different sets of ever you know of database technologies you've kind of got these mainstream technologies that have got better at dealing with everything so you're you know one stop shop database is still what brand of most people are doing and most people are using and the big transition there has really been you know the utility has got of each database has got a bit broader but also you know there's obviously been this transition to the cloud which has changed things massively and then on the other side you've got these niche databases which you know are for very specific use cases which normally relate to some form of performance so there's like some something you know something about the performance characteristics of your problem that mean that a specific database is you know something that's written specifically for your your area is much better and there are like a couple of like broad examples of that so you know roughly speaking you've got oltp databases and i know lab databases are still kind of a two the two use cases it's like do i want to do transactional updates where i've got multiple people competing about around writing data or do i want to do analysis on data that's actually mutable i.e got created someone else somewhere else and i'm i want to do some analytics on it i want to do some museums to create some dashboards those are the that's kind of the two broad categories we're saying are you optimizing for readers or writers because that's your dividing line yeah exactly yeah just embarrassing enough to have my phone off because it'll never put it on silent mode i know if i hadn't put it on silent mode there we go i'll try and segue into notifications so yeah i apologize for that but yes i think for you know obviously there's those two those two broad categories and then you know the the reality is is this kind of like there's the performance element there's the utility the functionality that kind of goes with it and yeah i think the obviously the analytics systems tend to be precised separate from the transactional systems still today there are some kind of people that are trying to do the one size fits all and then there's a lot of people using post postgres yeah and and that actually makes a lot of sense you know it's a bit like that have you heard the old you know does that all kind of add adage that the you know the best camera is the camera that you have with you which is obviously why like yeah cameras on mobile phones you know often the best camera that you've got even if you they're not quite as good as the fancy slr lens that i think is very true like if you're building like a microservice application you're quite like to use postgres and you're probably not going to use you know maybe you don't care too much about about performance and that's only where you should start but yeah if you wanna if you're hitting you know moving into one of these problems that's just very hard for a general purpose database to solve then yeah then you kind of need to look elsewhere and that's where a particularly time series databases tend to specialize analytics databases and they are all making specific normally fairly low level changes to the way that they structure data really to try and improve either network time or or this time maybe processing time depending on what kind of database it is but usually actually it's it's mostly to do with how you actually access data on disk so do you think the these dividing lines are like are you mostly reading or writing are you mostly worrying about a single machine or spreading over the sized into multiple machines those are the two axes of our graph yeah i mean i think it's a good that's a good it's a good way of thinking about it life is pretty much always easier on a single machine right yeah single address space like life is is just easy if you can there are the problems for there there are certain types of query that are really challenging and just distributed environment so you know if you want to be able to do like ad hoc sql on a relational database that involve joining that involves joins there are certain queries that are incredibly hard to do certainly in a kind of shared nothing architecture and even with a shared nothing of your architecture so shared nothing architectures where you're just sharding the data across a bunch of nodes so like each node has autonomy over the data that it holds like some subset of it that being compared with the shared disk architecture which is really where you have these processing nodes and they can all do everything and they share a big discovery right there's a big debate over which of these two architectures is better and the reality is is that it you know it changes as the hardware gets more advanced so interestingly shared nothing got very popular and for good reason it's it's very scalable a very scalable architecture these days it's actually getting kind of going back and and being used having a set of worker nodes and a set and a shared disc array is actually becoming certainly a more preferable choice because it gives you more utility you can actually get away with these these more sort of complex joins and so forth so the yeah the kind of get yeah the architecture definitely matters and yeah it does definitely split between these you know those two the operational ones and then they've they're more kind of specific analytic ones based on the the performance that each of them requires right so are you saying that you're i mean if you were working on a green or even brownfield project today right you you would aim to start with postgres evolve and find out what your specific problems are i think if it's not broken then you know it ain't broken then there's no point in fixing it yeah i think they're just a set of problems that weren't a certain different type of database and i think that's probably fairly well understood right so if you are doing something that is time series based or if you're doing something that requires aggregation which is really like what a lot of time series databases end up doing anyway to some extent then you are better off with a database that at least knows how to organize data in a way that suits them and what that really means on the most part is some sort of columnar mechanism so you know kilometer databases are the difference really is just the way that they laid the data on disk they layer by column and what that really means is a the biggest benefit actually tends to come from compression so if i have a if you imagine if you've got like a you know like a set of numbers or a set you know a column full of text you can do very efficient compression on that even just like basic compression like run length encoding and it can actually be really efficient in terms of reducing the amount of disk data that you've got to move around and if you can change that by a factor of five or ten then at relatively you know little cpu cost for the compression and decompression algorithms then i can actually significantly improve improve your performance and likewise when you're doing an aggregation for doing like a let's say you're grouping by some some fields that you might be grouping orders by the by the by the a regional the user's name etc etc these things work very efficiently when you've got a single column so that that kind of column oriented mode is very very different to the row oriented mode but it's a trade-off right so if you want to if you do select staff from a database there's column warranty database and it's got 10 you know 100 fields in each in each in each row then it just takes a long time to construct all that stuff together yeah single query you know a single field aggregation in the column database is incredibly fast so that you know that's an example of like where something very specific works and in that analytical space if you're doing analytics you're using you know i guess something like bigquery or now redshift you know these are examples of databases that are designed to do that very specifically and just literally can't do transactional workloads there are these like hybrids in between but on the most part yeah if you're if you're doing kind of analytics on web data data that's not being mutated then you probably know that and you probably are going to go for you know one of these kilometer things but the the interesting thing probably these days you know increasingly is that the utility that comes from the cloud providers is probably more important than the actual online database itself so that's that's probably like the yeah that's so whilst we've had this kind of cambrian explosion particularly in the 2000s and maybe like the sort of early early in the last decade i think it's kind of like stabilizing a lot now so you know what's really happening is a lot of the you know there's been a lot of a sort of soup of new ideas a soup of different approaches to solving database problems and you know to hosting them on the cloud yeah and then i think that's you know there's there's we haven't really gone back to an oligopoly but is definitely a massive landscape with a i would say a relatively small number of leading players and that's probably the way that it's you know that it's gonna it's gonna end and maybe sadly the reality is you know when you store data in a database even in an analytics database you kind of you want it to be reliable you want it to are you in the region that you want it to be in all of these things are really really difficult you know to build make it expensive to do to do really well that's why you kind of end up with going back so probably we actually are sort of going back to the the oligopoly that we had weirdly in the 80s and the 90s there's more players now yeah so the field's bigger but that's that's kind of where we're going back to do you mean dominant players as in you think they're a handful of companies emerging or you think they're a handful of architectures emerging i think there's a i think the reality is there's a ah yeah there's a handful of companies and and a handful of architects i mean there's always kind of been a handful of architectures the all that really ever changes for you know from a database perspective all that really changes is hardware that that's the truth right so most of these you know said nothing's been around since i mean it got really trendy in the 2000s but it was around in the late 1970s early 1980s and the first teradata was doing nothing all right on early early 1980s it was very basic but yeah these things have been around it the main thing that's changed is really just this this this shift around you know networks get faster cpu processing gets more efficient the big changes in terms of resiliency and how recovery and you know algorithms for consensus and all that that all of that has definitely changed yes and what we demand for uptime isn't the big one i think yeah yeah it used to be that every database had like overnight where it could be down yeah the weekend you could switch it off for maintenance right yeah i mean it's really it's really hard to do and it's really hard to it's probably like you know one of the hardest problems and i think it's it's really that is it you know our expectations of what a database should do and the way that you know in the up times that it should be able to perform it should be able to maintain and the you know resiliency guarantees that it provides a definite increased romantic and again i think that's why you're kind of getting this this you know a smaller subset of more dominant players in the database space do you think inevitably then that all database creating companies will become database providers do you think this the difficulties of maintaining and always-on database will eventually become the domain of people that write databases all cloud companies yeah but do you think that companies that make databases will inevitably be pushed towards being cloud companies oh yeah absolutely i mean i think that's already happened right i mean the number of yeah the number of popular databases that aren't available in the cloud it's pretty small now i would say and certainly if yeah if you're not on the cloud then yeah that's that's because that's half the problem right getting up getting it to work getting a database to work on the cloud yeah that's a arguably as big a task to do well as building a database in the first place so oh really i think the two things have to go hand in hand because i would have thought initially that creating a database from scratch would to most people seem a lot easier than then deploying it to the cloud i mean creating a simple database is easy but creating something that works i think it's pretty good yeah but it kind of works well i mean so i guess if you look back in history let's pick so if we look at some of the sort of you know then no sql this you know no sql database is like you know was famous for its ability to lose data remember in the early days that was definitely true sadly yeah yeah i mean it didn't it didn't write anything transactionally it was kind of a mess and they they basically you know the storage engine they did really well they bought they bought this this thing called wire tiger which was somebody else basically went and rebuilt the storage engine and you know mongodb were able to acquire this company it was called wired tiger and they had a good storage engine and you know the reality of the reason that people like mongodb was they had a great i had a great query model it had a it was very developer oriented they had had very good marketing it was actually more that than than probably and probably anything else and then they were able to kind of catch up in the background and and they did that bridge by replacing the storage engine so yeah that's kind of one you know most implex db was another one they ended up they originally used i think they used rocksdb whatever it would be can't remember but they ended up writing their own for time series you know time series against kind of a slightly it's a tricky it's a particularly tricky problem time zero's databases and then yeah you kind of get in these kind of more esoteric ones i guess if you look at things like event sourcing that's kind of that's what i would describe here is event sourcing a type of database is it a does it require a title type of database you know or is it just a pattern that you use over the top say the same thing with for you know by temporal databases is there is that an implementation pattern or does it actually warrant a database you know a specific database you know that's designed to solve that problem and if you go for the specialist ones then they will do a better job they will be more purposely just means they will be more performant you might get some features that work better but you can probably build all of this stuff in postgres you just a you might run a bit slower and b you might have to work a little bit harder to get the kind of queries to work so even under those circumstances would you say start with postgres until it becomes painful i mean i think that you are probably only not i would always pick postgres until i knew i i thought i was going to have a problem that it where it isn't going to fit but you know that's kind of if i'm working on premise if i'm not if i'm working on the cloud i'd probably pick the one that made the most sense to me so one of the the big probably one of the big changes that occurs with the collab is is actually a little bit easier to you know if it's changing database technology was always very very difficult you know but yeah so you can think back for 15 or 20 years you just didn't really change people would talk about changes they talk about like yeah it's all antsy sql 92 compliant or whatever yeah very very rarely doing whatever really change yeah there's this dream that you'd be able to just swap out postgres for my sequel for oracle and it never really worked beyond anything basic no well the vendors also have like a they're kind of incentivized to try and get his lock in so they add in these little features which are really useful but make it hard for you to kind of log in and then and then the reality is is that the semantics although the standard would be the same natural implementation it's not necessarily quite the same the execution times i mean exactly you know exactly the same so it is quite hard it was very hard i think to switch you have to buy new hardware you had to do all this stuff on the card it's like a little bit easier i think mainly partially because you don't have to worry about you know you can australian new service but partially because the way that people tend to use database databases these days is more like a repository than it used to be like there was a you know if you're if you're sitting behind an orn and doing most of the stuff in your in the application space then it is probably a little bit easier or it is a little bit easier to switch between different providers but then the argument is like well if you're working through an orm then you're not really using a database as anything much more than that what kind of store for your application so yeah that's very difficult difference or something there's a lot of business value as you would see let's say in an electrical side or maybe if you're doing something that's highly transactional where you actually care about performance this actually leads on on to something maybe you've got some ideas about this that i've always felt was a huge tension in the database world is that you've got orms and they they never really work beyond the basics not that well because there is a fundamental tension between object orientation and if you've got relational database relational set theory i always just thought it was the orms were just you know they were just a way that people could be a bit lazy and not have to learn sql [applause] i mean but yeah the it's convenience i mean yeah there is this this this relational you know obviously there's like a you know object relational mismatch it's it's a very real thing if you're writing something very simple then an orm definitely helps you yeah i mean i i'd argue like if you're a serious application developer you're gonna know enough sequel to be to be fairly dangerous then yeah you're better off just doing it yourself because that way you actually at least know what's going on like debugging i mean it's a while since i used i guess the the bigger or ends but you know debugging orms is always like relatively painful and yeah and inevitably you try to get down to the point where it was just sequel anyway so you could actually understand what's going on yeah i mean if you care about performance then and you're building an application that actually probably the best way to think about it is if you are investing significantly in your application then i would say you know any and the database is more than just you know a kind of a store of let's say something you know renewable state then you're probably better off just embracing the database as being part of your application and you know i think if you're a developer then you should learn how to you shouldn't you should learn new databases like it's part of it's as much part of your application is everything else you should learn how to get the best of it you know wrapping it in an orm so that yeah for me it's as you said there's this mismatch it's better to kind of manage that kind of mismatch yourself building a little fast you know application it's really a website just want to get out the door yeah no rm is probably fine so as ever it depends on your depends on your constraints yeah but there are some rules to go for okay so that takes us across to the other kind of integration question maybe i can reference back what you were saying about like columnar databases they're great if you want to aggregate a single field they're kind of lousy if you want to get a single row by id right if you need both if you genuinely need both and under high performance conditions so let's say you're not allowed to say postgres you're spreading over multiple nodes at very high transaction rates or whatever is there any kind of universal integration pattern if you've got to use two different styles of database well firstly there are actually a bunch of approaches that do do both or trying to do both so so like there are definitely architectural styles that kind of give you your cake and eat it to a certain extent anyway so yeah so generally the patterns that get used here are there are databases that effectively have like a lot of databases in some world form one another but but they have like like really like two different types of database inside the database right so okay for example you have like something transactional which is accepting data which allows you to do sort of fast rights and you can do different checks and validations and so and so forth inside the sort of the the part of the database that is responsible for really taking data getting it down on this transactionally and then you've got like another part of the database which is you know suited for queries so i think druid's a good example of this as like a two effectively two different databases inside it now the reason that's a little bit tricky it's only from a database programmer's perspective is that you're gonna manage these two different stores right so you've got data in one and data in another and when you if somebody sends a query you kind of have to like query both of the databases inside but you own both of them so it's not really that hard to do you can actually do exactly the same pattern using something like event streaming this is what a lot of people obviously do it at a macro level is they have like a operational database and they have an analytical database and they use you know something like kafka to move the data from one to another and you kind of address the one that you want but the yeah the ability to kind of do these things internally is is kind of more powerful so you're seeing like you know snowflakes trying to do stuff like this at the moment you know that they're trying to increase their ability to operational operational workloads you know companies like oracle which is you know they you know they're actually you know there are good databases is is a pretty impressive piece of technology that kind of manages to do both you know through actually mostly through group four through hardware optimizations but it wasn't really further clever technology you know technology in there so yeah that my my guess is that like you know whilst and you say okay everyone you know you can do everything with postgres but the reality is that the the workhorse database that kind of sits in the middle it's abilities are never simply going to grow and i think the cloud really helps with that because you do get these big players like there's no vote that i've got like a you know anything else i know their investment budget is but it must be massive and they've got like you know the opportunity to kind of host which gives them a lot of control over the way that you know the optimizations that they can make because they are they own the whole runtime and they'll you know sort of provisioning playing so there's definitely an opportunity for that you know that more generalist database to kind of grow into a lot of different different use cases yeah i'm not sure that answers your question what what i was one thing i mean i know i know you have fans in the kafka community and you go back a long way into event sourcing i was trying to push you into discussing is event sourcing what do you think stepping back at the moment do you think event sourcing is like a universal bridge is it part of the puzzle do you think potentially we'll just start running more databases that connect to postgres's event log and read directly from that i well do you think kafka has a sweet spot that like event sourcing has a sweet spot that just works for specific organizations yeah i mean although although i read a lot about i've written a little about event sourcing in kafka you know i think it's and yeah there's a there's a lot of people with very strong opinions about this but you know event sourcing and event streaming are very closely linked but they're actually quite different i i actually think that event streaming is a lot more powerful than event sourcing just because it's always a complete it solves a very different need so it solves that need which thing is obviously what you're getting it before which is you know the ability to basically tie different databases together but it's not really about time different databases together it's about embracing the fact that your application is not a little island right it's it's not just you and your database and that's it unless you're like some tiny little company it's you and a whole bunch of other systems you know most most companies have tens hundreds thousands tens of thousands of different systems that need to somehow operate together in a way that looks joined up to a customer or an internal user or what have you so the reality is is that one database can never do it all because it's not one application and it's really hard to share data across applications particularly with a database so you end up having to embrace this anyway and perhaps where kind of event streaming comes from and you know it takes a lot of the elements of event sourcing but when it when you know when you say events also when i say event sourcing it tends to just mean you know the application of events to store data at the level of an application whereas event streaming it for me is using you know the same the same kind of tool set and the same thinking to move data across different applications different microservices and it's it's that kind of fabric that joins it together so you know event stream is is just much more powerful because it helps solve this very real you know fundamental issue that you have that you're gonna you're gonna coordinate data across a variety of different applications and you're not going to do that by sharing a single database for a whole bunch of different reasons vent sourcing itself is a pattern and you know this i know you do but you know in my mind is yeah it's a really nice pattern to build an application with but i actually think that you're better off using biotemplo database that's my take you i think you have to go into that argument a bit deeper yeah i well a by tempo databases i mean that's like a whole different thing but i'm a like a real fan of biotemporal databases it's a fairly niche pattern you can build a bidenpro database on postgres actually there is a they there was actually a proposal to put a language extension to do it kind of provide like proper support in postgres for by temporal data but james henderson that it's being argued into the spec already has been argued into the spec has it okay there's definitely some motion on it about a decade ago and then it just kind of stalled it was a bit of a shame but it is it for me it's kind of event sourcing done right oh it doesn't it doesn't get it doesn't it doesn't have all of the attributes of event sourcing and it actually has very little to do with event streaming but it has basically most of the really good stuff that you want there's a way to so you can't have a conversation with events sourcing people about it because it becomes all about the different sort of you know the the dogma that surrounds event sourcing and it's got nothing to do with that it's just to do with the utility like why do i actually want to eventually in the first place well normally because i want to make sure that i have a record of what really happened but then i also want to have this like efficient way of viewing the world like you know installment effectively i want to be able to have a table of orders and i want it to look like well i won't have you know my shopping basket and i want to look like my shopping basket so i can just bet for you to use it but i also want to have this kind of this structure that tells me exactly what happened and it maintains it over time has that kind of audit and it's all kind of built into the into the into the you know the fabric of the way that the data is stored and i can also you know take the login port it to another machine and by temporality does that really just by then two indexes on a table like for two different times so one is is your world clock time that's your event log and you basically lower that you layer a temporal index which gives you you know business time it's normally the terminology that's used and that's just like a view which basically gives you the the that turns the event log into that table and it just maintains both all the time and if you build you know you there aren't many specific bi-temporal databases but you know if you you the reason that you want a specific by tempo database is that you want something that's going to maintain that view very efficiently and it's actually pretty difficult to compute like if so if you just build it in postgres you know the the actual query that builds those two views with the two you know the the event log view and the sort of tabular you know everything's reduced by a key view yeah it's kind of kind of expensive queries they end up with like you end up using timestamps you end up with like a greater than equal to this time less than equal to that time yeah or like less than that time on every single one of your queries and sometimes the query optimizes you can handle doing table scans and it just gets kind of kind of gets pretty painful so you know in in a bespoke database you can build something that's a bit more efficient and can take advantage of the fact that that you know that you're going to have queries of this particular type but i said there aren't really many of them but yeah it it has this really nice yeah it solves a lot of those event sourcing problems in a in a really neat way but it doesn't give you everything that event sourcing gives you yeah okay so is that then you're is that your dreamed of future where we have a bi-temporal database acting in in a lot of applications as their core database and then streaming it out as an event log to speak between departments yeah i mean getting an event log out of a biceps is kind of natural anyway so i think you kind of have that i think eventually is still separate but the you know if particularly on the the you know the lltp side on what you know where you're sourcing data if every single database because it by temple database looks like a regular database it can it has all tables by defaults look like normal tables like you you know you used to use select scale from your basket and you get your basket you know it says you know inside the basket chris has chosen three passive trousers he's got three pairs of trousers in his basket it doesn't say chris added a pair of shoes and removed a pair of traps yeah whatever you know some glasses or something remove that it doesn't give you that event longview by full it's there but it gives you the nice stability so he feels and operates just like a normal database but because it maintains that log you have that audit trail you have that ability to to easily create that that you know you know that uh an event stream of it and that databases do this anyway because they do it in their transaction log actually it's exactly the same thing but it's about kind of wrapping that up in a way that works really efficiently and if every if every every database could have sort of had that book that functioning functionality out of the box it makes a vendor streaming a lot easier because you know they're all you know the the storage model is actually design is such a way that it it it's built it's maintaining this this view right you don't need you don't just need to have like a you know you don't need to have a connector that's gonna be there at the right point in time to pull the the event log out it's not you're not throwing this event log data away which is what pretty much every single you know this is the source database does so you know you're just in a much better place and and i think that i think that i think that that that's going to be the future but i've been saying that for a long time and it's taken off so maybe in the next venture will be my next venture will be by temporal database company i don't know i'd like to see that i'd like to see how you do it what okay so final question then in this theoretical future will you go and build a bi-temporal database company which language you're going to pick oh it wouldn't be jvm-based censorship oh why not i was really hard to manage today along the jvm let's control i mean yeah i mean the the so it works for like like it works well what works pretty well for kafka works for like his friend streaming use cases you know i think that you can you can definitely do it but you just have to fight harder so you know i mean ultimately bringing a lot of data into the jvm and manipulating it is painful yeah are we talking about disk management or memory management or something like that yeah it's basically [music] because your options are either you bring it onto the heap in which case it's it's like it then has like a bunch of extra you know java creates a bunch of extra overhead and there's a level of abstraction which makes it hard to manage large data sets well on the heap not to mention garbage collection or you can manage it off heap which is slightly better but then you still have to do garbage collection that means you you know ultimately most problems require garbage collection so if you do it on feet then you've got to manage the garbage stretch yourself which can be more efficient but it's also quite hard work and then and then like if the yeah and if you do manage your feet you still then you then go deal with like serialization issues every time you break back on and off again so it just there's just quite a lot of for very sort of highly you know for anything that requires storing a lot of data particularly if you want to bring that data into memory and manipulate it then you know i think the jvm's kind of kind of kind of tricky okay you probably drag off with with something else yeah i mean these days you know rust looks pretty good but does it have the library support yeah i don't know you you i think the jury's still out okay fair enough i thought you'd go for something in the sea-ish family yeah i mean which i'm including rustin going the sea-ish kind of way of doing things yeah i think that's that's that's rust rusts maybe go yeah definitely i mean or even just like you know see i mean does the c-star library which is sillier db created which looks fairly painful to program with to be honest but you know that's like a c rewrite of cassandra which is a database an lsn based database which is built on the jvm yeah like it probably does have some performance improvements but i think if you start again these days yeah you're probably going to start with something that is not jvm based if you're going to build a database fair enough i shall leave you to enjoy your new garden mow it and contemplate how to build your time series database all right yeah well great great to see you thank you thanks very much for having me on the show thanks for doing always a pleasure chris and yeah that's all for to see you again all right cheers thank you very much ben now i don't know if ben is actually going off to work on his rust database of the future but if he does i'm really hoping he calls it ben db i think it's got a good ring to it and the mascot just designs itself right bendy b perfect i'm not sure he's going to thank me for saying that but if you'd like to thank me for making this episode please take a moment to share it tweet it rate it click the thumbs up icon like subscribe all that stuff you know how this works by now did you know that you can rate podcasts on spotify but only from the mobile app true fact that you spotify listeners might want to do something with and of course if you want to get in touch with me for any reason including inviting yourself on the show my handles for twitter linkedin and mastodon are in the show notes but until next time i've been your host chris jenkins this has been developer voices with ben stopford thanks for listening [music]