death by a thousand microservices the software industry is leading once again or learning once again that complexity kills yeah it does the church of complexity there is a pretty well known sketch and in which an engineer is explaining to a project manager how an overly complicated maze of microservices works in order to get a user's birthday and fails to do so anyways the scene accurately describes the absurdity of the state of the current tech culture we laugh and yet bringing this up in a serious conversation is tantamount to professional heresy rendering you borderline unhirable so how do we get here how did our aim become not addressing the task at hand but instead getting setting a pile of cash on fire by solving problems we don't have the perfect storm there are a few things in recent history that may have contributed to the current state of things first a whole army of developers writing javascript for the browser started self-identifying as full stack dude this is single-handedly the greatest roast of all time it's immediately it's immediately going on to the twitters so people are gonna think i'm posting which people tend to think i'm just only i only should post i also quote post you know to be fair dhh ghost dude i love this one diving into server development and asynchronous code javascript is javascript right what difference does it make what you want uh what difference does it make what you create using it user interfaces servers games or embedded systems right node was still kind of learning a project of one person and javascript back then was deeply problematic choice for server development pointing this out is still a green server-side developers usually resulted in a lot of huffing and puffing this is all they know new after all the world outside of node effectively did not exist the node way was the only way ed so this was the genesis of stubborn dogmatic thinking that we deal with to this day and then a steady stream of fang veterans started merging into the rivers of startups mentoring the newly minted and high highly impressionable young javascript server-side engineers i want you to know that the more times you identify or you have adjectives in front of the word engineer likely the bigger mistake you're making just so you know the apostles of the church of complexity would assertively claim that how they did things over at google was unquestionable and correct even if it made no sense under current context and signs what do you mean you don't have separate user preference services this will not scale bro this is so good this is so good my favorite fact of life is that there are more startups with more servers than users like that's just the reality they have more servers dedicated than they do actual users but it's it but it's easy to blame the veterans and the newcomers for all this what else is happening oh yeah easy money what do you do when you are flush with venture capital you don't go for revenue sure league one more than let's see on more than one occasion i've received an email from management asking everybody to be in the office tidy up their desks and look busy as a cloud of patagonia vests was about to parade through the office investors needed to see explosive growth but not in profitability no they just needed to see how quickly the company could hire ultra expensive software engineers to do things and now though you have these developers what do you do with them well you they could build a simpler system that is easy to grow and maintain or they could conjure up a monstrous constellation of microservices that no one really understands microservices the new way of writing scalable software are we just going to pretend that the conception of a distributed systems never existed let's skip the whole parsing of nuances that microservices are not real distributed systems dang this is such a shots fired article such a good so good back in the day when the industry was not i really do like this because i can't tell you how many people reach for complex systems when they have nobody to serve it too you know what i mean they don't do you really need all these things just to develop a service like if you're doing it for the sake of learning so i do want to like time out if you're doing it for the sake of learning for the sake of understanding how complex systems are built you should do that everything is not a learning exercise you know what i mean not everything's a learning exercise sometimes you just need to build something and now that you have seen these developers what do you do with them oh yeah we already read that back in the day when the tech industry was not such a bloated farce distributed systems were respected feared and generally avoided reserved only as a weapon of last resort for a particular gnarly problems everything with distributed systems become more challenging and time consuming development debugging deploying testing resilience but i don't know maybe it was all super easy now because tooling this is actually a really good observation which is observability into a micro system architecture is extremely difficult it just really is like it is very very hard to have great observability to trace requests to go through things it's still really hard like it's not something that's just simple it's very time consuming and then getting the right understanding there's a lot to it i can't tell you how many times i've logged on to a server at netflix gone to the specific instance and looked at the catalina log from my groovy output right to find out what happened and went wrong right here no it's not services are easy they just work you just go in there and you just do stuff he just you just go on there they're simple i would venture i forgot to turn off alerts i would venture to say that a singular item is easier than many items open telemetry sure open telemetry but it's still some it's more things like you still have to put all these things in place like you you forget the fact that none of these problems exist until you have them all right and then you have to have all the items in place there's not you just there's not like a simple just jump open television it's just a format i know open telemetry that's not what i'm saying it's still there's still a lot to it debugging is non-trivial not only that but now you have like this whole problem of testing you have a staging environment you have to reflect what is in prod and staging if you wish to do that how do you have separate staging environments that you make sure that it's not getting destroyed like there's just so much more than just the thing right it's not just the thing correlating ids are hard you have to make sure you're using headers every system propagates these headers if you want to wrap these things oh staging is so bad right now every staging is bad there's no staging that's good i i've had a problem at netflix that i changed a staging only environment flag and i took down production okay staging and production is not easy okay this is very hard you could totally screw up everything dude it's just when anyone says that distributed systems are easy i feel like they've just never done a lot of stuff okay it's very easy to f yourself it's so easy it's so easy it's hard to have great observability it's hard to know what's happening there's no like because here's the deal like you know even like you know you heard about all the twitter stuff or the where there was like tweets going on like we just turned off five more services does twitter work it's shocking that things just work hey that's a really resilient system great job but b what was it doing what was it you know like it i love just seeing like what you could do at netflix netflix we have chaos monkey chaos gorilla and chaos kong running at all times and so chaos kong runs every down then and shuts off an entire region just turns it off and things still keep working it's wild what you can build and what how fault tolerant it can become but it's still you know chaos monkey chaos monkey kills an individual instance chaos gorilla kills an individual service chaoscon kills an individual region so u.s west just disappears what happens right what happens when us west disappears does your program still run but you got to remember we have like hundreds of engineers working on this it's an expensive problem but we have an actual reason to have it be expensive all right anyways there's no standard tooling for microservice development there's no such common framework to working on distributed systems has gotten marginally easier in 2020s using docker and kubernetes of the world that did not magically take away inherent complexity of distributed setup thank you i love referring to this summary of five years of startup audits as it's packed with common sense conclusions based on hard evidence and paid insights let's see the startups we audited that are now doing the best usually had an almost brazen keep it simple approach to engineering cleverness for cleverness sake was a board on the flip side the companies were where we were like whoa these folks are smart as hell for the most part kind of faded that's pretty funny literally complexity kills the audit revealed an interesting pattern where many startups experienced a short collective imposter syndrome while building straightforward simple performance systems there is a dogma attached to not starting out with microservices on day one no matter the problem oh this is so good everyone is doing microservices yet we have a single the django monolith oh thank you baby very beautiful wife by the way beautiful wife beautiful wife beautiful wife look at that she made me a little she made me a little bit of aggies little toast a little fork what a wonderful wife everyone is doing micro services yet we have a single dejango monolith maintained just by a few engineers and my my squeal instance what are we doing wrong nothing it's okay to start there misogyny why what i still i i am shocked okay so i kid you not so when this happened when i was called a misogynist the response was why are you afraid of women or something this why are you a misogynist and i responded with don't worry i think the same thing of men too and then they they accused me of being like a misanthrous thorpe or something someone who's afraid or distrusting of all humans and i said i don't think you know what that word even means and then of course that's when i got dragged in with the whole wife bringing me food i just genuinely appreciate it and she's beautiful lovely super smart talented and runs a bunch of crap so fu wherever you're at thank you beautiful wife a misanthropist yeah such so stupid anyways the answer is almost nothing likewise it's common for a seasoned engineer to experience hesitation and inadequacy in today's tech world and the good news is that no it's probably not you it's common for teams to pretend like they are doing web scale hiding behind libraries orms and cash confident in their ex expertise they crushed that lead code yet they may have not even been been aware of databases aware of database index indexing basics if you haven't indexed your own database at least once you know you should you are operating in a sea of unjustified overconfidence waste and dunning krueger so who is really the imposter here is nothing wrong with the monolith the idea that you can't grow without a system that looks like the infamous diagram of afghan afghanistan war strategy is largely a myth yeah that seems about that seems about a proper war strategy here dropbox twitter facebook instagram shopify stack overflow netflix they didn't say that these are companies that others started out as monolithic code bases many have monolith at their core to this day stack overflow makes it a point of pride how little hardware they need to run massive site shopify is still a rails monolith that sucks leveraging the tried and trued risque to process billions of tasks whatsapp went supernova with the erlang monolith and 50 engineers how it's actually 32 engineers this sounds like somehow oh they must have hired' since the other article i read whatsapp constantly keeps the engineering staff small to about only 50 engineers individual engineering teams are small consisting of one to three engineering engineers and a team are each given a great deal of autonomy in terms of service what app prefers to use smaller number of servers and vertically scale each server to the highest extent possible i like this approach actually quite a bit i actually i do like this quite a bit instagram was acquired for billions with the crew of 12. i mean i always i also don't like this part because that was i mean facebook just wanted to make millions and they knew how they were going to do it they wanted that billions right well i mean that's the thing is you don't necessarily need to engineer everything to the maximum i'm taking a bite [music] oh [music] see and do you imagine threads was an effort involved a whole metacampus no they followed the instagram model this is the entire threads team it took that many people to copy twitter's open source code base perhaps claiming that your particular problem domain requires a massively complicated distributed system and an open office stuff to the gills with turbo geniuses is just crossing over into arrogance rather than brilliance don't solve problems you don't have okay i like i like this it's a simple question what problems are you solving is it scale how do you know to break it all up for scale and performance do you have enough data to show what needs to be separated services and why distributed systems are built for size and resilience can your system scale and be resilient at the same time what happens if one of the services go down and comes to a crawl just scale it up yes well that's a great question what about other services what about automatic canary analysis how often are you releasing how are you doing staging versus production services will get flooded with load do you have a war game the endless permutations of things that can that can and will go wrong is their back pressure everyone's favorite phrase circuit breakers cues jitter sensible timeouts on every endpoint is their default value returnables we call that a blue service are there a foolproof guards to make sure a simple changes do not bring everything down the knobs you need to be aware of and tune are endless and there are all let's see and they are all specific to your system's particular signature of usage and traffic this is a great great statement of just how complicated these things can become especially when you have 10 users you have 10 users just put it on a machine just put it on a machine okay one simple shared resource 5.5 dollars a month the same price as it is the sub to your boy right here you can get a machine and you'll be able to serve 10 000 users on that thing stop stop the truth is that almost most companies never reach that massive size that will actually require building a true distributed system you are cosplaying amazon and google without their scale expertise and endless resources it is very likely just an egregious waste of money and time religiously follow all the steps from this article called 10 morning habits of very successful people is not going to make you a billionaire the only thing harder than distributed systems is bad distributed systems that is such a great statement ninety percent of all companies in the world could probably just be a monolith running against a primary db cluster with db backups some caches and proxies and be done with it for 10 of the companies that hit planet scale no pun intended here sam it's gonna be an art figuring this out fair this is fair i would argue that 90 of companies don't even need most the things he even said there you just need dbs backups and a monolith you don't even need some caches and proxies you probably don't even need any of that but each team but separate but api trying to solve the distributed topology of your company structure and it is a noble effort but it almost always backfires it is a common approach to break up a problem into smaller pieces and then solve those one by one so the thinking goes if you break up one service into multiple ones everything becomes easier right the theory is sweet and elegant each microservice is being maintained rigorously by a dedicated team walled off behind a beautiful backward compatible versioned api in fact this is all so steely that you rarely even have to communicate with that team as if the microservice was maintained by a third party vendor it's that simple it's simple if that doesn't sound familiar that's because this rarely happens oh you don't recognize that yeah neither do i laughs i definitely don't recognize that one at all in reality our slack channels are flooded with messages from teams communicating about releases bug configuration updates breaking changes psas and everyone needs to be on top of everything all the time if this wasn't great it's normal for one already slam team to half-ass multiple microservices instead of doing a great job on a single one this is another reality is you rarely have one team one micro service can we just be real here does that ever happen no often owners as people come and go in order to win the race we don't build one good race car we build a fleet of shitty golf cards all right kelsey hightower this is a great question here's my answer i'm melinda wager and monolith will all perform every microservice architecture just do the math on the network latency between each service and the amount of serialization and deserialization each request no contest now the question can a giant monolith application packaged and deployed with auto scaling models be as effective performance wise as microservice architecture i love the fact that that question even has to be asked this just goes to show like this right here if this is so true like you you gotta think that like people think javascript object notation is fast it's not fast it is really slow and it is one of the most primary ways servers communicate with each other it's not fast it's never been fast you can't even make it fast like it's as fast as fast gets we sim d the out of deserialization and it's still not that fast what do you lose there are multiple pitfalls to building with microservices and often that minefield is either not fully appreciated or simply ignored teamspend months writing highly customized tooling and learn lessons not related at all to the core product here's just some of the often overlooked aspects say goodbye to dry after decades of teaching developers to don't repeat yourself code which does lead to a lot of abstractions i'm kind of in the don't do dry but only do dry when it's obviously should do dry like when you do multiple of the same thing literally over and over again then you should abstract it out you know you know what i mean that kind of dry i'm that kind of dry guy it is let's see it seems to just stop talking about it all together microservices by default are not dry with every single service stuffed with redundant boilerplate very often the overhead of such plumbing is so heavy that the size of the microservice is so small that the average instance of a service has more service than product so what about common code that can be factored out have a common library how does the common library get updated keep different versions everywhere forceful updates regularly creating dozens of pull requests across repositories keep it all in a mono repo this comes with its own set of problems allow for code duplication forget it each team gets to reinvent the wheel every time multiple overlapping implementations of the same thing trademarked that it it's dude it's very true each company going this route faces these choices and there is no good ergonomic options you have to choose your version of the pain developer ergonomics will crater developer ergonomics is the friction the amount of effort a developer must go through in order to get something done be it working on new features or resolving a bug with microservices an engineer has to have a mental map of the entire system in order to know what service to bring up for any particular task what teams to talk to whom to talk to and what about and it and the you have to know everything before doing anything principle how do you keep on top of it spotify a multi-billion dollar company spent probably a non-negligible internal resources to build a backstage software for for cataloging its endless system and services yeah i mean this seems a little bit more overwrought you don't need as much it's i i find this if okay so i guess hold on let's undo this when i was working in office this process is not that bad when everyone's required to be in office it's really not that bad when it's on slack it is worse calling it i'm calling it the reason why is that communication is not instant i can't sit in front of somebody and talk to them now you can huddle you can try to huddle but they have to be after complete like there's all these these hurdles that exist i'm curious about this i wonder how much of that is true or is it my perception anyways this should at least give you a clue that this game is not for everyone and the price of the ride is high so what about tooling the the not spotifys of the world are left with mac macgyver they're oh left with macgyvering their own solutions the robustness and portability of which you can probably guess how many teams actually streamline the process of starting a yes yet another stupid service this includes developer privileges in github git lab default environment variables and configuration ci cd i literally just hand rolled my own artisanal ci cd just last week code quality checkers code review settings branch rules and protections monitoring and observability test harness infrastructure as code and of course multiply this list by the number of programming languages used throughout the company maybe you have yourself a usable template or run book maybe a frictionless one-click system to launch a new service from scratch it takes months to iron out all the kinks of with this kind of automation and the best part is that it doesn't work for everybody it works for like a very narrow set so you can either work on your product or you can get working on tooling yes it's going to be the name of my next microservice yes integration test law at every stage microservices grind was not enough you also forfeit the peace of mind offered by solid integration tests your single service and unit tests are passing but but our your critical paths still interact oh my goodness but are your critical paths still intact after each commit who's in charge of the overall integration test suite in postman or wherever else is there one okay fair potentially i'd have to think about that one why is it so hard to read i have the sweet sweet dyslexias and so this you know me starting this channel is just me wanting to get better at reading and i would also like to do other stuff as well integration testing and distributed setup is a nearly impossible problem so we pay much or so we pretty much gave up on that and replace it with another observability just like microservices are the new distributed systems observability is the new debugging in production that's actually really funny surely you're not writing real software if you're not doing observability observability has become its own sector and you will pay in both pretty penny and a developer time for it it doesn't come as a plug and pay either oh yeah you need to you need to understand and implement canary release's feature flags etc who is doing that wanna already overwhelmed engineer who accidentally takes down production because they accidentally put in the wrong value okay just because i put in the wrong value and things went down what about just services what do your services need to be micro what's wrong with just services sub startups has gone as far to create a service for each function that can't be real isn't that just like a lambda is a valid question this gives you the idea of how a far gone this unchecked cargo cult is that's strange what do you do or what do we do starting with the monolith is one obvious choice a pattern that could also work in many instances is trunk and branches where the main is meats and potatoes monolith is helped buy branches branch services a branch of service can be a service that takes care of cleanly clearly identifiable and separately scalable load a cpu hungry image reciting resizing service makes more waste makes way more sense than a user registration service or do you get so many registrations per second that requires independent horizontal scaling do you with your 10 users just 10 users going nuts inversion control back in the day cs cvs and subversion we rarely use master branches we had trunk and branches because you know trees master branches appeared somewhere along the way and when github decided to do it do away with their rather unfortunate naming convention the average engineer was too young to remember the trunk branches pattern and so the generic main default became or came to be okay the peninsulum is swinging back the hype however is seeming to die down the vc cash faucet is tightening and so the business have been market corrected into exercising common sense decision recognizing that perhaps splurging on web scale architects when they don't have web scale problems is not sustainable yeah i so this is actually a very interesting point which is i wonder what's gonna happen over the next so many years because either there's gonna either something is going to exist that makes this stuff more and more easy to deal with which is effectively like serverless or edge functions any of those things are attempting to make all of this easier or b are we going to just actually go back to monoliths i want that i want that but it's not web scale what will you do when your rail app monolith hits max capacity you can't scale beyond your company checks notes 94 billion dollar market cap it's fair amazon prime video team are migrating one system from microservice to monolith yeah i mean this was just crazy we read this article it's on the youtube this one was just crazy it was just crazy ultimately when faced with the need to travel from new york to philadelphia you have two options you can either attempt to construct a highly intricate spaceship for orbital orbital or to orbital descent to your destination or you can simply purchase an amtran train ticket for a 90 minute ride that that is the problem at hand while i could not read for the latter half of that i've ruined this i've wrote the youtube video due to the the reading it's like i fell apart reading i read for too long my brain started falling apart and now i can't do it dude i had so many brain farts the train analogy dude you degraking your guys are encouraging you could do this too overwhelmed by the truth well the thing that really hurts is that i've seen this a lot and i've seen a lot of people just absolutely struggling setting up all these services trying to make everything happen having all this data distribution having all these services that can be uptime horizontally scaled and they're just building like the world's simplest service and i'm just like hey man put it on a machine the name is the primogen