so we're going to talk mostly about the classes we write and you're probably familiar with the pitch giant peit metaphor from from one of the herb stocks there there's all sorts of classes we usually write either utility wrappers function objects all sorts of typ characteres and polymorphic behaving types containers and of course value classes your plain old structs without any funny pointers inside but some are more special than others and what i'm going to try to explain is some of the characteristics of these types of classes and some of the unexpected behaviors that can arise from from using them in in weird ways so i did talk about this topic a while back five years ago actually and start some real good conversation back then and this year i've been asked to revisit thep the topic and that's that's why i'm doing this so i'm going to start with this funny quote from titus good types are all alike every poorly designed type is poorly u defined in its own way and it of course it it alludes to the famous quote from to stream so why regular types why are we talking about this so we shall see that regular types naturally appear as necessary foundational blocks in in programming and i'm going to try to take you with me on an investigation to see how they appear in in the standard library in specification in requirements and even in modern c++ in in concepts and and and similar ideas but even before c++ 20 concepts we've seen these things in in in in all sorts of guidelines including the core cpp guidelines we have c11 make concrete types regular regular types this is quoting from from the guideline regular types are easier to understand and reason about than types that are not regular the c++ built-in types are regular so are the standard library classes such as string vector map and so on and concrete classes without assignment inequality can be defined but they should be rare and we have required template arguments to be at least semi-regular for similar reasons including comprehension so we have guidelines we have conference talks we have books i'm going to mention one or two and they talk about these concepts and i it all goes back to an fairly old paper by now it's 25 years old and it's the alexander stepanov paper from 98 fundamentals of generic programming where it talks about stl and it designs its design principles and so my talk is not just about regular types it it goes and investigates values primarily objects concepts we're going to focus on ordering relations requirements equality equality is going to be a big part of this discour whole part semantics for objects of course object lifetimes and i already mentioned some some of the guidelines and spans multiple c++ versions because we have things coming in in the library that make use of these concepts so i do recommend by the way the slides are going to be peppered throughout with links and references to videos and articles so when you get the slides after this if you're inclined to investigate some of these things further just follow the links i do recommend that you watch this two parts series of talks by titus winters on modern c++ api design specific especially part two and where discussed type families and combination of type properties in good type designs and of course designing overload sets and other things so good all around but let's start with the beginning anyone seen this series of lectures by alexander stepanov i see just two hands okay so four algorithmic journeys if you google for it it's actually three they cut it short so these are the the three tracks it's fairly long so i do warn you if you're not really into this thing it's it's very long there is a a sort of condensed readers digest version on the internet in written form if you want something like that so if you don't have the patience to follow 32 hours of video content and trust me you cannot watch it on 1.5x on youtube i do recommend the book format so the book format for the lecture series is this one from mathematics to generic programming and it sort of goes through 4,000 years of mathematic more or less following from egyptian multiplication and following basically a core algorithm like gcd in multiple incarnations and how investigations in its nature and structure gave yeld to new new fields in mathematics and new ways of reasoning and structuring mathematical concepts and up to sort of modern times where we have incarnations of this kind of work in modern cryptology before we get started let's just we have to nail down some common vocabulary because some of these terms are sort of overloaded and can be confusing so i'm going to use terminology from elements of programming so a datum is a finite sequence of zeros and ones and can represent anything a value type is a correspondence between a species and a set of datums a value is a datm together with its interpretation function so an integer as 32bit to complement big endan let's say that's a value and mind you a value cannot change we're talking here about the abstract concept of the value let's say five five is a value it cannot change some laws and correspondence to equality if a value is uniquely represented equality implies representational equality sort of makes sense and if a value type is not ambiguous representation equality implies equality so the other way around but this ambiguous thing needs to be settled a bit more and an object and i don't mean here like o object object is a representation of a concrete entity as a value in computer memory so it's address and and length so where it leaves in memory and an object has a state that is the value of that of the domain of those value types so an object has a state which is a value and of course the state of the object can change so what we store in memory at a particular location if we store a five or if we later update it to 10 that is something that can change so the object the location in memory and the type is a set of values with the same interpretation function and operations on those values we're sort of familiar with this concept ccept and the concept is a collection of similar types and we're going to see what we mean by similar what we expect from them so all these come all these terminologies and and definitions come from elements of programming it's a i would say one of the foundational books of our field i know not everyone is familiar with it even fewer people have read it from the people who read it i always hear that it's impenetrable or that they couldn't understand anything or that it's it's too difficult or too abstract or to mathematical and i get it i get it you sort of it's good that if you try to read it in progression and you sort of have to do multiple passes and your understanding of the concepts within will be gradual when you come back to it and reread some some of the things there if you want to like a gateway version to that maybe you can start with this shock which definitely very few people know about so mathematics does matter so it's greatest common measure the last 2,000 years very very good gateway into into eop so you can start that way at least it worked for me but you might say okay all this intro all this mathematical uh why should i care about that i' i've been working for n years programming and i didn't do didn't need any eop or math stuff to to help me and the reason why things just work for you is because other people have thought about these hard concepts and encoded them either in the type system or in the libraries that you're using so that it feels naturally intuitive to you so it's not for free it's not like i don't care it's somebody else's problem sure it was somebody else's problem and you're using the fruits of those struggles and and and and rigorous design sometimes rigorous but i would argue that you should care and i'm going to show why so it's basically 4,000 years of mathematics mathematics leading to this paper which i mentioned already and the reason why you should care even if you're using components that have been designed to make it easier for you is that some sometimes those components may fail you and you may miss why you might have surprising results you might have weird behavior uh and this is where your understanding of the world or that system or that design will will start to fall apart and you'll you'll get lost on why that happened we already got a hint of that in this morning's keynote by cavin i'm going to mention it concretely later on so generic programming depends on the composition of programs into components which may be developed separately combined arbitrarily subject to well defined interfaces okay all nice and good sounds like the good the good stuff that all trainers preach and among the interfaces of interest the most pervasively and unconsciously used are the fun al operations common to all c++ built-in types as extended to user defined types for example copy constructors assignment and equality why am i quoting these parts of that paper and it goes on we must investigate the relations which must hold among these operations to preserve consistency with their semantics for building types and with the expectations of programmers and this is why i'm quoting these parts because they what the types that we design and the the the types that we're consuming the the the functions that we're using the algorithms from the standard library that we're consuming make some assumptions and if we're using them fulfilling those assumptions or if we're using them sort of in contract on on how they're supposed to use and if if the types we're designing or the types that we're extending or the types that we're using with let's say stl algorithms satisfy those assumptions those requirements then things will just work and also it's about uniformity and meeting the expectations like even if we design something that works but if it works very differently than other things that people are used to then it breaks expectations and might be surprising even if it does the right thing if it even does the the thing that you document so we we strive for consistency with built-in types or the stl vocabulary types intuition and expectation of programmers and of course mathematical concepts that are established we cannot reuse a concept like i don't know less than or plus to mean something radically different than what people expect from years of logic or mathematics so we want a foundation powerful enough to support any sophisticated programming test but simple and intuitive to reason about okay we might see okay simplicity that's overrated our problems are complex we're building complicated things we deal with c++ we're used to things being difficult i sort of disagree with this yes we're building very complex things but they're all built out of very simple things and or at least they should be so things that we can reason about because it's very hard for us to to reason about complex things and especially relationships between many moving parts and complex systems are very very difficult to reason about so simplicity is a good goal and the way to achieve that is build smaller things that we can understand and relations between those things that are unsurprising and this is where regular types come in at least one side of the the story and i would say i would argue an important part of the design by the way if you want a more modern take on fundamentals of generic programming by stepanov the 98 paper if you want a newer let's say version of it mentioning modern c++ and sort of a modern interpretation of that paper i do recommend this one by titus winters so it's a it's a good synthesis and it makes a case for regular types as well of course and was one of the inspirations for for my talk okay it mentions some of the new additions like stream view and span i'm going to mention those as well so let's go back to the roots stl and its design principles again who has seen this presentation by alexander stepanov this one is fairly well known aside as opposed to the other one from smart friends no nobody okay then should really really watch this one okay so i would say this is the as best as i could describe it is the manifesto of stl so if you're a big fan of stl if you're using it if if you want to understand how we got to this design and and why why some of these parts are designed in certain way maybe it feels weird to you then this is the tok that you should watch okay i'm going to try to extract the the highlights from from that almost to our presentation so fundamental principles of stl systematically identifying and organizing useful algorithms or data structures finding the most general representation of algorithms using whole part value semantics for data structures and i'm going to revisit this item because it's very important using abstraction of addresses like iterators as interface between algorithms and data structures this by by now these are not no longer surprising things but back in in 9394 these were like groundbreaking things and usually algorithms are associated with a set of common properties of operations for example plus multiplication mean max these are all associative operations so that means you can reorder operands and that means you can easily paralyze the operations built out of these operation these kinds of operation chains and we have concrete examples of these things like accumulate or transform reduce so stl data structures again i'm taking you back to that stepanov manifesto video that i i recommended stl data structures extend the the semantics of c structures no no surprise there this is the part that sort of trips people two objects should never intersect and what i mean by that they should model separate entity is and separate lifetimes and this is where we sometimes fail in our designs and this is tied to the whole part semantics that i mentioned earlier and when we copy a hole we we copy all its parts when the hole is destroyed all the parts are destroyed two things are equal when they're have the same number number of parts and their respective parts are recursively equal and so on these all sound noncontroversial things i would believe i don't think anyone would want to argue these points but we sometimes fail miserably at modeling these things when we're designing stuff because of of shortcuts of or convenience we might just add something in in in our type or we might feel the need for some sort of connection that we need to to establish between our types in in in the systems we design so we although we strive maybe for these things we we sometimes fail i i do recommend how how many of you are familiar with hilo programming language or formerly known as val well just one hand okay i i'm not advocating that that you go learn it or use it but i i would say that it's very instructive to to read about its principles and and again there's it has a nice website there's there have been very nice articles about it and some presentations i highly recommend this one by dave abrahams i i hope people are familiar with dave abrahams by now so this talk covers at length some some of the ideas of whole part semantics and how they relate to the design of of hyo and formerly known as val so you can figure it out that if it has or at least had val in its name the language is very much about value semantics so the talk will present some of the ideas of using pure value systems some of the things some of the learnings from swift what worked what could have been done better some of the limitations of producing an industrial designing an industrial programming language that needs to integrate into existing ecosystem and some of the the limitations they had with swift and the path the the at least fresh start that hilo can can get anyway a a very good my opinion very good exposition of building value systems and and and and working with a value oriented programming language so again that manifesto presentation by stepanov mentions introduces mainly programmers to generic programming principles because back then it wasn't as popular as it is now and it talks about abstraction penalty which in early 90s was a really big thing so some of the abstractions that stl introduced came with the runtime cast so many of these went away of course as stl implementations got better and compilers got better at figuring things out of course we have to deal with so the the stepanov talks about some of these drawbacks including implementation in the interface early binding horrible error messages up to this date i would say duck typing some some sur surprises when when using these algorithms for example it might they might work with existing type that you're using in a system and fail to work when when you change some of the behavior of that type or if you're introducing a new type in the system might surprise that it stops working so and the reason why these surprises u appear is that we need to fully specify the requirements on on algorithm types and up until recently the have been formulated in documentation form but very few people actually bother to to look up these things and they're all documented in in in the language specification and you can browse them on cpp reference of course and these named requirements were sort of the informal expectation of the stl so that what they offer the tools they offer you actually work and if you satisfy the expectation of each of those algorithms or data structures because some of these apply to data structures as well then it will they will just work but if we fail to meet one of these requirements surprises do appear so named requirements are used in the normative text of the standard to define these expectations and some of these most of these have been formalized using c++ 20 concepts and they sort of look this way now so just a few examples these are not all of them we can see them a bunch of them that we're going to analyze today like equality comparable totally ordered st quick ordering we see regular and semi-regular as well so now they're fully formalized and they appear in the actual implementations of stl and they're actually checked by the compiler so it's sort of more difficult to to stray from the right path i would say but it's it still might be surprising when you get sure the the the the diagnostic message would be far better now but you still need to understand the concepts and why you broke that requirement because it will tell you that you don't satisfy that requirement but you still have to figure out how does how does that relate to the thing to whatever my vocabulary type my my my thing that i'm using with that algorithm so for more specification of concepts makes possible to verify that template argument satisfy expectations of the template during overload resolution and template specialization blah blah blah sounds very technical what is important is that each concept is a predicate that is evaluated at compile time and bec becomes part of the interface of the template where it's used as a constraint so you might say i usually don't design these things i'm consuming them and if i'm using it wrong i'll get the diagnostic message and i'll i'll deal with it so sure you can you can get by but at at some point when you'll expose either similar functionality yourself and you might not be a library developer necessarily but you might expose similar functionality in in in your application code again you're going to run into the same problem because people are going to expect the same kind of behavior from your code that they see from the standard library so they they would expect uniformity in behavior and again when you're designing your your own types that you plug in or if you're extending existing functionality you you'll have to deal with these concepts anyway and i'm going to pick just one algorithm sort because i'm i assume it's one of the most popular ones in the stl and we already see that we have a a compare predicate there so what are the requirements for a compare type that we have plugged in into into into standard sort well it's u first of all needs to be a callable which means it's we expect it to be a function object and we expect it to be a predicate which means it returns a boolean value and it sort of needs to be a binary predicate because we need to compare two things at a time so intuitive this is what we expect to be there and we sort of expect a a signature similar like like this one where we we take two iterators and we have to decide which one goes first but the big question here is what kind of ordering relationship is needed for the elements of the collection so the stuff that we apply sort on let's say we're sorting a a vector of t's what do those t's have to be or how do those t's need to behave so that it works and i mentioned kevin's keynote this morning did you all remember the do you all remember the the set example with nans that was a fun one right just a refresher and for the the ones who are seeing this video on on youtube so kevin showed a set of floating point numbers where we inserted some some numbers and at some point we inserted a nan and then we we asked about okay what's the size of the set yeah and the other way around we inserted the nan first and then we inserted some numbers what's the size of the set u and or we called we call the count function and to see how many nans do we have in the set and so on and all sorts of of interesting answers that were certainly unexpected by the audience and the reason why those were anecdotical and you might say i'm not i'm never going to insert nans in a set or i'm never going to try to sort a vector that might contain a nan well i'm i'm not going to be so sure about that so if you're dealing with floating point numbers at some point some nan values is going to sneak up on you and you're going to end up with an n value in a vector and then you're going to sort it or you're the the standard set example that kevin gave does the same thing it it tries to keep unique values and and it tries to achieve that using the less than operator that i'm going to talk about so again we're using a type in kevin example it was floating point number that doesn't be behave like we expected to and it sort of breaks that contract just for some special values like for nan for example so it and it breaks some fundamental properties that are expected some fundamental requirements on that the algorithm imposes or the data structure for standard set example imposes the same kind of u requirement is broken for both and it it it works 99% of the time but when it fails it's going to be really ugly to see why so i asked about compare is partial ordering enough now i have just a very simple example there of 2d points where we can we cannot decide an or ordering relationship between all point combinations for example p2 and p3 we can we can state for certain in that example that p2 is less than p3 given the predicate that we defined the predicate is the one under the the picture whereas for p1 and p2 or p1 and p3 when we try to compare them using the same predicate we cannot establish an ordering relationship we say that it's undecided according to this predicate and we we the the formal way we state this is that the the two points p1 and p2 are equivalent with regards to this predicate because we cannot decide which one goes first and it's not a defect of the point it's the the way we decided to compare them the predicate that we're using and that might be an external thing for example if we're providing the predicate as a lambda or power function to into the sort algorithm or it might be a built-in like if that structure implements a less than behavior so it it might might come intrinsically from the type or be provided externally so it turns out that partial ordering is not enough for for sorting to work we actually what we're missing and we can clearly see from from that example where the points were equivalent is that we're missing transitivity of equivalence and this is what comes in to complete all the a axioms required to form strict week ordering and yes stl expects strict week ordering it's the very same thing that is broken for nans and kevn actually explained that this stems from the fact that the the result of comparing n nans with other floating point numbers is is is defined but it's not what what you expect from st we quing so it's sort of it's not a defect so what comparing nan to fl to another floating point number is defined by the triple i standards to to give as a predicate as a boolean result is well defined but it doesn't match up with the expectation of or or the the the requirement of the algorithm so it breaks strictly ordering and equivalence like i said it just means that we cannot decide so it's exactly the the red red segments in the picture so we cannot decide which one goes first according to our comp predicate so formally yes i warned you it's good it's math so formally these are the axioms that need to be need to be satisfied by something to be strict weak ordering compliant i think we're accustomed to seeing these in like fifth grade or sixth grade math they're not exactly something new so ir reflexivity anti symmetry transitivity and yes we also need transitivity of equivalence and it's sort of maybe u maybe a bit harder to follow because we have like a configurable comparator like comp everywhere but if you if you squint and you instead of comp you think about less than then it's going to make a lot more sense but that's sort of a more strict concept than strict we ordering so yeah strict week ordering is actually formalized since c++ 20 so it's this concept and its implementation is exactly what you expect with that table of aums so it just codifies the the four properties required there and like i said it's far easier i think this is what a a fifth grader would recognize from from a math class so if we if we look at it with less than so it's no longer generic comparator then this is the less than comparable concept which is a different concept it's a stronger requirement than than strict week ordering all right so going back to all those named requirements we talked about less than there's one more one more equality comparable that i want to cover and this turns out to be one of the most important ones and again this should not be a surprise for a kid learning math in school they might not like it but this is this is what we're taught very early on about equality and i i would say the meets the expectations i don't think anyone sort of mistakes this or or deliberately tries to break any of these assumptions when when thinking about equality and if we look at the formal definition using c++ 20 concepts we can see how equality comparable concept is defined it uses an intermediate thing weak equality comparable with so it has the same two types that's just a more generic form so we can see that it tests the exact same properties that we had in the table so if we look at the table of the formal specification and the implementation of the concept really this is the actual implementation in c++ 20 so this is what codifies those axioms now i want to just a bit about the difference between equality and equivalence because i i would say this is where we sort of mudy the waters many times when we define stuff so for for types that define equality and less than comparable stl makes a clear distinction between equality and equivalence where equality is what we generally mean when we put that equal equal sign between stuff an equivalence is that thing we seen early on when we talked about um partial ordering when i show the example example with with the three three points in the picture there so equivalence means when we cannot decide either way when we cannot say that a we say a less than b no b less than a no so then we say they're equivalent with regards to to to this predicate to less than whereas equality means more means identity in many cases so equality is a special case of equivalence and formally we say that equality is both an equivalence relations and a partial order but that's just mathematical mumbo jumbo so comp in in total ordering i i told you that when we try to refine things and use less than instead of that generic comp in we had in the axioms then we're we're actually building something something a bit stronger which is a strict total ordering this is what you come to expect from for example natural numbers and the equivalence relations and its equivalence classes partition the elements of the set that are totally ordered and if we look at the totally ordered concept as it's defined we see that it it exactly matches the mathematical definitions now there's a it's it's no longer a a documentation story for stl at this point like h you should know these math concepts or you should satisfy these requirements that are do documented but you should read that documentation now they're actually codified now with actual c++ that the compilers can actually check and produce diagnostics about and they very closely model what we see in those math tables so stl assumes equality is always defined or at least equivalence so we we we can sometimes squint and say okay i'm building an equivalence relation here and it works so equivalence is is more than enough for all stl algorithms and data structures to actually work but we generally mean equality when we implement them there are many cases where it it makes total sense to implement equivalence which is different than equality can anyone suggest an example of equivalence that is not equality we that we frequently deal with for example if we we're trying to compare case insensitive some strings yeah so we say okay for the purpose of this operation i'm i'm doing a search i'm searching a string i i i don't care about it if it matches the case i i'm satisfied with a case in sensitive match for so for my purposes in in this workflow in this operation i they're equivalent but in reality they're not equivalent right they're different representations of they're different strings okay so stl algorithms assume regular data structures so that's why i'm making all the fuss about regular that's why we're having this uh presentation so stl was written with regularity as its basis and we see we're going to see that even the standard broke that contract that assumption so what is regular because i've been talking about ordering relations and requirements and concepts but i didn't specify the the the regular concept so we have to again this is the i'm talking about eop terminology here so elements of programming regular and semi-regular so semi-regular default constructible move constructible copy constructible and so on blah blah blah all these properties yeah we usually want all of them special special mention for default constructible one might make a case that asking for a type to be default constructible is not really requirement for something to be regular but it's usually what stl does for its types formally this is how it's defined in c++ 20 again this is actual c++ code no longer words from the standard and regular just adds one more thing equality comparable to that so regular it just means semi-regular plus equality that's why i said equality is so important and it's so difficult to define sometimes and we're going to see that and this is the again c++ 20 concepts implementation for the named requirement but equality and defining equality is hard it's very hard sometimes depending on the thing we're trying to model this is again a quote from from the generics programming fundamentals of genics programming paper two objects are equal if their corresponding parts are equally applied recursively including remote parts but not comparing their addresses excluding inessential components and excluding components which identify related objects mouthful what that means is that u and even stepanov said that it's h sort of even this definition although it looks complicated and complete it's it's hand wavy so it's defining qualities really hard and it's it's hard especially when our types are not well structured remember when i referenced whole part semantics of objects and lifetimes and overlapping parts and so on things that we should be careful when designing types all those things complicate what equality means for those types or even if we can define equality or equivalence for them special mention here for c++ 20 three-way comparison which helps a lot helps a lot it brings consistency it eliminates a lot of boiler plate of course but it adds complexity so it removes complexity from your code that stuff that you need to write but it adds complexity in terms of the mental model and the stuff that you need to know now so three-way comparison doesn't just return like bull like true false or 0o minus one plus one or stuff that we've seen before it it it it deals in in relation strength and again it ties back to the things that i mentioned earlier those named requirements for how we how we order things so it's all about the ordering relationship that we can establish over the te's that this space operator is is synthesized for so we need to be very explicit about the kind of ordering that we expect and and use and be very careful of weak equality so yeah it provides this handy syntactic sugar it gives us some gateways to more efficient implementations so we can separately specify equality and inequal inequality for for our types and in combination with the synthetized spaceship operator and this is to deal with more complex cases where an optimally a more optimal implementation of equality can be provided separately than the generic ordering relationship that's synthesized for the spaceship operator if you want to see a lot of interesting examples of these kinds of optimization opportunities and what it what it means to define to default synthesize this operator for types i' do recommend that you read the original paper for for for this the link is there and if you're into videos content this is by far the best presentation on on the three-way comparison out there in my opinion link is at the bottom so sometimes we just want a value who who has seen the herbs keynote at this year's cpp con it's already online by the way oh that's a quarter of the room way better than i expected okay so ignore the cpp front stuff and all the future looking things what i do care about is that herb show the way to formalize that something is a plain value and of course using the traditional point example so the word value carries the meaning and and and it's it's it's it's right there in the code so it shows the clear intent and there's no like way around it like documenting that this is a value it codif codifies this anyway i thought it was a a nice touch so again sometimes we just want a value but be before we get too far with fancy cpp2 stuff future looking successor things or if we were looking at c++ 23 or 26 and we we have a few things from from older c++ by now for example option of t so i'm not asking for a show hands i i think everyone should be using optional by now i hope you can it's old enough i hope everyone has access to stuff like optional so it it has become a a common vocabulary type and why this matters is because optional extends t's ordering operations so if your t defines and you those stuff optional will extend these these things so as if they're t so when you're comparing optional of stuff if they will compare as as if you compare your t's within and of course it it saves you a lot of error checking and stuff so it's good all around special mention here for optional of t-f this one you don't have access to unless you're using like a a separate library implementation i have my opinions on this i think it's it's something that we need it it provides rebinding shallow con deep comparison all good stuff i'm optimistic i still think we can get it there are people actively pursuing this so i'm i'm still optimistic but in the meantime there are implementations out there and i always say learn learn from others if you don't know what you're doing look over the fence so this is a a rust talk i go into a lot of details of these kinds of things for examples with using continuations and and the the monadic extensions for optional that's a separate presentation that i have so another one again should be fairly accessible to everyone by now i hope everyone is at least on c++ 17 fingers crossed i'm not going to do a poll because i'm scared of the answer string view again not going to explain why it does what's important is that it's a continuous sequence of char like objects and it's a constant thing so the underlying buffer is constant right this that's the important bit and string this succeeds admirably at at at being a droing replacement for a const string gra that's what it was designed for it was designed to be a glue code to be used at at your interface boundaries to be used in in as function arguments as glue code as your duck type for interconnecting all sorts of different string types you have in your system and so on so it's all good all around but i i think it's it was the first stl type that actually broke some assumptions for c++ programmers because it was sort of weird because it it looks like a value type it looks like looks like a string sometimes behaves like a const string graph in when when used with function arguments so it it looks like a value type it can be cheaply copied around so it sort of tricks you that it's a value but it's actually not a value and it's not actually a reference either so it's sort of weird somewhere in between like a like a borrow type that you you use when when constructing your functions so bar types are references to existing objects they lack ownership they're usually shortlived they generally can do without an assignment operator oo this is where it gets interesting because it ties to defining equality they can generally appear in arguments okay unsafe to store them it's basically the same kinds of gutes that we have for references but now they're sneaked into this thing that looks more decent or less scary but it's just as scary as references right the interesting bits that are relevant to our equality discussion and type regularity is that string view is assignable assign has shallow semantics because the underlying strings are immutable right meanwhile comparison has deep semantics because it actually does a lexicographic compare so this is what you would expect you would expect to compare the underlying strings not some pointers right so when the underlying data type is extant and it's constant like it is for string view we can sort of squint and say h this typee sort of behaves as if it's regular although it doesn't satisfy all the requirements of a regular type strictly but it sort of looks regular so if we're using it properly in function arguments because the we have no surprises with under the underlying buffer because it's a constant thing that we're pointing to we're not expected to modify things we cannot modify it through the string view and so on it sort of behaves as as a regular type but then we have this and this one is really weird because it sort of looks like string view but the underlying buffer is no longer constant and we're not expected to to to be constant that's we're trying to do something to it that's why we're we're using that span we're not just reading it so yeah so i'm going to skip the the r i expect people know so what would stepanov do so turns out with span we actually almost screw it up when when we standardizing very late in the process we actually sort of fix it so the question is should span be regular and by the way that's the paper that dealt with all the nasty details so obvious things okay the meaning of copy construction and copy assignment is to copy the value of the object okay we've covered this already copy assignment in equality should be go together okay when designing try to be regular okay that's the manifesto that's what we're trying to achieve when we design span right make it all these things say make it regular right but what does really happen so assignment is shallow so it just does pointer and size that's what all all we copy because span is meant to be cheap to pass around so it is shallow that's part of its design we could make equality deep and maybe compare elements as if we're using standard equal on them just like we do with string view right this is what string view does so the again the intuition of the programmer is okay i know string view i've been using string view i get how it works i'm using span now okay i think it works the same so these first two bullet points just say span behaves like string view however string view can't modify the elements it points to right we've said that already so a shallow copy of string is similar to a copy andri optimization that's a just a consequence but is span really a value can we consider span a value or is just convenience structure that we manipulate memory with and and and traverse memory and refer to memory can we say is if it's a value or not conceptually i mean and if so do we need to do a deep compare so span sort of tries to act like a collection so it sort of tries to act like a vector we can even construct easily stuff from from collections so it's it's sort of tries to behave as if it's of a collection it has similarly named functions and it's sort of almost there but it's not a collection not really it's not it's not a collection and it's definitely not regular according to any of the semantics that we defined for what regular means more than this i would say span has reference semantics and arguably maybe it should have gotten a more explicit name like span ref or span ptr or something i don't know i guess span is more appealing as a name so getting back to to equality so equality implies deep const logical const as extending to all its parts as per the definition in in elements of programming so we expect if we define equality to mean deep con because it would be very surprising if we define it any other way so all parts all the things that constitute part of the value should participate in the equality operator right right equality operator should do the same things that we do when we copy things right when you copy things we copy stuff right and we expect to compare that stuff to say okay what we copied we got the same thing right according to whatever copy whatever equality means for that thing but again span is not really a value so deep equality means the value of the span and elements it spans not just pointer and length that's what deep means right so if we want span to act like a lightweight representation of it elements we need to have like a shallow shallow equality just like we do for smart pointers by the way that's what smart pointers do so shallow const means shallow equality but shallow equality quality might be really confusing especially like if you're trying to to meet what you know like okay i know how string view works and i expect span to work the same way so it's sort of i don't know a bit surprising so finally the the what we got was a compromise thing so and the compromise was to remove equality all together and because we just couldn't figure out an a way that that makes sense and it just works so i i think it was the right thing to do remove the operator all together but definitely definitely is it's a strange thing and it's definitely no longer regular right that's what regular means regular means equality comparable so so it it it's sort of not a not a value not a container it's it's a strange beast so it and it's semi-regular at best i i i chuckled when i saw this picture from quarantine u a few years back and by the way if you want to like a really gnarly details about span do read this article it's it's very good so for for non-owning reference types like string span you need more contextual information working with them to to understand these concepts shallow compare mutability how we define equality and so on so it's it's it's a lot of it's a lot of work so i would say it it also has some implications when when dealing with uh when dealing with these types so i would say my call to action would be make your types regular when you can model them as closely as what you have in the standard library not span right think of strings think of standard vectors think of integers so that's what you should try to aim for so sometimes yes we need to define utility stuff like string view and span because they're just convenient but i would say those should be the exception rather than the rule okay i don't have time for question on record but the program is over so we have plenty of time to chat in the hallways or over drinks thanks