and now we're going to listen to rino grim telling us about concurrency improvements in c++ 20 in a deep dive really looking forward to this talk right please take hello need m let's go okay i start hello thanks for your words yens today i talk about c++ 20 but not about all what we have in c++ 20 only the concurrency stuff and i do a deep dive what do i mean here the following only the red part here therefore i will not talk about the big four about core language and library improvements i talk essentially about atomics seop force ledges and barriers cooperative interruption and finally about st g okay i will also talk about a little bit about 11 or previous c++ standards to make in particular the picture complete but you will see atomics okay we have atomics since c++ 11 they are the foundation of the c++ memory model atomics when you apply operation on atomic of course this is atomic but what is more important they defin synchronization ordering constraints and the key part is that this synchronization ordering constraints will not only hold for atomics but also for non atomics and this is the let me say other pillars of concurrency in c++ so the synchronization oring constraints are used by the high level threading interface such as threats tasks newex locks condition rs and so on this is the important observation all what we have the the synchronization we have with with threading is based on atomics and they also establish guarantees for non- atomics so what kind of atomics do we have since c++ is 11 we have atomic flck it's extremely as extremely simple data type it only supports two operations clear test and set clear puts it in a kind of fal state test in set puts it in a kind of true state and when you call test in set on atomic flag it returns the old value in this same atomic operation you see when when you read this to member functions you can for example not get the value of atomic flag without changing it you have to set it but there's one extraordinary guarantee atomic flag provides and this is the following one this is the only data type which must be lock free all the other atomics to which i will come in a few seconds can have internally a loocking mechanism have a look we have st atomic and st atomic has a few partial full specialization you can specialize it for pointer for integral type for user defined type for floating points and for smart pointers and this is by the way new with 20 but my point is the following all of them can use underhood unlocking mechanism and so far stud atomic smart pointer uses always unlocking mechanism and this makes atomic flag special because it guarantees to be log free so what can we do with that atomic flag of course you can say test in set and clear and for st atomic we have essentially the following operation is lock free returns to our force if it's lock free or not you can load stor value you can exchange them and these are the bread and butter operations of atomics compare exchange weak compare exchange strong i will ignore weak but to make it complete we also have fetch at and plus equal fetch sub and minus equal the difference between this both operation is that fetch at returns the old value but plus equal the new value and of course we can increment decrement now let me come back to compare exchange strong this is the i would say the most important operation we have on atomics this operation is also sometimes called a cast operation compare and swap but here is called compare exchange strong i don't care so this is how this looks like you see you have an atom atomic variable atom you say compare exchange strong on it and it gets two arguments expected and desired meaning in one atomic operation you compare at tom with the expectation of the value atom should have if both are equal you in what the same atomic operation update atom with desired and return true when at tom is not equal to expected meaning the expectation of the atomic changed in the meantime you update expected with the current value of atom in the same atomic operation and you return forse let me show you how this works in a simple example let me put it here here's a fetch m what is a fetch m this is a atomic multiplication of course this program there's no need for using an atomic only for let me say to explain how it works here have an atomic my atomic in and now i want to multiply by five you see it works five goes to 25 but now is the interesting part what happens here fetch m first of all all this is a function template and what i use here is a concept to integral so this is a function template this function template takes this atomic by reference because the caller want to see this result and the value it should be multiplied with then it stores the old value you see you load the value of shared load and you store it here and now comes this compare exchange strong now in one operation you compare the value of shared with the old value of shared then what this one you get got here if they are equal you in the same operation update to old times m because you want to multiply and you return through meaning this this y loop is done if for some reason something happened in between here and there and the value of and the value of old value changed in between therefore short is not equal to old value anymore you do nothing but you add you change the value of old value to the current value of shared you update your expectation but you return false meaning you do it once more and you do it so long until this is successful and how this looks like is a kind of an atomic transaction you store the the state of the world and then you try optimistically to change it when it works you continue if when it does not work you do it once more until you are successful because you have to mat this is would be typically at a concurrent program therefore you would there could be a lot of inter leing and what you return here is the old value because this is what fetch m should do it should return the old value okay this was the atomic multiplication now we have additional to fetch at and fetch sub fetch might okay this was essentially honestly c++ 11 stuff let me jump n years further we have atomic fleck and st atomic and what they essentially support in 20 is synchronization on one atomic you can say notify one or notify all on on the same atomic you can wait and now you will be notified by this either notify one or notify all and here's the extremely interesting point this atomic weight call blocks if atom is equal to one this is an important observation so let's say atomic is a boolean when this is false and this is also false this call blocks in case of two not let me show you how you can use that let me go to the right and put it to the left here we are this is a simple workflow i have two threats one is waiting for work one is saying set that ready so i have a producer consumer workflow initially i initialize my atomic pool to false meaning this guy here has always to wait because atomic w is false and falce is equal to falce therefore this call blocks it blocks until this guy the producer stores two inside now it has and then afterwards notifies now it has true inside and therefore this call will not block and finally waiting for work can add two to the index position one and now we have a synchronization on a nonatomic because my shell work is is just a vector and we have the synchronization based on atomic pool okay let me jump back i will come back to this example in a few seconds okay with c++ 20 we also have atomic shared putter atomic weak putter let me put it this way one of my favorite quote from tony fer forget what you learned in kindergarten don't share and shared pointer makes this wrong by design it's shared and when you share you have to synchronize you have to protect you have to you have to be aware of data races but the question is is a shar pointer threat safe kind of once more i'm only talking about 11 kind of the control block the handling of the resource is threat safe but not the resource and therefore we got with c++ 20 atomic shed putter atomic weak pointer and to repeat it once more both of them are currently always impl m with a locking mechanism they are called atomic but under they use a locking mechanism which is fine from the standards point of view you might ask yourself or let me put it differently here's the reasoning from hub from our paper why do we need atomics or atomic sharepoint atomic weed pointer first of all out of consistency you may not be aware of it but stood shared pointer was in 11 the only nonatomic data type on which you could apply atomic operation such as load store exchange and you know what and this was incon this was inconsistent therefore now it's consistent we need an explicit atomic shar pointer out of correctness reasons you see in c+ + 11 you could you have to do it this way when you want to store something in a share pointer in atomic way you have to use this function atomic store but you can easily forget it and then you do this one and you have a data race therefore we need this for correctness and the second third argument is you we could also make the shared pointer by design in 20 threat safe but this would be a ptimization because you often want to use the share pointer in a single threed environment and here using a lock would be an overkill okay and this would break the general a the meta rule in c++ i don't have it exactly my my head only pay for what you use we have a new atomic data type in c++ 20 this is atomic ref and this applies atomic operation to the referenced object you see ref meaning reading and writing of this reference object is no data race of course you have a reference from the ownership semantics point of view you must guarantee that the thing you reference lives long enough and stud atomic graph provides essentially the same interface such as st atomic have a look such as this stuff here it has almost the same specialization such as stud atomic with one exception we don't have stud atomic graph of smart pointers because we don't need them okay let me show you an example here we are let me start here here i have a expensive to copy object sorry it's not expensive to copy but i have to start my story you see expensive to copy and then i work the function count and afterwards i return the counter which is now 1500 37 and let me see what's happening here in particular count this is the function count it gets this expensive to copy thing and now here's the interesting part i create an atomic gra around this counter inside this exp and this is of course not sweat sa you see this is an in but because i use it in atomic ref is rat safe because now also this count is rat safe and here i do the the interesting stuff i c create 10 threats you see in vector of threat i create 10 threats each take the counter by reference then i create a random number between 100 and 200 and i add that amount of i add that amount of values to this shared i sorry to this shar counter this is just it's um the running variable so i added to this shared counter and this counter is the counter here which is atomic ref and this is sweat save i cannot prove it but i can you give give you a str strong hint when i use f sanitize to the tech data races it will not become red let's wait for few second sun ah is is missing still running still running you see you see nothing which which is good sorry but when i make this here a nonatomic you will see in a few seconds this looks not so nice anymore still running still running it's r threat sanitizer detects a dat race and the start race is in line let me show you that 28 28 is this line oh here we are this this is this line and of course it's the counter because this is local and this is local okay let's go on we have in c++ 20 sema force there are synchronization mechanism to control access to a shared variable a sem for is initialized with a counter greater than zero requesting the sem for decrements the counter releasing the sem for increments the counter a requesting threat is blocked if the counter is bigger than zero sorry if the count is zero sorry this was unmistaken we have two kinds of de force we have essentially have one we have a counting semaphor and a full specialization for one which is called a bino semaphor and a binary sem for behaves pretty similar such as a mtic because it can have only the values zero and one and for mutex you can think about okay unlock is zero lock is one so you can switch back forwards and back between zero and one okay once more i would see this as a let me say a generalization of a mutex but there's one key difference between a semaphor and a mutex a mutex must be locked and unlocked in the same threat but not a semone you can lock it h not lock it you can acquire it in one threat and release it in another this is the main difference okay this is the interface of a semop for you can ask the maximum value the counter could have you can release the semap for and by default you update the counter by one you can acquire it acquire means you decrease the account by one and this called loock if the count is zero and then you can do it you can try to do it try acquire try acquire for try acquire until try acquire means you try to acquire it if the sem for if the count is bigger than zero you get it when the counter is zero you will of course not get it but you will also not block you just try to to get it and you can also do it with a time a time duration and a time point these are entities from c++ 11 once more this is time duration this is a time point and here you try to acquire it for a time duration or until a time point okay let me show you an example the same workflow such as before exactly the same i have waiting for work i have set that already and here is my nonatomic variable just a vector which i fill partially in the set. ready function and which i put in the rest of it into waiting for work function and here's the semap accounting semaphor it starts with zero meaning it blocks and it can add most have the value one therefore it can flip between zero and one meaning the guy waiting for work this guy here cannot get it because it has the value zero it can only have it if this guy here releases it with this release call the the count goes from zero to one and therefore this guy can have it so you see this is i would say a pretty easy to read and pretty easy to use synchronization between threats okay and let me jump back now to my favorites we have various ways in c++ to synchronize i will show you a few additional examples in a few seconds in 11 you essentially when you want to synchronize more than once you only have one way to do it one possibility and this is to use a condition variable when you have only a one time synchronization please use a future promise pa but here i want to do it more than once so i have a condition rebel a condition rebel has two function to notify notify one notify all with notify one one of the waiter is notified with all all of them on the opposite side we have the waiting guys wait wait for wait until this guy wait waits without a condition without a time condition this four weights with additional um time duration in this one with additional time point and now let me talk about the fun i'm not a big fan of condition rebels let me talk about the fun condition rers can be victims to to extremely ugly phenomena and this is boers wake up and lost wake up let me explain you tell your story and then i say this is how they work imagine you lay in bed you sleep and you wait for the alarm clock to go this is your notification and then then for some strange reason you are working but it was not alarm clock it was a cat scratching at a door what can you do when you un bed you have to check something which happened immediately before the notification and this check is what this three dots here represent i will explain it in an example in a few seconds even better so what you essentially check here is is it how late is it for example once more i was in the picture you lay in bed this is a spous wake up the waker can be a wen but it was not a notify one call or notify all call and then we have the lost wake up thing lost wake up means you go to bed after the alarm click clock went and this is a lost wake up which means underhood a deadlock because you wait for an event which will never happen once more because the standard says only when the waiter the threat executing this weight function is in the weight state it will recognize a notify one or notify all call if not you have a lost wake up let me describe it to you once more i want to explain it because you immediately see that this is pretty complicated to make right here's a single producer single consumer workflow someone prepares the work someone consumes the work let me describe this workflow and but but i have to say this is executed in one separate threat this is some other sweat and let me describe this workflow from the point of view of the waiter so here first of all you call lock on the mutex then when this mutex is locked you gain you go into the weight call and first you check now if return ready exist return ready is something in this case here which happened before the notification meaning when the return ready is set you know that this already happened therefore you know this was the right notification when your return ready is not set this so far didn't happen meaning this was a sp wake up the cat scratching at a door for example then after this check so assume return ready is not set meaning for this means you immediately release the lock and go into the curel modus and sleep then you sleep you sleep you sleep then at one point you get a notification now you check once more is this a spous wakeup or not when you return ready is set you know this was not a sp wake up when you return ready is set you know this was the cat scratch let's continue now in one point in the future you get a new notification and now now return ready is set therefore this event happened before therefore you now okay okay this is my time i can continue here you complete your work and exactly here when this lock goes out of scope you release it i'm not sure if you recognize it that i made a small mistake in my first sentences once more when you are the first time here you check if return ready is set when return ready is said here you know that this r true already happened and this means the alarm clock went before you were before you on the bed and this is how you protect yourself against a lost wakeup once more a lost wake up okay let me show this to you live okay i have the same workflow such as before but now it's a little bit more complicated but essentially the same workflow okay waiting for work set out already now let's check here waiting for work waits here you see while holding in lock and here the lock is released set data ready as in my example sets here data ready to two initially it's false set start ready to two and sets afterwards notification this call notify one is red save therefore you don't have to protect it but of course you have to protect this start ready therefore i have here two critical sections okay so far is fine let me do it once more always when the worker happens or is executed before the center this is fine this means you are first in bed before you got a signal but when the center comes first the alarm clock goes before you go to bed this means i lost wakeup let me try to provoke it now i remove you see i remove the additional predicate and therefore now i'm i'm a victim of lost wakeups so far is fine let me do it a few times i hope i have a little bit a little bit of luck here now i'm out of luck maybe i change the order here which may increase the probability that i get a issue go on go on looks good this is a timeout i have a timeout you see processing time exceeded meaning i had a deadlock and in this compiler explorer this was the l of service attack and now you see i i executed once more now it works so essentially it's a 5050 chance that you get a deadlock when you do it the way such as i did it here okay and now i have a play i want to make a play and i call or a game and i call this game let me see it i call this game ping pong and i do it in different ways because honestly i love it when i have when i could can do one workflow in more than one way i always always i i try to implement it in various ways and then i answer two questions first question what's the easiest way to implement it and second what's the fastest way and this is my game one threat executes a ping function and the other a pong function the ping sweat the ping sweat is a sweat performing the ping function the ping sweat waits for the notification of the pong s and sends the notification back to the pong s so we have always ping pong ping pong ping pong and this game ends after one million all changes let me now show you a a few implementations here i use a condition rebel but honestly i cannot do it with 1 million calls i can only do it with 1,000 calls because this takes too long and now you see 1,000 ball exchanges take around what is it 100 of a second and here's how this game goes f have one two condition vares one and two f two sweat one performing ping one performing pong i end this game after count limit and count liit in this case is 1,000 and the f numbers it's 1 million and this is what the ping guide us it uses a unique lock and then it waits it waits while holding the log until this body card is fulfilled that is equal to for when is this for it puts it back to true and uses the other condition rebel to send a notification to the other s and the other s is exactly waiting on this condition re you see two is notifying and here two waiting one is waiting and one is notifying so it's a back and forth essentially this is the same code such as here but let me say anti-symmetrical i i hope you know what i mean and here i increment the counter because i want to end at 1 million in this case only 1,000 ball changes okay this is how i have done it with condition rs and i have measured the time let me go to the next example let me use an atomic flag i'm way slower but the reason is i did 1 million b exchanges you see now i do it this 1 million and this is how i do it with a atomic fleck i have an atomic flck which has initially the state for meaning here i put it to two you see two and now it has the state two meaning true meaning this guy can continue because this guy blocks on false but of course here it's the here it has the value true then it clears it it puts it to false and notifies and this guy does exactly the opposite it blocks on two sets it to force once more this blocks on two meaning when this passes it's false therefore i set it here to two increment the counter and then i notify it okay this was the workflow with atomic fleck the workflow with atomic po looks honestly pretty similar f1 atomic pool initially set to forse here i set it to tool meaning this guy can start because this guide blocks on on force then i store false in it and notify and here i plock on true and set it true you see also kind of symmetrical finally i come to semap for i used two semors both initialized with zero but both can have also the value one and this is how it works i first release signal to ping now signal to ping goes from zero to one meaning this guy can acquire it then it increases the counter then releases the other and now this guy can apply it and releases the other and so it goes forward backwards now the interesting question we have two questions to answer which one is the nicest to implement or to consume implementation i'm not 100% sure i only know that i think this one is the complicated implementation and then i would say atomic pool or semors are the nicest one but this is a matter of taste but it's pretty clear this is the by far most complicated one because you have to use a predicate okay let me jump back and here are the numbers please don't compare this both this is a windows pc and this is a virtualized linux but what can what you can see here is it's pretty obvious condition reps is terribly slow on linox ends slow on windows and what astonished me really was how fast our semop for are they in the ball packs of atomics and of course way easier to use so in c++ 20 i strongly suggest that you don't use condition re let me talk about another synchronization mechanism lees and barriers a ledge is useful for managing one task by multiple threats when you have a ledge let me put it this way you initialize a ledge with a counter and all have to wait until the counter becomes zero so it's kind of the opposite to a semap so let's countdown which countdown you count down by one but you will not block if the count down if the ledge becomes zero with tr and weight you return two if the coun is zero with weight you block if the count is zero sorry you block if the count is not zero i hope i made no error once more this only blocks when the count is bigger than zero meaning here you block if the counter is bigger than zero and r and weight makes both in one step it counts down and it eventually blocks essentially it's a countdown and weight call by default you countown by one but you can also provide a bigger value and here's a simple workflow i synchronized standard se out in an ugly way i will show it to you in a more nice way in a few seconds have a look here i have six workers help scott b and andre andrew and finally david all perform the same work and this is what they have to perform this is a function object say write their name out and then work done then say say arrive and wait meaning here say decrement the counter by one and block or away if the counter is bigger than zero and of course initially the counter is six and i have six ss meaning all wait here until the count becomes zero and then they say say see you tomorrow and this is the reason why we have such a nice output here first all six prepare the work and then say say see you tomorrow this is a ledge but we have also a barrier it's pretty similar such as a ledge but a barer can do one thing a barer can be used more than once alleged only once so we have an arrive call which act to de decen the count by update we have a weight call which blocks when the count is not zero order to p to be specific until the completion step is done i will say a few words about completion step then we have arri in wait which is equivalent to arrive and then wait and this is pretty interesting we have arrive in drop this means mr r you count down but drop is special here you say in the next iteration i want to be out of this game meaning for the next iteration by default you have the same counter so we initialize with five the next iteration it stays five buss arrive and drop you go down to four and i said something about completion step you can invoke a barrier with a created with a call in this call runs when the counter becomes zero and this is the so called completion step and when this completion step is done the second iteration if required will come or the next duration let me show it to you here i have let me see it a more elaborate workflow i have three full-time worker and three part-time workout and i have a barrier with the value six the parttime worker and i have two work packages one at the morning one at the afternoon but the parttime worker will only work in the morning session and then when they are done say say arrive and drop meaning initially the counter is six they count down here by three and here by three makes in some six but in the afternoon session only the full-time worker will be working meaning here they call one more arriv and fed but here the counter is not six it's 6 minus 3 3 you see here i have two iterations one two and to do that you need a bar up okay now i come to cooper cooperative interruption first of all why it's a bad idea to kill a threat you don't know in which state the threat is maybe the threat is not done with its work maybe the threat is an in a critical section this would mean you would have you could have a deadlock therefore we don't allow it to inter to kill threats we only allow cooperative interruption meaning you can send a signal to a threat and now this thre can react to it and you can do only do it once and this feature is built in into g threat this is the improved st threat and to stood condition reel any i emphasize it once more any this is a generalization condition rebel a generalized condition rebel and this functionality consists essentially of two parts we have a stop token which can ask if it has an associated stop state or if a stop was requested you can only request to stop once on the other side we have to stop source this is the guy sending the stop signal with this get token call you create the stop token out of a stop source with stop possible you ask if source can be requested to stop with stop requested this is to if stop possible and request stop was already called and this request stop is this request to stop or this signal let me show you an example in this case using the g s the next example is more sophisticated by the way this is red because i use standard c the ar chel okay let's see what's happen here i have a little bit of intering which is not bad anyway okay i have two sweats g sweat non-interruptible interruptible and this interrupt gots an additional argument a stop token a stop token is pretty easy pretty cheap to copy it gots a stop token and because it has this stop token it canot use it here to ask if a stop was requested this is cooperative interruption and both sweats count up to 10 and sleep for a fifth of a second and then they display non-interruptible interruptible and this is how it starts you see interruptible non interrupt interruptible non interrup and here it stops why because in the main threat after the main sle slept for one second in the main threat the main threat says request to stop on both threats but only the interruptable threat recks and therefore this swap thre here where is it here re thre and does it by returning and this means only the non-interruptible thread continues this was corporative interruption how you can use it with a chee thre honestly i was when i started c++ 20 a little bit disappointed because i thought okay it's a fine feature but we could imagine more but then i recognize you can do way more stop source and stop talken are general mechanism for sending a signal you can essentially cooperatively interrupt any running entity let me show you an example and i will use also now a stop call back you will see in a few seconds let me start here i have a stop source then i create out of this stop source a stop token and now i copy this stop token in different entities you see a sweat a cheese sweat a promise exactly to the snc here promise where's my promise here's my promise and i also do something here locally let's see what st sweat is doing stat performs this function gets the stop toen and its name and this is what stat is doing function one here's function one stop talking and the string and this is the interesting part it sleeps for one second and now what i do here is i ask for stop requested after one second i have to apologize the interesting part will come here i can also do it with a cheese s so i can also use function one in a cheesee i can use my stop token as as you see sto on here i asked if a stop was requested but now comes the interesting part here have a promise which turns void meaning nothing then i create a future out of this promise and now i execute function two function two gets a promise by l value because you cannot copy a promise you can only move it and the stop token and let's see what the function two is doing it sleeps for one second and here this is the interesting part here i register call meaning when some stop request happens i will just say stop requested you can register call backs not one and up to number of callbacks you don't have to guarantee in which order they are performed but you have to gu that they are performed in general and here i registered the call back and at the end you see it here i say request stop and i also ask in the main s if a stop was requested see i can also ask for it in the main s and here are all the entities which i friendly ask to stop and now you see this is a pretty generic mechanism to cooperatively interrupt any running entity but once more you can only do it once you can only say once request stop now to the last point oh almost this is only a small thing you know this issue with we had with stood threat when you have a threat when you have a threat and you forget to join it and this s t t goes out of scope and it's still joinable meaning no neither called join or detach on it in the distractor of t st terminate is called which causes the abortion of the program and this is the meage you get terminate call is active exception how can you overcome this issue pretty easy just use a gese sweat instead of a sweat now you see it works because a ches s automatically joins in its destructor if necessary a chees models are ai resource acis is ination because in case you call you join automatically in its destructor okay this was a small feature but a nice feature but now to the last feature we have synchronized output streams and i see i'm good in time and they allow you to write an entire let me put it this way an entire sentence in automically to to an output stream let me show you an example here i have you see stood oing stream which w is a wrapper around standard out and all what i put here on side nothing would happen even this stood end call which will usually flash the buffer will not have any effect the output is with an atomic step when this guy here goes out of scope and this is exactly here and this is once more our ai modeled because this is what you do when you go out the scope you synchronize the output stream or you flash the output and you can also do it here with a temporary and you see i create a temporary two standard out this temporary goes out of scope exactly here and therefore here all is written in one atomic step without inter leing finally here's in program i have an this is by the way from cp reference and wrapper around standard z out it says hello world at the end why at the end because this guy goes here out of scope and then the output is flushed and here in between i get a reference to it and write it here in atomic step and so we got here inside bip planet and afterwards when b out one goes out of skape oroscope hello world and now i'm done i only talked about this red part in my in my timeline about atomics which were improved with c++ 20 in particular once more you can you can wait and notify synchronize with them we have now atomics for floating points and for for smart pointers and and we have atomic gra we got additional semop force which blocks when the counter becomes zero ledges in barriers which blocks when the counter is not zero cooperative interruption and finally stood j thanks a lot this was it thank you ror that was a very interesting presentation i enjoyed it a lot