hello everyone sorry for the slightly late start we will well we sort of started in an initially suspended state but i'll save the jokes for later welcome to c plus plus co-routines from scratch i am phil nash work at uh sonar you can see i'm wearing a solo lint t-shirt today some developer advocate there we do a static analysis tools it's not what we're going to be talking about today but i need to mention that at the start do catch me afterwards if you do want to talk more about that of course we're going to be talking about color routines of course before we get to that i want to ask you a few questions first of all who here is an expert at c plus plus co-ratings i'm not seeing any hands okay that's not surprising all right let's make it a little bit easier who here feels like they're comfortable with sleep fast care routines they could probably use it in a project if they haven't done it already half two halves of a hand that's one on average i think okay what about this one and who here has been to another talk on co-routines in c plus plus or read an article and still doesn't quite get it oh i thought it's about half the room yeah that's that's more in line with expectations why is that why is it that we need to go to multiple talks or read multiple articles before we get it because they're not actually that complicated but there are a lot of moving parts and there's another problem with the way we usually teach a complex subject and the right way to do it which spoiler is not the way i'm going to do it today the right way to do it is to say well the subject itself is fairly complex so i'm going to present the simplest possible example so you're not going to be distracted by the other details and and so that's exactly the right way to do it that's the way most other talks and articles will do it one of the problems with that well the trade up let's say trade off with that is first of all you can go away thinking well yeah but how does that apply to a real world problem maybe the more serious problem with that is you can go away thinking that was a really complex solution to a really simple problem which again it's not quite so satisfying or motivating so this is going to be a little bit of an experiment and i should say i've done this talk or i talked with this title twice before now it's my third vanity and i've said every time this is an experiment this is the third iteration of the experiment i i've slightly adjusted it and the experiment is i'm going to present a more complex problem to start with a more complex example and there's obviously risks with that there's a risk i'm going to lose you before i get to actually presenting the material and there's a risk you just be overwhelmed with those details it's also going to take about probably about half a talk before we actually get to co routines because i'm going to build up to it but if it does work the payoff is you will have more of a an appreciation of how co routines can work in the real world and and see a problem where there's a good complexity match and you can say yeah covertings did actually help you there so that's what we're aiming for and hopefully we will achieve it because this is the third time i've done it i've got some feedback from previous runs and i will say they've been a bit mixed which was sort of expected and quite a few people have actually found that it's been very valuable so hopefully you'll be one of them this time around okay what's the problem that we're going to be looking at then that is more complex well first of all who is in the room for the talk before this does more hands going up let's say it's about a quarter of you that was on low latency software for trading this is also going to be coming from a a finance perspective it's actually that's just the context you don't need to understand any of that and it's going to be about performance but definitely not in the same sort of category as a previous talk not low latency you'll see what i mean by that as we get to it but from my experience years ago working at a bank on a quant system and we had to deal with lots of objects like this it's just a sampling of some names that i got from quant lib an open source quant library and of these i picked a few that were going to be dealing with today and so you don't need to know what any of these mean or do they're just there to sort of give more of a real world flavor to to flesh it out a bit now i've sort of created my own version of like mini version of this this library and it's got types like this this is one of the simpler ones looks like there's a lot there but these are all just simple value types so even though we might have say calendar and some vectors but they're just value types now the what they're going to be doing is loading this data in so how we deserialize this is important how we deserialize individual values we're not worried about that today that's another talk so this is a nice simple one another thing to bear in mind because you'll see this a lot a lot of quant libraries have these singly rooted oo hierarchies it's been a few years since i've been in that game maybe there's some more modern takes on it now i hope so but certainly this was very prevalent in my day so our one derives from this f object does actually make things a bit simpler in our case this was a slightly more complex object forward in particular the last two fields there you can see they're both shared pointers to something called a curve so these are dependencies what we're going to be doing is actually building up an object graph of interconnected objects that's why we have shared pointers so we're gonna have to load those separately and also that curve type there we go itself of course derived from meth object but in itself is the base of another branch in this hierarchy so like a little family of curves there which means in in our case where we just say sharepoint is to curves well we don't know what the concrete types are either that also has to be determined at load time another detail which for this iteration i've tried to smooth out a bit more it was a bit distracting was that one of the types we're going to look at fixed rate bond forward derives from forward so it really just extends that type in the code we don't really talk about that distinction anymore now we're going to be getting some jason in so the actual representation doesn't really matter it's incidental but it looks something like this for one of those fixed rate one forward objects you can see we've got actually three dependencies in there and they have this little notation like a string name with a type slash some id record all of these ids so we're going to have some mechanism to go away and find out what that is if we do go away and load one of these curves here what we'll actually get back is just a tiny bit of json that just says a field that says instance that tells you what we should actually load so we need to do two hops for those so a little bit more to it so we're going away load that one then we'll get in this case a fitted bond discount curve specifically as i say it doesn't matter what these actually do i've also stripped out all of the functionality we're just purely loading data here we'll take through objects okay so that's the context what we want to do in our particular problem please load these two objects oh by the way i've just put a load of json files in the file system to to represent some sort of data store there might really be a database or even a live feed so we want to know these two objects fixed rate one four to one fixed rate one forward two now in doing so because of their dependencies in some cases dependencies or dependencies we're going to end up with this object graph so there's 10 objects here that ultimately we need to load in as a result of just trying to load those two and that's really the problem that we're trying to solve so even if you're not working finance you'd probably recognize at least parts of this problem come up again and again it's fairly fairly common or one other thing to say here you see the doctor lines around the curves it's because those objects don't actually end up in the final object graph they're just sort of intermediate as we're loading it so we're going to have a stab at doing this first of all find the right project this one now it's switch mirroring okay [music] what's that font size like at the back is it readable i need to go up a bit i'm getting sort of half hands okay i did create a shortcut to increase the font size i can't remember what it is now it wasn't that okay all right hopefully you can follow this right this is our main this main is going to be the same in all of the examples i'm going to show so i'll just walk you through it once the meat of it is this line here this is actually doing the load and build of objects the reason we say load and build is loading is just loading the json infant file build is actually creating an object to memory setting any fields and then doing any further computation on that as you might do in in the real world see we've got our two ids they're the fixed rate one forwards one and two and we get them back as a presumably a vector now we've got these timers before and after we forget the difference of just so we can see how long that took and and we print that out to this to this log they were doing this in milliseconds and again if you were in the room before you'll think milliseconds that's not going to be accurate enough it turns out it is and for reasons that we'll come on to in a moment that's fine and the last little block of code at the end there the last three lines all that's doing is it's just like a little smoke test it's not an exhaustive test or anything but just tries to probe in and get one of the the values on one of the leaf objects at the end just to check that we're actually loading what we thought we were loading so we know that all the objects first level objects are fixed rate bond forward so we cast them up here we're going to discount curve out there which we happen to know is a fitted bond discount curve and then we can finally check this value at the end so let's say we're going to do the same main for all of our examples for comparison let's have a look then the more interesting part or in fact i skipped over one part which we've got this repo object here let's have a look at there first not much to it as well as i load and build objects and then it will load helper we had this unordered map strings to f object pointers such as a sharepointer to f object and that's our cache so anytime we load anything we put it in the cache and we can look it up by name simple as that we're going to populate that so if we're now looking load and build objects that does the work we've got our initialize a list of ids coming in we're not front how many objects we want so we can reserve those iterate through our ids look it up in the cache because we've already loaded it it's going to be there and if it is there we just put that straight into our output object object vector and if not we call load to actually load it and that will also cache it and and push that back instead return it at the end simple enough so far so that load helper which is at the top here that actually forwards on to deserialize to do the actual work of loading and building and then with the returned object just put that in the cache so let's look into deserialize it's really a little bit more interesting a little bit more messy as well the first line we are just creating our deserializer i've just got a simple wrapper around the end loman json library doesn't matter it's incidental to this we could be loading from xml or protobuf or something doesn't matter first thing we do is find out what the type of the object is that's one of the fields but we're getting it as a string here and now this is the bit that you might have some concerns with we're just doing a series of cascading ifs to see if it's this type we'll create it this way and so on based on the string obviously in a real world project you would have some sort of map with some factory functions yes we can do all of that at this scale this is going to be fine for now so for each one of these strings there will be a corresponding specialization of this build template so if we have a look in the one for fitted one discount curve if you remember from the json earlier this was the the simple one just value types just the leaf type so we create one and then we use the deserializer to settle the fields and that's it we return the object nice and simple if i go up a bit you can see that i haven't implemented all of them the one for fixed rate bond forward this is the one that had the three dependencies and so it's a little bit more complex we first need to load the dependencies so you can see we actually call right back to the repo and call load and build objects again so quite heavy recursion here but that will transitively load the free dependencies then got that in a vector and we can use that to populate our fields so a little bit more to it still fairly straightforward i think but we've got a couple of big problems here one is this very tight coupling now between the the repo that's doing the load and build objects and the serializer that really should just be serializing the field deserializing fields but we've got this this tight coupling here and the other thing is we've got this deeply ingrained depth first algorithm for how we transitively load everything in as you can see that's going to cause us some problems one other thing to show you here is that curve is a special case because if you remember we've got to load that extra file first to find out what the actual type is so we just do that in one extra top here and again recursively call back to the deserialize method so this is our first naive stab at the problem hopefully you followed all of that let's run it and see what happens completed 122 milliseconds so it told you milliseconds was enough run it a few more times it's hovering around 123. why is it taking so long oh by the way this is this is the release builder i meant to start with a debug build but it's about the same does make a difference and the reason is that i didn't show you it's a bit that actually loads from jason i sneaked in this extra sleep for 10 milliseconds the reason i did that as the comment says if you can read that usually we would well in a real world project we will probably be loading this over network something with a bit high latency and that's really what we're measuring here is the latency of these round trips to some remote data store okay so there are 10 objects to load each of them takes an additional 10 milliseconds round trip that's most of most of what we're measuring here but now let's go back to the slides for a moment we were looking at this object graph now we know that the first two objects that we wanted to load the ones in the middle but we know those two are up front we could load those in one round trip and then we can ask each one of those not both of those what their dependencies are and collect that list before we go off to do a second round trip so we're going to batch our loads and then with that i think five second level dependencies or first level dependencies we can ask it for its dependencies and we get the final three and we end up with something more like this if we batch them up so we've reduced 10 round trips down to three which in this particular example it's not always going to work out quite so nicely in this particular example should give us a really significant performance improvement so let's have a stab at changing our example to something like this so okay i think this is the one yeah so main as i say is exactly the same so let's go into load and build objects and this you can see there's a lot more to it now in fact i should start by looking at the repo so we've got the cache as before but we've also got this additional vector to load and this is the thing that's going to collect all the ids for batching so initially we'll populate that with our initial list then as we go collecting the second level dependencies we'll put those in there let's have a look at how that works so right up front we're going to need to populate the two load vector with the ids coming in that's all that's doing and then we're going to go into this loop where all the time there are more things to load we're gonna we're gonna keep looping okay and instead of deserialized we now have deserialize all so it's now a batch loader we'll look at that in a moment and what it gives you back are not the objects but these things that i'm calling build tasks because if the object can't be fully deserialized because it's waiting dependencies it's in this partially built state and so the build task sort of represents that partially built state and the set of dependencies that it's waiting for so that we can match them all up later but having done so we can clear out to load vector ready for the next round go through our build tasks and try to resolve them any any dependencies there we'll look at that in a second if it can't resolve them at this point because the dependents haven't been loaded yet then it puts it into this incomplete tasks vector so we can come back to them later and it will keep doing that as i say until we run out of objects to load so let's have a look first of all at deserializable so this there's a little bit more to it now but you can see right up front this is now where we're doing our 10 millisecond sleep we're doing it for the whole batch that's what we we wanted and instead of creating an object we're creating a vector of build tasks and freak of the ids as before we create our deserializer but then we call build object which gives us a task and that's what we put in our vector and return so let's have a look in build object this looks now very similar to deserialize before except that we return this build task instead but it's got the same type switch so i won't go into that again except just to note that curve is now not treated differently at least at this level we have a build curve and we'll see why in a moment so let's have a look at first of all that simple one fitted bond discount curve this looks almost identical to before no real changes there other than the fact that we return the build task now in this case we actually have the object we return that at the end so build task as an overloaded constructor that takes the objects and says okay no dependencies nice and simple so let's have a look at the more complex one the one that actually has dependencies now we're doing quite a bit more so we have this dependencies object it'll be great give it the deserializer and for each of our dependencies we express it as a requirement dot require the the field that needs to be populated so it's actually going to take a reference to to the field and the the name of the field in the serialized version and if we have a quick look in require you can see it doesn't matter too much but what we're doing internally is just creating this lambda but captures the operation of once you've got the dependency actually writing it into the field that we we passed in and also and then adds it into this unmet dependencies structure so the details don't matter too much but that's what we're doing that's how we're capturing our dependencies up front and then so we're returning a bill to us now we actually create one and we call on it continue with dependencies and pass it this lambda so this lambda is a is what we call a continuation it's like the logical continuation of the same function we're saying well once we've got those dependencies call me back on this lambda you know traditional callback and we'll continue this this building of the object so that there may be more going on here we don't have it here because it is the logical continuation of this function we're having to move in our current state which at the moment is just the object that we're building into the lambda so that we can continue it we also passed it the dependencies object so that we can wait for the dependencies to be resolved and we've returned the build task so later when that task has been resolved we're going to get called back here and produce an object okay hopefully this is making sense so far so it's not terribly complicated but there's just a lot of bits of code to try to hold in your head at once and the curve similar in a way but this might jump out at you make shared of a shared pointer a sharepointer to a shared pointer if that doesn't set up alarm bells i don't know what does but the reason we're doing that is if you remember because this is going to be a dependency and we need to pass a reference to the field that holds a dependency so we need some stable block of memory that that's going to be in so we're going to create it here and put it in a shared pointer now we could have used a unique pointer and i was trying to do that just before coming here today hit some problem like i gave up and reverted back to the shared pointer but it shouldn't necessarily be a shared pointer but it's the level of indirection that's important here then we create our dependencies object require the instance field and we say we're going to write into our outer shared pointer and then the second create the build task continue with dependencies we pass the curve holder in and once that's been set we can the reference the outer sharep pointer to get the inner one and return that so a little bit more convoluted but it's uniform with the with the rest of it now if that didn't make sense don't worry too much okay so that's how we are now building the objects in this batched world let's go back to our top level loop so we deserialized all of our objects into build tasks many of them will be incomplete we try to resolve the ones that we can so let's now have a look at how we do that so give it a build task we'll go through its dependencies each dependency will say whether it's already been met if it's already been set before so we're going to do this for new ones and if not we will call require object which is the same thing we recalled the the very start just to look up objects in the cache or put them on the to load vector and if we did look it up in the cache we can supply that immediately and that's going to call that settle lambda otherwise we'll just record the fact here we still got we're still waiting for something and if we are sorry if we're not then we can resume the task that's going to then call back our continuation lambda that we saw in the builder and assuming that returns a valid object then we can put that in the cache and we're good so that's how we resolve dependencies so if i go back so we did that here as we got the object but after we've loaded all the objects that we can there are still going to be some tasks in the incomplete tasks vector that now hopefully the dependency should have been loaded for so we will reverse through that so from the least dependent to most dependent and call resolve dependencies for those after that we should now have loaded and built all of our objects so we can well they'll be in the cache here so we put them into our output vector and return it so i'm tempted to say and that's it it's obviously a lot more complicated than the original example was it worth it well let's run it and see i run a couple of times so it's coming in at about 38 milliseconds now before it was 120 something wasn't it so we've definitely seen pretty much the expected speed up through reducing that round trip latency that's what we wanted very likely that's going to be worth it for you if you're in this situation pay a bit of extra complexity cost and i'm not saying this is the only way you could do it maybe there's something else that makes more sense for you but it's the sort of thing we're gonna have to do now this is obviously still not using co-routings and i wouldn't be presenting this if there wasn't a co-routing solution for it so let's finally get to talk about co-routings and we are exactly half an hour in so i said we've spent about half and half talk didn't they all right let's go back to the slides there we go so this is what we've done now we've batched up our loads but basically using the same same code let's talk about co-routines so a bit of a an abstract break this before we dive into the code again because when people first hear about co-routines the first reaction is to be overwhelmed by all the moving parts you've got to try and holding your head while you're trying to work out what what works with what i can't guarantee to get ahead of that but i'll do my best so you can see i'll spit this up into user provided on the left hand side the things that we have to write and then standard library or compiler provided on the on the other side there's some bits across the two we'll see what that means in a moment so we'll start with the task or generator type we've already seen build task in our batch example serving the same same sort of role that's is effectively a co-routine task just not using co-routines syntax yet we're serving the same role task generator because a special case of this sort of co routine object is a generator we'll talk about that a little bit later but we've been talking about tasks so far now you can think of this type as being like a remote control for your co-routine so you've got a co-routine going on over here there's some way to control it and this is the interface that you're going to give users of your curry routine how to control it zooming it seeing whether it still needs to carry on getting any state that it's collected along the way that all happens here and you get to control that so this is an interface for your your users which may be you of course and we'll see how this all hangs together when we get to the code but that's its role now above that we have the promise type free misleading name nothing to do with futures and promises well there's a very slight overlap but not not worth mentioning this is really a place that you put any sort of common state we'll talk about that in a moment but in terms of its interface it's if the task type is the interface for your users the promise type is interface for the compiler or the co-routine infrastructure it's what gets cold by the the magic of co-routings so you're going to be writing some stuff to satisfy the compilers actually there's not many places in c plus plus if that happens we've got things like main the infrastructure calls may nobody ever calls that there's a couple other places and now suddenly the promise type comes along and it's got about six or seven methods they get called so that can take it by surprise as well they're a lot simpler than they look at first sight that's what we'll get to that now we have this thing called the co-routine frame you can see that dotted line or the box at the top it's sort of creeping into the user provided side but you never actually see the curry routine frame in the same way that you don't see a stack frame it sort of is provided for you you have stuff in it but you never actually get to say you know what's ever at the stack what not within defined behavior anyway and it's similar here and it's playing in some ways it's playing much the same role so all your local variable within your co routine will be in the in the co routine frame but also the promise type the instance of the promise type is in the co-routine frame and that's actually really significant because it means anything you put in the promise type is going to be is going to persist for the the lifetime of the coating this is quite quite useful information there may be some other bits and pieces in there as well fully running at the co routine now said that you don't get to interact with it directly what you do get is this co routine handle so one of the small number of library types that we do get is the co routine handle and that wraps the magic for interacting with the co-routine itself so you've got a few things on there like resume is on there destroy and a couple of other convenience methods that we'll run into there's not that much to it and importantly the co-routine handle doesn't have ownership that puts that responsibility onto you so it has destroyed but you've got to call it explicitly that's really important so typically not always but typically your it's your task object or generator that has a copy of a co routine handle that does the lifetime management doesn't have to be that way in our example it's going to be and it usually is so we need to take that in into consideration another bit that's a little bit subtle is because the promise type lives in the coroutine frame access to the promise type instance is via the curry jean handle the reason it's a bit subtle is because usually it's the the task or generator type that also provides the premise type so usually an embedded type or you can have a using statement using alias sorry to an external type but it's usually associated with the task type but the instance is held within the co routine frame and is accessed via the curry gen handle so we will see this in practice but i want to walk you through it from a high level first okay now there's one other type we need to provide on the user provided side that's what we call the awaiter you can actually write co-routines without an awaiter or at least without a customer waiter as we say there are some standard library provided ones but for most non-trivial co-routines you are right your own awaiter and an awaiter is it's another case where you're providing methods that the infrastructure of the curry routines are going to call that the magic of co-ratings is going to call back to your awaiter there's only three methods in this one we'll see them in a moment but they're quite important and it will typically have access to the co-routine handle at different points as well now i'm i mentioned that there are some standard library provided awaitors they may not look like awaiters but they are one of the methods on a waiter is are you ready which you can translate as should i suspend or not because if if you're you're ready then you don't need to be suspended so there's two library types which are what we call trivially awaitable types they're just awaitors that simply say to spend always will suspend never and there's not really much else to them but because they are well-known types you should use these because the compiler can see them and say ah yeah i know now at compile time this co routine always suspends at this point or never suspends at this point and we'll look at that a bit more in a moment two more types which i'm not really going to talk about at all really slightly more advanced stud co routine traits and no up covington promise just put it up there for completeness i'll only say about stud chlorotine traits this is where you can customize how some things get get mapped we might mention that in a bit but don't worry too much about it let's just dig into the user provided types a little bit more starting with the test type or generator type as i say it has its responsibility is to provide the promise type usually as an embedded type which is what we're going to use most examples you'll look at will do it this way there's a couple of other ways to do it as well but not the instances of thing what it does also usually hold is the color routine handle and it manages its lifetime so that's up to you so looking into the promise type now this is where you can suddenly be overwhelmed by lots of methods but they're actually fairly simple so first of all we have these four get return object it's almost always the same implementation so if you don't remember exactly how to write get return object just copy from another example it's probably right it's really the thing that creates the task or generator type from a a promise if you remember the promise the instance of the promise type is in the co-routine frame that's been created for you by magic it's already alive there and the a method is called on it get return object that's got to return our task or generator type i remember the task or generator type usually wants to have a co routine handle okay which is interesting because well i've got a promise i need a handle there's a method to get between the two we'll see that later you put those things things together and you get this implementation that's almost exactly the same everywhere unless you really need to to customize it so don't worry too much about it definitely something crying out for a library support the next two initial suspend and final suspend just answers the questions of should i suspend at the start of a co-routine or not or have a bit of code that runs as soon as you call it and similarly at the end should be co-routine finish in a suspended state or just immediately be destroyed now with the first one it depends entirely on your use case do you have code that it makes sense to run before you get to the first suspension point or not simple as that with final suspend unless you know otherwise always call spend always always return suspend always because otherwise the tasks can't actually clean it up there is a way for the co routine itself to effectively clean itself up which can be useful if you're having if you've got multi-threaded co-routines we're not going to talk about that today this will make a little bit more sense when we see the code but trying to give you a heads up and then return value or return void one or the other and this is just a function that gets called method that gets called when you hit co-return or drop off the end of the car routine so in a normal function you have a return keyword you can return the value because it's a co-routine and you have the co-return keyword that calls a function instead or a method it's one of these two so obviously if there's no value to co-return it's a call with return void otherwise it calls return value pretty simple there's no like hard interfaces for these as well i should say it's not like your inheriting from some virtual interface that it has to conform to exactly this so if you want to use different value categories for these types you can or even have it as a template that could be deduced it all just works now you can see there's a bit of a space at the bottom that there's two more that i want to bring up they're both optional in different ways which is why i didn't put them up first the first four you have to provide obviously return value or return void it's one or the other but you have to provide those first four yield value you've only provide if your co routine has the co-underscore yield sleeping in it and if it does then in the same way that co-return calls return value or return void co-yield will end up calling yield value exactly the same way you pass it the the object that you're co-yielding except that co-yield then will usually suspend the the coveting as well in fact it returns on a waiter so you can decide whether it does or not but otherwise it's much the same as co-return and an unhandled exception well if an exception is thrown during the running of the co-routine that's not caught within the coating itself then unhandled exception is called with i believe the exception pointer almost every single demo or example code that i've seen just to terminate there and i'm following that tradition but if you want to do more custom error handling then that's the place you'll do it okay so that's the promise type that's the big one so it looks overwhelming when you see that all at once but actually when you break it down there's not that much to it a waiter is a bit simpler i've just these free methods i'll wait ready wait suspend await museum i already talked about our weight ready i just didn't name it that just returns the boolean to say is the thing you're waiting for ready or not before suspending so if it is you don't need to spend and that's the thing that the trivially awaitable types will will differ await suspend is called just before a co routine is suspended with the handle of the cosine that's being suspended which means within there you can get access to the promise of the chloe team being suspended and that can be useful to either get or put state into the promise type remember i said because the promise type is in the co-routine frame it's in this stable block of memory for the duration of the color routine and that's how you can interact with it including at the point of suspension and a weight museum is called again by the magic of the co-routines just before a routine is resumed so if you've got a co routine handle and you say dot resume on it we saw that earlier before it talks about it it will first call a white vision and then resume the the color routine now we're going to talk about it today but there is a way to get it to resume a different co-region which allows you to transfer control between co-routines without going all the way back again but you could think of it as a performance optimization so we won't talk about it today okay then i think i need to go back to the code look at how this works in practice so this is our build task so we had to build tasks before and say it plays basically the same role but now there's a bit more to it you can see we've got the promise type in there so i've gone with the embedded struct option it's the most common option if you control the build task why not just put it in there nice and convenient if you don't want to put it in there you can have an external type and in here you just have a using promise type equals what do we have outside the third way i think you can use the co-routing traits to say for this particular type builds task type this is the promise type there's three ways you can do it but this is the common way and here we have our methods that are called by the co routine magic the ones we just walked through so get return object remember i said they almost always have the same implementation obviously with different type names in there but we want to produce a build task and we want to give it a handle which you can see down here is the there's an ideas for chloe tune handle that has a static method from promise and we are on promise so we pass ourselves in we get back to chloe gene handle we can construct the build task and return it pretty straightforward it might seem a odd choice to make you go through those hoops surely this could be done automatically but it does give you some customization points you may want to do something different here you don't always need the curry jean handle usually you do so if in doubt just copy this from somewhere else initial suspend final suspend will usually use these trivially irritable types to spend never and suspend always as i say final suspend will almost always be to spend always so that you can clean up in this case we don't want to initially suspend because we actually have some work that we can do before we need to await our dependencies in other cases you may want to wait before doing anything at all that gives you the control and because all we're doing here is returning an awaitor if we need to determine something at runtime to make that choice we can do that as well but usually we'll use these when we get to a co-return in our case it's going to be the object that we are producing it calls return value so here i'm passing an f object to pointer by our value reference as i say it's up to us what value category we want to do here and i'm just moving that into our internal state member so we're holding on to it in a place that we can get to later and then i i lied there was one other method that we can have on the promise type that i didn't talk about before because you don't usually see it actually certainly in these examples a weight transform when we do a weight curate something there's again three ways that we can get in a waiter from something else one of them is to provide a weight transform so in this case we want to await dependencies if we do curl weight dependencies it will call a weight transform and this is going to return our dependency awaitor now if you control the object being awaited you can either give that the awaiter interface itself or give it a method that returns an awaiter and that's more common instead of a weight transform but the reason i've done it this way if i go into that it's because it gives us this point where we can immediately store those dependencies in the promise type before creating the the awaiter and then finally unhandled exception we're just terminating here so they're the moving parts we also have this state we will decide the object so when we co-return the object it's going to end up here in the promise type later we can ask the task object for the object and it can call by the handle to the promise and get the object we'll see that in action and these dependencies we just saw that when we call a weight transform we're storing the dependencies up here and notice it's a stood span of dependencies in our dependency object we look in there here you can see we have a vector of dependencies the reason we can hold a span of dependencies is because that dependencies object lives in the co-routine frame remember all of the local variables of a co routine are instantiated on the co-routine frame so it's still going to be alive when we suspend and resume so it's actually safe to have spans or views references that even that span suspension points in our promise type now i wanted to highlight that because with the the lambda based version that we saw previously we couldn't do that remember that was why we had to create that shared pointer to a shared pointer and we'll see how that cleans that that bit up in a moment because we needed some block of memory that was going to be stable between those calls so this is an improvement and we have the id that's mostly for tracking purposes so i've added this convenience function method here to get the promise type because we tend to do that a lot all it does is just call handle.promise given a handle you can get to the promise type that's how you do it but you'll actually see that i go by this promise method instead lifetime management i said that we as a task are responsible for managing the lifetime of the co-writting the whole co routine frame and everything in it via the kobe tune handle so in a destructor i'm calling destroyco routine which calls handle.destry simple as that really you could have some sort of raii wrapper for the handle maybe even give it move semantics it's it's usually not worth it because you don't usually want to have copies or even move around your task objects so just calling dot destroying a destructor is usually what you need to do but you can do that and most of the rest of it is just getters and setters really and then we've got this resume method so remember i said the build chart or the task object or the generator object is like our remote control for the color routine it's our interface as users of it of how we interact with it so we've got a method.resume if we have a look in there it ultimately just calls resume on the handle i can't seem to highlight that some reason there we go so that will resume the code routing but we can also do a little bit extra we can check whether it's already done and if it is done we can get the object out and return that so we've got a slightly different interface there's our interface we can do what we like here how we present the co-routine to the outside world is up to us so i've now shown you all of the build tasks and the promise type which is actually most of the the co routine the only bit that i didn't really did show you the awaker as well so i think we're there one other thing to mention while we're here you notice here we've got co routine handle with empty angle brackets later we've got cartoon handle with promise type so the empty angle brackets is a specialization of the co routine handle template which basically implements a type erased version so if you don't know or care what the promise type is you don't need to get to it then you could just use this it's nice and convenient so all that really remains is to show what that actually buys us straight to the more complex one so the builder for fixed rate bond forward with its dependencies now this part all looks the same we're building up dependencies but then we just call weight dependencies and now we know what happens when you do that that's going to call a weight transform on the promise type which will store the dependencies in the promise type and return our dependency awaitor which is only really used by the the color routine machinery that will suspend the co routine return control back to the top level caller well we can we can carry on and later we can do t resume on the task which will not resume on the co routine handle which will go we'll call resume on the awaiter sorry a weight resume on the awaiter and then resume the color routine and come back to here straightforward enough and ultimately now we've got the object it's fully built we can co-return it which we'll call return value on the promise type we store the object in the promise type and later we can ask for it via the build task which gets it from the promise type and returns it so hopefully you can see how that's all fitting together there seem to be extra hops involved and it seems very unnecessary to begin with but it all starts to make sense and very quickly become second nature so believe me if it does seem a little bit much do persist now what i want to highlight here is compared to the previous version where we had the lambdas not only is this less syntactic noise but there are some fundamental differences rather than having a continuation lambda this is all in the same body of code and all the local variables are still there sitting there in the co-routine frame accessible and stable that makes particular a particular difference in the case of build curve up front we just have a shared pointer to a curve we express that as a dependency can't wait our dependencies curve return the curve it's a lot simpler because now we don't have to do that dance any extra heap allocation to to hold on to that block of memory between these calls so this is not just syntax it's not just syntactic sugar over the what you could do with lambdas there are very real differences here that are valuable two other things i wanted to show you if i can find them both here actually first of all i thought i was going to forget this i did last time so i wrote it as a comment add deserialize our batch deserialize function deserialize all in this version we are taking our strings our ids as a vector by value now i actually caught myself out when i was going over this code again ready for today doing a bit of refactoring i came across this and help why am i taking a vector by value if i change it to contrast in fact let's do that now and see what happens this is definitely worth emphasizing okay cool good adjacent exception why would i get a json exception well this is a co-reaching i didn't show you this one but because it's a co-routine if we pass the argument in by by reference the finger passing in may not still be around when the co routine is resumed and we are using those ids after we've got a code yield here so it's a dangling reference but it's a really subtle one to spot so i'll put that back we usually consider it a an error or a bug to take anything by by reference to a privacy there are some cases where you can do it but you've got to be really really careful and in fact i had wanted to show you but for some reason it's not kicking in now that oh because i just took it out further back sorry and i think i'm running after time so let's hope this works there we go that might be a bit small to read but it says pass this parameter by value it may be used after co routine is suspended and may become dangling so yeah i have to put my sonar hat on and say this is why you should use sona link because it catches things like this that are really hard to spot but i think i'm going to have to cut that there i wanted to show you this generator because there's a lot of extra code here to make the the final vector into a co routine instead it's c plus plus 26 we've got stud generator which will basically just replace all of that you just include stud generator return stood generator of build task and you're done but i'm going to have to quickly go back to my recap slide skip over that and wrap up by saying that was it i wanted to do a little bit more but we ran out of time there and make a a promise that i will have all the references from this talk including all the code on my site level of indirection.com refs covertings.html it's not there right now and i did say this the last time i gave it one i forgot to put it up there so i will put it in this afternoon i promise but that is co-routines from scratch so thank you very much [applause]