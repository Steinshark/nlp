you only need one great project to landar a job as a software engineer you might have been sold this later or to get a job as a software engineer you need like 10 projects you need to build like all of these things and the more projects you build the better but that is not really the case at all because what employers are really just looking for is strong complex software engineering skills and to show that all you really need is one really impressive projects so if all i could do was build one project and that was the only thing i could build to get me hired as a software engineer in 2024 one great option would be an e-commerce web scraping analyzer and today i'll be showing exactly why this is a great project and also exactly how you can build this even if you're a beginner and i'll give you the actual code to this sort of demo project that we have here so that you can then take it and go extend it from there to make it your own so this is the project it is a cross marketplace analysis tool so essentially what we'll be doing is we'll be selecting some kind of product like let's say this cracking decoding interview coding book and what we want to do is search up the prices for that book on amazon and on ebay and then on any other marketplace websites perhaps in your country or whatever you're using and we're building this tool that allows us to see and compare the different prices in these different sites so you can just have a database of all the products you're interested in and then you can refresh the prices to see where it is the cheapest so before i show you exactly how to build this step by step what the architecture is everything like that let's talk about why this is so such a great project specifically for landing and job so number one it solves a problem this is the first thing that employers want to see they want to see that you understand that coding is a tool to solve actual problems this an actual problem that i've for example had in the past i've had products i want to buy and i need to go to all of these websites and like manually search them up and like go find the lowest price on ebay and things like this this essentially just automates it for us and nicely visualizes it as well number two this project showcases complex software engineering skills to build this project you will have to combine quite a few very crucial software engineering concepts you have build a front end you have a server that we're running in the back end in the finished project you would have a database and what's really great about this is that it really covers all of the foundations of software engineering that you're really expected to know as a junior developer and number three it is visual it is something that's easy to understand the thing when a recruiter sees a project if they can't immediately understand what it does they will just ignore it because they don't have the time to really like look at the code and anything like that that is a very crucial part of a great resume project so with that said what actually is a web scraper so what a web scraper is is essentially you can think of it like a programming bot that goes to the website and just in the same way as you would navigate to the website as a human in your browser except the bot sort of just does it for you automatically and it goes to the html of the website and then you can code it up search that it will find whatever information you're looking for from that html for example you can can see all of these html elements have ids they have classes and using these ids and classes and some other tools will'll be able to access for example this price element right here and that is then what the scraper will return to us as data and then of course whatever other data we're interested in that in all its simplicity is what a web scraper is you can build one of them from scratch as well but the problem that you will run into and that i always ran into when i was building web scrapers is that the thing is many websites don't really like the fact that you're using a web scraper they're like actually very small and they have many tools that they use to essentially recognize when you're trying to use a bot to access their site so you'll end up in situations like your ip address getting blocked by the website you'll get held behind chest and your entire tool might get blocked out of the website entirely but today i'm going to show you a very easy way that you can build a great web scriber without any of this hassle even if you're a total beginner and that is bright data so i found bright data when i first ran into these issues when i was building one of my first web scrapers essentially what bright data is is that web scraping and web data platform where essentially if you use bright data to build a web scraper they have all this infrastructure and all these tools in place to for example automatically rotate your ip address so you don't get into the ip address issues that i just mentioned and this really makes it the easiest and fastest way to build a web scraper today and that's exactly what we will be using today so i spoke to bright data and they were kind enough to partner with me on this video to show this tool to you so what we'll be doing is using their web scriber id which they also provide to you as part of the platform that essentially allows you to use their readymade javascript functions and code templates from major websites to build your web scrapers really really quickly without even having to figure out how to build it all from scratch and then behind the scenes they will take care of like essentially simulating real user behavior with your web scraper and they use antibot detection and things like this to make sure that your web scraper keeps working smoothly over time as well so they get started with right there then what you can do is go down below in the link in the description where you're going to be able to get free credits to get started with bright data and after that what you're going to do is go to bright dat.com you're going to create an account you can start a free trial and once you do that you're going to get into this dashboard right here it's asking me to change my password we're going to ignore that and then what you can do is go to the left hand side and click on web data so here we have a bunch of stuff first of all whatever web scraper you want to build it's useful to check whether they already have a data set that they've already collected for you that you can use they have they have for example crunchbase.com company data they have linkedin company information you could build something like a job posting tool or whatever amazon products data set they have a bunch of readymade data that you can already use so that's super useful as well but to build our web scraper what we're going to do is go out here and click on my scrapers so you can see that i've got a bunch of web scrapers in here that i built in the past but specifically for this one we're going to use this one ebay and this amazon collector which i forgot to nam i'm just going to name me now amazon like that so i've already built them but to build a new one where you could click on is up here develop a web scraper and what that will give you is access to their web scraper api so then what you can do is either start from scratch and use their javascript syntax to build a web scraper pretty easily i have a different video which you can click on right here where i actually build a web scraper from scratch but they also have these templates that we can use they conveniently have an ebay products template and an amazon products template so what you can do is click on one of these templates that will essentially give you a readymade template for for example this ebay products so i'm going to open up the ebay scraper that i have right here and there's only a couple of changes that i made to this so i'm going to click on this and then edit the code just like that and so i believe from this template i removed these conditions because i don't actually care about the conditions i'm not searching for clothes and i believe i removed this line from here because we're not talking about the conditions at all and then other than that i simply changed the currency from gbp to usd right here so i'm going to do this in usd and also this template is for ebay.co.uk so it's for the uk one which of course you could use if you're from the uk but i'm going to use the us one just to be more general so i'm just changing this to ebay.com and those were the only changes i made this code so what this is going to do is over here it's going to build up this search url where essentially just adding these parameters to the url and then what is going to happen is that the web scraper is going to then navigate to that url on this line 10 right here and then after that it's going to wait for a bit to s like some result to show up and and then what it's going to do is is going to use this pa function which is going to be down below here to like pause the page to then find all of the information that we want from all of the search results so the way you can test this out it's easier if i just show you is down here you can define the input that you're giving to this code so for example we're giving cracking the coding interview as an input and going to click on preview and then up here it's going to show the preview of this web scraper running it's going to see it's it navigates to this ebay page up here which we can even open up in our browser to see exactly what's happening and then it's just finding this html page and essentially in this code down here it's just finding okay what is the id of all the prices and like the titles and things like this and it's just returning them to us which is now then going to show up in this output in here looks like right here it didn't work for some reason but usually the way it would come back is if you go back to development and then you can click on here and then statistics it's going to create this web scraper run that is going to take a few minutes for it to run and then it's going to get back a certain number of records and then you'll be able to download it in any kind of format you want so i downloaded one of these before and the result comes back as something like this it's just as a list of these products that the web scriper finds with all of the prices and information and things like this so that is the first step we will build that for the ebay and for amazon which are also have in here and for this one i believe i simply used their template almost exactly i don't think i changed anything here you would find here from templates and amazon products that is what i used so now that we have our web scrapers built the next step is to build our actual application where we utilize this data and the key thing to understand here that while you can run it manually what you can also do is running via an api so what we're going to do is build a server with an api that calls right data with these specific urls that then automatically call these web scribers and get the data from these for us in our application and so what our apps looks like is something like this so so this is built in react and in flask so we have our react front end right here and i'm going to run through the code in a second and then we have a flask backend right here so what is happening here is that we have for example this roue in here called trigger ebay so when we send a post request to this trigger ebay endpoint this function in here is calling bright data with a specific url which you're going to get by the way by when you go here to copy link and you paste it you you'll be able to see that this is the exact data collector url that you want to insert here and then after that we define some headers where we define the api token which i have defined up here and i'm going to have to change it after this video because i've now shown it to you we define content type things like this and then we send the request to that endpoint we get the data back as json we get the keyword and we get the count then we set a data object and then we send the request by going request. poost the url with this headers and the data that we just defined and then we're going to get back data that at this point is just going to indicate to us that okay we started the web scraper run but as remember from before it will take a while for that web scriber to actually run so that is why i have first of all a different function to trigger the amazon web scriber which will build exactly in the same way and then i have this endpoint in here that actually fetches the data after it is ready so the way that this works in the front end side of things that we have this main app component where most of the logic is happening and we have first of all this form up here where you can enter an amazon url and a keyword which are going to be the keyword and the amazon urls that are given as parameters to these web scrapers because the amazon web scraper is going to take an product url as a parameter and the ebay one is going to take the keyword as we saw before so what we'll do is we'll copy this we'll paste it in here and then we will copy the name which will use as the ebay keyword we say that's the keyword and when we click on add product in here what is going to happen is that it is going to call the add product function just like here and then this function itself is going to run this fetch amazon and fetch ebay functions which have defined above so it's a post request and as the keyword we're giving this keyword that we now then need to access down here and well i guess that's just a default value that we can remove right there and we can remove that as well so over here we're grabbing the keyword from this incoming data that is coming to this back end and that is then making the actual call to the web scriper after that what happens is that when we get the response back assuming nothing goes wrong we will return turn the data from this fetch ebay and very similarly from this fetch amazon function and i can see that from here because i'm console logging in on this line in here is that what we actually get back is simply something like this where it gives the collection id for the data that is being gathered and it just tells us the day on when that data gathering began and then inside of our bright data we'll be able to see that we started the data gathering and we have this collection id and then what will happen is that it will show this sort of disclaimer in here that says fetching prices come back in a couple of minutes to refresh because we need to wait for that web scraper run to finish and then we have this different button here called refresh prices that will then call this fetch data set from server function for all of the products in our products state which is simply stored up here in a real application you would store this in a database because right now if we refresh the page everything disappears but this is just to show you a demo of what we're doing so for all of those products it's going to call fetch data set from server where we get the amazon collection id which we have stored as part of this product when we added the product right here specifically on these two lines so it will fetch the data for the amazon collection id and the ebay collection id and then from those it will set the amazon price to be the amazon final price that we find from the data that comes back we'll see in a moment when we actually get this data to come in which format it is looks like it's still not already but i was doing this before so i believe right here we can see the format in which it comes back so it comes as an array which is one item where the price will be this item final price and then value so that is what we're accessing here we're getting the amazon price and then for the ebay price it comes back in a slightly different format it comes back for some reason it just came back with one item it usually should come back with more but anyway we get that and from all of the array of ebay items that we get back we will access the price from the item price and then value and then this function here finds the minimum of those prices so essentially you don't need to worry about how this works it's the reduce function in javascript you can just ask chap gbd honestly just describe it to data format and tell it just find the minimum price from this that what that's what we're doing we're find the minimum price from all the ebay listings and then we're setting the amazon and ebay prices as part of the state of the updated products that we're then setting it into the products st state and then once this eventually comes back we we will be able to refresh this and see the price is here it's not ready yet so i'll just show that to you in a moment but that is the core architecture of this product and then other than that we have this product search component where we have just defined the input fields and things like this honestly all of this i just got from chat gbt i could walk you through all of this code but it's honestly easier for you to just describe exactly what you see here what you want to get and then chbt will basically just give this to you or you can just use my code down below all of this is completely open source you can go and develop it further and things like this and once i finally refresh it will eventually look something like this where we can see the amazon price the ebay price and the price difference down below just like this and this is essentially the core idea of the project now what you can do is you can go to amazon find a different product as well like for example this one right here the same thing copy the amazon url the ebay search term that we're going to be using and it will add the product which will send a request to our backend which sends a request to our bright data web scrapers both the amazon and the ebay ones it will start the web scraping behind the scenes which you don't need to worry about because you're using bright data and then eventually again you can refresh prices and you'll be able to see the price details for all of these products and the one last thing over here is that of course over time what we want to do is be able to update these prices so we want to be able to rerun these web scrapers on a regular basis to find updated prices so what we're doing is we have this use effect that is defining that on an interval of one day which we're defining in here it is going to run this refresh products function up here which essentially just goes and takes all the products and for each of them it fetches ebay and amazon and it essentially updates the collection id for both of them to be the new collection so the updated data that we're now getting from the web scraper and then it will push them to this updated products array which we're initializing up here and assuming nothing goes wrong it will then set the products list which will now have updated collection ids for both of them and now whenever we refresh pices we will see the new and updated data you can of course define whichever interval you want and again if you use bright des for the link down below in the description you get free credits so this can all be completely free for you but that is essentially the product right here essentially as you can see quite quite a complex product hopefully you understood like the higher level architecture of the project and then i will leave the code down below you can go and explore it and then extend it from there go explore the different web scribing tools and bright data go explore what else you could do with this in the real project you might want to add some kind of graphs in here to like see how the prices are changing over time you could have a database which would probably be your first order of priority to actually store this data persistently you could add an automation script to like run these web strivers in the background rather than having to have your servers and everything running a bunch of things you can do but i'm going to leave that to you to go and extend it again thank you for bright day to partner with me on this video really great tool that i use all the time when i'm building web scrapers again link down below go use that with that said if you didn't like this project and you want to see more ideas for really impressive resume projects that you could build to actually get hired then i recommend you watch this video right here you guys have loved a bunch of great ideas over there to get more great projects built go that video and i will see you there