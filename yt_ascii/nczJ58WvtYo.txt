last time we talked about pipelines and pipelining and cpus so you give us a little hint about what might be next on the horizon absolutely and branches yes predicting branches yeah predicting branches so yeah so the story so far is we have our little pipeline of robots and i forgotten how i to draw a robot they have square heads not not round heads otherwise they're humans right and we've got our various conveyor belts and we've got the shoveling robot at the beginning who's picking up bites from from memory and these btes encode the instructions the recipe steps that the the computer is going to follow the next robot in the production line interprets them oh i don't know what i'm drawing here but something like that interprets them as instructions and so he now says hey i decoded those sequence of numbers this means please add the number one to address 22 or something like this and then at the very end we've got a robot and again who has a square head who's actually doing the work of the addition and all that stuff right and that's great and it's faster but there's a problem because every time the end robot discovers that we need to be doing something different if we're going to change which recipe step we're on and it's not just strictly the next one in the sequence like for example going back round to the top of a loop he has to pull the horn and everything has to restart and that's a shame because now it takes two ticks of the clock before any useful work is done again so we discussed last time some simple ways of of of making this work this time we're going to talk about branch prediction most of the things that modern processes do actually involve adding more steps to this pipeline so i haven't d myself room on this piece of paper now but there is now a new robot at the beginning of the production line and that robot's job is to make a prediction and i think we had some really squiggly eyes that you drew you animated beautifully in the last one once crystal ball but it proved beyond my capabilities so instead he turned into a hypnotized h because i said something about it being clairvoyant it has to predict the future and that's exactly what this robot is going to do this robot now is responsible for handing the address of the bites to fetch to the shoveling robot so to start with this robot is going to start with the program counter like the place in the recipe you know step one for example and he's going to just say fetch bite one then fetch bite two then fetch bite three and he's just going to keep handing addresses sequential addresses to our fetching robot who then fetches address one puts it onto the conveyor bel and in this extended version as well as putting the btes onto the conveyor about he also notes down which address they came from because we need to do some checking later on and we'll get to that so now everything else is pretty much the same though so right now as it started what we've done is we've added one extra stage to our pipeline which means it takes one more cycle one more tick of the clock to start up and we've got no benefit but this is where it gets clever now when our executing robot says hey we got to a a jump or a branch and he has to pull the ripe to say you know everything needs to restart he sends a message to the first robot and says by the way i got to this point in the code and then i needed to go somewhere else i needed to branch to a new location and our little robot notes that down so i'm going to make up a really really simple example just so that we've got something to talk about and so our instructions are going to be and i'm going to say this is like an address 50 in memory and i'm still using the 6502 based assembly code hopefully it's you know it doesn't really matter what it is and the 6502 didn't do this nor would it need anything like this but it's we're sticking with what i know so i'm just going to have a loop of incrementing the x register which is a one bite instruction and then the next thing is to jump unconditionally like every single time back to address 50 which is a three byte instruction what's this one's eb hex this is 4 c and i'm doing this in hex but whatever these are the bytes that are actually going to be in our memory cells in sequential memory which i can draw out in a second and then it it doesn't really matter what's next but i'm just going to write down that there are some other bites after this in memory so that we can and i'm going to put knops here we wouldn't normally do this it's just so that i've got something to do so this is ea i think ea there we are right okay so just i mean it's probably obvious but knp is null operation a no operation yes it's it's it seems weird that you have to have a recipe step that says do nothing today you know have a lie in have a nice relax for a clock cycle but it's very useful for this kind of thing and also for timing and stuff like that but right now yeah we i've just put those there because i need a bit of padding exactly exactly so in our production line the predicting robot would predict let's say we already knew that we were starting at number 50 he would predict number 50 he'd hand over 50 to the the fetching guy who would fetch the bite the bite would be put on the conveyor bel the next person the next robot would decode it as an increment it would go to the executing robot meanwhile of course the predicting robot has predicted 51 given it to the fetching robot 52 53 these are the btes over here so this is bite 50 this is bite 51 52 2 53 54 55 or whatever and he's just happily shoveling out incrementing numbers with no no idea at all he's just like 50 51 52 53 54 it's a best guess right meanwhile the increment has gone through and then the jump instructions gone through and eventually gets to the executing robot so by the time that the third bite of the jump has been decoded by the decode robot turned into a jump to address 50 handed to the executing robot the the predictor and the fetcher have already fetched these next two bytes and it's been coded as a kn so there's a knp that's waiting in the pipeline and there's another kn that's been the bites of it have been loaded onto the conveyor belt and those are not things we want to do right we want to actually go back to the top of the loop so just to be clear this this jump is an infinite loop that's just going to sit and increment the x register forever it's a pointless thing to do but it was just a very straightforward little little program for the purposes of this so the first time this happens the executing robot pulls the rip cord and says way way wa wait wait wait we're going the wrong way i need to get back to address 50 please he sends a message over to the predicting robot and the predicting robot notes down oh interesting next time i i fetch bite 53 i should actually then start back at 50 because that's what the executing robot has told me he said i've got to the end of a jump i took this jump i just the address was 53 because that was noted down on the flow of instructions coming through and by the way next time could you just like go straight to 50 please all right we'll talk about how the predicting robot notes that down but now you can see that the pipeline is flushed and then we start again and so we know that we have to start at 50 and we go to 50 and so now the fetcher is going to do 50 51 52 53 oh the prediction rob says having just predicted 53 i should predict 50 now and so that's the number he sends to the fetcher and and now the sequence of instructions is just going to keep flowing through correctly and we won't have any delays while we flush the pipeline because our executing robot actually peaks ahead and says well okay i would like you to i would like to jump to address 50 and then before he pulls the rip cord and says oh we need to flush the pipeline he peers ahead and looks at the next instruction and if it's tagged with address 50 he's like oh cool the predicting robot predicted the correct way i don't have to pull the rip cord we just have to carry on this is great and so now we filled up the pipeline with increment jump increment jump increment jump and none of these knots make it through anymore mh so we have predicted for a very very very very simple case what's going on so let's talk about how the robot at the beginning of the pipeline the predicting robot how the predicting robot does this job because i just said he notes it down but like yeah sure i could also say hey why doesn't he just read the op the the the memory himself and just look it up then it's a jump to 50 but that's too much work for a single step of the pipeline so some what whatever he does has to be incredibly simple so first piece of paper off so let's there are many ways that this can be done and in some ways it's similar to caching which i'm sure there are computer file videos about and or we'll talk about some more another time but let's just say this is the simplest way that i could think of that that's visually straightforward let's give the robot a notebook with 10 entries 0 one two and in this table he has a from and a to address every time he's told that there is a branch at address say 53 and i've already thrown that on the floor so let me put this over here in this particular instance i'm i'm using the last bite of the jump instruction itself as being the place because that's the last one the robot the the fetcher would have to fetch before he had to start going back to address 50 there are different ways to do this but oh and of course i haven't actually put three in the table here okay there's three dot dot dot the robot could search through this whole table every single time and look for if there's one of these 10 entries that matches the from address then you could go to the two address but that's a lot of work even that i mean it's that's 10 whole steps every single click of the of the clock and that's just too much work for for our simple predicting robot so what he does is he looks at the last digit of the address so in this instance as he's predicting address 53 he knows to only look in slot three now that means that there could be some other things in there that are the wrong thing but if it matches then he's going to take that so let let me work through that and hopefully that'll make a little bit more sense so the table starts out empty to begin with the robot is predicting 50 and as he's predicting 50 he quickly looks in the table and he looks at the last digit of 50 zero the table entry for zero is empty fine 51 without anything in the table he just predicts the next address right we're just going to sequentially sequentially go from address to address and so on and so forth so we get to 54 and 55 and that's when the the air horn is pulled and our friend the executing robot says hey 53 has a jump to 50 so we will update entry three of our table and say hey 53 goes to 50 then we reset we start again zero check 5501 check 52 check 53 okay we're looking at slot three oh the from address matches for this particular jump oh so i know that instead of incrementing i'm going to go to address 50 and that's a really simple way of doing it now there are obvious flaws with this simple approach and that is what happens if there are two branches one at address 53 and one at address 63 they're going to land in the same bucket and then what we keep doing is overwriting them and that's a shame and it's unfortunate there are limitations to this and there are ways of improving that we can have multiple slots in this thing in this this table but it's a straightforward way and it's you a flavor of the kinds of things that are going on inside in modern cpus this is called the btb the branch target buffer and it's a predictor for where the target of a branch is and in fact it's also predicting whether there is a branch because our predicting robot doesn't know anything about the program at all he doesn't know anything at all he just has he's just got a increment numbers and occasionally check his table and say oh no no no actually we're going to go somewhere else now if you've ever heard of branch prediction before a lot of it a lot of it concentrates on predicting whether a branch is taken or not and in this instance i've started with an unconditional branch this always happens and so it's an easy choice every it always happens so every time we get to address 53 we want to go back to 50 fine what happens if this was a conditional branch what if it was comparing two numbers and it says well if the number is greater than 10 do something else not how can we update this well let let's get a very simple example i'm going to put you over there and i'm going to work through let's say we've got a our fibonacci sequence they again load 1,000 comma x add 1001 comma x store 1002 comma x increment x compare x with say 100 to get the 100 fidar numbers branch if not equal back to 60 at the top here this is address 60 this will be 60 3 66 69 70 72 i think i'm they're trying to remember how big each of these it doesn't really matter but like it gives us some idea but you know for example here's the first example where these two instructions 60 and 70 would land in the same table entry and so if there was a branch in both of those locations they would fight for each other but there aren't in this particular example but what we've got here is a conditional let's do rts here which would be 74 we've got a conditional branch at this this point in the table so let's assume we've actually run one program and then the other so we're going to use the same bit of paper for the sake of making this easier what would happen if we just use this the approach that we've got so far well we would run through 60 and there' be nothing there 61 62 63 of 63 when we get to the ad we would look in this slot but we would compare it with 53 and we're like well that's not the address of a branch right that's we know that it's not a branch because 53 not equal to 63 so we don't use this particular entry to the table we keep on going round and round this thing eventually we get to this branch now let's say it's the first iteration of the loop so the branch is definitely taken when we get to the branch and the executing robot says wait a second i did the comparison and we're going to go back to address 60 here we are at number 72 in this instance the end of the branch is address 73 oh isn't that convenient that actually wipes out our branched hobby buffer over here so 73 would actually land in this same slot so this is a good example of evicting something from the branch target buffer unintentional he would send a message and say wait a second next time you get to 73 go back to 60 please so our our our predicting robot would come in cross out 53 here and we write 73 and it goes to 60 brilliant and then we would go back to 60 and we'd loop round and of course when we get to that branch we would correctly predict that it we go to the top of the loop again and so this is going to work for 100 times that's great we've predicted the branch correctly 100 times or 99 times i guess if the first time was a misprediction and then we get to the problem on the hundredth time when we don't take that branch something interesting happens the executing robot will get to the branch he will look ahead and go well i'm expecting to see address 74 now because i didn't take the branch but the next thing in the pipeline is actually the load for 60 oh dear this is a new kind of emergency situation instead of us taking the branch it's like well we took a branch and you didn't guess right sorry mr predictor you made a mistake so he pulls the chord and we throw away all the work again but he also sends a message back to the predictor to say like you guessed wrong and this could also happen for example if we've loaded a new program and we actually don't have a branch there anymore for example but so in that instance what the robot would do in this very simple predictor is just cross out these entries and leave them empty again and then he next time around he won't make that prediction and so that's an okay prediction system we always predict effectively what we're doing is for every branch we predict if it's conditional that it did the same thing it did last time because if we remembered it from the last time and the and we were rered we go oh all right well next time i'll predict it to be taken or whoops no next time i predict it to be not there at all and that's not terrible you know it's like the old adage about like predicting the weather you know yesterday's weather is a perfectly good predictor for today's weather under almost all circumstances and and it's pretty true of most branches they probably go the same way certainly of loops that is a good guess if you took it last time you'll probably take it again cuz loops often go more than a couple of times and you've already paid back the cost of predicting or mispredicting but what if we wanted to go a little bit more intelligent so you know maybe i mean what would you do if you if if if if you kept being asked or being told that things are being taken or not taken how might you think of like trying to make a guess about whether next time something's taken or not well you could maybe jot how many times you'd done it i don't know would that exactly exactly so yes what we're going to do and again all these things have to be so ludicrously simple that they can be done in one clock cycle by this prediction robot and i have a prop you don't know this but i've got a prop hopefully this shows up on the camera this is like me raiding the kids toys they're all grown up now so that you know we've got a basement full of nonsense here is our table again drawn out or rather doodled onto the side of a toy here are our slots are from and our two and i've got some validity thing here that's to say whether or not it's filled it or not but i'll just use whether i've written in it or not and so what we're going to do is every time we take a branch let's let's copy out my chart from here what were we number three was to from 73 back to 60 so number three was 73 whoops now it's not going to write on here 73 back to 60 and i guess it's valid i'll tick the box there to say it's valid there you go it's an actual branch that we we did take you know in obviously in computing terms you can't have empty boxes you have to have a bit somewhere that says are the boxes empty or not and that's what this little bit is on the end here it's like a earli thing so we start out with these predictions here and i have these frowning faces going through to smiling faces which may not be visible on the camera but never mind and this is our the number of times that we have either taken or not taken and every time we take the branch we move the counter one to the right and every time we don't take the branch we move it one to the left and then when we have to come and make a prediction we say if it's in the left half we'll assume that it's not taken and if it's in the right half we'll assume it is so we have some kind of track of like it so like for example well let's say we initialize them all as like we're going to guess that these are referred to as you know very unlikely unlikely likely and very likely something like that and so we'll assume that it's just likely slightly likely is our sort of default case so the very first time we hear about a branch that's conditional we write it into our table and we initialize its counter to be here right in the in the somewhat likely case and then we go around the loop and then the next iteration around the loop we we we predict that it's taken because it's in the somewhat likely camp and then when we get the feedback so now now our executing unit has to always give us feedback it doesn't always tell doesn't just tell us when we got our prediction wrong and you know pulled the rip cord has to tell us like hey yeah you guess right well done you and if he says well done we pick up our counter and we move it over to the the right here and now we're even more likely to predict it now obviously that means that next time around the l we're definitely going to predict it in our particular example that we just explained here with the with the loop of 100 when we get to that 100th iteration and we make a mistake and we go yeah we're predicting it instead of throwing away our work the executor robot says hey you guessed wrong we didn't take that branch this time and we go oh well i guess we're going to move you back down to only slightly likely and that's pretty cool because if we were to re-execute our fibonacci loop it's still the case that the next time we run it we probably start from zero again that we do actually want to predict it was taken in without this this counter here we would have just said no it's not taken immediately we'd have just predicted the same way as last time but here we have a little bit of hysteresis we've got a little bit of a memory about how this has gone before and it's still extremely extremely straightforward for system this is just two bits inside this otherwise quite large table that predicts whether or not we're going to take and obviously if it was a more complicated conditional instruction or sorry conditional branch then eventually we might learn that it's not taken ever again you know we keep going back until it's like no never predict this is being taken that's kind of the the simplest form of this s of branch prediction with with the conditional part of it like that is deciding whether this branch is taken or not so this this branch target buffer here which i'm representing has two jobs the first thing is is there a branch at all and the second thing is should it be taken should we predict that it's taken this time and obviously you can just if you get an unconditional branch you could use the same table and just initialize it as you know extremely likely like if there's a branch up here but in practice they're done separately and so this is great but there are a lot of things even that this doesn't cover and so just to give you a flavor of the way that modern processes work what modern processors tend to do is they separate these two tables out they have the predictions in one table that's much bigger because the tables of it's only these two bits for every entry in the table and then they have the the from and the two and then they use a combination of where the branch was the history of the last few branches that have been taken like for every time we take a branch we add a one to like a a register that's being shifted along and every time we don't take a branch we put a zero so we've kind of got like a pattern of like what's happened recently and we smoos all those bits together with like a very simple hashing algorithm to get like a unique fingerprint for when i got to this branch and i had taken the pre previous three branches and i had not taken the the branch immediately before that then i go and look at a particular entry in my likely or unlikely table and then i will update and use that for my prediction and that allows the branch predictor to take into account patterns in sequences so for example you know if this if two things are correlated as they often are then the the branch pr will learn that if you take this branch you're almost certainly not going to take this other branch because that will be in the pattern and it will be in the history so it's kind of like a learning very straightforward learning system system and it's remarkably good at predicting the flow which as i've said before is really important with modern cpus where this pipeline isn't the three or four steps that i've described it's many many many steps and it gets even more important to get this right when we start adding more and more execution units that is more and more robots at the end of the pipeline that can do lots of work simultaneously is i ask a question is is there a situation where no matter how complicated or impressive this is that it just doesn't improve things absolutely yes yes there absolutely is so there are pathological cases for certain so things that can't be predicted are like random events random events can't be predicted and so the pipeline is got you know at best 50/50 chance of getting things right in which case you know you're throwing away work half the time it's still no worse than if you didn't do prediction at all because you'd still be wrong a lot of of the time but it can be considerably slower than a branch that is predicted so for example actually there's there's a i wrote a ray tracer which i'm sure you've covered before and one of the things you do when you're ray tracing is you take a line in space and you intersect it with a triangle and see if does this line cross through this triangle and for any one individual triangle you're very unlikely to hit the triangle with any particular line this is in three dimensions and one of the checks is am i off to the right of the triangle or i am off the left side of the triangle right and each of those is a comparison and a and a check now for any random triangle and any random line you're it's it's a literally a random chance whether it's off the left or off the right and so the branch predictor there can't get it right it's like hey you just gave me a ray that's anywhere in 3d space and it turns out it's off the right but it's just as like to be off the left right and that's unpredictable and that's hugely slow to predict but if you combine those two comparisons together and say is it off the left or is it off the right together and then do a branch off of the the pair of those things combined that branch is very very predictable because it's almost always yes like you didn't hit the triangle branch away skip this triangle go to the next triangle and so a tiny literally one character change in my source code for the ray tracer sped it up by 30 or 40% because this was in the deep core loop of of of the c of the rendering loop and it was just really fascinating and really interesting sort of to to be able to track that down and and trace it right back to the predictor inside the cpu metronome clicks before that particular thing has finished but what you'll notice is that if we can keep it fed if this therefore we can calculate the lighting effects and it's why i'm able to have a shadow here because