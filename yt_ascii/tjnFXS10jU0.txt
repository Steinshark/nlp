and i see someone saying hello in the chat so i said that was a good sign so let's get started hello welcome to zen and the art of code lifecycle maintenance so i'm phil nash i've got my twitter handle there on the title slide and you also see that i'm now at sona source so if you've seen some of my previous talks i've now moved on from jetbrains but we could talk about that afterwards so if you want let's think this talk's not going to be about that what is this talk about well that's interesting so if you've seen my talks before you know i've done quite a lot of them probably too many and i was actually i keep track of them on my website and i was having a look at them just recently since 2015 when i started doing more right are you keeping track yeah i've done about 115 talks that is way too many but as i was looking through i realized there were a number of common themes that i tend to talk about a lot either single talks on the same subject or multiple talks then those themes are well testing perhaps comes naturally given my involvement with catch functional programming techniques that my longest run of talks was on functional c plus plus for fun and profit but i've done a few other talks in that same german area as well a couple of big talks on error handling and one on simplicity only one on solidity but that's what turns out to have been one that i sort of mined for material for other talks probably more than any other and this one is going to be no exception we will dig into that but even amongst those four common themes or four themes i found that there's actually a common thread and that common thread is software quality so this talk is really going to be taking that step back and having a look at software quality in general and to do that we first need to actually ask what it is what is software quality and it turns out to be quite a hard question to to answer now there's a blog post that i follow from time to time the shape of code derek jones who is actually the author of author of a book on evidence-based software engineering yeah interesting guy too to follow and he did a post just earlier this year back in march i think the aura of software quality and it's an interesting post but towards the end i think he really starts to show what he thinks of equality at least as an expression particularly like this quote people in industry are very interested in software quality and sometimes they have the confusing experience of talking to me about it i like to turn a phrase but a little bit later in the same paragraph it gets right to what he really how he really feels software quality is a meaningless marketing term so yeah he doesn't think much of it not that he doesn't think much of software equality in general just people talking about it his main point is that everyone has their own definition and yeah talking about it becomes meaningless because we're not talking about the same thing and yeah we've seen this problem before i'm sure you know you remember this cartoon the only valid measurement of code quality wtfs per minute and the reason that we relate to this the reason it's funny is because it sort of gets to the heart of the matter you know people know what good quality software looks like when they see it but actually defining it up front what it really is yeah everyone has their own definitions they may not agree but they know it when they see it and that's a common experience not just in in software equality just equality in general in fact that ties back to to this book so many of you probably recognized my title for this talk as being a play on on the title of this book well-known book now zen in the art of motorcycle maintenance interesting particularly because it's not really about zen or motorcycle maintenance although both do make an appearance in it subtitle and inquiry into values this is really about philosophy or metaphysics if you like it's a great book if you haven't read it i do encourage you to do so just for the experiment of it and a big part of the book is trying to define quality quality in general not software quality and it turns out to have exactly the same problem in fact eventually concludes oh actually because quite early on that quality is undefinable it's not that it's hard to define you can't define it but it does have this property of you know it when you see it so what he does instead is he he cuts it as he says or splits it into what he calls classical quality and romantic equality where classical quality is the sort of the engineering aspect of you know how things work which is how he sort of comes into the story versus the the romantic quality of you know how things look or how they're used for the design the aesthetics and that sort of thing which is an interesting way of breaking things down and his conclusion is actually you need both sides for a really sort of universal understanding of quality it's both now this book's quite well known the the follow-up book liver is less well-known but i think maybe even the more interesting book so if you've just read the first one read the second one as well and there he actually splits it further into static quality and dynamic quality where static quality is or rather dynamic quality first of all is that sort of in the moment as things happen and he uses the example of hearing a new song for the first time and your first experience of it but this static quality is something that well you know it's good but you're used to it now you've heard it many times for example and you start to have a different relationship with things that have static quality versus that sort of leading age of reality that dynamic quality gives you so we're getting a little bit off topic the point is there are different ways to divide things up that actually give you things that you can actually reason about more even though the fundamental aspect of quality is inherently undefinable now thinking back to derek jones's blog where he said that everyone has their own idea of what software quality is if you go to the the wikipedia page on software quality you'll find many definitions i've just pulled a few of them out here and most of the ones that you'll find on this page really relate to what i think of as like the external qualities of a software project as in the how it relates to the end user how it relates to what the system was actually meant to do in the first place in fact a lot of these quotes are from systems theorists and i particularly like the the quote from jerry weinberg at the end that quality is value to some person so so typically broad that you know as long as there is a value to some person that there is inherent quality in this software project but yeah it does have this problem of many different definitions so maybe we just need a standard a way to define right this is what software quality is and we're all going to agree to it and there has been an attempt to do this we have the consortium for information and software quality and like with piersic it sort of splits it cuts it into a number of different things but the the bit that we will probably relate to the most is what actually calls structural quality so so structural quality refers to the software's security reliability performance efficiency and maintainability okay now there's a list of things we can get active into that let's actually put it up there as a list this is a good starting point so this is the cisq's definition of software quality at least what it calls structural quality now before i came across this page i'd actually put together my own list and the core of it actually lines up fairly well maybe the first two are a little bit more donation so security and correctness so not the same thing even if there's a big overlap and i'm not really an expert on software security so i'm going to focus just on on correctness as in low defect rates being bug-free free of logic errors that sort of thing reliability pretty much the same on that cisq has performance efficiency amusingly i had performance slash efficiency because we're talking about slightly different but related things but definitely corresponds there and then maintainability i had mainly ability or evolvability now mine are the more hard to pronounce terms but we're just talking about how easy things are to to change over time without introducing new bugs so i think that corresponds pretty well as well now i add one more to this along these lines which i call reasonability the ability to reason about your code we sometimes talk about readability how easy it is to read the code and this is a related maybe even like a subset of reasonability i think reasonability is a bit more than just readability because it's it encompasses the whole of your code and how you can reason about parts of it in isolation from the rest so i'll go with reasonability and then just add one more to the list it's the one that the the systems theorists had on that wikipedia page the clickability how your software actually applies to the problem at hand how well it actually matches the requirements if you like or even how well the requirements match what it's actually used for that's clearly important but it's also so qualitatively different from the other aspects which is why the cisq separate the others out as structural quality it does talk about applicability as well of course but now i think we have a reasonably complete set of sub qualities if you like we can we can stack those up we'll go with my list because i think they correspond well enough now once you've got a list of things it's very tempting and i'm no stranger to this to take their initial letters see if they can make an acronym out of them so i had to go over this unfortunately best i could come up with was mr crap which wasn't particularly compelling so i thought i could do better than that and fortunately because i do have those a couple of alternates there many ability and evolvability performance and efficiency i thought well what if i just go with the second of those two terms we've got a couple of these there that's a bit more promising shuffle those about a bit and you get career okay well that's a career move i hadn't anticipated i haven't really thought of myself as a career programmer before but maybe it's not too late to start so okay a little aside we don't need an acronym for this but it can help you to to keep these things in mind if that helps great point is we have this list of sub qualities that we divided the overall umbrella of software quality up into now we can look at these individually and see well how do we measure up now that would be my traditional talk to go through these one by one and have a look at them all i'm not going to do that at least not as such see i'm more interested in the bits in between the intersections where these things meet where they conflict whether trade-offs or whether they work well together and sometimes you can turn one of those things into the other that's really what this talk is about those intersections so what i'm going to do is actually look at a few intersecting properties and see where we go with them so to give you an idea we're going to start with applicability and correctness and intersection of those now we might think of these as applicability doing the right thing whereas correctness is doing the thing right this might sound familiar in fact we often hear about it being more important to do the right thing first and then maybe doing that thing writer later we can trace that back to another systems theorist russell ekkoff who is often quoted here saying it's better to do the right thing wrong than the wrong thing right and there's a slightly longer version of that quote that gives a little bit of explanation to that the writer we do the wrong thing the wrong will we become and when we make a mistake doing the wrong thing and correct it we become wronger but when we make a mistake doing the right thing and correct it we become writer therefore it's better to do the right thing wrong than the wrong thing right so that sort of makes sense so yeah if you're very effective at doing the wrong thing you're going to be going further down the wrong path and it's harder to turn back but we often hear that but there's a bit of a problem with this point of view and i think it's really highlighted if you continue on reading from from the same quote this is the bit we don't normally hear about it says this is very significant because almost every problem confronting our society is a result of the fact that our public policy makers are doing the wrong things and are trying to do them right so yeah society public policy makers maybe this isn't the framing that we're normally thinking of when we read these quotes yeah he's talking about societal level things let's say his assistant fear is not a software engineer so trying to apply this thinking to our software quality may not be the best fit doesn't mean it doesn't apply but this idea of well if i'm very effective at doing the wrong thing it's harder to change but there may be some some problems with that and this was the topic of a talk by ellen kelly a few years ago do it right and then do the right thing now if you look at that carefully see that's a reversal of what akov was saying do it right and then do the right thing and alan's main takeaway from this was that actually knowing what the right thing is is often hard to do until you actually start doing it so you have to start doing something and iterate rapidly to to get to the right thing but there's another part to it as well and he has a whole slide which i'll reproduce here that he calls the alignment trap i've got this nice quad diagram that he pulls out of the study and it's talking about businesses companies particularly in terms of their approach to i.t so this is depictable and clearly that the best quadrant that you want to be in is that top right yellow quadrant the i.t enabled growth they're more effective and they're highly aligned so alignment here means aligned with the business needs so doing the right thing so if you're doing the right thing effectively that's clearly where you want to be and it breaks it down into it spending and sales sells growth so yeah that all makes sense very few companies are there that bottom left quadrant the maintenance zone obviously the worst place to be is where most companies are most businesses are there so they've got low i.t spending sorry average i.t spending and low growth the more interesting quadrants so are the other two so we've got the the top left blue alignment trap quadrant so this is really sort of across recommendation do the right thing before doing a thing right here's class of the trap you've got high spending and low sales growth and it's actually hard to move out of that zone whereas the the bottom right green quadrant well with iot you've got low spending and high sales growth so you're already in a much better position than the lineup trap and alan argues it's easier to move from there into the yellow zone because you're already effective at doing things all you need to do is just be effective doing more of the right thing so that's alan's argument in the talk that interests you at all i do recommend that you you dig that up and go watch it or i should mention a lot of things that i'm going to refer to here including my own talks there will be a single link at the end where you can go and get all of the references so you don't need to note these down so yeah do do watch that talk this is very interesting spends a whole talk talking about that i'm just going to summarize it here just one more slide from his talk i like this one we're used to saying in a ready aim fire but he says no ready fire fire fire their name and then fire the idea be here being yeah take a few shots to see where you are and see where you need to go and how you need to get there it's that rapid iteration with feedback this is the key here and then once you once you're locked in then you can just keep keep shooting at the target again watch the talk very interesting okay so correctness and applicability there may be a slightly different view there than we used to what else can we look at correctness and reliability this is an interesting one in fact this is probably going to be the bigger section of this talk right remember correctness is in this case about low defect rates using best practice bug free reliability it's actually more about handling unexpected cases so error handling in particular or just good code coverage in general so let's start with with code coverage in fact if you've used code coverage tools you know they usually come in line or statement coverage versions there's slight differences between what those really mean but they're basically basically the same thing so yeah a statement maybe you made more than one statement online or more than one line per statement but to a first approximation we're talking about the same thing now with the coverage you're usually talking about what's covered by your tests so if you have good code-based tests you should have good coverage in fact if you're doing pure tdd you're doing it properly you should automatically end up with 100 code coverage and you can use the code coverage tool to verify that but if you're doing pdb it's almost not worth even using a code coverage tool because well you should be 100 anyway at least close to it and that means you've got no bugs doesn't it well clearly not so line of statement coverage is not going to get you all the way there because you can have every line covered by tests but it doesn't mean that all the possible values passing through those lines and the different paths to get there are all covered should have put this bit up so yeah line of statement coverage is typically driven for unit testing cdd should get 100 of the way there but what we're talking about now i'm going to call data coverage and data coverage what broad line is statement coverage we've got tools that do that fairly easily data coverage for first approximation is basically impossible so what can we do we can't necessarily measure it effectively but we can do more to drive up our data coverage so i mentioned a moment ago that yeah tdd will should get you to 100 line coverage automatically but then it sort of you know saturates out at that point and you get to this point if you're doing cdd this is something that i talk about in my tdd training class where you sort of written all the tests that test the things that you you know about and just writing more tests you're just testing more of the same and it you get this awkward part where you're thinking well you know maybe i forgot about this maybe i forgot about that you're starting to try to probe the unknown and those sort of example based tests that we'll write in the context of tdd are not a good way to do that particularly when you may have often like billions of possibilities yeah trying to think of those examples out of thin air it's not a good way to do it so boy is to use a technique called property based testing now it requires slightly different sort of shift in thinking in how you test you're still testing at basically the unit test level so testing against your own code directly but rather than giving specific examples you're saying what property will hold or what properties hold for all possible values that i can make this call with for example then you can actually get the framework to generate values for you usually randomly there may be some ways to to put in a few sort of known problematic values like you know zeros and other boundary conditions but usually we're talking about random selection because they're now trying to probe for those things we didn't think of to generate those values you make a call you say these properties should always hold and a slightly weaker version is we can say well you can carve the domain up a bit and say but it always holds in these conditions but the best properties the ones that always hold and at first it can actually be quite challenging to think of those properties but with a bit of practice you'll start to just get into the that mindset of teasing out the properties and you'll be able to reason about your code better as a result thinking about properties it should always hold now a related discipline is false testing it's usually a bit higher level often more sort of end-to-end and much more trying to stress test as well rather than just simple random values but a very similar principle so particularly useful if you're trying to address just the the security of your code as well so going back to the cisq qualities and don't forget manual testing manual testing is another great application of testing here because you're relying on a tester who is just perhaps mentally tuned or at least through practice to have that mindset trying to break things so you as an engineer may be trying to build things up and they're trying to break it down they're going to think of things that you didn't think of and they're very good at it so if you have access to manual testers don't get them executing predefined scripts that's what automated testing for not getting doing this this exploratory probing work you can't really beat that between those three things you can get a long way towards making sure that your your code is very reliable and the correctness applies not just to to the happy path so okay so in summary line of statement coverage that you can use tools for well tdd can get you pretty pretty much 100 of the way there whereas data or path coverage techniques like property based testing does testing the manual testing are really where it's at but i mentioned aeropaths i think this deserves its own special treatment partly because error paths are often hidden particularly thinking about exceptions in c plus plus at least so our code coverage tools depending on which tool you're using they they may or may not show you exception plans as well so they may not even show up in your coverage statistics but the other thing about error parts is there's two very different types one is what i tend to call io errors sometimes called disappointments these are things that you don't usually want to think about it's like well i wanted to do this i couldn't for some reason it's something that it's not a bug it's a runtime condition you can maybe use control flow around it you may use exceptions for this but yeah you should be writing the code to handle it but it's not really what you wanted first what we call logic errors aka bugs and this is more the domain of contracts i need this in the more general term so not specific to what nearly went into c plus 20 and maybe probably won't go into 23. so contracts in general involve preconditions post conditions and variants but we can get most of the way there or a long way there just the old assert statement or use the third party library that maybe gets you a bit further the key though is to say well if if you violate one of these contracts or one of these asserts that's a bug this is a situation we shouldn't have expected to be in that's the logic error so usually the best approach here is to abort ideally with some message it's going to tell you what happened now we'll often talk about this in two plus plus world as being two different things it's not the case in most other languages most other languages tend to conflate these and you know you have to get things like stack over for exceptions it's a classic one or no pointer the reference exceptions exceptions are not a good mechanism for for handling those although safety critical systems may be a special case there there is a case for trying to carry in as best you can despite the presence of bugs all right let's drill into this a little bit more and look at some of the ways that we can handle disappointments so let's take this example of simple function to convert a string to an integer don't worry too much about the implementation just using a string string because it should be something that everyone should understand if you're doing this for real there's better ways to do it in fact there's standard library because it is now if you want to do this if you passed it a string that doesn't contain an integer what do you expect this to do well when i ran this i got a zero and my reading of the standard is that should be guaranteed i could be 100 sure because it's actually quite difficult to go through the different layers of meaning but my interpretation is we start off accumulating our our integer with a zero and we stop the first non-numeric character because there are none we're not going to zero but that's not a good situation now we can't distinguish between a string that has a zero in it and no no numbers in there at all probably not what we wanted what we wanted to do was some way convey that error so we can test the stream and one thing we might do is throw an exception that involves not having to change the signature that may not be what we want to do in this case though so exceptions can be used for handling disappointments but they're they're all for the those exceptional disappointments the very rare cases because the there's an overhead to exceptions that we don't necessarily want to pay in this case we probably want something a little bit lighter weight so a good candidate could be an optional i'm sure we're all familiar with using optionals now so won't believe it too much but rather than returning an integer will return an optional integer if we don't have a value we return null optional and in usage we can treat the optional as if it's a pointer point to semantics we can test it against the explicit boolean operator and dereference it in the case that we have a value simply enough we know how this all works but there's still a problem here because yeah while we did test that we did test it before dereferencing it we're not forced to test before we do reference we can do reference without testing and if we do that's undefined behavior and that's not a situation we really want to expose ourselves to now coming in c plus plus 23 are the the so-called magnetic operations on instead optional map bind and or else and basically that just means we do the same thing using these lambdas we could pass to map and now you see the map function its method itself we'll do the test and do the deer reference and pass it to referenced value we don't have to de-reference that option ourselves if we've got a value we know it was valid otherwise it's going to filter down to the or else which you can consider a bit like the catch you know an exception block as well and then we don't have any value we can't accidentally dereference the value that we never had so this is a safer way to do it it might look unfamiliar and and so a little bit scary or a bit too much syntax there but it actually compares pretty well go back there it's i think it's actually clearer once you get used to it that's coming at 23. look out for that it's not the only way that we can deal with these we talked about exceptions we can have good old error codes but if you do use error codes please use them with no discard we may still have to deal with code that was written before we had no discard but we have it now there's no excuse that was one way that we could end up ignoring an error situation it's good optional we've mentioned if you do if you are going to use error codes rather than just using raw enums do consider using stood error code we've had it since c plus plus 11. that's very underused but i do look into it i'm not going to go into that in much depth now there's also boost outcome boost outcome is sort of like the halfway house between exceptions and error codes or something more like stood expected which should also mention also coming in 23 stood expected if you don't know it's it's like an extension to stood optional where in the case that you don't have the value you can have another type that tells you why you didn't have the value so it's more like a union type but specific to error handling possibly when they go down down the road of static exceptions that's a p0709 got a bit off track the last year or so but i don't think it's completely dead at the very least it's going to shake up what we do with exceptions so it's definitely still a hot space error handling lots of different options if you pardon the pun so i've done a couple of talks on the subject so do watch those for more depth okay so we talked about i o errors and disappointments i mentioned logic errors and contracts as well i'm going to dig into that a bit too so or should also know don't know if it was really obvious but you said the bubble is up in the top right corner we've been talking about reliability and correctness but now we're getting free bubbles get efficiency in there as well we'll see how that comes out so let's have a look at an example different example this time another simple one function to convert a month number to a string so presumably that month number must be between 1 and 12 maybe 0 and 11 that should be documented somewhere but by the way we can look at this function as saying well that integer that month integers have a range of between like minus 2 billion and positive 2 billion pretty big range but in the context of this function it has a domain of valid values between well let's say 1 and 12. that's a pretty big difference between the range of the integer and the domain of this argument when you have that difference between a parameter's range and its domain that's when effectively you have a contract whether you split out as such or not so how do we deal with that how do we deal with the case where you pass a value that's not within the valid domain of an argument what one thing we could do is just what we were talking about before maybe throw an exception do a check for an exception put a bit of information in there all sounds good and in most other languages we would probably stop there but say plus plus we like to embrace undefined behavior and with good reason so what do we do instead until we get contracts we might do an asset and let's say that there may be third-party third-party libraries to achieve something in between but what we're saying here is well i'm going to assume that you're only ever going to pass me my valid month number but just in case you don't in a debug build whatever that means i will test it and terminate if it fails but we know how a cert works but that means that in a in a release build it's not going to be checked if you pass a value that's not a valid month from that point you're an undefined behavior because the code has been written to assume at least from a programmer's level that that month is always valid and one of the reasons that we had trouble getting contracts into the language was that that that word assume may actually become something the compiler can rely on as well but we won't get off track okay why would we do this rather than throwing the exception well for one thing if we know we have a valid month why do we want to pay for that check that's where the efficiency part comes in we want to not pay for things that we don't use that's that's what c plus plus is all about there's another another argument that says this can actually hide bugs because you do pass about an invalid month and we throw an exception that exception may not show up in a way that you as a developer would immediately see depending on how it's handled so this pretty much puts it in your face and forces you to deal with it at least in development okay now that that means that the onus is on the cooler to pre-validate mumps so if you're getting that value from somewhere else let's say it's been fed in from my own well you want to do that check outside of this call and that means you've got to duplicate the implementation part of the implementation of this function or an implementation assumption outside of it that seems like a recipe for disaster especially considering we're opening ourselves up to undefined behavior here so what we could do of course is factor that checking code out let's call it is valid month now we can call that from within our assert and we can call it outside in our calling code if we are we have an untrusted value and we want to validate that so well that seems better but a bit like the this adoption we looked at earlier now we have to remember to make that call before we call the the month of string function so it's still a bit of a problem can we do something similar to what we did with optional and push that combining the check with the call into one place well we could just write simple wrapper function so now we can have monthly string checked which does the check and then makes the call and in the case that we file the test now we could use exceptions or error codes or stood expected or whatever disappointment mechanism we want to use only on the checks path now depending on how this is used you may prefer to do that the way around we could spell the contract-based version unchecked and have the default if you like the shorter name for the checked one there are different scores of fault on this i tend to lean slightly more towards this in most cases but it does depend on your exact use case but is this really a problem in the language if we look on wikipedia for ada one of the examples it could say is of a date class that is built up of bounded integers so we actually have a month type there it's defined in the language gives you the mechanism to say this is in the range of one to twelve and that means if you passed a month you know that it's always going to be valid and we don't have that in that language in c plus plus but of course we can approximate it so we could do something like build our own month class now we could do this with the bounded integers library that may be a good good approach as well but we can also do it in a slightly more custom way we'll stick with that for the moment so now our month constructor you might want to do something slightly more sophisticated than this but just to keep it all in the slide in the constructor we'll do our is valid month check through the exception so it's exception based here but from that point on or and i should say now we can change our month for string function to take a month instead of an integer now month for string doesn't need to do any checking because it knows it's always got a valid month but if we pass an invalid month to our month constructor that's going to throw an exception what if we still have an integer that we know is a valid month at that point we can't write a separately named constructor so we can use a technique like use a attack type so just an empty type i call it unchecked tag here that's only used just to overload the constructor and now we can we can call those two constructors either the default one which throws an exception or the one with the unchecked tag that does an assertion so we have the same same capability now here i definitely lean more strongly towards making the the throwing the constructor the default one and the unchecked one the one you have to opt into because now what we've effectively done here by introducing this corrects by construction type is we're pushed that checking as close to our boundary with our untrusted data as we can so the moment we're getting something saved from io we put it into a month and it gets checked there and then the few places left where we actually need to construct a month with an integer that we know is going to be a valid month well then i think it's worth putting that clearly in the code with the unchecked tag now you may still disagree and do it the other way around that's not the main point of this the main point is using the type system to reduce the places that we have to to check things and reduce the the scope for undefined behavior accidentally creeping in so we can get that perfect trifecta of reliability correctness and efficiency let's go back to our list i think we are getting ripped shorter of time than i'd hoped for i want to talk about reasonability and evolvability evolvability remember being how easy things are to change and reasonability how easy they are to reason about and mostly i think of this as being about simplicity remember i've done a talk on that but that usually apply implies in code of functional programming techniques particularly use of immutability and correct by construction techniques like we just talked about with month so usually not limited to that but now you can see how those talks are connected as well but the core of my simplicity talk i actually borrowed from talked by rich hickey simple made easy and also borrowed these illustrations from him because he define goes back to the the latin definitions of the word complex and simplex a complex is something with many folds or braids whereas a simplex whether we get the english word simple is one fold or braid and i think the illustrations really bear that out but something that is complex it has the things that are crossing over it's maybe the same number of things if you look at the illustration on the left hand side the same number of strands there but it's the crossing over that's different now as a consequence if you look at take one of those strands from the bottom on the left hand side and follow it all the way to the top in that simple case no problem at all it's trivial on the left right hand side if you want to follow one of those strengths at the top you've got to carefully follow all the way around to see where it comes up and there's only four things there and that's really the crux of this it doesn't take many things crossing over for your ability to trivially reason about them to just almost disappear so getting rid of the necessary complexity is really key in our ability to be able to reason about code what are the main sources of complexity in our code now we've got that definition to work with so this is the list i came up with and i've actually been updating this list over time because every time i give a tpb call so i ask the same question and we with the whiteboard session and put down any suggestions that people come up with and the last time i did this somebody mentioned templates as well and there may be something in that but forgot the obvious ones like threading and concurrency globals and singletons singleton's really just being a design patterned global as well as other types of shared state so even the shared pointer can give you extra complexity mutability is the interesting one and that's where it ties into the functional techniques because mutability is really it's got the crossing over that complexing as rich hickey likes to call it of value and the passage of time because at different points in time it may have a different value the only way you can reason about the value is by following it through the whole path through your code that's why mutability is such a complexity adding thing cyclomatic complexity but it's got complexity in the name but it's it's specific to control flow if statements for loops that sort of thing all these things of course are necessary but they can add complexity unnecessarily if you use them whether they're not needed so minimizing them as much as possible is really the key also did leaky obstructions again abstractions are really important but they're also leaky i go into exactly why in my simplicity talk so be careful with your abstractions use them appropriately code and module dependencies as well very similar to what we said about with the globals and singletons the more things are interrelated just the harder it is to reason about so it turns out that if you have lower complexity not only is your code easier to reason about as well as we've said but it's also easier to test and easier to change and those three things really go hand in hand or hand in hand in hand because again tying this back to tdd one of the reasons that tdd works well if you're using it appropriately is your tests will tell you when something is hard to change because you've got unnecessary complexity in there and that forces you to then think how can i lower that complexity i can read it about it more clearly and now i can test it and you're able to change it in order to do that those three things always seem to come together so my magic formula for lowering complexity is combination of test driven development and functional programming for me that's the single biggest combination that that makes this work let's get to i think it's not even the last pairing but reasonability and efficiency i try and position with this one so we have high level code and we have a low level machine and we may be happy to say this with high level code and many languages are happy to do that but then we leave efficiency on the table so systems languages came in to try to bridge that gap give you just enough high level abstractions while still exposing how the machine works works the trouble is that machine that particularly languages like c and therefore c plus plus were sort of originally designed around it's basically the pdp 11. now if you've never seen a pdp-11 here's one in fact the main computer is sort of just in that middle middle bit but you typically have these things in big cabinets with tape machines and so on yeah they came out in the 70s and although modern processors particularly on the intel line are sort of loosely inspired by the pdp11 in terms of how processors optimize things now we are so far removed from the pdp 11 days that most of the low level assumptions that you could make in c back in the day just literally don't apply anymore are there often pessimisations so using low level coding techniques for optimization is i wouldn't say it's impossible but it's very rarely a win unless you really really know what you're doing so how do we bridge this gap well one of the things we can do is working on the reasonability side of things if we make our code easy to reason about particularly using techniques that reduce the the complexity we're also making it easier to reason about by the compiler the compiler can then do that optimization much more effectively for us most of the time there will still be times that we'll have to optimize further if we really need to but that's when we we start measuring and then we take those extra steps if we need to but here's an example that i used in my function of c plus plus talk so we have some code that wants to initialize this enum variable but it needs to call another function in order to know how to initialize it so one way you can do it is have an uninitialized declaration up front make the call and then we have an assignment statement to actually set it simple enough but there's a number of problems with this even in such a few short lines of code one we have the uninitialized variable we don't like those but initializing it to some value that we don't want or might not want doesn't seem to be the right way to go either we also can't make that variable const because we need to assign to it and that means we can't reason about that value now without looking through all of the code that it might pass through remember i said immutability really is a key part of reasonability and we've had to use side effects within the the curly brackets there both those statements are always side effects now of course in surplus plus we have an easy solution for this we can just use the ternary operator and that does exactly what we want we can make our variable const we can initialize it right up front and as a bonus we can use type inference great there's a couple of problems with that though i mean i am actually quite comfortable using ternary operators you do have to be careful about precedence that's not always quite as intuitive as other things so if you're careful with that you don't overuse it it could be fine the bigger problem is it doesn't really scale so look at another example now we've got a switch statement we've got more than two states we can't use the ternary operator so we're back to animationalize variable and side effects and it's messy code but there's a technique that we can use that effectively fakes converting this into an expression and that's to move it into an immediately invoked lambda expression so wrap the whole thing in a lambda which we immediately invoke at the end you can see the empty parentheses at the end there and now we get back all of those benefits that we saw before it's const we use type inference there's no side effects technically there are but they're pretty much invisible to us because there's still a return statement in there but we don't see the effect of that and it's actually even less code as well if we compare that to that i think this is clearer so definitely easier to reason about even though we've got the extra syntax of the lambda expression in there now when i talked about this in my functional c plus plus talk i also said that in this case it should compile down to basically the same code and i even showed some decompiled assembler to to prove the point i said that with a more expensive to construct type rather than an enum it may actually be cheaper to do it this way because we don't have have to initialize to one state and then assign to another so i did do a little experiment with a more expensive to construct type this one just copies characters in to a vector and then we construct our expensive type like so if we convert that to the version using the so that is the converted version yes so that should avoid having to construct our expensive objects more than once should construct it in place my extra slide was they can even shorten it further using the an explicit return type for the lander the last time i gave voting this talk i did show a godbolt link that showed that this generated less statements less assembler than the previous version just before going live i discovered there was a problem with it and i wasn't doing exactly what i had intended to do so i've got to pull that bit out i'll fix that up but it should be fairly obvious why this should be more efficient and of course as i said it doesn't always mean that code that's more readable is also more efficient but it's a great starting point so i think we shouldn't lose sight of that now back to testing again we're still talking about reasonability and efficiency and specifically property-based testing comes into this again so we mentioned property-based testing before we can actually use property-based testing not with true properties but let's say you have a an algorithm you've got a slow but easy to reason about version of this algorithm it's trivial to look at and say yeah i can see why that works and then you have this highly optimized version that should give you the same result but just in a much harder to reason about weight now you can actually use property-based testing to test your fast but tricky version in terms of the slow but easy version and you know depending on what it's doing you may need some tolerances in there but you can usually get this to work so now you are getting the benefits of reasonability in the sony easy one but the efficiency of the highly optimized version so even if you do have to resort to low-level tricks you can still intersect these properties okay we're getting towards the end but i'm running very short of time to sum up we looked at these six properties but we looked at all the all of these intersections so quite a few there that gets quite crowded we can link these up actually so we've got the correctness here we can we can join these bubbles up we can move this one in and in fact if we're willing to just let go of that reliability and reasonability link we actually get quite a nice cascade there we used a few different approaches and tools to to help us with all of these and you can see how much coverage we have of all of those properties just between a good use of the type system paying attention to error handling and using different types of tests for me these three things between them are what give us the best coverage of all of those software quality properties there's one other thing that i want to bring in here which touches on pretty much all of those and helps of all of those in almost all of the examples that we looked at and that's static analysis now just so happens i now work for a company that specializes in static analysis but i start a coincidence my interest in this is what led me there rather than the way around so i wanted to bring it up as well i'm not going to talk too much about it right now but if you're not already using a static analysis tool and this applies to dynamic analysis as well then you really should consider doing that as a part of your approach to software quality so i think again i'll have to skip over the bit that i want to talk about from michael feathers where he's in summary he talks about all these different techniques really boiling down to thinking about code look at your code and and reasoning about it no matter what technique you're using that's always at the core of it which leads back nicely to zen so that we weren't going to talk about then but actually the original definition of zen was meditation and on the wikipedia page for meditation it says it's focusing the mind on a particular object's thought or activity to train attention and awareness and achieve a mentally clear and stable state so if paying attention to your code is meditating on it then i think zen and the art of code life or life cycle maintenance is an appropriate title so that is the end there's the link to all of the references that i mentioned on my website neverlivingdirection.com refs slash zen.html i'm slightly over time so i imagine we should take q a outside thanks thanks phil for the great session thanks a lot i think we don't have any questions yet but let's wait for a few seconds otherwise i think we can move to the lounge you have a table for you dedicated for the follow-up okay and so folks if you have any questions please use the q a tab and phil can can answer apparently we don't have any we are perfectly on time field so great job and okay thanks a lot phil for the session thanks all the folks for coming and now i shut down the stream see you in the lounge and cheers thank you see you there bye see you there