let's start about talking about convolutional newal networks again a few people have been asking what do the convolutional layers look like so you know what transformations are happening on these input images that mean we can do something interesting in terms of machine learning so what i've done is i've trained up a pretty basic network to do digit recognition and so we can see what the convolutions are doing what the intermediate layers look like and then hopefully what the classification is at the end so people can get a good idea let's start talking about mnist so mist is a data set that was that's been around for a few years and was produced by yan lun who is i think currently at facebook and is big in deep learning and loads of good papers and one of his early efforts into convolutional networks was lenet is or what we call it which was a sort of five layish small convolutional neural network aimed at doing this nness data set and it basically said look this convolutional neural network is going to be really good on digit recognition the current state of the art is all these machine learning techniques and now we're even better than that so what i've done is i've tweaked the lenet model a bit just to make it a little bit more interesting and then i've basically printed out all the intermediate layers so we can see them on a few digits so you can see how it works so this is numbers when you say digits l that's right just for digits not to n in in fact it's it's small 28 pixel by 20 28 pixel images of any handwritten digits not to n9 and there's about i think 990,000 or so in the dat data set so there's about 10,000 for testing and about 880,000 for training the normal lenet network is i think a convolutional layer followed by a pooling sort of spatial down sampling layer followed by another convolution followed by another spatial downsampling and all this kind of thing now the thing about spatial down sampling is it's useful in some situations but it's not very interesting to look at because we're then looking at images that are just really really small so what i've done is i've done away with that and i've just put in loads more convolutional layers so my network is i think if i refer back to my 1 two 3 four five six is six convolutional layers apparently according to my piece of paper and then two fully connected artificial neural network layers at the end so i'm just going to write these down so we've got one two 3 four five six convolutional layers all of which have 5x five cur so this isn't the standard network this is just one i came up with myself on this digit recognition task any reasonable network will probably do a pretty good job you know if you thought a little bit about it because it's just not you know digit recognition is not quite as hard as character recognition which in turn is not as hard as other problems and so on is that just purely because there are less digits than characters there's less there's basically less variation between images if you're if you're taking lots of pictures of cats and lots of pictures of dogs there's going to be more variation over the image and more pixels to deal deal with than there is in a 28x 28 picture it may have a nine in it or it may have a slightly different shaped nine you know and then i've got my fully connected layer so i'm going to say fc1 and then i've got a fully connected layer here fc2 fc1 has an output size of 500 according to my piece of paper i've forgotten already and fc2 has an output size of 10 which is the digits right so if you think back to our last video on convolutional networks after we've done all our convolutions we have some fully connected layers which actually perform the classification and the last fully connected layer in this case is going to be however long we have different classes so we have 10 classes zero to all the way to nine so 10 outputs and when output number two lights up or produces a high value that means that digit one which is slightly confusing because it's zero index but digit one has been recognized okay so i won't go into too much detail about what effect each of these will have on the input image but you can imagine that if you've got a 28x 28 image input then this first convolutional layer which is 5x5 is going to reduce the width of that and the height of that image by four because you know it's not going to go right to the edges and we're not doing any padding so you're going to then have a 24x 24 image and then the next layer will take it down to 20x 20 and the next layer will take it down further than that so let's talk about how many feet how many different kernels i have at each of these layers so the first layers i've got 20 different kernels per layer and then if i refer back to my model file is that the code for it's actually a text document in cafe because this is the library i've been using to do this which basically explains is where you detail with what size of kernels how many kernels how many layers you have which ones connect to which other ones and so on okay this is obviously slightly different to the stock mist model file but it's you know similar stuff okay so for example if we pick a layer at random can you see this layer here so we've got 20 outputs kernel size of five a stride of one and this tells you how you're going to randomize your weight when you begin training okay so we just describe all of these things to the network and it goes off and does most of the work for us so my first two layers of 20 kernels then because i decided this was a good idea i increase this number to 50 kernels and 50 kernels and i have four 50 kernels you can imagine that your input image to begin with is 28 by 28 and it's one deep because we have a grayscale image these are grayscale digits we're looking at here after the first 5x5 convolution this image is going to shrink to 24x 24 but because there's 20 different kernels all producing their own image output it's going to be 24x 24 by 20 and so on okay i won't draw the whole thing out because we've done that in the last video but these convolutions here because i'm not using any padding will slowly decrease the size of the image and when it gets to this point here at the first fully connected layer the image should be 4x4 by 50 deep which is 800 different values now often we would go right down to 11 one but that is not really necessary in this case cuz it's not too much data so this first fully connected layer is 500 neurons long all of which connect to all of the different poss possible 800 values and then the final 10 come from this 500 so let's look at some pictures and then maybe this will be more clear okay it's not a very complicated network modern networks get much bigger than this but this shows you the kind of thing that they're doing so i've printed out some examples of the kind of things that these networks will do so let's just use number two as an example this is a picture of a two right it's very exciting for everyone watching it's a 28x 28 picture of a two which has been normalized so but it's it's the background is basically black and the foreground is white okay you get slightly better results if you normalize because if they've pressed lightly with their pen and maybe not done a very firm two then maybe you sort of increase the contrast a little bit so we're first going to do a 5x5 convolution over this and we're going to do 20 of those so unsurprisingly if if i move this away we're going to see a number of kernel convolutions these are performing lowlevel image processing tasks just like the kind of sober edge detector that i talked about in previous videos so this one for example is a kind of diagonal gradient you can see that the edges for going diagonally are quite highlighted and then there's different orientations so this one's horizontal and there's a vertical one sort of here and so on we can't do a lot of interesting things with this image after just one set of convolutions but we're we're getting there so this one is starting to be transformed some of them are noisier than others that's partly due to my you know not having trained it very long and partly because maybe that's useful so we're going to do another set of convolutions on all of these inputs so these are now going to be convolutions of convolutions they starting to get a little bit smoother because we're shrinking our image down and we're slowly starting to find higher level features so now you can see that the loop in the top of the two has been highlighted here and this one has highlighted only the horizontal bit on the top of the bottom of the two if that kind of makes sense so different areas of image are now starting to be highlighted we're bringing in different information and as we keep going you can see we're going even further so we've increase the number of features and you can kind of see maybe there was used to be a two there but we've extracted away the actual two now and we're looking just at features so there's lots of diagonals here which have been highlighted and they're highlighted in very specific neurons because some of them are looking for some things and some of them are looking for other things just by looking at these pictures it's hard to know exactly what each of these is looking for because they'd be looking for something different if you had a different number in there we keep going they get smaller and smaller and they get more and more abstract so you're still seeing the tip of the two here and this is the right hand side of the image highlighted things that the computer thinks are useful to learn that tell us about what it is to be a two which is a kind of weird concept right and we keep going and the images continue to just get smaller and smaller until we get to to our final 4x4 images now i'll put a comparison of two different digits up on these in a minute but you can see that obviously we're getting very general shapes now there's no concept of the two anymore this has been completely extracted away into which of these are lit up and where and we connect that to our first fully connected layer which i've tried to print out but it's kind of odd which is just a bunch of activations spread out over these 500 not all of them are activated as you can see the white ones are very strong activations the gray ones are in the middle and the black ones are very low activations so you can see that you know these two are good so in some sense it's learned that when there's a two in the image these two are going to light up and so is this one and so on basically i've said here's a picture of a two i'd like you to output the number two and it said well okay if i make these like this then that's what works so it's just following a mathematical process so even for different images of two would that would those two things they will be yeah they will be subtly different i mean if you've got a really well trained algorithm these will start to look very similar but there's a lot of neurons here and there's only 10 classes so there's going to be more information in here in some way than you need and then at the end this is a little bit perhaps a little bit easier to understand these are our final 10 outputs these two are not real i've just they're just left in from by mistake when i've been printing so you can see 0o one two the the white one the one that's lit up is number two okay so this is essentially correctly identified a two now obviously in my program i would read this value out and do something useful with it i wouldn't just print it as a block but you get the idea okay let's have a look at two versus let's say some other number four is kind of like a two two in the sense that it has some sort of horizontal bits in it although actually that's two of any digit so really fors nothing like a two i'm talking nonsense the first layer looks much like the one from the two right because it would do because we've only done one set of convolutions and they all do much the same thing so you can see that for example in this one here you've got mostly these kind of corners here that are highlighted and that's true of the four as well as we sort of progress in i'll skip a few layers let's see if i can get the matching layer from the four you can see that some elements of the same and some are different so this one here this new one here is darker but it's got a white region that isn't in this two okay so this one's starting to pick up differences between these two images now and you know if you studied these for a while you could see there's some other differences again i'm showing you this because it's interesting to see what a convolutional neural network does but it's very difficult to look at this and go oh of course this is finding all the corners of the four here and so on you'd have to study it for quite a long time to work out what what that is there are people doing these sort of things but to be honest most people will just go oh that's you know nice and it works and that's what's important so as we progress a bit further so this is the last convolutional output before the fully connected layers now you can see that actually there are some quite big differences so this one for example is bright in the top left and dark in the top right for the four whereas it's dark in the top left and bright in the bottom right for two at this point we've now extracted away anything but said exactly what the image looked like and now we're looking just at features so these are basically things that the computer finds useful and now they're completely different and as we now look at the fully connected layers completely different neurons have been activated these two are now dark and there's some bright ones in this four that aren't in this one and so on so what it's done is it's transformed the image using the convolutional layers into something that when it gets to the fully connected layer looks different to the computer and that's really useful and then finally unsurprisingly number four is lit up right so it's successfully worked and that's basically what it looks like now obviously if you have a much deeper convolutional network with many more classes this is going to be doing lots of more hierarchical complex operations but this is basically the gist of what a convolutional network would do how long did that take for you to do that i just put oh well building the model took a few minutes and then i know to train it was a few hours because i've added a few convolutional layers it takes you know 40 minutes to train at most if you're doing the standard small network which still is 98% accurate on these on these digits and how much harder is it to do for say letters it's a bit harder because you've got 26 classes instead of or maybe for capitals as well you've got even more classes but on the other hand it's if you if you're pro if you're providing images like this which are very controlled it's not very difficult if you're producing any possible a then it's going to be more challenging but still convolutional networks can do these tasks quite easily you just have to increase the number of convolutions increase the number of kernels you have per layer just to increase the amount that it can do and then you just leave it to train a bit longer and it seems to work this i mean this seems to me that all these things we see on websites these days where it says are you a human click this button are kind of a thing of the past then are they now captures yeah so in some sense the the old capture style that we had where you would see like five or six letters and have to type them in they are defeated by convolution networks if someone has bothered to train a convolutional new network to defeat that task one important thing to remember is that i've trained this network on a very specific set of digits if i give it some kind of capture with digits in particularly if there's more than one digit per image it doesn't it's not going to understand because i've been giving it 28 by 28 images with just one digit in so to get to work on a specific capture system you're going to have to train it on that specific capture system now one of the nice things that capture systems do from the point of view of trying to crack them is generate a lot of images so you just download their api and you can just generate data set after data set so in some sense image-based captures are starting to look a bit weak on the other hand as a researcher i'm not inherently interested in breaking capture i think it's probably th quite a useful purpose so you know maybe a spammer is trying to do this so you start to look into more complex capture systems so for example google's recapture which won't necessarily provide you with numbers will ask you can you see all the biscuits in this image and you'll see a 9x9 grid of biscuits and then it's it's slightly more complicated for a bot to interact with this html and it's a slightly more complicated problem particularly if you don't know what it's going to ask until it does so i guess the idea is to keep changing your capture system with enough frequency that if anyone had trained a network to solve it it then becomes redundant and they can't solve the next one the problem is that if i obtain a cookie off you which is supposed to be secure then i can send that to let's say amazon or to a shop and say i'm sean please you know what's in his shopping basket what's his address what's his credit card details