so we're now talking about humans but if we think about building artificial intelligence systems robots do you think all the features and bugs that you have highlighted in human beings are useful for constructing ai systems so both systems are useful for perhaps while instilling in robots what is happening these days is that actually what is happening in deep learning is is more like a system one product than like a system to product i mean deep learning matches patterns and anticipate what's going to happen so it's highly predictive what's right what deep learning doesn't have and you know many people think that this is a critical it it doesn't have the ability to reason so it it does and there is no system to bear but i think very importantly it doesn't have any causality or any way to represent meaning and to represent real interaction so until that is solved the you know what can be accomplished is marvelous and very exciting but limited that's actually really nice to think of current advances in machine learning is essentially system one advances so how far can we get with just system one if we think i'm learning in artificial systems and i mean you know it's very clear that deep mind is already gone we're way beyond what people thought was possible i think i think the thing that has impressed me most about the developments in ai is the speed it's that things at least in the context of deep learning and maybe this is about to slow down but things moved a lot faster than anticipated the transition from solving solving chess to solving go was i mean that's the world rain how quickly it went the move from alphago to alpha 0 is sort of bewildering the speed at which they accomplished that now clearly they're they're eight so there are many problems that you can solve that way but there are some problems for which you needs something else something like reasoning where reasoning and also you know that one of the real mysteries psychologists there gary marcus who is also a critic of ai i mean he what he points out and i think he has the point is that humans learn quickly children don't need million examples they need two or three examples so clearly there is a fundamental difference and what enables would enable the machine to to learn quickly what you have to build into the machine because it's dear that you have to build some expectations or something in the machine to make it ready to learn quickly that's that at the moment seems to be unsolved i'm pretty sure that the mind is working on it but yeah they're if they have solved it i haven't heard yet they're trying to actually them an open air trying to start to get to use neural networks to reason so assemble knowledge of course causality is temporal causality is out of reach to most everybody you mentioned the benefits of system one is essentially that it's fast allows us to function in the world ask them skilled you know it's skill and it has a model of the world you know in a sense i mean there was the earlier phase of a i attempted to model reasoning and they were moderately successful but you know reasoning by itself doesn't get you much deep learning has been much more successful in terms of you know what they can do but now that's an interesting question whether it's approaching its limits what do you think i think absolutely so i just talked to john lagoon he mentioned you know i know him so he thinks that the limits were not going to hit the limits with you all networks that ultimately this kind of system want pattern matching will start to start to look like system two with without significant transformation of the architecture so i'm more with the with the majority of the people who think that yes you know networks will hit a limit in their capability he on the one hand i have heard him tell they missus obvious essentially that you know what they have accomplished it's not a big deal that they have just touched that basically you know they can't do unsupervised learning in in an effective way and but you're telling me that he thinks that the current within the current architecture you can do causality and reasoning so he's very much a pragmatist in a sense that saying that were very far away that they're still yeah i think there's this idea that he says is we can only see one or two mountain peaks ahead and there might be either a few more after or thousands more after yes so that kind of idea right but nevertheless it doesn't see a the final answer not fundamentally looking like one that we currently have so neural networks being a huge part that you know i mean that's very likely because because pattern matching is so much of what's going on behind you can think of neural networks as processing information sequentially yeah i mean you know there is there is an important aspect to for example you get systems that translate and they do a very good job but they really don't know what they're talking about and and and for that i'm really quite surprised for that you would need you would need an ai that has sensation an ai that is in touch with the world and soreness and maybe even something resembles consciousness kind of ideas li awareness of you know awareness of what's going on so that the the words have meaning who can get in touch with some perception or some action yeah so that's a big thing for yan and as well here first is grounding to the physical space so so that's what we're talking about the same yeah so but so how how you ground i mean the grounding without grounding then you get you get a machine that doesn't know what it's talking about because it is talking about the world ultimately the question open question is what it means to ground i mean we're very human centric in our thinking but what does it mean for a machine to understand what it means to be in this world does it need to have a body does he need to have a finiteness like we humans have all of these elements it's very nice to know i'm you know i'm not sure about having a body but having a perceptual system having a body would be very helpful to me if if you think about human mimicking human ooh but having a perception that seems to be essential so that you can build you can accumulate knowledge about the world so if you can you can imagine a human completely paralyzed and there's a lot that the human brain could learn you know with a paralyzed body so if we got a machine that could do that it would be a big deal and then the flip side of that something you see in children and something in machine learning world is called active learning maybe it is awesome is being able to play with the world how important for developing system waters or system to you think it is to play with the world be able to interact with me a lot a lot of what you learn as you learn to anticipate the outcomes of your actions i mean you can see that how babies learn it you know with their hands are they how they learn you know to connect you know the movements of their hands was something that clearly is something that happens in the brain and and and the ability of the brain to learn new patterns so you know it's the kind of thing that you get with artificial limbs that you connect it and then people learn to operate the artificial limb you know really impressively quickly at least from from what i hear so and we have a system that is ready to learn the world through action at the risk of going into way too mysterious of land what do you think it takes to build a system like that obviously we're very far from understanding how the brain works but how difficult is it to build this mind of ours you know i mean i think that yonder coons answer that we don't know how many mountains there are i think that's a very good answer i think that you know if you if you look at what cool very cool coil is saying that strikes me is of the war but but i think people are much more realistic than that were actually they missus abhi's is and yanis and so the people are actually doing the work fairly realistic i think - maybe phrase it another way from a perspective not of building it but from understanding it how complicated are human beings in in the following sense you know i work with autonomous vehicles and pedestrians so we tried to model pedestrians how difficult is it to model a human being their perception of the world the two systems they operate under sufficiently to be able to predict whether the pedestrians gonna cross the road or not and i'm fairly optimistic about that actually because what we're talking about is a huge amount of information that every vehicle has and that feeds into one system into one gigantic system and so anything that any vehicle learns becomes part of what the whole system knows and with a system multiplier like that there is a lot that you can do so human beings are very complicated but and and you know system is going to make mistakes but human makes mistakes i think that they'll be able to i think they are able to anticipate pedestrians otherwise a lot would happen they're able to you know they're able to get into a roundabout and into the end to traffic so they must know both to expect though to anticipate how people will react when they're sneaking in and there's a lot of learning that's involved in that currently the pedestrians are treated as things that cannot be hid and not treated as agents with whom you interact in a game theoretic way so i mean it's not it's a totally open problem and every time somebody tries to solve it it seems to be harder than we think and nobody's really tried to seriously solve the problem of that dance because i'm not sure if you've thought about the problem of pedestrians but you're really putting your life in the hands of the driver you know there is a dance as part of the dance that would be quite complicated but for example when i cross the street and there is vehicle approaching i look the driver in the eye and i think many people do that and you know that's a signal that that i'm sending and i would be sending that machine to an autonomous vehicle and it had better understand it because it means i'm crossing so and there's another thing you do that actually so i'll tell you what you do because we watched i've watched hundreds of hours of video on this is when you step in the street you do that before you step in the street and when you step in the street you actually look awake away yeah yeah now what what is it what the saying is mean you're trusting that the car who hasn't sloane down yet will slow down yeah and you're telling him yeah i'm committed yeah i mean this is like in a game of chicken so i'm committed and if i'm committed i'm looking away so there is you you just have to stop so the question is whether a machine that observes that needs to understand mortality here i'm not sure that it's got to understand so much it's got to anticipate so and here but you know you're surprising me because here i would think that maybe you can anticipate without understanding because i think this is clearly what's happening in playing go or in playing trace there's a lot of anticipation and there is zero understanding so i thought that you didn't need a model of the human yes and the model of the human mind to avoid hitting pedestrians but you are suggesting that i do yeah you do as and then it's then it's a lot harder so this is all you