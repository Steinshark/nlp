frames win games we proved it nvidia advertises it and now we get to double how many we get for free nvidia says yes thanks to a brand new feature exclusive to 40 series gpus called dlss 3.0 like previous generations of dlss it improves your frame rate by trading off some image quality unlike old school dlss however dlss 3.0 works not by lowering the resolution but instead by pretending it's running faster than it really is sounds like bs but i promise you it's not what does it actually do should you turn it on and can we even tell the difference i'll tell you right after i tell you about our sponsor boost mobile boost mobile provides you with unlimited data talk and text for just 25 a month all on one of america's largest 5g networks click the link below for a limited time offer [music] dlss 3.0 or more accurately deep learning frame generation which i'll call it from now on is nvidia's answer to low frame rates only officially available for nvidia's rtx 40 series gpus for now it mandates the use of nvidia's reflex low latency tech and using an optical flow model on the gpu's tensor cores inserts fake frames in between the real ones that your gpu is actually rendering literally doubling your frame rate even without upscaling that's right it can be enabled without dlss which is why i won't be calling it that this obviously makes gameplay look a lot smoother but you might be thinking back to the battle days of the 2010s when tvs would advertise 120 hertz and 240 hertz when all they really did was hold back multiple frames to blend them more or less by brute force that resulted in an often broken looking effects that added substantial input lag and was only really good for keeping track of where the puck is so you don't miss a sports ball hole in one what makes dlfg different is that it's making an educated guess at what the next frame should look like in near real time based on the previous frame and some motion vectors provided by the game engine which should look a lot better and be more responsive unfortunately dlfg isn't available in very many games right now so i'm going to pick two to closely examine starting with marvel's spider-man remastered this game looks shockingly good with dlfg and able to give us double the frame rate though there are some things to take note of first off there's a sort of forward ghosting that happens from time to time as dlfg does its thing sort of the same way dlss 2.0 is ghosting happened you don't see it often but you can see it clearly here when spider-man jumps out of his apartment window as a kind of halo thanks to the game engine's insistence that he's moving but the way the camera moves counteracts the motion vector data from the game engine in gameplay this manifests is a kind of shimmer on the walk and wall crawling animations looking almost like a lighting error and when scenes change dramatically from shot to shot you'll find yourself staring at a frame made entirely of visual artifacts something common to all games compatible with frame generation right now and nvidia says it's a bug somewhere in the chain and the flag should be getting set that disables frame generation during such transitions it'll be fixed soon the more severe but paradoxically even less noticeable artifact is the breakup of sharp shapes when in front of or behind character models as digital foundry pointed out the rooftop running part of the intro shows this off pretty well and same deal with the running animation when running up certain buildings my feelings are more or less the same as theirs unless you really know what you're looking for you might not even notice these artifacts especially since they look a bit like the kind of artifacts you'd get from motion blur or streaming video that you've subconsciously learned to ignore by now but anyway we'll see if our own gamers can notice them later on in the video and honestly i would be surprised if they could this game has far more distracting visual anomalies that are unrelated to dlfg like the way its ambient occlusion crawls along certain scenes and how it renders even nearby background objects at a lower blurred resolution regardless of your depth of field settings all of which is to say that despite the pixel peeping we're doing here dlfg doesn't seriously harm image quality and those artifacts are gone in the next frame anyway they're only on screen for anywhere from 16.7 milliseconds to 8.3 and even smaller as the frame rate climbs of course in order for frame generation to do its thing it really needs a certain frame rate to be usable nvidia recommended 40 to 60 is the baseline when i ask them about it in terms of graphical artifacts while they're still minor they definitely got a lot more pronounced when i locked the frame rate to 60 instead of 120 and when i dropped it down even further to 30 you can start to see how much guesswork dlfg has to do as there's more changes between the frames like check out spider-man's mask in the this scene i had to see how deep that rabbit hole goes so i dropped it down once again to 15 frames per second and that exposed even more weirdness check out how it handles the intro video here it looks like the gpu is failing like it's really weird the game clearly was never meant to run at this frame rate though there are some fascinating things that happen to the laptop display here and to peter himself when he's flailing around and when he finally jumps out of the window it looks almost like 2 000 sarah youtube but higher resolution he even mostly disappears behind the railing and the railing doesn't fare much better the other game i tested for image quality is f122 and when it looks good it looks really good but when it looks bad it looks really bad right off the bat the thing you'll notice most is the thing that's front and center the driver name tags it's not such a huge deal at 120 hertz but they shimmer and shake at 60 fps and things get worse from there i'm not sure why such small motions relatively speaking are causing eui to corrupt like this when it wasn't nearly as noticeable in spider-man even with fast motion but there it is another curious thing you'll notice is at the bottom of the screen even at 120 hertz you'll see phantom pieces of the minimap flash on screen from time to time and if you look really closely you can make out what looks like an f1 car's tires with optical camouflage applied to them when we crank the frame rate down you can see this way more readily it looks like nvidia trained the data set exclusively using the hood camera and possibly even on a single track while we're down in low fps territory you can also see some more examples of ghosting and overshoot on the car's tires and sometimes even the front wings start to overshoot ahead of the car it's really too bad because at high frame rates most of these issues are easily ignored and f122 itself would be an ideal candidate for gamers looking to crank the visuals on weaker hardware because it relies more on anticipation than twitch aiming and it is often played with a controller after all it's far more tolerant of input lag than say a competitive shooter the same could be said of most simulators even pc building simulator check out our float plane exclusive by the way for the uncut jake vs linus shenanigans and what about input lag we were never going to get 120 hertz level input latency with 60 real frames and 60 fake frames at least in theory we should see roughly the same input latency as the original frame rate right due to the shortage of games available to test with and with labs tied up with pre-testing for the upcoming rdna 3 release we've only got input latency results for cyberpunk but we can already see an interesting pattern here the complete dlss 3.0 package provided input latency somewhere between dlss 2.0 and native 4k on both our high-end and low end cpu benches which is expected due to the extra processing frame generation requires nvidia cited about an extra three milliseconds though in our case we measured more like four and a half or even as high as 13 on the core i3 that's almost a frame at 60 fps for that one perhaps this is a driver optimization thing but it seems like even though it can boost frame rates and cpu bound scenarios it can only help responsiveness so much still it is lower than running at 4k native and if you're not quite a cpu bound you aren't likely to perceive the difference at all that brings up a good question we've looked at all of this under a microscope so far but how does it actually feel to play with does it make things significantly worse do people even notice when it's on and which do they prefer to find out we set up three identical test benches connected to three identical monitors each displaying a different configuration one rendering natively one using dlss set to quality and one using dlss 3.0 with frame generation all other settings were identical for guinea pigs we selected five subjects of varying familiarity with graphics technology and asked them to play the games and rank each setup in order of visual fidelity and responsiveness first up marvel spider-man captain 120 frames per second note that this means that dlss 3.0 was running at 60fps and doubling the frames using ai let's see what the normies think see i notice in this one here in the reflections there's like a bit more flickering okay this this one seems a little slower i think i do like this one this is like fast it's like someone hit the turbo button on the computer i'm gonna say that this middle one looks the best so the normies seemed to not be able to tell the difference but what about cultured and discerning gamers i don't know they seem so similar now i'm not sure what i think it's funny how they have the same guy like in every single scene it's like the same face i'm looking at yeah i feel like that's the smoothest you can kind of see a little bit of shimmer but i think that's just a setting things not necessarily it's fun i would choose to play on this one and i don't know why and naturally we have to bring in someone who is relatively knowledgeable about displays and graphics yeah i'm kind of the display guy i guess i do all the reviews for displays i own a display i got it crazy right no they're all really similar the ui elements they get garbled with dls s3 i don't know man it kind of the same thing one two three and here are our results for visual fidelity native rendering appears nearly indistinguishable from dlss's ai upscaling and only when frame generation gets involved does quality seem to suffer though most subjects found it difficult to detect any difference as for responsiveness while we know that frame generation measurably hurts latency many of our subjects actually felt it was more responsive than dlss 2.0 which it literally is not so what you might be asking i'm playing a game at 120 fps natively why would i bother using dlss that's a fair question how does the technology fare at 60 fps we took our same subjects and ran the test again swapping the configurations for each monitor to try to account for any unknown bias preferring a specific monitor i don't know i don't know dude i feel like the middle one is the worst whatever i said yesterday i don't know if i was just kind of making it up in my head okay at this point i cannot tell the difference i noticed a weird artifact and like it kind of like it's hesitating it looks like it's hesitating right now when i move the graphic scope potato the text isn't so bad but the marker itself gets garbled when i flick it around a little bit i'm i'm still liking this left one a lot at 60 hertz we see dlss 3.0 really start to suffer in both visual quality and latency most subjects quickly selected the frame generated rig is the worst at everything we did the same 60 fps test in a plugtail requiem and found similar results with nobody preferring the generated frames but what if we just uncap the frame rate and really let those systems fly into the triple digits well we did just that and interestingly we see frame generation take the lead in latency our guess is that many subjects interpreted the added smoothness of the generated frames as feeling more responsive at high frame rates dlss 3.0 does a great job of adding frames without introducing unplayable latency or immersion breaking artifacts at the lower frame rates well things are more of a compromise but here's something to note the only card available with dlss 3.0 is a 4090 and if there's any card that really doesn't need frame gen is that thing the real benefit of frame generation will be providing budget gamers the ability to crank the settings and get frame rates that they typically would not be able to achieve so it was one last test we played a game of would you rather would you rather play your game without frame generation at 30 frames per second or at 60 frames per second with frame generation probably want whatever you dlss thing you just put on okay this one automatically oh definitely the first option easily previous setting i think this is better yeah i really can't tell a huge difference i think i prefer this one i want smoother i prefer the first one oh this one hands down i'll take smoothness and artifacts every day if you went into this thinking dlfg was a dud or if you still do think that i wouldn't write it off so quickly think about what dlfg is doing say you're limited to 38 ps for whatever reason you can either have an experience that's full of what looks like stuttering or you can reduce visual fidelity in a far more noticeable way by reducing settings of resolution or you can turn on dlfg and look at a smooth 60fps with some very minor visual artifacts that might be masked by motion blur anyway your input latency is going to be similar to 30fps but because you have smoother looking gameplay you'll be able to adjust your aim and track objects far more easily it won't save you in a competitive shooter of course but it'll turn single player games into a more enjoyable experience as two clicks philip put it in a recent video we didn't really embrace resolution scaling with dlss early on either but it's now ubiquitous and well accepted among gamers i mean it's either that or you run at a lower resolution and let your monitor scale it the stupid way right dlfg is still in its infancy with bugs that are actively being hunted down and squashed and before you conclude that you'd never use it because you don't want any input lag at all two clicks phillips video had another interesting angle that has me very excited for the future use ella for vr to dean put from the real frame rate making games playable even sub-60 it's a separate concept from dlfg but the demo built by comrade stinger showcases the intended effect very well here we have 30fps rendering but by enabling reprojection or async time warp power movements especially mouse movements are smooth and responsive you can see in this mode that it works by basically projecting the scene in a kind of a virtual display that moves back to the center of the screen as each frame is updated we'll have this link below so you can try it for yourself since the video really won't do it justice on its own two clicks phillips idea of combining this with full gated rendering to render a low resolution extension of the screen means that you'd practically never notice it and combined with frame generation to smooth everything out you've got a recipe for comparatively very low hardware requirements along with very high responsiveness and frame rates this would be a holy grail of sorts there are many games that could benefit from this setup but none that i can think of would be a better fit than digital combat simulator dcs requires a beefy system to run and while you can get away with a not so beefy control setup one thing that you really need while flying is to keep an eye on your target whatever that may be so you've got to be able to whip your view around a lot and low frame rates make that job so much more difficult to do while just tracking small fast moving objects and if you lose track of your target in dcs you can go from hunter to hunted in an instant no matter what you're flying in a hypothetical future where eagle dynamics and developers like them embrace technologies like dlfg and async time warp the price of admission becomes substantially lower and they'll require less power to run too it may be a situational feature for today but if it means that more gamers can have better experiences and even experiences that they wouldn't be able to have at all otherwise i'm keeping my hopes up for a tomorrow where our ai overlords regularly serve us those delicious imitation frames and we're i talk about our delicious sponsor mine mine is the smart data assistant that helps you discover where your data is and then helps you keep it where you want it to be with mine you can exercise your data rights and reclaim your right to be forgotten by asking services that you no longer use to delete your information with how many data breaches there are these days i don't know about you but i wouldn't want any companies that i don't use holding my data so sign up and mine will let you know how many companies are holding your information we ran our email address and over 360 companies are holding our data including many services holding financial data that our team hasn't used in years mine will even automate the process of sending an official data deletion request through your inbox so the company can then delete the personal data they have stored mine also helps companies with the ultimate goal of simplifying and improving consumers online privacy experience so sign up at saymine.com using the link below and own your data thanks for watching guys maybe go check out the video where we tested to see if we could tell when dlss 2.0 is on or not these kinds of analysis videos they tend to miss out on the experience of actually using the feature and a lot of new ones can be lost just looking at the flaws instead of looking at the hole you know