if you're watching this video on any device made in the last 10 years be it a desktop a laptop or a tablet or a phone then there's an extremely high chance that your device is powered by a multi-core processor since the release of the first dual core processor in 2005 by ibm it has become more and more common for computer processors of all varieties to be multi-core this is in direct contrast to laptops in the 2000s like my early ibook g4 for example which was powered by a single core power pc processor clocked at around 800 megahertz nowadays it is extremely common for any desktop to having at least four cores and clocked into the low four to five gigahertz but what does it mean for a processor to have multiple cores how does a processor with multiple cores work and why are many cores better than just one how many cores are too many these are all really important questions and like you i was curious to find the answer to be able to answer these questions though we first needed to find what a cpu core is at a very basic level all the computers processor really does is run code to run code the cpu will need a few basic things like fast internal memory in the form of registers temporary storage better known as cached act as a buffer between the internal memory and ram and then some additional hardware to interface between the cpu and the motherboard obviously the cpu will also need an execution engine that is capable of receiving instructions and doing something with them to do this the cpu will run an extremely fast efficient loop where it reaches into memory and runs the code that it finds the process to do this is as follows first the processor will fetch an instruction which is the task it must execute from memory then it will decode that task from memory and convert it into its own internal micro instructions and logic and then execute that task which may be the form of arithmetic or memory operation or something else like that once that execution is complete it will then store the result of that operation into the destination described in the instruction which that may be a memory location or a destination register for example the piece of hardware inside the processor responsible for this is referred to as a core so in layman's terms one cpu core is able to perform what is referred to as one thread of execution or in simpler terms one program now if that's the case how is it that a processor with only one core so basic early processors back in the 2000s were ever able to run multiple programs at the same time well the simple truth of it all is that they never were instead before processors had multiple cores a cpu would simply jump between tasks at an extremely high speed such that a user would never realize that only one task was ever occurring but now with cpus that have multiple cores and are capable of multiple threads of execution things get more interesting so we're going to talk about an arm cortex m0 processor for example which is a multi-core risk processor when a multi-core processor boots at the very beginning only one core is active for example in the arm cortex m0 processor on the boot the primary core so the first core is reset and begins execution at address zero the reset vector which points to the area where the boot loader would eventually begin executing program memory once in program memory software there then activates the extra cores which all began executing code at the address specified in their separate reset vectors which may live at different addresses eventually the operating system boots up with all cores running maybe in an idle state until there's more work to do at that point it is the job of the scheduler within the operating system's kernel to make sure that all the cores are being used efficiently and everyone's happy and this is not an easy task to perform at any given time there are cores that are hungry to execute code and a user who wants this computer to do work but the question is which processor gets to run which pieces of code and for how long so code executing on a processor actually creates some effects that one must consider when designing a scheduler around them the first effect is called processor affinity which means that the code prefers and is more efficient to be ran on the core that it started running on this happens for a few reasons primarily due to the way that cpu cache works where cache is filled with data related to the code being ran on the core leaving a piece of code running on a core comes at a cost though for example if the code is blocking the processor on an input event or waiting for an interrupt it may be advantageous to forgo the cost of violating affinity to make sure the core is being effectively used and not blocking so as a result there are two approaches to multi-core scheduling the first is referred to asymmetric multiprocessing the idea of asymmetric multiprocessing is that one core is the boss of the other cores as a simple example in an asymmetric scheme on a four core processor core one runs the kernel code and hence the scheduler and then cores two three and four take orders from the scheduler and only ever run user space code as directed by the kernel this is the direct opposite for example of symmetric multiprocessing our second schema where every processor is just a worker that is free to execute code as needed and the work is derived from some global work queue where tasks are pushed and popped as requirements for execution to rise generally speaking asymmetric multi-processing is easier to implement but less efficient and the opposite is true for symmetric multi-processing so now that we understand how multi-core processors work and generally how they're scheduled the question is why not more why can processors not just be built to have 16 32 128 cores well in full transparency some processors these days actually do have double digit numbers of cores but this core density is a result of some insane material and semiconductor engineering that had to consider first some difficult constraints the first one is that of thermal efficiency as you begin to pack more silicon into a tighter space making it more thermally dense the efficiency and performance of those cores go down ultimately at a cost to the performance that outweighs that gain from adding a core the second is memory bottlenecks while the memory internal to a processor is extremely fast via the cache or the registers themselves it is ultimately bogged down by its ability to write back memory to ram which is limited by the speed of the ram bus and its size of its access bus at a certain number of cores there's so much blocking on memory accesses that eventually no one can get any work done and ultimately the addition of cores is not worth the cost and then finally some code just doesn't parallelize well ultimately it is actually on the programmer to make use of all threads of execution available on the processor and to write code in a way that it scales up linearly with the number of cores available if you've ever played a game that hogs up your cpu despite you having the latest intel i69 420xxgy processor it is likely not because intel designed a bad cpu but rather that the code that you're playing isn't designed in a way that it cares about how cool your processor is so could intel produce a processor with a thousand cores it would be huge and ugly but probably yes would all the cores operate well and would any code out there take full advantage of the potential processing power probably not so what's the point right now cpus are extremely powerful and are able to do things computer engineers 50 years ago never would have thought possible and according to moore's law which dictates that the number of transistors packed into a chip doubles every two years the same may be true again 50 years from today if you guys enjoyed this video or you learned something please do me a favor leave a comment about what you want to see next time hit like and i'll see you guys in the next video take care [music] you