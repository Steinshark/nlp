welcome to this session of meeting c plus class we have with us patricia asked and she will talk to us about memory exploitation i'm very much looking forward to this talk patricia take it away thank you so much fabio so i'm going to read you as a bit from a blog post that came out many years ago now basically an attacker can grab 64 km memory from a server the attack leaves no trace and can be done multiple times to grab different run a different random 64k of memory this means that anything in memory ssl private keys user keys anything is vulnerable and you have to assume that all of it is compromised all of it catastrophic is the right word on a scale from 1 to 10 this is an 11. so this was from bruce meyer's blog post about heartbleed in in 2014. now heartbleed is now quite old but it is very interesting and we're going to talk about it for a couple of reasons so the bug itself it was a buffer overread and also an attacker control size and these two things made it very easy to exploit also it was a remote attack it was remote it was high value and this is probably the most important part of park bleed that it was targeting the the process that had loaded open ssl library into its process and so this process whatever it was was was expecting to be contacted over the internet and but it also had high value memory so you would have all sorts of things in this memory that would be interesting in addition you could basically dump the entire virtual address space of the process using heartbleed the other problem with it was that it was widely deployed like openssl was used everywhere it was used on everything from from smart light bulbs to to servers right a lot of these things weren't designed to be updated at all but they were now vulnerable for this attack so we're going to talk about memory exploitation in this talk i've done some talks before where i talked about stack based attacks but then here we're going to be talking about the heap so let's look at the description for the cve for for heartbleed so it says that the tls and the dtls implementation in openssl 101 before 101g do not properly handle the heartbeat extension packets now the heartbeat extension package was a very simple protocol where where a client would send some some sort of of a packet and and that the server would then reply with the same package that was the idea unfortunately you could lie about how much data you sent and so so the the second part here says which allows remote remote attackers to obtain sensitive information from process memory via crafted packets that trigger a buffer overrate now heartbleed is a prime example of what is in security circles called an information link an information leak can mean most many things but it means in itself that what you are leaking is information it doesn't give you any kind of execution any any other type you don't crash the application necessarily and the goal of an information leak is usually intelligence gathering of some sort now in this case before you could dump the entire memory of the process maybe get some keys then you can use those keys to log into the server perhaps or things or or use them against whatever right and but oftentimes when you have information leaks you're often leaking addresses and that's because to to defeat address-based layout randomization you often want to know where things are in memory so if you can get the process to leak addresses and memory to known objects then you could try to map out the address space but in this case you can use heartbleed to dump the entire contents of the virtual address space which was demonstrated multiple times by by security researchers so harpley was famous for how devastating it was to the entire industry like this changed how we approached computer security how we approached device upgrades it changed a lot of things about how we work but it also became the poster child for fuzzing and that's because hartley was found by fuzzing by two independent teams and more or less playing around testing their fuzzers at the same time more or less the same time two different teams found heartbleed and the reason for that is that it it's and i do this in my training actually we find heartbleed it's super easy to find once you fuss the right interface it is ridiculously easy to find and it became sort of a very easy example to show how fuzzing can find bugs so my name is patricia olis i'm a trainer and consultant i'm doing a training on monday and tuesday for meetings equals plus i'm a c plus plus programmer i've been focusing a lot on application security for the past a few years but i've been working sort of in that in the nearby area for most of my career i work from my company that i co-founded called turtle sac but i previously worked at a bunch of different places my first job was at opera software working on the original opera browser then i worked as a java consultant for a couple of years and then i went back to see cisco making embedded telepresence systems and then i went back to doing a browser again at vivaldi i have a master's degree in computer science and my pronouns are cd so but let's get back to fuzzy so what is fuzzing really so let's i'll give you an example of a type of fuzzing which which is the common type of fuzzing that is done today so this is is what is often referred to as coverage guided fuzzing so in coverage kind of fuzzing we are going to start with a bunch of inputs now these are usually represented as files in the file system so we have a bunch of files that we that have the data that we're going to feed the function that we are fuzzing and these are often called the corpus so when we start our fuzzer it it will take a look in the corpus then it will pick one one of these and these are these are valid inputs so these are like non-crashing inputs so if i was trying to first let's say an open source application i might go and look at files used in unit tests and things like that in in inside of the the source code to try to find like different sorts of files that would exercise the application in different ways so so these are good inputs hopefully exercising the application in many different ways so the fuzzer will pick one of these inputs then make some change to it and this change has some randomness to it but also some strategy so there are some like heuristics here but a change will be made and it will also record both what change it made and also which input it used and then it will feed this this this input this modified input to the the the application that you're fuzzing so if this is a library then you would have to build an application that loads this library and then fuzz it in that manner but this target application is instrumented and it's instrumented it can be instrumented in a variety of ways but one of the things that we want is that it has to to report back coverage and this is this is the model for coverage guided fuzzing now this coverage is very similar to probably what you've seen when it comes to to tests to see test coverage so the idea here is that the fuzzer wants to see given this input can i reach code paths that i haven't reached before and so even if this input that it and this input that it created might might not cause the application to crash but it actually entered an if that the fuzzer has never been inside before or it ended up calling a function that had never been called by any previous input so so if if the the coverage by this input it increases to what the fuzzer had previously the festival will record this input as interesting and we'll keep it for later and think okay if i do more modifications on this input then maybe i can reach more code right and the reason why this is is extremely important as an optimization is because you need optimizations for fuzzing because the the fact is we're doing basically mutations on often binary data and and the the the the amount of mutations that you can do is exponential in all sorts of directions and so this becomes extremely slow so you want to make sure that whatever you whatever input you're looking at and you're continuing to mutate it should be something that is leading you in a sensible direction so in coverage guided fuzzing it is mostly about trying to reach all parts of the of the code with the inputs that you have so this is a learning process right for the fuzzer and there also might be a crash so so perhaps this input caused the target to crash and then you want to to record the crash and the input that caused it to crash now this could be extremely useful like for attaching to maybe a bug report or something that this this input here caused the application to crash you can maybe load it up in your debugger you can you can try to see if you can reproduce the crash so that's really nice okay so now we have an idea on how we might be able to find a bug in an application so we might be able to to use fuzzing to find find a bug but the thing is okay i can find things that crash but very often and we know that especially memory bugs and simplest plus they don't crash right mostly they just kind of linger corrupting memory for a while and might crash in the future sometime so we want actually to get the application to crash to be able to record the crashing input now you can and this makes it interesting because now we can actually use the causing the application to crash as a way to to to signal input that is interesting so you can use this in a variety of ways for crashing it on purpose by adding asserts or things like that but we're going to do a different tact for for especially for finding memory errors now the combination i'm going to talk about here is the most popular combination out there among security researchers so when you are seeing memory vulnerabilities in in like all of the big memory vulnerabilities almost all of them are found this way so we want the application to crash when there is a memory error and a lot of you know how to do that with sanitizers or more specifically we use address sanitizer and that is that is the case most security researchers will use address sanitizer together with fuzzing often a live fuzzer will be used because it's quite fast so you can come combine lymph fuzzing and and climb with sanitizers like like ubisoft or address sanitizer and it's quite easy to fuss an application that you can compile now if you cannot compile the application there are ways of doing this harnessing a binary application but you will generally then use maybe some sort of emulation layer to give you some of the feedback and crashiness that we're looking for but this is this is the the simple way so if you can do it this way then this works so what is address sanitizer added sanitizer itself will will be compiler instrumentation of the binary so it will insert instructions generally before loads and stores and things like that in addition there is a runtime component that will be recording all sorts of debug information that will be used if an error occurs like stacks from when memory was allocated when it was deallocated when it was used after free things like that it will also it's also instrumenting memory with what is often called shadow memory so the runtime library is is basically a malloc replacement and so how do we use it so you can pass f sanitize equals address to climb but it and it will if you run the application and it has some sort of overflow perhaps then address sanitizer will error out the moment the overflow is triggered so this is dynamic analysis right now this was introduced in klein like over 10 years ago but it was adopted very quickly in gcc and much more recently in visual studio but in addition versions of address sanitizer has been adapted to almost every kernel out there so there is a is an address sanitizer for for the linux kernel for the basic kernels for you know whatever whatever kernel you're using they've made address sanitizer replacements for those kernels to be able to find memory errors yeah so it started in clang and got into gcc and is now in visual studio and for about a year it's been available for for 64-bit before then it was only available for 32-bit so this is something that you will find on every platform it's available on mac linux and windows and various compilers so so this of all the sanitizers this is is the the one that has the widest adoption in compilers now what address sanitizer gives us is crash-like behavior at the moment of a memory error so if we can if we can combine this with fuzzing we get a supercharged fuzzer so if we can trigger any type of memory error then the fuzzer will will record it as a crash and we can look at the input and see if we can exploit it in somehow some some way and so that will make it easier for us to find bugs that might be harder to find otherwise so the combination of coverage guided fuzzing with address sanitizer makes it really easy to find memory errors in c plus plus 1c applications and that in my opinion is the reason for the massive surge in memory related bugs that we've seen in the past few years because they are super easy to find and they're even easier to find if it's your application so you should definitely be doing this yourself so the basic technique is we want to make the application crashy by using sanitizers we want to provoke a weird behavior and i'm going to get back into what weird behavior is but but we're going to use these sanitizers to make the application crash here we're going to use the fuzzer to feed lots of weird input to our application and then we want to analyze the crashes that we get out to see what was it that caused the crash is this something that we can control another thing that is really important about fuzzing is that we are pushing this input from the boundary of the application so if if we're fuzzing a specific interface to the application we know that from that interface we can reach this crashy code with this input so you could have some kind of part of your application that is vulnerable to something but it's totally unreachable from the outside but with fuzzing we know that we can reach it from the outside because we did so we found a bug right now we that way so then we get to exploitation and very often you will see with people who are professional security researchers that they will often specialize as you might have teams where some people are are specialized in finding bugs and and some people are specialized in exploiting books so here i want to talk about the a model for thinking about exploitation which i do talk about a lot in my training which is which is a motto called the weird machine but first i have to kind of present to you the underlying idea here and the idea here is that you as a programmer has have a mental model for how your program is supposed to work so imagine that we have some sort of program that prints you know secret colon and then the user's supposed to type something so then if a user types joshua we'll say access granted if the user types david we'll say access to nine so this is how we imagine that our application works so if access was granted then we will be launching missiles and it either way we'll say operation complete so this is how we intended our application to work either you know either it was it was the right password or if it were or it wasn't the right password but either way the program will exit in the end but what if someone types something really long right if we have a stack allocated fixed size array then here we might have a stack buffer overflow right and it might cause the application to crash or a correct memory or something now this state is an unintended state for the program it's not in not a state of the program that the the programmer ever intended the program to be in and so in this in the weird the weird machine model these states are called weird states oftentimes weight states are very unstable and will usually cause the application to crash but the goal of exploitation and of native applications is to try to control weird states so the application doesn't crash and we can do something else so if we imagine here on the on the left that we're seeing and this is the programmers like mental model for how this program is supposed to work and we have some sort of vulnerability so in this case we had a stack buffer overflow right when when it overflows it will bring us to a weird state and our goal is then to use that weird state and some sort of functionality in the program to bring us to another weird state and from maybe from there to multiple other ones but in the end what we want to do is run our shell code so this is the this is the basic idea of exploitation some of the stuff that i go through in my training is different ways that these things can happen but the basic model is the same now this model of a weird machine was introduced by sergey brothers who's a professor and how that's like which is whose name is actually thomas dolan and he he refined it wrote a paper it's very interesting for for grasping this especially if you're coming from computer science or or math both of these were are are mathematicians by by by education but let's get back to what is shell code right and so so this is this is a word that a lot of people are not familiar with so let's let's see so it's a piece of code in our case it's it's basically compiled assembly so it's typically a machine code and it's often it's then delivered and executed as a part of the exploit basically often as a as a character array of with the bytes delivered somewhere and and maybe copied around the memory it's called shellcode because the the compiled program which is the the shell code was often at least in the 80s and 90s i used to start a shell like bash or sh or whatever and that's basically to prove that you have code execution on this machine so if you can start a shell then that means you could basically do anything today there are modern versions of this so you would often hear windows exploiters call say things like pop calc which means they started the calculator on windows in real exploits you generally don't do this you often deliver some other type of mechanism that makes it easier to do some kind of secondary stage exploitation sometimes you can have multiple stages of shell code leading to the installation of some kind of root kit or something so so this this can be quite complicated in real life exploitation today but usually what you're looking for is to install something on the machine that makes it possible for you to later control this machine remotely so if you're looking at an exploit in itself it usually has multiple components and today most have all three of these components that i'll show you and usually multiples of each one so it needs some kind of way to read the memory the addre the like the address space of the of the target process needs some way to write to that memory and it needs a way to execute code inside of that memory and so the reading of memory is often called information leaks writing a memory with what you would want to do for planting your shell code and then you need some way to run your show code so so let's see about code execution so a lot of people talk have probably heard about remote code execution and all sorts of things like that so the idea here is basically code execution we want our shell code to run and to do that we need to control the instruction pointer so that it jumps to our shell code so wherever we have managed to write our shell code in the memory of the process we want the instruction pointer to jump there and start executing that code now we have many different mechanisms in in native applications for the instruction pointer to move and here we are looking for a way to control those jumps so for example in returning from a function we have a return address on the stack for example maybe in an x86 scenario you could have a virtual function call or a function pointer with a version function protocol you are using pointers in the virtual function label in a function port you could have just a function pointer you could have a whole table of function pointers now these kinds of of things of capabilities that that an attacker manages to accumulate in your application are often called primitives so within each category a read write and execute you will have different types of capabilities and they're usually called by different names so so this is as a vulnerability or capability and why are saying vulnerability or capability is because it could be a feature it might not be a bug but it can be used as a part of a wider exploit they are often often have like very explanatory names once you know what they are as you can have something like arbitrary read primitive this means that i can read memory at an arbitrary location in the address space on the other hand you know you might not be able to read arbitrarily any address you might only be like i could have a read of you know three bytes within let's say a thousand bytes of the beginning of some buffer so you might have like these can be modulated in many different ways you have something called the right what where primitive that means i have a way to write what i want at whatever address of my choosing a read where as i have a way to read whatever i want at whatever address i want in the memory and so you have many different versions of these with you know and they might be have like modifiers to them like i have a an arbitrary read primitive of five bytes right i have a right where primitive within two pages of the beginning of something but they're often referred to as primitives so let's look at what kind of mitigations exist right so to try to to to to mitigate some of these some of these capabilities things have been introduced in in compilers or in the platforms to try to to avoid these things happening so for example some of the some of the ways that that platforms and compilers have worked to try to make it more difficult to execute code in memory is by for example introducing non-executable memory or non-executable stacks this is basically a is a feature where you but you you mark the page as it's loaded into memory whether or not it should it should be executable you also have secondaries which try to detect stack buffer overflows and there are many other features trying to to avoid this some of them quite advanced for writing memory you have you have address based layout randomization and and that is mostly about trying to make sure that addresses are not predictable so it does affect multiple parts of this both reading and memory and writing and execution if you don't necessarily know the layout of the virtual address space it makes things quite difficult and so actually to to target that we will today see almost always some kind of of of information leak so so we have we have ways of trying to to avoid people reading things that are interesting and that's address-based layer randomization but you might also want to limit the the access to interesting information like if you have have a part of your application that has a lot of high value memory you might want to maybe separate it out into a separate process maybe maybe sandbox it more carefully be so there are many different ways you can do this but what about just cleaning memory like let's say that you have like one thing that we remember from from the horrible heartbleed thing was that there were like stuff just lying around in memory someone was in a parts of memory that was was de-allocated some of it was just randomly like memory right that wasn't even valid so how about we just kind of try to clean any kind of sensitive information that we have so we only have it in memory for a very short time actually this idea was widely used for a long time and also caused a different a different vulnerability and this was caused by a change in compilers it was an optimization technique called dead store elimination here compilers are allowed to optimize away stores that cannot be detected so a lot of places applications were mem setting memory to zero and that had worked for many years and then they upgraded their compiler and the optimizer optimized the way the mem said so so when you read the code you would say oh here okay this buffer when i'm setting it to zero but the mem setting actually was optimized away and never occurred i jokingly refer to this as the case of the disappearing memsa but let's go back to the heap so to understand how heap exploitation works we have to have like a very short introduction to to allocators so let's look at at a very simple pool allocator and how it could look and we'll we'll use that as as sort of a model so imagine that this is our memory and we have to to to to provide chunks of memory to our application so when let's say that we're here we're implementing malloc right or something similar so so if the application asks for some memory then we will allocate that memory right so okay so the application got these three and then maybe these five and then two and then three right so we're just kind of filling up memory with these objects that are varying sizes but then we have suddenly the application deallocated something so now we have a hole now if we were in a garbage collected language then this could be like compacted and things like that but in in c and simplest that is not the case these addresses need to be stable we can't move these objects around so now we have a little hole and we don't want to fragment our heat because that might be problematic later so okay so let's save this right we'll just save a pointer to this like i have a little thing here which which if somebody asks for a two then they might get this this lot right here then somebody so the application deallocated the first allocations now we have another hole okay so maybe if we just like okay we're gonna make a list of these these little chunks that are free so that next time somebody tries to allocate something we might give them something of one of these holes instead then you have suddenly this this adjacent chunk was deallocated so what are we going to do now like are we going to put them together to make a larger chunk or maybe we just want to link it in like we did with the other ones all of these are questions that are are things that an allocator will have to work out how to deal with these things the thing is the the the basic approach has been very similar across many allocators over time so how can we exploit this behavior these are this is your allocator will work in some way like this so how can we exploit this well one thing we can do like as an attacker we can try to allocate objects on the heap now this could be legitimate objects like we could send a buffer to some kind of server application and then the server will copy maybe that into some kind of buffer on the heap so that's a way that we can allocate memory on the heap by sending messages maybe to the server application but the first example we're going to be looking at is something called heapspring now heapspring was very popular especially amongst people who were doing a browser exploitation you know let's say 10 years ago it was very popular and and and the reason for that is it was very easy to allocate on the heap in the browser because they were doing this from javascript they just would create like javascript strings to do it but let's have a look at how it works so the basic idea is we want to fill the memory with with a certain byte sequence as many as possible and then in that we probably have our shell code the idea is that if we then later can hijack the instruction point to just jump into the heap anywhere we hope to get to a point where we can run our shell code now this technique i used a specific format of of the exploitation string and to make this more probable so if you imagine that this is our shell code string then you would add lots of no ops here in the beginning so these are no ops instructions in bytes and then at the end we have our actual payload this is the code that we want to run and this this chunk of no ops is also called a no op sled or a knob sled the idea was that if you filled the entire heap with strings that look like this where most of the shellcode string might be no ops then a random jump will probably hit inside of the no ops chunk of this and then it will the instruction pointer will just know what know up no up all the way through until it hits the payload and execute it so it was a very probabilistic type of attack so it would look something like this so you would have all of your normal allocations on the heat and then you would just fill memory with this thing and then at a certain point later you might manage to get to to get the instruction pointer to jump into a random place in the heat and then you would execute your shell code now this of course required that the heap was executable but at the time that was very common this is a very scatter shot kind of thing we're just kind of blasting all this copy of our exploit string all over the heat right so maybe we can do this with a little bit more fine grained control so that brings us to heat grooming also also called heat feng shui now the idea here is to try to create predictable patterns on the heap and then trick the allocator to to allocate a specific chunk to us as an attacker this should be a chunk that we can control maybe adjacent to another chunk that we can control so that we could have some kind of predictable behavior in the heap this is often used for our heat buffer overflows so let's see what that could look like in reality so so first i have to introduce this a little bit so we have something called the shadow brokers this is a hacking group that was behind a leak that leaked in 2016 2017. they had multiple leaks we're going to be looking specifically at the last link that they did the the they leaked exploits and tooling that is is assumed to be nsa tooling and a lot of people today suspect that the shadow brokers are in fact russian and russian intelligence the leak was done in several batches but we're going to be looking at the last one which which was basically windows tooling and inside of that we're going to be looking at the in the eternal blue exploit so i'm not going to go very into the the application that it attacked but this is basically all of these all of the exploits that are are in this eternal grouping are going for attacking windows smbv1 which which was which was an ipc type of mechanism on windows so so basically we have a client it sends some kind of request to some kind of server and then it gets some kind of response now since the the request can go over several messages then then the state for for the request is stored on the server and so these objects while the request is opened are stored on the heap in the server and this makes it possible to control both the length of allocation like when it gets allocated when it gets de-allocated might get deallocated when you close the connection maybe so you can control that and you can also control the content and and things like that so so these these vulnerabilities were based on on on vulnerabilities in this mechanism specifically around the server handling messages so there are a bunch of of exploits in this eternal exploits family the basic idea for all of them was to install this double pulsar back door on windows and this was the the mechanism that they would have then for being able to control this machine post post exploitation so the the whole idea was to install this double pulsar back door and then it was over so eternally blue became the most famous but there are variations on it called eternal champion eternal romance internal synergy most of these were basically trying to address different types of security mitigations and windows to try to make it work again but we're just going to look at eternal blue to show you how this might look in in practice [music] so the the foundation of a kernel blue is a ripe what wear primitive and remote code execution it's based on a buffer overflow on the heap together with a heap spray and a heap grooming now there was basically one main bug that was behind this and and i want to show that to you to show you how small of a vulnerability can be and how devastating it was so so this this bug was the main bug and the reason why you could remotely install the double pulsar backdoor when updating the length of the list the size is written to as if it were a 16-bit u-short when it's actually a 32 bit long this means that the upper 16 bits are not updated when the list gets truncated so this is from the microsoft analysis now one of the things that that is probably true i'll show you the code but this is probably a part of a refactoring that happened this code is very old like it predates windows itself this is goes back to the 80s so the code is very old and it went through several refactorings and one of those refactorings was going from 16-bit to two to 32-bit and and what i think or i suspect is that this bug was a result of that refactoring so let's look at the code before so here we have this this and of course i've done some copy and pasting to try to fit it on the slide but but here we have this this cb list which is a length and it's a u-long and at a certain point there is an attempt to to reset this value to a sensible value and and it calls this smb put you short and and here we are basically setting bytes and we are only setting two of them so when this is called we are only resetting the the the lower the word here not the high d word so if you had a significantly and like a large value in this this resetting did not work it would only reset the the low d word and the fix for it was very simple it just used a different function so it called smb put you long which actually did reset the entire you long so this is this is the bug and this is the fix it's very very small very easy to miss and and i just wanted to show you what it would look like so so the the the exploitation itself is a heap grooming spray which i mentioned before so we need some way to prime the heat and then we want to to fill it with blocks that are ready for shell coat now the reason for this is that we are because of the s how smb works there is a lot of control of the heap by these requests and these connections so so you could fill buffers in pending requests and things like that and then we will make some room in the heap for for another type of request and then we will in there we will do a buffer over run the overrun will overrun into an adjacent an adjacent block and and there we will overrun amongst other things uh function pointer yeah so let's look at what that would look like so this is just just to to to give you a mental visualization so we have some sort of initial state this is the heap it has you know some initial allocations and the heap grooming then you will fill you will do a bunch of allocations generally into your size to be able to try to fill in all of the holes between the regular allocations and this gives you gives us kind of a clean slate afterwards for for trying to create our predictable patterns so these could be called grooming packets so for our heat grooming then we fill the rest of it with you know our pattern objects so this is basically just so now we have full control of this entire contiguous section of memory these are also grooming packets and some sometimes referred to as second stage gourmet packets and so what we want to do is we want to free up some holes here and then our predictable size so these are the same size as our second stage grooming packets here so we know how big these holes are so then we in in this case there there are smb packages that are being sent that fit into this hole right so now we have we made holes for them specifically and we are hoping now that they are adjacent to this this other type of grooming packet when we then do a buffer overflow we're overflowing into adjacent objects and one of the things that we can do then is overflow for example function pointers inside of these objects and later on when these objects are deallocated or some kind of function is called on them then they might execute or jump through those pointers and in this case they are pointing back into the the overflow buffer and in this case the the pointer that is being overflowed is some kind of cleanup function that happens when you close the connection so we send the shell code to everything because we don't necessarily know where everything is and when the connection is closed the shell code is executed because we overflow the function pointer in in the the ones that were overrun and this will then install the double pulsar backdoor so this was a tool used by the nsa for for many many different years and you can see that through how it was maintained it was probably one of the the most powerful tools that they had and one of the things that was was clear the moment this was leaked it became very stressful for a lot of people because they saw that it worked against basically every version of windows one thing they realized though after a little bit was that only a few months earlier windows hadn't had had given out an an out-of-bound patch for windows to that patch specifically the vulnerabilities here it is widely thought that nsa when they realized that this leak was forthcoming actually did notify microsoft so that microsoft could fix it and and and microsoft has released patches going way back to try to fix this but but it was quite devastating at the time the problem is also that a lot of people who have windows machines are don't upgrade or are not able to upgrade so eternal blue was later used in multiple ransomware attacks for example wannacry and not petya and that that cost hundreds of millions of dollars worldwide and also disrupted multiple industries because the reason it became quite popular amongst ransomware is that it spread really fast and easily within a network and so this mechanism of eternal blue was was used then to spread ransomware across the network once you got in so the question then becomes like okay so so all of this memory exploitation how does it affect me and i think we have to go back to to what i said in the beginning how how are they finding these vulnerabilities they're generally finding them through fuzzing and using address sanitizer or some similar mechanism to address sanitizer as these are malloc replacements that will some somehow instrument memory so the idea here is that these are things that you can do you can use address sanitizer both in your ci cd pipeline you can use address sanitizer locally while testing you can fuzz there's all of these things that they're doing it's not magic and it's something that we can all do to to make our applications better [music] because there is no magic here they don't like just do typey typing on the keyboard and then suddenly they scream we're in they're basically doing work that you are used to doing this is basic basically a type of debugging and very similar to stuff that you've done before so these bugs are bugs that you can find in figs and they use the same tools you use they use the same compilers they use address sanitizer they use all the same same things that you are used to working with in your day-to-day so if you want to make your application more secure there's really just one answer and that's fixed bugs they are using bugs to provoke weird behavior in your application and by doing so trying to get to a point where they can execute code inside of your application and do what they want the best way to make your application more secure is to fix those bugs so that was my talk and i think we could get to q a now fabio are you here yes here i am i hope that the video works now again we had a bit of problems with your video but the sound seemed to be all right and everyone could see your slides okay that's good your face might have been out of the video for a while so let's see we have just one question and that is about isn't smb version one no longer used today or are there still installations supporting it now so so hopefully nobody's using it today but there are still unfortunately some places where where they're still in use and and what we've seen especially with with these these windows these windows exploits was that certain sectors were more vulnerable than others and those are sectors that are afraid to upgrade so so we saw especially hospitals and kind of medical type of of industries that were very afraid to upgrade because it broke their equipment and so there was a lot of trouble getting them to do windows upgrades but i think i think it's better now you shouldn't be using smb as a baby one even with the fixes you should definitely be using v3 but but it depends like a lot another thing that we saw certain certain people had pirated windows they couldn't upgrade they were also vulnerable so so yes it's it's it's an issue and a new question just came in is it possible to write absolutely invulnerable fail-safe c plus plus code i'll say no to that question no okay so so that it's it's a little bit like saying like can you write this equals close program that does not invoke undefined behavior and the question is is is a trick question because it's super hard not to have any undefined behavior but we should try our bestest right and and that's that's where a lot of the new tooling comes in a lot of modern c plus plus makes it easier to to to write code where you won't make these mistakes but but it's it's very it's very difficult to say for sure that you don't so i would definitely go following core guidelines type of things using using the tools that you have like clang tidy and and and the sanitizers and things like that too to to help i think there's another question there is will we ask can the death story elimination be worked around it sounds like a good idea to clear sensitive info once you're done with it yeah now and several people have worked on this so one of one of the things that we had in c11 was the annex k that was introduced in c11 which introduced the function called that that was specifically supposed to be used as a as a as a dead store eliminates safe men's set unfortunately nxk was an optional and a part of c11 and was not adopted in c plus 11. but it is supported on certain platforms what we've seen is that most platforms introduce different functions like this themselves and there has been work in future simplest standards to try to find a portable way to to tell the optimizer not to optimize this one away so they are all equally voted so i can go into for more recent you mentioned that the heap was commonly executable in the past what is the situation today i thought only the program code is executable and immutable yeah so this this in most modern operating systems and especially desktop operating systems this is today the heap the the system heap is usually not executable unfortunately you will have applications that need to do jitting and things like that and they will have to dynamically map pages to be executable for this jitting process because if you want to do just in time compilation you have to actually write executable code somewhere in memory and jump there in addition there are various platform apis to to remap pages or to allocate new pages that are executable so and there's a lot of legacy applications and that might have to turn this off because otherwise they don't work and so it's it's complicated yeah very true so the next question is from thomas great talk i completely agree that the fixed bugs conclusion however asan does not yet find everything there's some limits what else do you suggest static analysis serp misra autostar so so currently i'm i'm not a super big fan of of some of these secure coding standards mostly because they are quite old often and the solutions that they recommend are usually not modern sequels plus but that might improve in the future i know peter sumlin has been working to to update some of this and so so hopefully we'll get some updated standards maybe next year when it comes to static analysis i would say yes and and i and i also want to say that these things are not alternatives they are complementary so definitely lean hard into your your static analysis tools and use them to to find find bugs and maybe code that you don't run very frequently and it's also hopefully a very short feedback loop you can integrate them locally into your ide you can find bugs really quickly so so i definitely say yes to both and then jonathan asks if the applications aren't available outside of the organization are these attacks impossible so there's as i i'll have to do another time to show you an examples of this but there are some some really obscure ways of exploitation like the us and israel went together to try to to to create a like a computer-based attack on iran's and like nuclear program and they did that by attacking a an embedded component in the refinery the the refining process for uranium inside of an of an air gap system inside of iran right so so the the point here is that if people want it enough they'll they will get their hands on it and they'll usually do that in a variety of ways like the actors that you're dealing with it could be state sponsored right so they might actually have people who will physically go in to your building to get a hold of what they need to do the analysis and then in the case of of this this attack on iran it is widely thought that the us actually built a facility mimicking the one in in iran to test and then develop their attack so that's the kind of like scale some some governments are willing to do yeah so we are out of time for the last questions but if you have more and want those questions the answers answered and hear the answers you can go to the launch and go to track b to the q a session of track b and patricia will join there in a minute or so to answer more questions thank you everyone and bye