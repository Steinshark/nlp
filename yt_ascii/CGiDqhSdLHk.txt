- every star in the sky
probably has planets and life is probably
emerging on these planets. but i think the combinatorial
space associated with these planets is so different. our causal cones are never
gonna overlap, or not easily. and this is the thing that
makes me sad about alien life, it's why we have to create alien life in the lab as quickly as possible, because i don't know
if we are gonna be able to build architectures that will intersect with alien intelligence and architectures. - and intersect, you don't
mean in time or space time? - [lee] time and the
ability to communicate. - so the ability to communicate? - yeah. my biggest fear in a way is that life is everywhere but we've become infinitely more lonely because of our scaffolding
in that combinatorial space. - the following is a
conversation with lee cronin. his third time in this podcast. he is a chemist from the
university of glasgow who is one of the most
fascinating, brilliant, and fun-to-talk-to scientists i've ever had the pleasure
of getting to know. this is a "lex fridman podcast". to support it, please check out our
sponsors in the description. and now, dear friends, here's lee cronin. so your big assembly theory
paper was published in "nature". - yeah.
- congratulations. - [lee] thanks.
- it created, i think it's fair to say, a lot of controversy but also a lot of interesting discussion. so maybe i can try to
summarize assembly theory and you tell me if i'm wrong. - [lee] go for it. - so assembly theory says that if we look at any object in the universe, any object, that we can quantify how complex it is by trying to find the number
of steps it took to create it. and also, we can determine if it was built by a process akin to evolution by looking at how many copies
of the object there are. - [lee] yeah, that's spot on. - spot on?
- spot on. - i was not expecting that. okay, so let's go through definitions. so there's a central equation
i'd love to talk about, but definition-wise, what is an object? - (chuckles) yeah, an object. so if i'm gonna try to be
as meticulous as possible, objects need to be finite and they need to be
decomposable into subunits. all human-made artifacts are objects. is a planet an object? probably yes, if you scale out. so an object is finite and
countable and decomposable, i suppose mathematically. but, yeah, i still wake up some days and think to myself what is an object? because it's a nontrivial question. - "persists over time." i'm quoting from the paper here. "an object is finite, is distinguishable." so that's a weird adjective. "distinguishable." (chuckles) - we've had so many people help offering to rewrite the paper after it came out. yeah, you wouldn't believe,
it's so funny. (laughing) - "persists over time
and is breakable such that the set of
constraints to construct it from elementary building
blocks is quantifiable. such that the set of
constraints to construct it from elementary building
blocks is quantifiable." - the history is in the objects. it's kind of cool, right? - okay, so what defines the object is it's history or memory, whichever is the sexier word. - i'm happy with both,
depending on the day. (laughing) - okay. so, "the set of steps it
took to create the object." so there's a sense in which every object in the universe has a history, and that is part of the thing that is used to describe its complexity. how complicated it is.
- yeah. okay, what is an assembly index? - so the assembly index, if you're to take the object apart and be super lazy about it or minimal, 'cause, you know, it's like you've got a really short-term memory,. so what you do is you lay all the parts on the path and you
find the minimum number of steps you take on the path
to add the parts together to reproduce the object, and that minimum number
is the assembly index. there's a minimum bound. and it was always my
intuition the minimum bound and assembly theory was really important, and only worked out why a few weeks ago, which is kind of funny, because i was just like,
"no this is sacrosanct. i dunno why. it'll come to me one day." and then when i was pushed
by a bunch of mathematicians, we came up with the correct
physical explanation, which i can get to, but it's the minimum, and it's really important, is the minimum. and the reason i knew
the minimum was right is 'cause we could measure it. so almost before this paper came out, we published papers,
explain how you can measure the assembly index of molecules. - okay, so that's not so
trivial to figure out. so when you look at an object, we could say a molecule, we could say object more generally. to figure out the minimum number of steps it takes to create that object, that doesn't seem like
a trivial thing to do. - so with molecules, it's not trivial, but it is possible
because what you can do. and because i'm a chemist, so i'm kind of like i
see the lens of the world through just chemistry. i break the molecule apart, break bonds. and if you take a molecule
and you break it all apart you have a bunch of atoms, and then you say okay i'm
going to then take the atoms and form bonds and go up the chain of events to make the molecule. and that's what made me realize, take a toy example,
literally a toy example, take a lego object which is
broken up of lego blocks. so you could do exactly the same thing. in this case, the lego blocks
are naturally the smallest, they're the atoms in the actual
composite lego architecture. but then, if you maybe take, you know, a couple of blocks and put
them together in a certain way, maybe they're offset in some way. that offset is on the memory, you can use that offset again
with only a penalty of one, and you can then make a square,
triangle, and keep going. and you remember those
motifs on the chain. so you can then leap from the start, with all the lego blocks or atoms just laid out in front of you and say right, i'll take you, you, you, connect, and do the least amount of work. so it's really like the
smallest steps you can take on the graft to make the object. and so for molecules, it
came relatively intuitively, and then we started to
apply it to language. we've even started to apply
it to mathematical theorems. but i'm so well outta my depth. but it looks like you can
take a minimum set of axioms and then start to build up kind of mathematical architectures
in the same way, and then the shortest path to get there is something interesting
that i don't yet understand. - so what's the computational complexity of figuring out the shortest
path with molecules, with language, with mathematical theorems? it seems like once you have the fully constructed lego castle or whatever your favorite lego world is, figuring out how to get there from the basic building blocks. is that hard problem? - it's a hard problem, but actually if you look at it. so the best way to look at it. for this, take a molecule. so if the molecule has 13 bonds, first of all take 13
copies of the molecule and just cut all the
bonds, so cut 12 bonds, and then you just put them in order. and then, that's how it works. and you keep looking
for symmetry or copies, so you can then shorten it as you go down, and that becomes
combinatorially quite hard. for some natural product molecules, it becomes very hard. it's not impossible, but we're looking at the
bounds on that at the moment. but as the object gets bigger, it becomes really hard. and the that's bad news. but the good news is there are shortcuts. and we might even be able
to physically measure the complexity without
computationally calculating it, which is kind of insane. - [lex] wait, wait, how would you do that? - well, in the case of a molecule, so if you shine light on a molecule, let's take it infrared, the molecule has each of the bonds absorbs the infrared differently in with what we call the fingerprint region. and because it's quantized as well, you have all these discreet
kind of absorbances. and my intuition, after we realized we could
cut molecules up in mass spec, that was the first go at this. we did it with using infrared. and the infrared gave us an even better correlation assembly index. and we used another technique as well in addition to infrared, called nmr, nuclear magnetic resonance, which tells you about the number of different magnetic
environments in a molecule, and that also worked out. so we have three techniques which each of them independently gives us the same, or tending towards the same, assembly index from a molecule that we can calculate mathematically. - [lex] okay, so these are all methods of mass spectrometry, mass spec. you scan a molecule, it gives you data in the form of a mass spectrum. and you're saying that the data correlates to the assembly index? - [lee] yeah. - how generalizable is that shortcut, first of all to chemistry, and second of all beyond that? 'cause that seems like a nice hack, and you're extremely knowledgeable about various aspects of chemistry, so you can say, okay, it kinda correlates. but, you know, the whole idea
behind assembly theory paper and perhaps why it's so controversial is that it reaches bigger, it reaches for the bigger general theory of objects in the universe. - yeah, i'd say so. i'd agree. so, i've started assembly theory of emoticons with my
lab, believe it or not. so we take emojis, pixelate them, and work out the assembly
index of the emoji, and then work out how
many emojis you can make on the path of the emoji. so there's the uber emoji from which all other emojis emerge, so you can then take a photograph, and by looking at the shortest path, by reproducing the pixels
to make the image you want, you can measure that. so then you start to be
able to take spatial data. now there's some problems there. what is then the definition of the object? how many pixels? how do you break it down? and so we're just learning
all this right now. - how do you begin to
compute the assembly index of a graphical like a set
of pixels on a 2d plane that form a thing? - so you would first of all
determine the resolution. what is your xy, and what are the number
on the x and y plane, and then look at the surface area, and then you take all your emojis and make sure they're all
looked at the same resolution, and then we would basically then do exactly the same thing we
would do for cutting the bonds. you'd cut bits out of the emoji. you'd have a bag of pixels, and you would then add
those pixels together to make the overall emoji. - wait, wait a minute. but, like, first of all, i mean, this is at the core
sort of machine learning and computer vision. not every pixel's that important. and there's like macro features, there's micro features and
all that kind of stuff. - [lee] exactly. - like, you know, the eyes
appear in a lot of them, the smile appears in a lot of them. - so in the same way in chemistry we assume the bond is fundamental. what we're doing here is
we assume the resolution at the scale at which
we do it is fundamental, and we are just working that out. and you are right, that
will change, right? because as you take your lens out a bit, it will change dramatically. but it's just a new way of looking at not just compression, what we do right now in
computer science and data, one big kind of misunderstanding as assembly theory is telling you about how compressed the object is. that's not right. it's a how much information is required on a chain of events. 'cause the nice thing is, when you do compression
in computer science, we're wandering a bit here, but it's kind of worth wandering i think. and you assume you have
instantaneous access to all the information in the memory. in assembly theory, you say, no, you don't get access to that memory until you've done the work. and then when you've done
access to that memory, you can have access but
not to the next one. and this is how in assembly theory we talk about the four universes, the assembly universe,
the assembly possible, and the assembly contingent, and then the assembly observed. and they're all scales in
this combinatorial universe. - yeah. can you explain each one of them? - yep, so the assembly
universe is like anything goes, it's just combinatorial kind
of explosion in everything. - [lex] so that's the biggest one? - [lee] that's the
biggest one. it's massive. - assembly universe, assembly possible, assembly contingent, assembly observed, and the y-axis is assembly steps in time. and, you know, and the x-axis is as the thing expands through time, more and more unique objects appear. - so assembly universe, everything goes. assembly possible, laws
of physics come in. in this case, in chemistry bonds. so that means- - [lex] those are extra
constraints, i guess. - yes, and they're the only constraints. they're the constraints at the base. so the way to look at is
you've got all your atoms, they're quantized and you
can just bang them together. so in the way in computer science speak, i suppose the assembly universe is just like no laws of physics, things can fly through mountains, beyond the speed of light. in the assembly possible, you have to apply the laws of physics, but you can get access to all
the motifs instantaneously with no effort. so that means you could make anything. then the assembly contingent says, no, you can't have access to
the highly assembled object in the future until you've
done the work in the past on the causal chain, and that's really the
really interesting shift where you go from assembly
possible to assembly contingent. that is really the key
thing in assembly theory that says you cannot just
have instantaneous access to all those memories. you have to have done the work somehow, the universe has to have somehow built a system that allows
you to select that path rather than other paths. and then the final thing, the assembly observed
is basically us saying, oh, these are the things we actually see. we can go backwards now and understand that they have been created
by this causal process. - but wait a minute. so when you say the
universe has to construct the system that does the work, is that like the environment that allows for, like, selection? - yeah.
- so that's the thing that does the selection? - you could think about in terms of a von neumann constructor
versus a selection of ribosome, tesla as a plant,
assembling teslas, you know? the difference between the
assembly universe in tesla land and the tesla factory is everyone says, "no, teslas are just easy,
they just spring out. you know how to make them all." at tesla factory, you have
to put things in sequence and out comes a tesla. - so you're talking about the factory? - yes. this is this is really nice. super important point is that when i talk about the universe having a memory or there's some magic, it's not that. it's that tells you that there must be a process encoded somewhere in physical reality, be it a cell, a tesla factory, or something else that is making that object. i'm not saying there's
some kind of woo-woo memory in the universe, you know,
morphic resonance or something, i'm saying that there is
an actual causal process that is being directed,
constrained in some way. so it's not kind of
just making everything. - yeah, but, lee, what's the factory that made the factory? so first of all, you
assume the laws of physics has just sprung to
existence at the beginning. those are constraints. but what makes the factory the environment that does the selection? - well, it's the first
interesting question that i want to answer out of four. i think the factory
emerges in the interplay between the environment and the objects that are being built. i'll have a go at explaining
to you the shortest path. so why is the shortest path important? i'm gonna have to go with
chemistry for a moment then abstract it. so imagine you've got
an given environment, that you have a budget of atoms you're just flinging together. and the objective of those atoms that are being flung together, in say molecule a, they decompose. so molecules decompose over time. so the molecules in this environment, in this magic environment, have to not die, but they do die. they have a half-life. so the only way the
molecules can get through that environment out the other side. let's pretend the environment is a box, you can go in and out without dying. and there's just an infinite
supply of atoms coming, well, a large supply. the molecule gets built, but the molecule is able to
template itself being built and survives in the environment, will basically reign supreme. now let's say that that
molecule takes 10 steps and it's using a finite
set of atoms, right? now let's say another molecule, smart-ass molecule
we'll call it, comes in, and can survive in that
environment and can copy itself, but it only needs five steps. the molecule that only needs five steps, 'cause both molecules are being destroyed but they're creating themselves faster than they can be destroyed, you can see that the
shortest path reigns supreme. so the shortest path tells us
something super interesting about the minimal amount
of information required to propagate that motif in time and space, and it seems to be like some
kind of conservation law. - so one of the intuitions you have is the propagation of motifs, in time, will be done by the things
that can construct themselves in the shortest path. so like, you can assume
that most of the objects in the universe are built
in the most efficient way? big leap i just took there. - yes and no, because
there are other things. so in the limit, yes, because you want to tell the difference between things that
have required a factory to build them and just random processes. but you can find instances where the shortest path isn't taken for an individual object,
a individual function. and people go, "ah, that means the shortest path isn't right." and then i say, "well, i don't know, i think it's right still because there are other driving forces, so it's not just one molecule. now that you start to
consider two objects, you have a joint assembly space, and now it's a compromise between not just making a
and b in the shortest path, you wanna be able to make a
and b in the shortest path, which might mean that
a is slightly longer. you have a compromise. so when you see slightly more nesting in the construction when
you take a given object that can look longer, well, that's because the overall function is the object is still
trying to be efficient. and this is still very hand-wavy. i maybe have no legs to stand on, but we think we're getting
somewhere with that. - and there's probably some
parallelization, right? - yeah.
- so this is not sequential, the building is. yeah, i guess-
- no, you're right. - when you're talking
about complex objects, you don't have to work sequentially, you can work in parallel. you can get your friends
together and they can- - yeah. and the thing we're working on right now is how to understand
these parallel processes. now there's a new thing we've introduced called assembly depth. and assembly depth can be lower than the assembly index for a molecule when they're cooperating together, 'cause exactly, parallel
processing is going on. and my team have been working
this out in the last few weeks because we're looking at
what compromises does nature need to make when it's
making molecules in a cell. and i wonder if, you know, i'm maybe like, well, i'm always leaping
out of my competence, but in economics, i'm just wondering if you could apply this in an economic process. it seems like capitalism is very good at finding the shortest
path, you know, every time. and there are ludicrous things that happen because actually the cost
function's been minimized. and so i keep seeing parallels everywhere where there are complex nested systems, where if you give it enough time and you introduce a bit of heterogeneity, the system readjusts and
finds a new shortest path. but the shortest path isn't
fixed on just one molecule now, it's in the actual existence
of the object over time. and that object could be a city, it could be a cell, it could be a factory. but i think we're going
way beyond molecules and my competence, so probably we should
go back to molecules. but, hey. - all right, before we get too far, let's talk about the assembly equation. okay, how should we do this? lemme just even read
that part of the paper. "we define assembly as the total amount of selection necessary
to produce an ensemble of observed objects,
quantified using equation 1." the equation basically has a on one side, which is the assembly of the ensemble, and then a sum from 1 to n, where n is the total
number of unique objects. and then there is a
few variables in there, that include the assembly index, the copy number, which we'll talk about. i don't remember you talking about that. that's an interesting addition, and i think a powerful one. has to do with that you can create pretty
complex objects randomly. and in order to know
that they're not random, that there's a factory involved, you need to see a bunch of them. that's the intuition there. it's a interesting intuition. and then some normalization. what else is a n? - n - 1. just to make sure that one object could be a one-off and random. and then you have more
than one identical object. that's interesting. - when there's two of a thing. that's interesting.
- two of a thing is super important, especially if the assembly index is high. - so we could say several questions here. one, let's talk about selection. what is this term, selection? what is this term, evolution,
that we're referring to? which aspect of darwinian evolution are we referring to
that's interesting here? - yeah so, you know the paper, we should talk about
the paper for a second. the paper, what it did
is it kind of annoyed- we didn't annoy. i mean, it got the attention, and obviously the angry
people were annoyed. - there's angry people in
the world. that's good. - so what happened is the
evolutionary biologists got angry. we were not expecting that. 'cause we thought evolutionary
bodies would be cool. i knew that some, not many, computational complexity
people will get angry, 'cause i've kinda been poking them, and maybe i deserved it. but i was trying to poke
them in a productive way. and then the physicists kind of got grumpy because the initial
conditions tell everything. the prebiotic chemist got slightly grumpy because there's not
enough chemistry in there. and then finally, when
the creationist said it wasn't creationist enough, i was like, i've done my job. - because you're basically saying that physics is not
enough to tell the story of how biology emerges. - i think so.
- and then they said a few physics is the beginning
and the end of the story. - yeah. so what happened is the
reason why people put the phone down on the call of the paper. i mean, if you're the reading the paper like a phone call, they
got to the abstract. and in the abstract- - [lex] first sentence is pretty strong. - the first two sentences
caused everybody- - "scientists have grappled with reconciling biological evolution with the immutable laws of the
universe defined by physics." - true, right? there's nothing wrong with that statement. totally true. - yeah.
- next one. "these laws underpin life's origin, evolution and the development of human culture and technology, yet they do not predict the
emergence of these phenomena." wow. first of all, we should
say the title of the paper. this paper was accepted
and published in "nature". the title is "assembly theory explains and quantifies selection and evolution". a very humble title. and the entirety of the paper i think presents interesting
ideas but reaches high. - i would do it all again. this paper was actually
on the preprint server for over a year. - you regret nothing. - i think, yeah, i don't regret anything. - you and frank sinatra did it your way. - what i love about being a scientist is kind of sometimes, 'cause i'm a bit dim and i don't understand
what people are telling me. i wanna get to the point. this paper says, hey, the laws
of physics are really cool, the universe is great, but it's not intuitive that you just run the standard model and get life out. i think most physicists might go, yeah, you know, we can't just go back and say that's what happened 'cause physics can't explain
the origin of life yet. that doesn't mean it won't or can't, okay? just to be clear, sorry, intelligent designers,
we are gonna get there. second point, we say that evolution works but we don't know how evolution got going, so biological evolution
and biological selection. so for me, this seems
like a simple continuum. so when i mentioned
selection and evolution in the title, i think,
and in the abstract, we should have maybe prefaced that and said nonbiological selection and nonbiological evolution, and then that might have made
it even more crystal clear. but i didn't think that
evolutionary biology should be so bold to claim ownership of selection and evolution. and secondly, a lot of
evolutionary biologists seem to dismiss the
origin of life question, just say it's obvious. and that causes a real
problem scientifically. when the physicists are like, we own the universe, the universe is good, we explain all of it, look at us. and the biologists say
we can explain biology. and the poor chemist in the middle going, but, hang on. (laughing) and this paper kinda says, hey, there is an interesting disconnect between physics and biology. and that's at the point at which memories get made in chemistry through bonds. and hey, let's look at this close and see if we can quantify it. so yeah, i mean i never expected the paper to kind of get that much interest. and still, i mean it's only been published just over a month ago now. - so just to link on the selection. what is the broader sense
of what selection means? - yeah, that's a really good. for selection, so this is where for me the concept of an object is
something that can persist in time and not die, but
basically can be broken up. so if i was gonna kind of bolster the definition of an objects. so if something can form and persist for a long period of time
under an existing environment that could destroy other, and i'm gonna use anthropomorphic terms, i apologize, but weaker
objects or less robust, then the environment
could have selected that. so a good chemistry example is if you took some carbon and you made a chain of carbon atoms. whereas, if you took some, i don't know, some carbon, nitrogen, and oxygen and made chains from those, you'd start to get different
reactions and rearrangements. so a chain of carbon atoms
might be more resistant to falling apart under
acidic or basic conditions versus another set of molecules. so it survives in that environment. so the acid pond the resistant
molecule can get through. and then that molecule goes
into another environment. so that environment now
maybe being acid pond is a basic pond, or maybe
it's an oxidizing pond. and so, if you've got carbon and it goes in an oxidizing pond, maybe the carbon starts to
oxidize and break apart. so you go through all these
kind of obstacle courses, if you like, given by reality. so selection happens
when a object survives in an environment for some time. but, and this is the
thing that's super subtle, the object has to be
continually being destroyed and made by a process. so it's not just about the object now, it's about the process
and time that makes it. 'cause a rock could just
stand on the mountainside for four billion years and
nothing happened to it. and that's not necessarily
really advanced selection. so for selection to
get really interesting, you need to have a turnover in time. you need to be continually
creating objects, producing them, what
we call discovery time. so there's a discovery time for an object. when that object is discovered, if it's say a molecule, that can then act on itself or the chain of events that caused itself to bolster its formation, then you go from discovery
time to production time, and suddenly you have more
of it in the universe, so it could be a
self-replicating molecule. and the interaction of the
molecule in the environment, in the warm little pond
or in the sea or wherever, in the bubble, could then start to build a
proto factory, the environment. so really, to answer your question, what the factory is. the factory is the environment, but it's not very autonomous, it's not very redundant, there's lots of things
that could go wrong. so once you get high
enough up the hierarchy of networks of interactions, something needs to happen, that needs to be compressed
into a smaller volume and made resistant or robust. because in biology, selection and evolution is robust. that you have error correction built in. you have really, you know, there's good ways of basically making sure propagation goes on. so really the difference between inorganic abiotic
selection and evolution, and evolution and stuff
in biology is robustness, the ability to survive in lots
of different environments. whereas, our poor little
inorganic soul molecule, whatever, just dies in lots of
different environments. so there's something
super special that happens from the inorganic molecule
in the environment, it kills it, to where you've got evolution and cells can survive everywhere. - well, how special is that? how do you know those
kinds of evolution factors aren't everywhere in the universe? - i don't. and i'm excited, 'cause i think selection isn't special at all. i think what is special is the history of the environments on earth that gave rise to the first cell that now, you know, has taken all those environments and is now more autonomous. and i would like to think that, you know, this paper could be very wrong, (chuckles) but i don't think it's very wrong. it mean, it's certainly wrong, but it's less wrong than some
other ideas i hope, right? and if this inspires us to go and look for selection in the universe, 'cause we now have an equation where we can say we can
look for selection going on and say, oh, that's interesting, we seem to have a process that's giving us high copy number objects that also are highly complex. but that doesn't look
like life as we know it. and we use that and say, "oh, there's a hydrothermal vent. or there's a process going on, there's molecular networks." because the assembly
equation is not only meant to identify at the higher
end, advanced selection. what you get, i would call it in biology, your super advanced selection. and even, i mean, you could
use the assembly equation to look for technology and god forbid, we could talk about
consciousness and abstraction, but let's keep it primitive,
molecules and biology. so i think the real power
of the assembly equation is to say how much selection
is going on in this space. and there's a really simple
thought experiment i could do. is, you know, have a little petri dish, and on that petri dish,
you put some simple food. so the assembly index of all the sugars and everything is quite low. and you put a single e. coli cell. and then you say, i'm
gonna i'm gonna measure this amount of assembly in the box. so it's quite low, but the rate of change of assembly, the adt will go, voom sigmoidal as it eats all the food. and the number of e.
coli cells will replicate because they take all the food, they can copy themselves, the assembly index of all the molecules goes up, up, up, and up until the food is exhausted in the box. so now the e. coli's stop. i mean, die is probably a strong word. they stop respiring 'cause
all the food has gone. but suddenly the amount
of assembly in the box has gone up gigantically because
of that one e. coli factory has just eaten through, milled lots of other e. coli factories, run out of food and stopped. so in the initial box, although the amount of
assembly was really small, it was able to replicate and
use all the food and go up. and that's what we're trying
to do in the lab actually, is kinda make those kind of experiments and see if we can spot the emergence of molecular networks that
are producing complexity as we feed in raw materials and we feed a challenge, an environment, you know, we try and kill the molecules. and really that's the main kind of idea for the entire paper. - yeah, and see if you
can measure the changes in the assembly index
throughout the whole system. okay, what about if i
show up to a new planet, we go to mars or some other planet from a different solar system, how do we use assembly index
there to discover alien life? - very simply actually. let's say we'll go to mars
with a mass spectrometer with a sufficiently high resolution. so what you'll have to be able to do- so a good thing about mass spec is that you can select the
molecule from the mass, and then, if it's high enough resolution, you can be more and more sure that you're just seeing identical copies. you can count them. and then you fragment them and you count the number of fragments and look at the molecular weight. and the higher the molecular weight and the higher the number of fragments, the higher the assembly index. so if you go to mars
and you take a mass spec with a high enough resolution
and you can find molecules, and i'll give a guide on earth, if you could find molecules say greater than 350 molecular weight
with more than 15 fragments, you have found artifacts
that can only be produced, at least on earth, by life. and now you would say, oh, well, maybe the geological process. i would argue very vehemently
that that is not the case. but we can say, look, if you don't like the cutoff on earth, go up higher, 30, 100, right? because there's gonna be a point where you'll find a molecule with
so many different parts the chances of you getting a molecule that has 100 different parts and finding a million identical copies, you know, that's just impossible, that could never happen in
an infinite set of universes. - can you just linger on
this copy number thing? a million different copies. what do you mean by copies, and why is the number of copies important? - yeah, that was so interesting. i always understood the copy
number was really important but i never explained
it properly for ages. it goes back to this. if i give you a, i dunno, a really complicated molecule and i say it's complicated, you could say, hey,
that's really complicated, but is it just really random? and so i realized that ultimate randomness and ultimate complexity
are indistinguishable until you can see a
structure in the randomness. so you can see copies. - so copies implies structure. - [lee] yeah, the factory. - i mean, there's a deep
profound thing in there. 'cause, like, if you just
have a random process, you're going to get a lotta complex, beautiful sophisticated things. what makes them complex
in the way we think life is complex or something like a factory that's operating under
a selection processes, there should be copies. is there like some looseness about copies? like, what does it mean for
two objects to be equal? - it's all to do with the the telescope or the microscope you're using. and so, at the maximum resolution. so then the nice thing about chemists is they have this concept of the molecule and they're all familiar
with the molecule, and molecules you can hold, you know, on your hand, lots of
them, identical copies. a molecule's actually a super
important thing in chemistry. to say, look, you can
have a mole of a molecule, so an avogadro's number of
molecules and they're identical. what does that mean? that means that the molecular composition, the bonding and so on, the configuration is indistinguishable. you can hold them together, you can overlay them. so the way i do it is if i say, here's a bag of 10 identical molecules, let's prove they're identical. you pick one out of the bag and you basically observe
it using some technique, and then you take it away, and then you take another one out. if you observe it using technique and you see no differences,
they're identical. it's really interesting to get right, because if you take say two molecules. molecules can be in different vibrational and rotational states, they're moving all the time. so with this respect, identical molecules
have identical bonding. in this case, we don't
even talk about chirality 'cause we don't have a chirality detector. so two identical molecules in one conception assembly theory, basically considers both
hands as being the same. but of course, they're
not, they're different. as soon as you have a chiral distinguisher to detect the left and the right hand, they become different. and so it's to do with
the detection system that you have and the resolution. - so i wonder if there's an art in science to which detection system is used when you show up to a new planet? so like, you're talking
about chemistry a lot today. we have kind of standardized
detection systems, right? of how to compare molecules. so, you know, when you
start to talk about emojis, and language, and mathematical theorems, and, i don't know, more
sophisticated things at different scale, at a smaller scale than molecules, at a larger
scale of than molecules. like if we look at the
difference between you and me, lex and lee, are we the same? are we different? - sure, i mean of course
we're different close up, but if you zoom out a little bit, it will morphologically look the same. you know, high in characteristics, hair length, stuff like that. - well, also like the species. - [lee] yeah, yeah, yeah. - and also, there's a sense
why we're both from earth. - yeah, i agree. i mean, this is the power of
assembly theory in that regard. so the way to look at it, if you have a box of objects, if they're all indistinguishable, we're using your technique, what you then do is you then
look at the assembly index. now, if the assembly index
of them is really low, right? and they're all indistinguishable, then they're telling you that you have to go to another resolution. you know, it's kind of a sliding scale. it's kind of nice.
- yeah, got it. so those two kind of are
at tension with each other, the number of copies
in the assembly index. - [lee] yeah. - that's really, really interesting. so okay, so you show up to a new planet, you'll be doing what? - [lee] i would do mass spec. - on a sample of what? first of all, like how big
of a scoop do you take? do you just take a scoop? so we're looking for primitive life. - yeah, so if you're just going to mars or titan or enceladus or somewhere. so a number of ways of doing it. so you could take a large scoop or you go through the
atmosphere and detect stuff. and you could make a life meter, right? one of sara's colleagues,
an asu, paul davies, keeps calling it a life meter. which is quite a nice idea, because if you think about it, if you've got a living system that's producing these
highly complex molecules and they drift away
and they're in a highly kind of demanding environment, they could be burnt, right? so they could just be falling apart. so you want to sniff a
little bit of complexity and say, warmer, warmer, warmer. oh, we've found life. we've found the alien. we found the alien elon
musk smoking a joint in the bottom of the cave on mars, or elon himself, whatever, right? and say, okay, found it. so what you can do is
the mass spectrometer, you could just look for
things in the gas phase, or you go on the surface, drill down, because you want to
find molecules that are- you've either gotta find
the source living system, because the problem with
just looking for complexity is it gets burnt away. so in a harsh environment, on, say, the surface of mars, there's a very low probability that you're gonna find
really complex molecules because of all the radiation and so on. if you drill down a little bit, you could drill down a bit into soil that's billions of years old, then i would put in some
solvent, water, alcohol, or something, or take a scoop, make it volatile, put it
into the mass spectrometer, and just try and detect a high complexity, high abundant molecules. and if you get them, hey presto, you can have evidence of life. wouldn't that then be
great if you could say, okay, we found evidence of life, now we want to keep the
life meter keep searching for more and more complexity until you actually find living cells. you can get those new living cells, and then you could
bring them back to earth or you could try and sequence them. you could see that they have
different dna and proteins. - go along on the gradient
of the life meter. how would you build a life meter? let's say we're together starting a new- - just a mass spectrometer.
- a new company launching a life meter.
- a mass spectrometer would be the first way of doing it. just take-
- no, no, no. but that's one of the
major components of it. but i'm talking about like, what if it's a device, and branding, logo, we gotta talk through that. that's later. but what's the input? like how do you get to a metered output? - so, i would take my life
meter, our life meter. there you go.
- thank you. - yeah, you're welcome. would have both infrared and mass spec. so it would have two ports, so we could shine the light. and so what it would do is you
would have a vacuum chamber, and you would have an
electrostatic analyzer, and you'd have a monochromator
to producing infrared. so you'd take a scoop of the sample, put it in the life meter. it would then add a solvent
or heat up the sample so some volatiles come off. the volatiles would then be put into the mass spectrometer into the electrostatic trap, and you'd weigh the
molecules and fragment them. alternatively, you'd shine
infrared light on them and count the number of bands. but you'd have to, in that case, do some separation, 'cause you want to separate in- and so, in mass spec, it's really nice and convenient 'cause you can separate electrostatically, but you need to have that. - can you do it in real time? - yeah, pretty much. yeah, so let's go all the way back. okay, we really gonna get
the lex and lee's life meter. - oh yeah, lex and lee. it's good ring to it. - all right, so you have a vacuum chamber, you have a little nose. the nose would have a packing material. so you would take your sample, add it onto the nose,
add a solvent or a gas. it would then be sucked up the nose and that would separated using
what we call chromatography. and then, as each band comes off the nose, we'll then do mass spec and infrared. and in the case of the infrared, count the number of bands. in the case of mass spec, count the number of
fragments and weigh it. and then, the further up
in molecular weight range for the mass spec and the number of bands, you go up and up and
up from the, you know, dead, interesting, interesting,
over the threshold, oh my gosh, earth life. and then right up to the batshit crazy, this is definitely, you know, alien intelligence that's
made this life, right? you could almost go all the way there. same with the infrared. and it's pretty simple. the thing that is really problematical is that for many years, decades, what people have done,
and i can't blame them, is they've rather been
obsessing about small biomarkers that we find on earth, amino acids, like single amino acids or evidence of small molecules and these things, and looking for those rather
that looking for complexity. the beautiful thing about
this is you can look for complexity without
earth chemistry bias or earth biology bias. so assembly theory is
just a way of saying, hey, complexity in abundance
is evidence of selection, that's how our universal
life media will work. - complexity in abundance
is evidence of selection. okay, so let's apply
our life meter to earth. you know, if we were just to apply assembly index
measurements to earth, what kinda stuff are we going to get? what's impressive about some
of the complexity on earth? - so we did this a few years ago when i was trying to
convince nasa and colleagues that this technique could work. and honestly, it's so funny
because everyone's like, "no, ain't gonna work." because a chemist was saying, "of course there are
complicated molecules out there you can detect that just from randomly." and i was like, "really?" that's a bit like, i don't know, someone saying of course darwin's textbook was just written randomly by
some monkeys and a typewriter. just for me it was like, really? and i pushed a lot on the chemists now, and i think most of them are on board, but not totally. i really had some big arguments. but the copy number caught there, 'cause i think i confused
the chemist by saying, "one-off," and then when i made it clear about the copy number, i think that made it a little bit easier. - just to clarify, a chemist might say that, of course, out there, outside of earth, there's complex molecules? - yes.
- okay. and then you're saying, "wait a minute, that's like saying of course there are aliens out there?" - [lee] yeah, exactly that. - okay, but you clarify
that that's actually a very interesting question and we should be looking
for complex molecules of which the copy number
is two or greater. - yeah, exactly. so on earth, to coming back to earth, what we did is we took
a whole bunch of samples and we were running prebiotic
chemistry experiments in the lab. we took various inorganic minerals and extracted them, look at the volatile, because there's a special
way of treating minerals and polymers in assembly theory. in our life machine,
we're looking molecules. we don't care about polymers
because they're not volatile, you can't hold them. if you can't discern
that they're identical, then it's very difficult
for you to work out if there's undergone selection or they're just a random mess. same with some minerals, but we can come back to that. so basically, what you do, we got a whole loads of samples. in organic ones, we've got scotch whiskey, and also took a ardbeg, which is one of my favorite whiskeys, which is very peaty, and another-. - [lex] what does peaty mean? in scotland in islay, which is a island, the whiskey is led to mature in barrels. and it's said that the peat, the complex molecules in the peat, might find their way
through into the whiskey. and that's what gives it
this intense brown color and really complex flavor. it's literally molecular
complexity that does that. and so, you know, vulc
is the complete opposite. it's just pure, right? - [lex] so the better the whiskey, the higher the assembly index, or the higher assembly index,
the better the whiskey. - that's what i mean. i really love the deep,
peaty scottish whiskeys. near my house, there is one of the lowland distilleries
called glengoyne. it's still beautiful
whiskey but not as complex. so for fun, i took some
glengoyne whiskey in our bag and put them into the mass spec and measured the assembly index. i also got e. coli. so, the way we do it, take the e. coli, break the cell apart, take it all apart. and also got some beer. and people were ridiculing us, saying that, "oh, beer is
evidence of complexity." one of the computational complexity people who was just throwing- kind of, he's very vigorous in his disagreement of assembly theory. he was he just saying, you know, "you don't know what you're doing. even beer is more complicated than human." what he didn't realize is
that it's not beer per se, it's taking the yeast
extract, taking the extract, breaking the cells,
extracting the molecules, and just looking at the
profile of the molecules, see if there's anything
over the threshold. and we also put in a really
complex molecule, taxol. so we took all of these, but also nasa gave us, i think, five samples, and they
wouldn't tell us what they are. they said, "no, we don't believe you can get this to work." and they really, you know, they gave us some super complex samples. and they gave us two fossils. one that was a million years old and one was at 10,000 years old, something from antarctica's seabed. they gave us some immerses and
meteorite and a few others. put them through the system. so we took all the samples, treated them all identically, put them into mass spec, fragmented them. and in this case, implicit in the measurement was- in mass spec, you only detect peaks when you've got more than, let's say, 10,000 identical molecules. so the copy number's already baked in but wasn't quantified, which is super important there. that was in the first paper, 'cause i was like, "it's
abundant, of course." and when he then took it all out, we found that the biological samples gave you molecules that had an assembly index greater than 15. and all the abiotic
samples were less than 15. and then we took the nasa samples, and we looked at the
ones with more than 15 and less than 15, and we gave them back to nasa. and like, "oh gosh. yep, dead, living, dead, living. you got it." and that's what we found on earth. - [lex] so that's a success? - yeah, a resounding success. - well, can you just go back
to the beer and the e. coli? so what's the assembly index on those? - so what you were able to do is like, we found high assembly
index molecules originating from the beer sample
and the e. coli sample. - [lex] so the yeast and the beer. - i mean though, i didn't
know which one was higher. we didn't really do any detail there because now we are doing that. because one of the things we've done, it's a secret, but i
can tell you. (laughing) - nobody's listening. - well, is that we've just mapped the tree of life using assembly theory, 'cause everyone said that you
can't do anything in biology. and what we're able to do is, i think there's two ways
of doing tree of life- well, three ways, actually. - yeah, what's the tree of life? - so the tree of life is
basically tracing back the history of life on earth for all the different species going back, who evolved from what, and it all goes all the way back to the first kind of life
forms, and they branch off. and like, you have plant kingdom, the animal kingdom, the fungi kingdom, you know, and different
branches all the way up. and the way this was classically done. and i'm no evolutionary biologist. the evolutionary biologists
tell me every day, at least 10 times. i want to be one though. i kinda like biology, it's kinda cool. - [lex] yeah, it's very cool. it's evolutionary.
- but basically what darwin, and mendel, and all of these people do, it's just they draw pictures, right? and they text though. they were able to draw pictures and say, "oh, these look like common classes." - yeah. they're artists, really,
they're just, you know? - but they we're able to
find out a lot, right, in looking at vibrates and vibrates, cambrian explosion and all this stuff. and then came the genomic revolution, and suddenly everyone
used gene sequencing. and craig venter is a good example. i think he's gone around
the world in his yacht just taking up samples
looking for new species, where he's just found new species of life just from sequencing. it's amazing. so you have taxonomy,
and you have sequencing, and then you can also do a little bit of kind of molecular
kind of archeology like, you know, measure the samples and kind of form some inference. what we did is we were
able to fingerprint. we took a load of random
samples from all of biology, and we used mass spectrometry. and what we did now is not just look for individual molecules but we looked for coexisting molecules where they had to look at
their joint assembly space, where we were able to cut them apart and undergo recursion in the mass spec and infer some relationships. and we were able to recapitulate the tree of life using mass spectroscopy, no sequencing and no drawing. - all right, can you try to say that again with a little more detail? so, recreating. what does it take to
recreate the tree of life? what does the reverse engineering
process look like here? - so what you do is you
take an unknown sample, you bung it into the mass spec. 'cause this comes from what you're asking, like, what do you see in e. coli? and so in e. coli, it's not that the most sophisticated cells on earth make the most
sophisticated molecules. it is the coexistence of lots of complex molecules above a threshold. and so what we realize
is you could fingerprint different life forms. so fungi make really
complicated molecules. why? 'cause they can't move. they have to make everything on site. whereas, you know, some
animals are like lazy. they can just go eat the fungi and they don't need to make very much. and so what you do is, so you take, i don't
know, the fingerprint, maybe the top number of high
molecular weight molecules you find in the sample, you fragment them to get
their assembly indices, and then what you can do is you can infer common origins of molecules. when the reverse engineering
of the assembly space, you can infer common roots and look at what's called
the joint assembly space. but let's translate that
into the experiment. take a sample, bung it in the mass spec, take the top say 10
molecules, fragment them, and that gives you one fingerprint. then you do it for another sample, you get another fingerprint. now the question is you say, hey, are these samples
the same or different? and that's what we've been able to do. and by basically looking
at the assembly space that these molecules create. without any knowledge of assembly theory, you are unable to do it. with the knowledge of assembly theory, you can reconstruct the tree. - how does knowing if
they're the same or different give you the tree? - let's go to two leaves on different branches on the tree, right? what you can do, by counting
the number of differences, you can estimate how far
away their origin was. - got it.
- and that's all we do. and it just works. but when we realized you
could even use assembly theory to recapitulate the tree of
life with no gene sequencing, we were like, "huh." - so this is looking at samples that exist today in the world. what about like things
that no longer exist? i mean, the tree contains
information about the past. some of it is gone. - yeah, absolutely. i would love to get old fossil samples and apply assembly theory mass spec and see if we can find new forms of life. they are no longer
amenable to gene sequencing 'cause the dna is all gone. 'cause dna and rna is quite unstable, but some of them are complex molecules. it might be there, it
might give you a hint of something new. or, wouldn't it be great
if you find a sample that's worth really persevering and doing, you know, doing the proper extraction to, you know, pcr and so on, and then sequence it, and then put it together. - so when a thing dies, you can still get some
information about its complexity. - yeah. and it appears that
you can do some dating. now, there are really good techniques. there's radiocarbon dating. there is longer dating, going and looking at
radioactive minerals and so on. and you can also, in bone, you can look at the- what happens after something dies, you get what's called racemization, where the chirality in the
polymers basically changes and you get decomposition. and the rate of the deviation
from the pure enantiomer to the mixture, it gives you
a timescale on it, half-life, so you can date when it died. i wanna use assembly theory
to see if i can use it and date death and things, and trace the tree of life, and also decomposition of molecules. - [lex] do you think it's possible? - oh yeah. without a doubt. it may not be better. 'cause like, i was just at a conference where some brilliant people were looking at isotope enrichment and looking at how life enriches isotopes, and there are really sophisticated
stuff that they're doing. but i think there's some
fun to be had there, because it gives you another dimension of dating how old is this
molecule in terms of- or, more importantly, how long ago was this
molecule produced by life? the more complex the molecule, the more prospect for decomposition, oxidation, reorganization,
loss of chirality and all that jazz. but what life also does is it enriches, as you get older, the
the amount of carbon 13 in you goes up because
of the way the bonding is in carbon 13. so it has a slightly different
bond strength than you, it's called the kinetic isotope effect. so you can literally date
how old you are, you know, or when you stop metabolizing. so you could date someone
how old they are, i think. i'm making this up, this might be right, but i think it's roughly right. the amount of carbon 13 you have in you, you can kind of estimate how old you are. - how old living humans
are or living organisms? - yeah, like you could say, oh, this person is 10 years old, and this person 30 years old because they've been
metabolizing more carbon, and they've accumulated it. that's the basic idea. it's probably a completely
wrong timescale but- - signatures of chemistry are fascinating. so you've been saying a
lot of chemistry examples for assembly theory. what if we zoom out and look
at a bigger scale of an object, you know, like really complex objects, like humans or living organisms that are made up of, you know, millions or billions of other organisms? how do you try to apply
assembly theory to that? - at the moment, we should be able to do
this to morphology in cells. so we're looking at cell surfaces. and really, i'm trying to extend further. it's just that, you know, we work so hard to get this paper out and people to start discussing the ideas. but it's kinda funny, because i think the
penny is falling on this. - what's it mean for
a penny to be falling? - i mean, the penny's dropped, right? 'cause a lotta people were like, "it's rubbish, it's rubbish. you've insulted me. it's wrong." and, you know, i mean
the paper got published on the 4th of october. it had 2.3 million
engagements on twitter, right? and it's been downloaded over
a few hundred thousand times. and someone actually said to me, wrote to me and said, "this is an example of
really bad writing," and what not to do. and i was like, if all of my papers got read this much, 'cause that's the objective. if i have a publishing, a paper, i want people to read it. i wanna write that badly again. - yeah. i don't know what's the deep insight here about the negativity in the space. i think it's probably the immune system of the scientific community making sure that there's no bullshit
that gets published. and that it can overfire, it can do a lot of damage, it can shut down conversations in a way that's not productive. - i mean, i'll answer your question about the hierarchy in assembly, but let's go back to the perception, people saying the paper was badly written. i mean, of course we could improve it. we could always improve the clarity. - let's go there before
we go to the hierarchy. you know, it has been criticized
quite a bit, the paper. what has been some criticism
that you found most powerful, like, that you can understand
and can you explain it? - yes. the most exciting criticism came from the evolutionary biologist, telling me that they thought that origin of life was a solved problem. and i was like, whoa,
we're really onto something because it's clearly not. and then when you poked them on that, they just said, "no, you
don't understand evolution." and i said, "no, no, i don't think you
understand that evolution had to occur before
biology and there's a gap." for me, that misunderstanding, and that did cause an immune response which was really interesting. the second thing was the
fact that physicists- well, the physicists were
actually really polite, right? and really nice about it. but they just said, "huh, we're not really sure about the initial conditions thing." but this is a really big debate that we should certainly get into because you know the emergence of life was not encoded in the initial
conditions of the universe. and i think assembly theory
shows why it can't be. - okay, sure. if you could say that again. - the the emergence of life was not and cannot in principle be encoded in the initial
conditions of the universe. - just to clarify what you
mean by life is like what? high assembly index objects? - yeah. and this goes back to
your favorite subject. - what's that?
- time. (both chuckling) - right, so why? what does time have to do with it? - i mean, probably we
can come back to it later if we have time. i think i now understand
how to explain how- you know, lots of people got angry with the assembly paper, but also the ramifications of this is how time is fundamental in the universe and this notion of combinatorial spaces. and there are so many layers on this, but i think you have to become
an intuitionist mathematician and you have to abandon
platonic mathematics. and also, platonic mathematics
has left physics astray. but there's a lot unpack there. so we can go to the- - platonic mathematics. okay. the evolutionary biologists criticize it because the origin of life is understood and it doesn't require an explanation that involves physics. - yeah.
- that's their statement. - well, i mean, they said
lots of confusing statements. basically, i realized the
evolutionary biology community that were vocal, and some
of them were really rude, really spiteful and needlessly so, right? because look, you know, people misunderstand publication as well. some of the people has said, "how dare this be published in nature? this is, you know, what
a terrible journal." and i said to people, "look, this is this is a brand new idea that's not only
potentially going to change the way we look at biology, it's gonna change the way
we look at the universe." and everyone's, like, saying, "how dare you? how dare you be so grandiose?" i'm like, "no, no, no, this is not hype." we're not like saying we've invented some, i don't know, we've discovered a alien in a closet somewhere just for hype. we genuinely mean this to
genuinely have the impact or ask the question. and the way people jumped on that was a really bad
precedent for young people who wanna actually do something new because this makes a bold claim. and the chances are that it's not correct. but what i wanted to do
is a couple of things. is i wanted to make a bold claim that was precise and
testable and correctable. not another wooly information
in biology argument, information turing machine,
blah, blah, blah, blah, blah. a concrete series of statements that can be falsified and explored, and either the theory could
be destroyed or built upon. - well, what about the criticism of you're just putting
a bunch of sexy names on something that's already obvious? - yeah, that's really good. so the assembly index of
a molecule is not obvious. no one had measure it before. and no one has thought to
quantify selection complexity and copy number before in such
a primitive quantifiable way. i think the nice thing about this paper, this paper is a tribute to all the people that understand that biology does something very interesting. some people call it negentropy, some people call it, think about, you know, organizational principles. lots of people were not
shocked by the paper because they'd done it before. a lot of the arguments we got, some people said, "oh, it's rubbish. oh, by the way, i had this
idea 20 years before." i was like, "which one?" the rubbish part or the
really revolutionary part? so this kind of plucks
two strings at once. it plucked the there is
something interesting the biologies are, as
we can see around us, but we haven't quantified yet. and what this is, is the first
stab at quantifying that. so the fact that people
said this is obvious but it's also- so if it's obvious, why
have you not done it? - sure, but there's a
few things to say there. one is, you know, this is in part a philosophical framework
because, you know, it's not like you can apply this generally to any object in the universe. it's very chemistry focused. - yeah, well, i think you will be able to, we just haven't got there robustly. so if we can say how can we- let's go up a level. so if we go up from a level, let's go up from molecules to cells, 'cause you would jump to people and i jump to emoticons, and both were good and
they will be assembly. - [lex] yeah, let's stick with cells. yeah, good point. - so if we go from
molecules to assemblies, and let's take a cellular assembly. a nice thing about a cell is you can tell the
difference between a eukaryote and a prokaryote, right? the organelle are specialized differently. we then look at the cell surface, and the cell surface has
different glycosylation patterns and these cells will stick together. now let's go up a level. in multicellular creatures, you have cellular differentiation. now if you think about
how embryos develop, you go all the way back, those cells undergo differentiation on a causal way that's biomechanically a feedback between the
genetics and biomechanics. i think we can use assembly theory to apply to tissue types. we can even apply it to
different cell disease types. so that's what we're doing next, but we are trying to walk. you know, the thing is, i wanna leap ahead to go, well, we'll apply it to culture. but clearly, you can apply
it to memes and culture. and we've also applied assembly theory to cas, and not as you think. - [lex] cellular automata, by the way. - yeah, yeah, to cellular automaton, not just as you think. different ca rules were
invented by different people at different times. and one of my coworkers, a very talented chap, basically was like, "oh, i can realize that different people had different ideas with different rules, and they copied each other and made slightly different
cellular automaton rules, and they looked at them online." and so he was able to
affirm an assembly index and copy number of rule
whatever doing this thing. but i digress. but it does show you can
apply it at a higher scale. so what do we need to do to
apply assembly theory to things? we need to agree there's a
common set of building blocks. well, in a multicellular creature, you need to look back in time. so there is the initial cell, which a creature is fertilized
and then starts to grow, and then there is cell differentiation. and you have to then make that
causal chain both on those. so that requires development
of the organism in time. or if you look at the cell
surfaces and the cell types, they've got different features on the cell walls and inside the cell. so we're building up. but obviously, i wanna leap
to things like emoticons, language, mathematical theorems. - yeah, but that's a very
large number of steps to get from a molecule to the human brain. - yeah, and i think they are related but in hierarchies of emergence, right? so you shouldn't compare them. i mean, the assembly
index of a human brain, what does that even mean? well, maybe we can look at the morphology of the human brain. say all human brains have these number of features in common. and then let's look at a brain in a whale or a dolphin or a chimpanzee
or a bird and say, okay, let's look at the
assembly indices number of features in these. and now the copy number is just a number of how many birds are there, how many chimpanzees are there, how many humans are there? - but then you have to discover for the features that
you would be looking for. - yeah, and that means
you need to have some idea of the anatomy. - but there's an automated
way to discover features? - i guess so. i mean, and i think this is a good way to apply machine learning
and image recognition just to basically characterize things. - to apply compression
to it to see what emerges and then use the thing. the features used as
part of the compression as the thing that is searched for when you're measuring assembly
index and copy number. - and the compression has to be remember the assembly universe, which is you have to go
from assembly possible to assembly contingent. 'cause assembly possible
or possible brains or possible features all the time. but we know that on the tree of life, and also on the lineage of
life, going back to luca, the human brain just didn't
spring into existence yesterday, it is a long lineage of
brains going all the way back. and so, if we could do assembly theory to understand the development, not just in evolutionary history but in biological development as you grow, we are gonna learn something more. - what would be amazing is if
you can use assembly theory, this framework, to show the increase in the assembly index associated with, i don't know, cultures or pieces of text like language or images and so on, and illustrate without knowing
the data ahead of time, just kinda like you did with nasa, that you were able to demonstrate that it applies in those other contexts. i mean, and that, you know,
probably wouldn't at first and you have to evolve the theory somehow. you have to change it, you
have to expand it, you know? - [lee] i think so. - but like that. i guess this is, as a paper, a first step in saying, okay, can we create a general framework for measuring complexity of
objects, for measuring life, the complexity of living organisms. - [lee] yeah. - that's what this is reaching for. - that is the first step. and also to say, look, we have a way of quantifying selection and evolution in a fairly, not mundane, but a fairly mechanical way. because before now, you know, the ground truth for
it was very subjective. whereas here, we're talking
about clean observables. and there's gonna be layers on that. i mean, with collaborators right now, we already think we can do
assembly theory on language. and not only that. wouldn't it be great if we can figure out how under pressure
language is gonna evolve and be more efficient, 'cause you're gonna wanna transmit things. and again, it's not
just about compression, it is about understanding how you can make the most of the architecture
you've already built. and i think this is something beautiful that evolution does. we're reusing those architectures. we can't just abandon
our evolutionary history. and if you don't wanna abandon
your evolutionary history, and you know that evolution
has been happening, then assembly theory works. and i think that's the
key comment i wanna make, is that assembly theory
is great for understanding when evolution has been used. the next jump is when we go to technology. 'cause of course, if you
take the m3 processor. i haven't bought one yet, i can't justify it, but
i want to at some point. the m3 processor arguably, there's quite a lot of features and quite large number. the m2 came before it, then the m1, all the way back. you can apply assembly theory to microprocessor architecture. it doesn't take a huge leap to see that. - i'm a linux guy, by the way, so your examples go away over my head. - [lee] yeah, well, whatever. - is that a fruit company of some sort? i don't even know. yeah, there's a lotta interesting stuff to ask about language. like you could look at- how would that work? you could look at gpt-1,
gpt-2, gpt-3, 3.5, 4 and try to analyze the kind
of language it produces. i mean, that's almost trying
to look at assembly index of intelligent systems. - yeah, i mean, i think the thing about large language models, and this is a whole hobby
horse i have at the moment, is that obviously they're all about- the evidence of evolution
in the large language model comes from all the people that
produced all the language. and that's really interesting. and all the corrections in
the mechanical turk, right? - [lex] sure. - and so-
- but that's the part of the history, part of
the memory of the system. - exactly. so it would be really
interesting to basically use an assembly-based approach
to making language in a hierarchy, right? my guess is that we might
be able to build a new type of large language model
that uses assembly theory that it has more understanding of the past and how things were created. where basically, with a thing with llms is they're like everything
everywhere all at once, splat, and make the user happy. so there's not much
intelligence in the model. the model is how the human
interacts with the model. but wouldn't it be great
if we could understand how to embed more
intelligence in the system? - what do you mean by intelligence there? like you seem to associate intelligence with history and memory. - i think selection produces intelligence. - wait, what? you're almost implying that
selection is intelligence. no.
- yeah, kind of. i would go out and limb and say that. but i think it's a little bit more. human beings have the ability to abstract and they can break beyond selection. darwinian selection. because a human being
doesn't have to basically do trial and error. like they can think about it and say, oh, that's a
bad idea, won't do that. and then technologies and so on. - so we escaped darwinian evolution and now we're onto some other
kind of evolution i guess? - yeah.
- higher level evolution. - and the assembly theory will
measure that as well, right? because it's all a lineage. - okay, another piece of criticism, or by way of question is, how's assembly theory
or maybe assembly index different from kolmogorov complexity? so for people who don't know, a kolmogorov complexity of an object is the length of a
shortest computer program that produces the object as output. - yeah, there seems to be a disconnect between the computational
approach, so yeah. so a kolmogorov measure requires a turing machine, requires a computer. and that's one thing. and the other thing is assembly theory is supposed to trace the process by which life evolution emerged, right? there's a main thing there. there are lots of other layers. so kolmogorov complexity, you can you can approximate
kolmogorov complexity but it's not really telling you very much about the actual- it's really telling you about like, your compression of your dataset. and so, that doesn't really
help you identify the turtle, in this case is the computer. and so what assembly theory does is, i'm gonna say, (chuckles) there's a trigger warning
for anyone listening who loves complexity theory. i think that we're gonna show that ait is a very important
subset of assembly theory, because here's what happens. i think that assembly theory allows us to understand when were
selections occurring, selection produces factories and things, factories in the end produce computers, then algorithmic information
theory comes out of that. the frustration i've
had with looking at life through this kind of information theory is it doesn't take into account causation. so the main difference
between assembly theory and all these complexity measures is there's no causal chain. and i think that's the main- - that's the causal chains at
the core of assembly theory. - exactly. and if you've got all your
data in a computer memory, all the data's the same. you can access it in the same type of way, you don't care, you just compress it, and you either look at the program runtime or the shortest program. and that for me is
absolutely not capturing what its selection does. - but assembly theory looks at objects, it doesn't have information
about the object history. it's going to try to infer that history by looking for the
shortest history, right? the object doesn't like
have a wikipedia page that goes with it about its history. - i would i would say it does in a way, and it is fascinating to look at. so you've just got the object and you have no other
information about the object. what assembly theory allows you to do just with the object is to- and the word infer is
correct, i agree with infer. so it's, you know, like say
well that's not the history, but something really
interesting comes from this. the shortest path is
inferred from the object. that is the worst case
scenario if you have no machine to make it. so that tells you about the
depth of that object in time. and so, what assembly
theory allows you to do is, without considering any
other circumstances, to say from this object how
deep is this object in time if we just treat the object as itself without any other constraints. and that's super powerful because the shortest path then allows you to say, oh, this object
wasn't just created randomly, there was a process. and so, assembly theory
is not meant to, you know, one up ait or to ignore the factory. it's just to say, hey,
there was a factory, and how big was that factory
and how deep in time is it? - but it's still
computationally very difficult to compute that history, right? for complex objects. - it is. it becomes harder. but one of the things that's super nice is that it constrains your
initial conditions, right? it constrains where you're gonna be. so one of the things we're doing right now is applying assembly
theory to drug discovery. now what everyone's doing right now is taking all the proteins
and looking at the proteins and looking at molecules not the proteins. why not instead look at the molecules that are involved in interacting with the receptors over time, rather thinking about and use
the molecules evolve over time as a proxy for how the
proteins evolved over time., and then use that to constrain
your drug discovery process. you flip the problem'0 and focus on the molecule evolution
rather than the protein. and so you can guess in the
future what might happen. so you rather than having to consider all possible molecules, you know where to focus. and that's the same
thing if you're looking in assembly spaces for an object where you don't know the entire history but you know in the history of this object it's not gonna have some other motif there that doesn't appear in the past. - but just even for the drug
discovery point you made, don't you have to
simulate all of chemistry to figure out how to
come up with constraints through the molecules and- - no.
- i don't i don't know enough about producing. - this is another thing
that i think causes- 'cause this paper goes
across so many boundaries. so chemists have looked at this and said this is not correct reaction. it's like, no, it's a graph. (laughing) - sure, there's a assembly index and shortest path examples
here on chemistry. - yeah. and what you do is you look
at the minimal constraints on that graph. of course it has some
mapping to the synthesis, but actually you don't have
to know all of chemistry, you can build up the
constraints space rather nicely. but this is just at the beginning, right? there are so many
directions this could go. and i said, it could all be wrong but hopefully it's less wrong. - what about the little
criticism i saw of do you- by way of question, do you consider the
different probabilities of each reaction in the chain? so like, that there could be different- when you look at a chain of events that led up to the creation of an object, doesn't it matter that
some parts in the chain are less likely than others? - no - it doesn't matter.
- no, no. well, let's go back. so, no not less likely, but it reacts so- so, no. so let's go back to what
we're looking at here. so the assembly index is the minimal path that could have created that
object probabilistically. so imagine you have all
your atoms in the plasma, you got enough energy, there's collisions. what is the quickest way you
could zip out that molecule with no reaction constraints? - how do you define quickest there then? - it's just basically a
walk on a random graph. so we make an assumption that basically the timescale for forming the bonds. so, no, i don't wanna say that because then it's gonna have
people getting obsessing about this point, and your
criticism is a really good one. what we're trying to say is like this puts a lower bound on something. of course, some reactions are
less possible than others. but actually, i don't think
chemical reactions exist. - oh, boy. what does that mean? why don't chemical reactions exist? - i'm writing a paper right now that i keep being told i have to finish, and it's called "the origin
of chemical reactions". and it merely says that reactivity exists, as controlled by the laws
of quantum mechanics, and reactions, chemists
put names on reactions, you could have like, i don't know, the wittig reaction, which
is by, you know, wittig. you could have the suzuki
reaction which is by suzuki. now what are these reactions? so these reactions are
constrained by the following. they're constrained by the fact they're on planet earth, 1g,
298 kelvin, and one bar. so these are constraints. they're also constrained by the chemical composition of earth. oxygen, availability, all this stuff. and that then allows us
to focus on our chemistry. so when a chemist does a reaction, that's a really nice compressed shorthand for constraint application. glass flask, pure reagent, temperature pressure,
boom, boom, boom, boom, control, control,
control, control, control. so of course, we have bond energies. so the bond energies are kind
of intrinsic in a vacuum. so the bond energy. you have to have a bond. and so, for assembly theory to work, you have to have a bond, which means that bond
has to give the molecule a certain half-life. so you're probably gonna find later on that some bonds are weaker. when you look at the
assembly of some molecules, you're gonna miscount the
assembly of the molecule 'cause it falls apart too quickly, 'cause the bonds just form. but you can solve that
with looking at infrared. so when people think
about the probability, they're kinda misunderstanding. assembly theory says
nothing about the chemistry because chemistry is chemistry and their constraints
are put in by biology. there was no chemist
at the origin of life, unless you believe in
the chemist in the sky and they were, you know,
it's like santa claus, they had a lot of work to do. but chemical reactions do not exist, the constraints that allow
chemical transformations to occur do exist. - okay, okay. so there's no chemical reactions, it's all constraint application which enables the emergence of- what's a different word
for chemical reaction? - transformation.
- transformation. - [lee] yeah, like a function. it's a function.
- yeah. but no, but i love chemical
reactions as a shorthand and so the chemists don't all go mad. i mean, of course chemical
reactions exist on earth. - it's a shorthand
- it's a shorthand for these constraints. - right. so assuming all these
constraints that we've been using for so long that we just assume
that that's always the case, in natural language conversation. - exactly. the grammar of chemistry of
course emerges in reactions and we can use 'em reliably. but i do not think the wittig reaction is accessible on venus. - right, and this is useful
to remember, you know, to frame it as constraint
application is useful for when you zoom out
to the bigger picture of the universe and
looking at the chemistry of the universe and then starting
to apply assembly theory. - yeah.
- that's interesting. that's really interesting. (chuckles) well, we've also
pissed off the chemist now. - oh, i expect they're pretty happy, well most of them. (laughing) - everybody deep down is happy, i think. they're just sometimes feisty, that's how they have fun. - everyone is grumpy on some days when- the problem with this paper is you- i used to do this
occasionally when i was young. go to a meeting and just
find a way to offend everyone at the meeting simultaneously. even the factions that
don't like each other, they're all unified in their hatred of you just offending them. this paper, it feels
like the person that went to the party and offended
everyone simultaneously, so they stop fighting with themselves and just focused on this paper. - maybe just a little insider
interesting information. what were the editors of "nature", their reviews and so on, how difficult was that process? 'cause this is a pretty, like, big paper. - when we originally sent the paper, we sent the paper, and the
editor said that, you know- this was quite a long process. we sent the paper, and the
editor gave us some feedback and said, "you know, i don't think it's that interesting." or, "it's a hard concept." and the editor gave us some feedback, and sara and i took a
year to rewrite the paper. - was the nature of the
feedback very specific on like, this part or this part, or was it, like, what
are you guys smoking? - yeah, it was kind of the latter. what you smoking?
- okay. (lee laughing) - but polite and there's promise. - yeah, well, the thing is, the editor was really critical, but in a really professional way. and i mean, for me, this was
the way science should happen. so when it came back, you know, we had too many equations in the paper. if you look at the preprint, they're just equations everywhere, like there are 23 equations. and when i said to abhishek, who was the first author, and we've gotta remove all the equations, but my assembly equation's staying. and abhishek was like,
"you know, no, we can't." i said, "well, look, if we
want to explain this to people, there's a real challenge." and so sara and i went through the, i think it was actually
160 versions of the paper, but basically we got to
version 40 or something. we said, "right, zero, let's start again." so we wrote the whole paper again. we knew the entire archive.
- amazing. - and we just went bit
by bit by bit and said, "what is it we wanna say?" and then we sent the paper in, and we expected it to be rejected and not even go to review. and then we got the notification back, it had gone to review, and we were like, "oh my god,
it's so gonna get rejected. how's it gonna get rejected?" 'cause the first assembly paper on the mass spec we sent to "nature" went through six rounds of
review and were rejected, right? and this by a chemist who just said, "i don't believe you, you
must be committing fraud." and long story, probably a boring story. but in this case, it went out to review, the comments came back, and the comments were incredibly- no, they were very deep comments from all the reviewers. but the nice thing was
the reviewers were kind of very critical but not dismissive. they were like, "oh, really? explain this. explain this. explain this. explain this."
- that's great. - "are you sure it's not kolmogorov? are you sure it's not this?" and we went through, i think, three rounds of review pretty quick. and the editor went, "yeah, it's in." - but maybe you could just
comment on the whole process. you've published some pretty huge papers on all kinds of topics
within chemistry and beyond. some of them have some
little spice in them, a little spice of crazy. like tom waits says, "i like my town with a
little drop of poison." so, you know, it's not a mundane paper. so what's it like psychologically to go through all this process
to keep getting rejected to get reviews from people
that don't get the paper or all that kind of stuff? just from a question of a scientist, what is that like? - i mean, this paper, for me, kind of- 'cause this wasn't the first time we tried to publish assembly theory
at the highest level, the "nature" communications
paper on the mass spec on the idea went to
"nature" and got rejected. look, it went through six rounds of review and got rejected. and i just was so confused
when the chemist said, "this can't be possible, i do not believe you
can measure complexity using mass spec. and also, by the way, complex molecules can randomly form." and we're like, "but look at the data. the data says." and they said, "no, no,
we don't believe you." i just wouldn't give up. (laughing) and the editor, in the end, different editors actually, right? - what's behind that never giving up? when you're sitting there
10 o'clock in the evening, there's a melancholy
feeling that comes over you, and you're like, "okay, this
is rejection number five." or it's not rejection but
maybe it feels like a rejection because of the, you know, the comments are that you totally don't get it. like what gives you strength
to keep going there? - i don't know. i don't normally get
emotional about papers. it's not about giving up because we wanna get it published, 'cause we
want the glory or anything. it's just like, why don't you understand? so why i would just try to
be as rational as possible and say, "yeah you didn't like it, tell me why?" and then- sorry. silly.
- and you part- - i never get emotional
about papers normally, but i think what we do is
you just compressed, like, five years of angst from this. - so it's been rough? - it's not just rough,
it's like it happened. you know, i came up with
the assembly equation, you know, remote from sara in arizona and the people at sfi, i felt like i was a mad person, like, you know, the guy
depicted in "a beautiful mind". not the actual genius part, but just the, gibberish, gibberish,
gibberish. (laughing) because i kept writing expanded. and i have no mathematical ability at all, and i was making these
mathematical expansions where i kept seeing the same motif again. i was like, "oh, i think
this is a copy number." the same string is coming
again, again, again. i couldn't do the math. and then i realized the copy
number fell outta the equation and everything collapsed down. i was like, "oh, that works, kind of." so we submitted the paper, and then when it was
almost accepted, right? the mass spec one. and there was astrobiologists,
said, "great." you know, a mass
spectroscopist said, "great," and the chemist went, "nonsense." like, "biggest pile of nonsense
ever, fraud," you know? and i was like, "but why fraud?" and they just said, "just because." and i was like, "well." and i could not convince
the editor in this case. the editor was just so off, 'cause they see it as like a kind of a, you know, you're wasting my time. and i would not give up. i wrote. i went and dissected,
you know, all the parts. and i think although, i mean, i got upset about it, you know, it was kind of embarrassing
actually, but i guess- - [lex] (speaks faintly) beautiful. - but it was just trying to understand why they didn't like it. so a part of me was
like really devastated. and a part of me was super excited, 'cause i'm like, "huh, they
can't tell me why i'm wrong." and this kinda goes back to, you know- when i was at school, i was in a kinda learning
difficulties class and i kept going to the teacher and say, you know, "what do i
do today to prove i'm smart?" and they were like, "nothing, you can't." i was like, "gimme a job," you know, "gimme something to do. gimme a job to do. something just to do as we-" and i kinda felt like that a bit when i was arguing with the- and not arguing, there
was no (indistinct), and i wasn't telling the
editor they were idiots or anything like this, or the reviewers, i kept it strictly, like, factual. and all i did is i just
kept knocking it down bit by bit by bit by bit by bit. it was ultimately rejected, and it got published though, elsewhere. and then, the actual experimental data. in this paper, the
experimental justification was already published. so when we did this one and
we went through the versions and then we sent it in, and in the end it just got accepted. we were like, "well,
that's kinda cool, right?" the first author was like, "i can't believe it got accepted." like, nor am i, but it's great. it's like, it's good. and then when the paper was published, i was not expecting the backlash. i was expecting computational- well, no actually, i was
just expecting one person who'd been trolling me
for a while about it just to carry on trolling. but i didn't expect the backlash. and then, i wrote to the
editor and apologized. and the editor was like,
"what are you apologizing for? it was a great paper. of course it's gonna get backlash, you said some controversial
stuff, but it's awesome." - well, i think it's a
beautiful story of perseverance, and the backlash is just a
negative word for discourse, which i think is beautiful. that's the science. - you know, when it got accepted and people were saying we're
kind of like hacking on it. i was like, "papers are not gold medals." the reason i wanted to publish that paper in "nature" is because it says, "hey, there's something
before biological evolution." you have to have that if you're not a creationist, by the way. this is an approach. first time someone has
put a concrete mechanism, sorry, a concrete quantification. and what comes next, you're
pushing on, is a mechanism. and that's what we need to get to is an autocatalytic set,
self-replicating molecules, some other features that come in. and the fact that this
paper has been so discussed, for me, is a dream come true. like, it doesn't get better than that. if you can't accept a
few people hating it. and the nice thing is, the thing that really makes me happy is that no one has attacked
the actual physical content. like, you can measure the assembly index, you can measure selection now. well, either that's helpful or unhelpful. if it's unhelpful, this
paper will sink down and no one will use it again. if it's helpful, it'll help
people build a scaffold on it, and we'll start to
converge to a new paradigm. so i think that that's the
thing that i wanted to see, you know, my colleagues,
authors, collaborators, and people were like, "you've just published this
paper, you're a chemist. why have you done this? like, who are you to be
doing evolutionary theory?" like, well, "i dunno. i mean, sorry, did i need to-" - cause anyone to do anything. well, i'm glad you did. before coming back to origin of life and these kinds of questions, you mentioned learning difficulties. i didn't know about this. so what was it like? - i wasn't very good at school, right? - [lex] this is when you were very young? - yeah, yeah, in primary school. my handwriting was really poor, and apparently i couldn't read, and my mathematics was very poor. so they just said this is a problem, they identified it. my parents kind of at
the time were confused because i was busy taking things apart, buying electronic junk from the shop, trying to build computers and things. and then, when i was i think about- the major transition in my stupidity, like, you know, everyone thought i wasn't that stupid when i- basically, everyone thought i was faking. i like stuff and i was
faking wanting to be- so i always wanted to be a scientist. so five, six, seven years old, be a scientist, take things apart. and everyone's like, "yeah, this guy wants to be a scientist, but he's an idiot." (laughing) so everyone was really confused, i think, at first, that i wasn't
smarter than i, you know, was claiming to be. and then i just basically didn't do well in any of the tests and i went down and
down and down and down. and i was kinda like, "huh, this is really embarrassing." i really like maths and
everyone says i can't do it. i really like kind of, you know, physics and chemistry and science, and people say you can't read and write. and so, i found myself in a
learning difficulties class at the end of primary school and the beginning of secondary school. in the uk, secondary school
is like 11, 12 years old. and i remember being put
in the remedial class. and the remedial class
was basically full of, well, three types of people. there were people that had quite violent, right, you know?
- yeah. - and there were people
who couldn't speak english. and there were people that
really had learning difficulties. the one thing i can
objectively remember was- i mean, i could read. i like reading. i read a lot. i'm a bit of a rebel. i refused to read what i was told to read. and i found it difficult
to read individual words in the way they were told. but anyway, so i got
caught one day teaching someone else to read. and they said, "okay, we
don't understand this." i always knew i wanted to be a scientist, but didn't really know what that meant. and i realized you had
to go to university. and i thought i can just go to university, it's like curious people. like, no, no, no, you need to have these, you have to be able to
enter in these exams to get this grade point average. and the fact is the exams
you've been entered into, you're just gonna get c, d, or e. you can't even get a, b, or c, right? this is the uk gcses. i was like, "oh, shit." and i said, "can you just
put me into the high exams?" they said, "no, no, you're gonna fail. there's no chance." so my father kind of intervened and said, you know, "just let him go in the exams." and they said, "he's
definitely gonna fail, it's a waste of time, waste of money." and he said, "well, what if we paid?" so they said, "well, okay." so he didn't actually have to pay. he only had to pay if i failed. so i took the exams and
passed them, fortunately. i didn't get the top grades but i, you know, i got into a levels. but then that also kind of limited what i could do at a levels. i wasn't allowed to do a-level maths. - what do you mean you weren't allowed to? - because i had such a bad
math grade from my gcses, i only had a c. but they wouldn't let me
go into the abc for maths 'cause of some kind of
coursework requirement back then. the top grade i coulda got was a c. so c, d, or e. so i got a c. and they let me do kind of as-level maths, which is this half intermediate, but i didn't get go university. but in the end i liked chemistry, i had a good chemistry teacher. so in the end, i got to
university to do chemistry. - so through that kind
of process, i think, for kids in that situation, it's easy to start
believing that you're not, well, how do i put it? that you're stupid, and basically give up. that you're just not good at math, you're not good at school. so this is by way of advice for people, for interesting people, for interesting young kids right now, experiencing the same thing. what was the source of
you not giving up there? - i have no idea other than i really liked not understanding stuff. for me, when i not understand something- (chuckles) i feel like i
don't understand anything now. but back then, i remember
when i was like, i don't know. i tried to build a laser
when i was, like, eight. and i thought, how hard could it be? and basically i was
gonna build a co2 laser. i was like, "right, i think i need some partially coated mirrors, i need some carbon dioxide, and i need a high voltage. and i was so stupid, right? i was kind of so embarrassed. i had to make enough co2. i actually set a fire and
tried to filter the flame- - oh, nice.
- to trap enough co2. and i was like, it completely failed and i burnt half the the garage down. so my parents were not
very happy about that. so that was one thing. i was like, i really like
first principle thinking, and so, you know? so i remember being super curious and being determined to find answers. and so, when people do
give advice about this, why i ask for advice about this, i don't really have that much advice other than don't give up. and one of the things i tried to do as a chemistry professor in my group, is i hire people that
i think that, you know- if they're persistent enough, who am i to deny them the chance? because, you know, people gave me a chance and i was able to do stuff. - do you believe in yourself essentially? - so i love being around smart people and i love confusing smart people. and when i'm confusing smart people, and, you know, not by
stealing their wallets and hiding it somewhere, but if i can confuse smart people, that is the one piece of hope that i might be doing
something interesting. - well, that's quite brilliant. like as a gradient to optimize. hang out with smart
people and confuse them. and the more confusing it is, the more there's something there. - and as long as they're not telling you you're just a complete idiot, and they give you different reasons. 'cause like with assembly theory, when people said, "oh, it's wrong." and i was like, "why?" and no one could gimme
a consistent reason. they said, "oh, because
it's been done before," or "it's just kolmogorov," or "it's just there, that, and the other." so i think the thing
that i like to do is in- and in academia, it's hard, right? 'cause people are critical. but i mean, you know, the criticism- i mean, although i got kind
of upset about it earlier, which is kind of silly, but not silly, because obviously it's
hard work being on your own or with a team, spatially separated, like during lockdown, and
try to keep everyone on board and, you know, have some faith. i always wanted to have a new idea. and so, you know, i like a new idea and i wanna nurture it
as long as possible. and if someone can give
me actionable criticism. that's what i think i
was trying to say earlier when i was kind of like stuck for words. give me actionable criticism. you know, it's wrong. okay, why is it wrong? say, oh, your equation's
incorrect for this, or your method is wrong. and so what i try and do
is get enough criticism from people to then
triangulate and go back. and i've been very fortunate in my life that i've got great colleagues, great collaborators, funders, mentors and people that will take the time to say, you're wrong because. and then what i have to do
is integrate the wrongness and go, aah, cool, maybe i can fix that. and i think criticism is really good. people have a go at me
'cause i'm really critical. i'm like, but i'm not criticizing, you know, you as a person, i'm just criticizing the idea and trying to make it better and say, "well, what about
this," and, you know? and sometimes i'm kind of, you know, my filters are kind of,
you know, truncated. and in some ways, i'm just like, "that's wrong, that's wrong, that's wrong, why'd you do this?" and people are like, "oh
my god, you just told me. you destroyed my life's work." i'm like, "relax, no." i'm just like, "let's make it better." and i think that we don't do that enough 'cause we're either personally critical, which isn't helpful, or we don't give any criticism at all because we're too scared. - yeah. i've seen you be pretty
aggressively critical, but every time i've seen it, it's the idea, not the person. - i'm sure i make mistakes and that. i mean, you know, i argue with lots- i mean, i argue lots with sara, and she was like kinda shocked. i've argued with joscha
in the past, joscha bach, and he's like, "you're
just making that up." i'm like, "no, not quite, but kind of." you know, i had a big
argument with sara about time, and she's like, "no, time doesn't exist." i'm like, "no, no, time does exist." and as she realized that her
conception of assembly theory and my conception of assembly
theory were the same thing, necessitated us to abandon
the fact that time is eternal. to actually really fundamentally question how the universe produces
combinatorial novelty. - so time is fundamental
for assembly theory? 'cause i'm just trying to figure out where you and sara converged. - i think assembly theory is
fine in this time right now, but i think it helps us understand that something interesting is going on. and i'm been really inspired
by a guy called nick gisin. i'm gonna butcher his argument, but i love his argument a lot. so i hope he forgives
me if he hears about it. but basically, if you want free will, time has to be fundamental. and if you want time to be fundamental, you have to give up on
platonic mathematics and you have to use
intuition as mathematics. and again, i'm gonna butcher this. but basically, hilbert
said that, you know, "infinite numbers are allowed." and i think it was brouwer said, "no, you can't, all numbers are finite." so let's go back a step, 'cause it was like people were gonna say, assembly theory seems to explain that large combinatorial space allows you to produce things
like life and technology. and that large combinatorial
space is so big it's not even accessible to a sean carroll or david deutsch multiverse. the physicist saying that all of the universe already
exists in time is probably, provably, that's a
strong word, not correct. that we are gonna know that
the universe as it stands, the present, the way the
present builds the future so big the universe can't
ever contain the future. and this is a really interesting thing. i think max tegmark has
this mathematical universe where he says, "you know, the universe is kind of like a block universe." and i apologize to max
if i'm getting it wrong. you have the initial conditions and you can run the
universe right to the end and go backwards and
forwards in that universe. that is not correct. - yeah, let me load that in. the universe is not big
enough to contain the future. - [lee] yeah, that's it. - so that's another
beautiful way of saying that time is fundamental. - yes. this is why the law of
the excluded middle, something is true or false, only works in the past. is it gonna snow in new york
next week, or in austin? you might, in austin, say, probably not. in new york, you might say, yeah. if you go forward to next week and say, did it snow in new york
last week, true or false? you can answer that question. the fact that the law
of the excluded middle cannot apply to the future
explains why time is fundamental. - well, i mean that's a good
example, intuitive example. but it is possible that we
might be able to predict, you know, whether it's gonna snow if we had the perfect information. you're saying it'd not. - impossible. impossible. so here's why. i'll make a really quick argument. and this argument isn't mine, it's nick's and a few other people. - [lex] can you explain his
view on time being fundamental? - yeah, so i'll give my view, which kind of resonates with his. but basically, it's very simple actually. it would say that your ability to design and do an experiment is
exercising free will. so he used that thought process. but i never really
thought about it that way. and that you actively make decisions. i used to think that free will was a kind of consequence
of just selection, but i'm kind of understanding
that human free will is something really interesting. and he very much inspired me. but a thing what sara walker said that inspired me as well. and these will converge. is that i think that the universe- the universe is very big, huge. but actually, the place that is largest in the universe right now, the largest place in
the universe is earth. - yeah. i've seen you say that, and boy, that's an interesting one to process. what do you mean by that? earth is the biggest
place in the universe. - because we have this
combinatorial scaffolding going all the way back from luca. so you've got cells
that can self-replicate. and then you go all the way
to terraforming the earth. you've got all these architectures, the amount of selection that's going on, biological selection, just to be clear, biological evolution. and then you have multicellularity. then animals, and abstraction. and with abstraction, there was another kick because you can then build architectures, and computers, and cultures, and language. and these things are the
biggest things that exist in the universe because we
can just build architectures that couldn't naturally arise anywhere. and the further that
distance goes in time, and this kind of is gigantic and- - [lex] from a complexity perspective. - yeah.
- okay, wait a minute. i mean, i know you're being poetic, but how do you know there's
not other earth-like- you're basically saying
earth is really special. it's awesome stuff. as far as we look out, there's nothing like it going on. but how do you know there's
not a nearly infinite number of places where cool stuff
like this is going on? - i agree. i'll say again that earth
is the most gigantic thing we know in the universe. combinatorially, we know. - [lex] we know. okay, yeah. - now, i guess, this
is just purely a guess, i have no data, but other than hope. well, maybe not hope. no, i have some data. that every star in the
sky probably has planets and life is probably
emerging on these planets. but the amount of contingency
that has associated with life is that i think the
combinatorial space associated with these planets is so different our causal cones are never
gonna overlap, or not easily. and this is a thing that
makes me sad about alien life. that's why we have to create alien life in the lab as quickly as possible, because i don't know
if we are gonna be able to build architectures that will intersect with alien intelligence architectures. - and intersect, you don't
mean in time or space? - [lee] time and the
ability to communicate. - so the ability to communicate. - yeah. my biggest fear, in a way,
is that life is everywhere, but we've become infinitely more lonely because there are scaffolding
in that combinatorial space, because it's so big. - so you're saying the constraints created by the environment that led to the factory of darwinian evolution are
just a little, tiny cone in a nearly infinite
combinatorial space, so there's other cones like it.
- exactly. - why can't we communicate with other- just because we can't create it doesn't mean we can't
appreciate the creation, right? sorry, detect the creation. - i truly don't know, but it's an excuse for
me to ask for people to give me money to
make a planet simulator. - yeah, right. with a different kind of- - i'm just like another
shameless scientist, it's like gimme money, i need to play. - this was all a long plugged
for a planet simulator. hey, i will be the
first in line to donate. - my rick garage has run
out of room, you know? - [lex] yeah. - no- - and this is a planet simulator. you mean, like a different kind of planet or different set sets of
environments and pressures. - exactly. if we could basically recreate
the selection before biology, as we know it, that gives
rise to a different biology, we should be able to put the constraints on where to look in the universe. so here's the thing, here's my dream. my dream is that by
creating life in the lab, based upon constraints we understand. so let's like go for venus-type life or earth-type life or something again. do earth 2.0. screw it, let's do earth 2.0. an earth 2.0 has a
different genetic alphabet. fine. that's fine. different protein alphabet. fine. have cells and the
evolution all that stuff. we will then be able to say, okay, life is a more general phenomena. selection is more general
than what we think is the chemical constraints on life. and we can point the james webb and other telescopes at other planets. that we are in that zone, we are most likely to
combinatorially overlap with, right? so there are chemistry- - [lex] you're looking for some overlap. - and then, we can then
basically shine light on them, literally, and might look
at light coming back, and apply advanced assembly theory to general theory of
language, that we'll get, and say, ha, in that signal, it looks random but there's a copy number. oh, this random set of things that looks like a true and random number generator has structure as not kolmogorov, ait-type structure, but
evolutionary structure, given by assembly theory. but i would say that, 'cause i'm a shameless assembly theorist. - yeah. it just feels like the cone, i might be misusing the word cone here, but the width of the cone
is growing really fast to where eventually all the cones overlap, even in a very, very, very
large combinatorial space. but, then again, if
you're saying the universe is also growing very quickly
in terms of possibilities. - i hope that as we build abstractions- i mean, one idea is that
as we go to intelligence, intelligence allows us to
look at the regularities around us in the universe, and that gives us some common grounding to discuss with aliens. and you might be right. that we will overlap there, even though we have completely
different chemistry, literally completely different chemistry, that we will be able pass
information from one another. but it's not a given. and, you know, i have to kind of try and divorce hope
and emotion, you know, away from what i can logically justify. - but it's just hard to
intuit a world, a universe, where there's nearly
infinite complexity objects and they somehow can't detect each other. - but the universe is expanding. but the nice thing is i would say- you see, i think carl sagan did the wrong, well, not the wrong thing, he flicked the voyager probe
down at a pale, blue dot, said, "look at how big the universe is." i would've done it the
other way around and said, "look at the voyager probe that
came from the planet earth, that came from luca, look at how big earth is." - [lex] they produced that. - it produced that. and i think it's like, completely amazing. and then that should allow people on earth to think about, well,
probably we should try and get causal chains off earth onto mars, onto the moon, wherever. whether it's human life or
martian life that we create, it doesn't matter. but i think this
combinatorial space tells us something very important
about the universe. and that i realized in assembly theory, that the universe is too
big to contain itself. and now coming back, and i want to kind of
change your mind about time, 'cause i'm guessing that your
time is just a coordinate. - yeah.
- so i'm gonna change- - [lex] i'm guessing you
are one of those, yeah. - one of those. i'm gonna change your mind in real time, or at least attempt. - oh, in real time. there you go. i already got the tattoo, so this is gonna be embarrassing
if you change my mind. - [lee] but you can just add an arrow of time onto it, right? - yeah, true. just modify it. - or erase it a bit.
- yeah. - and the argument that i think that is really most interesting is like, people say the
initial conditions specify the future of the universe. okay, fine, let's say that's
the case for a moment. now let's go back to newtonian mechanics. now, the uncertainty principle in newtonian mechanics is this. if i give you the coordinates of an object moving in space and the coordinates of another object, and they collide in space, and you know those initial conditions, you should know exactly
what's gonna happen. however, you cannot
specify these coordinates to infinite precision. now, everyone said, "oh,
this is kind of like, you know, the chaos theory argument." no, no, it's deeper than that. here's the problem with numbers. this is where hilbert
and brouwer fell out. to have the coordinates of this object, an given object as it's colliding, you have to have them
to infinite precision. that's what hilbert says. he says, "no problem,
infinite precision is fine." let's just take that for granted. but when the object is finite and it can't store its own coordinates, what do you do? - [lex] mm-hmm. - so in principle, if a finite
object cannot be specified to infinite precision, in principle, the initial conditions don't apply. - well, how do you it can't store its- - well, how would you store
an infinitely long number in a finite size? - well, we're using
infinity very loosely here. - [lee] no, no, we're using- - infinite precision. i mean, not loosely, but- - very precisely.
- so you think infinite precision is required? - well, let's take the object. let's say the object is a golf ball. a golf ball is a few
centimeters in diameter, we can work out how many
atoms are on the golf ball. and let's say we can store numbers down to atomic dislocations. so we can work out how many atoms there are in the golf ball, and we can store the coordinates in that golf ball down to that number. but beyond that, we can't. let's make the golf ball smaller. and this is where i think
that we get randomness in quantum mechanics. and some people say you
can't get randomness in quantum mechanics, is deterministic. but, aha, this is where we realize that classical mechanics
and quantum mechanics suffer from the same uncertainty principle. and that is the inability to specify in the initial conditions
to a precise enough degree to give you determinism. the universe is intrinsically too big. and that's why time exists. it's nondeterministic. looking back into the past, you can use logical arguments, because you can say, was it true or false? you wouldn't know. but the fact we are unable
to predict the future with the precision is not
evidence of lack of knowledge, it's evidence the universe
is generating new things. - okay, first of all, quantum mechanics, you can just say statistically
what's gonna happen when two golf balls hit each other. - statistically. sure, i can say statistically
what's gonna happen. but then when they do happen, and you keep nesting it together. i mean, it goes almost back to- let's think about entropy in the universe. how do we understand
entropy change or a process? we can use the ergodic hypothesis. we can also have the counterfactuals, where we have all the different states. and we can even put that
in the multiverse, right? but both those, they're nonphysical. the multiverse kind of collapses back to the same problem, about the precision. if you accept you don't have to have true and false going
forward into the future, the real numbers are real. they're observables. - i'm trying to see exactly where time being fundamental sneaks in. the golf ball can't contain its own position perfectly precisely, how that leads to time
needing to be fundamental. - do you believe or do you
accept you have free will? - yeah, i think at this moment in time, i believe that i have free will. - so then you have to believe
that time is fundamental. - i understand that's the
statement you've made. - well, no, that we can logically follow. it's because if you don't have free will. so like, if you're in a
universe that has no time, the universe is deterministic. if it's deterministic,
then you have no free will. - i think the space of
how much we don't know is so vast that saying the
universe is deterministic and from that jumping
to there's no free will, it's just too difficult of a leap. - no, it logically follows. no, no, i totally disagree. i mean, it's deep and it's important, all i'm saying, and it's actually different
to what i've said before, is that if you don't require
platonistic mathematics and accept that nondeterminism
is how the universe looks, and that gives us our creativity in the way the universe
is getting novelty, it's kind of really deeply
important in assembly theory. 'cause assembly theory starts to actually give you
a mechanism why you go from boring time, which is basically initial
conditions specify everything, to a mismatch in creative time. and i hope we'll do experiments. and i think it's really important to- i would love to do an experiment that proves that time is fundamental and the universe is generating novelty. i don't know all the features
of that experiment yet, but by, you know, having
these conversations openly and getting people to think
about the problems in a new way, better people, more intelligent people with good mathematical
backgrounds can say, oh, hey, i've got an idea. i would love to do an experiment that shows that the universe- i mean, universe is too big for itself going forward in time. and, you know, this is why i really hate the idea of the boltzmann brain. the boltzmann brain makes
me super, kind of like, you know, everyone's having a free lunch. it's like, well, let's break
all the laws of physics. so a boltzmann brain is this idea that in a long enough universe the brain will just emerge
in the universe as conscious. and that neglects the causal chain of evolution required
to produce that brain. and this is where the
computational argument really falls down, because the computationalist can say, i can calculate probability
of a boltzmann brain, and they'll give you a probability. but i can calculate probability
of a boltzmann brain. zero. - just because the space
of possibility is so large? - yeah, it's like when we
start fooling ourselves with numbers that we
can't actually measure and we can't ever conceive of, i think it doesn't give
us a good explanation. i want to explain why
life is in the universe. i think life is actually
the novelty miner. i mean, life basically mines novelty almost from the future and
actualizes in the present. - okay. life is a novelty miner from the future that is actualized in the present. - yep. i think so.
- novelty miner. first of all, novelty. what's the origin of novelty? when you go from boring time to creative time, where's that? is it as simple as randomness, like you're referring to? - i'm really struggling with randomness because i had a really good argument with joscha bach about randomness. and he says that randomness
doesn't give you free will. that's insane, 'cause
you'd just be random. and i think he's right at that level, but i don't think he is
right on another level. and it's not about randomness, it's about constrained. i'm gonna sound like- i'm making this up as i go along. so making this up. constrained opportunity. so the novelty. what is novelty? you know, this is why i
think it's a funny thing. well, if you ever wanna discuss ai. why i think everyone's kind of gone ai mad is that they're misunderstanding novelty. but let's think about novelty. yes, what is novelty? so i think novelty is a
genuinely new configuration that is not predicted by the past, right? and that you discover
in the present, right? and that is truly different, right? some people say that
novelty doesn't exist, it's always with precedent. i want to do experiments that show that that is not the case. and it goes back to a question you asked me a few moments ago, which is where is the factory? - yeah.
- right? because i think the same mechanism that gives us a factory gives us novelty. and i think that is why i'm
so deeply hung up on time. i mean, of course, i'm wrong, but how wrong? and i think that life opens
up that combinatorial space in a way that our current laws of physics, as contrived in a deterministic
initial condition universe, even with the get-out-of-the-multiverse
david deutsch-style, which i love, by the way, but i don't think is correct. but it's really beautiful. - [lex] the multiverse? - the david deutsch's
conception of the multiverse is kind of like given. but i think that the problem
with wave-particle duality in quantum mechanics is
not about the multiverse, it's about understanding
how determined the past is. well, i don't just think that. actually, this is a
discussion i was having with sara about that, right? where she was like, "oh, i think-" we've been debating this
for a long time now, about how do we reconcile novelty, determinism, indeterminism? - so, okay, just to clarify. you both, you and sara think the universe is not deterministic? - i won't speak for sara, but i roughly can. i think the universe is
deterministic looking back in the past, but undetermined
going forward in the future. so i'm kinda having my
cake and eating it here. this is because i fundamentally don't understand randomness, right? as joscha told me or other people told me. but if i adopt a new view now. the new view is the universe
is just nondeterministic. but i'd like to refine that and say the universe appears deterministic
going back in the past, but it's undetermined going
forward in the future. so how can we have a universe that has deterministically looking rules that's non determined
going into the future? it's breakdown in precision
in the initial conditions. and we have to just stop
using initial conditions and start looking at trajectories and how the combinatorial space behaves in the expanding universe
in time and space. and assembly theory helps us quantify the transition to biology, and biology appears to be novelty mining, 'cause it's making crazy stuff. you know, that we are
unique to earth, right? that there are objects
on earth that are unique to earth that will not
be found anywhere else, 'cause you can do the combinatorial math. - what was that statement
you made about life is novelty mining from the future? - [lee] yeah. - what's the little element of
time that you're introducing? - so what i'm kinda meaning is 'cause the future is
bigger than the present, in a deterministic universe, how do the states go from one to another? i mean, there's a mismatch, right? - [lex] mm-hmm. yeah. - so that must mean that
you have a little bit of indeterminism,
whether that's randomness or something else, i don't understand. i want to do experiments
to formulate a theory to refine that as we go forward that might help us explain that. and i think that's why i am so determined to try and crack the
nonlife to life transition looking at networks and molecules and that might help us
think about the mechanism. but certainly, the future
is bigger than the past, in my conception of the universe and some conception of the universe. - by the way, that's not obvious, right? the future being bigger than the past. well, that's one statement. and the statement that the
universe is not big enough to contain the future
is another statement. - [lee] yeah. - that one is a big one. that one's a really big one. - i think so. but i think it's entirely- because look, we have the second law. and right now, i mean, we
don't need the second law if the future's bigger than the past. it follows naturally.
- right. - so why are we retrofitting
all these sticking plasters onto our reality to hold
onto a timeless universe? - yeah, but that's because
it's kind of difficult to imagine the universe that
can't contain the future. - [lee] but isn't that really exciting? - it's very exciting,
but it's (laughs) hard. i mean, we're humans on earth, and we have a very kinda
four-dimensional conception of the world, of 3d plus time. it's just hard to intuit a world where- what does it even mean? a universe that can't contain the future? - yeah, it's kinda crazy but obvious. - it's weird. i mean, i suppose it sounds
obvious, yeah, if it's true. - so the reason why
assembly theory turned me onto that was that- let's just start in the present and look at all the complex molecules and go backwards in time and understand how evolutionary processes gave rise to them. it's not at all obvious. the taxol, which is one of the most complex natural
products produced by biology, was gonna be invented by biology. it's an accident. you know, taxol is unique to earth. there's no taxol
elsewhere in the universe. and taxol was not decided
by the initial conditions. it was decided by this
interplay between the- so the past simply is
embedded in the present, it gives some features. but why the past doesn't map
to the future, one-to-one, is because the universe is
too big to contain itself. that gives space for creativity, novelty, and some things
which are unpredictable. - okay, so given that you're disrespecting the power of the initial conditions, let me ask you about- so how do you explain
that cellular automata are able to produce such
incredible complexity given just basic rules and
basic initial conditions? - i think that this falls
into the brouwer-hilbert trap. so how do you get a cellular automata to produce complexity? you have a computer,
you generate a display, and you map the change of that in time. there are some cas repeat, like functions. it's fascinating to me that for pi, there is a formula where you can go to the millionth decimal place of pi and read out the number
without having to go there. but there are some numbers
where you can't do that. you have to just crank through. whether it's wolframian
computational irreducibility or some other thing. well, it doesn't matter. but these cas, that complexity, is that just complexity, or a number that is
basically you're mining that number in time? you know, is that just a display screen for that number, that function? - well, can't you say the same thing about the complexity on earth, then? - no, because the complexity on earth has a copy number and an assembly
index associated with it. that ca is just a number running. - you don't think it has a copy number? wait, wait a minute. - well, it does where we're looking at humans producing different rules, but then it's nested on selection. so those cas are produced by selection. i mean, the ca is such a fascinating pseudo-complexity generator. what i would love to do is quantify the degree of surprise in a
ca and run it long enough. but what i guess that means is we have to instantiate, we have to have a number
of this experiments where we're generating different rules and running them time-steps. ah, i got it. cas are mining novelty, you know, in the future by iteration, right? and you're like, oh,
that's great, that's great. you didn't predict it. some rules you can predict
what's gonna happen, other rules you can't. so for me, if anything, cas are evidence that the universe is too
big to contain itself. 'cause otherwise, you'd
know what the rules are gonna do forever more. - right. i guess you were saying
that the physicist saying that all you need is
the initial conditions and the rules of physics is somehow missing the bigger picture. - yeah.
- and, you know, if you look at cas, all you need is the initial condition and the rules. and then run the thing. - you need three things. you need the initial conditions, you need the rules, and you need time
iteration to mine it out. without the coordinate,
you can't get it out. - sure. and that is fundamental. - and you can't predict it
from the initial conditions. if you could, then it'd be fine. - [lex] and that time is- - a resource.
- like the foundation of the history, the memory of each of the things it created. it has to have that memory of all the things that led up to it. - yeah, you have to have the resource. - [lex] yeah. - 'cause time is a fundamental resource. yeah, i think i had a major
epiphany about randomness. but i keep doing that every two days, and then it goes away again. it's random. - you're a time fundamentalist. - you should be as well. if you believe in free will, the only conclusion is
time is fundamental. otherwise, you cannot have free will. it logically follows. - well, the foundation
of my belief in free will is just observation-driven. i think if you use logic, it's like logically it seems like the universe is deterministic. - looking backward in time. and that's correct, the universe is. - and then everything
else is a kinda a leap. it requires a leap. - this is why i think machine learning is gonna provide a chunk of that, right? to help us explain this. so the way i'd say, if you take- - that's interesting. why? - 'cause the ai doomers
are driving me mad. and we don't have any
intelligence yet i call ai, autonomous informatics
just to make people grumpy. - yeah. you're saying we're
quite far away from agi. - i think that we have no
conception of intelligence and i think that we don't understand how the human brain does what it does. i think that neuroscience
is making great advances, but i think that we
have no idea about agi. so i am a technological,
i guess, optimist. i believe we should do everything. the whole regulation of ai is nonsensical. i mean, why would you regulate excel other than the fact that
clippy should come back? and i love excel '97 'cause we can play, you know, we can do the flight simulator. - i'm sorry. in excel? - yeah, have you not played
the flight simulator in- - in excel '97?
- yeah. - what does that look like? - it's like a wireframe. very, very basic. but basically, i think it's
x, zero, y, zero, shift, and it opens up and you can
play the fight simulator. - [lex] oh, wow. wait, wait. is he using excel? - [lee] excel. excel '97. - [lex] okay. - i resurrected it the other
day and saw clippy again for the first time in a long time. - well, clippy is definitely coming back. but you're saying we don't
have a great understanding of what is intelligence? what is the intelligence
underpinning the human mind? - i'm very frustrated by the way that we're ai dooming right now. and people were bestowing
some kind of magic. now, let's go back a bit. so you said about agi. are we far away from agi? yes. i do not think we are gonna
get to agi anytime soon. i've seen no evidence of it. and the ai doom scenario is
nonsensical in the extreme. - [lex] yeah. - and the reason why i
think it's nonsensical. and i don't think there
isn't things we should do and be very worried about, right? i mean, there are things we
need to worry about right now, what ai are doing. whether it's fake data, fake users, right? i want authentic people or authentic data. i don't want everything to be faked, and i think it's a really big problem. and i absolutely want to go on the record to say i really worry about that. what i'm not worried about is
that some fictitious entity is going to turn us all to paperclips or detonate nuclear bombs. i don't know. maybe. i don't know. anything you can't think of. why is this? and i'll take a very simple
series of logical arguments. the ai doomers, they do not
have the correct episdemiology. they do not understand what knowledge is. and until we understand what knowledge is, they're not gonna get anywhere because they're applying things falsely. so let me give you a very simple argument. people talk about the
probability, p-doom, of ai. we can work out the probability of a asteroid hitting the planet. why? 'cause it's happened before. we know the mechanism. we know that there's a gravity well, or that, you know, space-time is bent and stuff falls in. we don't know the probability of agi because we have no mechanism. so let me give you another one. which is like, i'm
really worried about ag. what's ag? ag is antigravity. one day we could wake up
and antigravity, you know, is discovered, we're all gonna die. the atmosphere's gonna float away. we are gonna float away. we're all doomed. what is the probability of ag? we don't know because
there's no mechanism for ag. do we worry about it? no. and i don't understand the current reason for certain people in certain areas to be generating this nonsense. i think they're not doing it maliciously. i think we're observing the
emergence of new religions, how religions come. because religions are
about kind of some control. so you've got the optimist
saying ai's gonna cure us all and ai's gonna kill us all. what's the reality? well, we don't have ai, we have really powerful
machine learning tools and they will allow us
to do interesting things. and we need to be careful
about how we use those tools in terms of manipulating human beings and faking stuff, right?
- right. well, let me try to sort of (indistinct) in the ai doomers argument. and actually i don't know. are ai doomers in the
yudkowsky camp saying it's definitely gonna kill us? 'cause there's a spectrum. - [lee] 95% i think is that limit, yeah. - and 95% plus, that's the- - no, no, not plus. i dunno, i was seeing on
twitter today various things. but i think yudkowsky's is at 95%. - but to belong to the ai doomer club, is there a threshold? i don't know what the membership- - maybe.
- and what are the fees? - well, i think scott aaronson, like, i was quite surprised. i saw this online, so it could be wrong, so sorry if it's wrong, says 2%. but the thing is, if someone said there's a 2% chance you're
gonna die going into the lift, would you go into the lift? - in the elevator
- yeah, elevator. - for the american
english speaking audience. well, no, not for the elevator. - so i would say anyone higher than 2%. i mean, i think there's
a 0% chance of agi doom. zero. - just to push back on the on the argument where at the end of zero on the agi. we can see on earth that
there's increasing levels of intelligence of organisms. we can see what humans
with extra intelligence were able to do to the other species. so that is a lot of samples of data what a delta in intelligence gives you. when you have an increase in intelligence, how you're able to dominate
a species on earth. and so the idea there is that if you have a being that's 10x smarter than humans, we are not gonna be able to predict what that being is going to be able to do, especially if it has the
power to hurt humans. you can imagine a lot of trajectories in which the more benefit ai systems give the more control we
give to those ai systems over our power grid,
over our nuclear weapons or weapons of any sort. and then it's hard to know what a ultra intelligence system would be able to do in that case. you don't find that convincing? - i think i would fail that argument 100%. here's a number of reasons to fail it on. first of all, we dunno where
the intention comes from. the problem is that people think. you know, because i've been watching all the hucksters online
with the prompt engineering and all this stuff. when i talk to a typical
ai computer scientist, they keep talking about the ai as having some kind of
decision-making ability. that is a category error. the decision-making ability
comes from human beings. we have no understanding of
how humans make decision. we've just been discussing free will for the last half an hour, right? we don't even know what that is. so the intention. i totally agree with you, people who intend to do bad
things can do bad things and we should not let that risk go. that's totally here and now. i do not want that to happen, and i'm happy to be regulated to make sure that systems i generate, whether they're like computer systems or- you know, i'm working on a new
project called chemmachina. - (chuckles) nice. well done.
- yeah, yeah. which is basically a- - (laughing) for people who
don't understand the point, the "ex machina" is a great film about, i guess, agi embodied. and chem is the chemistry version of that. - and i only know one way
to embody intelligence, that's in chemistry in human brains. so, category area number
one is they have agency. category area number two
is saying that assuming that anything we make is
gonna be more intelligent. now you didn't say superintelligent, i'll put the words into our mouths here. here's superintelligent. i think that there is no reason to expect that we are gonna make systems that are more intelligent, more capable. you know, when people play chess computers they don't expect to win now, right? the chess computer is very good at chess, that doesn't mean it's superintelligent. so i think that superintelligence- well, i mean, i think even nick bostrom is pulling back on this now. so i see this a lot. when did i see it first happen? eric drexler, nanotechnology,
atomically precise machines. he came up with a world where we had these atom cogs everywhere, we're gonna make
self-replicating nanobots. not possible. why? because there's no resources to build these self-replicating nanobots. you can't get the precision. it doesn't work. it was a major category error in taking engineering principles down to the molecular level. the only functioning
molecular technology we know- no, sorry. the only functioning
nano molecular technology we know produced by evolution. there. so now let's go forward to agi. what is agi? we dunno. it's super, it can do this, or humans can't think. i would argue the only agis
that exist in the universe are produced by evolution. and sure, we may be able to
make our working memory better, we might be able to do more things. the human brain is the
most compact computing unit in the universe. it uses 20 watts. it a uses a really limited volume. it's not like a chatgpt cluster which has to have thousands of watts, a model that's generated, and it has to be
corrected by human beings. you are autonomous and
embodied intelligence. so i think that there are so many levels that we're missing out. we've just kinda went,
oh, we've discovered fire, oh gosh, the planet's just
gonna burn one day, randomly. i mean, i just don't understand that leap. there are bigger problems
we need to worry about. so what is the motivation? why are these people, let's assume they have their earnest, have this conviction? well, i think it's kind
of they're making leaps, they're trapped in a virtual
reality that isn't reality. - well, i mean i can continue
a set of arguments here. but also, it is true that ideologies that fearmonger are dangerous. because you can then use it to control, to regulate in a way that halts progress, to control people, and to cancel people, all that kinda stuff. so you have to be careful, because the reason ultimately wins, right? but there is a lotta concerns
with superintelligent systems, very capable systems. i think when you hear the
word superintelligent, you're hearing like,
it's smarter than humans in every way that humans are smart. but the paperclip manufacturing system doesn't need to be smart in every way, it just needs to be
smart in specific ways. and the more capable
the ai systems become, the more you could see us
giving them control over, like i said, our power grid, a lot of aspects of human life. and then that means they'll be able to do more and more damage when there's unintended
consequences that come to life. - i think that that's right, the unintended consequences
we have to think about. and that i fully agree with. but let's go back a bit. sentient. i mean, again, i'm far
away from my comfort zone in all this stuff, but,
hey, let's talk about it 'cause i'll give myself a qualification. - yeah, we're both qualified
and sentience, i think, as much as anyone else. - i think the paperclip scenario
is just such a poor one. because let's think about
how that would happen. and also, let's think about we are being so unrealistic about how
much of the earth's surface we have commandeered. you know, for paperclip
manufacturing to really happen, i mean, do the math. it's not gonna happen. there's not enough energy. there's not enough resource. where is it all gonna come from? i think that what happens
in evolution is really. why has a killer virus not
killed all life on earth? well, what happens is, sure, super killer viruses that kill the ribosome have emerged. but you know what happens? they nuke a small space
because they can't propagate, they all die. so there's this interplay
between evolution and propagation, right? and death. and so- - in evolution? you don't think it's possible
to engineer, for example, sorry to interrupt, but
like a perfect virus- - no
- that's deadly enough. - no, it's nonsensical. - okay.
- i think that just, again, it wouldn't work,
'cause if it was too deadly, it would just kill the
radius and not replicate it. - yeah. i mean, but you don't think
it's possible to get a- (lee stammering) not kill all of life on
earth, but kill all humans? there's not many of us. there's only like, 8 billion. there's so much more ants. - i mean, i don't-
- so many more ants. and they're pretty smart. - the nice thing about where we are. i would love for the ai crowd to take a leaf out of the book of the biowarfare, chemical warfare crowd. i mean, not love, 'cause actually people have been killed with chemical weapons in the
first and second world war, and bio weapons have been made, and, you know, we can argue about covid-19 and all this stuff. let's not go there just now. but i think there is a consensus that certain things are bad and we shouldn't do them, right? and sure, it would be
possible for a bad actor to engineer something bad, but we would see it coming and we would be able to
do something about it. now, i guess what i'm trying to say is when people talk about doom and when you ask them for the mechanism, they just say, you know,
they just make something up. i mean, in this case, i'm yann lecun. i think he put out a very good point about trying to regulate jet engines before we've even invented them. and i think that's what i'm saying. i just don't understand why these guys are going round literally making stuff up about us all dying, when basically we need to
actually really focus on. now, let's say that
some actors are earnest. right, let's say yudkowsky
is being earnest, right? and he really cares. but he loves it, he goes, he-he-he, and then you are all gonna die. it's like, you know, why don't
we try and do the same thing and say, you could do this, and then you're all gonna
be happy forever after. - yeah.
- you know? - well, i think there's
several things to say there. one, i think there is a role in society for people that say we're all gonna die, 'cause i think it filters
through as a message, as a viral message that gives us the proper amount of concern. - okay. all right. - it's not 95%. but when you say 95%, and it filters through society, it'll give an average of
like .03%, an average. so it's nice to have people that are like, "we're all gonna die," then we'll have a proper concern. like for example, i do believe
we're not properly concerned about the threat of
nuclear weapons currently. it just seems like people have forgotten that that's a thing. and, you know, there's a war in ukraine with a nuclear power involved. there's nuclear powers
throughout the world. and it just feels like were on the brink of a potential world war to a percentage that i don't think people
are properly calibrating, like, in their head. we're all thinking it's a twitter battle, as opposed to like actual threat. so like, it's nice to have
that kind of level of concern. but to me, like, when i hear ai doomers, what i'm imagining is, with
unintended consequences, a potential situation where, let's say, 5% of the world suffers deeply because of a mistake made
of unintended consequences. i don't wanna imagine the entirety of human civilization dying, but there could be a lot of suffering if this is done poorly. - i understand that, and i kind of, i guess, i mean, i'm involved
in the whole hype cycle. so what's happening right now is there seems to be- so let's say having some people
saying ai doom is a worry. fine, let's give them that. but what seems to be happening is there seems to be people
who don't think ai is doom and they're trying to use
that to control regulation and to push people to regulate, which stops humans generating knowledge. and i am an advocate for generating as much knowledge as possible. when it comes to nuclear weapons, i grew up in the '70s and '80s where lot of adults really
had existential threat. almost as bad as now with ai doom, they were really worried, right? there were some great, well, not great, there were some horrific documentaries. i think there's one called "threads" that was generated in the uk, which was like, it was terrible. it was like so scary. and i think that the correct thing to do is obviously get rid of nuclear weapons. but let's think about
unintended consequences. we've got rid of- (lee muttering) we got rid of all the sulfur particles in the atmosphere, right? all the soot. and what's happened in
the last couple of years is global warming has accelerated 'cause we've cleaned up
the atmosphere too much. so-
- sure. i mean, the same thing if you
get rid of nuclear weapons, you get-
- exactly, that's my point. so what we could do is if we actually started
to put the ai in charge, which i really like, an ai to be in charge of all world politics. and this just sounds ridiculous
for a second, hang on. but if we could all agree on- - [lex] the ai doomers just woke up. - yeah, yeah, yeah, yeah.
- on that statement. - but i really don't like politicians who are basically just
looking at local sampling. but if you could say globally, look, here's some game theory here. what is the minimum
number of nuclear weapons we need to distribute around the world to everybody to basically
reduce war to zero? - i mean, just the start
experiment of the united states, and china, and russia, and major
nuclear powers get together and say, all right, we're gonna
distribute nuclear weapons to every single nation on earth. - [lee] yeah. (chuckles) oh boy. i mean, that has a probably
greater than 50% chance of eliminating major military conflict. - yeah.
- yeah, but it's not 100%. - but i don't think anyone will use them. and look, what you've
gotta try and do is, like, for to qualify for these nuclear weapons- this is a great idea. the game theorists
could to do this, right? the question is this. i really buy your question, we have too many nukes. just from a feeling point of view that we've got too many of them. so let's reduce the number,
but not get rid of them, because we'll have too
much conventional warfare. so then, what is the minimum
number of nuclear weapons we can just shoot around to remove- humans hurting each other is
something we should stop doing? it's not out with our
conceptual capability. but right now, what about certain nations that are being exploited
for their natural resources in the future for a short-term gain because we don't wanna generate knowledge? and so, if everybody had
an equal doomsday switch, i predict the quality of
life for a average human will go up faster. i am an optimist, and
i believe that humanity is gonna get better and better and better, that we're gonna eliminate more problems. but i think, yeah, let's- - but the probability of a bad actor, of one of the nations
setting off a nuclear weapon. i mean, you have to integrate
that into the atmosphere. - but we just give you the
nukes like population, right? what we do is we- (laughing) i can't believe this. but anyway, let's just go there. so if a small nation with
a couple of nukes uses one because they're a bit bored or annoyed, the likelihood that they
are gonna be pummeled out of existence immediately is 100%. and yet, they've only
nuked one other city. i know this is crazy, and i apologize for- - well, no, no. just to be clear, we're just having a thought experiment. that's interesting, but, you know, there's terrorist organizations that would take that trade. we have to ask ourselves a question of which percentage of humans would be suicide bombers, essentially? where they would sacrifice their own life because they hate another group of people. i believe it's a very small fraction, but is it large enough if
you give out nuclear weapons? - i can predict a future where
we take all nuclear material and we burn it for energy, right? 'cause we're getting there. and the other thing you could do is say, look, there's a gap. so if we get all the countries to sign up to the virtual nuclear
agreement where we all exist, we have a simulation, where we can each other in the simulation and the economic consequences
are catastrophic. - sure. in the simulation. i love it. it's not gonna kill all humans, it's just going to have
economic consequences. - [lee] yeah. i don't know, i just made it up. it seems like a cool idea.
- no, it's interesting. i mean, but it's interesting whether that would have as much
power on human psychology as actual physical nuclear exposure. - i think so.
- it's possible. but people don't take economic
consequences as seriously, i think, as actual nuclear weapons. - i think they do in argentina,
and they do in somalia, and they do in a lot
of these places where- no, i think this is a great idea. i'm a strong advocate now for- so what've we come up with? burning all the nuclear
material to have energy. and before we do that, 'cause mad is good, mutually assured destruction
is very powerful, let's take it into the metaverse, and then get people to
kind of subscribe to that. and if they actually nuke each other, even for fun in the metaverse, there are dire consequences. - yeah. yeah. so it's like a video game. we all have to join this
metaverse video game, and then there's dire
economic consequences. and it's all run by ai, as you mentioned, so the ai doomers are really
terrified at this point. - no, they're happy, they have a job for another 20 years, right? - oh, okay, fearmongering. - yeah, yeah, yeah. i'm a believer in equal employment. - you've mentioned that,
what did you call it? chemmachina?
- yeah. - yeah. so you've mentioned that a chemical brain is something you're interested in creating and that's a way to get conscious ai soon. can you explain what a chemical brain is? - i wanna understand the
mechanism of intelligence as gone through evolution, right? 'cause the way that intelligence
was produced by evolution appears to be the following. origin of life. multicellularity. locomotion. senses. once you can start to see
things coming towards you and you can remember the past and interrogate the present and imagine the future, you can do something amazing, right? and i think only in recent years did humans become turing complete, right? - [lex] yeah. - and so, that turing completeness kinda gave us another kick up. but our ability to
process that information is produced in a wet brain. and i think that we do not have the correct hardware architectures to have the domain flexibility and the ability to integrate information. i think intelligence also comes at a massive compromise of data. right now, we're obsessing about
getting more and more data, more and more processing, more and more tricks to get dopamine hits. so when we look back on this, going, oh yeah, that was really cool, 'cause when i asked chatgpt, it made me feel really happy. i got a hit from it, but actually it just exposed
how little intelligence i use in every moment,
because i'm easily fooled. so what i would like to do is to say, well, hey, hang on, what
is it about the brain? so the brain has this
incredible connectivity and it has the ability to, you know, as i said earlier about
my nephew, you know, i went from bill to billy and
he went, "oh right, leroy." like, how did he make that leap? that he was able to basically,
without any training. i extended his name, that he doesn't like. he wants to be called bill. he went back and said, "you
liked to be called lee, i'm gonna call you leroy." so human beings have a brilliant ability- or, intelligent beings appear
to have a brilliant ability to integrate across all
domains all at once, and to synthesize something which allows us to generate knowledge. and become turing complete on our own, although ai's a built-in
turing complete things, their thinking is not turing complete in that they are not able to
build universal explanations. and that lack of universal explanation means that they're just inductivist. inductivism doesn't get you anywhere. it's just basically a party trick. i think it's in the "fabric of
reality" from david deutsch, where basically, you know, the farmer is feeding
the chicken every day and the chicken's getting fat and happy. and the chicken's like, "i'm really happy every time the farmer
comes in and feeds me." and then, one day, the farmer comes in and instead of feeding the chicken, just wrings its neck, you know? and had the chicken had an
alternative understanding of why the farmer was feeding it. - it's interesting though, because we don't know what's special about the human mind
that's able to come up with these kinda generalities, this universal theories of things. and to come up with novelty. i can imagine, 'cause you
gave an example, you know, about william and leroy. i feel like a example
like that we'll be able to see in future versions
of large language models. we'll be really, really,
really impressed by the humor, the insights, all of it. because it's fundamentally trained on all the incredible humor and insights that's available out there
on the internet, right? i think we'll be impressed. - [lee] oh, i'm impressed. - right, increasingly so. - but we're mining the past.
- yes. - and what the human brain
appears to be able to do is mine the future.
- yes. it's a novelty. it is interesting whether
these large language models will ever be able to come up with something truly novel. - i can show on the
back of a piece of paper why that's impossible. and it's like, the problem is that, and again, these are domain experts kind of bullshitting each other. the term generative.
- yes. - right? average person thinks,
oh, it's generative. no, no, no. if i take the numbers
between zero and 1000 and i train a model to
pick out the prime numbers by giving all the prime
numbers between zero and 1000. it doesn't know what a prime number is. occasionally, if i can cheat a bit, it will start to guess. it never will produce
anything out with the dataset because you mine the past. the thing that i'm getting to is i think that actually current
machine learning technologies might actually help reveal
why time is fundamental. it's like kind of insane. because they tell you about
what's happened in the past, but they can never help you
understand what's happening in the future without training examples. sure, if that thing
happens again, it's like- so let's think about what large
language models are doing. we have all the internet as we
know it, you know, language. but also, they're doing something else. we're having human beings
correcting it all the time. those models are being corrected. - steered. - corrected. modified. tweaked. - [lex] well yeah, but i mean- - cheating. - (chuckles) well, you
could say the training on human data in the first
place is cheating but- - the human is in the
loop. sorry to interrupt. - yeah, so human is
definitely in the loop. but it's not just human is in the loop, a very large collection
of humans is in the loop. and that could be- i mean, to me, it's not intuitive that you said prime numbers, that the system can't
generate an algorithm, right? that the algorithm that
can generate prime numbers, or the algorithm that can tell you if a number prime and so on, and generate algorithms
that generate algorithms that generate algorithms that start to look a lot like human
reasoning, you know? - i think, again, we can show
that on a piece of paper. that, sure. so this is the failure in episdemiology. like, i'm glad i even can say that word, let alone know what it means, right? - you said it multiple times. - i know, it's like three times now. - without failure quit while you're ahead. just don't say it again,
'cause you did really well. - yeah, thanks. so what is reasoning? so coming back to the chemical brain, if i could show that in a- 'cause, i mean, i'm never gonna make an intelligence in chemmachina, because if we don't have brain cells they don't have glial cells, they don't have neurons. but if i can take a gel
and engineer the gel to have it be a hybrid
hardware for reprogramming, which i think i know how to do, i'll process a lot more information and train models billions of times cheaper and use cross-domain knowledge. and there's certain
techniques i think we can do. but it's still missing the abilities of human beings that had
to become turing complete. and so, i guess the
question to give back at you is like, how do you tell the difference between trial and error and the
generation of new knowledge? i think the way you can do it is this. is that you come up with
a theory, an explanation, just inspiration comes from out, yeah. you test that, and then you see that's
going towards the truth. and human beings are
very good at doing that in the transition between philosophy, mathematics, physics,
and natural sciences. and i think that we can see that. where i get confused is
why people misappropriate the term artificial intelligence to say, hey, there's
something else going on here. because i think you and i both agree, machine learning's really good. it's only gonna get better, we're gonna get happier with the outcome. but why would you ever think the model is thinking, or reasoning? reasoning requires intention. and the intention, if the
model isn't reasoning, the intentions come from the prompter, and the intentions come from the person who programmed it to do it. - but don't you think you can
prompt it to have intention? basically start with
the initial conditions and get it going. you know, currently large language models, chatgpt, only talks to
you when you talk to it. there's no reason why you
can't just start it talking. - but those initial conditions came from someone starting it, and that causal chain in there. so that intention comes from the outside. i think that there is something in that causal chain of
intention that's super important. i don't disagree we're gonna get to agi, it's a matter of when and what hardware. i think we're not gonna
do it in this hardware, and i think we're
unnecessarily fetishizing really cool outputs and dopamine hits, because obviously that's
what people wanna sell us. - i mean, agi is a loaded term, but there could be incredibly super impressive intelligence
systems on the way to agi. so these large language models, if it appears conscious, if it appears superintelligent, who are we to say it's not? - i agree. but superintelligence, i want to be able to have a discussion with it about coming up with fundamental new ideas that generate knowledge. and if the superintelligence
we generate can mine novelty from the future, that i didn't
see in its training set in the past, i would agree that something really interesting is coming on. i'll say that again, if the intelligence system, be it a human being, a chatbot, something else, is able to
produce something truly novel that i could not predict, even having a full audit
trail from the past, then i'll be sold. - well, so it should be clear
that it can currently produce things that are in a shallow sense novel that are not in the training set. but you're saying truly novel? - i think they are in the training set. i think everything it produces
comes from a training set. there's a difference between
novelty and interpolation. we do not understand where
these leaps come from yet. that is what intelligence
is, i would argue. those leaps. and some people say, "no, it's actually just what will happen if you
just do cross-domain training and all that stuff." and that may be true, and i may be completely wrong. but right now, the human
mind is able to mine novelty in a way that artificial
intelligence systems cannot. and this is why we still have a job and we're still doing stuff. and, you know, i used
chatgpt for a few weeks, "oh, this is cool." well, what happened is,
it took me too much time to correct it, then it got really good, and now they've done something to it. it's not actually that good. - [lex] yeah. right. - i don't know what's going on. - censorship, yeah. i mean, that's interesting, but it will push us humans to
characterize novelty better. like, what is novel? what is truly novel? what's the difference between
novelty and interpolation? - i think that this is
the thing that makes me most excited about these technologies, is they're gonna help
me demonstrate to you that time is fundamental and the unit future is
bigger than the present, which is why human beings are quite good at generating novelty because we have to expand our data set and to cope with unexpected things in our environment. our environment throws 'em all at us. again, we have to survive
in that environment. never say never. i would be very interested in how we can get cross-domain training
cheaply in chemical systems, 'cause i'm a chemist and the
only sentient thing i know of is the human brain, but maybe that's just me
being boring and predictable and not novel. - yeah, you mentioned
gpt for electron density. so a gpt-like system
for generating molecules that can bind to host automatically. i mean, that's interesting. that's really interesting. applying this to the same
kind of transform mechanism. - yeah. i try and do things that are non-obvious but non-obvious in certain areas. and one of the things i
was always asking about. in chemistry, people like to
represent molecules as graphs. and it's quite difficult. well, if you're doing ai and chemistry, you really want to basically
have good representations so you can generate new
molecules that are interesting. and i was thinking, well, molecules aren't really graphs and they're not
continuously differentiable. could i do something that was
continuously differentiable? well, i was like, "well,
molecules are actually made up of electron density." so then i got thinking, and said, "well, okay, could there be a way where we could just
basically take a database of readily solved electron densities for millions of molecules. so we took the electron density for millions of molecules
and just trained the model to learn what electron density is. and so what we built was a system that you literally could give it a- let's say you could take a protein that have a particular active site or, you know, a cup with a certain hole in it, and you pour noise into it, and with the gpt you turn the
noise into electron density. and then, in this case, it hallucinates, like all of them do. but the hallucinations are good because it means i don't have to train on such a huge data set, 'cause these data sets are very expensive. 'cause how do you produce it? so go back a step. so you've got all these molecules in this data set, but what you've literally done is a quantum mechanical calculation where you produce electron
densities for each molecule. so you say, oh, this
representation of this molecule has these electron densities
associated with it, so you know what the representation is, and you train the neural
network should know what electron density is. so then you give it an unknown pocket, you pour in noise, and you say, right, produce me electron density. it produces electron density
that doesn't look ridiculous. and what we did in this case is we produce electron density that maximizes the
electrostatic potential, so the stickiness, but minimizes what we
call the steric hindrance, so the overlaps, so it's repulsive. so they, you know, make the perfect fit. and then, we then use a kind
of like a chatgpt type thing to turn that electron density
into what's called a smile. a smile string is a way of representing a molecule and letters. and then, we can then- - [lex] so it just generates them then? - it just generates them. and then the other thing is, then we bung that into the computer and then it just makes it. - yeah. the computer being the
thing that, you're right, that could generate it.
- yeah, the robot that we've got that can basically just do chemistry. - creating the-
- yeah. so we've kind of got this
end-to-end drug discovery machine where you can say, oh, you want to bind to this active site? here you go. i mean, it's a bit leaky
and things kind of break, but it's the proof of principle. - but were the hallucinations,
are those still accurate? - well, the hallucinations
are really great in this case. 'cause in the case of
a large language model, hallucinations just make everything up. well, it doesn't just make everything up, but it gives you an output that you're plausibly comfortable with and it thinks you're
doing probabilistically. the problem on these
electron density models is it's very expensive to
solve a schrodinger equation going up to many heavy
atoms and large molecules. and so, we wondered if
we trained the system on up to nine heavy atoms, whether it would go beyond nine. and it did. it started to generate
molecules of 12, no problem. they looked pretty good. and i was like, "well, this
hallucination i will take for free, thank you very much." this is a case where
interpolation extrapolation worked relatively well and we were able to generate
the really good molecules. and then, what we were able to do here is, and this is a really good point of what i was trying to say earlier, that we were able to
generate new molecules from the known dataset that
would bind to the host, so a new guest would bind. were these truly novel? not really, because they
were constrained by the host. were they new to us? yes. so i do, well, understand. i can concede that
machine learning systems, artificial intelligence systems, can generate new entities. but how novel are they? it remains to be seen. - yeah, and how novel the
things that humans generate is also difficult to quantify. they seem novel. - that's what a lotta people say. so the way to really
get to genuine novelty, and assembly theory shows you the way, is to have different
causal chains overlap. and this really resonates with the time is fundamental argument. and if you're bringing
together a couple of objects with different initial
conditions coming together, when they interact, the more different their histories, the more novelty they generate
in time going forward. and so, it could be that genuine novelty is basically about mix it up a little. and the human brain is
able to mix it up a little, and all that stimulus
comes from the environment. but all i think i'm saying is the universe is deterministic
going back in time, nondeterministic going forward in time, 'cause the universe is
too big in the future to contain in the present. therefore, these
collisions of known things generate unknown things
that then become part of your data set and don't appear weird. that's how we give ourselves comfort. the past looks consistent with this initial condition hypothesis, but actually we're generating
more and more novelty. and that's how it works. simple. - (chuckles) so it's hard to quantify novelty looking backwards. i mean, the present and the future are the novelty generators. - but i like this whole
idea of mining novelty. i think it is gonna reveal why the limitations of current ai is a bit like a printing press, right? everyone thought that when
the printing press came, that writing books is gonna be terrible, that you had evil spirits and all this. they were just books. - and the same with ai. but i think just a scale you can achieve in terms of impact with ai
systems is pretty nerve-racking. - that's what the big
companies want you to think. - but not like in terms
of destroy all humans, but you can have major consequences in the way social media
has had major consequences, both positive and negative. and so, you have to kinda
think about and worry about it. but yeah, people that
fearmonger, you know- - my pet theory for this, you wanna know? - [lex] yeah. - is i think that a lotta, and i really do respect, you know, a lot of the people out there who are trying to have discourse
about the positive future, so openai guys, meta guys, and all this. what i wonder, if they're
trying to cover up for the fact that social media's had a pretty disastrous
effect on some level, and they're just trying to say, ah yeah, we should do this. and covering up for the fact that we have got some problems with, you know, teenagers, and instagram, and snapchat, and, you know, all that stuff. and maybe they're just overreacting now. it's like, "oh yeah, sorry, we made the bubonic plague
and gave it to you all, and you're all dying, and, oh yeah. but well, look at this over
here, it is even worse." - yeah, there's a little bit of that. but there's also not enough celebration of the positive impact that all
these technologies have had. we tend to focus on the negative and tend to forget that- in part, because it's hard to measure. like, it's very hard to measure the positive impact social
media had on the world. - yeah, i agree. what i worry about right now is like i do care about the ethics
of what we're doing, and one of the reasons why i'm so open about the things we're
trying to do in the lab, make life, look at intelligence, all this, is so people say, "what are
the consequences of this?" and you say, "what are the
consequences of not doing it?" and i think that what
worries me right now, in the present, is the
lack of authenticated users and authenticated data and- - human users.
- yeah, human- - i still think that
there will be ai agents that appear to be conscious, but they would have to
be also authenticated and labeled as such. 'cause there's too much
value in that, you know, like friendships with ai systems. there's too much meaningful
human experiences to have with ai systems that i just... - but that's like a tool, right? it's a bit like a meditation tool, right? some people have a meditation tool, it makes them feel better. but i'm not sure you can ascribe sentience and legal rights to a chatbot that makes you feel less lonely. - sentience, yes. i think legal rights, no. i think it's the same. you can have a really deep
meaningful relationship with a dog and a pet. - well, the dog's sentient. - [lex] yes. - the chatbot's right now, using the technology we use
is not gonna be sentient. - aah, that's gonna be a
fun continued conversation on twitter that i look forward to. since you've had also, from another place, some debates that were inspired by the assembly theory paper, let me ask you about god. is there any room for notions
of god in assembly theory? whose god? - yeah, i don't know what god is. i mean, so god exists in our mind, created by selection. so human beings have
created the concept of god in the same way that
human beings have created the concept of superintelligence. - sure. it still could mean
that that's a projection from the real world, where like we're just assigning words and concepts to a thing
that is fundamental to the real world. that there is something out there that is a creative force
underlying the universe. - there is a creative
force in the universe, but i don't think it's sentient. so, i do not understand the universe, so who am i to say, you
know, that god doesn't exist? i am an atheist, but i'm not an angry atheist, right? there are some people i
know that are angry atheists and say, you know-
- yeah, cranky. - say that religious people are stupid. i don't think that's the case. yeah, i have faith in some things, 'cause i mean, when i was a kid, you know, i was like, "well, i need to know what
the charge of a electron is." and i'm like, "i can't measure
the charge of a electron." you know, i just gave up and had faith. okay, you know, resistors worked. i want to know why the universe is growing in the future and what
humanity's gonna become. and i've seen that the
acquisition of knowledge via the generation of
novelty to produce technology has uniformly made humans' lives better. i would love to continue that tradition. and- - you said that there's
that creative force. just to think on that point, do you think there's a creative force? is there like a thing, like a driver that's creating stuff? - so i think that- - and where? what is it? can you describe like mathematical? - well, i think selection. i think selection.
- selection is the force. - selection is the force in the universe that creates novelty. - so is selection somehow fundamental? - yeah. i think persistence of objects that could decay into nothing through operations that
maintain that structure. i mean, think about it. it's amazing that things exist at all, that we're just not a
big combinatorial mess. - [lex] yes. - so the fact that- - a thing that exists, persistent time. - yeah. let's think, maybe the universe is actually in the present. everything that can exist
in the present does exist. - well, that would mean
it's deterministic, right? - so the universe started super small, the past was deterministic, there wasn't much going on, and it was able to mine,
mine, mine, mine, mine. and so the process, i mean, is somehow generating- the universe is basically- i'm trying to put this into words. - did you just say there's
no free will, though? - [lee] no, i didn't say that. - 'cause it everything that can exist- - sorry. i said there is free will. i'm saying that free will
occurs at the boundary between the- - the past and the future?
- the past and the future. - yeah, i got you. but everything that can exist does exist. - so, everything that's
possible to exist at this- so, no. i'm really- - there's a lotta loaded words there. in that there's a time element
loaded into that statement. - i think the universe
is able to do what it can in the present, right?
- yeah. - and then, i think in the future, there are other things
that could be possible. we can imagine lots of things, but they don't all happen. - sure. that's where you sneak in
free will, right there. - yeah. so i guess what i'm saying is what exists is a convolution of the
past with the present and the free will going into the future. - well, we could still
imagine stuff, right? we could imagine stuff
that will never happen. - and it's a amazing force. the most important thing
that we don't understand is our imaginations can actually change the future in a tangible way, which is what the initial conditions and physical cannot predict. like, your imagination
has a causal consequence in the future. - isn't that weird to you? - yeah. - how do you- hmm?
- it does break the laws of physics as we know them right now. - yeah. so you think the imagination has a causal effect on the future? - yeah.
- but it does exist in there, in the head. - it does, but-
- and it must be a lot of power in whatever's going on. there could be a lot of power, whatever's going on in there. - if we then go back to
the initial conditions. it's simply not possible that can happen. but if we go into a
universe where we accept that there is a finite
ability to represent numbers and you have rounding- well, not rounding errors. what happens, your
ability to make decisions, imagine, and do stuff is at that interface between the certain and the uncertain. it's not, as joscha was saying to me, randomness goes and you just, you know, randomly do random stuff. it is that you are set free
a little on your trajectory. free will is about being able to explore on this narrow trajectory that allows you to build. you have a choice about what you build. or that choice is you interacting with a future in the present. - what to you is most beautiful
about this whole thing? the universe? - the fact it seems to be
very undecided, very open. the fact that every time i
think i'm getting towards an answer to a question, there are so many more questions that make the chase, you know? - do you hate that it's gonna
be over at some point for you? - well, for me. i think if you think about it, is it over for newton now? newton has had causal
consequences in the future. we discuss him all the time. - his ideas, but not the person. - the person just had a lot of causal power when he was alive. but, oh my god, one of
the things i wanna do is leave as many easter eggs in the future when i'm gone to go, "oh, that's cool." - would you be very upset if somebody made like a good large language model that's fine-tuned to lee cronin? - it would be quite boring 'cause i mean- - [lex] no novelty generation? - if it's a faithful
representation of what i've done in my life, that's great. that's a interesting artifact. but i think the most interesting thing about knowing each other is we don't know what we're gonna do next. - sure. (sighs) sure. - i mean, within some constraints, i can predict some things about you, you can predict some things about me, but we can't predict everything. - [lex] everything. - and it's because we
can't predict everything is why we're excited to come
back, and discuss, and see. so yeah, it'll be
interesting that some things that i've done can be captured, but i'm pretty sure that
my angle on mining novelty from the future will not be captured. - yeah. yeah. so that's what life is, it's just some novelty generation, and then you're done. each one of us just generate a little bit. or have the capacity to, at least. - selection produces life and
life affects the universe, and universes with life
in them are materially and physically fundamentally different than universes without life. and that's super interesting. and i have no beginnings of understanding. i think maybe this is like in 1000 years, there'll be a new discipline, and the humans will be like, "yeah, of course, this is
how it all works, right? - in retrospect, it will
all be obvious, i think. - i think assembly theory is obvious, that's why a lot of
people got angry, right? they were like, "oh my god,
this is such nonsense." - yeah.
- you know, and like, "oh, you know, actually, it's not quite, but the writing's really bad." - well, i can't wait to
see where it evolves, lee. and i'm glad i get to exist
in this universe with you, you're a fascinating human. this is always a pleasure. i hope to talk to you many more times, and i'm a huge fan of just watching you create stuff in this world. and thank you for talking today. - it's a pleasure, as always, lex. thanks for having me on. - thanks for listening to this
conversation with lee cronin. to support this podcast, please check out our
sponsors in the description. and now, let me leave you with
some words from carl sagan. "we can judge our progress by the courage of our questions and the
depth of our answers, our willingness to embrace what is true rather than what feels good." thank you for listening, and hope to see you next time.