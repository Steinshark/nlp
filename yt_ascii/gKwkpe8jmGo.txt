hello and welcome. i'm james murphy. in this episode, we're talking about the core guideline that says that you shouldn't use std::endl and some common pushback about this guideline that i hear concerning multi-threaded code. the core guideline says that most of the time you should just prefer to use a newline literal inside of your strings instead of using the standard endline. the reason for doing this is twofold. sometimes it avoids an extra write operation. here we needed a second call to the write operator in order to write the new line. but here, we were able to just include it in our string since we were already using a string literal. but even in a case like this, where you can't save the extra write operation, it's still preferred to use a new line over standard endline. the reason for this is buried in the standard. so, don't feel bad if you didn't know where to look. but the effect of writing a standard endline is to first write the new line character and then call flush on the stream. not all the time, but sometimes, flushing can be very expensive, like if you're writing to a file, especially. and in that case, doing unnecessary flushes will severely impact your performance. if you're not already familiar, a lot of output streams are buffered. what that means is, when you write text into this file object, it doesn't necessarily mean that that immediately writes the text to the underlying resource, in this case, the file. instead, it may just keep track of all the stuff that you've written in an in-memory buffer and then sometime later write all the stuff to the file all at once. the process of writing the in-memory buffer data of the file object into the actual file on disk is the process of flushing if we were to use endline because of the flush that end line implies, this means that we're going to be flushing and synchronizing with the file system three times in this code. whereas, in this code, we don't necessarily have to flush it all until the file object is destroyed. so, in its destructor, it would call flush and flush all the data all at once. the actual amount of speed-up you get from doing this is going to depend a lot on the relative cost of doing a flush. so, for something like writing to a file, you'll typically see a bigger speed up. but for something like writing to standard out, you wouldn't see as much of a speed up. it's not required by c++, but a lot of implementations will flush the buffer for standard out every time it sees a new line anyway. in that case, if you use endline, you're basically just doing a redundant flush of zero characters immediately afterwards. any decent implementation won't actually flush if there are zero characters. so, your penalty will just be the penalty of an extra if-check. however, whenever i suggest this guideline, inevitably someone asks: hey, doesn't endline protect you in a multi-threaded situation? i'm not quite sure where this myth originates from but it's sure widespread. and the answer is: no, it does not protect you at all. let's take a look at a simple multi-threaded example to investigate. here, i have a worker that takes in a start, a stop and a stream to output to. it just loops from the start until the stop and output some info about which thread and what number it's on. then down here, i just start up two threads that call the worker function. the first worker is going to print from ten thousand to twenty thousand and the second worker is going to print from twenty thousand to thirty thousand. for this example, the stream i'm using is just a file stream going to this out.txt okay, i went ahead and built it and let's run it. it appeared to run fine with no errors but let's check the output. when we look at the output, we see all kinds of messed up lines here. some lines like this one printed out just fine. other lines have sort of part of one line and part of another line mixed together. and other lines are just fragments of what they should be. so, clearly this is not the output i was expecting. so, what output was i realistically hoping for? well, i'm doing these two different chunks of work in two separate threads. so, i can't really expect them to be ordered in any particular way with respect to each other.   however, the bare minimum that i could hope for is that, i at least get complete lines.   let's take that as our goal. suppose we don't care the order the lines come in, only that we get complete lines. so, how do we accomplish that? well, as per the common myth, let's see what happens if we try standard endline. does this protect us in some way? recompile rerun but the output is exactly the same, garbage. i hope this helps dispell the rumor that standard endline somehow is better than newline because it fixes data races. it clearly does not do that. the underlying issue here was not whether or not the data has been flushed to the file yet. the real issue is that we have two threads trying to write to the same place at the same time. if changing a newline to an endline fixes this problem for you, then you got lucky. most likely this did not fix your issue and it just made it less likely to occur. so, you now have the same bug that will only manifest in a very rare case. maybe it only happens every 100th time you run the program. and honestly, to me a bug like that is much worse than a bug that fails everytime. at least, if it fails every time, i know something is wrong and can try to fix it. if endline doesn't actually fix this, then what's the real fix? let's take a look at the solutions for c++ 20, c++ 17 and c++ 11. if you have the luxury of using c++ 20, it's really simple. start by including the syncstream header. make a standard osyncstream that wraps the output stream that you actually want to write to. then everywhere that you were going to write to the output stream, write to the osyncstream. osyncstream guarantees that it's safe to write to an output stream from multiple threads as long as all of those threads write to it through an osyncstream object. under the hood, it uses some kind of lock or mutex in order to accomplish this. it will acquire the lock or mutex on construction and release it when it's destructed. and while we're at it, since we're using c++ 20, we might as well use jthread instead of thread. jthread is the same as a thread except it automatically joins in its destructor so you don't have to remember to call join. and here's the output. in that case, as you can see, we get only complete lines in the output. of course, these threads are computing. so, the order of these lines is not deterministic. if i were to run this again, i would get something completely different. so, the order is still not guaranteed. but at least, we don't have any mangled lines. okay, what about c++ 17? osyncstream and jthread were added in c++ 20, so we need to use something else. osyncstream took care of the mutex for us. prior to c++ 20, we need to do it ourselves. so, include mutex and make a global write_mutex. you might be tempted to just lock and unlock the mutex yourself and that would probably work. but that's not the best solution. the issue with this is that if an exception is thrown even if you handle it somewhere else, you might not release the lock in time. in c++ 17, use scoped_lock. it locks the mutex on construction and releases it on destruction. if you're using c++ 11 on the other hand, then use standard lock_guard. it does the same thing as scoped_lock. scoped_lock is basically just an all-around better version of lock_guard. of course, we can't remove lock_guard from the language because people depend on it. but notice that for lock guard, i have to specify this is a standard mutex, whereas for a scoped_block it was inferred. and scoped_lock can handle multiple locks, whereas lock guard can only handle one.   so, that's the real way that you fix these mangled lines in c++ 11 through 20.   finally, let's take a step back and think about the design that we have going on here.  i didn't really mention it before. but anytime that you really have two threads competing for the same resource like this, you might want to rethink your design. although the mutex is protecting us from undefined behavior and mangled lines, it's not protecting us from bad performance. we still have two threads that are constantly fighting over acquiring this mutex. this is going to be horrible for performance. instead, we may want to implement our own buffering where we say, write a thousand lines into a local string stream and then only try to grab the lock and write to the file every thousand lines. this is going to be much better for performance because each thread acquires the mutex a thousand times less than it did before, meaning there's way less contention. and another design decision that you might want to think about is that it may not be the best practice to have each thread just trying to write to whatever file stream or standard out or whatever. in larger applications, it would be a common design to have a single thread in charge of all of the printing or writing to file that needs to be done. and other threads just submit data to the printing thread through some kind of thread safe queue. hey, thanks for watching and since you made it all the way to the end you get to hear about the giveaway that i'm doing. this is a paid editor for c and c++ that i'm using called clion. if you'd like a chance to get a license for free, then be sure to make a comment including #clion below. thanks to jetbrains for providing the licenses. and as always, thank you to my patrons and donors for supporting me. if you enjoy my content, then please consider becoming a patron. thanks and see you next time.