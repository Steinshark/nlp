foreign well i was wrong so time to own it what is a photo what is a photo that's a that's a real question that i'm not sure has a straightforward answer anymore in this age of smartphone cameras that we live in case in point the latest questions with samsung now this is a bit of a part two to a video i've already made called what's happening with the iphone's camera but that's about the broader topic of smartphone cameras and computational photography and the more interesting thing which is taking pictures of people i'll link that below the like button this one is more of a side quest of the specific edge case of phones with zoom at night zooming all the way in and taking pictures of the moon so first i'd like to admit i was wrong i made a short about a month or so ago i'm not going to delete it but it's of me zooming all the way into 100x space zoom on the galaxy s23 ultra and taking a picture of the moon that looks really impressive and i said i guess it's not doing the ai fakery that huawei got caught doing years ago but to be fair that's not what i should have done what i should have done is actually tested it done some a b experiment type stuff i should have tested it and ran an experiment like reddit user i break photos actually did this past weekend and well as you can probably tell the findings were kind of interesting so let me show you so basically when you point a camera in the sky and zoom all the way into the moon it recognizes the moon as a subject of the photo and it locks the electronic stabilization on the target sets the focus distance to infinity and fires up a detail improvement engine to make the moon look much clearer than it would normally be the easiest way to prove this is exactly how the reddit experiment went if you load up a full resolution picture of the moon and point the camera at it it triggers all these systems and the same set of processes but then if you pull up a blurred photo of the moon with many of these details obscured and do the exact same thing zoom all the way in point the camera at it what happens is it still runs all the same improvements and processes because it recognizes a moon and then it turns out the camera will spit out a clearer more detailed photo of the moon with all sorts of sharp detail that wasn't even in the source image it feels weird it feels fake like the fact that it's getting a bunch of detail out of the shot that wasn't in front of your camera in the first place just feels wrong to be fair it's not exactly doing what huawei was accused of doing huawei is accused of doing this brute force like overlay fakery where okay you point theirs at the moon it recognizes the moon and then it just drops an overlay on top of the moon to get that detail out of nowhere because that's what our brains assumed that was happening huawei denies this but to be fair this would work with moon photography because the moon as you know is tidally locked and the same side always faces earth so the overlay would always be perfectly accurate but what's actually happening with samsung's is a little more complicated than that so like i said you point that camera at the moon once you get past 25x zoom if the sky is clear enough and the moon is recognized as the target the camera app turns the exposure all the way down to take it from a glowing white orb to an actually somewhat detailed object then like i said it sets the focus to its furthest distance it locks the electronic stabilization on the target object and then it runs a series of noise reduction and detail enhancement processes that basically ai sharpen in what you see in the viewfinder towards what it knows the moon is supposed to look like so yes everyone who has this phone that takes a picture of the same moon is gonna get like basically the same looking image at 100x but it you know if it's got some color to it if the moon is red to you then it will keep that intact if something flies in front of it theoretically that should stay intact and then it matches the phase of the moon so it'll work on any phase half moon gibbous crescent whatever that's fine too now i might be asking marquez how do you know all of this well one because we actually ran these experiments on pictures of the moon like the reddit user did but also too there is an entire post on a samsung forum there's a samsung community forum and there's a post that details all of this like how it works what phones it works on and the step-by-step process that it goes through when it recognizes the moon in the sky it's in korean so you may have to run it through translate to read it yourself but yeah it's out there so you can disable this feature just by turning off the scene optimizer setting in the camera app whose description right now on my phone says it makes dark scenes look brighter food look tastier and landscapes look more vivid they should also add also makes the moon look extra crispy and bright and detailed so you can flex on all your iphone friends who don't have 100x zoom but to me this is just one of many types of photos that our smartphones are already editing for us i've said it in a previous video the the stuff that comes out of the smartphone camera isn't so much reality as much as it's this computer's interpretation of what it thinks you'd like reality to look like so of course anytime there's a full moon everyone with an s23 ultra is super tempted to zoom all the way in and take the same picture of the moon because it looks super impressive and it's visually cool but also then the headlines are going to say hey that's kind of fake but these phones will continue to recognize the land escape and turn the grass more green or recognize a wide angle shot with the sky in it and turn the sky more blue it'll recognize a photo of food and boost the most saturated colors of course the one with the moon is the most visually impressive and easy to pay attention to but what is a photo moon mode magic makes the media mad but many more manipulated megapixels have their merit thanks for watching catch you guys in the next one peace [music] foreign