there's now two questions which i both want to read to you because they're basically almost the same thing but one is coming from like then the other one is from who below what do you think about the use and role of ai and code development especially in c plus plus and let me layer over linkedin how do you see the future of tools in ai extensions which do generate the code and also programmers in the very long okay yeah this is a this is an interesting topic and one that i i managed to find a quote from myself in a talk and i gave him poland in 2016 where i i was asked a very similar question and obviously the the world in 2016 from the point of view of code based generative ai is very different to the world in 2023 at that point we're saying what might happen in the future well now we're in the future and my key observation was you've still got a job well done but you better be testing you need to get better at asking questions you need to get better at understanding what it is that you want you or your eye also needs to get better at being able to discriminate a good solution from a bad solution being able to generate code is wonderful at one level except when it doesn't work and you need to know that it doesn't work and what we're going to find is that a lot of people are going to use ai related tools so you can use a lot of you know generative ai to generate code and a lot of that code is going to be not quite right and they won't know it because they won't test in other words what we're going to find is that in future they will be the people that remember to test their code and already are good at testing but they're also good at specifying their problem and immediately recognizing if what they're getting is not quite right and then we're going to have a lot of people who are going to use this just like any other tool and they're not going to do that and they are going to create what we like to call legacy code because it's legacy code because you didn't write it it's written by somebody else it doesn't quite work or doesn't quite do what you need it to do but now you've got to fix it and you and this often happens sometime you know we we push the code into production but we didn't test and now next week i've got to fix a problem but i thought the code looked okay and the problem is we're already seeing this happening and we're seeing it happening in a number of cases i think one of my favorite ones is bertram meyer actually published an article earlier in the year where he talked about getting a solution from ai and to a very simple problem and he said it looks plausible in this but there's a there's a bug and then he chose another solution and he asked the question differently and it generated and he was satisfied with it there's only one problem it didn't work but he didn't test he just thought if it looks and feels right or it looks complicated enough that it's probably right we have this very funny filter the cut off you you probably have mixed feelings about generating unit tests versus ai which i've seen typically yeah yeah because because again i i tend to ask when i so i i had an interesting experience it wasn't with c plus plus early in the series i i did some stuff with kotlin but i'm not a kotlin programmer but i thought you know what i'll ask i'll ask chat gpt [music] i've also since asked bard and gave me it gave me a much more working solution at that point but chat gpt asked its solution and it gave me something that was idiomatic kotlin and it was absolutely brilliant there's only one problem is it completely hallucinated the functions that i needed and then he eventually gave me a solution when i pointed this one out and that solution again looks plausible except for one thing it didn't produce the right answer fortunately i had tests to spot that it did all the mechanics it did all the movement you had the loops and all the rest of it but it didn't produce the right answer and then the next so in other words you need to consider when you look at it from the point of view of ai you need to consider there's a conversation it's not generating code for you it's not a straight through process it's not a formal transformation it's a conversation what about this what about that let me just check that for you okay that's not quite what i was after or i'll take what you got and then i'll adapt it but there's a human in the loop and there's tests in the loop now when we start saying let's generate unit tests for that it's like well tell me what you mean by that are you going to tell me that you're going to get something to generate you both the code and from the same words and specifications it's going to generate the say it's going to generate tests yeah good luck with that first of all it's not going to run them it's going to leave it to you because these are not running them that's an important thing they that's that's a solvable problem by the way they can do that and they can learn from that but at the moment that's not really that's not really what's happening but there has to be something in the loop that asks the question different way and there has to be something that applies judgment and goes oh wait a minute i understand the ambiguity of what i asked the problems with me or actually the problems with you you're hallucinating that's that's where the human is going to be important because otherwise we're going to be generating code that other people wrote we already have that problem so in other words that's we've already got that problem the idea of multiplying it and creating a huge legacy debt is a problem i'm perhaps a little more interested in seeing ai on the refactoring side take this code refactor it into something cleaner and then i already know what i'm expecting and i can write the tests against that and now we've got rid of the problem with legacy code but if the problem that we have is creative if we start using ai to create new legacy code i think and there's a lot of people that are doing that and have done that and will do that i think that's going to be a problem yeah it's fast it looks like you're getting results but the what's going to distinguish the top programmers from the rest is those are the top programmers who know what they want and know how to get it and know there's a dialogue and they are going to potentially they're gonna get some really good stuff so i think it's going to widen the gap but in terms of software developers in terms of potentially the skills or capabilities that people adopt i've seen your experiment with scotland and yes it's really interesting that basically you know you get to to the point where you have code that you can put on a slide then most people in the audience will believe that kevin henny or you know anyone else could present this slide and people would read through it and say oh of course that's how you do it in kotlin and then well actually no that's completely hallucinated and i think there's a huge problem with which a lot of people still need to start understanding that those systems are not truthful and do not have any idea of wrong or true or false they have the i mean there's a bigger discussion here which i don't think we have the time for but there's there's understanding what is the nature of such software and that idea i think is going to be [music] i i think there are certain things that can be improved and will improve but there's also something else that is fundamentally missing that still requires a human in the loop and i think that is going to be you know you are left with the same problem how do i specify what i want okay that requires precision and that is sometimes people call that computational thinking it's not about the curly brackets it's about being able to say that i want this with this and being absolutely precise and then knowing what you've got that there is a skill in that space and if you don't have that you're constantly going to be chasing broken things you'll look very busy and in some ways you might even look productive but i i think that there is a there are going to be some issues with that i would also be interested in the role of ai from the point of view there was a question the question was phrased also by the way with specific specifically with spread to c plus plus let's go right back to where we started and also talking about cpp2 the complexity of c plus plus what you kind of want is a you know static analysis but at a at a richer level potentially it's that let me not just offer things to ai and say hey generate me this is i've got some c plus plus can you see anything wrong with this or you know what are the memory what potential memory issues here are all you know these kinds of things tell me about this from a security point of view let's turn this around and not think of it just as generator but as reviewer i think there's potential yeah okay oh yeah so i think there's a lot of things that it's very easy to fall into the generation idea as being of that's what we're going to get it's like actually no there's a number of issues with that not all of which are going to be problems forever there are but there are still a number of issues but maybe we're missing some of the point maybe maybe there's a lot more that we can use something that has been trained on a vast body of code that could potentially offer us and again i want to go back to this idea of conversation it's a you know that that i do it's a dialogue if you start looking like that i think you're more likely to get good results all right and to kind of close