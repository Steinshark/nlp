okay a cautionary tale about chat gpt for advanced developers now this is funny because typically when i when i think about these things is that i think chat gpt is really really bad for new users but i think okay it there's some advantages being a being an advanced developer being someone that has a lot of seniority to being able to use something like chat gpt so i'm actually very curious why this is the case when chat gpt first came out i decided to essentially only use it sort of like a coworker that i would occasionally get help from and i decided not to more deeply integrate ai assistants like github copilot into my workflow but i've actually really enjoyed github co-pilot i have i have i've actually genuinely enjoyed it i think it's it's pretty dang pretty dang good you hate co-pilot well the thing is you got to make sure if you use co-pilot if you use co-pilot as something to write your code you're wrong i've said this a lot of times co-pilot as a means to write your code is terrible co-pilot as a means to write your bo boiler plate really really good and you got to you got to do that do do i use co-pilot on netflix absolutely i just use it all the time year or so later i've still been sticking to this i still haven't used github co-pilot and whilst i'm still not heavily using chat gpt it has become a common part of my workflow and has unlocked skills and opportunities for me that might not have been possible without it just recently something happened that i think highlights what are both the most powerful and most dangerous aspects of chat gpt for more advanced code so this little story with this issue that was opened on an open source utility i've been maintaining the existence of this utility is what highlights the powerful aspects of chat gpt i had a lot of the knowledge necessary to build this thing by the way this is what i call this is what i this is why i say typescript is kind of bad okay and the reason why i say this is that look at if you make a change fundamentally at all to your program how much f effort and time is it going to take for you to rework all of these if at any point you think that too many unit tests cause it is it makes it so that people are scared to delete code and all these kind of things like this is even harder but it's so good when it's working that's the problem it's type masturbation it's not you're not providing a materially like it is nice but is it worth the effort and that's the thing that i often see is sometimes you know a record string whatever is just nicer i understand that you can do that but man i'm always just so hesitant about these things because they always end up being such a pain in the ass to maintain just such a pain in the ass to maintain but the toping required for it is quite complex and i couldn't rely on my real person coworker in this scenario to just do all of the my boy i recognized this image from from the old twitters the hard bits for me although chat gpt couldn't just in stly solve all of the typing problems i threw at it its suggestions combined with the knowledge i did have about typescript allowed me to get things working it also push me to learn more about the areas where i lacked the appropriate knowledge and apply them directly and immediately to a real scenario without this sort of i still i still think this is just still completely wrong accelerated learning chat gpt can provide i might not have had the time to complete this task this is the part that i think is extremely powerful about chat gpt it can be great at getting you unstuck you might know most of what you need to build something or achieve some task but maybe there is some part you are lacking that just completely blocks you from getting it done chat gpt can help break through those barriers quickly and point you in the direction you need to go especially in these more advanced scenarios where there might not be obvious or pre-existing solutions figuring out what you need to even be learning in the first place can be difficult and timec consuming what i found with building this utility was that for the early parts of the project i'm much more heavily relied on chat gpt for ideas or implementations but as the project progressed i was rapidly learning the key bits of knowledge i was missing and felt capable solving most typing issues with no assistance by the way this is like the ideal right can we all agree that this would be the ideal ai learning ability which is that you have these knowledge gaps it helps you get across them and by getting across them you now have this new knowledge gained and you are now faster like this is the ideal way of of of learning really is like even just i was having just yesterday i actually used chat gpt as a method for searching because i want to find a way to craw a project based on imports in node and produce out the minimal set of javascript files that are used in a project and i realized that it's that's very hard to google it is you use way too many words that just that are commonly used for everything but i can explain it via chat gpt and chat gpt actually pointed me into some libraries that were semi-useful and so that was pretty cool it was like a good experience i was very happy about that i still need a lot more work and i realize that it's it's completely it's not there but it is nice ended up with a solid product and a bunch of new knowledge i could use for future projects and for maintaining this project this i think is a healthy and powerful way to use ai coding assistance where i think it is not as healthy is where you are relying on it to substitute for large gaps in knowledge there is a scenario i run into constantly with chat gpt that feels like a giant trap for people who might be over relying on chat gpt and don't have an appropriate level of knowledge and context for the task so this is where this issue comes into the story when first reading about this bug i did already have a sense of what was happening it's a type inference issue i had run into before but it had been a while since i had worked on signal slice so i was lacking some context and like everyone else i'm always lacking time so i handballed it to chat gbt to see what it would say it gave me a seemingly reon reasonable answer he wanted me to create these util the term reasonable is is hilarious in this situation in the sense that a lot of us look at this and already feel like something unreasonable has happened here but what are all these but seemingly reasonable but i i do like what this is going which is there is definitely a danger here that you're going to just you're going to get into this infinite tree of exploration on all the wrong paths because you can't guide that's where my assumption of this is going i instead of using the taction sources and te action effects types directly the crux of the problem was that the generic types for taction sources and taction effects were being inferred too early my knowledge of advanced typescript still isn't strong enough to know at a glance if this was going to work but it looked promising it didn't work though this sort of thing happens all the time with chat gpt it gives a promising looking answer but it just doesn't work so i press chat gpt some more explaining that it doesn't work and as is commonly the case it suggested sweeping changes it wanted me to switch to a class-based approach and use a builder pattern that would completely change how the public api for the utility works i feel at this point it would be easy to assume that chat gpt is right and that what you're trying to do just isn't possible with the current setup so you either give up or make the drastic changes chat gpt suggests but i wasn't just swinging wildly with chat gpt here i did have an understanding of the problem general knowled of how the utility works overall and what i'm trying to achieve with it i i do i am actually just curious overall if there's like something to be said about this moment where chad gpt suggests a a different type in which if a builder let's just pretend this builder pattern actually allows for this to happen and allows you to make it easier perhaps there is something to this to always just kind of take in which is maybe there's just even though it changes the api and all that maybe the api is part of the problem you know it's one of the dangers i always have with typescript which is that you can build the most immaculate type inferences which often can lead to really simplistic apis which actually hide underneath the hood an incredible amount of complexity and so i'm i'm curious about this like is it both wrong and right it's obviously wrong in the sense that suggesting a complete rewrite is stupid like that's not that's not that's almost never the answer but maybe it's accidentally suggesting something different which is maybe there's just a simpler way to approach the problem to begin with i have a whole heap of context that chat gpt doesn't and so with a little more effort i was able to come up with my own solution it involved creating more targeted types so that properties were typed only with the specific features they actually need to function rather than supplying them everything in by the way i can't i i don't even know what this stuff says like i i i vaguely recognize things right i know that that mean this thing extends this just means that this thing is like some sort of ti some sort of structural value value of this thing with a you know but i'm still not very good at it the signal size this is what would cause some types to be inferred too early this required only a small change to fix for those saying what the f is this it's a type it's a type definition so effect state has three generics on it they all need to fall within this parameters and the type and effect state is a selector state and an extra selectors and an action methods so it's it's it's a union of all these things together with these generics needing to be set but i still like i don't like these things are still very just like a lot to me it's the issue out of curiosity i decided to grill chat gpt a bit i asked what it thought of the solution i had come up with with the typical chat gpt flattery it said the solution was elegant and gave reasons why i asked why it didn't suggest something like this initially and it defends itself quite well actually it said essentially that my approach is tailored to this specific situation whereas chat gpt was generally going to go for a more general solution again with some flattery thr in for good measure this is essentially why i think at least for now it is still so important to not too heavily rely on coding assistance having again i think this is actually just one of the best arguments for why co-pilot is better co-pilot doesn't you don't ask co-pilot questions effectively like yeah sometimes i'll say co-pilot read read the standard in line by line and it will do that and that's nice but it's it's it's me in control whereas like i'm asking an open-ended question that could go in several different several different directions whereas with typically with co-pilot you're you're kind of taking it in this one specific direction cop chat i'm i i i'm not really into the chat based versions i think that they're just largely going to be a miss for a long time and maybe someday in the future maybe a year from today maybe when chat gpt 5 is announced maybe when chat gpt 6 is announced i'm just not really fully convinced that these chat style programs are are really that huge of a win other than there are some things that it's it's pretty good at right like if you wanted to bounce some ideas about how to do module resolution in node like let's just go back to that example i gave you want to be able to take a singular file and resolve to which actual literal js files this resolves to how would you do that now this is something that you could bounce ideas off of chat gpt but i wouldn't necessarily want to use chat gpt as a method to implement it even though it's a fairly blackbox problem you could start kind of trying to you know bring it down and all those kind of things but i think you're going to just run into a lot of oddities because it's not it's so much better if you have the knowledge and you drive it in these small little slices as opposed to you letting it drive and you're just giving it the small slices if that makes sense in context of the problem and the system in general allows you to search for solutions where a coding assistant might miss them and to know when a coding assistant might just be leading you astray this is partly my worry about more integrated ai assistant like github co-pilot having it handled boiler plate syntax and apis for you probably provides a massive speed boost to development with no important loss but i think it also makes it easy to start letting co-pilots steer the ship too much and then you are losing that important knowledge and context of the system you're building until we get to the point where ai can do all of the coding for us completely we do still need knowledge in context of the code stored in human brains to get the job done properly until then ai assistance wielded with a good strategy can still be a powerful ally anyway i'd love to hear about how you approach integrating ai into your own workflow if at all and if you like this video please feel free to leave a like or subscribe before you go i like that that was a great video i'll give you a like and a subscribe that was a great video i so i do got something kind of unusual maybe to say about ai so i you know on this channel we've learned a lot of languages we've spent a lot of time learning things and one thing that i've taken from all of this is that learning a new language with co-pilot i have found that i am less confident using the language itself even though i can write it quickly if that makes any if that makes sense and what i mean by that is that when i have nothing that helps me learn other than my memory it's like it stores really fast and when i have something that kind of helps me more and more i learn less and less and i rely more and more and yeah like eventually it'll all catch on and i'll be able to do it but there's definitely something about it where if i'm the one purely driving it like even when if i like turn off the lsp i like really learn the language quick and if i you know take off one thing at a time i learn i you know it becomes better and better yes that was a windows alert sound shut up okay i still stream from windows okay shut up anyways windows mentioned let's go this was great there's definitely a lot of dangers i would definitely heavily consider by the way why i love neovim oh man wait why wait why neovim nerds are so obsessed with the terminal wa okay calm down like yes i do like the terminal okay bro slow down slow you're cooking here anyways i do absolutely i think there's a lot of dangers my honestly my biggest worry is not me getting kind of bamboozled by chat gpt or people in the professional world submitting not as good of code even though that is something you worry about you hope that code reviews and stuff like that catch it my big worry is that students can go through a 4-year program and come out knowing nothing honestly that's like that's more of what i'm worried about is that some of the most important times in my life were struggling through an avl right struggling through how to do recursion struggling through these things and so that's like that's honestly my my bigger worry is that you don't take the time to actually learn you don't take the time to actually struggle and just be okay with struggling be okay with struggling just be okay it's not a big deal it's not a big deal okay it was the case before chad gpt but it was rare because you had to get through all this and you had to get decently threw it a jen