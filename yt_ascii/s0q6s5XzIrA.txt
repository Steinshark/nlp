um so good morning my name is is diego i am one of the co-founders of konan pakas maner and today i wanted to do this talk because this is the current state by the iso c++ survey and in the the pains the survey is is asking about the pains for developers and the four top pains are managing libraries built times setting ci and managing cmake those are the four topmost pains in the survey and at the same at the same time how do you manage your libraries and then the answer is i just put the source code in inside my repo or i build manually following the ryth me from the from the github repo okay so there is like a something that is off there something that is really not not working so i wanted to to do this presentation today trying to understand why what the current state what was the situation in the past and how especially how we are looking forward for the for the future of this of this problem so let me start i'm going to start with the present today what is possible today and i'm going to start i always like to do demos so i'm going to do a live demo of what is possible today with dependency management and i'm going to build a small application here i have the source code this is an application that is using the tensor flow for artificial intelligence it's very trendy so i'm going to use it it's is super cool and i'm going to use open cp okay so i need these two dependencies in my application these two libraries and of course the transitive dependencies this is very important this is the cic list that i'm going to use to build my application okay can you see something there that is specific to conan or any other package manager there is nothing this is pure pure standard cake okay so whatever we are going to do now this cake list is completely unaware of the dependency management for it h and finally in some play we need to specify the dependences that we want in this case for this application i need tensor flow and i need open cv in this case i'm running i'm writing a cor file. py that contains these two dependencies with the versions that i want to use and then for a developer when a developer they get this they of course they have to have conan install in their machine but let's check that i don't have any con dependency install so far everything that a developer needs to do now is clone the repo then they will be doing cake preset default and then this will launch cake and then cake will start installing the dependencies we see that it's installing not only the two dependencies but all the transitive dependencies that open cv and tensor flow need it will install all of them it will install pre-compile binaries okay we can see that it wasing fmp and and others that are it took a little bit more to unip them and now i can just build my application i could open my id but i'm building from the common line i can just build my application and hopefully execute it and if there is is working this is a post detection animation i i can dance as you did yesterday night and it will be working so this is the current state okay i think it's good i think it's really good we achieve a fully transparent integration it was commanded by cake i didn't have to type any con commands at all and the cool thing is that it works exactly the same in all platforms windows linux mac cross building you can do it in every platform and note that we were not only installing open cv and tensor flow we were installing all of those dependencies okay because those are the transitive dependencies of those two libraries okay if you try to do this by hand in your this is a windows machine by the way in windows it can take days to set up something like this okay so i think the situation is how have we managed to get there first thanks to a great community so now in conan center we got the experience and we have more than 1,500 recipes for different packages that the community contributed and they form they create more than 500,000 binaries for different configurations and those recipes for those packages are downloaded more than 250,000 times per day nowadays these recipes they were contributed by our amazing community last year alone we got more than 5,000 po request okay for conan center for these for these recipes and also we got a ton of feedback from private users in this case k and c++ is very very enterprise so there are tons of enterprises using conan privately actually way more than people used in conan center and they are also driving a lot of feedback and asking hey how do they want us to evolve conan and cake integration together for their needs so let's see now let's go back to the past and let's see how we started we started with this this was 2015 and this is our first public release and this was our only integration with cake it was called the cake generator and the cake generator when you type the con and install command it was creating one single file that was called kinfo cake that file you had to include it explicitly in your cake list like this include something conan bino cake then you had to call a conan basic setup macro and finally you had to define a conan lips in your targeting libraries for your own applications okay explicitly con and li this is as is know that this was also back compatible with cake 2 28 okay we were talking about 20 2015 h internally the con basic set up was doing something like this it was a macro with two different parts the first part the conan global flags was intended to manage dependencies information and then it you had all the all the information from your dependencies like set le and other other dependencies they include paths library paths library names etc you have them in variables and then the macro con and global flags was defining globally globally with include directories and le directories it was defining those variables okay the other part of the conan basic setup was focus on the tool chain in this case on the compiler things like that in for example setting up the c++ standard for our for our application and again it was getting the information from from there and activating something like cc cxx standard this is a bit simplified because back in 2015 this was not a standard so you had to set the c c cxx flags manually for these things but more or less you you get the idea where the information from the con b gets from h from two different sources the first source was the is the profile the profile is a text file that defines our inputs in this case that we are using the gcc compiler this version this standard library this c++ standard and so on and this profile is maap to the conan belal cic variables that are later activ activated by the con basic setup macro the other part of the information comes from the packages from the recipes of the packages that we are using in our application this is more or less how a recipe of for the set leip library looks like it will contain different different methods like the build method the package method it describes how this package is built from source to create to create the binary but the most important thing that i wanted to to focus today is the package info method because this this method here is the one that contains the information for the consumers okay is the one defining a for this package the headers are in the includ folder library are in the le folder the library name itself h can change if you compile set li yourself you will realize that in windows is called set li or cdl or in linux is called just set so the the library name is is changing based on the on the system the recipe is the one responsible for defining that it's not the consumer that they need to figure okay i'm linking c set leip and then the name will be no no is the recipe itself of set leip defin for their consumers their information what is their the things that they they they contain and this information is what is mapped is translated to the g bild in for cake in the form of variables that then are laterally activated as include directories or or library directories and you might be asking a why are you using just global variables why are aren't you using the cic files first because we are talking about 2015 okay at the time many libraries they didn't have f moduls they didn't generate config files at all and some of them that they did they did them very poorly i'm talking especially about transitive dependencies you you could be for example using a a find model or something of a library and then it will be find in open ssl it will be finding open ssl in the system so if you have some package that depends on open open ssl it will not get openl from your package it will get the old version of open in the system for example and as you can imagine that that's that's very bad and also now we are a bit more used to modern cmake with targets and stuff the modern cmake was popularized we are talking on 2017 and 2018 okay and this first integration was in 2015 so it took a while for for the modern seakan targets to to be to be mainstream but there is one special reason that we really wanted to have the package in method in our recipes to work and the reason is interoperability there was one design criteria in conan from the very beginning and it's still today that a every package created with any build system should be usable by any other package in any other build system and i know that you are probably most into cmake and you don't care only about cmake but there are still many many critical packages out there with other build systems and there are also other bild systems like meson for example that they are pushing hard or xm whatever they are good competitors they are good build systems okay that they should be they should have a chance also to compete and space the only way that we can have like a fair game for for everyone is actually if we care about interoperability between build systems okay the way we achieve that with the con and file and package info is okay any package in in conan center any of the 1500 con packages can be used by any build system okay so those were our principles that was our stting and from there we started to evolve together with cake and then as as cake targets started to be more mainstream then our first natural step was okay let's do not use global variables since he make let's use targets and then our con basic setup and con build inf to make was generating targets we could op in hey we want the targets so we could pass the targets parameter there and then instead of getting global variables we would be creating targets like still we will be creating like our own artificial targets many of the libraries out there they didn't define their own targets names yet so we just invented some new new targets names and then we started to get the push from the community and we conan was getting traction and more and more traction and then we started to get the feedback a okay this is looking great but we would like to have our simic list as less modified as possible we don't want to introduce con specific things that's a totally legit claim okay and this was the the the reason that we created the first the first almost transparent integration that was called cake find package the the cake find package was creating still module files not config files module files because back then we are talking now in 2018 modu files were still like probably the the most common use and most projects were creating modules for thea dependencies so many project they were not creating the config files yet and then it was on the consumers to create the models to use their dependencies so we created s fine package that was created a module file for every dependency that you had in your dependency graph and then with this approach we could do the def find package and it will be find in the conan package library and still we have the two approaches we still allowed the global variables and as targets were already were already there we also enabled targets in the as a result of fine package and then we could start like linking something that it was closer to like the fully transparent thing which was set lip colum colum set lip so this started to look to look very nice then the next step of the feedback right yes this is almost what we wanted but it happens that the what we call the ab string like the official s setly project it creates targets or the official simic model in that is bundled with cake when you install cake is calling set lip not with lowercase it's call it's calling setly with uppercase so you are almost there but you are still creating for me targets and names and file names with sli lowercase and that means that i cannot have a fully transparent integration because my previous my previous c list i'm using setly with uppercase so then we what we did is okay it's no problem we have a method in recipes that is dedicated to define the information for the consumers we have the package info method and where we are defining everything the include directories the library names let's define here what is the name of the target that c should be creating or the name of the files and in this case we added a section there it's called the names and we could then define okay this is going to be uppercase note that not all package is not just lowercase and upper and uppercase there are some libraries and packages out there that their project is is called f and the target is called bar is calling something absolutely different okay so it's not just a buan for uppercase lowercase it's a full string you can put the name that you want there and with this change in in our package info method then we managed to get like an almost transpar creation again with the right casing with the right names and then the fight set li module was okay theine packet with set li in uppercase was find in the our module and the target was called set le colum colum set le in uppercase and this is what what the users wanted okay next iteration config files start to get more popular and and projects start to create their own config files and okay we and cake also said hey config files are much preferred they realized that modules didn't scale at all okay and the only way to have something that that that really scaled is having each project generate their own config files okay so then the trend start to move towards config files say okay let's have a generator that instead of creating model files see model files it will create cake config files and this was called the cake find package multigen instead of creating the model we were using the same rules we we already had the information about the uppercase name or whatever so we could reuse that and then we could create the the set li config config file instead of the model file the main the main thing the main new thing that the c package multigen brought was managing the multiconfiguration okay the previous one they were single configuration if i don't know if you use both windows and linux and cmake but the way they they manage the configuration is different if you are working with linux and you want to have a build a debug and a release bills those are basically different projects those are you have to do two h project generations to cake generate a step and then to cake build a steps into different folders if you don't want to have them overwrite each other and then for other other setups like visual studio and the visual studio generators in cake it is a multi-configuration it's a multiconfiguration generator it means that you only need to generate once you generate one project for visual studio and then you can build both in thebag and release from the same product if you go to the id there is a box there that you can select without having to generate a new c pro or whatever that means that h for single configurations we have to pass the minus d cake build type release or theb at generate time and in visual studio we don't have to to pass that ever we define it at build time so this was the contribution of cake find package multi the generator started to create both release and debug variants and you could use them from your id as we have seen in the in the previous in the previous slide you might be asking why you need two con installs again the only way that you can really scale is if you manage configuration one by one because release andb are not the only configurations you have the real with info you have you want there are many projects in the enterprise that they are called i get that you have them release d who has a release dl configuration somewhere yeah it's it's not that that unusual so there are custom configurations the only way to manage them you cannot just package all the different binaries in one package you need to have one package and then one con install per configuration and then you can aggregate them and with the c f package multi we manage to have a visual studio that you can switch in the id directly from the back and release and it would it would work still this had some some problem it was still too intrusive i simplify a little bit the slides because i when i was talking about c find package generators i have forgot i have dropped the tool chain part there is still a setup about the compiler compiler version and c++ standard that i've i've hidden here that part is still necessary that means that in the in the previous in the past you needed both generators you need the cake to define at least the tool chain part and then you could use any of the cake f package or cake f package multi to get the dependencies information but h honestly this was this was too messy users were confused they didn't know how to choose and the whole the whole approach was still a bit intrusive because you needed to at least include the con and b for he make for the for the bist and there was an extra problem here that is the model for dependencies in con one and with these legacy generators is was over linking they didn't have a model of the of the different of the different libraries that they were involved in the in the process that means that no matter when we have a dependency graph like this it didn't matter what were the what was the the type of the libraries if it was a c library or a static library in this case the application was always linking with both engine and math and that can generate over linking that can generate bled binaries j depending on the on the library types we will see it later in the solution you don't want that okay these generators they couldn't manage they couldn't manage this scenario they were always linking everything and that that was also a a problem at the same time we were we were getting the feedback hey we want more transparent integration we want to execute conan install and then our cmake should be pure should be absolutely agnostic about conan and at the same time there were a bunch of users that they especially enterprise users say oh okay now i need my developers to not change absolutely anything that means when they are typing cake to create their projects i want cake to call con and install to install the dependencies okay and this is what we call the cate conan integration is calling conan from the execution of cake so moving from the canonical let's say canonical flow that is call con install and then calling cake they want to have a single command that was cake and that should do everything internally so the approach to do this was something like that we had to do like a step back and the only the only way to achieve that i'm talking about back in in 2019 something like that was this is adding things to your cic list is the only way okay and what what were those things in your sim list you have to to handle you need to get the functionality to do this in this case you could for example download the the cony make file from from a place then you needed to include this file then we were using the functionality inside this file for example to create the con file.txt or con file. py on the fly based on something that is defined in the cic list then we would be the using the conan profile settings from the c configuration if the c compiler was this then we translated that from to a conan profile and finally we were calling con and install to st the dependes all of that and that's very simple if something changes something you would get your cic list growing and growing just to be able to call co and install from your c ex execution at the end of the day we manag it was possible with with that cake integration there were developers they could go cake and they would get their dependencies installed and this work problem of course is this was extremely extremely intrusive you have to have like a big chunk of your shim le polluted with conon things and that was less than ideal and besides that there were too much boiler plate consider that we have just there a macro we are calling a function just to generate a text file and for me this is absolutely overkill it's just another layer of of ind functionality to write a a text file for me this is this is really this is absolutely unnecessary furthermore if you put this in your simic list and then you create a package for this at some point you will be installing this package if you install this package and and build that package from source then you are calling conan to install that package that package will be calling cake to build itself and c cake could be calling g and install again recursively to the dependencies which is something that you don't want so you also needed to protect the cod so it didn't re reenter the the the functionality so this was of course less than than ideal then this is the present situation this is what i've been h showing in the demo before h we move those generators cake and c sign package and c package multi h two two clear generators which the responsibility very very very decal the c tool chain to generate a modern c tool chain with the definition of the compiler and our tool chain and the s deps that is creating the the the files necessary to find my dependencies and with with these two files we is the way that we achieve a fully transparent integration with with c without needing to modify any of our our c list at all let's have a quick look at at the at the c des generator it's looking something like this so of course it got both all the good things from the previous generators it it got them it is a multi-configuration generator so it will it will be installing release and thebag and real with the b info as many configuration that you have it can manage them in parallel it will be generating a bunch of files so things are kind of decap it's easy to to debug so it will be generating a file just with the data with the variables for your dependency so if something is wrong you can check that file and see if you got the the folders in the right place and if your packages are correctly defined is a way to to easily debug then it follows the typical config c config structure you know if you have created config files yourself or if you have used them you will see this config file the config version file and you will see also the targets which is where the actual targets are created so we are mimicking that and we are have a a set li targets that is the one creating the targets the in this the set lip set liip uppercase target will be created and then we will have one file per configuration and every one of these files would be the one adding the specific information from that configuration in this case the include directories for release will be added library directors for release with generator expressions they will be they will be added that way we generalize so we realize besides the information of the target names that we had in the past we realize that there is a bunch of information that we might need in the consumers for cake so basically there are packages changing the file name different to the target name so there are libraries out there that they have a the package name is one the file that generates is a file name is different and the target names are different there are packages there that they want to generate still they want to generate all legacy module files or they want to create alas so there are a bunch of configurations there that now are possible to define how do you want your consumers to customize the c file that are are generated and finally with these new generators and con to z we managed to solve the problem of over linking how how we did we manage it we introduced a thing that is called the the dependency or requirement traits the requirement traits is similar is an extension of the private and public linkage requirements in make okay it's basically the same concept but a bit a bit generalized in this case when we have an application linking a static library that is linking another static library we know that the application should be linking with both libraries okay so the trait the trade that says a you should be linking with the libraries is propagating down the graph till the app and by default and this is something that was very requested by the enterprise by default we should be hiding the headers so h engine is using the math library but we don't want the math headers to be visible to the application because if we make them visible that means that the game developers they will accidentally include the the math library then engine do that's a refactor remove the math library and then everything starts to to fail so if you have a transitive dependency by default by software engineer r it should be as hidden as possible of course unless engine public headers are including math headers but you have the full control so so the trad can define what gets propagated that the graph both for headers and libraries so then for for a static library the default is you need to propagate the libraries linkat requirements and by default you don't want to propagate the headers visibility so if you can hide them and math can be an implementation detail of engine you want to hide those header propagation and now this is this is successfully done and for other cases for for example with when when engine is a shed library and it is linking a static library it's linking math as a static library this is what happens actually in the binary for engine dll we have the math functions copied inside that means that when we are linking the application with the with the engine we really don't need to link with math because everything is an implementation detail of engine and this is what the trades manage in this case the game the game is linked with engine and the trade say hey no you don't need the heads of math because they were hidden and you also don't need to link with the with the math static library because it has already been embedded in the in the engine again very similar to the private and public concept of cake but generalize to any build system recall that the the cool thing is here is you can have a graph there and every different package can be built with different build systems so it's not that everything is cake and you can define private public make targets for everything so every different package out there can be a different build system okay that was the cic deps for managing the dependencies and now the cic toolchain the cic tool chain created also a tool chains in cake started also to get more traction start to be be more popularized and be recommended as a way to define your compiler settings so nowadays no one should be hard coding the c list something like the cbp std or the le cxx or anything anything related to a specific compiler version or a specific operating system things like that shouldn't be hardcoded anymore in c list they should be part of a c tool chain that you can pass in the command line and this is what we did we created we have we have the sim toolchain generator to create a con toolchain sim file that is looking something like this okay this is the file created by the generator first first very important we always allow users to do what they want so if a user they want to inject they want to define their own tool chain files they can do it and it will be included in the con and toolchain do make file so it will be adding their functionality then we will be defining things like platform and tool set we will defining the runtime c++ standard flags and also how to locate the other files that cc dep is generating for us why why the tool chain is so important because we have a dependency graph we when we are now working we shouldn't be thinking just about our application that we are building at this moment if we are building my application in this case and i want to create a package or i just want to build a binary i will be defining my configuration hey i'm using visual studio this version c++ 17 whatever okay say okay yeah i will generate a conan tool chain for my current application to build with these settings but we have to consider now that we have dependencies let's say let's say that this application depends on open cv okay and let's assume that open cv i don't have a pre-compile binary for my configuration so open cv needs to be built from source in this case how do i guarantee that the that the binary for open cv is binary compatible with my application it needs to be built with the same tool chain basically with the same compiler settings the same flags is the only way so when i'm building open cv i need to be able to pass to open cv hey you need to create yourself with this tool chain okay so now i hope that you start to say why why simic le why recipes and there is a very good talk about by r marcker about packaging things why simly shouldn't be hardcoding things like that the the configuration should be a parameter it should be a tool chain that can be passed to them so you can command a i want to create a binary for this configuration passing a tool chain or passing another different tool chain and you will you will build a different one recall again that this is not only cake okay we sometimes we need to build uh things in our dependency graph build with other build systems how do we achieve that okay every build system they have different mechanisms to inject the tool chain so if we are talking about open ssl for example that is buil with something kind of not really auto tools but close to auto tools and so it understand some auto tools so we can use the auto tools tool chain and we can define compiler flags that will set the architecture the the build type release optimizer flags c++ 17 we can define all of those things and that well c++ 17 for our open is irrelevant of course but it will it will guarantee that the openl binary that we create as a dependency is compatible with our with our current build again the one of the major contributions of the of the c toolchain for the mod c toolchain generator is that you can customize many many things if you need to inject anything like from the system name system version system processor for cross building you can you can inject your own tool chain you can override the full tool chain if you want you can inject a compiler flags at will so it has a a lot of configuration how how to use a tool chain if you haven't used a tool chain before a tool chain is just a common line argument for for cake so you call h in this case con install it will install the dependencies it will create the con toolchain do cake file and then you can pass to cake a cmake s find this file and if you are in a single configuration you will pass s build type if you are not in a single configuration you will not pass the c build type and then this will create your project and it will it will work okay still i need to type like a relatively long cmake command which is cake with the tool chain etc but the the great thing that cake cake 319 brought is the cake presets honestly i think that we need something like cake 324 to have presets that are are usable but this is a this is a great feature basically a cic preset files is a is a json file that goes in the root of our project it has to be collocated with with the root se list of our project it cannot be in a sub folder it has to be there okay it can be a s user present if you want to okay but basically it's a it's a json file that looks like that looks like all the possible all the possible command line arguments that you could be passing manually to cake they are contained there in the json file so instead of passing like a long a long command line to cmake you just pass one argument which is the preset file that you you want to apply and the other good thing about cimic presets is that it can contains many different configurations you can put the commands for debug commands for release and you can create your own c configuration which is basically sets of commandline arguments to cake and that's super super convenient so so what we did is okay we already have the c toolchain generator is creating the toolchain file already let's have the c toolchain generator also create a c user presets and a c presets file that was relatively straightforward we are already talking about conan one 47 and it was released like last year so this is pretty pretty modern so what we did is create a json file on the fly h the pres file this file contains here you can see it will inject the and tool chain automatically it will define the generators and that's that's basically it that's that's how it works so let's do also another quick demo so this is basically the same demo as before but without using the cake the cake conan integration that means that the first thing that i should be using is calling con install explicitly it will install my dependencies and one of the good things that we we see here when we are using conan is that it can fail fast for example in this case it's tell me a there is a dependency there tensor flow light for example that it really needs c++ 17 to work and i didn't i i use my default is c++ 14 and i when i typed con and install it was using my default which was c++ 14 so now okay it told me okay no problem i will use c++ 17 to build my application and then i did con install this generated for me a c user pret i didn't have the c user prets before okay the c tain integration generate for me the preset file and now i can use the preset file as i did before in this case it generates conan something default to differentiate from your own if you have your own presets so having the conant name there is to to to make evident that you are using a file a a target that is defined by by conan and then we can build it again conan release and if everything works i should be able to get the compile the same application as i did before oh yeah this will be working okay so this is much much better than we have in the past still there are some problems in those integrations that we are aware of these problems is cimic deps still generate some targets that are a bit artificial we generate too many interface interface targets that can be a bit a bit messy when you are using them there are some gaps especially for windows shared libraries h we might be missing in some cases the import location information in the target properties it's not evident to get that we have a a conan feature that is called deployers so if you want to copy all your dls for example from your dependencies is very simple you just use a conan deployer and it will copy all the dls to the place that you want but if you want to do it with cake you you might struggle a little bit and believe it or not but one of the issues that we have recently had is the push back from happy 2015 conan users and they were saying no no no no we we don't like the transparent integration we don't like the targets we don't like fine package the all the old cake integration was great we love that we could do the include goon b photos she make and we love the conan lips there because in that way we didn't have to touch cake at all we could just add a new dependency we added a new dependency in our conan file and then everything worked and our application started to link with a new library transparently with having having to touch a simic list at all so now i hope that you understand better sometimes the the tension that the open source maintainers we are we are because yeah we got like a a huge push to move to a transparent integration but now we have some users and those are typically big enterprise users that you want them happy that are pushing are pulling in the completely opposite direction completely opposite direction and i believe it's a very bad place to be to be there be kind with your open source maintainers please okay and finally something super exciting is the sem conan integration for conan to z because we this need was still there users there were still users that they wanted in conan 2 they wanted their developers to just be calling simic and not having to call conan install before good news cake 324 introduces dependency providers dependency providers is nothing but a way to define an interceptors for certain c calls in this case the most typical one is defined package so you can define something in your in a file in a c file that you can inject okay and you say hey whenever someone calls find package instead of call in the simic find package please call this other method here and i will manage to have the functionality there and then this file let's call it setup. c but it can be called any way you you you like this file can be defined again in the command line as cake project top level includes you can define this file and this file will automatically ally inject the interceptor for fine package that means that means that in this way is how we can achieve a fully transparent integration for for calling simc the first demo that i did today coling simc with a preset was doing exactly this it was using the conan provider to inject the interceptor and when it found the fine package it was calling conan install at that moment so a simplified implementation of the the simonan dependency provider is like this first we don't want be calling con and install for every fine package a typical project will contain multiple find package one per per dependency okay we don't want to call con and install for every one of them one con install is good enough to install all the dependencies so we have some variables there that basically protect and they will allow only con conan install once we check that conan is itself is installing the system otherwise the error for the developers is confusing so we'll be telling them hey you don't have conan in your system we still need to call conan install please install conan we will be mapping the c configuration to conan because we have learned that it's very important to be able to pass the the profile information the configuration information to dependencies that they might be in a different build system so in this case when we are calling cake the driver is not conan anymore the driver is cake and cake will have their own configuration so this this method here this conan profile detect default and detect host profiles they're basically getting all the information from cake and it's translating that information to a conan profile because that conan profile we can pass it to the dependencies and then we will guarantee that our dependencies binaries are matching our current simic bild but we are inverting the control when we call conon install the driver is conan and it will be defining their profiles when we are calling cake with this integration the driver is cake and we have to extract the information from cake and then convert that to a conan profile to be injected into the dependencies and finally we will be calling a conan install with those arguments and finally this is very important we have col con we have intercepted we have inhibited the the fine package call we have called con and install to install the dependencies but we still need to forward to the to the cmake find package so it works and it finds the package and it defines the targets and everything so this using the bypass provider argument to find package is the way that we can call defined package without entering infinitely recursively in our own in our own interceptor okay so i wanted to summarize here the two different flows first we have the flow that is defined is driven by conan is was in conan install first this would be very similar to h other languages you go i don't know to to javascript and then type in something like npm install to dependencies and then type in gulp or whatever to build the project is something that is typical this will be like the canonical proposed conan flow which is a you call conan install it will be installing things it will be generating files and then you can call cake and you can either pass a tool chain file if you want to or if you are using mod cake you can also define you can pass the preset the preset generated preset file that is also convenient and this is the other approach if we don't want our developers to touch or have to call con install manually we can invert the control and we can use the the cake conan integra integration with the dependency provider and again we can pass the provider as a command line argument like this or we can put that command into a cic preset and then we can just pass the preset to the to the cic command okay good so this was about the the present and as i've told you there are still some problems that we we need to figure out we want to improve both our s tool chain we want to add environment information to the sim chain something that today we are generating script files like bad files or cell files cell script files okay we want to be able cic toolchain to also generate environment information we want to improve c depths we want to refactor we want to simplify so there are still this is something that is is ongoing but today i wanted to talk about something more exciting is the common package specification okay this is something that we are actively working on and this is going was going to be the hopefully the future for dependency management in c++ so we are talking here a a cps file is basically a file that defines a package defin the content of a compil binary okay so it doesn't matter how this binary was created if a dependency manager brought it to your system you install it manually it was already in your system it doesn't matter it's a file that represents your compil binary and that can be used by any build system to use that package okay in theory in the simplest form that i'm proposing today i'm talking today that you really don't need the version you don't need the ai we are assuming that this binary is already binary compatible with your with your current build okay we are just focusing on how the information from the package needs to be passed to the bill system the consumer bill system so this package can be can be successfully used so i'm not the first one about talking about the the cps there has been a lot of previous work there but the good things is that things are starting to get traction now like now in the previous cpp con there were existing solutions for this problem previous attempts we have of course package config pc files there they have problems mainly that they are only defining variables like global global compile flags and this is a bad approach is difficult to manage we have c list we have the config c l is basically an attempt to solve this problem but the problem is that specific to cake it only works for cake and of course the the generated files they are not usable by other you cannot parse a c a c list or a config c file and understand what is there this is this is a definitely not not something that we want to do and of course the package in me of conan is another approach to to tackle this problem to have a a a common representation of a package so it can be used by any b system the goal of the cps is exactly this is we want every build system when they are building a something besides the artifacts besides the library they should be creating a cps file and then this cps file can be consumed by any other bill system this is the goal of the cps proposal this is to achieve the interoperability that conan has been proposing for for years this is what is happening with the with the cps proposal so what is the cps cps is something is as can be as simple as that is ajon representation in this case if we are talking about set li it would be something like this is a where are the headers where are the libraries and what's the library name that's basically all you need to know to successfully use your your setly package in your own application of course this is specific for this is specific for h for a specific so then we could be we could be discussing many details about this hey they include it seems very very simple right why is it a list why it is not by default we assume that is empty an empty means or or not defin it means that is include by default okay so there are tons of discussions there why are they relative relative pths they are relative because by default we want this we want be able to have a package and we want to be able to be to move that package to elsewhere and we should be able to use that package from the moved location without any issues should we force in the in the cps specification should we force that ps should be relative alwayss probably not because there are other packages that they might be installing the system in a in a path that is it cannot be made relative because they are installed in different places and typical example windows if you you put things in a different unit you cannot make a relative path between different units in windows that's a limitation so in some occasions you might need an absolute path there so these are the things that we are discussing in this in this cps proposal set le was simple op ssl open ssl actually contains two libraries what does open ssl when you're linking opell what does it means are you linking both of them are you linking only one what if you only want to link one of them but not the other how do you manage that we need a way to represent that problem in the cps and we call it components so a cps should also be able to model what is inside a package and a package is can be more than one library there is no way that we are splitting openl in one package per library liary op maintainers won't do this so we have to leave that one packet should be able to have more than one library at the same time and some users will want to link with both and some users will only want to link with one of them and there should be a way to represent that and there should be a way to represent the relationships between different components of the same package and also relationships between the the components of one package and components and libraries of other packages in this case op ssl the crypto component of opl depends on set li and this is something that we need also to represent in in this opel cps file other things that we are considering you this also works not only for your own when you have a package when you're also developing your project you can have a cps file that is pointing to something at developed time so you don't need to be repackaging all the time to be able to use a dependency and you can work simultaneously on several dependencies on your dependency graph and the cps file should be able to connect each other like kind of a meta project that is connecting several sub projects even if they are built with different build systems and the most exciting part of this and this is ongoing work this is get interaction this was one of the keynotes in cppcon was by cake and bloomberg and this load package function there is a prototype that they have okay so they have a prototype already that is calling load package and they can explicitly pass a cps file and instead of calling fine package they will be getting the information from a cps file okay we are also collaborating with them to towards another demo that the cps file are actually generated by conan so this is also thing in conan itself we already have all the information in our package info so for us the cps is basically dumping d d in one json file from the information that we have already there so we are very very close to have lots of information cps files for many different packages i also did a talk in in cpp con so it's not available yet online but if you are interested about i i recommend having a look when it's online and to finalize this would be the call this is actively happening today in the cppp lang slack there is an ecosystem ecosystem evolution i think slack channel that you can join okay and you will get there what is what is happening there is a repo there that we will be using as a main point of contact and discussions and issues for this proposal there is a mailing list h in the mailing list if you subscribe and everything you will get calls for monthly meetings we are doing monthly meetings via zoom and we are discussing things over over there okay so to finish my conclusions the c meanon integration is something that is life and evolving okay and always very important based on user feedback we cannot do anything without the users so it's very important cake an in 2023 can provide a fully transparent integration we have seen in the demo called just cake presets and you got your depenses install and it works in all build systems and operating systems using this is very important this is my my my key take using a package manager in 2023 is not not perfect i will not lie you if you use conan you will find you will find issues if you use other package manager you will find issues for sure it will not it will not be not perfect it will not adapt perfectly to your needs okay still is much better than not doing it okay and it's still the only way that we can all move forward together to something better inde dependency management is if you start dropping a i know i'm building libraries manually from source in my c directly and you start engage with any i don't care conan or other but engage any of them contribute back to them and and and move the ecosystem forward together and finally the future is looking even better i think with the cps proposal it will be a game changer and we our aim is to have much better dependency management for c++ in maybe in two years time or something like that and i think it will be possible so thank you very much and if you have any questions [music] [applause] any questions h maybe you you need to go to the microphone so everyone and also the recording h gets it hello oh hello so at the company i work for we're very interested in being able to reproduce or like rebuild all our programs in like 30 years in the future when i see like in the cmake uh lists text and like find package cib i get like very worried like oh this is going to be like the latest cib that we're downloading so i mean we are using artifactory because like a public repository would be very unreliable but still i would be very interested into knowing like how would i use conan or can i use use k to make sure that i can still remake rebuild the same programs in 30 years and have the exact same yes absolutely we we have a we have users especially there are some sectors like medical sector for example health sector that they are very concerned about this they have they they need to be able to reproduce exactly the same build with the same hardware in 20 years so they even keep physical machines and dvds and things like that in a storage so they can reproduce everything from hardware to the and the way to achieve this is okay you have to de couple things so because you have the cic list here and you have a fine package not even version information okay then this is where a dependency manager or or package manager enters when we define the conan file. py the first thing that we can put there is we can put a version number okay that version number guarantees that you are getting that version but even inside that version you can get what we call a revision a revision is something like that is a has is a has that is the has of the contents is equivalent to a g commit for for a dependency that it guarantees that you get exactly the same thing you get exactly the same dependency er now and 10 years from now the idea is that these two dependencies they have many transitive dependencies so you cannot put the the the exact revision the exact g there because you will need to put like a bunch of them and all of them so conan in this case it implements what we call it's a very common mechanism in other package manag it's called log files so when you do a conon install basically i can i think i can show you log file out let's see if it works and then let's see what i i'm put no sorry this is so i'm basically generating a log file that is like this it will contain in every dependency with its s revision okay so if i use this log file 10 years from now i will get exactly the same dependency graph that i' i've used today okay good thank you one more quick question why did you name it con that that's a that's a good question a very very old one so like eight years ago when we were looking for a name we were looking for something that was powerful something that started with c hopefully something that was not an existing command so if you try to use something like package or something like that in there will be a weird linux drro that is already using that that name or there will be another so then when we realized someone was joking i say hey what about con i say what are you crazy something like that and then we realized and the domain k. was available and finding a domain that was available back then was super difficult so when we say k. available okay this is a single let's go for it i don't care if the name is crazy let's go for it and then it cat up and we have the con and the fogan and all that stuff so it happen to be a good name thank you okay we have time for one question from the internet inside full talk diego do you recommend any conan best practices trainer facing some pain points at present at my work with conan and other def ecosystems cac clang tool tooling etc for various use cases we use conan 1.59 and cac 3. 24 i see training in jrog are marked as deprecated now so good practices about conan and learning conan is to true that right now we have we are in the transition from conan 1 to conan 2 conan 2 was released in february okay but conan is is very popular in the enterprise and migrating from one major version to another major version can take years okay h it's true that we have replicated the trainings in the jr academy because they were teaching the very legacy generators like seake and this is considered nowadays they are considered bad practices they are not even following seake by best practices so even if you need to attach to conan one the best practices would be you use only the modern generators use only c deps and c tool chain of course try to use presets if possible that's very that's very convenient h and besides that is one of the things this is a very common question is good practices the users want silver pallets there is no such in c++ we have something that we have learned is that every company they have different needs the projects are widely different the different constraints different requirements different policies whatever so it's very very challenging to recommend something there will be companies that requires strict log files for from 10 10 years from now there are companies that they don't care they prefer to be as quickly as they don't care if their bills break and they will be just fixing things and and move forward so there are not like general good practices i would say best practice is reach out go to our github repo file a ticket ask questions we will be there to help even if you if you need some help we can do zoom calls or whatever to to talk to you and then for every specific use case we will try to say hey maybe you want to use a loog file or maybe you don't need it maybe you you can just pin your versions in your in your or if you want to go fast then you can maybe the recommended practice will be using a maybe you want to use something like a version range something like this because this way whenever a tensorflow light version comes up you don't need to modify your conan file anymore that you you get a new release and then you this this will be automatically picking the picking the the last version so depending on on what is the problem that you are trying to solve with a dependency and package manager the solutions might be different so my best practic recommendation is read the docs and reach out to us and we would love to to help you okay thank you very much oh