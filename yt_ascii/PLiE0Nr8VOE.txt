up until now... an awful lot of information security  mechanisms and the policy debate has been about the use of security to protect the privacy of personal data and the confidentiality of business data but in the future once we get software and communications in everything, it's going to be much more about safety and this is going to change the policy debate as well because at present many people might not object too much to the idea that the fbi has a golden master key that that lets them break into your iphone and read all your embarrassing private chat messages but i think people will be very much more nervous about the idea that the fbi will have a golden master key that will enable them to break into your car remotely and turn it into a weapon that could kill you and if this golden master key is available also to other intelligence and police agencies around the world then perhaps that begins to become a real problem, and we have to revisit the whole question of government special access to cryptographic keys and the systems in general so far, people have talked about the possible privacy risks of the internet of things and we saw the cayla doll being banned in germany because it's basically a remotely commandable room bug and we also saw the mirai botnet last year where some bad person recruited a couple of hundred thousand tv cameras to ddos a dns service which took twitter offline for a few hours in the us eastern seaboard but i think that the big problem with the internet of things isn't going to be privacy or availability, it's going to be safety what we are now doing is putting online an awful lot of devices on which people depend for their lives, and which can kill people if they go wrong the obvious cases are cars and medical devices, but there are many more and the other thing that's going to make this complex and difficult is the fact that up until now we've known how to make two kinds of dependable system the first is a system like a mobile phone, where are you upgrade it every month to make sure that all the security flaws are patched but where you're expected to throw it away after two or three years and nobody bothers to patch really old versions of your phone software or your laptop software and the other type of thing that we build is stuff like cars and medical devices and electricity substations and other durable things that we expect to last for 30 or 40 years. now, in the case of cars, what we do is we test the software to death before the thing goes on sale, and we hope that's going to be good enough and we never upgrade it afterwards unless there's some real panic. now this is going to change because tesla is already shipping monthly software upgrades for their cars ford and bmw have already shipped some upgrades and everybody will be doing this within three or four years. all of a sudden your car becomes something like your phone or your laptop which gets a monthly software upgrade. and this is great for some purposes and terrible for other purposes. it's great because it means that if there's some safety vulnerability like for example when a tesla driver was killed when his car went into the back of a truck which was painted white because the sky was was gray and it wasn't visible enough something like that you can fix by shipping a software upgrade and it will be very very much cheaper than having to recall millions of cars and reflashing all the firmware at a cost of billions and billions and billions but although it brings us the possibility of steady growth in vehicle safety it brings a terrible cost with it which is that we've got to maintain the capability to patch that software not just for years but for decades and we don't know how to do that either in organizational terms or in technical terms so let me state the problem suppose you're working in cambridge, england or in cambridge, massachusetts on some software that will, say, help do navigation in a land rover, or a jeep, or a phone or whatever that you expect to go on sale in 2020 how are you going to be able to patch that software in 2030? in 2040? there are small numbers of systems that have been maintained for a long time for example deep-space probes another example is avionics software where, basically, stuff may be replaced or may get a midlife upgrade but where regular updates aren't expected because the kind of devices that you have in an airport, in an airport's air traffic control system, or in an aircraft cockpit tend not to be connected directly to the internet and so you don't have the same attack surface you don't suddenly have the need to patch stuff because of shell shock or something like that which could actually render it open to attack, but in the future we're looking at a world in which all our cars are online all the time right? because the car will be autonomous or at least partly autonomous. it will be communicating over the network; it will be downloading maps, it'll be downloading traffic information it will be contributing to traffic information. it will be getting updates of all sorts of kinds of kinds of code and data it will be a very very complex beast, and how we manage that is going to be a big problem. now, at present we have serious problems in getting oems to patch systems like android and so most of the android phones in the world are insecure simply because their vendors can't get it together, or don't have the incentives to patch them now this is going to become considerably worse from once we start talking about cars because the car is not just a simple system that's made by one vendor anymore. the brands that you buy, be it volkswagen or mercedes or peugeot or general motors or whatever are basically integrators who buy in components from lots and lots of people who sell the parts, who sell the the abs, who sell the automatic emergency braking, who sell in future the robo chauffeur which will actually drive you to work while you're sitting there hacking some code, and so you then got the technical problems and the business problems of how do you produce software upgrades which marry together code written by potentially dozens of different firms? then there's a question of who's going to be liable for it all when things go wrong and then there's going to be the question of who pays for it all. now, at present software firms try and get rid of the liability for software going wrong and that's not going to be possible when software is in devices that can kill people. legislators simply won't allow it. laws in both america and europe see to it that if you sell a device that kills people, then you're liable and it doesn't matter how often you get your users to click on the "don't sue me" button. that basically doesn't work. for now. we won't talk about exactly what's going to see understand, but the idle hold that [observations] of [a] bottom pp it's been very difficult yet out all the shuttle enter, but then we fight around making difficulties all these done them to see minute [very] [tiny] bringing in [duplication]. that's already having