when zig outshines rust memory efficient enum rays okay okay okay enums are tagged unions whose variance vary in size are prone to significant memory fragmentation in rust okay type one in the chat by the way who knows what a an enum tagged union is okay these are not typescript enums okay so if you if you know what a typescript enum is don't don't think they're the same all right sorry i asked this question incorrectly 69 in the chat if you have just absolutely no idea what they are okay there's a lot of people so let's hear i'll give you a quickie can i give you guys a quickie so that way we make sure everybody's on the same page it's pretty straightforward okay so here do i i don't think i have a car here i'll just cargo knit a new project in here whatever that's fine we'll go to main all right so in enum here we can go like this enum foo right so i've created an enum in rust and now i can say some different types right i can have a bar which let's just say it has a subtype string i can have a baz here struct other right and let's just say that it has a which is an i32 and a b right i can have a bass that contains an other i can also have a nothing element right and i can put that at the tippity top little optimization whatever not a big deal but this is an enum what it does is it actually shows it's a way to tag different types right so what happens underneath the hood is that it has i think i think it's just your system word size of what type it is and then the rest of the memory is devoted to the type underneath the hood so that way so like the equivalent of this in in in typescript would be something like this right type foo equals undefined or string or other right like i think that would be the equivalent but they're not quite the equivalent right they're not quite the equivalent because when i want to go like this foo equals foo bar hello into there we go i've just created a bar right but it's just a foo size right so it's just type foo i can pass this food to any function and it's just a food it takes in function food it takes in that type food to be able to do something here with foo i have to lift it right and so i have to lift the actual inner value out of it this one would be if it's a type bar if it's a foo bar then we get the string out if it's a foo baz we get the other object out so it's a little different than typescript because typescript what you do with typescript is that you'd go if undefined handle the undefined case if a is in the thing if type of is string do the thing else it's the other one right so it's kind of like you have to do a bunch of if else's as opposed to a pattern match on top of it plus it's efficiently stored its type is stored as part of the information so this pattern match is effectively the same thing like comparing a integer right so it's very fast it's just a it's just a it's it's just a comparison of an incher whereas a switch is not a comparison of an integer let's see you can serialize a tagged union with typescript you cannot without keeping the type exactly so this is another cool part about a tagged union you can serialize them like integers on and then deserialize them back into that tagged union structure it's pretty cool what did i use into okay well this is just a rust question now this right here is a stir why is it a stir when you compile a program and you just raw dog a string right into a program this is actually the type the underlying type is a static oh i don't know how i got that little t in there is a static stir because it's in memory somewhere right that string is like actually in the memory of the program if you looked at the binary there would just be a hello somewhere within there and so it's just a reference to that point so to create it into a capital s string which is like an object right which is its own object with its own underlying copy of memory which that memory hello is located somewhere on somewhere on the heap that's what i just did but mr hdmx made an improved morph dom oh cool that's something i would want to look at okay anyways so now that everyone knows what a tagged union is and kind of how to use it and what was going on there let's go back into the article so consider this one foo there you go so here again here's the tagged union with its different types a is a u8 b would be a type u16 32 so here you go because of the space needed for tagging and alignment this type is 16 bytes long this makes sense because remember so one thing i forgot to say is any tagged union contains the size of a tagged unit contains the the tag plus it contains the largest submember so the this members one byte this is two bytes this is four bytes this is eight bytes so one tag which is usually system width so that would be you know a u64 effectively then another one of these so that'd be 16 bytes which they say right here right you can see that right here it contains each one of the the units and that's just how a union works in c it's how it works at any language and you can't complain about in typescript because well if you're using javascript which everything is like a minimum of 16 bytes it's just gigantic this presents real pain when collecting a large number of them into a vector hash map okay this makes sense this actually makes sense so this tag and padding thing is kind of interesting you can have a lot of them obviously the reason why they choose this i believe is reading speed right it's it's just more efficient to read out an entire word than it is to read out some u8 and so just a thing to think about you can handle specialized data structures for particular for particular enums that reduce fragmentation to a minimum but doing this generically or generically for an arbitrary enum with maximum memory efficiency is close to impossible in rust the only option we have are proc macros which compose poorly no derive on third-party code or type aliases and are not type aware unless using workarounds based on generic const expressions which infect the call graph with the verbose trait bounds and don't work with generic type parameters so all this to say i have no idea what he's talking about but that sounds that sounds terrible or congratulations i'm sorry a zig on the other hand lets us perform the wildest data structure transformations in a generic concise way well that's exciting i like that i like the sounds of that because i understand the problem right so just for everyone to understand the problem let's say you had a million a million foods right and almost every single foo is an a and you have very few of these other ones right like let's just say foo represents a utf-8 encoding and it's it's an english paper most of them are going to be this maybe there's some sort of weirdness that actually causes some other large character right i get i know u64 is not utf-8 encoding i get what you're saying and so what's going to be is you're going to have like all this unused space in every single spot right you're only using two bytes out of 16 one out of eight so you're only using like 12 and a half percent of your memory at any one time almost throughout the entire array which ends up being 16 megabytes which is a lot of memory so i i get i get the argument the argument sucks you want a tight structure you want yeah you want you want to pack it you want to pack a tat but that's the problem about unions they need the space they have to have the space because you have to be able to lay out memory in a certain way let's see before i go to the implementation details i'd like to explain why reducing the aforementioned memory fragmentation is a useful in practice okay background to me one of the biggest motivators for efficient enum arrays have been compilers one problem that keeps coming up when designing an ast is figuring out how to reduce its memory footprint big asds you know girl you know i like big asts can incur a hefty performance penalty during compilation because memory bandwidth and latency are frequently bottleneck in a computer front end chandler kurt's video on carbon compiler has been making the rounds on language forums in it he describes how he parsed clang ast regularly consumes 50x more memory than the original source code dang dang that's a lot of i mean think about it source code is largely like white space too there's so much white space in code and you're telling me that it's like 50x more memory that's crazy all right so what does this have to do with enums well the most common way of representing a syntax tree nodes is by is via some kind of recursion or recursion like data structure let's define a node for expressions in rust using our new type indices for indirection expression unit number binary so there you go so like this looks just like this if you've done anything with like the thorsten ball book building an interpreter this looks like you you immediately recognize this right we can write an ast node in o camel let's go let's go oh camel let's go oh campbell there you go you got the exact same thing this all looks good a big difference compared to rust is that we can express truly recursive data types without any form of explicit indirection that's because the runtime system and garbage a garbage collector take care of memory bookkeeping for us yes this is true it just makes everything an o camel is just slightly easier you just have to learn a new syntax which is emotional which is what i want to do but i just haven't done it yet the problem we have now is that we want to improve packing efficiency of those enums a simple vec expression will consume size of enum this is actually a really great article i love where this is going this is fantastic amount of memory for every element which corresponds to the size of the largest variant plus tag plus padding luckily there are some ways of dealing with this reducing fragmentation let's take a simple example of a three variant enum with a member sizes 8 16 and 32 bytes storing those in a regular vec would look something like this this makes perfect sense right every is everybody on board with this by the way this guy is using excalibur can we all take a second and appreciate a little bit of excalator right this is some good excalibur skills right here i think he's using excalibur dude o camel is rising oh camel is a big w i'm getting excited about it the most common way to improve packing efficiency is by keeping the enum variants as small as possible using tagged indices for example in rust take a look at the tagged index crate used by the compiler or check out the recent blog post on small string optimizations you'll find these optimizations all the time in high performance code like a language runtimes garbage collectors compilers game engines and os kernels okay very cool we won't look at those but exciting unfortunately that doesn't completely solve the fragmentation issue the other way to tackle the container let's see the other way to tackle the container type directly oh whoopsies the other way is to tackle the container type directly we could use a struct of arrays approach to store the discriminants and values in two separate allocations in fact that's what the self-hosted zig compiler actually does okay okay this makes sense an array of structs approach was practically ecs at this point the tag and union are stored in two separate allocations so we're not paying for padding anymore however the union collection still has the variant fragmentation yes this makes sense because you have to store does this make sense is everyone understanding this like if you still have an array of 8 16s and 32s that still means you have to have an array of only 32s and all these eights and 16s just fit in the 32s right that makes sense because of zig's stage compilation we have a container types that perform this soa struct of arrays transformation generically for any type in rust we're constrained to proc macros like structs of arrays derived which has several downsides we can't place derive on third party yep we've already talked about that reducing variant fragmentation this structure of array a transformation reduces a loss of way a lot of wasted padding introduced by the enum tag but still isn't optimal to really get rid of fragmentation of the values we can create a create one vector per variant okay this would be hard because now you have to use because one thing they're missing in here is that you'd have to have some level of bookkeeping right you'd have to have something that tells something else where to look for this information right it's you can't just do three separate arrays for freezing size equivalent classes we could stop here but let's consider items that have lots of variants that can be grouped into small number of clusters with the same type size okay a b and c and d these are all the same thing okay nice yep e f yeah yeah yeah yeah yeah yeah and then i four four okay beautiful beautiful look at that a u32 and a u32 wait hold on wait these aren't the same i should i looks larger oh i is supposed to be thinner i it's hard for me to read what i supposed to mean anyways okay as you can see the once per a variant approach would add 15 vectors it's like the number of reallocations in the system's call would increase substantially and that requires a lot of memory to amortize compared to the native effect yep or the naive fact the vector it's also just super hard like this would be such a hard thing to program can we all agree that this is like virtually the impossible this solution feels impossible to program the vectors may also be arbitrary spread in memory leading to a higher chance of cash conflicts the aova collection i don't i actually don't know what that is collection itself also consumes a lot of memory bloating any struct it's embedded in now if we group every variant by size we get three clusters two four and eight bytes such clusters can be allocated together into the same vector therefore reducing the number of total vectors okay so we have a bunch of different kind of vex right this makes sense you collapse them all based on their size you could say this dense version of of our aova pattern however once we co-locate different variants of the same allocation we lose the ability to iterate through the vector in a type-safe way exactly so what he means by that is you can't like you literally just can't match the type you can't just four match four match four match you have to i mean i'm not even sure how you'd walk through this in order to begin with how do you know what order is what order and when it comes to an ast ordering is it's pretty important so i don't quite see how we do something with this yet if you lose access if you if your access password pattern does not require blind iteration which can be the case for flattened index-based tree structures absolutely this this might be a worthwhile trade-off okay i've implemented a prototype of this data structure in zig the most important pieces are the compiler built-ins that allow reflection of field types by byte and bit sizes as well as inspecting discriminant okay so at its core this performs a straightforward compile time reflection to compute the clusters and field two cluster mappings we do a pseudo dynamic allocation using a stack allocated vector this cluster information is used to construct the aova data structure okay very cool you gotta oh this is kind of wild i this would take a while to digest so we're just gonna have to jump forward if you want to do typesafe iteration you could pay the cost of padding and add the tag back in okay okay very cool i don't understand why the tag is matching these sizes right that i don't quite get why the tags are matching sizes if padding is too much you can do a structure transfer obstructive arrays transformation on each array variants yep you can do that that's cool that's cool as you can see there's quite a few trade-offs you can make in this space and they've all depend on the concrete memory layout of our enum wow this is super complicated programming this correctly would it feels like an index nightmare it feels like a genuine index nightmare to save all this because there has to be there there has to be one more missing array somewhere that is like this information of which one to access in what order i feel like there's a missing there's one missing piece in here that we're not seeing and that's what i'm worried about which is i i feel like i'm kind of missing this let's see watching you i get imposterism don't worry about that maintain the same memory boundary maybe so they can be stored inside of beck as well maybe an array of pointers that are you can't have you can't do that in rust or it's very hard to do what you're saying in rust you know what i mean get work treat i i there's just nothing that needs to be changed i don't think anyways let's keep on going all right so as you can see there's quite a few trade-offs that we can make in the space and they all depend on concrete memory layout for the cinema while creating such a data structure is pretty straightforward and zig creating any of these examples in rust using proc macros is basically impossible completely agreed the the moment you enter into proc macro land you've pretty much entered into the impossible land so i'm trying to move something below i think i just bonked my camera my bad the reasons being that proc macros don't have access to type information like size or alignment which could have let's see while you could have a proc macro generate a const function that computes the clusters for particular items this function cannot be used to specify the length of an array for a generic type another limit to rust generics is that the implementation of generic containers cannot be conditioned or whether the type the given type is an enum or a struct in zig we can effectively do something like this that's pretty cool that's pretty cool again i think zig has a bright future i think zig really does have a bright future it has and the thing is it also it prevents you it has no pointer safety which i think is like 80 percent of all the issues is no pointer safety and so you have nil pointer safety and then it has a bunch of other safety it has tagged unions it has errors at values it has syntax to handle errors so you don't get the if error equals nil go problem it's nice it's like it's a very nice language i do want to take see the problem is i'm stuck between what's my next big language learn because i finished my you know i'm in my i'm done with the rust learning i don't really necessarily need need more rust learning i'm not going to benefit a ton by learning the deeper parts of rust and so my next one is either zig or o camel and i just don't know which one to do i know people love elixir they always want me to learn elixir i just am not sure about it i've only dabbled in zig i've dabbled in zig and just kind of checked it out it has null pointer safety but you can still leak and use after free etc sure pete's c though yeah it sure does beat c it sure does why not both because it it's time consuming it it takes all it's a it takes a lot of time to learn a new language and so i don't want to learn something i want to really get it oh they're done well vs chode sorry vs chode avs chode thank you for the fifty dollars you're in a youtube video now thank you thank you for that thank you for that all right let me finish this bonus determining index bit width at compile time while implementing my prototype i notice other ways of saving memory for instance if you know the maximum capacity of your data structure at compile time you can pass that information to the type constructing function and let it determine the bit width of the returned tag index with this tagged index isn't let's see when this tag index is included in the subsequent data structures let's say another enum this information carries over naturally and the bits that we didn't need can be used for the discriminant so zig gives you the composable memory efficiency oh that's pretty cool i don't quite understand what this means but i like the ending which is that as you specify things downwards everything kind of compile to it and it just makes sense in zig and that's pretty cool to have composable memory efficiency by being specific about the number of bits you need different parts of the code can take advantage of that and with implicit widening integer coerced and dealing with apis of different bit with stay ergonomic yes dude that's one thing rust i i personally don't like this i don't like that you constantly have to specify upward maybe there's some safety reason that i'm missing in rust but i don't like that a u32 can't be instantaneously promoted to a u64. like to me that just feels natural and it just it does make me a little bit wonky and using like eye size versus you size it feels emotionally painful yeah but i don't want to have to specify this right i don't want to have to think about this whole thing right like i get that you should never downcast no no again you're still making me think about it why not use u size then well use size doesn't always work like a time api time apis either use u64 or they use u128 right like if you call as milliseconds you get a 128 back so then you got this whole you got this whole thing that goes on of course but rust already does a bunch of implicit stuff as it is yeah you know what i mean so it's not straightforward in a way this reminds me a lot of refinement typing and ranged integers so this ties a lot with my post on custom integer bit on custom bit with integers by the way zig allows you to do custom bit with integers which is crazy you can do like a i-18 i don't even know what to do with that writing extremely efficient generic data structures in rust is not always easy in some cases they incur lots of accidental complexity and in some others they're essentially impossible to implement i think one of the biggest takeaways for me with regards to stage compilation was the ability to be composable on memory layout level yeah or to be composable on a memory layout level if you're developing a system programming language that embraces a braces efficiency and zero cost abstraction you should absolutely take another look at staged programming and in particular ziggs comp time this is awesome this is a great this is just great absolutely love that comp time is just the greatest i think comp time is one of the greatest features of zig in fact i i'd argue that comp time is one of the coolest features of any programming language i agree with that as well and so that's the one thing i just love comp time comp time and zig effectively allows you to you build these types it's kind of like generics you can kind of think of it like generics except that you're writing code that executes at compile time so you write zig that creates zig but it doesn't feel like a proc macro or something that's really hard to do right it's not like rust's proc macros virtually impossible proc macros there's like seven people in the world that can write proc macros the rest of us are just too stupid slash don't have two months of peer study on proc macros to write them good i'm glad that this is your first comment orsgoth i just want you to know you've made it into a youtube video and that you my friends very first comment is this okay just want you to know that right now like and subscribe like and subscribe like like and subscribe