so hello everybody i would like to introduce you to dr paula boddington dr boddington is a moral philosopher she teaches at several schools and she's also a published author on questions of morality and several issues as well she she's kind of dabbles in all kinds of subjects you know i've seen her on television in the uk she discusses the problems of ai which is why i have her on our show today to talk about the narratives around ai the ethics of ai because i know it's something that interests you the people that watches this channel quite a bit this is jonathan pedro welcome to the symbolic world so dr paula maybe you can start by introducing yourself because i do what i can to introduce yourself and tell us a little bit how you got interested in how you you moved into the field of ai and morality okay hi thanks very much so well i started working on issues about ai and ethics about five or six years ago just by one of those chances because i was working with some i was working at one of the colleges in oxford and there were a couple of people people there who were really interested in this so we applied and around about the time what was happening was it was around about 2014 2015 there was a lot of attention to the problems of there might be forthcoming disasters in relation to ai so people like stephen hawking and elon musk were speaking out claiming that they're well really worried about concerns about what might happen when we develop ai in the future and then what happened was that there's an organization called the future of life institute which is based in boston and elon musk donated a whole lot of money for research projects looking at beneficial ai so three of us we put in a proposal and we're lucky enough to get we got got one of our grants so i was working on that for a couple of years but the topic we were looking at was developing developing codes of ethics for ai so i worked on that which is it kind of it's really interesting there's now there are there are so many codes of different codes of ethics for ai all over the world there's actually a website that collates and tracks them all but but what i was really interested in was not so much developing a code of ethics because well what i'm really interested in is looking at the issues behind that looking at how you might even start to think about what the ethical issues are and then talking about codes of ethics there's two layers to it because you don't have just to think about what the ethical issues are you have to think about how you're actually going to bring this about in practice how you're actually going to bring about good practice because there are so many examples of organizations that have got fantastic codes of ethics and it makes no difference whatsoever one of my favorite examples is enron who everyone that you know younger people might not remember collapsed disastrously taking the livelihoods of hundreds of thousands of people had a fantastic code of ethics there's also a really fantastic code of medical ethics but giving dignity to the patient and informed consent that was around in germany before the second world war so that was before the nazis so that's always really really really important to remember that kind of thing so so that's how i got to work into in the ethics of ai but prior to that i'd done quite a lot of other work in philosophy in relation with i've previously looked looked at work with teams of genomic scientists looking at ethical issues and genomics research and performative clinical genetics and before that i've done a lot of work in relation to how we think about what a person is so i've done some work in relation to with a psychologist in relation to how people with learning disabilities are are regarded and i also do so what i've also been doing because i've done lots of different bits of work so this is a really long introduction so one of the things i've been doing as well for the last few years at the same time as doing work in relation to the ethics of ai it's i've been working with the team of sociologists who do ethnographic work looking at the care of people with dementia in hospital boards which is like it's really it's such good luck to be looking doing working those two different things at the same time because they seem like they're worlds apart but it's really really valuable because because of it because of a contrast because of how people with people with dementia are so marginalized and and also it's related of course to two ideas of a loss of cognitive capacity or on the other hand you've got people working in ai who feel that intelligence and cognitive capacity is is the you know the pinnacle of human endeavor but we should try to surpass so sorry it's a really really long introduction but no but i think that it's very i think that you really right away in your introduction i kind of see the the issue or the question because one of the the problems that or not of the problem one of the realities of ai is that there's a personification of ai it just happens naturally you know in terms of how we how we treat it how we approach it you know and it's a long story with robots and isaac asimov and you know it's a very old story it's not something that just right away happens but we have this tendency to personify ai and like you said there is a tendency to de-personify people who have cognitive breakdown because we have associated personhood with with cognitive ability or with with mental ability yeah yeah precisely so but yeah those are the issues i'm really really interested in and and when we think about ai there are different kind of narratives that we that are told not always consistent with each other but different narratives in different areas of ai about ai but they always go along with an assumed or explicit or often implicit narrative about humans because humans and ai are seen in in relation to each other so that so but we use ai or the ai is being developed in order to sometimes replace humans so when you'd have to ask the question of why would you want to replace a human sometimes for good reasons actually so so for example i mean one really good reason would be if you wanted to clear a landmark field of landmines so much better to use a robot but so some of it some of it is some of it's good but so you either want to replace humans or you want to try to enhance humans but if you want to enhance humans if you want to enhance something you have to have an idea about what would make it better so so you have to have a night because not all you know not all changes are enhancements are they so you have to have some idea about what it is that humans are lacking so it always goes along with some idea about how humans stand in relation to the rest of the world and some idea about what faults humans might have or what imperfections they might have that we can surpass and but it does it does really really tend to to reinforce there's been work in moral philosophy for quite a long time about notions of personhood which i think are my personal views they are too biased towards the cognitive but the work in ai only just reinforces that well there's something there's something about what you're saying in the idea of this image of the golem or right this image of the artificial being that we saw you know kind of popped up very strongly in the time of the the romantics and you know frankenstein and all of this kind of narrative is very important to understand this mirror it really does end up acting like a mirror yeah and so we end up projecting our politics our morality and like you said the the most dangerous part of it is that it's often implicit we don't actually know so like you said like when when elon musk says he wants to make human beings better by implanting a chip in their brain no one ever asks what you're talking about like what is this better and it usually just means more powerful in terms of like adding capacity like it seems that seems to be the the the what we're talking about but adding capacity you know what is it the spider-man famous spider-man quote right with great power and so adding capacity is not always something you want to do yes yes yeah yes it's it's interesting so one of the things that one of the things i was just looking up this week thinking about talking to you is that very often you talk about a if you google it you'll find lots of people talking about ai defroning humans but it's really really quite interesting as to the context in which that's used the idea that we've been knocked off our throne and actually it's also really interesting because a lot of people are kind of like welcoming that because a lot of people are really against so a lot of people say for example have a really simplistic notion of a religious view of humanity but where the crown of creation and and but no darwin has come along and not just about petals and that's a really good thing because we shouldn't lord it over the rest of verifiable but if you look at the context in which they talk about dethroning ai is defroning humans it it seems a lot it's often in context of something like when alphago beat lee zidol the world go champion or at something like chess or something where there's some where there's some beating the humans at some intellectual task or often where it's really really easy to work out it's it's if it's really easy to work out whether somebody's better at go because they're a criteria for whether you've won or not completely certain but but also it's made me think about the sorts of things that we're worried about being dethroned because as far as i know arnold schwarzenegger is not crying his eyes out because a forklift truck can lift heavier things than he can and and you know usain bolt isn't worried that cheetahs can run faster than him so it's it's something it's really is something about it really does tell a lot about why we think that like being clever at certain things are kind of defroning us we're not not at all worried that chimpanzees could a chimpanzee could rip you from limb to limb because they're so much stronger than us we don't care it's but we don't some people seem to care about that joe rogan seems to care about that a lot he talks about all the time all right but yeah but yeah yeah the idea i think that the idea that you're talking about is is because we the west has really taken up the underdog story as being the story right we've taken up the revolutionary story as being the the story itself and so all our movies all our stories you know since the enlightenment have been revolutionary yes and so because of that then there's this surprising thing like you said which appears in stories which appears in something like the desire to have ai dethroned us or the desire for extraterrestrials to come and show us up or or just even the cuckolding narrative which has become strangely popular all of this is this strange manifestation of this revolutionary tendency which turns against you it's almost like it's like you're revolutionary but then you you expect almost almost like implicitly that something from underneath is going to come and and take your place you know and you see that in it's it's an old story it's the story of the greek gods how they castrated their father and then you know that's what it is it's a it's a so one of the things that i've been that i've been saying on my channel and i've said it kind of here and there but i want to say clearly here i guess because i have some friends that are in computer science and very smart people you know who i'm talking about here the people who are watching this and they tell me that it's technically impossible right general intelligence in computers is technically impossible and and it's funny because i don't have no way of knowing that because i'm not a computer scientist what i do know is that it doesn't matter it doesn't matter whether it's technically possible or not it what truly matters mostly matters is what story we tell if everybody believes that this is happening then that will have way more an effect way more of an effect than if it actually happens and you can't know something's conscious anyways how can you know that like i can't know that of you i can't know that of completely no like i can't know it internally the way i know my own consciousness yeah i don't know how you would even evaluate that no i always wondered that about about people talking about ai becoming conscious because you you know you don't know if another person is conscious i remember when i was a philosophy undergraduate and we had to write an essay about the problem of other minds and i spent i spent a whole week really really really worried because when you think about it you don't know that anybody else is conscious so it's actually that's one of the things that's really interesting about how we project these things onto ai because a lot of people are talking about oh if if ai or robots become conscious then they they've got rights we should treat them in the same ways we should treat humans but it's really interesting because even if they were conscious you wouldn't you wouldn't how would you tell they were conscious but also how would you know what their consciousness was like because we look lots of i mean loads and loads of animals we assume are conscious but we don't think they have the same rights as human beings we don't think that the dog's got the right to vote because he's conscious so it's it's really interesting how quick how quickly we assume but how quickly so many people assume but also it's i mean actually it's really human tendency it's a really human tendency to extrapolate humanity onto onto things like you see faces of things all the time and there's a tendency to sort of extrapolate humanity onto robots really quickly or worry about i remember joanna bryerson who's works in robotics and she also works now a lot in ethics she she said she noticed that when she was working with robots people would really worry about whether it was like cruel to unplug the robot so yeah it's really interesting to project project onto it but also i think i think there's another reason for so we could sorry it's really it's super it's not it's not just a little interesting it's very interesting because what's mostly interesting about that to me is the notion of the the making of a body right and so the idea that yeah the idea that you can make a body to host intelligence is something which has existed forever that's what idols are idols have always been you know statues of gods have always been the creation of bodies that would host intelligences and that intelligence would manifest itself through proxy like in a proxy through proxy through it's the believer that they are the people sacrificing to that god through this through this image and so it seems to me that we're noted we're seeing something similar happen now is that the the let's say the intelligence of artificial intelligence is through us like we are the proxies of the artificial intelligence it needs us in order to be intelligent but that doesn't mean that it it doesn't act the way that an ancient god would also act because we trust it like yeah the way that the ancients trusted the gods we trust google we trust facebook we trust these algorithms we kind of good give our trust and we all look to it so it ends up acting like really does end up lacking almost like a like a god like a ancient god yes but also also it's worse than that because we've we've painted ourselves into a corner because we have to we have to trust it because everything is set up everything is set up in order to have you have to use it and even if you aren't you're walking down the street and it's being used so we've paid we've painted ourselves into a corner there so yeah so say you because there's also a lot of distrust as as as well but but it actually gets back to the question about you say your computer scientists say you'll never have artificial general intelligence which is i who knows because others others argue that you can but you can it's always in a sense you always have to oversimplify to explain points but you can divide you can divide concerns in ethics of ai broadly into people who are looking at the future so the possibility of super intelligence something which might be in the future sometimes maybe 25 years in the future or whenever there's lots of debates about how long it's going to be if that happens so some people are worried about super intelligence and then worried about whether so that's in two branches so some people really look forward to that and think that is really great and our descendants will actually be digital all humans will become digital so that's one one lot actually think that and another lot are really worried about this and we need to prepare so one argument is that maybe it won't happen but we need to be ready just in case it does trying to make ai sort of beneficial for humans and really worried about ai is going to take control so there's a worry that in the future it'll take control and then there are people who are concerned about what's happening now with the ai we have now and all the other computing which is maybe not quite ai but i think that's a false dichotomy because it's already taken control yeah it's already taken control yeah and i think the to me the best way to see it is still in the analogy of the ancient god or the ancient temple is that it's taken control through through a priestly cast which is what would have happened in the all the temples before that the will of the god manifest itself through the priestly cast which in which informed the people yes you know and tell them to look to the god right the people the cast is saying look to the statue and then then they are explaining the will and it's like i'm i'm not even saying that as if it's bad like it's actually how reality works but it's a fr but you need to know who your priestly cast is and i think that that's one of the things that at least in certain spheres is worrying people the most is that these tech elites are not definitely not uh a superior cast like they're definitely not the people you want to entrust your civilization to no no no so yeah i think it's really important to remember that because when people talk about ai being in charge we also have to remember that but there's there's people it's actually people doing it big corporations and and they're half in charge and half not in charge that's the problem they don't really don't really know what they're doing it's like you've got a pre a priestly chart cast of heart half wits really it's like that's also why that's why so why there's a it seems like there are some mechanisms which are set at hand and so like one of the things you said at the outset which really intrigued me is the idea that the problem of the ethics of like the problem of the ethics of ai isn't just about deciding what the code of ai is it's that there are certain there are certain patterns which are there which will lay themselves out and so you can say whatever you want it's it's almost as if you said like i'm going to create an ethics of weapon making and my ethics of weapon making is that you can't use these weapons to kill people okay dude it's like that's really nice but though you're making weapons right and so and so it's the same with ai it's like there's a there's an internal mechanism to what ai is doing that means that you can't just impose an ethical system on it you can recognize the ethical possibilities of it and you have to and you can try to implement them as best you can but there are certain things for example the the near infinite amount of power that it can give certain aspects of reality it's something that it doesn't matter what ethical system you apply to right whatever whatever ethical system you try to apply to something which has massive power is not going to not gonna hold yeah well yes i mean there's there's so many different things you could say about that so what so one of the things that's happening so for example it we're trying to sorry i'm stuffing because there's so many different things to think about but there are ways in which people are trying to make certain that the ethical systems are as ethical as but sorry the ai systems are as efficient as possible so there are loads and loads of people working on like technical aspects of how do we ensure privacy so there's big big issues with privacy because of all the data that's been collected all the time but not for data that's being collected for ways in which we can analyze it so you can extract stuff out of the data that you had no idea that you could extract for example so they could work out but they can they can work out from they can work out from your shopping habits whether or not you might be developing dementia they can work out your mood from how you're typing they can work out all sorts of all sorts of things about you they can guess all sorts of things about you but by analyzing the data but but so the the way in which we think about privacy is all being shaped by how we use the tech at the same time as we're trying to make certain that the tech guards are privacy is that the kind of thing you're thinking of so the ways in which the technology lures us into posting stuff on social media the way in which it manipulates our emotions so that it it it tends to like twitter for example tends to incite the worst emotions it tends to get at your kind of like angry feeling so that you you you'll you then reveal things about yourself that you wouldn't ordinarily reveal so so is it so the way in which we're thinking about the notion of the self how we relate to other people how we think about all those things is changing all at the same time as we're trying to try to call it is that right that's the right that's exactly the right way to say it is that it's actually modifying the manner in which we engage with each other yes through in its image yes like in the image of the tech and so it's having a like a parasitic effect and i mean that's also obviously the danger of any kind of extern any kind of supplement right is that it has a parasitic possibility which is that it then starts to shape reality to its own image and i think that one of the things we saw with like kovid you know i did this interview with christian about marcia mcluhan and he talks about how mcluhan said that we're basically already the sex organs of the machine and it's like it sounds like something witty to say and you know you think okay that's really pithy but i think that i've been seeing it more and more now with kovid like just how much that's true because all of the things that we did for kovid would not have been possible without this would not have been possible without zoom without social media without all the technical technical tools that we have and it actually modified our the way that we perceive kovid because if covet like i'm i'm sorry to say this for people who have it and and like have suffered from it but if co if the the something the size of kobe had happened 100 years ago it would have gone pretty much unnoticed like it would have not had been it would not have changed the very structure of reality like it would have been noticed like as a disease but it wouldn't have changed everything yeah yes so i i'm not we i think we i think it's a strong argument to be made for saying we couldn't possibly have had a lockdown we couldn't possibly have done a lockdown if we didn't have the internet and even even if it was just like 10 years ago or five years ago then we couldn't possibly have had this kind of lockdown could we no it's now this is it's like this is coveted is the image of of now and it's the and it's and it looks like the internet and let's say this this technology yes yes wanting to get th it lives through attention and so it's it's actually it's actually increasing the amount of attention we give it through through the mechanisms its very own mechanisms and how it's able to adapt to reality it's like it's like almost like a weird darwinian thing where it's like adapting to reality and taking opportunities to increase its its its effect and power yeah yes but it's but it is i that the idea that the where the sex organs of the technology is is kind of really really intriguing but i also kind of want to fight back about it a bit because if we take that too literally any kind of it lets the tech guys off the hook because they are deliberately they are it does we don't want to let them off the hook we really don't want it because otherwise they're just mark zuckerberg it's just for helpless pawn and could do nothing so there's a sense in which they are there's a combination but it's like they're they're the doctor evil's henchmen or something but they're actually working in in conjunction with it but yeah so for william but i think it's really interesting to have a way in which we relate to each other through all this zoom and not and distance meetings is changing so much of course one thing to remember is that but lockdown hasn't changed the lives some people's lives haven't been changed very much at all so for people who are delivering they're still going out delivering so but it's like it's that's interesting as well the way in which it helps to divide people because it's basically as you could point out there was a tweet the other day that i really laughed at but because you know how tweets are always taken too literally these days somebody said in reality there has been no lockdown middle class people have been hiding while working class b people bring them stuff so there's wishes and of course there are people saying oh no no i'm middle class i'm a doctor i go out but the point the point is that it's actually also it does actually divide people a lot so the technology divides dude we have different experience of it but the way in which we relate to each other say over zoom is really really interesting because it changes how we think of ourselves because it makes you much more conscious because you can see yourself so you're thinking that's right i look stupid do i look stupid you know what's in the background like i need to go to class a couple of months ago and realized that i had my washing in the background so i didn't like didn't want the students to see my washing it's all that sort of thing but how we relate to the other person so even the visual information you get from a camera even a really good camera it's a tiny fraction of what you'd get if you're in the room with a person yeah exactly because you don't realize that when you're with someone you noticed very small things like you notice them almost kind of implicitly the way they're sitting the way their hand hand is twitching the way you know the smell of the room the there's so much happening like you know you notice how you notice like how dirty someone's hair is or like it's like these little things that you sense when you're with someone and it gives you an impression of how that person's doing or you know what's kind of going on around them whereas with zoom you know and and it's just it's a it's another version of something like social media you know i've argued for a while that social media is is basically you know a form of of showing yourself and and then watching other people it's like entertainment brought to the individual level and it's not true it's not true interaction right it's a form of even this like obviously we're having a public discussion right this is not the same discussion we would have if we were sitting together in a in a you know in a coffee shop no no it had been a cup of tea for a start and yeah exactly yeah it would be but there was something i've been thinking about recently which is which i'm really would be interested to know what the effect of this is because also again like in lockdown i think the experience of there are millions of people who've been in lockdown completely on their own for months after month after month so i think that experiences could well be really quite different but then one of the things i was thinking about in terms of in terms of i was thinking about it in terms of how ai ai sort of runs on electricity and the importance of electricity and then it occurred to me but of course we run on electricity as well as biological creatures and our electric fields from our bodies extend beyond our bodies so but i actually have no idea what impact that would be and whether you could pick it up from other people if you're in the same room as people i'm just thinking about the physical distance of not phys because we can communicate as much as we want sort of verbally yeah no but i think i think you're absolutely right you know the idea that you know that someone's looking at you from behind is real like that's not fake when you know all of a sudden you know someone's looking at you yeah and it's like but that why would that like i don't know why that would bother anybody like why would that bother you because animals have all kinds of yeah of of ways of perceiving that are not just like the four senses or whatever so i think that you're right that we obviously that this technology is is extremely focusing like it's extremely limiting in terms of our human experience with my kids i see it it's nuts like my kids you know we had very limited tech in our house so very very limited like an hour of of watching something a week pretty much and then kobe did and we just lost absolutely there was no way because the only way they could have contact with their friends was through was through digital and then you realize that some of your kids actually prefer it because it's safe yes yeah right it's it's safe because you have total control over what you're projecting yes and you you don't you don't have all the side effects of of a conversation you know and all the possibilities of of misspeaking and of of of making a mistake and you know of whatever of having a snot come out your nose or whatever it is that kind of disc little thing that can happen that makes you embarrassed or makes you whatever in a real conversation it's much it's nice and clean yes but but it does focus towards certain parts of the experience wasn't it because i think all of this tech focuses very much on cognitive and linguistic and in a way and away from embodiment i mean i was thinking about i was thinking about it like being so distant from people so it just occurred to me that like the family i'm from like my mum and dad especially my dad really we're not the sort of family who actually spoke very much you know we weren't terribly chatty you know what i mean but you still want to go and see somebody and you would like i'd often spend hours with my dad just like sitting together in silence but and it's that kind of thing it made me if that's thinking about that maybe you really realize how this is all focusing towards certain aspects of human experience only so would that be an example of how the technology itself is is is twisting stuff without it even actually having any content the way in which it's the way in which it's where using it is yeah and there's also a kind of it's also it's all based on attention which is really important i mean i kind of talk about that a lot how attention is the basis of reality but the the tech companies and these these platforms they seem to have understood that and now they are using it in a crazy manner because the like like the likey thing is so smart like whoever came up with the like button is an absolute demonic genius like it's a it's amazing because you can get pure attention yes yes it does it's not messy or it's not messy attention it's not like the kind of attention where someone is looking at you and and all of a sudden you see something in their eyes and you don't understand what it is like are they angry with you or like it's none of that it's just like like yeah pure pure attention yes like like or dis like or dislike yeah exactly it doesn't matter really it's all about quantity of attention yes yes yes it is but it's only a it's it's not attention the same as a sort of attention if you really wanted to attend to a person but that is going to be that's really complex attending to a person is really really complex thing to do isn't it if you're really but it's it's so it's it's sort of attention but it's only attention to a tiny bit of attention it's a currency of attention attention transformed into currency because that's what it is and it's hilarious because you know it's like i fall in that all the time people ask you how many people are following you on youtube how many people are following you on twitter and you tell them right and then you see in their eyes that it gives you power it's like i have so much attention this is how this is the the currency of attention that i hold and like if i want to be invited on a podcast or if i want to to have up someone comment my on my on my show my currency of attention is going to decide whether or not they'll accept and so it's like it's a very i mean it was always kind of like that obviously prestige has always been a part of of how how things work but now it's been so quantified and it's it really is a type of currency yeah yeah it's yeah it's interesting it's really interesting how it's quantified so you can like count you can count but i mean that's just you can count the likes yeah you can see there's a number and it's like you can see how many people have said they like you yes it's not about quality it's just about quantity because you know it's like someone the one person saying they like something because they're scrolling through and they see it and they find it mildly interesting and they just like it and another person who sees it and it like changes their life and then all they can do is still just click like like yeah you know or low or put a heart instead of a thumbs right it's like just a little a little more but still it just shows you how much it has been transformed into and just a kind of quantifiable currency yeah yes so what i was gonna say like that for example like that system let's say that this system now if you try to apply an ethical layer on top of that right it's limited by the very system itself but the very system of let's say current turning attention into currency will reduce the ethical possibilities of that system i don't know if that makes sense yeah i think so but i was just going to point out something something really paradoxical at this about how this is if this relates to ai and computing so the value of ai we can see the currency of that is intelligence and trying to introduce cognitive capacity and intelligence is in fact the most important part of human beings but then how it treats us is nothing to do with intelligence it's it's it's hitting the sort of basic part of ourselves it's like hitting raw emotion and not just even general emotion but just a really just just a really attenuated part of it so so for ways in which yeah so this is an aspect of control that's like really really disturbing i think and really really worrying and and also a big split in how on what values there are in the system so that it's you especially see this in a lot of a futuristic futuristic talk about ai it's as if there's a lot of a futuristic talk as if humans are okay we're pretty intelligent we've come as far as we can get and then the next stage is going to produce even more intelligence to try to either have a transhumanist to extend our intelligence or maybe just see but that biology is has got its limits and we need to go into a digital form and get more and more and more intelligence so there's that aspect of it but then how we're being treated is we're being we're basically being treated like farm animals right we're just basically being treated like like objects yeah yes when you've reduced intelligence to quantity then and i mean the mecha and you mechanize it and you you have this idea that mechanized reality is somehow higher then then you're treated like a machine that's just how it's gonna it's not you can't stop that right it's yes yeah yes yes yes so we just we just manipulated some emotions our emotions are just manipulated and yeah and just just reducing us then yeah and so like for example like if you but this is also one of the ways that for the idea of like submitting to a god let's say and how once you do that then you can't change let's say the the direction right so i have this contention maybe i'm wrong maybe i give them too much good good good reasons for their action like good intentions but you know what i think that like when facebook and twitter started they basically they understood one insight which is attention we just need to keep people's attention yeah and then they didn't at all realize that the easiest way to get someone's attention right is through appealing to the lizard brain right appealing to the rawest emotion you can appeal to and then then you'll get have their attention and so now they're it's like they they were they set up a like an ideal like they set up this false god and now they're paying the price for it and they don't know what to do with the with the results of it and it's like so how what do you do now that you've created this well i suppose there's quite a lot you could do there's but yeah there's a sense in which they they've created something they don't know what to do with but also there's another sense in which if you're already if you're a billionaire you've got quite a lot of choice about what you do and it's and there's there's a lot there's a lot going on which is like really shocking and awful of the things that they but the the way in which you're projecting is it so here's an example a lot of the stuff it's it's as if they're projecting this idea so one of the narratives is there's an idea that ai is going to take over it's going to do a lot of work for it make life better for for humanity in general and that's a beneficial ai movement is all about that but if you look at a lot of the things that's happening with things like social media and facebook there's an underclass there's all sorts of work all sorts of hidden work that's going out to human beings actually doing it so appalling jobs doing content moderation which are generally really really poorly paid and a job that no human being should have to do having to look at the relationship it's just just horrendous and a lot of the stuff a lot of stuff like in machine learning is farmed out to people people who are labeling images and doing sort of it's actually people doing the labor so in a sense it's a bit of a it's a bit of a con disabled it's a machine's doing it because there's armies and armies of people doing it really low grade really really poorly paid people so that's a really interesting point because it it like you said because intelligence actually comes from humans like real intelligence yes so what they're doing is they're farming intelligence in people yeah they're feeding it to the machine yes yeah yeah right yeah yeah yeah that's what it is that's really fascinating it's like like and it's interesting that it's like you said it it inevitably happens that the people that are doing this like the content moderation and the image labeling are like semi slaves right there they're at the bottom of the social sphere yeah they get paid minimum wage or whatever yeah you know and and they work at night and do all kinds of craz like it they end up looking like the dregs of society you know and so then it it even it even makes even more sense to imagine it like like the matrix like really the matrix but instead of like instead of getting body instead of farming for body which is what the matrix suggests right is that they they're getting energy from the human they're not it's the opposite they're actually farming intelligence and farming farming capacity to the capacity to identify quality because that's what the machine doesn't have so yeah you get that from the humans yes yeah yes but yes but yeah it's really interesting yeah sorry for somebody it's really interesting so another dirty secret is it uses up masses of energy so it's like it's really really energy hungry so a lot of us a lot of the stuff is a lot of stuff a lot of stuff is really really hidden and it's it's it's not at all what you expect so you but so that's a dive that's a real divergence in the narratives there's a narrative for in the future but we'll have lives of endless leisure and be able to do whatever we want to be really creative and so on because the ai is doing all the stuff which is really interesting as if the work is going to be really fascinating but yeah that's yeah that's that's that's wonderful yeah that's very that is very that it definitely does show you i mean i think the content moderation is one of the most fascinating i sense is that it's almost like the people who do content moderation have to be lured in like you said from very low like low lungs of society because who in their right mind yeah would do that like everybody knows that doing that would destroy you yeah it's like you hear those ads on tv like you hear those ads on the radio of like going to test pharmaceutical products like the people who do that are the same people who will be doing content moderation because yes yes yes yes yes yeah yeah it's really terrible but but as you say it's for humans have to make the judgment i mean that would be given that you're gonna have to have people doing content moderation that would be one thing that you really would want to be able to train an ai to do because you really do not want any human being to ever have to do that and it i mean some of the stuff would have to then be handed over over to the police wouldn't it some of the stuff some of the stuff there is like illegal and needs to be given to the police like yeah i'm sure it happens all the time yeah yeah but but then if the thing is that you don't want the ai to be in charge of that because the the problem is always the side effect of power yeah right and so in the sense that it's like it's it's almost it really you know what it is it's like the genie and the wish that's what we're getting yes you know the genie comes and says you've got to wish and then the person wishes but the genie gives that with absolute power yes and so the person never thought of the side effect of what they wish for and then the side effect comes crashing in yes yes yes yes so yes so so we keep on coming back to the fact that you you that you really do need humans in all of this so one of the one of the side effects one of us like side effects of what's going on in social media are things like the proliferation of so-called hate speech that's like a really interesting thing to think about because there are loads and loads of people working on say developing algorithms to be able to detect hate speech so that you can automatically take it off but of course you i you i mean you'll be able to work out a lot of the problems with that straight away because detecting irony is a little bit of a problem for a machine yeah yeah it's a problem for a lot of people actually detecting irony so so there are problems then you get problems where so there are also people working on bias in all the data because he wanted to eliminate bias and that's that's another whole story as well so ben is bias in hate speech because certain language groups or subcultures will maybe do something which seems to hate speech but then there's also a problem that it's really interesting how it how it creates itself because one of the reasons so it all feeds into then cultural issues so one of the reasons why you might so let's suppose we take the idea of hate speech one of the reasons why there's so much stuff which counts as hate speech is because of how social media works it encourages it so it's created the problem and then it's trying to solve a problem but it all spills over into society because as well as this happening we have issues that going on in culture where people are now falling out having rows getting thrown off social media all those kinds of stuff and then the idea of hate speech is then getting built into laws various kind of laws so there's a really interesting this is one of the reasons why i think we need to modify the idea that whoever sex organs of a machine because there's far more complex going on as well so we can't just look at the technology we have to look at what's simultaneously happening in in the culture and how that feeds back into it yeah so what you said about hate speech is actually brilliant because like you said the the anonymization and the fact that we are physically distanced from someone and we can forego getting punched in the face right by saying something offensive means that people have feel like they have all the opportunity to to let loose their id and to let loose all these darker aspects of them and then the same system which brought it about is now trying to clamp down and it ends up like you said spilling out into into normal society and then it ends up becoming a becoming the standard by which we we have rules in in reality yes because like when i meet someone in real life you know the type of insult that's that you would be capable of do saying online is you'll be really reticent to do that in person i mean some people will but it's very rare and and that person will be ostracized quite rather quickly yeah yeah and then things can happen like you know pylons on twitter so you're not going to get that in real life where somebody else is going to join in and like thousands of people who just start like giving you death threats that doesn't happen in like when you're walking down the street and you you know you flip off someone or you like say something you're saying something stupid yeah yeah but then but then of course people can get then of course the solution is it can also be a problem as well because people get ousted unfairly so you you so there's no kind of right answers people can get thrown off throw off social media and then then there's a there's a there could be you can say oh you don't need social media but there's a problem we've become so we've become so used to it and their appeal actually was really interesting last term i was in the middle of writing a lecture on censorship online i thought i just checked twitter only to discover that my twitter account had been suspended so i have no idea why not i have no idea why not you had this real really weird appeals process i had to put in an appeal and say why it was i thought that i shouldn't have been suspended but i didn't know why i'd been suspended so i couldn't reply it's really it's really it's like it is like and this is something that i've seen it's it's really insane it's like it's almost it's a strange thing it's like how is it that tech companies are bringing about the like kafka state like the the insane bureaucratic communist type state where you don't even know who to talk to you don't know like there's no human on the other end of the line you have no idea how to to appeal to whatever it is they're doing to you and like you said and because they're afraid of you gaming their system then they make all their rules completely opaque yes yeah yes yes it's it's yeah it's it's yeah it's really interesting it's really interesting that you have no idea what to do what to do about it but it's also interesting that but a lot of people working i think haven't actually necessarily thought about the problem of being the problem of being ousted because of hate speech because they assume because a lot of people working on this problem there are lots and lots of people working on this problem technically and we're looking at hate speech and how the algorithms work and so on but a lot of them have certain assumptions i've noticed have certain assumptions where it hasn't occurred to them that the hate speech is going to be biased in certain directions so it actually was interesting a couple of months ago i was reading a paper where some researchers had looked at an algorithm but facebook uses and how it tends to be biased towards what they call hyperactive users so certain users who are on online a lot and comment a lot and so the algorithm boosts them so they get more visibility in facebook yeah so you might kind of think well good for them they're putting in the effort but they were concerned about this when i first read it i said concerned about it because these groups tend to be far right but they want to read it again i'd actually misread it they were just concerned that the groups were right-wing yeah so it wasn't and they were concerned that they have a certain that they're biased politically it's because they're concerned that they were right-wing i think hang on a second you are allowed to be right-wing aren't you last time i looked it's because they have them people writing it have got themselves their particular bias yeah they're and they're blind to it they don't even see it's like yeah you hear it all the time it's like it's like oh but he's right wing i'm like what wait what is that did you just say that as if it's like he's not human or like that he shouldn't exist because because he's right-wing that is just and and people will say it like just like that without even thinking i know yeah it's really weird but that's quite new i think it's quite new so i think that's i think that's that's an exam well i think it's an example i think that's an example of how the tech of a culture were kind of working hand in hand to accelerate that so another example is another example of a lot of the stuff that's going on is really contradictory so on the one hand a lot of bai a lot of the ai is tending towards uniformity so uniformity of language the dominance of english for dominance of particular sorts of english actually yeah the dominance of of american in american english and oh things like you know that when we spoke before we were talking about that annoying i find it really annoying when you're writing an email and tries to write for you suggest yeah gmail does that yeah yeah yeah so that's gonna that's gonna sort of unify and but at the same time fragmenting a different to different identity groups but you might think those are intention but the social media is actually encouraging and enabling the identity identity groups to happen and it happens so quickly because so for example the different different gender categorizations that has happened so fast the proliferation of gender categories it could never have happened as fast as that before the internet it just could never have happened because we don't communicate so quickly it could never have happened as fast as that yeah and also because it's because let's say people with alternative gender like identification are so rare but because they appear as a marginalized group on the social media platforms so the social media platforms want to protect them because they're marginalized therefore bolster their voice therefore make them appear as yes a substantive like category of of human of society when when in reality you know like actual transgender people are like how many people like unless you're in that scene you'll maybe meet one or two transgender people you know in in in the world like you rarely meet people like that unless you're like really in a certain scene so i mean i mean that's just that's fine that's it's that's reality but it's it just like you said the very system itself creates this weird thing and then because it bolsters let's say the group then it also ends up attracting attention to it and then for attracting people who want to bash because that's just just how it works yeah yeah yeah yes and it's also it's also actually linked to a consequence of trying to do the right thing ethically so there's quite rightly concern about being biased because who wants to be who wants to be biased who wants to exclude people but because there's such a concern about being biased in the data and biased online that that feeds into the idea that you need to you need to protect these minorities because because of a focus on particular particular minorities but but i also discovered something i also discovered something really interesting you know famous facebook's famous 70 different two different genders yeah identities that you could have like i was looking it up and you could if you put in your gender you have to start typing it if you drop down menus and different different sorts of different sorts of ones but then underneath it is underneath it there's one that you can click interested in who you're interested in and when you click on that the options it's not 72 options the options are men or women you're funny they could have at least added the other 70 back in there you know it's like have this like exponential possibility it's like because then they're like wait a minute how like we don't really actually we're like we just want attention so we don't care what you say you are we just want to know what you're attending to it's like if we put 70 down there then we can't be a lot harder to track that it'll be harder to have our algorithms you know like to sell that data yes yeah yeah yeah that's probably why oh mercy that yeah that is that is some frightening stuff but so what ends up happening this is a fascinating thing is that because there's so much power that in order to like for example in order to counterbalance this the hate then they create this weird upside down world like it's actually there right if you write straight couple on google you'll get gay couples all right right or you'll get straight couples that are talking about homosexuality or that say like i think one of the top things on google that came if you wrote straight couple was something like a straight couple that said we won't get married until lgbt rights are are accepted you know right so it's like so you get this like weird this like really strange world where it's like it's like you want like let's say you you they end up having to to promote the margin to a certain extent like more than normal right and so it creates this like i talk about this weird upside down hierarchy which ends up manifesting itself yeah yeah and of course and of course there's a margin of a margin because it's only going to be the really vocal people the only the only the activists who are going to be out there because there must be there must be lots of transgender people who just want to carry on and live their lives of course i would say probably most yeah yeah but that's why it's because it's an attention economy so it's even more like it always used to be that the squeaky wheel gets the grease but now it's it's it's it's increased by the very system yes the fact that people can can can congregate and become mobs right they become these attack mobs and they do all these these these these kind of gestures online yeah but so it's fascinating like i mean and it's fascinating one of the most fascinating things is that what ai is doing is that it's basically just giving more power like huge amounts of power to whatever it is that's leading it like to whatever this priesthood has power and so it seems like the fight like the the cultural fight and that's something people haven't i think there's a little bit of it like the fight for what comes up on the first page of google like that should probably be the ultimate culture war like what it is that appears on the first page of google because that's really it's become like the frame of of of reality and it's clear that it's not it's there are people behind that like you can see like there's something when you auto type then it doesn't auto type it and then something just doesn't there's all these things and you know that there's like people pulling the strings behind yes yes but yeah but it's like the wizard of oz it's actually it's actually it's wonderful because they can just say it's the algorithm they can even make ai they can even point ai and say oh it's these algorithms it's not it's not it's not our bias right it's not our bias isn't there it's just these it's just ai doing it but yes that might also be one of the more frightening aspects of ai yes yeah yeah yes i mean the whole notion of bias is really interesting as well actually because because it tends to rest upon an idea that we can get an unbiased view of the world and my my view of the world is unbiased what are you talking about but together to get an unbiased view how would you get non-biased view of the world you want to collect all the data and you can't the world is not just collecting data you'd have to analyze it so how could you get a completely unbiased view of analyzing the data so so that again but about actually so some interesting things can come up so when when people talk i mean if you if you say anything critical it sounds like you're against trying to get rid of bias but what i'm interested in how people speak about it and failed to see that underneath it you've got to have some view of how the world is divided up so so it's not yeah it's not it's not the problem of saying you want to get rid of bias it's the problem of saying you want to get rid of bias but secretly wanting to impose your bias on everybody else yeah that's really the problem right it's not like if we had a normally like if we had like a normally recognized hierarchy of being that it's like we recognize it we see its problem we see it's and we just say this is what it is right let's say like the ancient world is like okay so you have the king you have the the bishop or the pre or the pope and it's like and then the world kind of lays itself out so you can hate the king but he's still above you and you you recognize that hierarchy and so and then the world kind of lays itself out in that way and everybody kind of knows that that's how it happens but now because we say no there is no hierarchy right it's equal and it's objective and it's all this stuff but then secretly there is a hierarchy there's like a secret hierarchy and a secret bias that no one wants to acknowledge this is something that has been frustrating so many people in the media as well like not just media like media and social media companies that they keep saying that they're being objective but obviously they're not we just wish they would tell us yeah just say that you're not and so at least we can start there yes yeah yes yes yeah but there's i mean it's one of the really interesting things about about the emphasis on bias is because i think it also speaks to an idea about the idea about what's what ai like how ai sees what's wrong with humans and way in which ai might seem to be better than humans so it's like if you if you this is talking in really really crude simplistic terms but if you think of ai as being better than us because of the intelligence and its data processing capacity then it's as if the problems with human decisions come in from from our biases and that's because of our emotions which and the emotions are getting in the way of getting to the right answer and being completely objective so that's that's really really interesting because the emotions are seen as so on the one hand having these emotions and being biased because of our emotions it seemed to be a problem whereas at the same time as we've seen the whole system is working on manipulating our emotions so it's kind of like it's slapping us around the face like accusing us of stuff but then encouraging us to do the same thing is you do what i mean yeah and that seems to be like the the that seems to be kind of what tim cook was trying to get at in his speech at the edl where he talks about the god out of the machine and he says he's he's saying he actually doesn't like the idea like he says i don't think that ai can do it on its own but he says it's people behind the ai and then he says that's the god out of the machine which is even more frightening to me it's actually even scarier to me because it's like it's like mr cook is like i really don't want you as the god riding on the machine not you seriously my friend yes that frightens me tremendously yeah yeah because yeah i mean it so quickly goes to a sort of totalitarianism because that these guys are not elected you can't get rid of them yeah it's it is it's much more frightening isn't it so the power of the tech companies it the power of tech companies in relation to to politicians and to politics is is is is it's a really frightening thing actually no is well i mean i would say that this this election the american election was basically run by social media maybe the last one too but this one for sure like they they just decided some things you're not allowed to talk about yeah you're not allowed to talk about certain things and then and then certain things are put up at the top you know of trending and so that's just it ends up being and also because we're all on lockdown anyways and we're all looking at our screens all day yeah yeah so it's like it just it just it's it has become the ultimate totalitarian possibility is right there in front of us it's right there in the situation in which we're in yes yes yeah yeah yeah quite right so i think it's one of the reasons why it's the idea that worrying about super intelligent ai and the future taking control of us is just a misnomer because it's already it's already happened it's already happening but but then on the other hand i really do think that we have to try not to sort of cancel despair because we had to try and do something about it what do you think we can do what do you think we can do about it well i suppose there's stuff happening already isn't it like people trying to set up alternative you know alternative social media and yeah like parlor right yeah yes then it was deleted yes right and so i don't it's like right now it feels like their their the control is is extremely strong it seems like it's going to be very difficult to create alternative narratives and also because also because the alternative narratives like i don't know if you saw the article on the times in the in the new york times today about what is the name of this this new app where you just talk man i can't believe i can't ever forget what it is anyways it's this new i don't i don't i'm not on it but it's like this app where you just pop into conversations so you have these conversations right you can just pop into a conversation and they were saying unfettered discussions are being had on this app and they were seeing it as a bad thing what yes they were saying unfettered discussions are being had and it raises the problem of intimidation and bullying and all this stuff and you're like it's insane and so yeah and so and you see it like even the some articles have been going out against the the messenger applications like the encrypted messenger application saying like this is shady shady these these shady applications that are encrypted you know why you know we why would you want to hide your conversations it's like it's just insane that it's become it's become it's been taken for granted that private conversation yes is in itself yes shady yes yeah and that's that's something that you really have to watch out about because that that thought then just can translate into a real world so for example in in scotland at the moment for example they're discussing there's a new hate crime bill up for discussion and one of the aspects of it was to repeal there's a private dwelling exception for like hate speech that you could you like basically but you're but if you're inside you're getting say things in your house well there's discussions about whether we should get rid of that but i kind of think that what's happening on social media is is like warming a brain up for thinking that maybe that's a good idea but but of course luckily there's a huge backlash against it there's a there's a huge backlash against it so one of the things that's happening in lockdown is we're forced into all this social media but i do wonder on what might happen when if we ever get out of it i kind of think we might be like have you ever seen cows let out at the end of the winter you know when they're left under the fields and they jumper i think we might be like that so but i think that we might just kind of realize what we've been missing and maybe we'll see a good thing someone someone it's hard to know what these polls are real or not but someone posted a poll in the u.s saying 75 percent of people say they'll still wear masks after covid so yeah yeah we take your mask off during a zoom call though that's all good yeah it's yeah it's it's difficult see because is it one of the things i find really interesting about working in the ethics of ai i kind of like the most interesting area i've ever worked in because partly it's like it's the most scary but also i think when we're when we're looking really really closely at how the technology might clash with human values i think it has got the potential to be really really fruitful and useful because it helps to remind us of what we're missing helps to remind us what our real human values are so yeah and if you can use the things you're saying to put a mirror up to people so that we can see ourselves in the way that we talk about ai and the narratives that are surrounding our eyes yeah yeah that's yes that's probably the first step in helping us yeah yeah major pitfalls yeah yeah but it's i was yeah it it maybe we'll maybe there'll be little groups you know like in is it i can't remember it's brave united in brave new world when they got the savages is it was it i get it yeah yeah yeah yeah yeah brave new world they they have like this little tribe of savages we can be a few groups of savages that actually like that actually see each other face to face that might be good yes yeah but but i also think one of one of one of the big problems one one of the background problems for when people are trying to think about the ethical issues here ever paucity of how they're thinking about it so a lot of a lot of the work that i see around ai ethics is basically built into what you might broadly call like broadly utilitarian or broadly consequentialist ways of looking at things which also fits into the ways in which intelligence is is understood so so those are really interesting narratives i think as well i've been running behind ai so there's lots and lots of different disputed definitions of how you might define intelligence and lots of different forms of intelligence but but but the form that's often used which fits really well with computing is the idea that something along the lines of the intelligence is the capacity to reach your goals to be able to take steps to reach your goals so that intelligence is just instrumental but it's like it's just like a an instrumental account of like a means-end rationality that you have a goal that you're aiming to aiming towards so then it fits really neatly it fits really really naturally into a utilitarian way of looking at things where you're going to try to produce as much benefit as possible we have certain goals and preferences so that it fits into notions of trying to maximize happiness or minimize unhappiness or looking at how we might achieve our desires or achieve our preferences so it tends to fit into that so one of the problems with that is that it fits in it fits into a an idea of reason that fits really well into say like an enlightenment ideal of reason that we're just making progress because we're having more and more rationality or where we're achieving more and more of our goals like a stephen pinker type view yeah yeah yeah and then everything but the thing is that it's i don't i don't actually mind that way of seeing intelligence the capacity to reach your goals it's just that the there are higher goals and there are lower goals yes and so the world like on the materialist world and this even pinker world it's like it's a lower world it's a world of of whims and desires and pleasures and pain whereas virtue and the good let's say in a in a christian sense or a platonic sense that's the goal right that that's actually the the actual goal of reality and not only is it the goal of reality but it is also the achilles heel of artificial intelligence which is why it has to farm because what it's farming from people is not it's not just it's not information it's the good it's it's farming quality the red the capacity to recognize quality and and to engage in quality yes that's with the purpose yes and so it's flipping everything upside down where it's it's instrumental it's you it's using instrument to i can't say that word making instrumental the the the capacity to view quality in order to attain practical more like money-making and desire desire filling goals so yeah but yeah but but i think that's i agree but i think that's one of the points where that's one of the points where it might flip and turn on its head because people will realize the futility of it so you can you can see those kinds of things in narratives or discussions around how what we might do if super intelligent ai develops how we might be protected so the idea that you might need to one of the wonderful worries that if it's like it's like the the wish fulfillment worry but if you program a super intelligent ai to say make us happy then what it might do is like plug us into electrodes so that we're just getting our present centers stimulation just getting endorphins yeah injected into our brain yeah so for people working so we don't want that we don't we don't want that we can't have that so he's like oh sam harris talks about that positively all the time yeah yeah my goodness yes yeah i know said but actually it's interesting because these debates have been going on in philosophy for a long time so the utilitarian it's it's it comes out of the discussions about utilitarianism people have been talking about this for a long time because they discovered decades ago that that's what rats would do if you if you put their brains that's what they do they do it until they like collapse with exhaustion so but of course you you would have to be out of your mind to out of your tiny mind to think that that was a good way of living life wouldn't you it kind of you would have to be out your tiny mind so then you then as a branch was looking at we need to try to fulfill human desires but you also really quickly realize that fulfilling your desires which desires so there's a problem about which desires you choose but it makes it worse because of what ai is already doing to us because it makes it absolutely apparent but how easily our desires can be manipulated yeah absolutely yeah but see the worst part and this is the worst step is when the people behind ai understand the nature of desire and actually understand that human beings are religious in nature and then they'll try to implement that [laughter] so we bet it's better to have zuckerberg like moronic zuckerbergs for now than have someone who actually understands let's say the let's say the qualitative aspect of the the human person and how it looks for communion real communion and towards a transcendent ideal and then like they you don't want them to get a grab of that and try to plug us into that because that's going to be right well well on that we probably should finish our conversation yeah yeah yes yeah whatever sorry that i'm more of a doomsayer i feel like i've been constantly pulling the rug from under your feet here oh well well i mean but i just yeah you might be my you might be right i'm just kind of trying to it's partly because i don't want the tech guys to get off the hook but but yeah i think even if there's a sense in which even if you're right we have to try not to be too doomsayery especially because there's a pandemic on we don't want to be too gloomy yeah so what's your final word on this so i'll let you have the final word on possibilities for the future or for us as people to to to deal with this well i think for us for people to deal with this i think we need to realize that actually we still have free will we can still we we still have some control over it and but we can also use it we can also use it to good because it's in opening up all sorts of transmission of knowledge and understanding different sorts of things and communication and just use it for that and and and but also really really think really really deeply about what kind of life you actually want to live you know well yeah dr paula thank you so much for your time and i'm really looking forward to seeing the conversation that's going to be to be had in the in the comment section and i'm sure we we'll have another discussion at some time that yeah that would be great because there's some fair i had loads of questions i wanted to ask you and i haven't asked any of them all right we'll definitely then we'll definitely have another conversation okay yeah yes yes okay great okay it's good to talk to you you too okay bye-bye bye-bye so i hope you enjoyed my discussion with paula boddington about artificial intelligence the stories and ethics that surround it by now the symbolic world is a whole network of things there are of course these videos there's a podcast version of these videos that goes out there's also a clips channel run by several people that are moderators and on the facebook group as well and we also have a blog where a lot of symbolic thinkers are working out their ideas on different subjects from religious symbolism to even movies and video games so make sure you check all that out on the symbolicworld.com and if you appreciate what i'm doing please consider supporting what i'm doing as well everybody who supports my my work gets a patron only video once a month where i deal on more tricky or prickly subjects that are more difficult to to deal with in these videos that are for public consumption so check that out and thank you for your attention