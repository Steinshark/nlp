we've talked about using facial points as features descriptors indicators whether there's a facial expression or not as you can see you can just look at let's say the angle here and compare that with the angle here, and they are very useful they're very powerful, but they can't decode everything for instance if you have a little dimple in the mouth there's no real movement of the the of facial point it's just [that] this mouth corner is sort of pulling inwards, so [you] don't get a geometric variation you do get changes in appearance it's these kinds of features [that] we're looking at when we're looking at appearance features. so they're [very] good at looking at first when i open a frown and so actually when i smile the corner of my mouth will look very different from a neutral position, [so] the question, then is how are we going [to] encode? disappearance and we want to minimize the variation in our you know features and our scripted that's caused by things that are irrelevant to expression such as lighting or identity and we want to maximize the variation or features that are relevant to facial expression and in our case that's quite open edges so we want to sort of encode edges in a very cheap way and a very interesting and highly successful feature for that is called the local binary pattern local binary pattern looks at nine pixels at a time so it looks at a little block of three by three pixels and it's particularly interested at the central pixel so let's say that the pixel value of our central pixel is eight and it has eight pixels around it, and it's nine block let's put in some numbers and that make some sense a local binary pattern is now going to turn this set of nine by nine pixels into a single value, and it'll do that by first comparing every neighboring pixel with the central pixel this is the intensity value or the luminosity value we're not looking at color although. you could do this three dimensions, but normally people [just] look at it in grayscale values, so we're going to compare every neighbor of this center pixel with the center, and if it's greater than or equal to the center we will assign a [1] and if it's smaller than that will assign a zero so 12 is bigger than 8 so that's a 1 15 is bigger 1' is bigger 3 is smaller than 8 as is 2 and? [1/8] is equal to 8 so that's a 1 again and 5 is smaller and then we're going to turn these 8 bits basically because they can only have a 1 or a 0 value you're going to turn those into one byte 1 1 1 0 0 0 1 0 as long as we're consistent we can turn any ordering of these numbers into one string of numbers which we then turn into a decimal number which we will be using to train our system the nice thing about these local binary patterns is that it is illumination invariant if you change the lighting on the scene all these pixel values will go up but the relative difference [between] the pixels will remain the same 32 will still be bigger than 28, so your binary pattern will remain the same irrespective of illumination variation in general, so that's a shadow now as long as we're talking about constant you do get aberrations. you do get difficult situations at the point where you have a cast shadow but i'm only at the location of that cast shadow because we're usually looking at [3x3] pixels this is not a big problem because what we're now going to do is we're going to take a face and it's our big smiley face think i'd be better in drawing faces by now after 10 years of working this area but i'm not we're going to divide this area into a number of blocks the [moment] [i'm] choosing 4x4 and this local binary pattern it's centered on a single pixel and then compares with its neighbors, so basically we have to do this for every pixel in this block and each of those will result in a different decimal number for this block here you might get values of 2 3 4 2 8 8 13 12 etc, and if there's enough pixels in that block if the block is big enough we will actually turn these values into a histogram so basically looking at the statistics how many times did 13 come up? how many times did 12 come up because there's only 256 different values in? this block you actually get quite robust statistics in practice we use something what's called uniform local binary patterns and they only have 59 different possible values rather than 256 so you get really quite robust statistics the other thing that local binary patterns and code is edges as i said we're interested in edge detectors in the edges that sort of show you the outline of the mouth or the eyelid and as you can see here you've got three ones then a set of zeros and one and a zero basically what that means is that you have a transition here from a [1] to a [0] you've got a transition here from 0 to 1 from 1 to 0 again f of 0 1 those transitions are edges so we now very clearly indicate where you've got a transition from a light area in the face to a dark area in the face which is exactly what an edge is so we've turned a possibly very high dimensional space [that] was based purely on pixel intensities into a low dimensional space that only encodes relative intensity values and in doing so encodes edges so we now have got an illumination invariant descriptor of edges when you think about it facial expression recognition is actually action detection. you're not necessarily [you're] not really interested in the static smile you're interested in the fact that i'm you know went from a neutral face to smiling. so you're looking at differences you're looking at actions movements and all these descriptors the appearance descriptors they only describe the edges in one frame [its] static so what you really want to do is you want [to] see how these [pixels] change over time one way of doing that is you could actually extend this block to become a cube and you would get comparisons between the center of that cube somewhere down there and all its neighbors you would have to ^ 26 different possible by values and that's just saying that as it goes back into 3d that's time communities exactly, so if we're now going to look at not at a single frame, but at a set of frames let's say three frames, so then this is our y direction. this is our x direction this is our horizontal and vertical space, it's just a normal image, and then this is time basically saying that this is the first frame. that's the second frame and that's your third frame you can now look at the differences not just within [one] frame between the central pixel but also the difference between this pixel and the pixel at the same location in the next frame or the pixel in the next frame, but a little bit up you should get a cube of pixels around this central pixel 9 in front 9 in back and 8 surrounding it in the in the current frame that's a total of 26 different neighbors so you get 2 to the power of 26 different possible values, and that's a lot instead you can do a little trick, so you can say i'm still interested in the changes over time but [it] might not be interested in just every possible change. i just want to look at 3 or token all planes that's it called the first orthogonal plane of course being just the xy your normal image, and then you take a slice through x and t so there's a horizontal slice and you take a slice through the vertical and time, so that's a vertical slice there that one is orthogonal to the x and t and of course it's orthogonal to the normal xy plane, so [that's] why it's called three orthogonal planes in each of the network codes either edges in space in just your normal 2d image or an edge in x and time or an edge in one in time and if you do this you get 3 times 2 to the power of 8 solutions? which is a lot smaller than 2 to the power of 26? and you still perfectly encode movements actions of edges over time and if you do this, you will get significant performance increases illegal patterns get their own code and all the illegal patterns get meshed together into the 59th