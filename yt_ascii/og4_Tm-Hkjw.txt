hello i'm bryce idene laback i've worked on programming languages and compilers for over a decade i've served as chair of the standard c++ library evolution group which designs and standardizes the c++ standard library i'm a principal architect at nvidia where i drive our strategy for hbc programming models c++ compilers and c++ libraries and i'm here today to talk to you about the future of c++ c++ 20 was the largest release in over a decade it delivered four major features modules co routines concepts and ranges and dozens of other additions and improvements c++ 20 is now widely available with most implementations shipping most of c++ 20 in production we're seeing increasing adoption and more projects in organizations switching to c++ 20 as their default the next standard c c++ 23 shipped back in february there's a lot of exciting changes coming in c++ 23 to name a few enhancements and additions to ranges which were added in c++ 20 formatted output md span a multi-dimensional array abstraction expected a new error reporting paradig time standard library modules and deducing this in the months leading up to a new release of c++ our focus is often on what makes it into that release and what doesn't we put long longer term goals on the shelf today i want to dust off those longer term goals let's look beyond c++ 20 and c++ 23 what's next for c++ i want to tell you about three features that we're working on features that i think will revolutionize how we write c++ code and those three features are reflection pattern matching and senders our exploration today will focus on what we can do with these facilities not the specifics of the committee proposals or the merits of different design decisions this is a talk about possibilities not details much of what i'll show you is tentative and in some cases speculative in places where the design is uncertain i've chosen the option that makes the most sense to me and i've ignored the alternatives this talk represents my own views i do not speak for the committee as a whole no one can first let's talk talk about reflection metaprogramming is the craft of creating or modifying programs as the product of other programs reflective metaprogramming is metaprogramming that incorporates data from the program being modified there are three components to reflective metaprogramming reflection extracting information from the program compiled time programming tools for manipulating that information and injection inserting new program entities let's look at a simple example a function that takes in a numerator and returns its name as a string we're using a few new c++ constructs here the rifi operator takes takes a c++ entity a function a struct in a numerator a variable a namespace etc and produces a reflection a reflection is an is a handle to an internal compiler representation of the type t stood meta info is the type for reflection objects reflections can be manipulated and transformed just like any c++ objects here we pass the reflection of the enum type t to the function meta members of meta members of returns a meta info that represents all of the enumerators of t such a meta info object is a range so we can use a range based for loop to iterate through the elements we want to use the new compile time expanded for loop template 4 each element may be a different type with a template 4 which a normal for loop wouldn't allow in each iteration of this compile time for loop we want to check if the enum parameter of the function is equal to the value of the current enumerator to do that we need to take the reflection of the current enumerator and turn it back into a real entity we can do this with the splice operator the splice operator takes a reflection value and turns it back into the entity that it represents in this case the enumerator in question if the parameter is equal to the current enumerator then we need to return its name we can get that name with another function that operates on reflections meta name of and that's it here's another example hash append a hash protocol that incrementally passes input to a hash algorithm it takes a hasher object and an object to hash first we reflect on the object we're hashing and use the members of function to get all of its members the members of function takes an optional parameter which filters for certain kinds of members in this case we only want non-stat ic data members next we do a template for loop over all those data members we use the splice operator to access the data member and we recursively call hash append on the member we can also inject a class scope allowing us to build powerful wrappers this traced class wraps another type adding a print call before invoking each of the underlying methods traced has a data member of the wrapped object we use a the template 4 at class scope to generate a member for each member function of the wrapped type we inject the protection attributes and return type of the member that we're wrapping next we need to name the me the method that we're injecting we can't use the regular splice operator it would inject the method of the underlying type but what we want is to create a new method in traced with the same name think of the regular splice operator as injecting something akin to a pointer to member we can only use it on an object of the underlying type not on our wrapped type instead we use the identifier splice which operates at the lexical level and inserts a name now we need to generate the parameters for the method here we use splicing pack expansion adding triple dots before a splice will cause it to expand to a parameter pack like construct which can be unpacked with a trailing sequence of triple dots as shown then we inject the qualifiers of the underlying method finally we generate the body of the wrapping method first we print out the name of the method we're calling next we generate the call to the underlying method on the underlying object that we've stored note that here we use the regular spli operator not the identifier spli operator because we're operating on an object of the type that we're reflecting on we forward all parameters and we inject the names of the parameters again using splice pack expansion here we use the identifier splice we're referring to the generated parameters of the wrapping method not the parameters of the underlying method and with that we're done reflection can be a powerful tool for automating data layout transformations and optimizations one common transformation that can have huge performance impacts is switching between array of structs where data is stored as a single sequence of multicomponent elements and structive arrays where data is stored as one sequence for each separate component switching between the two usually requires structural code changes array of structs is often more intuitive but structive arrays usually offers better memory access patterns which can be critical when paralyzing or vectorizing consider this code which applies an operation to just the red channel of a sequence of colors it will have a strided axis pattern and in some cases may have alignment issues which inhibit vectorization we can use reflection to write a wrapping type that auto automates transforming from array of structs destructive arrays first we get the non-static data members of the type that we're wrapping then we inject a vector for each data member of the underlying type this constructor initializes the wrapper from a range of the underlying struct or the obstruct data we use a template four to iterate over each of the component vectors for each component vector we resize it and then we copy from the range of array of structs data we can make our rapping instructive arrays type a range of topples of references to the components so that it can be be iterated as if it was a ray of structs for example to write an indexing operator we use the identifier pack splice operator to get a pack to the element in each of the component vectors at the specified index then we use ti to return a toule of references to those ele ms the same approach can be used to create actual iterators but in the interest of brevity we're not going to look at that in detail i think this is enough to illustrate the general approach now we can take our natural and intuitive array of structs code and by simply changing the type of image from vector to s soa we've switched the code from array of structs destructive arrays this changes the memory axis pattern for our single channel operation from strided access to contiguous access which is more cache efficient and easier to vectorize reflection will fundamentally change how we write c++ code reflection will help us solve problems that today often require boiler plate macros or external code generation things like serialization protocol and language bindings instrumentation logging debugging etc it will change how we build and design libraries and how we evolve the language itself now let's move on to pattern matching c++ has two selection mechanisms today switches operate on a single integral value which is often too limited you can't use them with string literals or objects if statements on the other hand operate on arbitrary boolean expressions they're powerful and can express almost anything but they're often too complex and verbose we need something in between the two a powerful but concise way to select and decompose objects that's what we get with inspect a new selection mechanism for c++ inspect matches values against patterns and binds variables when matches are successful inspect is an expression not a statement an inspect expression takes a parameter the object is select against and a series of patterns there's a variety of different patterns available i'll highlight a handful of them today each pattern is followed by a statement which is taken if the pattern matches inspect stops at the first match not the best match constant patterns match if the object is equal to the constant and the wild card pattern will match anything constant patterns aren't limited to integrals or enums they can be strings or any arbitrary object here's another example fibonacci written with inspect here we use the identifier pattern which binds the value to a name pattern guards can be used to perform arbitrary tests for a match since c++ 17 we've been able to destructure tupa likee objects we can do that with inspect two with compound patterns this compound pattern consists of three constant patterns it will match if the object can be destructured into three components like a tle and each of those components is equal to the corresponding constant on the other hand this compound pattern consists of three variable patterns so it will match anything that can be destructured into three components regardless of their value alternative patterns can match different types and variant like objects any like objects and polymorphic objects they give us a much cleaner way to work with variants instead of writing a visitor and calling stood visit we can just inspect the variant and use alternative patterns we can use alternatives to match a polymorphic object against different classes here we have a circle class and a rectangle class both of which inherit from a shape class when inspecting a shape we can use a combination of the alternative pattern and the compound pattern to determine whether the shape is a circle or a rectangle and decompose it into its defining characteristics at the same time alternatives can also be useful when working with dependent types in a template extractor patterns allow ow us to completely customize matching and decomposition by implementing our own extractor protocols an extractor is an object that has either an extract or tri extract method when an extractor pattern is used this method is called with the value under inspection and then if the result of that call has a value it is matched against the child pattern for example in the first pattern in this inspect phone number. tri extract will be called and if it returns a value that value will be matched against the compound pattern here let's look at a more detailed example that combines the power of pattern matching and reflection we're going to write a simple function to serialize c++ objects to json our function will take an object that we want to serialize and return a stood string first we create the string that will fill with the json we add an opening brace to it which will close at the end of the function after we've filled it with content next we'll get a meta info listing all the non-static data members and we'll iterate through it with a template 4 we output the name of each member and then we inspect the member to output its value if it's a bu we output either true or false as those are constants in json if the member satisfies the numeric concept then we output it as a number using the default formatting if it's a pointer and it's equal to null then we output null which is a json constant if it's a nonnull pointer we just output its address if it's something convertible to a string we output it in quotes if it's a range we recursively call save json on each element of the range and then use format's default range formatting which outputs a json list finally if the member is something else we just recursively call save json on it and we add a comma after the member unless it's the last member and finally after we've done that for each of the members and added the closing brace we return the string in just a a few lines of code we've written a powerful and generic serialization function using pattern matching and reflection writing this today would be a lot more verbose and would likely require each type to opt in and provide its own serialization function inspect gives us a powerful new way to select and decompose objects it makes working with tupple like invariant like objects far more natural in c++ it will revolutionize how we write c++ expressing conditional logic will be simpler and far more natural finally let's talk about asynchrony in c++ today c++ has no standard model for asynchrony and no standard way to express where things should execute that's why we're introducing senders a model for asynchronous execution in c++ there are three key concepts in the senders model schedulers are lightweight non-owning handles to execution contexts schedulers produce senders senders represent asynchronous work that will eventually send a signal a signal is either success and a set of values produced by the work failure and an error produced by the work or cancellation senders can be composed together with sender algorithms to form task graphs receivers are connected to senders and process their asynchronous signals let's look at a simple example first we need to get a scheduler from somewhere this could be a thread pool a tasking system a gpu driver etc to start a chain of work on thater we call schedule which returns a sender that sender will complete complete on the execution context associated with the scheduler next we use a sender algorithm then to compose work onto the sender that we got from the scheduler this work will be performed on that same execution context the sender algorithm will return a new sender which we can use used to add more work onto the chain finally we wait until the chain of work has completed using syn weight which will return the value sent by the final sender in the chain the pipe syntax gives us a clean way to compose chains of senders in the order that they will be evaluated now let me show you some of the most important sender algorithms sender adapters are a type of sender algorithm that take one or more senders as parameters and return a sender most sender adapters are pipeable just like range adapters the semantics are similar to unix shells languages like tasco and apl call this pointf free style the primary input argument is not explicitly named then takes an invocable f and calls it with the values sent by the prior sender the sender returned from then will send the results of the invocation of f this is how you attach a continuation to a sender bulk is similar to then it evaluates the invocable once for every index in the shape n in the simplest and most common case the indices are one dimensional and start at zero and the shape argument is an integer indicating how many invocations to perform the sender returned from bulk will pass along the signal from the prior sender transfer changes the scheduler that will be used for the next sender it doesn't change the scheduler for the prior sender some senders can only be connected to a single receiver for example because they move any values or error they send instead of copying them we call these oneshot senders senders that can be connected multiple times are called multi-shot senders split takes any type of sender and returns a multi-shot sender that passes along the signal from the original sender split senders represent forks in a sender task graph conversely win all takes multiple input senters and returns a single aggregate sender that will send signals from all of the inputs senders returned by winall do not have a scheduler associated with them which means they do not promise where they complete win all senders represent joins in a sender task graph win all is not a pipeable sender as the partially applied piped form would be ambiguous with the fully applied non- piped form ensure started connects and starts a sender returning a new sender that will pass the signal sent by the original if the input sender is a composition containing other senders those senders will be connected and started as well sender factories are another type of sender algorithm they do not take senders as parameters but they do return a sender sender factories are used to start new chains and graphs the senders they return are the root nodes we've already seen one sender factory schedule which returns a sender that completes on the specified scheduler the return send doesn't send values or represent any actual work it's just a handle you can use to compose work on the schuler just is another sender factory it takes a set of values and produces a sender that will send those values immediately when connected the last kind of sender algorithms are sender consumers they take senders but do not return senders they typically launch a sender graph by connecting and starting it they are the leaf nodes of sender graphs syn we is a sender consumer and synchronization primitive that blocks until a sender completes and then returns or throws whatever was sent we've developed a prototype of senders that supports cpu schedulers gpu schedulers and distributed schedulers this simple electromagnetic wave simulation solves maxwell's equations on a uniform grid this is the entire solver loop which is expressed as a graph of senders this code can be run with a variety of different schedulers by changing just one line of code the kind ofer passed to the solver we can go from running in line on a single cpu thread to running in parallel on the cpu using open and p to a single gpu to multiple gpus within a single node and to multiple nodes scaling up to thousands of gpus we've ported a simulation from the plos fluid dynamics framework two senders this simulation models carbon sequestration techniques the poorest structure you see is sandstone saturated in saltwater the red bubbles are liquid co2 which is injected at the bottom and travels through the sandstone because of buoyancy for ources using a distributed gpu schuler we've run this application on up to 512 gpus with standard c++ senders you can change one line of code and scale from a single cpu thread up to an entire cluster of gpus let's look at an example from the networking world in asing synchronous read of an array of data of unknown length we'll use this dynamic buffer type to store the data we read in a unique pointer as well as the size our async read array function will return a sender which sends a dynamic buffer it will take a handle to whatever network library we're working with we'll start our center chain by introducing a new dynamic buffer object with just next we use a let value sender adapter to create a scope that will keep the buffer alive for as long as we need it now the first thing we'll need to do is figure out how big the array will be we'll expect that sender will send a size t that contains the size of the rest of the data we'll need to read that first so we get a span to the size member of the dynamic buffer then we call async read a sender adapter that expects a s span and reads into it async re will send the number of bytes red we'll add a then which will do three things first we make sure that we read the number of bytes that we expected a size t's worth next we will allocate that many bytes in the unique pointer finally we return the span to that storage now we're ready to do a second async read which will read the actual data after that read we have a second then which will confirm that we read the number of bytes that we expected and with that we're done now let's look at another example generic asynchronous and parallel inclusive scan it'll take three parameters a sender which will expect to send the input as a range an initial value and the number of tiles to split the input into we're going to use the classic two pass parallel scan approach which requires temporary storage for partial results communicated between tiles we need to allocate this temporary storage asynchronously once the prior sender has sent us the input so we'll chain a then sender onto the prior sender in the body of that then we'll create a vector to hold the partial results we return both the input range and the vector next we need to do the first parallel pass the down sweep we'll use bulk to invoke the body of the pass for each of the tiles the first thing we do for each tile is calculate the range of elements that belong to the tile then we take all of the elements in each tile and perform a local serial inclusive scan on them which we do right here next we need to propagate information between the tiles the sum of each tile needs to be added to the elements of all subsequent tiles we've already computed that sum it's the last element of the local inclusive scan we store that result into the partials vector assignments to partials from different tiles may happen concurrently but that's fine each tile uses a different and unique slot in partials and no one reads from partials yet so there's no data race here then after all the tiles have completed their local inclusive scans in written to partials we need to have one execution agent do a serial inclusive scan of partials we do this by piping another then sender onto the chain which will perform the partials inclusive scan can this then sender will again pass along the input sequence and the partials vector the result of the scan over partials looks like this the information that each tile needs to add to its elements is in the partial slot for the tile directly preceding it now we need to go parallel again to distribute that information within all tiles this is the up sweep path so we'll pipe another bulk once again over all tiles in the body of this bulk we'll need to calculate which elements belong to the current tile just as we did before in the down sweep pass then we'll use a serial for each to increment each element in the tile by the appropriate value from the partials vector after that addition we'll have the correct result finally we want the sender returned by our asynchronous inclusive scan to only send the input sequence not the partials vector so we add a final then sender which only passes along the input the partials vector which we no longer need will be destroyed when this then center completes and that's it we're done we've got a generic asynchronous and parallel inclusive scan that we can run on any scheduler we want reflection pattern matching and senders i believe these are the three most exciting c++ features that we're working on combined they'll radically improve how we express ourselves in c++ and allow us to elegantly solve problems that are challenging today finally i'd like to thank everyone who's worked on the features that i've discussed in this talk or otherwise helped me prepare this material thank you for your time and attention feel free to contact me if you want to learn more about or get involved in the development of c++ you can also check out my other talks on youtube and my podcast adsp