the nasa space project advanced the technological progress of the human race by leaps and bounds examples of these revolutionary developments abound but one extra special item was in its computer the apollo guidance computer or agc was one of the first to use silicon-based integrated circuits their adoption heralded a revolutionary technology about to make a titanic impact on the world and the beginning of silicon valley as we know it i try not to make videos about america because it gets me yelled at but i really like this topic in this video we're going to look at how the silicon integrated circuit supercharged the agc and guided us literally to the moon but first i want to talk a little bit about the asian geometry patreon i'll make a quick early access members get to see new videos and selected references for them before they are released to the public it's not a lot of money and i appreciate the support thanks and all with the show when president kennedy challenged america to put a man on the moon and bring him back safely that part matters in 1962 the united states had about 15 minutes total experience putting humans into space there were many unknowns nasa had to solve but one of the biggest was navigation how to guide the spacecraft so that it can travel 400 000 kilometers through space and then properly enter orbit 110 kilometers above the surface of the moon the velocity has to be just right miss it by a few percentage points too low and apollo hits the moon a few percentage points too high and apollo swings into an erratic orbit that they cannot exit to illustrate the enormity of the task the pioneer 4 space probe had been launched just a few years prior to jfk speech with the intention of taking radiation measurements of the moon pioneer 4 traveled fast enough to exit earth orbit but a small timing error in the rocket booster stage swung the little probe too far out and ended up missing the moon by about 27 000 kilometers too far to trigger its photoelectric sensor but hey 27 kilometers is no biggie right in august 1961 nasa handed out its first contract for the future lunar mission that contract went to the instrumentation lab at the massachusetts institute of technology or mit for a guidance and navigation system the instrumentation lab would eventually be named the draper lab in 1970 and was spun off from mit in 1973 due to protests regarding their weapons work the lab came up with a system based on their previous work for the polaris ballistic missile which was fired out of a submarine their system is best described as an inertial system a self-contained system with a basketball sized sensor with three gyroscopes at its heart gyroscope technology would greatly advance during this time the system would also use a general purpose computer to calculate the craft's position orientation and velocity periodically the astronaut would take star readings using a sextant and feed their observations into the computer and to measure drift astronauts would find a known star center the ship's optics towards it and press a button the computer does the rest this approach was controversial the astronauts were former pilots so they wanted to control their spacecraft just like a military aircraft mission control for their part wanted to guide apollo themselves from the ground luckily mit ended up getting their way but their solution would require a general purpose computer one that can be relied upon thousands of miles away from the earth determining how to achieve this led to a lot of heated debate other options existed for achieving reliability when apollo lifted off the apollo guidance computer wasn't the only computer on board another less sophisticated digital computer was located further down inside the saturn v rocket the saturn's launch vehicle digital computer had no user interface but nevertheless fulfilled a critical task it provided the rocket's guidance and navigation functions sending commands to the engines to direct their thrust this rocket computer did not use integrated circuits its supplier ibm knew that the technology existed but determined that it was not mature enough for the task they opted to stick with more traditional transistor technology rockets are known to be volatile high temperature environments subject to occasional high rates of acceleration to ensure nasa's standards for reliability ibm built something they called tmr which stands for too much reliability just kidding it really meant triple modular redundancy here ibm stuffed three identical versions of the launch computer's major circuits then they added a voting circuit that selected the majority output in case one of them failed the triple modular redundancy method worked perfectly and the saturn v guidance computers never failed during operation not even during that one time in november 1969 when lightning struck the saturn v after liftoff and wiped out the apollo command module's electronics so the method had its supporters nasa had engaged a branch of at t for technical consulting and those guys recommended that ibm supply the guidance computer but mit wanted to go another approach the guidance computer needed to be more flexible more generalized it had to accept inputs from people and other instruments to achieve this while meeting nasa's required reliability goals they turned to an emerging electronics technology let us pause a little bit and recount some brief history from tubes to transistors to integrated circuits for a long time computers depended on the vacuum tube except vacuum tubes suck they are unreliable power hungry and extremely fragile so when the first transistor was invented in 1947 people hailed it as a vacuum tube replacement for low power compact situations packaged into individual discrete items you can plug them in to amplify electrical signals or switch them on or off but early germanium-based transistors had their own problems manufacturers had trouble producing these and mass furthermore they were unreliable breaking when shook or exposed to extreme temperatures and had to be connected together by hand more on the second part later despite these shortcomings the industry and particularly the military saw that transistors had a lot of potential in 1953 ibm debuted their first transistorized digital calculator the ibm 608 armed with 3 000 germanium transistors the computer was 50 smaller than its predecessor and impressively it used 90 percent less electricity eventually transistors replaced vacuum tubes in the electronics industry spurred on by manufacturing improvements that reduced cost and improved reliability in the mid-1950s the united states military started work on its next big intercontinental ballistic missile or icbm the minuteman the minuteman was a deterrence weapon designed to provide the united states with second strike capability so if the soviet union were to ever nuke the usa a nuclear response would be guaranteed with a fast reaction time minuteman needed to be on constant alert with the ability to fire with less than an hour's notice previous missiles had bigger bombs but miniman compensated for that with a more accurate guidance system that guidance system like apollo's was inertial in 1958 the us military chose north american aviation's autonetics division as one of the prime contractors for this guidance system for their transistors autonetics in turn turn to texas instruments and a small semiconductor manufacturing startup in mountain view california fairchild semiconductor to meet autonetics strict reliability requirements fairchild put their silicon-based transistors into centrifuges and subjected them to both hot and cold temperatures by 1960 the us military had bought more transistors for its missiles than its space programs 52 million dollars to 33 million dollars these early tests combined with the military's buying power allowed fairchild to hone their techniques and later evolve their transistor business into something bigger the integrated circuit takes the transistor idea another step forward remember what i said earlier about connections transistors are great but then you have to manually connect them together often by soldering a circuit is only as reliable as its weakest link so manual errors in connecting them caused short circuits and failure modes the reason why an integrated circuit performs so much better than its predecessors is that it is made of a single crystal of silicon now you can make millions of transistors resistors and capacitors the elements of a circuit and cram them together without worrying about the human manual effort element you get immense economies of scale and escalating performance famously jack kilby of texas instruments first invented the integrated circuit in 1958 he shared the physics nobel prize for it in 2000 but his integrated circuit invention wasn't commercially viable the circuit's individual elements transistor resistors and so on were made of silicon but they were connected with individual gold wire and like i said before a circuit is only as good as its weakest link then in 1959 one of fairchild's founders developed what is called the planar process silicon reacts with the air to create a layer of silicon dioxide this layer had previously been a manufacturing nuisance and the layer was frequently removed but fairchild learned to turn this nuisance into a benefit that layer of silicon dioxide protected the transistors from the outside environment making them far more durable during manufacturing you can cut holes into that layer to insert necessary elements combined with the use of photolithography to deposit wires of aluminium for connection fairchild managed to put many circuit elements and their connections onto a single piece of silicon a monolithic integrated circuit texas instruments first invented the integrated circuit but fairchild made it commercially viable so the lawyers of the two companies cross-licensed their methods fairchild's processes soon dominated the industry integrated circuits started making an impact on the industry as soon as they were invented if only because of the reliability and performance advantages in 1962 the united states military started the minuteman 2 project a follow-up icbm which required an even more powerful guidance system and computer for this reason autonetics chose to use integrated circuits for their design with texas instruments and westinghouse as the main suppliers ti developed over two dozen ic designs for the minuteman ii by 1965 they would be supplying over 15 000 circuits a week for the missile project demonstrations of the minuteman ii guidance computer found that it performed dramatically better than the minuteman one and word spread throughout the military that word eventually reached the mit lab and nasa apollo mission engineers knew about integrated circuits because they were at the cutting edge of electronics development forty percent of their boosted rocket budget seventy percent of their spacecraft budget and 90 percent of its tracking slash data budget was spent on electronic components mit had ordered a few integrated circuit samples from texas instruments in 1959 and 1960 basically soon after invention in order to study their potential then in 1961 fairchild announced their micrologic product line selling them to government and commercial clients at about 120 dollars each or about 1 200 today not an outrageous price at the time mit ordered a few micrologic products and found that they showed a lot of promise the product performed computational operations like multiplication addition and branch logic over twice as fast compared to standard transistor parts furthermore the new computer would be two-thirds the size and weight and it would be cheaper too reducing the number of unique logic modules inside the computer from 34 to just one you benefit from economies of scale but incorporating integrated circuits would require a radical and thoughtful redesign with integrated circuits you're doing away with pre-packaged components you have to plan out everything the chip has to do before it goes to fabrication and there was only one supplier of micrologic circuits at the time fairchild which is never a good situation a fair child failed to deliver then they were up a creek other suppliers were eventually found but procurement would be a persistent pain fortunately the nasa program had the flexibility and open-mindedness to be receptive to innovative solutions in 1962 the mit lab engineers received permission to rebuild the guidance computer based on integrated circuits this first iteration of the guidance computer would eventually be referred to as the block 1. it was built with 4 100 integrated circuits but all of them the same circuit type this was done for reliability and the aforementioned procurement reasons despite this decision the big question remained is this thing going to work can a computer based on integrated circuits be relied upon it sparked a great deal of debate as i mentioned before at t had recommended that nasa use the triple modular redundancy approach for their guidance computer in their view it was very likely that the computer would experience some kind of failure during its trip to the moon can the astronauts repair the computer in space so nasa contracted ibm to study the apollo requirements and see whether they could be able to adapt the saturn v launch computer to serve as the apollo guidance computer ibm was like yeah totally mit engineers knew otherwise of course their computer worked 10 to 20 times faster and was more flexible furthermore its position and velocity computational outputs were more accurate than the saturn computers by a factor of five they managed to fend off the notion nevertheless other parties joined the chorus grumman aircraft was building the lunar module they thought the guidance computer wouldn't make it and proposed that nasa built a fully separate and redundant backup for landing grumman brought political pressure into the deal minnesota politician joseph carth wrote a letter to nasa administrator james webb the guy they named a telescope after in the letter he wrote there has always been apprehension about the mit guidance system achieving the required reliability to ensure a safe mission is there documented test proven data to show that it will meet the needs of apollo lem he then asked about the backup guidance system like twice in their reply nasa mentioned that the apollo mission carried two guidance computers and that they can always receive commands from houston in the end the mit lab made its final decision in wake of a near disaster in may 1963 electronics for several critical systems in the mercury atlas 9 the last american solo orbital flight failed near the end of the flight pilot gordon cooper like a boss took manual control re-entered the atmosphere and safely brought the flight back to earth later on engineers determined that acids floating around in the zero-g environment entered the electronic system and ruined them when the mercury incident occurred mit engineers were in the midst of bringing out the next version of the guidance computer the block 2. this version would be the one used for all of apollo's manned missions block 2 showed all the benefits of moore's law it had more integrated circuits from its predecessor over 5500 compared to block one's 4100 yet it was smaller reducing its total footprint and cutting 17 pounds off the weight the 14 block 1 prototype computers had been very reliable having accumulated over 38 000 hours of operating time as of 1965. when properly made and sealed they worked mit thus decided that the best way to address the reliability issue was to seal it off from the outside environment astronauts wouldn't be able to fix the computer if it failed mid-flight but those seals would protect it from outside damage nasa did build one final backup computer the abort guidance system it was a general purpose computer supplied by a second group of suppliers trw with integrated circuits from fair child competitor signetics the abort guidance system was originally built just in case but it was never needed and probably shouldn't have been built later in 1975 nasa reflected that their resources probably would have been better spent reinforcing the reliability of the primary system rather than creating entirely separate backup systems it has been said that apollo and the minuteman 2 projects helped fund or kick off the integrated circuit era i probably wouldn't go that far nasa chose ics because they were faster smaller and eventually proved to be as reliable as anything made before but in 1962 at about 20 to 30 dollars apiece they weren't cheaper than the incumbent technology of discrete circuits nasa and the military were fine paying these prices and they certainly helped the companies involved but the commercial customers hadn't yet signed on in 1961 fairchild sold less than five thousand micrologic pieces texas instruments likewise was forced to cut pricing from 435 dollars to just 76 90 days after launch the industry didn't take off until 1964 when robert noyce and fairchild decided to sell their ic products at below cost betting that they would make it up with scaling efficiencies fairchild was right of course the year before the price cut the industry sold 2.5 million ics in total after the cut just one of fairchild's orders would be for 500 000 ics 20 of that a year later in 1965 the same year gordon moore makes moore's law computer maker burroughs buys 20 million integrated circuits by 1966 the whole industry knew that ics were the future so i would argue that apollo didn't kickstart the silicon revolution rather they tapped it and rode that rocket all the way to the moon all right everyone thanks for watching subscribe to the channel sign up for the newsletter and i'll see you guys next time