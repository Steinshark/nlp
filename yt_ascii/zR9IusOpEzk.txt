machine learning has been in the news a lot lately some of the early hype has died down but the trend still lives on and now it has really started to make waves in the chip design world machine learning and ai in chip design is such a sprawling field that i started to lose myself in all the research so i figured to just go into a recent breakthrough in the chip design field floor planning google has been applying the same ai prowess that allowed them to badly beat the best gold masters to this obscure but important subcategory of the field and the recent paper in the field by and i'm going to butcher this name azalea mirhosini and anna goldie illustrated their success with this approach tactec potato already did a video mentioning this it was a great piece go check it out for my take i will try to avoid treading old ground and go a little bit deeper feel free to scream at me in the comments if i fail but first let me talk a little bit about the asian arbitrator newsletter if you subscribe to the channel you should also sign up for the newsletter read the full scripts to older videos with additional commentary after the fact you can find the link to the newsletter in the video description below or you can just go to asianormatry.com as of right now you can expect a new newsletter every thursday 1am taiwan time all right let's get to it i recommend that you go through my earlier piece on eda software what it is and how it helps with the overall chip design process floor planning is the first major step in physical design if you recall from our discussion about how chips are designed the physical design stage comes after the logic design stage after the logic designer finishes their work the chip is a cluster of groupings of logic and memory circuits connected together with wires this grouping is referred to as a netlist in modern chip design additional abstractions are introduced tens of millions of logic gates are grouped together into things called standard cells thousands of memory blocks are grouped together into things called macro blocks the physical designer's job is to put all those onto the chip canvas and then wire them up with tens of kilometers of wiring tens of kilometers of wiring on a chip the size of a fingernail modern technology is amazing the goal of floor planning is to place and arrange the blocks and super blocks in a way that best meets all the requirements without any overlaps moving blocks around sounds literally like child's play right one of the big goals is to minimize the amount of white space which is any space in the floor plan uncovered by a block in addition to this the floor planning chip designer needs to keep in mind a bundle of other factors one is that in modern vlsi design the area and size and shape of the chip's floor plan tends to be fixed in other words someone else has already decided that the chip cannot be larger than this or that size this is often the case for a mobile phone where the smaller the chip is the more battery can be stuffed in the side another consideration is wire placement the chip component should be placed and the wires between them should be connected in a way that minimizes latency power consumption and heat intel has run studies and found that 51 of a microprocessor's power is consumed when driving signals through its interconnects traditional eda tools are not really equipped for this they are more qualified to position millions of small cells within specified parameters floor planning presents the opposite problem placing large blocks with little information about the chip's future parameters it is like trying to figure out where to place all the doors hallways wall sockets water connections and windows in a house but without yet knowing where the rooms are and how they will be used oh and the house has over 10 million rooms the possibilities get simply mind-boggling if go is a whole level more complicated than chess then chip floor planning is yet another level higher the mir hosseini and goldie paper says that chess has 10 to the 23rd power number of states go 10 to the 360 power chip floor planning up to 10 to the 9000 power every time tsmc or samsung debuts a new leading edge node the netlists get even larger and the problem gets even harder currently chip designers tackled the issue with a variety of approaches one of the most popular is called simulated annealing simulated annealing uses an objective equation to calculate a particular floor plan's cost this cost is usually based on a few objective input factors usually how long the wires are and how large the area size is by turning the floor plan into an equation a computer can now iteratively or greedily as they say search for a globally optimal solution kind of like how your graphing calculator tries to solve an equation back in math class there are a few flaws with simulated annealing for one thing the program might get stuck at a local optimum close to where it started its search the program thus airs in declaring victory too early unaware that an even better global optimum lies just over the hill thus sometimes we might ask the algorithm to modify its behavior when going up or down the hills of the cost curve these hill climbing methods help the algorithm to escape these local optimums in search of the best solution the sheer number of placement possibilities leads to very long search times even if the cost function is by itself not all that difficult to run as a result designers have introduced very creative tweaks to the approach one tweak would be to use compacted floor plans where no modules can move left or right this allows the floor plan to be represented as an ordered binary tree of nodes then we can use a computer to try to optimize each node's x and y coordinates in relation to the root node pretty creative i have to say there's more than one way to skin a cat before we close here are two other methods the analytical method and partitioning the analytical method uses an objective mathematical formula and a set of constraints to try and calculate the smallest possible floor plan it is like trying to solve for one of those algebra equations you get in school and partitioning attempts to overcome the larger problem by breaking it into smaller circuits you take passes and in each pass you divide the canvas into smaller sets optimizing all the way down and so on i am not really satisfied with any of these explanations but this is not an electrical engineering course the reality is that none of these are by themselves a silver bullet in the end designers do this semi-manually with a potpourri of methods that best fit their circumstances and constraints as well as a healthy dose of human intuition no one uses just one thing since it takes so long to test and iterate it becomes a real drag on chip team productivity and iteration speed if we had years to develop and release a new chip design then this would not be a game breaker but designs exist so the whole thing is ripe for trying a new approach and that is where machine learning comes into the picture so what is the big deal about machine learning and ai i'll take a pause to briefly explain it the word ai means nothing now a broad blanket term kind of like the cloud many things have ai video game characters and vacuum machines for instance machine learning however does mean something very specific and is not necessarily interchangeable with ai scientists have been developing ai since the 1950s however those approaches centered on the concept of symbolic ai symbolic ai assumes that human knowledge can be approximated using large amounts of handwritten rules and sets this had its successes but as it turned out researchers underestimated how much implicit knowledge we humans all share about the world and ourselves basic things like if president biden is in washington then his left foot is also in washington common sense essentially machine learning is a new ai approach dedicated to overcoming this problem enabled by recent advancements in gpu processing power rather than having humans write the rules let data do it neural networks are one implementation of the concept you feed the neural network some data the network's results are compared against pre-labeled results the difference between the two is called the error the goal is to minimize the error without overfitting to the data depending on the results tweaks are made and the whole thing is retrained or re-tested sometimes you're going to get some weird results and in those situations you might have to make extensive tweaks to the entire process but when done right well-trained networks can indeed work uncannily well the google team approached this problem like as if it were a game and it kind of is like go there is a board the chip canvas and varying pieces to place on that board your netlist blocks there are even wind conditions though these depend on the relative importance of the various floor plan evaluation metrics the goal thus would be to train a neural network capable of dynamically helping the chip designer with their floor planning efforts in other words help them win the game so if you look at how alphago works a trained neural network helps the player identify the best moves and the winning percentages of those moves the player can decide whether or not to actually place the stone making the network a tool my best guess is that google's ai floor planner acts similarly though i cannot quite find an explanation in the paper of how the actual tool works but it does go over how they created the tool first the team set the broad parameters of the chip netlist metadata process technology node for instance these are fed into the neural network the neural network is then trained this is done by showing it many episodes of state actions and rewards the computer is shown a chip canvas a state it then places a series of macro blocks which if you recall from earlier are the aggregations of memory blocks onto the chip canvas the actions the standard cells or logic circuits are then placed with a standard eda tool the final canvas is then evaluated for its reward reward being negatively correlated to wire length congestion and density these are standard measures of a floor plan's favor the reward information is then provided back to the network for future training over time the network has shown enough episodes of the state plus action plus reward cycle that it can look at any chip canvas and know where to set its macros so to maximize the final reward the final results are interesting in some ways the neural network performs as well as a human most notably it can do the job much faster during the design phase of google's latest tpu chip a human expert would have had to iterate for months on the floor plan with the latest eda tools he took the netlist code manually placed the blocks and then brewed coffee for 72 hours while the eda evaluated a floor plan iteration with this slow iteration cycle a tpu v4 floor plan took about six to eight weeks for a human to do but the ml floor planner with its trained ability to look far ahead on the proverbial chessboard was able to do it in just 24 hours the paper emphasized the speed and indeed the speed gains are quite great and have significant worth but the paper sometimes also said that it was better and for that i am not quite sure yes on occasion the ml floor planner did better but the human also did better on other occasions and then sometimes the industry standard eda tool had them both beat for the most part on all metrics other than speed the three methodologies were very close usually within two to five percent range and i think that is something to consider when it comes to this stuff machine learning is not superhuman magic it is based on data created or curated by humans and that generally means it will perform about as well as them apple is probably the best chip designer out of the american tech giants but google is taking rapid strides in developing their own chip proficiency strategically they seem to have recognized that having their own hardware is critical to achieving superior cost and performance thresholds they first began showing this in their databases and now in their consumer hardware the paper notes that the new neural network has already been applied to the chip design process of its latest google tensor processing unit tpu they have also started to bulk up their hiring presence in taiwan so we should expect to see a lot more out of google in the chip space going forward one last thing if machine learning can help place macroblocks onto a chip canvas much faster than a human can then there are many other possible use cases for this type of skill these include hardware design city planning and vaccine planning and distribution the possibilities are very intriguing i look forward to seeing this technology appear in more use cases in the future alright that's it for tonight thanks for watching if you enjoyed the video consider subscribing you will get to watch a lot of other videos on this channel that fits your interest want to send me an email drop me a line at john asinometry.com i love reading your emails introduce yourself suggest a topic or more until next time i'll see you guys later