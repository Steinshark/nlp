in this video we're going to be learning about the lru cache provided by funk tools and lru stands for least recently used so this is the least recently used cache and all it does is memorize a callable not memorize but memoize which means you save the result of a certain function call so that the next time you do that exact same function call with the same arguments you will already have the result there so you just have to grab the result if you already made that function call once all it's doing is caching the result from a function call that you already performed so this can lead to a huge performance boost in your program and i put 100 times in the title but it can be indefinitely faster than that anyway let's get started with an example which i ripped right from the python documentation and this is a function that counts the vowels from any given sentence which will be of type string and of course it should return to us an integer of the amount of vowels inside a sentence and the implementation is going to look like this it's going to return the sum for the sentence dot count with the vowel inserted for the vowel in in this string which contains all the vowels so right now if we were to use this function on something such as hello world and we were to run that we would get three as a return and if we were to use this several times on the same string we would get the same result back each time the only problem with this approach is that each time we use this function we're performing a fresh calculation which can easily consume our resources very quickly i know this is a very basic example but a good place to see this in action is with fibonacci or some other intense calculations we do not want to perform the same calculation over and over for something that we already computed once so let's take a look at how we can optimize this by caching the result and to do so we're going to use lru cache which has two optional arguments one is the max size which by default is set to 128 and the second one is typed and i'll explain what type does in just a moment but for now we're just going to insert max size with the default just to show you that that is the default and with typed set to false which is also the default so you can exclude these if you want but i just want to show you that these exist next we're going to create a function that will time how long it takes to execute this function one million times so what i'm going to use here is this main function and inside this main function i have a variable called sentences which contains a list of type string and it contains these three sentences now for each sentence in these sentences i'm going to use this function 1 million times with that given sentence so we're actually performing three million function calls but thanks to lru cache we're only going to be using this function three times the rest of the times we're just going to immediately return the result but let's also measure the time it takes to execute the main function and i've created a helper method the implementation is not important all it does is use the default performance counter to calculate the start time and the end time and then we get the difference and that's going to give us the total time it took to execute this function and this is actually a decorator so to measure it i'm just going to add this decorator but next inside our if name is equal to main check we can just run the main function to see how long it actually took to execute this code and if we were to run that we're going to get 122 milliseconds back if we run it again we're always going to get a result that's quite similar to that time frame but let's see what happens if we were to exclude the lru cache so if we were to comment that out and we were to rerun the script you'll see that it's going to take significantly longer it took nearly three seconds to execute our script and that's because every single time we referred to count values or we called count values it performed a fresh new calculation which is a huge waste of resources especially if we have some values that we're calling over and over and over again the arguments remained the same for each function call so why should we even waste our time with performing a fresh calculation and the answer is we shouldn't we should just return the pre-computed result but let's go back up and here i'm just going to uncomment that because i want to show you a few methods that you can use with lru cache or actually functions that use lru cache to either clear the cache or to get information regarding the cache so one that's quite important is cash info so right here we can print our account values function which uses the lru cache decorator and we can type in dot cache underscore info and if we run this now we're going to get some information regarding the cache for that particular function the first one tells us how many times we were able to use the cache so for 2999 997 times we were able to use the cached result and mrs refers to the amount of times we had to perform the fresh calculation so we only computed our values three times which makes sense because each time we inserted a new argument such as hello world or i don't know must be a king or we are three wise men these are all new arguments to our function call so we of course had to perform a fresh calculation but with the rest of the times we could use the cached result and then we have max size which refers to the total cache size so the amount of results we want to save and then we have the current size which refers to how many results we have currently cached in our cache so cache info gives us a lot of good information regarding our current cache state also in case your cache is getting too big or you don't want to keep it anymore you can use another method that comes with lru cache and that is the cash underscore clear method so we're going to call that and then i'm just going to copy the line from above and paste it directly under and if we run that now you'll see that the first cache info is going to contain a valid cache with all the information and once we clear it we can effectively see that our cache has been cleared so it's not going to contain the hits anymore or the misses or the current size because now the cache has been cleared but there are still a few questions such as what does typed do what is the point of typed well theoretically let's pretend you have a function called add and it takes a number as an argument so maybe 10. if you have typed set to true it's going to consider 10 and 10.0 as different types so those will end up being considered as distinct calls with distinct caches instead of just having one cache for that result also another thing to mention is that since lru cache uses a dictionary to store the results the keyword arguments and the positional arguments must be hashable and on top of that if you have a function that takes keyword arguments if you were to pass in a keyword argument of a with 10 and b with let's say 20 the order of these can lead to distinct caches so if you were to place b in front of a this can be considered a complete different call than the previous one even if the arguments are exactly the same anyway let's take a look at one more example using the fibonacci sequence because that's a good place to show you the massive power of lru cache so let's get rid of everything here and everything inside main for now because we will just replace that with the fibonacci sequence and i'm also going to remove this part here so the next function which i stole from the python documentation is going to be this fibonacci sequence and this time we're going to have max size set to none and all that means is that we do not have a cash limit which means it can easily exceed 128 results anyway going back to our fibonacci function as a lot of you probably know by now if you put a high number into this function it's going to take ages to load if we do not cache the result and actually this time i'm going to save the cache for later because i want to show you how much faster it is when we actually use the lru cache so in our main function we're still measuring everything as normal and i'm going to say fibonacci with the value of 25. something small for now and we can actually test this out by running it and that's going to take 12.18 milliseconds and it might also be cool to print the result so i'll go here and type in result of type integer it's going to equal fibonacci of 25 and we will print the result so we can actually see that something happened so if we run that we're going to get this result from our fibonacci sequence if we put something in such as 28 it's going to take a bit longer if we increase that to 40 it's going to even take longer and i don't know how long that's actually going to take maybe it will take 30 seconds maybe it'll take a minute i'm actually just going to stop the program now because it's taking far too long so let's change that maybe down to something such as 30. and that took 100 milliseconds anyway the point is that we are performing the same operation far too many times in our fibonacci function which also means that we're performing a lot of expensive operations for no reason but now let's try to catch the results and see what happens when we run our script you'll see that the execution is practically instant it only took .03 milliseconds to perform this exact same calculation and we can actually change that to 40. and it's not going to affect our performance at all because we're effectively catching the results instead of making a fresh calculation for each function call we can even set that to 200 and it only took 8 milliseconds it took almost no time to perform that calculation and i'm not even going to show you what happens if i remove lru cache for a number such as 200 in fibonacci i don't have the time for that i'm going to be an old man by the time it returns a result even if i'm performing this on a powerful computer and something more interesting might actually be the cache info that we get back for the fibonacci sequence so if we were to just place that under here and we were to run our script you'll see some of the information regarding our fibonacci sequence we performed a fresh calculation 198 times we used a cash result 201 times we have no max size which means the cache can be as big as it wants while the current size is set to 201 so that gave us back a lot of good information regarding the cache info for our fibonacci function anyway that just about covers everything i wanted to talk about in this video i am going to leave the link to the documentation for this function or for the lru cache in the description box down below so you can take a closer look at it if you want to take some notes or if you want to find out some more particular details regarding its usage you can find it in that link otherwise with all that being said as always thanks for watching and i'll see you in the next video