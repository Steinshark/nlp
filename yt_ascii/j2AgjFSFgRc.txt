hi welcome everybody i'm matthias yes what's that and i'm yeah working in the area of block-free programming and concurrency for mainly for autonomous driving in robotics and today i want to show you some techniques that may prove helpful if you yeah want to tackle similar problems and the cornerstone for all of this is complete exchange and i hope it will serve you as well as it does me so let's take a look at how talk will be structured first of all we have a brief introduction what what we consider real-time systems and what kind of yeah what log-free programming actually is before we move to looking at log-free programming specifically in c plus plus then we move on to take a look at atomic and so on before we look at some kind of case study where we explore a lot of issues that kind of cure if you are not careful in the free programming the location study is a so-called exchange buffer or i call it like this and we will see what it does and we will encounter various problems there on the way mainly the aba problem which we will solve and yeah this is the concludes the talk and then i hope i have convinced you that it actually makes sense to use something like this in real time systems so that that's the main goal to enable you to use those kind of tricks in real-time systems or otherwise and you could also talk a course's talk just a journey of log-free programming in c plus plus okay what are real-time systems real-time systems are systems yeah which of course perform certain tasks one algorithms those tasks are often often have priorities and and deadlines can be chaotic it doesn't happen you don't have to be periodic and we have something like a real-time operating system usually which guarantees that threats are scheduled in some kind of way but they cannot guarantee that the algorithm the user runs complete on time can only guarantee some kind of fairness with with regard that every threat gets an opportunity to do something and that's very important because this can help us to guarantee or to at least allow us to be able to meet deadlines and yeah have system by progress in the sense of distributed systems we distinguish between hard and soft real-time systems hardware intense system means well if you do not need deadlines it's a failure and that's usually hard because it's hard to come by those kind of execution or time bounds for the execution of one time of algorithms and you have hardware effects like caching large prediction you have a very hard time to predict how much time your algorithm will take in the worst case and so that's usually infeasible but there's also software return systems where meetings deadline not meeting the deadlines is okay but it degrades performance and it should not happen too often and it also should not exceed the deadlines by too much which which is yeah not too much lateness so but how much failure we can tolerate depends of course on on the application we are mainly concerned here with soft real-time systems because hardware time systems are fairly infeasible as i said to my knowledge of course in modern systems we really want to use concurrency because we then get more performance you can scale our systems further and yeah by using background sweats you can have increased responsiveness and so on but if we do this we immediately face the problem that we have to synchronize access to shared data and how do we do this usually usually we use synchronization primitives like mutex semaphore condition variable and so on but this leads also to problems like all those primitives are at the heart blocking which means if they block for too long this can lead to lockouts meaning some kind of processor wants the resource the mutex for example but cannot get it because another one has it and may even lead to deadlocks but this is more more or less a programming error or because of it well the results of a failure but it can in any case even if there's no programming error you can have priority inversion which means some high priority switch wants to acquire a resource but it cannot run because a low priority threat which may have been put to sleep by the operating system is holding the resource end so now the high priority set also has to wait for for no real reason so and there are other things like starvation and contact switches between sweats are of course expensive and so on so we want to use concurrency but we also want some kind of well those real-time guarantees are really at least as good as we can okay how can we achieve this well i would propose that log-free programming may help us here but in a nutshell not block-free programming the algorithms cannot use blocking primitives like i showed before it's not entirely correct well that is correct but it's also not actually actually the definition but this has a lot of advantages we cannot have deadlocks anymore because there's no logging we have some certain robustness against failures and lockouts and so on so in a nutshell we can guarantee progress meaning doing something useful of at least one threat and regardless of what other threats do they cannot interfere negatively and most importantly we cannot have this kind of priority inversion and also what it's not always true we may hope for less context switches however if we do this and there are also disadvantages so nothing is for free right synchronizing data access becomes harder the algorithms to do this become more complex and in the end it does not even have to be faster than log-based algorithms but they can so that's and we cannot eliminate starvation entirely but starvation may be reduced if you have some kind of fair operating system scheduling there are also some step up from this so-called weight-free algorithms but they are usually more of a theoretical theoretical importance because they yeah they guarantee more fairness but they are also slower usually okay so we want to do log free programming and of course that's the c plus plus confidence so we want to do this in c plus plus well i claim that log free programming is supposed to help but how do we write those kind of log free algorithms if you just have to use or if you just have those mutexes and so on on our disposal that does not do us much good right we need something something else so i would say we need some some more friends yeah okay and what would those friends be well first of all we need to think about the basic building block is using atomics they are they exist since in c plus in c plus plus 11. the basic idea is we can atomically access data and even log free if the data is small because if a data you store an atomic is large and the compiler may introduce hidden locks for you you do not want this of course there's much to know about atomics for example very important the memory model which somehow controls in which order different processors can or will see memory operations like stores and so on but unfortunately this is the topic entirely of its own in the scope of this talk but we do not need to think about it that much at this point at least and for our yeah purposes it suffices that we think that think of well we use sequentially consistent memory order but that's that's enough for us meaning that each pros in a nutshell each processor sees memory operations roughly in a similar way each other any other processor but this in turn requires heavy synchronization under the hood so they are more relaxed and more performant modes but we will not consider them in this talk okay the basic operations on atomics are just reads and writes or loads in stores it's called for atomics and there are more complicated operations which also modify the data as it says they read something they they modify it and they write and something and for example you can just consider having some atomic x type integer store 73 of course and if you load it again assuming no other sweat does something and if you load it again you will of course see this value you just stored you can call something like called fetch act which is a leak modified operation where you get the value before and increment the current value so the result should be 74 but we get back the old value which is 77. we can for example exchange the existing value again with something different like 37 in this case and the old value we would get back is 74. and yeah there are other operators like just increment yeah in some ways they behave like the native types you could say which we would increase this value to 38. all this happens atomically but they have not covered the most important operation or the most powerful operation you could say and that is compare exchange or compare and swap individual literature it exists as complex change strong in c plus plus and the basic idea is we have some kind of we have some kind of current value in in this atomic axis atomic from the previous slide and we want to exchange it under certain conditions with the desired value but in the certain the condition is it is still the value we expect so we have some expected value and we exchange it oh this is a bit bad i should maybe set this expected value to something so of course the chord will work regardless but i don't know what i expect here so anyway we it works or it does not work meaning we get if if the exchange worked we get true otherwise you get false so we could think of the semantics as being like this if you have to model this using no atomic we could model it like this you have to have some kind of value we have a mutex to get our you know to guarantee the atomicity of the operation basically and then it works like this the semantics as i said and we we get an expected value of the new value oh this should not have been reference and somewhat constant anyway we get a new value and we we compare it with the current value if it's equal we set the current value to the new value and return true otherwise we just reload the ex so the value that's important that in the failure case we somehow load the current value into expected and that's kind of that's important maybe a bit unintuitive but it's for efficiency reasons because the yeah the hardware already does this for us and so we do not have to reload it again and but we returned false because the exchange failed the condition was not true there's also a weak version we are not too much concerned about this and this sweet version can fail even if the condition is true that can usually be sometimes it's if it exists or the weak version always exists but it may do the same thing as a strong version but it may be actually a different hardware operation which is usually has a better performance but as i said it can seriously fail again this is not of course done with locks usually for small data no there are special hardware instructions for example a lot compare exchange on x 86 and this one is a major building block of all or almost all log free algorithms as we will also see so let's have a quick look at what we can actually do with compare exchange so the main use usage is often just some kind of looping i would call it the compare exchange or compared swap loop and let's see how this works it's a yeah it's a small example like we want to create a fetch multiply function which behaves similarly to fetch at this function does not exist in hardware but we can create it on our own with compute exchange and would work somewhere like this the parameters are a bit different here right because we pass the atomic but of course we can could also do this with some kind of some kind of member function and if we have our own atomic and so on but it's not important and we can be past the atomic by reference and we pass some multiplier it's of course only for the in case but we could generalize this to other types as well which support multiplication and the basic pattern is this we somehow load the current value that's called the old value because it may already be outdated if something is going on concurrently below this old value and then we perform our local computer local computation on this value in this case just multiply the old value with the multiplier and then we try to exchange the old value or the the actual value with our computed result but only if the old value did not change meaning nothing else happened in between basically it's not not entirely correct as you can see but the value for our purposes the value stay the same and then the this is consistent in some way we can yeah we would expect this kind of behavior and if this is exchange works we break and basically return the old value as fetch ad would also do otherwise we just retry it and it could be in theory an infinite loop right so meaning starvation would be possible but you can imagine that this is fairly unlikely because we always have to somehow lose the exchange and this will only happen if other threats somehow are always faster than vr okay so that's the first major trick or basic usage of computer exchange to create operations let's move on to something more complicated and potentially more useful and this is this will be our exchange buffer yeah some some motivating words right the problem to exchange data between sweats i would think it's fairly natural well it appears very often maybe not the most interesting problem depending but it appears very often in multi-sided programming and the and the basic requirement is that we can exchange types and almost arbitrary types as generic as we can can handle and also we would like to have an arbitrary number of concurrent readers and writers it should also be allowed that writing to this buffer somehow fails under certain circumstances but those should be well-defined and what we will introduce to solve this problem is our log3 exchange button it's useful yes but but it will just be able to hold one value at a time so it's a bit limited but this can be generalized but it just gets more complicated but i hope we can again you can see that the techniques that can can be used to generalize these queues and other structures for now you can think of it like some kind of limited atomic which can it has some limited operations not all equations within atomic but it can do it not for only for small values but for general generic values and not freeway which is not true for a regular atomic meaning if it gets a large compiler as i said may introduce lockstep which we not just do not see okay what would this exchange buffer like look like from the interface i propose certain functions we want to implement a write function a try write function and a take and a leak function okay writing means just that i want to write data into the buffer i provide the data and i just get back indication whether it worked or not and performing boom it may not work but only because i'm somehow out of memory in a certain sense another operation is tribrid which may fail if the buffer already contains data can be useful so then the it may fail data if it contains data or if it is out of memory as well so that can also happen here and then we have means to access the data in the buffer and there we distinguish between taking data which is some kind of a destructive operation because it destroys the data on the buffer the data is now it's a yeah it's caller side or we have a read function which just which beats the data and the data is still in the buffer for both we use to return it we return the value we use optional because we may return nothing if the buffer currently doesn't contain a value it's fairly natural i think any i favor those kind of functional like constructs like optional and so on but this is of course a design choice can be done differently as well okay and all of this of course have to be has to be log-free and types must be team and should be as general as we can handle and we do of course not want some kind of torn read we will see what the tournament is later meaning we need some kind of garbage which is not even the buffer okay so let's let's start implementing this we'll start with a very simple implementation where we just consider writing and taking the data we have several assumptions which are listed on the right but the main point is we restore not an atomic to the data but to the pointer to the data because pointers are small they are you know 64-bit systems they are and that can be handled with lovely atomics okay so that's basically how our class or our first attempt looks like and how would we handle the right writing well we get the value we try to copy the value using invoking a copy constructor if we get something back meaning we have memory and we had to get no nothing back we had no memory and then we failed here it should be unlikely but can happen [music] otherwise we just exchange the newly created value this is this copy of the you know sources with the with the old value by calling just exchange no compare exchange yet it's it's better because it's good because this is in less expensive operation we get the old value back and if we actually got something we are responsible for deleting it because at some point we would have created it by writing it previously and or if you get got nothing back you have nothing to do in all cases then we the operation succeeds and we require true so that's simple now the opposite side taking the data it works like a similarly you just exchange whatever's there with the null pointer and if you got something back you can move the data out into your optional then you have to delete whatever remains in the and now the actual data is now in the option we are about to return we'll return the actual data or we got nothing back and then we have to return not meaning nothing okay it looks good but yeah it looks also simple unfortunately it's wrong or is it it's not not not and how is it wrong well it's not lock free why is it not lock free because we are using we are using new and delete which means we are invoking some kind of allocator and we cannot expect this allocator to be log-free in all cases usually it it will not be it will be threat safe yes but not long free so we could not we would violate our log free constraint for structure well that's unfortunate so but but the message is we cannot use those memory allocators in general unless we really know they are not free but then we could and then it would be that simple for taking at least writing and taking okay we have to do something about this and what we do is we take matters in our own hand and that means we need to consider managing our own memory and of course we want to do the structure and i will sketch some kind of simplistic log-free memory manager that can be done much more sophisticated but we can build something from there okay first of all first of all we will have some lock free storage which means it is more or less just an abstraction around some la which can hold types t so you can consider it like some kind of memory pool for objects of type t and it has certain operations i will not show how they are implemented but they're easy enough to implement so like storing some value at a certain slot i will talk about slots in this storage or freeing the value in a certain slot meaning calling the copy as a destructor we make heavy use of emplacement new under the hood but it's also not too important or i get the corresponding pointer to some index so we we are now moving to work on the for the outside interface to work with indices which has certain advantages as we can see and also for example access the data at some index just with a bracket operator okay that's one part that's we are separating the storage and the logic to to work with the storage okay that's that's the storage itself or data effects it's easy enough to implement so we skip this and then we have something which i call just the log free index pool which manages indices which can be used to access the storage and the the main idea is to access a certain slot of the storage we have to process the index and each slot is either free or used initially they are all free and well we have of course a constructor and you can do certain things like getting an index maybe getting the index because there may be no free index left and then we get nothing again we make use of optional or the opposite operation if we are done with using a slot we will just return the index so because kind of of course we think of malloc and free but for those kind of indices and there's no actual allocations all that everything we need is pre-allocated which also has certain advantages and all we need to do internally is manage some kind of array of slots of atomic slots which we manipulate but also this yeah you can hopefully imagine how this works but and it will also again provide a link where you can find this but again here's it's most important to just consider that we have such a magic interface we will use it and another advantage of indices we have soon see why these advantages is they are smaller than pointers and not 64 bit in this case they will be 32-bit but of course depending on how much slots we need we could make this even smaller so we prepare these things over pointers from those kinds of operations okay what does this help us with our initial problem that our memory allocation [music] we cannot use the memory allocation okay or how does it work so you can imagine that it works like this first of all you have this index initially everything is free nothing is stored then you write something at index zero okay you write an a there you have to obtain the index now it's used you write something else and b and then it's also used you write you write something you have to see now it looks like this and after you're done this doing whatever you want with which with this be you delete it or you free it and then you get yeah you are you arrive at this situation and again only this is only allowed if you have ownership of this index meaning we own the corresponding memory slot now how does this help us with our problem okay now we move on to creating and well to repairing our exchange buffer observe that we now have some kind of parameter c which controls how many slots we have in the buffer and the buffer in this in the storage i mentioned before and we will now we have something like we have the storage on the one hand the storage and the inlet case to to access the storage and what we also have is some kind of indicator that we have no data which is now [music] yeah it's this one we have some indicator just think about it as some kind of logical null pointer and what we now have instead of our point atomic pointer before we have an atomic index and initially it was well before it was initially a null pointer now it's initially no data value indicating buffer is empty then again we have our interface and and that's that's about it we also have some kind of helper function the helper function is just for freeing whatever is in some index meaning recall this as i mentioned this will call the destructor of the value and maybe do something else in the storage shift if needed but it should not be really needed and then it will return the indica or the corresponding index back to the index pool to be and meaning that the slot is ready to be reused we will we we will maybe see that the c also controls how much concurrent access we can have to the buffer for successful concurrent access we may have as many contacts as we want but some of the operations may may fail and would not if we would have a larger value of c okay so the memory is managed by by the storage linux pool and we will see how it works okay so now we implement our right operation and how does it work we try to obtain an index and yeah we may be successful or maybe not successful again it's a similar tool to failing because of the other out of memory before now we can maybe have more slots left because other writers are occupying them and also trying to buy that's what i meant is to see controlling somewhat degree of concurrent access but if we get an index remember this is an optional then we can of course get its actual value then we just call our helper function which just stores the value we intend to write at a it's a corresponding slot in our storage so this happens here and after this we just exchange the current index to and and we obtain this with our new one so we get the old index back and if there was if there was any data in it we are responsible now to free it similarly to calling delete before we are responsible to free it otherwise you can just return so we return we are successful in any case and we could also do other things like instead of freeing the value we could imagine that we return the value back to the caller to do whatever you want with it but this is of course a bit more expensive and i would propose to have an extra operation for this this would be writing and now the opposite operation taking the tape taking the data it looks similar right and we just have now we have we have to to exchange we we have to to exchange whatever is there with with no data as opposed to the note point that we did before and if we get ah sorry if we get something well if you get nothing we well there was nothing in the buffer and we returned nothing that's okay otherwise there was something in the buffer and again we move it to the optional 3.3 but with remains and return the optional we cannot really avoid this move or copy if we want to have some kind of value semantics where we not just give a pointer to the caller and we especially with our new self-managed memory we do not want this because we want to reuse the buffer slot as soon as we can so that's taking and remember well it's important to to to think about the order of what happens if we first because the destructor and then returns the index because as soon as we return the index it's available to concurrently be reused and so the order is important otherwise you get nasty bugs well you certainly don't want to start to debug i encountered them okay we can also write drive right now that's almost the same but now we will actually need compare exchange because again we get we get the index and we write or if we get the index we write something in the storage or whatever we have the value we have [music] but then with tri-void we actually expect to have nothing in the index and we have to communicate this somehow and we do this this compare exchange here we expect that there's no data and we try to exchange no data with whatever we wrote before if this succeeds there was no data and we returned through otherwise there was data and our operation failed but before we return faults we have to free what we allocated because otherwise we have occupied this slot and we will run out of memory and that's bad of course so and we are allowed or the semantics of try white are we we are allowed to fail in in this case so because we just want to invite to an mp buffer so let's try right out of the way awesome i think fairly nice and how does this work can imagine it works somewhere like this now we have also the index pool we have the storage and we have the current value of our atomic initially it's no data of course and now we write the u where we obtain the index 0 we write something to the storage so we write due to the storage and the sprite completes we write v so we and after white writing of v is completed we of course have yeah removed u from and and just use this new index and now the index is one now we can consider that some kind of take operation occurs and then of course everything is free again and we arrive at no data again and we are back back where we were before and now consider that for example simultaneously or concurrently we have writing of x and y and one of the operations will complete first and let's assume that it's it's bright and why and then the situation would look like this x is already written to the storage but the operation is not complete and that is also an important point because the operation you could say the operation becomes observable for other threats as soon as the compare exchange succeeds and that's the case for why that so at this point it becomes observable and if you consider that that writing x will also succeed a bit later and then it will put switch then we would have x to be the the content of the buffer and zero of the index anyway so that's hopefully illustrating how how this kind of fighting here works and how yeah yeah at the moment compare exchange was only important for for try right remember but yeah we have not faced the real challenge right it all looks fairly very nice but the real challenge is is actually read taking data it looks rather simple because compare exchange or change are like made for it we transfer the ownership but what if we now want to read the data without taking it that's much harder without locking like in mutex but let's try it anyway so we try first let's see what what happens if we if we just do it naively [music] well let's think about we load the current index if there's nothing okay then it's fair enough to return nothing otherwise there was something we just copy it to our optional doing so and return the value we could do this but that has a very very bad bug right right it's wrong because we cannot really we have to assume that that concurrently someone may change the value in in certain ways by calling the right operation or the take operation and and then bad things will happen there are many possible outcomes but one outcome is of course we read the correct value which we which we want but other outcomes are we are reading the value while it's being manipulated which leads to a turn point read or we could even crash because the update is not complete and you may think of what happens if we have a stood list and some pointers are being manipulated in the stood list and or the operator object is about to be deleted or the constructor is running or already was deleted and the access is all kind of bad things happen specifically undefined behavior so we need to be aware of the data that can change concurrently we cannot just simply read it just like this [music] first thing to mitigate some of the problems is to to restrict our data type to be trivially copyable meaning that our copy is essentially a mem copy and then we at least do not have some kind of unpredictable questions of course it's a it's a it's a very very strong restriction of the data type we use but it's still a useful and it's still useful so we cannot have questions but the data can still be concurrently modified and well if we have not solved our problems like this we for now from now on we assume that we have a trivial recoverability okay now let's let's use computer exchange again to to try to check whether the data changes in the meantime so let's have a look well what can we do we can just we can just call we can we can read the data now in the loop if if there's no if there's no data we just return as before otherwise we'll re-read it and immediately after we're done with reading we recall compare exchange with well both arguments are the same which means we check whether whether the index is currently or has not changed and if it did not change we assume that nothing happened in between and our readers failed it so that's yeah otherwise we have to try again it looks promising unfortunately it's also not quite correct because we now have a new problem called the aba problem and in the nutshell it means the index value may have changed back and forth where we are reading and of course equal indices do not necessarily imply that the values are still equal or or were equal even if they are equal afterwards they may have not been equal between those operations so we need something smarter or how would this look like well consider that that the situation is like this and you want to read it and the readers yeah this is the situation and the read is interrupted here you write something now you have this in the buffer two x's then you write again something you have two y's in the buffer now the same slot you were initially reading and then the read completes but the me it changed the content of cell of the slot one changed from to use to two whites and now we could have read for example we could have read the old w okay we could have where two y's that's probably what we want but but we also could have a torn read we read some kind of weird mixture of of the data which was never in the buffer at all and that's the aba problem and the a b and a are on the indices here right from we change from one to zero to back to one when we are now checking again with the complex change and lead complete means to compare is successful okay so we have to solve this problem somehow and but how do we do this this is fairly hard and we need an idea is we could try to to count whenever we write a value let's see and we need something which is the aba account i really like this guy when i was a kid so he has to be counting stuff right so do we okay now it looks a bit overwhelming but actually it isn't because what we now do is we we introduce an attacked an extended version of our of our index which contains not just the index but this counter this is this ada counter right and there's a concept like pointer tagging and so i called it also tagged index where you in the pointer taking you you just use some not non-used otherwise not use bits to indicate certain states and this is actually exactly what we are doing here as well and because we are adding to the index some counter and the code is initially zero and we can also check that this data structure that's important is not too large to be used in a compare exchange operation with this silica third here it's available from c plus 17 onwards so otherwise the definitions are the same and now let's take a look at how this helps us the idea is always when we modify meaning writing and also taking but right something to the buffer we want to increment the counter as well and so we can detect concurrent changes compare exchange now we have in our instead of the index you have the stacked index in the atomic and compare exchange will work on both it will only compare to equal if both did not change index and counter that's that's the basic idea okay so writing the initial phase is the same as before maybe we get an index now we have to do some some tricks with the stacked index to get this into the text index and we have to store again our value before we move on to [music] to do the compact change loop and the idea is just well we take the old counter we have it because we have loaded the value and to set the news and the index is is frozen to the to the value we want to index we want to satellite depending on what index we got from the pool but the counter is set to to whatever was in the in this the counter before so now we plus one plus one so we want to increase it by one and we try the compare exchange and again if this did not fail and we we got we got data every there was data and we had to free it and then it is successful otherwise we just retry and so on so that's that's writing with an aba counter and it remember the the exchange operation only succeeds if the counter and the index are not changed so and the idea is that the leader can now use this to detect it taking the data is also similar as before you can't think of taking the data like writing nothing to the buffer and instead of returning whatever is there so again we have to load what what is there now we have to use comparexchange we increment the counter we try our exchange and if it succeeded we know that there was something in the buffer otherwise we would not have would not have arrived here in this comparative change in the first place to this loop condition and then we just free the internal value so calling destructor basically and return what was in the buffer otherwise copy exchange fade and that can mean either the counter changed in between or yeah the buffer got empty and then we just stopped this looping and now now we are in the position that we can read with the aba counter and the read code essentially did not even change at all the autos would our two values would have sometimes now have tech indices but that's about all and we can use the same code as before and now it actually works because now the compare exchange considers the counter as well so yeah that's essentially it consider that the corresponding concurrent rights are happening the counter changes concurrent takes are happening the content changes as well and if some mixture of those happens the counter also changes and so the compare exchange will fail if anything happens in between there's also some topic of discount i've wrapped around we will not consider this it's really unlikely but yeah we can mitigate this as well but we kind of cannot go there today okay we can use those monotony content to detect concurrent changes that is quite important and now we have solved the aba problem in our case up to this web around this course which i was talking about so if the picture now looks like this we are from 1 to zero to one again but the counter increases as well and so the only possible lead result we can have is two wise and you can have no possible no tolerance anymore and that's well and now we have implemented our complete interface there remains some kind of things like if you are you could say well you are using optional and optional as you may know will allocate dynamic memory so we are for the same reason we had initially it's not entire log free but this can be resolved by replacing the optional with something using no dynamic memory that's possible and of course we have the requirement on our type that t must also the copy constructor cannot use locks or something it must be lock free but we all we already moved to trivia copy the keys and so it uses mam copy and then copies for free the basic message is the function can only be look free if all functional functions it calls are also lovely so i think that's that's very clear well we have another restriction which i not actually like but i think we cannot really easily get around this with this construction that that we have to use trivially copy of the types of course we only have to do this if you want to use to be able to read if you want a restriction of this buffer you just want to write and take you do not have to do all this also not do this with a counter and so on and type can be more general but if you want to read can we drop this restriction the answer is yes but we have to solve a much more complicated problem which is called safe memory reclamation of course you have to sort it in locally way and there are ways to do this but that's not not that reason but those hazard pointers and and the idea is we need to somehow keep track of of the users of our memory before we allow other concurrent operations to reuse the memory and which this boils down to implementing a free garbage collection and our friend and helper here will be as well compare exchange so there's there's not really a way around this compare exchange is very powerful and yeah but implementing this is of course scorpio we have also initially i talked about memory order in our examples it was all it was all sequentially consistent by default usually you can relax it somewhat in many cases acquire release is enough but i would strongly advise that we only optimize the memory order once the algorithm that he is working because there's nothing no way that the algorithm will work and we will work with with a weaker memory order if it does not even work with a stronger one it's nothing short of familiar because people like to kind of yeah measuring probably wrong for me it is your both services so first going to write this sequentially consistent order and then move on to to tweak the memory order to something more and that is beneficial because sequentially consistent is very expensive if you can get away with weaker memory orders that's nice okay what does all this help us in real time systems to sum it up as i said we avoid deadlocks and priority inversion and also at least consider consider you have no competing swifts and at least one sweat will make progress because they are no they are not blocked they may only fail if another update and let's just compare exchange failed this that is but it's that's not blocking that is starvation and individual straight sets may start right and but you can even do something about starvation we can sketch some ideas here like we could we could and add some kind of timeouts in our operation of course we cannot interrupt our operation at any time that's a bit asking too much but we could after a failure look whether we exceed some data and if so we could return so with some kind of error indicator other other combination criteria are conceivable as well of course and you can't you can even to improve the fairness because as i said if many sweats are running and doing compare exchanges sometimes theoretically one may start and to reduce the chances of this happening you can introduce some some semi-random sleeps and and more sophisticated methods and where you arrive essentially making your algorithm in a way wait for you but you pay for it you pay for it and everything gets slowed down by this additional logic and sleeps it gets more fair yes but it also gets slowed down so it's still it's useful for real-time systems i would argue what depends on your use case you may be able to i think it it's it's fairly clear that we can try to generalize this and to produce stacks caches and and so on because the exchange buffer is is just any of these structures with some kind of capacity one but then we have we encounter more problems like yeah how many concurrent readers should allow concurrent writers and what is the size of internal buffer we need to deal with things like the read and write position in the buffer or consider what should happen if this container overflows and we may even encounter a problem which i would have liked to present how we can update multiple locations atomically without corrupting the structure that's that's fairly neat but a bit more advanced technique yeah many new problems arrive interesting problems i think yeah and we yeah i'm involved in developing this isolex zero copy middleware and there we actually use the ideal copy means we transfer memory efficiently and there we between between processes in this case so we have and and there we use actually log-free cues and not this exchange button but look for queues which is a step up from this and also have lock feature memory management and you can use this in high safety applications you can it's it's very fast and so it's suitable for real-time systems and for example it also comes from with some utility library and this for example contains this optional without using dynamic memory so we could solve for our remaining problem with this as well so that's i would argue with some kind of real-time application i can't consider others as well where you can use those techniques but yeah finally yeah i said algorithms are getting more complex testing algorithms is generally hard it's harder if its concurrency is involved because sweats can interleave in many ways and it's even harder if it's concurrent and lock free because you do not actually even have some kind of guarantees with critical sections where you can say okay only one thread can be here at this time and so on so that's that's harder to argue you cannot do this well i have no recipe to guarantee correctness i would like to hear one but i don't have one and but what would you do if you develop those algorithms well you need to define the algorithm properly or what you want from your algorithm then you devise algorithm theoretically then you can prove the correctness even zero improvements for this like because check out tla plus and things like that and you can implement it in cps plus or otherwise review the code hopefully by experts so people know what they are doing because it gets complicated or clicky fast yeah you need unit tests then you need stress tests and finally you need to instrument or you may consider instrumenting the code i do not quite like this but it's it's an option and yeah you know there are other tools like verification with cpp mem for small snippets but in general you can only disprove correctness with those kind of methods but still it increases your confidence in the correctness okay so i'm running out of time i think but now we have our we have hopefully seen that our new friend compare exchange allows us to yeah do interesting things and to implement algorithms and especially for data exchange but there's many more things and well the key observation we have already seen so but remember there are disadvantages it's rather expensive but lock locks with contentions as well but more they consider the complicated algorithms more of a disadvantage it can be subtly broken maybe what i showed you is even it's also something i'm not aware of this but i cannot pull it out and they are hard to test and to finalize all this you have to keep in mind that comparexchange is a very powerful operation and it's so because it solves the so-called distributed consensus problem and you can use this kind of theoretically decide to practically make synchronize access to any concurrent object so that's a very general method there are very general results and we cannot implement all those things in c plus plus as well okay that about sums it up you can read more and more about for example how it's used in isolex and you kind of look at the queues there here you can find this exchange buffer there so it's not not entirely cleaned up but the implementation and some tests are there and also a bit yeah code pieces which shows this kind of concurrently updating multiple locations and i highly recommend reading this book here and because i learned a lot about practical emojis writing there and so there are not many books about concurrency in cps plus so with with that being said thanks for your attention and if there are any questions i'm of course happy to answer them and i strongly encourage you to devise your own lock-free algorithms and finally i have to really thank my colleagues bob and so on which may not know him but he's also involved in the library's project which which i had a very useful discussions for this talk and he pointed out many many small issues in the code and yeah and also my brother okay i also showed the code thank you so okay thank you matthias i think we are really running out of time yeah i mean the the most wanted question was about the the testing how how is it tested but i think that was that was a lot focused on the last pages so i would guess it would be the best to have a discussion on the on the table on the launch table so that you can interact with each other and so please be at the table and then you can directly speak with matthias so thank you again very nice presentation and we'll see at the table you're welcome bye