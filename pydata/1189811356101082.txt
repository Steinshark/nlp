import torch 
import chess
import chess.engine 
import numpy 
import json 
import os 
import random 
import time 
import copy 
import multiprocessing
import sys 
sys.path.append("C:/gitrepos") 
from steinpy.ml.networks import ChessDataset,ChessModel
from torch.utils.data import DataLoader

chess_moves 		= chess_moves 		= json.loads(open(os.path.join("C:/gitrepos/steinpy/ml/res/chessmoves.txt"),"r").read())
move_to_index		= {chess.Move.from_uci(uci):i for i,uci in enumerate(chess_moves)}


def run_game(id,t_limit=.1,r_move=.5,depth=12):
	exps 	= []
	engine 	= chess.engine.SimpleEngine.popen_uci("C:/gitrepos/stockfish/stockfish-windows-x86-64.exe")
	board 	= chess.Board()
	depths 	= [] 
	times	= []
	mate_val= 1_000_000
	while not board.is_game_over():
		
		#Engine analysis
		t0 			= time.time()
		engine_res 	= engine.analyse(board,limit=chess.engine.Limit(depth=depth))
		score 		= engine_res['score'].white().score()
		best_move 	= engine_res['pv'][0]
		if score is None:
			if "-" in str(engine_res['score'].white().mate()):
				score = -mate_val 
			else:
				score = mate_val
		depths.append(engine_res['depth'])
		times.append(time.time()-t0)
		#print(f"ID: {id}  time: {sum(times)/len(times):.2f}s")
		
		#Save exps 
		exps.append((board.fen(),score))

		if random.random() < r_move:
			#Push move 
			board.push(best_move)
		else:
			board.push(random.choice(list(board.legal_moves)))
	
	#print(f"adding {len(exps)}\tavg. depth was {sum(depths)/len(depths):.2f}\tavg. time was {sum(times)/len(times):.2f}s")
	engine.close()
	return exps


def run_game_for_compare(id,r_move=.5,depth=12):
	exps 	= []
	engine 	= chess.engine.SimpleEngine.popen_uci("C:/gitrepos/stockfish/stockfish-windows-x86-64.exe")
	board 	= chess.Board()
	depths 	= [] 
	times	= []
	mate_val= 1_000_000
	while not board.is_game_over():
		
		#Engine analysis
		t0 			= time.time()
		engine_res 	= engine.analyse(board,limit=chess.engine.Limit(depth=depth))
		best_move 	= engine_res['pv'][0]
		score 		= engine_res['score'].white().score()
		if score is None:
			if "-" in str(engine_res['score'].white().mate()):
				score = -mate_val 
			else:
				score = mate_val
		depths.append(engine_res['depth'])
		times.append(time.time()-t0)
		#print(f"ID: {id}  time: {sum(times)/len(times):.2f}s")
		
		#Save exps 
		exps.append((board.fen(),score,best_move.uci()))

		if random.random() < r_move:
			#Push move 
			board.push(best_move)
		else:
			board.push(random.choice(list(board.legal_moves)))
	
	#print(f"adding {len(exps)}\tavg. depth was {sum(depths)/len(depths):.2f}\tavg. time was {sum(times)/len(times):.2f}s")
	return exps



def build_dataset(n_samples=8192,t_limit=.04,n_threads=8):

	experiences 	= []

	while len(experiences) < n_samples:

		with multiprocessing.Pool(n_threads) as pool:
			print(f"running {n_threads} threads for {n_threads} games")
			exps 	= pool.map(run_game_for_compare,list(range(n_threads)))
		pool.close()
		for ex in exps:
			experiences += ex
		
		print(f"sized to {len(experiences)}\n",flush=True)
	return experiences


def load_data(n_batches=3,test_data_range=[2,6,10,24,43]):
	path 			= r"c:/data/chess/exps/"

	#Find no of samples 
	nums 			= [] 
	for file in os.listdir(path):
		nums.append(file)
	
	for forbidden in test_data_range:
		if forbidden in nums:
			nums.remove(forbidden)
	
	#Randomly select data
	chosen_i		= random.choices(nums,k=n_batches)

	state_list 		= []
	moves_list 		= [] 
	scores_list 	= [] 


	state_test 		= [] 
	moves_test 		= [] 
	scores_test 	= [] 

	for i in chosen_i:
		for tensor in torch.load(path +"\\" + f"states{i}"):
			state_list.append(tensor)
		for tensor in torch.load(path +"\\" + f"moves{i}"):
			moves_list.append(tensor)
		for tensor in torch.load(path +"\\" + f"scores{i}"):
			scores_list.append(tensor)
	
	for i in test_data_range:
		for tensor in torch.load(path +"\\" + f"states{i}"):
			state_test.append(tensor)
		for tensor in torch.load(path +"\\" + f"moves{i}"):
			moves_test.append(tensor)
		for tensor in torch.load(path +"\\" + f"scores{i}"):
			scores_test.append(tensor)

	states 			= torch.stack(state_list)
	moves 			= torch.stack(moves_list)
	scores 			= torch.stack(scores_list)

	states_test 	= torch.stack(state_test)
	moves_test 		= torch.stack(moves_test)
	scores_test 	= torch.stack(scores_test)

	return states,moves,scores,states_test,moves_test,scores_test


def train_on_data(model,states,moves,scores,states_test,moves_test,scores_test,bs=8,epochs=range(1)):
	
	dev 			= torch.device('cuda' if torch.cuda.is_available() else 'cpu')
	dataset 		= ChessDataset(list(zip(states,moves,scores)))
	datatest 		= ChessDataset(list(zip(states_test,moves_test,scores_test)))
	dataloader 		= DataLoader(dataset,bs,True)
	dataloadertest  = DataLoader(datatest,bs,False)


	prob_loss_fn	= torch.nn.CrossEntropyLoss()
	value_loss_fn	= torch.nn.MSELoss()
	
	losses 			= [] 
	test_loss		= [] 

	for epoch in epochs:
		t0 			= time.time()
		num_equals 	= 40 
		printed 	= 0
		num_batches = int(len(dataloader))
		print(f"\tEPOCH: {epoch}\t{len(dataloader)} BATCHES\tPROGRESS- [",end='')
		for i,batch in enumerate(dataloader):

			percent 	= i/len(dataloader)
			while (printed / num_equals) < percent:
				print("=",end='',flush=True)
				printed+=1
			
			#Zero Grad 
			for p in model.parameters():
				p.grad 		= None 

			#Load Data
			state 		= batch[0].float().to(dev)
			moves 		= torch.zeros(size=(state.shape[0],1968),dtype=torch.float,device=dev)
			for i,index in enumerate(batch[1]):
				moves[i,index.item()]	= 1 
			value 		= batch[2].float().to(dev)

			#Forward Pass and Error
			prob,val	= model.forward(state)

			loss_prob 	= prob_loss_fn(moves,prob) 	
			loss_val	= value_loss_fn(value,val)

			total_loss 	= torch.mean(loss_prob+loss_val)
			losses 		+= [total_loss.mean().item()/bs]
			total_loss.backward()

			#Step optimizer 
			model.optimizer.step()

			#Telemetry 
		
	with torch.no_grad():
		for i, batch in enumerate(dataloadertest):
			#Load Data
			state 		= batch[0].float().to(dev)
			moves 		= torch.zeros(size=(state.shape[0],1968),dtype=torch.float,device=dev)
			for i,index in enumerate(batch[1]):
				moves[i,index.item()]	= 1 
			value 		= batch[2].float().to(dev)

			#Forward Pass and Error
			prob,val	= model.forward(state)

			loss_prob 	= prob_loss_fn(moves,prob) 	
			loss_val	= value_loss_fn(value,val)

			total_loss 	= torch.mean(loss_prob+loss_val)
			test_loss 		+= [total_loss.mean().item()/bs]


		loss 	= f"{sum(test_loss)/len(test_loss):.3f}".rjust(20)
		print(f"]\tEpoch validation loss: {loss} in t: {(time.time()-t0):2f}s")

	return sum(test_loss)/len(test_loss)


def custom_loss(prediction,actual):
	with torch.no_grad():
		bad_mask 	= prediction.clone()*actual.clone() 
		bad_mask[bad_mask > 0] = 1
		bad_mask[bad_mask < 0] = 2 	

		#scale correct sign evals by .5
		good_mask 	= prediction.clone()*actual.clone() 
		good_mask[good_mask < 0] = 1
		good_mask[good_mask > 0] = .5

	return torch.sum(torch.nn.functional.mse_loss(prediction,actual) * good_mask * bad_mask)


def train_on_data2(model,trainset,testset,ep,bs,converter):

	train_dataset 	= DataLoader(ChessDataset(trainset),shuffle=True,batch_size=bs)
	test_dataset 	= DataLoader(ChessDataset(testset),shuffle=True,batch_size=bs)

	loss_fn 		= torch.nn.MSELoss()

 
	train_loss 		= []
	test_loss		= [] 
	for epoch in range(ep):
		t0 			= time.time()
		num_equals 	= 40 
		printed 	= 0
		num_batches = int(len(train_dataset))
		print(f"\tEPOCH: {epoch}\t{len(train_dataset)} BATCHES\tPROGRESS- [",end='')

		#TRAIN
		for i,batch in enumerate(train_dataset):
			percent 	= i/len(train_dataset)
			while (printed / num_equals) < percent:
				print("=",end='',flush=True)
				printed+=1
			
			#Zero Grad 
			for p in model.parameters():
				p.grad 		= None 

			#Load Data
			fens 			= list(batch[0]) 
			orientations 	= []  
			for fen in fens:
				orientations.append( 1 if fen.split(' ')[1] == "w" else -1)
			
			state 		= converter(fens,orientations).to(torch.device('cuda'))
			value 		= batch[1].float().to(torch.device('cuda')).unsqueeze(dim=1)	/ 10000
			#Forward Pass and Error
			pred 		= model.forward(state)

			#CUSTOM LOSS 

			loss 		= custom_loss(pred,value)

			#input(f"loss shape is {loss.shape}")
			#If both positive, 


			train_loss.append(loss.mean().item())
			loss.backward()

			#Step optimizer 
			model.optimizer.step()
			#print(f"train loss={losses[-1]}")

			#Telemetry 
		
		#TEST
		with torch.no_grad():
			for i, batch in enumerate(test_dataset):
				fens 			= list(batch[0]) 
				orientations 	= []  
				for fen in fens:
					orientations.append( 1 if fen.split(' ')[1] == "w" else -1)
				
				state 		= converter(fens,orientations).to(torch.device('cuda'))
				value 		= batch[1].float().to(torch.device('cuda')).unsqueeze(dim=1)	/ 10000

				#Forward Pass and Error
				pred 		= model.forward(state)
				loss 		= loss_fn(value,pred) 
				test_loss.append(loss.mean().item())	


			trainloss 	= f"{sum(train_loss)/len(train_loss):.3f}".rjust(20)
			testloss 	= f"{sum(test_loss)/len(test_loss):.3f}".rjust(20)
			print(f"]\tTrain loss: {trainloss}\tTest loss: {testloss} in t: {(time.time()-t0):2f}s")

	return test_loss


if __name__ == "__main__":

	# exps 	= []
	# for run_i in range(5):
	# 	engine 	= chess.engine.SimpleEngine.popen_uci("C:/gitrepos/stockfish/stockfish-windows-x86-64.exe")
	# 	for _ in range(1024):
	# 		exps += run_game_for_compare(engine,depth=13)

	# 		if _ % 10 == 0:
	# 			print(_)

	# 	#Save to file 
	# 	engine.close()
	# with open(f"baseline/moves-ds.txt",'w') as file:
	# 	file.write(json.dumps(random.choices(exps,k=131_072)))
	# exit()
	ds_size 		= 512
	ds_root 		= "C:/gitrepos/chess/stockfish_baseline/"
	for i in range(ds_size):
		i += 375
		exps 	= build_dataset(n_samples=8192,n_threads=12)
		save_loc 	= ds_root + f"{i}"
		with open(save_loc,"w") as file:
			file.write(json.dumps(exps))
		file.close()
	
	exit()

		#Save repr and score 
	train_data 			= [] 
	test_data 			= [] 
	
	all_data 			= list(range(int(sys.argv[1])))
	test_set 			= [x for x in [1,5,17,32,33,50,101,150,200,250,300,400,500] if x < int(sys.argv[1])]



	for i in all_data:
		if i in test_set:
			with open("C:/data/chess/exps/"+str(i),"r") as file:
				test_data += json.loads(file.read())
		else:
			with open("C:/data/chess/exps/"+str(i),"r") as file:
				train_data += json.loads(file.read())


	losses 			= {}

	models 			= {
		"ChessModel":	["red","darkorange","darkred","firebrick","maroon"],
		"ChessConvNet":	["dodgerblue","cyan","blue","mediumblue"]
		  				}
	
	for model_fn in [ChessModel]:
		for act_fn in [torch.nn.ReLU]:
			for converter in [fen_to_tensor_expanded]:
				for lr in [.0002]:
					for bs in [4096]:
						for n_conv in [16]:

							title 			= f"{str(converter).split(' ')[1]}_{n_conv}"
							print(f"begin {title}")


							model 			= model_fn(in_ch=6 if converter == fen_to_tensor2 else 7,n_convs=n_conv).to(torch.device('cuda'))
							model.optimizer	= torch.optim.Adam(params=model.parameters(),lr=lr,betas=(.75,.999),weight_decay=lr/10)

							losses[title] 	= train_on_data2(model,train_data,test_data,4,bs,converter)
							torch.save(model.state_dict(),f"{title}.model")
							print(f"saved")
	

	from matplotlib import pyplot as plt 

	for t in losses:
		plt.plot(losses[t],label=t)
	
	plt.legend()
	plt.show()
	open("losses","w").write(json.dumps(losses))
							