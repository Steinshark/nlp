
<!doctype html>
<html class="">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
		<meta name="description" content="Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science." />
		<meta property="fb:app_id" content="1321688464574422" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@huggingface" />
		<meta name="twitter:image" content="https://huggingface.co/front/thumbnails/docs/transformers.png" />
		<meta property="og:title" content="Performance and Scalability: How To Fit a Bigger Model and Train It Faster" />
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://huggingface.co/docs/transformers/v4.15.0/en/performance" />
		<meta property="og:image" content="https://huggingface.co/front/thumbnails/docs/transformers.png" />

		<link rel="stylesheet" href="/front/build/kube-0ad51e9/style.css" />

		<link rel="preconnect" href="https://fonts.gstatic.com" />
		<link
			href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&display=swap"
			rel="stylesheet"
		/>
		<link
			href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&display=swap"
			rel="stylesheet"
		/>

		<link
			rel="preload"
			href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"
			as="style"
			onload="this.onload=null;this.rel='stylesheet'"
		/>
		<noscript>
			<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" />
		</noscript>

		<link rel="canonical" href="https://huggingface.co/docs/transformers/v4.15.0/en/performance">
<link rel="alternate" hreflang="en" href="https://huggingface.co/docs/transformers/v4.15.0/en/performance">
<link rel="alternate" hreflang="x-default" href="https://huggingface.co/docs/transformers/v4.15.0/performance">  

		<title>Performance and Scalability: How To Fit a Bigger Model and Train It Faster</title>

		<script
			defer
			data-domain="huggingface.co"
			event-loggedIn="true"
			src="/js/script.pageview-props.js"
		></script>
		<script>
			window.plausible =
				window.plausible ||
				function () {
					(window.plausible.q = window.plausible.q || []).push(arguments);
				};
		</script>
		<script>
			window.hubConfig = {"features":{"signupDisabled":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https:\/\/huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","captchaDisabledOnSignup":false,"datasetViewerPublicUrl":"https:\/\/datasets-server.huggingface.co","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)","spacesIframeDomain":"hf.space","spacesApiUrl":"https:\/\/api.hf.space","docSearchKey":"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6","logoDev":{"apiUrl":"https:\/\/img.logo.dev\/","apiKey":"pk_UHS2HZOeRnaSOdDp7jbd5w"}};
		</script>
		<script type="text/javascript" src="https://de5282c3ca0c.edge.sdk.awswaf.com/de5282c3ca0c/526cf06acb0d/challenge.js" defer></script>
	</head>
	<body class="flex flex-col min-h-dvh bg-white dark:bg-gray-950 text-black DocBuilderPage">
		<div class="flex min-h-dvh flex-col">
	<div class="SVELTE_HYDRATER contents" data-target="MainHeader" data-props="{&quot;authLight&quot;:{&quot;csrfToken&quot;:&quot;eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzI5MTg2MjU3OTEsInVzZXJJZCI6IjY3MTQzN2FjOGI3YWZiNzcyNDg2ZGY0MCJ9LCJzaWduYXR1cmUiOiJmZGVhNjE2ZmI3ZTI3NWJhMzQyNjEyN2EyMjVhMjlkYTQwNzEwODFlYmIzNDFlY2MyZjdjY2JmMjM3MTFjY2E3In0=&quot;,&quot;hasHfLevelAccess&quot;:false,&quot;u&quot;:{&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/KQCTFGLy3xuBc7Q4SSGby.png&quot;,&quot;isPro&quot;:false,&quot;orgs&quot;:[],&quot;user&quot;:&quot;Steinshark&quot;,&quot;canPost&quot;:false,&quot;canHaveBilling&quot;:true,&quot;canCreateOrg&quot;:true,&quot;theme&quot;:&quot;light&quot;,&quot;notifications&quot;:{}}},&quot;classNames&quot;:&quot;&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/KQCTFGLy3xuBc7Q4SSGby.png&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false,&quot;user&quot;:&quot;Steinshark&quot;,&quot;unreadNotifications&quot;:0,&quot;csrf&quot;:&quot;eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzI5MTg2MjU3OTEsInVzZXJJZCI6IjY3MTQzN2FjOGI3YWZiNzcyNDg2ZGY0MCJ9LCJzaWduYXR1cmUiOiJmZGVhNjE2ZmI3ZTI3NWJhMzQyNjEyN2EyMjVhMjlkYTQwNzEwODFlYmIzNDFlY2MyZjdjY2JmMjM3MTFjY2E3In0=&quot;,&quot;canCreateOrg&quot;:true}"><header class="border-b border-gray-100 "><div class="w-full px-4  flex h-16 items-center"><div class="flex flex-1 items-center"><a class="mr-5 flex flex-none items-center lg:mr-6" href="/"><img alt="Hugging Face's logo" class="w-7 md:mr-2" src="/front/assets/huggingface_logo-noborder.svg">
				<span class="hidden whitespace-nowrap text-lg font-bold md:block">Hugging Face</span></a>
			<div class="relative flex-1 lg:max-w-sm mr-2 sm:mr-4 md:mr-3 xl:mr-6"><input autocomplete="off" class="w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl " name="" placeholder="Search models, datasets, users..."   spellcheck="false" type="text" value="">
	<svg class="absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
	</div>
			<div class="flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden"><button class="relative z-40 flex h-6 w-8 items-center justify-center" type="button"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-xl" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg>
		</button>

	</div></div>
		<nav aria-label="Main" class="ml-auto hidden lg:block"><ul class="flex items-center space-x-1.5 2xl:space-x-2"><li class="hover:text-indigo-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/models"><svg class="mr-1.5 text-gray-400 group-hover:text-indigo-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
					Models</a>
			</li><li class="hover:text-red-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/datasets"><svg class="mr-1.5 text-gray-400 group-hover:text-red-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
					Datasets</a>
			</li><li class="hover:text-blue-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/spaces"><svg class="mr-1.5 text-gray-400 group-hover:text-blue-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 25 25"><path opacity=".5" d="M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z" fill="currentColor"></path><path opacity=".75" fill-rule="evenodd" clip-rule="evenodd" d="M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z" fill="currentColor"></path><path opacity=".25" d="M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z" fill="currentColor"></path></svg>
					Spaces</a>
			</li><li class="hover:text-yellow-700 max-xl:hidden"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/posts"><svg class="mr-1.5 text-gray-400 group-hover:text-yellow-500 !text-yellow-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 12 12" preserveAspectRatio="xMidYMid meet"><path fill="currentColor" fill-rule="evenodd" d="M3.73 2.4A4.25 4.25 0 1 1 6 10.26H2.17l-.13-.02a.43.43 0 0 1-.3-.43l.01-.06a.43.43 0 0 1 .12-.22l.84-.84A4.26 4.26 0 0 1 3.73 2.4Z" clip-rule="evenodd"></path></svg>
					Posts</a>
			</li><li class="hover:text-yellow-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/docs"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="mr-1.5 text-gray-400 group-hover:text-yellow-500" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path opacity="0.5" d="M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z" fill="currentColor"></path><path d="M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z" fill="currentColor" fill-opacity="0.75"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z" fill="currentColor"></path><path opacity="0.5" d="M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z" fill="currentColor"></path></svg>
					Docs</a>
			</li><li class="hover:text-green-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/enterprise"><svg class="mr-1.5 text-gray-400 group-hover:text-green-500" xmlns="http://www.w3.org/2000/svg" fill="none" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 33 27"><path fill="currentColor" fill-rule="evenodd" d="M13.5.7a8.7 8.7 0 0 0-7.7 5.7L1 20.6c-1 3.1.9 5.7 4.1 5.7h15c3.3 0 6.8-2.6 7.8-5.7l4.6-14.2c1-3.1-.8-5.7-4-5.7h-15Zm1.1 5.7L9.8 20.3h9.8l1-3.1h-5.8l.8-2.5h4.8l1.1-3h-4.8l.8-2.3H23l1-3h-9.5Z" clip-rule="evenodd"></path></svg>
					Enterprise</a>
			</li>

		<li><a class="group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400" href="/pricing">Pricing
			</a></li>

		<li><div class="relative group">
	<button class="px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center " type="button">
		<svg class=" text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 18" preserveAspectRatio="xMidYMid meet"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z" fill="currentColor"></path></svg>
			
		</button>
	
	
	</div></li>
		<li><hr class="h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800"></li>
		<li><form action="/logout" method="POST" class="hidden"><input type="hidden" name="csrf" value="eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzI5MTg2MjU3OTEsInVzZXJJZCI6IjY3MTQzN2FjOGI3YWZiNzcyNDg2ZGY0MCJ9LCJzaWduYXR1cmUiOiJmZGVhNjE2ZmI3ZTI3NWJhMzQyNjEyN2EyMjVhMjlkYTQwNzEwODFlYmIzNDFlY2MyZjdjY2JmMjM3MTFjY2E3In0="></form>
<div class="relative ml-2 w-[1.38rem] h-[1.38rem] ">
	<button class="ml-auto rounded-full ring-2 group ring-indigo-400 focus:ring-blue-500 hover:ring-offset-1 focus:ring-offset-1 focus:outline-none outline-none dark:ring-offset-gray-950 " type="button">
		
		<div class="relative"><img alt="" class="h-[1.38rem] w-[1.38rem] overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/KQCTFGLy3xuBc7Q4SSGby.png" crossorigin="anonymous">
			</div>
	
		</button>
	
	
	</div></li></ul></nav></div></header></div>
	
	<div class="bg-gradient-to-b py-3 text-sm md:text-base from-yellow-50 to-yellow-100 dark:from-yellow-500 dark:to-yellow-600 dark:text-gray-950 "><div class="container"><form class="flex flex-col justify-between md:flex-row md:items-center" action="/organizations/suggestions/dismiss" method="POST"><input type="hidden" name="csrf" value="eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzI5MTg2MjU3OTEsInVzZXJJZCI6IjY3MTQzN2FjOGI3YWZiNzcyNDg2ZGY0MCJ9LCJzaWduYXR1cmUiOiJmZGVhNjE2ZmI3ZTI3NWJhMzQyNjEyN2EyMjVhMjlkYTQwNzEwODFlYmIzNDFlY2MyZjdjY2JmMjM3MTFjY2E3In0=">
				<div class="mb-2 md:mb-0">Hugging Face is way more fun with friends and colleagues! ðŸ¤—
					<a class="ml-2 underline" href="/organizations/suggestions">Join an organization </a></div>
				<button class="btn text-sm" type="submit">Dismiss this message</button></form></div></div>
	
	<div class="SVELTE_HYDRATER contents" data-target="SSOBanner" data-props="{&quot;organizations&quot;:[]}"></div>
	
	

	<main class="flex flex-1 flex-col"><div class="relative lg:flex" id="hf-doc-container"><div class="sticky top-0 z-20 self-start"><div class="SVELTE_HYDRATER contents" data-target="SideMenu" data-props="{&quot;chapters&quot;:[{&quot;title&quot;:&quot;Get started&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;ðŸ¤— Transformers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;index&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/index&quot;},{&quot;title&quot;:&quot;Quick tour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/quicktour&quot;},{&quot;title&quot;:&quot;Installation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;installation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/installation&quot;},{&quot;title&quot;:&quot;Philosophy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;philosophy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/philosophy&quot;},{&quot;title&quot;:&quot;Glossary&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;glossary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/glossary&quot;}]},{&quot;title&quot;:&quot;Using ðŸ¤— Transformers&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Summary of the tasks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/task_summary&quot;},{&quot;title&quot;:&quot;Summary of the models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_summary&quot;},{&quot;title&quot;:&quot;Preprocessing data&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;preprocessing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/preprocessing&quot;},{&quot;title&quot;:&quot;Fine-tuning a pretrained model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;training&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/training&quot;},{&quot;title&quot;:&quot;Model sharing and uploading&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_sharing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_sharing&quot;},{&quot;title&quot;:&quot;Summary of the tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tokenizer_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/tokenizer_summary&quot;},{&quot;title&quot;:&quot;Multi-lingual models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;multilingual&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/multilingual&quot;}]},{&quot;title&quot;:&quot;Advanced guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Examples&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;examples&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/examples&quot;},{&quot;title&quot;:&quot;Troubleshooting&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;troubleshooting&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/troubleshooting&quot;},{&quot;title&quot;:&quot;Fine-tuning with custom datasets&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_datasets&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/custom_datasets&quot;},{&quot;title&quot;:&quot;ðŸ¤— Transformers Notebooks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;notebooks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/notebooks&quot;},{&quot;title&quot;:&quot;Run training on Amazon SageMaker&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sagemaker&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/sagemaker&quot;},{&quot;title&quot;:&quot;Community&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;community&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/community&quot;},{&quot;title&quot;:&quot;Converting Tensorflow Checkpoints&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;converting_tensorflow_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/converting_tensorflow_models&quot;},{&quot;title&quot;:&quot;Migrating from previous packages&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;migration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/migration&quot;},{&quot;title&quot;:&quot;How to contribute to transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;contributing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/contributing&quot;},{&quot;title&quot;:&quot;How to add a model to ðŸ¤— Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/add_new_model&quot;},{&quot;title&quot;:&quot;How to add a pipeline to ðŸ¤— Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_pipeline&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/add_new_pipeline&quot;},{&quot;title&quot;:&quot;Using tokenizers from ðŸ¤— Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fast_tokenizers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/fast_tokenizers&quot;},{&quot;title&quot;:&quot;Performance and Scalability: How To Fit a Bigger Model and Train It Faster&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;performance&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/performance&quot;},{&quot;title&quot;:&quot;Model Parallelism&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;parallelism&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/parallelism&quot;},{&quot;title&quot;:&quot;Testing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;testing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/testing&quot;},{&quot;title&quot;:&quot;Debugging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;debugging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/debugging&quot;},{&quot;title&quot;:&quot;Exporting transformers models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;serialization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/serialization&quot;},{&quot;title&quot;:&quot;Checks on a Pull Request&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pr_checks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/pr_checks&quot;}]},{&quot;title&quot;:&quot;Research&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;BERTology&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bertology&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/bertology&quot;},{&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perplexity&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/perplexity&quot;},{&quot;title&quot;:&quot;Benchmarks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;benchmarks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/benchmarks&quot;}]},{&quot;title&quot;:&quot;API&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Main Classes&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/callback&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/callback&quot;},{&quot;title&quot;:&quot;Configuration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/configuration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/configuration&quot;},{&quot;title&quot;:&quot;Data Collator&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/data_collator&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/data_collator&quot;},{&quot;title&quot;:&quot;Keras callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/keras_callbacks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/keras_callbacks&quot;},{&quot;title&quot;:&quot;Logging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/logging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/logging&quot;},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/model&quot;},{&quot;title&quot;:&quot;Optimization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/optimizer_schedules&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/optimizer_schedules&quot;},{&quot;title&quot;:&quot;Model outputs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/output&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/output&quot;},{&quot;title&quot;:&quot;Pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/pipelines&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/pipelines&quot;},{&quot;title&quot;:&quot;Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/processors&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/processors&quot;},{&quot;title&quot;:&quot;Tokenizer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/tokenizer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/tokenizer&quot;},{&quot;title&quot;:&quot;Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/trainer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/trainer&quot;},{&quot;title&quot;:&quot;DeepSpeed Integration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/deepspeed&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/deepspeed&quot;},{&quot;title&quot;:&quot;Feature Extractor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/feature_extractor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/main_classes/feature_extractor&quot;}]},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/albert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/albert&quot;},{&quot;title&quot;:&quot;Auto Classes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/auto&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/auto&quot;},{&quot;title&quot;:&quot;BART&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bart&quot;},{&quot;title&quot;:&quot;BARThez&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/barthez&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/barthez&quot;},{&quot;title&quot;:&quot;BARTpho&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bartpho&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bartpho&quot;},{&quot;title&quot;:&quot;BEiT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/beit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/beit&quot;},{&quot;title&quot;:&quot;BERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bert&quot;},{&quot;title&quot;:&quot;Bertweet&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bertweet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bertweet&quot;},{&quot;title&quot;:&quot;BertGeneration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bertgeneration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bertgeneration&quot;},{&quot;title&quot;:&quot;BertJapanese&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bert_japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bert_japanese&quot;},{&quot;title&quot;:&quot;BigBird&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bigbird&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bigbird&quot;},{&quot;title&quot;:&quot;BigBirdPegasus&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bigbird_pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus&quot;},{&quot;title&quot;:&quot;Blenderbot&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/blenderbot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/blenderbot&quot;},{&quot;title&quot;:&quot;Blenderbot Small&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/blenderbot_small&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/blenderbot_small&quot;},{&quot;title&quot;:&quot;BORT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/bort&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/bort&quot;},{&quot;title&quot;:&quot;ByT5&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/byt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/byt5&quot;},{&quot;title&quot;:&quot;CamemBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/camembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/camembert&quot;},{&quot;title&quot;:&quot;CANINE&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/canine&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/canine&quot;},{&quot;title&quot;:&quot;CLIP&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/clip&quot;},{&quot;title&quot;:&quot;ConvBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/convbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/convbert&quot;},{&quot;title&quot;:&quot;CPM&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/cpm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/cpm&quot;},{&quot;title&quot;:&quot;CTRL&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/ctrl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/ctrl&quot;},{&quot;title&quot;:&quot;DeBERTa&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/deberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/deberta&quot;},{&quot;title&quot;:&quot;DeBERTa-v2&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/deberta_v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/deberta_v2&quot;},{&quot;title&quot;:&quot;DeiT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/deit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/deit&quot;},{&quot;title&quot;:&quot;DETR&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/detr&quot;},{&quot;title&quot;:&quot;DialoGPT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/dialogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/dialogpt&quot;},{&quot;title&quot;:&quot;DistilBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/distilbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/distilbert&quot;},{&quot;title&quot;:&quot;DPR&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/dpr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/dpr&quot;},{&quot;title&quot;:&quot;ELECTRA&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/electra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/electra&quot;},{&quot;title&quot;:&quot;Encoder Decoder Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/encoderdecoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/encoderdecoder&quot;},{&quot;title&quot;:&quot;FlauBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/flaubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/flaubert&quot;},{&quot;title&quot;:&quot;FNet&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/fnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/fnet&quot;},{&quot;title&quot;:&quot;FSMT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/fsmt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/fsmt&quot;},{&quot;title&quot;:&quot;Funnel Transformer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/funnel&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/funnel&quot;},{&quot;title&quot;:&quot;herBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/herbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/herbert&quot;},{&quot;title&quot;:&quot;I-BERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/ibert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/ibert&quot;},{&quot;title&quot;:&quot;ImageGPT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/imagegpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/imagegpt&quot;},{&quot;title&quot;:&quot;LayoutLM&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/layoutlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/layoutlm&quot;},{&quot;title&quot;:&quot;LayoutLMV2&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/layoutlmv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/layoutlmv2&quot;},{&quot;title&quot;:&quot;LayoutXLM&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/layoutxlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/layoutxlm&quot;},{&quot;title&quot;:&quot;LED&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/led&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/led&quot;},{&quot;title&quot;:&quot;Longformer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/longformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/longformer&quot;},{&quot;title&quot;:&quot;LUKE&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/luke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/luke&quot;},{&quot;title&quot;:&quot;LXMERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/lxmert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/lxmert&quot;},{&quot;title&quot;:&quot;MarianMT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/marian&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/marian&quot;},{&quot;title&quot;:&quot;M2M100&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/m2m_100&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/m2m_100&quot;},{&quot;title&quot;:&quot;MBart and MBart-50&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/mbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/mbart&quot;},{&quot;title&quot;:&quot;MegatronBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/megatron_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/megatron_bert&quot;},{&quot;title&quot;:&quot;MegatronGPT2&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/megatron_gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/megatron_gpt2&quot;},{&quot;title&quot;:&quot;MLUKE&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/mluke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/mluke&quot;},{&quot;title&quot;:&quot;MobileBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/mobilebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/mobilebert&quot;},{&quot;title&quot;:&quot;mLUKE&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/mluke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/mluke&quot;},{&quot;title&quot;:&quot;MPNet&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/mpnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/mpnet&quot;},{&quot;title&quot;:&quot;MT5&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/mt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/mt5&quot;},{&quot;title&quot;:&quot;OpenAI GPT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/gpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/gpt&quot;},{&quot;title&quot;:&quot;OpenAI GPT2&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/gpt2&quot;},{&quot;title&quot;:&quot;GPT-J&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/gptj&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/gptj&quot;},{&quot;title&quot;:&quot;GPT Neo&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/gpt_neo&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/gpt_neo&quot;},{&quot;title&quot;:&quot;Hubert&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/hubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/hubert&quot;},{&quot;title&quot;:&quot;Perceiver&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/perceiver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/perceiver&quot;},{&quot;title&quot;:&quot;Pegasus&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/pegasus&quot;},{&quot;title&quot;:&quot;PhoBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/phobert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/phobert&quot;},{&quot;title&quot;:&quot;ProphetNet&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/prophetnet&quot;},{&quot;title&quot;:&quot;QDQBert&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/qdqbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/qdqbert&quot;},{&quot;title&quot;:&quot;RAG&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/rag&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/rag&quot;},{&quot;title&quot;:&quot;Reformer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/reformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/reformer&quot;},{&quot;title&quot;:&quot;RemBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/rembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/rembert&quot;},{&quot;title&quot;:&quot;RetriBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/retribert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/retribert&quot;},{&quot;title&quot;:&quot;RoBERTa&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/roberta&quot;},{&quot;title&quot;:&quot;RoFormer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/roformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/roformer&quot;},{&quot;title&quot;:&quot;SegFormer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/segformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/segformer&quot;},{&quot;title&quot;:&quot;SEW&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/sew&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/sew&quot;},{&quot;title&quot;:&quot;SEW-D&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/sew_d&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/sew_d&quot;},{&quot;title&quot;:&quot;Speech Encoder Decoder Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/speechencoderdecoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/speechencoderdecoder&quot;},{&quot;title&quot;:&quot;Speech2Text&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/speech_to_text&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/speech_to_text&quot;},{&quot;title&quot;:&quot;Speech2Text2&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/speech_to_text_2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2&quot;},{&quot;title&quot;:&quot;Splinter&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/splinter&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/splinter&quot;},{&quot;title&quot;:&quot;SqueezeBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/squeezebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/squeezebert&quot;},{&quot;title&quot;:&quot;T5&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/t5&quot;},{&quot;title&quot;:&quot;T5v1.1&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/t5v1.1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/t5v1.1&quot;},{&quot;title&quot;:&quot;TAPAS&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/tapas&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/tapas&quot;},{&quot;title&quot;:&quot;Transformer XL&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/transformerxl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/transformerxl&quot;},{&quot;title&quot;:&quot;TrOCR&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/trocr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/trocr&quot;},{&quot;title&quot;:&quot;UniSpeech&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/unispeech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/unispeech&quot;},{&quot;title&quot;:&quot;UniSpeech-SAT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/unispeech_sat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/unispeech_sat&quot;},{&quot;title&quot;:&quot;Vision Encoder Decoder Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/visionencoderdecoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder&quot;},{&quot;title&quot;:&quot;Vision Text Dual Encoder&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/vision_text_dual_encoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder&quot;},{&quot;title&quot;:&quot;Vision Transformer (ViT)&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/vit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/vit&quot;},{&quot;title&quot;:&quot;VisualBERT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/visual_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/visual_bert&quot;},{&quot;title&quot;:&quot;Wav2Vec2&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/wav2vec2&quot;},{&quot;title&quot;:&quot;Wav2Vec2Phoneme&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/wav2vec2_phoneme&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/wav2vec2_phoneme&quot;},{&quot;title&quot;:&quot;WavLM&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/wavlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/wavlm&quot;},{&quot;title&quot;:&quot;XLM&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/xlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/xlm&quot;},{&quot;title&quot;:&quot;XLM-ProphetNet&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/xlmprophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/xlmroberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/xlmroberta&quot;},{&quot;title&quot;:&quot;XLNet&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/xlnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/xlnet&quot;},{&quot;title&quot;:&quot;XLSR-Wav2Vec2&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/xlsr_wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/xlsr_wav2vec2&quot;},{&quot;title&quot;:&quot;XLS-R&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/xls_r&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/model_doc/xls_r&quot;}]},{&quot;title&quot;:&quot;Internal Helpers&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Custom Layers and Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/modeling_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/internal/modeling_utils&quot;},{&quot;title&quot;:&quot;Utilities for pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/pipelines_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/internal/pipelines_utils&quot;},{&quot;title&quot;:&quot;Utilities for Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/tokenization_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/internal/tokenization_utils&quot;},{&quot;title&quot;:&quot;Utilities for Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/trainer_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/internal/trainer_utils&quot;},{&quot;title&quot;:&quot;Utilities for Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/generation_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/internal/generation_utils&quot;},{&quot;title&quot;:&quot;General Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/file_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/internal/file_utils&quot;}]}]}],&quot;chapterId&quot;:&quot;performance&quot;,&quot;docType&quot;:&quot;docs&quot;,&quot;isLoggedIn&quot;:true,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;en&quot;],&quot;library&quot;:&quot;transformers&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;v4.15.0&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;},{&quot;version&quot;:&quot;v4.46.3&quot;},{&quot;version&quot;:&quot;v4.46.2&quot;},{&quot;version&quot;:&quot;v4.46.0&quot;},{&quot;version&quot;:&quot;v4.45.2&quot;},{&quot;version&quot;:&quot;v4.45.1&quot;},{&quot;version&quot;:&quot;v4.44.2&quot;},{&quot;version&quot;:&quot;v4.44.1&quot;},{&quot;version&quot;:&quot;v4.44.0&quot;},{&quot;version&quot;:&quot;v4.43.4&quot;},{&quot;version&quot;:&quot;v4.43.3&quot;},{&quot;version&quot;:&quot;v4.43.2&quot;},{&quot;version&quot;:&quot;v4.43.0&quot;},{&quot;version&quot;:&quot;v4.42.4&quot;},{&quot;version&quot;:&quot;v4.42.0&quot;},{&quot;version&quot;:&quot;v4.41.2&quot;},{&quot;version&quot;:&quot;v4.41.1&quot;},{&quot;version&quot;:&quot;v4.41.0&quot;},{&quot;version&quot;:&quot;v4.40.2&quot;},{&quot;version&quot;:&quot;v4.40.1&quot;},{&quot;version&quot;:&quot;v4.40.0&quot;},{&quot;version&quot;:&quot;v4.39.3&quot;},{&quot;version&quot;:&quot;v4.39.2&quot;},{&quot;version&quot;:&quot;v4.39.1&quot;},{&quot;version&quot;:&quot;v4.39.0&quot;},{&quot;version&quot;:&quot;v4.38.2&quot;},{&quot;version&quot;:&quot;v4.38.1&quot;},{&quot;version&quot;:&quot;v4.38.0&quot;},{&quot;version&quot;:&quot;v4.37.2&quot;},{&quot;version&quot;:&quot;v4.37.1&quot;},{&quot;version&quot;:&quot;v4.37.0&quot;},{&quot;version&quot;:&quot;v4.36.1&quot;},{&quot;version&quot;:&quot;v4.36.0&quot;},{&quot;version&quot;:&quot;v4.35.2&quot;},{&quot;version&quot;:&quot;v4.35.1&quot;},{&quot;version&quot;:&quot;v4.35.0&quot;},{&quot;version&quot;:&quot;v4.34.1&quot;},{&quot;version&quot;:&quot;v4.34.0&quot;},{&quot;version&quot;:&quot;v4.33.3&quot;},{&quot;version&quot;:&quot;v4.33.2&quot;},{&quot;version&quot;:&quot;v4.33.0&quot;},{&quot;version&quot;:&quot;v4.32.1&quot;},{&quot;version&quot;:&quot;v4.32.0&quot;},{&quot;version&quot;:&quot;v4.31.0&quot;},{&quot;version&quot;:&quot;v4.30.0&quot;},{&quot;version&quot;:&quot;v4.29.1&quot;},{&quot;version&quot;:&quot;v4.29.0&quot;},{&quot;version&quot;:&quot;v4.28.1&quot;},{&quot;version&quot;:&quot;v4.28.0&quot;},{&quot;version&quot;:&quot;v4.27.2&quot;},{&quot;version&quot;:&quot;v4.27.1&quot;},{&quot;version&quot;:&quot;v4.27.0&quot;},{&quot;version&quot;:&quot;v4.26.1&quot;},{&quot;version&quot;:&quot;v4.26.0&quot;},{&quot;version&quot;:&quot;v4.25.1&quot;},{&quot;version&quot;:&quot;v4.24.0&quot;},{&quot;version&quot;:&quot;v4.23.1&quot;},{&quot;version&quot;:&quot;v4.23.0&quot;},{&quot;version&quot;:&quot;v4.22.2&quot;},{&quot;version&quot;:&quot;v4.22.1&quot;},{&quot;version&quot;:&quot;v4.22.0&quot;},{&quot;version&quot;:&quot;v4.21.3&quot;},{&quot;version&quot;:&quot;v4.21.2&quot;},{&quot;version&quot;:&quot;v4.21.1&quot;},{&quot;version&quot;:&quot;v4.21.0&quot;},{&quot;version&quot;:&quot;v4.20.1&quot;},{&quot;version&quot;:&quot;v4.20.0&quot;},{&quot;version&quot;:&quot;v4.19.4&quot;},{&quot;version&quot;:&quot;v4.19.3&quot;},{&quot;version&quot;:&quot;v4.19.2&quot;},{&quot;version&quot;:&quot;v4.19.0&quot;},{&quot;version&quot;:&quot;v4.18.0&quot;},{&quot;version&quot;:&quot;v4.17.0&quot;},{&quot;version&quot;:&quot;v4.16.2&quot;},{&quot;version&quot;:&quot;v4.16.1&quot;},{&quot;version&quot;:&quot;v4.16.0&quot;},{&quot;version&quot;:&quot;v4.15.0&quot;},{&quot;version&quot;:&quot;v4.14.1&quot;},{&quot;version&quot;:&quot;v4.13.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.5&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.4&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.0.0&quot;},{&quot;version&quot;:&quot;doc-builder-html&quot;}],&quot;title&quot;:&quot;Performance and Scalability: How To Fit a Bigger Model and Train It Faster&quot;}">







<div class="z-2 w-full flex-none lg:flex lg:h-dvh lg:w-[270px] lg:flex-col 2xl:w-[300px] false"><div class="shadow-alternate flex h-auto w-full items-center rounded-b-xl border-b bg-white py-2 text-lg leading-tight lg:hidden">
		<div class="flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6"><p class="text-sm text-gray-400 first-letter:capitalize">Transformers documentation
			</p>
			<div class="mr-2 flex items-center"><p class="font-semibold">Performance and Scalability: How To Fit a Bigger Model and Train It Faster</p>
				<svg class="text-xl false" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z" fill="currentColor"></path></svg></div></div>
		<button class="hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2"><svg class="text-gray-500 group-hover:text-gray-700" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg></button></div>
	<div class="hidden flex-col justify-between border-b border-r bg-white bg-gradient-to-r p-4 lg:flex from-orange-50 to-white dark:from-gray-900 dark:to-gray-950"><div class="group relative mb-2 flex min-w-[50%] items-center self-start text-lg font-bold leading-tight first-letter:capitalize"><div class="mr-1.5 h-1.5 w-1.5 rounded-full bg-orange-500 flex-none"></div>
			<h1>Transformers</h1>
			<svg class="opacity-50 ml-0.5 flex-none group-hover:opacity-100" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z" fill="currentColor"></path></svg>

			<select class="absolute inset-0 border-none bg-white text-base opacity-0 outline-none"><option value="/docs">ðŸ¡ View all docs</option><option value="/docs/optimum-neuron" >AWS Trainium &amp; Inferentia</option><option value="/docs/accelerate" >Accelerate</option><option value="/docs/sagemaker" >Amazon SageMaker</option><option value="https://argilla-io.github.io/argilla/" >Argilla</option><option value="/docs/autotrain" >AutoTrain</option><option value="/docs/bitsandbytes" >Bitsandbytes</option><option value="/docs/chat-ui" >Chat UI</option><option value="/docs/competitions" >Competitions</option><option value="/docs/dataset-viewer" >Dataset viewer</option><option value="/docs/datasets" >Datasets</option><option value="/docs/diffusers" >Diffusers</option><option value="https://distilabel.argilla.io/" >Distilabel</option><option value="/docs/evaluate" >Evaluate</option><option value="/docs/google-cloud" >Google Cloud</option><option value="/docs/optimum-tpu" >Google TPUs</option><option value="https://www.gradio.app/docs/" >Gradio</option><option value="/docs/hub" >Hub</option><option value="/docs/huggingface_hub" >Hub Python Library</option><option value="/docs/hugs" >Hugging Face Generative AI Services (HUGS)</option><option value="/docs/huggingface.js" >Huggingface.js</option><option value="/docs/api-inference" >Inference API (serverless)</option><option value="/docs/inference-endpoints" >Inference Endpoints (dedicated)</option><option value="/docs/leaderboards" >Leaderboards</option><option value="/docs/optimum" >Optimum</option><option value="/docs/peft" >PEFT</option><option value="/docs/safetensors" >Safetensors</option><option value="https://sbert.net/" >Sentence Transformers</option><option value="/docs/trl" >TRL</option><option value="/tasks" >Tasks</option><option value="/docs/text-embeddings-inference" >Text Embeddings Inference</option><option value="/docs/text-generation-inference" >Text Generation Inference</option><option value="/docs/tokenizers" >Tokenizers</option><option value="/docs/transformers" selected>Transformers</option><option value="/docs/transformers.js" >Transformers.js</option><option value="/docs/timm" >timm</option></select></div>

		<button class="shadow-alternate mb-2 flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500"><svg class="flex-none mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
			<div>Search documentation</div>
			</button>
		<div class="flex items-center">
				<select class="form-input !mt-0 mr-1 !w-20 rounded !border border-gray-200 p-1 text-xs uppercase dark:!text-gray-400"><option value="0" >main</option><option value="1" >v4.46.3</option><option value="2" >v4.45.2</option><option value="3" >v4.44.2</option><option value="4" >v4.43.4</option><option value="5" >v4.42.4</option><option value="6" >v4.41.2</option><option value="7" >v4.40.2</option><option value="8" >v4.39.3</option><option value="9" >v4.38.2</option><option value="10" >v4.37.2</option><option value="11" >v4.36.1</option><option value="12" >v4.35.2</option><option value="13" >v4.34.1</option><option value="14" >v4.33.3</option><option value="15" >v4.32.1</option><option value="16" >v4.31.0</option><option value="17" >v4.30.0</option><option value="18" >v4.29.1</option><option value="19" >v4.28.1</option><option value="20" >v4.27.2</option><option value="21" >v4.26.1</option><option value="22" >v4.25.1</option><option value="23" >v4.24.0</option><option value="24" >v4.23.1</option><option value="25" >v4.22.2</option><option value="26" >v4.21.3</option><option value="27" >v4.20.1</option><option value="28" >v4.19.4</option><option value="29" >v4.18.0</option><option value="30" >v4.17.0</option><option value="31" >v4.16.2</option><option value="32" selected>v4.15.0</option><option value="33" >v4.14.1</option><option value="34" >v4.13.0</option><option value="35" >v4.12.5</option><option value="36" >v4.11.3</option><option value="37" >v4.10.1</option><option value="38" >v4.9.2</option><option value="39" >v4.8.2</option><option value="40" >v4.7.0</option><option value="41" >v4.6.0</option><option value="42" >v4.5.1</option><option value="43" >v4.4.2</option><option value="44" >v4.3.3</option><option value="45" >v4.2.2</option><option value="46" >v4.1.1</option><option value="47" >v4.0.1</option><option value="48" >v3.5.1</option><option value="49" >v3.4.0</option><option value="50" >v3.3.1</option><option value="51" >v3.2.0</option><option value="52" >v3.1.0</option><option value="53" >v3.0.2</option><option value="54" >v2.11.0</option><option value="55" >v2.10.0</option><option value="56" >v2.9.1</option><option value="57" >v2.8.0</option><option value="58" >v2.7.0</option><option value="59" >v2.6.0</option><option value="60" >v2.5.1</option><option value="61" >v2.4.1</option><option value="62" >v2.3.0</option><option value="63" >v2.2.2</option><option value="64" >v2.1.1</option><option value="65" >v2.0.0</option><option value="66" >v1.2.0</option><option value="67" >v1.1.0</option><option value="68" >v1.0.0</option><option value="69" >doc-builder-html</option></select>
			
			<select class="form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border"><option value="en" selected>EN</option></select>
			
<div class="relative inline-block">
	<button class="rounded-full border border-gray-100 p-1.5  flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 " type="button">
		<svg class=" text-yellow-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24" fill="currentColor"><path d="M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z"></path></svg>
			
		</button>
	
	
	</div>
			<a href="https://github.com/huggingface/transformers" class="group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300"><svg class="inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1.03em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 250"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z" fill="currentColor"></path></svg>
				</a></div></div>

	<nav class="hidden flex-auto lg:flex bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pb-16 pt-3 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]">
		
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Get started<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/index" id="index"><!-- HTML_TAG_START -->ðŸ¤— Transformers<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/quicktour" id="quicktour"><!-- HTML_TAG_START -->Quick tour<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/installation" id="installation"><!-- HTML_TAG_START -->Installation<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/philosophy" id="philosophy"><!-- HTML_TAG_START -->Philosophy<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/glossary" id="glossary"><!-- HTML_TAG_START -->Glossary<!-- HTML_TAG_END -->
		</a>
			</div>
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Using ðŸ¤— Transformers<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/task_summary" id="task_summary"><!-- HTML_TAG_START -->Summary of the tasks<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/model_summary" id="model_summary"><!-- HTML_TAG_START -->Summary of the models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/preprocessing" id="preprocessing"><!-- HTML_TAG_START -->Preprocessing data<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/training" id="training"><!-- HTML_TAG_START -->Fine-tuning a pretrained model<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/model_sharing" id="model_sharing"><!-- HTML_TAG_START -->Model sharing and uploading<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/tokenizer_summary" id="tokenizer_summary"><!-- HTML_TAG_START -->Summary of the tokenizers<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/multilingual" id="multilingual"><!-- HTML_TAG_START -->Multi-lingual models<!-- HTML_TAG_END -->
		</a>
			</div>
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Advanced guides<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/examples" id="examples"><!-- HTML_TAG_START -->Examples<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/troubleshooting" id="troubleshooting"><!-- HTML_TAG_START -->Troubleshooting<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/custom_datasets" id="custom_datasets"><!-- HTML_TAG_START -->Fine-tuning with custom datasets<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/notebooks" id="notebooks"><!-- HTML_TAG_START -->ðŸ¤— Transformers Notebooks<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/sagemaker" id="sagemaker"><!-- HTML_TAG_START -->Run training on Amazon SageMaker<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/community" id="community"><!-- HTML_TAG_START -->Community<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/converting_tensorflow_models" id="converting_tensorflow_models"><!-- HTML_TAG_START -->Converting Tensorflow Checkpoints<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/migration" id="migration"><!-- HTML_TAG_START -->Migrating from previous packages<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/contributing" id="contributing"><!-- HTML_TAG_START -->How to contribute to transformers?<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/add_new_model" id="add_new_model"><!-- HTML_TAG_START -->How to add a model to ðŸ¤— Transformers?<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/add_new_pipeline" id="add_new_pipeline"><!-- HTML_TAG_START -->How to add a pipeline to ðŸ¤— Transformers?<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/fast_tokenizers" id="fast_tokenizers"><!-- HTML_TAG_START -->Using tokenizers from ðŸ¤— Tokenizers<!-- HTML_TAG_END -->
		</a><a class="rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pl-2 pr-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-2" href="/docs/transformers/v4.15.0/en/performance" id="performance"><!-- HTML_TAG_START -->Performance and Scalability: How To Fit a Bigger Model and Train It Faster<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/parallelism" id="parallelism"><!-- HTML_TAG_START -->Model Parallelism<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/testing" id="testing"><!-- HTML_TAG_START -->Testing<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/debugging" id="debugging"><!-- HTML_TAG_START -->Debugging<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/serialization" id="serialization"><!-- HTML_TAG_START -->Exporting transformers models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/pr_checks" id="pr_checks"><!-- HTML_TAG_START -->Checks on a Pull Request<!-- HTML_TAG_END -->
		</a>
			</div>
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Research<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/bertology" id="bertology"><!-- HTML_TAG_START -->BERTology<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/perplexity" id="perplexity"><!-- HTML_TAG_START -->Perplexity of fixed-length models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/docs/transformers/v4.15.0/en/benchmarks" id="benchmarks"><!-- HTML_TAG_START -->Benchmarks<!-- HTML_TAG_END -->
		</a>
			</div>
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->API<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col">
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Main Classes<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/callback" id="main_classes/callback"><!-- HTML_TAG_START -->Callbacks<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/configuration" id="main_classes/configuration"><!-- HTML_TAG_START -->Configuration<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/data_collator" id="main_classes/data_collator"><!-- HTML_TAG_START -->Data Collator<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/keras_callbacks" id="main_classes/keras_callbacks"><!-- HTML_TAG_START -->Keras callbacks<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/logging" id="main_classes/logging"><!-- HTML_TAG_START -->Logging<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/model" id="main_classes/model"><!-- HTML_TAG_START -->Models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/optimizer_schedules" id="main_classes/optimizer_schedules"><!-- HTML_TAG_START -->Optimization<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/output" id="main_classes/output"><!-- HTML_TAG_START -->Model outputs<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/pipelines" id="main_classes/pipelines"><!-- HTML_TAG_START -->Pipelines<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/processors" id="main_classes/processors"><!-- HTML_TAG_START -->Processors<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/tokenizer" id="main_classes/tokenizer"><!-- HTML_TAG_START -->Tokenizer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/trainer" id="main_classes/trainer"><!-- HTML_TAG_START -->Trainer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/deepspeed" id="main_classes/deepspeed"><!-- HTML_TAG_START -->DeepSpeed Integration<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/main_classes/feature_extractor" id="main_classes/feature_extractor"><!-- HTML_TAG_START -->Feature Extractor<!-- HTML_TAG_END -->
		</a>
			</div>
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Models<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/albert" id="model_doc/albert"><!-- HTML_TAG_START -->ALBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/auto" id="model_doc/auto"><!-- HTML_TAG_START -->Auto Classes<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bart" id="model_doc/bart"><!-- HTML_TAG_START -->BART<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/barthez" id="model_doc/barthez"><!-- HTML_TAG_START -->BARThez<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bartpho" id="model_doc/bartpho"><!-- HTML_TAG_START -->BARTpho<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/beit" id="model_doc/beit"><!-- HTML_TAG_START -->BEiT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bert" id="model_doc/bert"><!-- HTML_TAG_START -->BERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bertweet" id="model_doc/bertweet"><!-- HTML_TAG_START -->Bertweet<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bertgeneration" id="model_doc/bertgeneration"><!-- HTML_TAG_START -->BertGeneration<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bert_japanese" id="model_doc/bert_japanese"><!-- HTML_TAG_START -->BertJapanese<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bigbird" id="model_doc/bigbird"><!-- HTML_TAG_START -->BigBird<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bigbird_pegasus" id="model_doc/bigbird_pegasus"><!-- HTML_TAG_START -->BigBirdPegasus<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/blenderbot" id="model_doc/blenderbot"><!-- HTML_TAG_START -->Blenderbot<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/blenderbot_small" id="model_doc/blenderbot_small"><!-- HTML_TAG_START -->Blenderbot Small<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/bort" id="model_doc/bort"><!-- HTML_TAG_START -->BORT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/byt5" id="model_doc/byt5"><!-- HTML_TAG_START -->ByT5<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/camembert" id="model_doc/camembert"><!-- HTML_TAG_START -->CamemBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/canine" id="model_doc/canine"><!-- HTML_TAG_START -->CANINE<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/clip" id="model_doc/clip"><!-- HTML_TAG_START -->CLIP<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/convbert" id="model_doc/convbert"><!-- HTML_TAG_START -->ConvBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/cpm" id="model_doc/cpm"><!-- HTML_TAG_START -->CPM<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/ctrl" id="model_doc/ctrl"><!-- HTML_TAG_START -->CTRL<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/deberta" id="model_doc/deberta"><!-- HTML_TAG_START -->DeBERTa<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/deberta_v2" id="model_doc/deberta_v2"><!-- HTML_TAG_START -->DeBERTa-v2<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/deit" id="model_doc/deit"><!-- HTML_TAG_START -->DeiT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/detr" id="model_doc/detr"><!-- HTML_TAG_START -->DETR<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/dialogpt" id="model_doc/dialogpt"><!-- HTML_TAG_START -->DialoGPT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/distilbert" id="model_doc/distilbert"><!-- HTML_TAG_START -->DistilBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/dpr" id="model_doc/dpr"><!-- HTML_TAG_START -->DPR<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/electra" id="model_doc/electra"><!-- HTML_TAG_START -->ELECTRA<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/encoderdecoder" id="model_doc/encoderdecoder"><!-- HTML_TAG_START -->Encoder Decoder Models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/flaubert" id="model_doc/flaubert"><!-- HTML_TAG_START -->FlauBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/fnet" id="model_doc/fnet"><!-- HTML_TAG_START -->FNet<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/fsmt" id="model_doc/fsmt"><!-- HTML_TAG_START -->FSMT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/funnel" id="model_doc/funnel"><!-- HTML_TAG_START -->Funnel Transformer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/herbert" id="model_doc/herbert"><!-- HTML_TAG_START -->herBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/ibert" id="model_doc/ibert"><!-- HTML_TAG_START -->I-BERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/imagegpt" id="model_doc/imagegpt"><!-- HTML_TAG_START -->ImageGPT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/layoutlm" id="model_doc/layoutlm"><!-- HTML_TAG_START -->LayoutLM<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/layoutlmv2" id="model_doc/layoutlmv2"><!-- HTML_TAG_START -->LayoutLMV2<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/layoutxlm" id="model_doc/layoutxlm"><!-- HTML_TAG_START -->LayoutXLM<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/led" id="model_doc/led"><!-- HTML_TAG_START -->LED<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/longformer" id="model_doc/longformer"><!-- HTML_TAG_START -->Longformer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/luke" id="model_doc/luke"><!-- HTML_TAG_START -->LUKE<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/lxmert" id="model_doc/lxmert"><!-- HTML_TAG_START -->LXMERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/marian" id="model_doc/marian"><!-- HTML_TAG_START -->MarianMT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/m2m_100" id="model_doc/m2m_100"><!-- HTML_TAG_START -->M2M100<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/mbart" id="model_doc/mbart"><!-- HTML_TAG_START -->MBart and MBart-50<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/megatron_bert" id="model_doc/megatron_bert"><!-- HTML_TAG_START -->MegatronBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/megatron_gpt2" id="model_doc/megatron_gpt2"><!-- HTML_TAG_START -->MegatronGPT2<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/mluke" id="model_doc/mluke"><!-- HTML_TAG_START -->MLUKE<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/mobilebert" id="model_doc/mobilebert"><!-- HTML_TAG_START -->MobileBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/mluke" id="model_doc/mluke"><!-- HTML_TAG_START -->mLUKE<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/mpnet" id="model_doc/mpnet"><!-- HTML_TAG_START -->MPNet<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/mt5" id="model_doc/mt5"><!-- HTML_TAG_START -->MT5<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/gpt" id="model_doc/gpt"><!-- HTML_TAG_START -->OpenAI GPT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/gpt2" id="model_doc/gpt2"><!-- HTML_TAG_START -->OpenAI GPT2<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/gptj" id="model_doc/gptj"><!-- HTML_TAG_START -->GPT-J<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/gpt_neo" id="model_doc/gpt_neo"><!-- HTML_TAG_START -->GPT Neo<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/hubert" id="model_doc/hubert"><!-- HTML_TAG_START -->Hubert<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/perceiver" id="model_doc/perceiver"><!-- HTML_TAG_START -->Perceiver<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/pegasus" id="model_doc/pegasus"><!-- HTML_TAG_START -->Pegasus<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/phobert" id="model_doc/phobert"><!-- HTML_TAG_START -->PhoBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/prophetnet" id="model_doc/prophetnet"><!-- HTML_TAG_START -->ProphetNet<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/qdqbert" id="model_doc/qdqbert"><!-- HTML_TAG_START -->QDQBert<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/rag" id="model_doc/rag"><!-- HTML_TAG_START -->RAG<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/reformer" id="model_doc/reformer"><!-- HTML_TAG_START -->Reformer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/rembert" id="model_doc/rembert"><!-- HTML_TAG_START -->RemBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/retribert" id="model_doc/retribert"><!-- HTML_TAG_START -->RetriBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/roberta" id="model_doc/roberta"><!-- HTML_TAG_START -->RoBERTa<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/roformer" id="model_doc/roformer"><!-- HTML_TAG_START -->RoFormer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/segformer" id="model_doc/segformer"><!-- HTML_TAG_START -->SegFormer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/sew" id="model_doc/sew"><!-- HTML_TAG_START -->SEW<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/sew_d" id="model_doc/sew_d"><!-- HTML_TAG_START -->SEW-D<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/speechencoderdecoder" id="model_doc/speechencoderdecoder"><!-- HTML_TAG_START -->Speech Encoder Decoder Models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text" id="model_doc/speech_to_text"><!-- HTML_TAG_START -->Speech2Text<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/speech_to_text_2" id="model_doc/speech_to_text_2"><!-- HTML_TAG_START -->Speech2Text2<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/splinter" id="model_doc/splinter"><!-- HTML_TAG_START -->Splinter<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/squeezebert" id="model_doc/squeezebert"><!-- HTML_TAG_START -->SqueezeBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/t5" id="model_doc/t5"><!-- HTML_TAG_START -->T5<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/t5v1.1" id="model_doc/t5v1.1"><!-- HTML_TAG_START -->T5v1.1<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/tapas" id="model_doc/tapas"><!-- HTML_TAG_START -->TAPAS<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/transformerxl" id="model_doc/transformerxl"><!-- HTML_TAG_START -->Transformer XL<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/trocr" id="model_doc/trocr"><!-- HTML_TAG_START -->TrOCR<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/unispeech" id="model_doc/unispeech"><!-- HTML_TAG_START -->UniSpeech<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/unispeech_sat" id="model_doc/unispeech_sat"><!-- HTML_TAG_START -->UniSpeech-SAT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/visionencoderdecoder" id="model_doc/visionencoderdecoder"><!-- HTML_TAG_START -->Vision Encoder Decoder Models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/vision_text_dual_encoder" id="model_doc/vision_text_dual_encoder"><!-- HTML_TAG_START -->Vision Text Dual Encoder<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/vit" id="model_doc/vit"><!-- HTML_TAG_START -->Vision Transformer (ViT)<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/visual_bert" id="model_doc/visual_bert"><!-- HTML_TAG_START -->VisualBERT<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2" id="model_doc/wav2vec2"><!-- HTML_TAG_START -->Wav2Vec2<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/wav2vec2_phoneme" id="model_doc/wav2vec2_phoneme"><!-- HTML_TAG_START -->Wav2Vec2Phoneme<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/wavlm" id="model_doc/wavlm"><!-- HTML_TAG_START -->WavLM<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/xlm" id="model_doc/xlm"><!-- HTML_TAG_START -->XLM<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/xlmprophetnet" id="model_doc/xlmprophetnet"><!-- HTML_TAG_START -->XLM-ProphetNet<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/xlmroberta" id="model_doc/xlmroberta"><!-- HTML_TAG_START -->XLM-RoBERTa<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/xlnet" id="model_doc/xlnet"><!-- HTML_TAG_START -->XLNet<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/xlsr_wav2vec2" id="model_doc/xlsr_wav2vec2"><!-- HTML_TAG_START -->XLSR-Wav2Vec2<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/model_doc/xls_r" id="model_doc/xls_r"><!-- HTML_TAG_START -->XLS-R<!-- HTML_TAG_END -->
		</a>
			</div>
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['â–¶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Internal Helpers<!-- HTML_TAG_END --></span>
						
					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/internal/modeling_utils" id="internal/modeling_utils"><!-- HTML_TAG_START -->Custom Layers and Utilities<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/internal/pipelines_utils" id="internal/pipelines_utils"><!-- HTML_TAG_START -->Utilities for pipelines<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/internal/tokenization_utils" id="internal/tokenization_utils"><!-- HTML_TAG_START -->Utilities for Tokenizers<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/internal/trainer_utils" id="internal/trainer_utils"><!-- HTML_TAG_START -->Utilities for Trainer<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/internal/generation_utils" id="internal/generation_utils"><!-- HTML_TAG_START -->Utilities for Generation<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4" href="/docs/transformers/v4.15.0/en/internal/file_utils" id="internal/file_utils"><!-- HTML_TAG_START -->General Utilities<!-- HTML_TAG_END -->
		</a>
			</div>
			</div></nav></div></div></div>
		<div class="z-1 min-w-0 flex-1"><div class="flex justify-center bg-blue-50 px-6 py-1.5 text-xs text-blue-600 dark:bg-blue-900 dark:text-blue-200 sm:text-sm"><div>You are viewing v4.15.0 version.
			
				<span>A newer version
					<a class="underline" href="/docs/transformers/v4.46.3/performance">v4.46.3</a> is available.</span></div></div>
			<div class="px-6 pt-6 md:px-12 md:pb-16 md:pt-16">
				<div class="prose-doc prose relative mx-auto max-w-4xl break-words"><!-- HTML_TAG_START -->	<link rel="modulepreload" href="/docs/transformers/v4.15.0/en/_app/start-c4963074.js">
	<link rel="modulepreload" href="/docs/transformers/v4.15.0/en/_app/chunks/vendor-b1433968.js">
	<link rel="modulepreload" href="/docs/transformers/v4.15.0/en/_app/layout.svelte-ba4f65ca.js">
	<link rel="modulepreload" href="/docs/transformers/v4.15.0/en/_app/pages/performance.mdx-75233f39.js">
	<link rel="modulepreload" href="/docs/transformers/v4.15.0/en/_app/chunks/IconCopyLink-7029626d.js">
	<link rel="modulepreload" href="/docs/transformers/v4.15.0/en/_app/chunks/CodeBlock-a320dbd7.js">
	<link rel="modulepreload" href="/docs/transformers/v4.15.0/en/_app/chunks/CopyButton-f65cb278.js"> 






<h1 class="relative group"><a id="performance-and-scalability-how-to-fit-a-bigger-model-and-train-it-faster" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#performance-and-scalability-how-to-fit-a-bigger-model-and-train-it-faster"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Performance and Scalability: How To Fit a Bigger Model and Train It Faster
	</span></h1>

<p>For now the software sections of this document are mainly Pytorch-specific, but the guide can be extended to other frameworks in the future.</p>
<h2 class="relative group"><a id="quick-notes" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#quick-notes"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Quick notes
	</span></h2>

<p>This section gives brief ideas on how to make training faster and support bigger models. Later sections will expand, demonstrate and elucidate each of these.</p>
<h3 class="relative group"><a id="faster-training" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#faster-training"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Faster Training
	</span></h3>

<p>Hardware:</p>
<ul><li>fast connectivity between GPUs<ul><li>intra-node: NVLink</li>
<li>inter-node: Infiniband / Intel OPA</li></ul></li></ul>
<p>Software:</p>
<ul><li>Data Parallel / Distributed Data Parallel</li>
<li>fp16 (autocast caching)</li></ul>
<h3 class="relative group"><a id="bigger-models" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#bigger-models"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Bigger Models
	</span></h3>

<p>Hardware:</p>
<ul><li>bigger GPUs</li>
<li>more GPUs</li>
<li>more CPU and NVMe (offloaded to by DeepSpeed)</li></ul>
<p>Software:</p>
<ul><li>Deepspeed ZeRO</li>
<li>Deepspeed ZeRO-Offload</li>
<li>Megatron-LM 3D Parallelism</li>
<li>Pipeline Parallelism</li>
<li>Tensor Parallelism</li>
<li>Low-memory Optimizers</li>
<li>fp16/bf16 (smaller data/faster throughput)</li>
<li>tf32 (faster throughput)</li>
<li>Gradient checkpointing</li>
<li>Sparsity</li></ul>
<h2 class="relative group"><a id="hardware" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#hardware"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Hardware
	</span></h2>

<h3 class="relative group"><a id="multigpu-connectivity" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#multigpu-connectivity"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Multi-GPU Connectivity
	</span></h3>

<p>If you use multiple GPUs the way cards are inter-connected can have a huge impact on the total training time.</p>
<p>If the GPUs are on the same physical node, you can run:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-symbol">nvidia</span>-<span class="hljs-keyword">smi</span> topo -m<!-- HTML_TAG_END --></pre></div>
<p>and it will tell you how the GPUs are inter-connected.</p>
<p>On a machine with dual-GPU and which are connected with NVLink, you will most likely see something like:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->        <span class="hljs-attribute">GPU0</span>    GPU1    CPU Affinity    NUMA Affinity
<span class="hljs-attribute">GPU0</span>     X      NV2     <span class="hljs-number">0</span>-<span class="hljs-number">23</span>            N/A
<span class="hljs-attribute">GPU1</span>    NV2      X      <span class="hljs-number">0</span>-<span class="hljs-number">23</span>            N/A<!-- HTML_TAG_END --></pre></div>
<p>on a different machine w/o NVLink we may see:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->        <span class="hljs-attribute">GPU0</span>    GPU1    CPU Affinity    NUMA Affinity
<span class="hljs-attribute">GPU0</span>     X      PHB     <span class="hljs-number">0</span>-<span class="hljs-number">11</span>            N/A
<span class="hljs-attribute">GPU1</span>    PHB      X      <span class="hljs-number">0</span>-<span class="hljs-number">11</span>            N/A<!-- HTML_TAG_END --></pre></div>
<p>The report includes this legend:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->  X    = Self
  SYS  = Connection traversing PCIe <span class="hljs-keyword">as</span> well <span class="hljs-keyword">as</span> <span class="hljs-keyword">the</span> SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe <span class="hljs-keyword">as</span> well <span class="hljs-keyword">as</span> <span class="hljs-keyword">the</span> interconnect between PCIe Host Bridges <span class="hljs-keyword">within</span> <span class="hljs-keyword">a</span> NUMA node
  PHB  = Connection traversing PCIe <span class="hljs-keyword">as</span> well <span class="hljs-keyword">as</span> <span class="hljs-keyword">a</span> PCIe Host Bridge (typically <span class="hljs-keyword">the</span> CPU)
  PXB  = Connection traversing multiple PCIe bridges (<span class="hljs-keyword">without</span> traversing <span class="hljs-keyword">the</span> PCIe Host Bridge)
  PIX  = Connection traversing <span class="hljs-keyword">at</span> most <span class="hljs-keyword">a</span> single PCIe bridge
  NV<span class="hljs-comment">#  = Connection traversing a bonded set of # NVLinks</span><!-- HTML_TAG_END --></pre></div>
<p>So the first report <code>NV2</code> tells us the GPUs are interconnected with 2 NVLinks, and the second report <code>PHB</code> we have a typical consumer-level PCIe+Bridge setup.</p>
<p>Check what type of connectivity you have on your setup. Some of these will make the communication between cards faster (e.g. NVLink), others slower (e.g. PHB).</p>
<p>Depending on the type of scalability solution used, the connectivity speed could have a major or a minor impact. If the GPUs need to sync rarely, as in DDP, the impact of a slower connection will be less significant. If the GPUs need to send messages to each other often, as in ZeRO-DP, then faster connectivity becomes super important to achieve faster training.</p>
<h3 class="relative group"><a id="nvlink" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#nvlink"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>NVlink
	</span></h3>

<p><a href="https://en.wikipedia.org/wiki/NVLink" rel="nofollow">NVLink</a> is a wire-based serial multi-lane near-range communications link developed by Nvidia.</p>
<p>Each new generation provides a faster bandwidth, e.g. here is a quote from <a href="https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf" rel="nofollow">Nvidia Ampere GA102 GPU Architecture</a>:</p>
<blockquote><p>Third-Generation NVLinkÂ®
GA102 GPUs utilize NVIDIAâ€™s third-generation NVLink interface, which includes four x4 links,
with each link providing 14.0625 GB/sec bandwidth in each direction between two GPUs. Four
links provide 56.25 GB/sec bandwidth in each direction, and 112.5 GB/sec total bandwidth
between two GPUs. Two RTX 3090 GPUs can be connected together for SLI using NVLink.
(Note that 3-Way and 4-Way SLI configurations are not supported.)</p></blockquote>
<p>So the higher <code>X</code> you get in the report of <code>NVX</code> in the output of <code>nvidia-smi topo -m</code> the better. The generation will depend on your GPU architecture.</p>
<p>Letâ€™s compare the execution of a gpt2 language model training over a small sample of wikitext.</p>
<p>The results are:</p>
<table><thead><tr><th>NVlink</th>
<th align="right">Time</th></tr></thead>
<tbody><tr><td>Y</td>
<td align="right">101s</td></tr>
<tr><td>N</td>
<td align="right">131s</td></tr></tbody></table>
<p>You can see that NVLink completes the training ~23% faster.</p>
<p>In the second benchmark we use <code>NCCL_P2P_DISABLE=1</code> to tell the GPUs not to use NVLink.</p>
<p>Here is the full benchmark code and outputs:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-comment"># DDP w/ NVLink</span>

<span class="hljs-string">rm</span> -<span class="hljs-string">r</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span>; <span class="hljs-string">CUDA_VISIBLE_DEVICES</span>=<span class="hljs-string">0</span>,<span class="hljs-string">1</span> <span class="hljs-string">python</span> -<span class="hljs-string">m</span> <span class="hljs-string">torch</span>.<span class="hljs-string">distributed</span>.<span class="hljs-string">launch</span> \
<span class="hljs-built_in">--nproc_per_node</span> <span class="hljs-string">2</span> <span class="hljs-string">examples</span>/<span class="hljs-string">pytorch</span>/<span class="hljs-string">language-modeling</span>/<span class="hljs-string">run_clm</span>.<span class="hljs-string">py</span> <span class="hljs-built_in">--model_name_or_path</span> <span class="hljs-string">gpt2</span> \
<span class="hljs-built_in">--dataset_name</span> <span class="hljs-string">wikitext</span> <span class="hljs-built_in">--dataset_config_name</span> <span class="hljs-string">wikitext-2-raw-v1</span> <span class="hljs-built_in">--do_train</span> \
<span class="hljs-built_in">--output_dir</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span> <span class="hljs-built_in">--per_device_train_batch_size</span> <span class="hljs-string">4</span> <span class="hljs-built_in">--max_steps</span> <span class="hljs-string">200</span>

{<span class="hljs-string">&#x27;train_runtime&#x27;</span>: <span class="hljs-string">101</span>.<span class="hljs-string">9003</span>, <span class="hljs-string">&#x27;train_samples_per_second&#x27;</span>: <span class="hljs-string">1</span>.<span class="hljs-string">963</span>, <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-string">0</span>.<span class="hljs-string">69</span>}

<span class="hljs-comment"># DDP w/o NVLink</span>

<span class="hljs-string">rm</span> -<span class="hljs-string">r</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span>; <span class="hljs-string">CUDA_VISIBLE_DEVICES</span>=<span class="hljs-string">0</span>,<span class="hljs-string">1</span> <span class="hljs-string">NCCL_P2P_DISABLE</span>=<span class="hljs-string">1</span> <span class="hljs-string">python</span> -<span class="hljs-string">m</span> <span class="hljs-string">torch</span>.<span class="hljs-string">distributed</span>.<span class="hljs-string">launch</span> \
<span class="hljs-built_in">--nproc_per_node</span> <span class="hljs-string">2</span> <span class="hljs-string">examples</span>/<span class="hljs-string">pytorch</span>/<span class="hljs-string">language-modeling</span>/<span class="hljs-string">run_clm</span>.<span class="hljs-string">py</span> <span class="hljs-built_in">--model_name_or_path</span> <span class="hljs-string">gpt2</span> \
<span class="hljs-built_in">--dataset_name</span> <span class="hljs-string">wikitext</span> <span class="hljs-built_in">--dataset_config_name</span> <span class="hljs-string">wikitext-2-raw-v1</span> <span class="hljs-built_in">--do_train</span>
<span class="hljs-built_in">--output_dir</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span> <span class="hljs-built_in">--per_device_train_batch_size</span> <span class="hljs-string">4</span> <span class="hljs-built_in">--max_steps</span> <span class="hljs-string">200</span>

{<span class="hljs-string">&#x27;train_runtime&#x27;</span>: <span class="hljs-string">131</span>.<span class="hljs-string">4367</span>, <span class="hljs-string">&#x27;train_samples_per_second&#x27;</span>: <span class="hljs-string">1</span>.<span class="hljs-string">522</span>, <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-string">0</span>.<span class="hljs-string">69</span>}<!-- HTML_TAG_END --></pre></div>
<p>Hardware: 2x TITAN RTX 24GB each + NVlink with 2 NVLinks (<code>NV2</code> in <code>nvidia-smi topo -m</code>)
Software: <code>pytorch-1.8-to-be</code> + <code>cuda-11.0</code> / <code>transformers==4.3.0.dev0</code></p>
<h2 class="relative group"><a id="software" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#software"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Software
	</span></h2>

<h3 class="relative group"><a id="anatomy-of-models-operations" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#anatomy-of-models-operations"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Anatomy of Model&#39;s Operations
	</span></h3>

<p>Transformers architecture includes 3 main groups of operations grouped below by compute-intensity.</p>
<ol><li><p><strong>Tensor Contractions</strong></p>
<p>Linear layers and components of Multi-Head Attention all do batched <strong>matrix-matrix multiplications</strong>. These operations are the most compute-intensive part of training a transformer.</p></li>
<li><p><strong>Statistical Normalizations</strong></p>
<p>Softmax and layer normalization are less compute-intensive than tensor contractions, and involve one or more <strong>reduction operations</strong>, the result of which is then applied via a map.</p></li>
<li><p><strong>Element-wise Operators</strong></p>
<p>These are the remaining operators: <strong>biases, dropout, activations, and residual connections</strong>. These are the least compute-intensive operations.</p></li></ol>
<p>This knowledge can be helpful to know when analyzing performance bottlenecks.</p>
<p>This summary is derived from <a href="https://arxiv.org/abs/2007.00072" rel="nofollow">Data Movement Is All You Need: A Case Study on Optimizing Transformers 2020</a></p>
<h3 class="relative group"><a id="anatomy-of-models-memory" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#anatomy-of-models-memory"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Anatomy of Model&#39;s Memory
	</span></h3>

<p>The components on GPU memory are the following:</p>
<ol><li>model weights</li>
<li>optimizer states</li>
<li>gradients</li>
<li>forward activations saved for gradient computation</li>
<li>temporary buffers</li>
<li>functionality-specific memory</li></ol>
<p>A typical model trained in mixed precision with AdamW requires 18 bytes per model parameter plus activation memory.</p>
<p>For inference there are no optimizer states and gradients, so we can subtract those. And thus we end up with 6 bytes per model parameter for mixed precision inference, plus activation memory.</p>
<p>Letâ€™s look at the details.</p>
<h4 class="relative group"><a id="model-weights" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#model-weights"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Model Weights
	</span></h4>

<ul><li>4 bytes * number of parameters for fp32 training</li>
<li>6 bytes * number of parameters for mixed precision training</li></ul>
<h4 class="relative group"><a id="optimizer-states" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#optimizer-states"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Optimizer States
	</span></h4>

<ul><li>8 bytes * number of parameters for normal AdamW (maintains 2 states)</li>
<li>2 bytes * number of parameters for 8-bit AdamW optimizers like <a href="https://github.com/facebookresearch/bitsandbytes" rel="nofollow">bitsandbytes</a></li>
<li>4 bytes * number of parameters for optimizers like SGD (maintains only 1 state)</li></ul>
<h4 class="relative group"><a id="gradients" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#gradients"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Gradients
	</span></h4>

<ul><li>4 bytes * number of parameters for either fp32 or mixed precision training</li></ul>
<h4 class="relative group"><a id="forward-activations" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#forward-activations"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Forward Activations
	</span></h4>

<ul><li>size depends on many factors, the key ones being sequence length, hidden size and batch size.</li></ul>
<p>There are the input and output that are being passed and returned by the forward and the backward functions and the forward activations saved for gradient computation.</p>
<h4 class="relative group"><a id="temporary-memory" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#temporary-memory"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Temporary Memory
	</span></h4>

<p>Additionally there are all kinds of temporary variables which get released once the calculation is done, but in the moment these could require additional memory and could push to OOM. Therefore when coding itâ€™s crucial to think strategically about such temporary variables and sometimes to explicitly free those as soon as they are no longer needed.</p>
<h4 class="relative group"><a id="functionalityspecific-memory" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#functionalityspecific-memory"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Functionality-specific memory
	</span></h4>

<p>Then your software could have special memory needs. For example, when generating text using beam search, the software needs to maintain multiple copies of inputs and outputs.</p>
<h3 class="relative group"><a id="forward-vs-backward-execution-speed" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#forward-vs-backward-execution-speed"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span><code>forward</code> vs <code>backward</code> Execution Speed
	</span></h3>

<p>For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally translates into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually bandwidth-limited, and itâ€™s typical for an activation to have to read more data in the backward than in the forward (e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the forward, and writes once, gradInput).</p>
<h3 class="relative group"><a id="floating-data-types" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#floating-data-types"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Floating Data Types
	</span></h3>

<p>Here are the commonly used floating point data types choice of which impacts both memory usage and throughput:</p>
<ul><li>fp32 (<code>float32</code>)</li>
<li>fp16 (<code>float16</code>)</li>
<li>bf16 (<code>bfloat16</code>)</li>
<li>tf32 (CUDA internal data type)</li></ul>
<p>Here is a diagram that shows how these data types correlate to each other.</p>
<p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/tf32-bf16-fp16-fp32.png" alt="data types"></p>
<p>(source: <a href="https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/" rel="nofollow">NVIDIA Blog</a>)</p>
<p>While fp16 and fp32 have been around for quite some time, bf16 and tf32 are only available on the Ampere architecture GPUS. TPUs support bf16 as well.</p>
<h4 class="relative group"><a id="fp16" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#fp16"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>fp16
	</span></h4>

<p>AMP = Automatic Mixed Precision</p>
<p>If we look at whatâ€™s happening with FP16 training (mixed precision) we have:</p>
<ul><li>the model has two copies in memory: one in half-precision for the forward/backward computations and one in full precision - no memory saved here</li>
<li>the forward activations saved for gradient computation are in half-precision - memory is saved here</li>
<li>the gradients are computed in half-precision <em>but</em> converted to full-precision for the update, no saving there</li>
<li>the optimizer states are in full precision as all the updates are done in full-precision</li></ul>
<p>So the savings only happen for the forward activations saved for the backward computation, and there is a slight overhead because the model weights are stored both in half- and full-precision.</p>
<p>In ðŸ¤— Transformers fp16 mixed precision is enabled by passing <code>--fp16</code> to the ðŸ¤— Trainer.</p>
<p>Now letâ€™s look at a simple text-classification fine-tuning on 2 GPUs (Iâ€™m giving the command for reference):</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->export BS=<span class="hljs-number">16</span>
python -m torch<span class="hljs-selector-class">.distributed</span><span class="hljs-selector-class">.launch</span> \
    <span class="hljs-attr">--nproc_per_node</span> <span class="hljs-number">2</span> examples/pytorch/text-classification/run_glue<span class="hljs-selector-class">.py</span> \
    <span class="hljs-attr">--model_name_or_path</span> bert-base-cased \
    <span class="hljs-attr">--task_name</span> mrpc \
    <span class="hljs-attr">--do_train</span> \
    <span class="hljs-attr">--do_eval</span> \
    <span class="hljs-attr">--max_seq_length</span> <span class="hljs-number">128</span> \
    <span class="hljs-attr">--per_device_train_batch_size</span> <span class="hljs-variable">$BS</span> \
    <span class="hljs-attr">--learning_rate</span> <span class="hljs-number">2</span>e-<span class="hljs-number">5</span> \
    <span class="hljs-attr">--num_train_epochs</span> <span class="hljs-number">3.0</span> \
    <span class="hljs-attr">--output_dir</span> /tmp/mrpc \
    <span class="hljs-attr">--overwrite_output_dir</span> \
    <span class="hljs-attr">--fp16</span><!-- HTML_TAG_END --></pre></div>
<p>Since the only savings we get are in the model activations saved for the backward passed, itâ€™s logical that the bigger those activations are, the bigger the saving will be. If we try different batch sizes, I indeed get (this is with <code>nvidia-smi</code> so not completely reliable as said above but it will be a fair comparison):</p>
<table><thead><tr><th align="right">batch size</th>
<th align="right">w/o â€”fp16</th>
<th align="right">w/ â€”fp16</th>
<th align="right">savings</th></tr></thead>
<tbody><tr><td align="right">8</td>
<td align="right">4247</td>
<td align="right">4163</td>
<td align="right">84</td></tr>
<tr><td align="right">16</td>
<td align="right">4971</td>
<td align="right">4793</td>
<td align="right">178</td></tr>
<tr><td align="right">32</td>
<td align="right">6827</td>
<td align="right">6207</td>
<td align="right">620</td></tr>
<tr><td align="right">64</td>
<td align="right">10037</td>
<td align="right">8061</td>
<td align="right">1976</td></tr></tbody></table>
<p>So there is only a real memory saving if we train at a high batch size (and itâ€™s not half) and at batch sizes lower than 8, you actually get a bigger memory footprint (because of the overhead mentioned above). The gain for FP16 training is that in each of those cases, the training with the flag <code>--fp16</code> is twice as fast, which does require every tensor to have every dimension be a multiple of 8 (examples pad the tensors to a sequence length that is a multiple of 8).</p>
<p>Summary: FP16 with apex or AMP will only give you some memory savings with a reasonably high batch size.</p>
<p>Additionally, under mixed precision when possible, itâ€™s important that the batch size is a multiple of 8 to efficiently use tensor cores.</p>
<p>Note that in some situations the speed up can be as big as 5x when using mixed precision. e.g. we have observed that while using <a href="https://github.com/bigscience-workshop/Megatron-DeepSpeed" rel="nofollow">Megatron-Deepspeed</a>.</p>
<p>Some amazing tutorials to read on mixed precision:</p>
<ul><li>@sgugger wrote a great explanation of mixed precision <a href="https://docs.fast.ai/callback.fp16.html#A-little-bit-of-theory" rel="nofollow">here</a></li>
<li>Aleksey Bilogurâ€™s <a href="https://spell.ml/blog/mixed-precision-training-with-pytorch-Xuk7YBEAACAASJam" rel="nofollow">A developer-friendly guide to mixed precision training with PyTorch</a></li></ul>
<h5 class="relative group"><a id="fp16-caching" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#fp16-caching"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>fp16 caching
	</span></h5>

<p>pytorch <code>autocast</code> which performs AMP include a caching feature, which speed things up by caching fp16-converted values. Here is the full description from this <a href="https://discuss.pytorch.org/t/autocast-and-torch-no-grad-unexpected-behaviour/93475/3" rel="nofollow">comment</a>:</p>
<p>Autocast maintains a cache of the FP16 casts of model parameters (leaves). This helps streamline parameter reuse: if the same FP32 param is used in several different FP16list ops, like several matmuls, instead of re-casting the param to FP16 on entering each matmul, the cast will occur on the first matmul, the casted FP16 copy will be cached, and for all later matmuls the FP16 copy will be reused. The cache is maintained only within a particular outermost autocast context. When you exit the autocast context the cache is dropped. For recommended usage, in which autocast wraps the forward pass, and then you exit the context before calling backward(), this means the cache only lasts the duration of the forward pass each iteration, and will be rebuilt next iteration. (The cache of FP16-casted copies MUST be rebuilt each iteration. The FP32 parameters get updated by the optimizer, so the FP16 copies must be recreated, otherwise the FP16 values will be stale.)</p>
<h5 class="relative group"><a id="fp16-inference" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#fp16-inference"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>fp16 Inference
	</span></h5>

<p>While normally inference is done with fp16/amp as with training, itâ€™s also possible to use the full fp16 mode without using mixed precision. This is especially a good fit if the pretrained model weights are already in fp16. So a lot less memory is used: 2 bytes per parameter vs 6 bytes with mixed precision!</p>
<p>How good the results this will deliver will depend on the model. If it can handle fp16 without overflows and accuracy issues, then itâ€™ll definitely better to use the full fp16 mode.</p>
<p>For example, LayerNorm has to be done in fp32 and recent pytorch (1.10+) has been fixed to do that regardless of the input types, but earlier pytorch versions accumulate in the input type which can be an issue.</p>
<p>In ðŸ¤— Transformers the full fp16 inference is enabled by passing <code>--fp16_full_eval</code> to the ðŸ¤— Trainer.</p>
<h4 class="relative group"><a id="bf16" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#bf16"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>bf16
	</span></h4>

<p>If you own Ampere or newer hardware you can start using bf16 for your training and evaluation. While bf16 has a worse precision than fp16, it has a much much bigger dynamic range. Therefore, if in the past you were experiencing overflow issues while training the model, bf16 will prevent this from happening most of the time. Remember that in fp16 the biggest number you can have is <code>65535</code> and any number above that will overflow. A bf16 number can be as large as <code>3.39e+38</code> (!) which is about the same as fp32 - because both have 8-bits used for the numerical range.</p>
<p>Automatic Mixed Precision (AMP) is the same as with fp16, except itâ€™ll use bf16.</p>
<p>Thanks to the fp32-like dynamic range with bf16 mixed precision loss scaling is no longer needed.</p>
<p>If you have tried to finetune models pre-trained under bf16 mixed precision (e.g. T5) itâ€™s very likely that you have encountered overflow issues. Now you should be able to finetune those models without any issues.</p>
<p>That said, also be aware that if you pre-trained a model in bf16, itâ€™s likely to have overflow issues if someone tries to finetune it in fp16 down the road. So once started on the bf16-mode path itâ€™s best to remain on it and not switch to fp16.</p>
<p>In ðŸ¤— Transformers bf16 mixed precision is enabled by passing <code>--bf16</code> to the ðŸ¤— Trainer.</p>
<p>If you use your own trainer, this is just:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> torch.cuda.amp <span class="hljs-keyword">import</span> <span class="hljs-built_in">auto</span><span class="hljs-keyword">cast</span>
with <span class="hljs-built_in">auto</span><span class="hljs-keyword">cast</span>(dtype=torch.bfloat16):
    loss, outputs = ...<!-- HTML_TAG_END --></pre></div>
<p>If you need to switch a tensor to bf16, itâ€™s just: <code>t.to(dtype=torch.bfloat16)</code></p>
<p>Here is how you can check if your setup supports bf16:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->python -c &#x27;<span class="hljs-keyword">import</span> transformers; <span class="hljs-keyword">print</span>(f<span class="hljs-string">&quot;BF16 support is {transformers.file_utils.is_torch_bf16_available()}&quot;</span>)&#x27;<!-- HTML_TAG_END --></pre></div>
<p>On the other hand bf16 has a much worse precision than fp16, so there are certain situations where youâ€™d still want to use fp16 and not bf16.</p>
<h5 class="relative group"><a id="bf16-inference" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#bf16-inference"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>bf16 Inference
	</span></h5>

<p>Same as with fp16, you can do inference in either the mixed precision bf16 or using the full bf16 mode. The same caveats apply. For details see <a href="#fp16-inference">fp16 Inference</a>.</p>
<p>In ðŸ¤— Transformers the full bf16 inference is enabled by passing <code>--bf16_full_eval</code> to the ðŸ¤— Trainer.</p>
<h4 class="relative group"><a id="tf32" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#tf32"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>tf32
	</span></h4>

<p>The Ampere hardware uses a magical data type called tf32. It has the same numerical range as fp32 (8-bits), but instead of 23 bits precision it has only 10 bits (same as fp16). In total it uses only 19 bits.</p>
<p>Itâ€™s magical in the sense that you can use the normal fp32 training and/or inference code and by enabling tf32 support you can get up to 3x throughput improvement. All you need to do is to add this to your code:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->import torch
torch<span class="hljs-selector-class">.backends</span><span class="hljs-selector-class">.cuda</span><span class="hljs-selector-class">.matmul</span><span class="hljs-selector-class">.allow_tf32</span> = True<!-- HTML_TAG_END --></pre></div>
<p>When this is done CUDA will automatically switch to using tf32 instead of fp32 where itâ€™s possible. This, of course, assumes that the used GPU is from the Ampere series.</p>
<p>Like all cases with reduced precision this may or may not be satisfactory for your needs, so you have to experiment and see. According to <a href="https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/" rel="nofollow">NVIDIA research</a> the majority of machine learning training shouldnâ€™t be impacted and showed the same perplexity and convergence as the fp32 training.</p>
<p>If youâ€™re already using fp16 or bf16 mixed precision it may help with the throughput as well.</p>
<p>You can enable this mode in the ðŸ¤— Trainer with <code>--tf32</code>, or disable it with <code>--tf32 0</code> or <code>--no_tf32</code>.
By default the PyTorch default is used.</p>
<p>Note: tf32 mode is internal to CUDA and canâ€™t be accessed directly via <code>tensor.to(dtype=torch.tf32)</code> as <code>torch.tf32</code> doesnâ€™t exit.</p>
<p>Note: you need <code>torch&gt;=1.7</code> to enjoy this feature.</p>
<h3 class="relative group"><a id="gradient-checkpointing" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#gradient-checkpointing"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Gradient Checkpointing
	</span></h3>

<p>One way to use significantly less GPU memory is to enabled â€œGradient Checkpointingâ€ (also known as â€œactivation checkpointingâ€). When enabled, a lot of memory can be freed at the cost of small decrease in the training speed due to recomputing parts of the graph during back-propagation.</p>
<p>This technique was first shared in the paper: <a href="https://arxiv.org/abs/1604.06174" rel="nofollow">Training Deep Nets with Sublinear Memory Cost</a>. The paper will also give you the exact details on the savings, but itâ€™s in the ballpark of <code>O(sqrt(n))</code>, where <code>n</code> is the number of feed-forward layers.</p>
<p>To activate this feature in ðŸ¤— Transformers for models that support it, use:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->model.gradient_checkpointing_enable()<!-- HTML_TAG_END --></pre></div>
<p>or add <code>--gradient_checkpointing</code> to the Trainer arguments.</p>
<h3 class="relative group"><a id="batch-sizes" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#batch-sizes"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Batch sizes
	</span></h3>

<p>One gets the most efficient performance when batch sizes and input/output neuron counts are divisible by a certain number, which typically starts at 8, but can be much higher as well. That number varies a lot depending on the specific hardware being used and the dtype of the model.</p>
<p>For example for fully connected layers (which correspond to GEMMs), NVIDIA provides recommendations for <a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#input-features" rel="nofollow">input/output neuron counts</a> and <a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#batch-size" rel="nofollow">batch size</a>.</p>
<p><a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc" rel="nofollow">Tensor Core Requirements</a> define the multiplier based on the dtype and the hardware. For example, for fp16 a multiple of 8 is recommended, but on A100 itâ€™s 64!</p>
<p>For parameters that are small, there is also <a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#dim-quantization" rel="nofollow">Dimension Quantization Effects</a> to consider, this is where tiling happens and the right multiplier can have a significant speedup.</p>
<h3 class="relative group"><a id="dp-vs-ddp" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#dp-vs-ddp"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>DP vs DDP
	</span></h3>

<p><code>DistributedDataParallel</code> (DDP) is typically faster than <code>DataParallel</code> (DP), but it is not always the case:</p>
<ul><li>while DP is python threads-based, DDP is multiprocess-based - and as such it has no python threads limitations, such as GIL</li>
<li>on the other hand a slow inter-connectivity between the GPU cards could lead to an actual slower outcome with DDP</li></ul>
<p>Here are the main differences in the inter-GPU communication overhead between the two modes:</p>
<p><a href="https://pytorch.org/docs/master/notes/ddp.html" rel="nofollow">DDP</a>:</p>
<ul><li>At the start time the main process replicates the model once from gpu 0 to the rest of gpus</li>
<li>Then for each batch:<ol><li>each gpu consumes each own mini-batch of data directly</li>
<li>during <code>backward</code>, once the local gradients are ready, they are then averaged across all processes</li></ol></li></ul>
<p><a href="https://pytorch.org/docs/master/generated/torch.nn.DataParallel.html" rel="nofollow">DP</a>:</p>
<p>For each batch:</p>
<ol><li>gpu 0 reads the batch of data and then sends a mini-batch to each gpu</li>
<li>replicates the up-to-date model from gpu 0 to each gpu</li>
<li>runs <code>forward</code> and sends output from each gpu to gpu 0, computes loss</li>
<li>scatters loss from gpu 0 to all gpus, runs <code>backward</code></li>
<li>sends gradients from each gpu to gpu 0 and averages those</li></ol>
<p>The only communication DDP performs per batch is sending gradients, whereas DP does 5 different data exchanges per batch.</p>
<p>DP copies data within the process via python threads, whereas DDP copies data via <a href="https://pytorch.org/docs/master/distributed.html" rel="nofollow">torch.distributed</a>.</p>
<p>Under DP gpu 0 performs a lot more work than the rest of the gpus, thus resulting in under-utilization of gpus.</p>
<p>You can use DDP across multiple machines, but this is not the case with DP.</p>
<p>There are other differences between DP and DDP but they arenâ€™t relevant to this discussion.</p>
<p>If you want to go really deep into understanding these 2 modes, this <a href="https://www.telesens.co/2019/04/04/distributed-data-parallel-training-using-pytorch-on-aws/" rel="nofollow">article</a> is highly recommended, as it has great diagrams, includes multiple benchmarks and profiler outputs on various hardware, explains all the nuances that you may need to know.</p>
<p>Letâ€™s look at an actual benchmark:</p>
<table><thead><tr><th align="left">Type</th>
<th>NVlink</th>
<th align="right">Time</th></tr></thead>
<tbody><tr><td align="left">2:DP</td>
<td>Y</td>
<td align="right">110s</td></tr>
<tr><td align="left">2:DDP</td>
<td>Y</td>
<td align="right">101s</td></tr>
<tr><td align="left">2:DDP</td>
<td>N</td>
<td align="right">131s</td></tr></tbody></table>
<p>Analysis:</p>
<p>Here DP is ~10% slower than DDP w/ NVlink, but ~15% faster than DDP w/o NVlink</p>
<p>The real difference will depend on how much data each GPU needs to sync with the others - the more there is to sync, the more a slow link will slow down the total runtime.</p>
<p>Here is the full benchmark code and outputs:</p>
<p><code>NCCL_P2P_DISABLE=1</code> was used to disable the NVLink feature on the corresponding benchmark.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600 " title="Copy code excerpt to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->
<span class="hljs-comment"># DP</span>
<span class="hljs-string">rm</span> -<span class="hljs-string">r</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span>; <span class="hljs-string">CUDA_VISIBLE_DEVICES</span>=<span class="hljs-string">0</span>,<span class="hljs-string">1</span> \
<span class="hljs-string">python</span> <span class="hljs-string">examples</span>/<span class="hljs-string">pytorch</span>/<span class="hljs-string">language-modeling</span>/<span class="hljs-string">run_clm</span>.<span class="hljs-string">py</span> \
<span class="hljs-built_in">--model_name_or_path</span> <span class="hljs-string">gpt2</span> <span class="hljs-built_in">--dataset_name</span> <span class="hljs-string">wikitext</span> <span class="hljs-built_in">--dataset_config_name</span> <span class="hljs-string">wikitext-2-raw-v1</span> \
<span class="hljs-built_in">--do_train</span> <span class="hljs-built_in">--output_dir</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span> <span class="hljs-built_in">--per_device_train_batch_size</span> <span class="hljs-string">4</span> <span class="hljs-built_in">--max_steps</span> <span class="hljs-string">200</span>

{<span class="hljs-string">&#x27;train_runtime&#x27;</span>: <span class="hljs-string">110</span>.<span class="hljs-string">5948</span>, <span class="hljs-string">&#x27;train_samples_per_second&#x27;</span>: <span class="hljs-string">1</span>.<span class="hljs-string">808</span>, <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-string">0</span>.<span class="hljs-string">69</span>}

<span class="hljs-comment"># DDP w/ NVlink</span>
<span class="hljs-string">rm</span> -<span class="hljs-string">r</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span>; <span class="hljs-string">CUDA_VISIBLE_DEVICES</span>=<span class="hljs-string">0</span>,<span class="hljs-string">1</span> \
<span class="hljs-string">python</span> -<span class="hljs-string">m</span> <span class="hljs-string">torch</span>.<span class="hljs-string">distributed</span>.<span class="hljs-string">launch</span> <span class="hljs-built_in">--nproc_per_node</span> <span class="hljs-string">2</span> <span class="hljs-string">examples</span>/<span class="hljs-string">pytorch</span>/<span class="hljs-string">language-modeling</span>/<span class="hljs-string">run_clm</span>.<span class="hljs-string">py</span> \
<span class="hljs-built_in">--model_name_or_path</span> <span class="hljs-string">gpt2</span> <span class="hljs-built_in">--dataset_name</span> <span class="hljs-string">wikitext</span> <span class="hljs-built_in">--dataset_config_name</span> <span class="hljs-string">wikitext-2-raw-v1</span> \
<span class="hljs-built_in">--do_train</span> <span class="hljs-built_in">--output_dir</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span> <span class="hljs-built_in">--per_device_train_batch_size</span> <span class="hljs-string">4</span> <span class="hljs-built_in">--max_steps</span> <span class="hljs-string">200</span>

{<span class="hljs-string">&#x27;train_runtime&#x27;</span>: <span class="hljs-string">101</span>.<span class="hljs-string">9003</span>, <span class="hljs-string">&#x27;train_samples_per_second&#x27;</span>: <span class="hljs-string">1</span>.<span class="hljs-string">963</span>, <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-string">0</span>.<span class="hljs-string">69</span>}

<span class="hljs-comment"># DDP w/o NVlink</span>
<span class="hljs-string">rm</span> -<span class="hljs-string">r</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span>; <span class="hljs-string">NCCL_P2P_DISABLE</span>=<span class="hljs-string">1</span> <span class="hljs-string">CUDA_VISIBLE_DEVICES</span>=<span class="hljs-string">0</span>,<span class="hljs-string">1</span> \
<span class="hljs-string">python</span> -<span class="hljs-string">m</span> <span class="hljs-string">torch</span>.<span class="hljs-string">distributed</span>.<span class="hljs-string">launch</span> <span class="hljs-built_in">--nproc_per_node</span> <span class="hljs-string">2</span> <span class="hljs-string">examples</span>/<span class="hljs-string">pytorch</span>/<span class="hljs-string">language-modeling</span>/<span class="hljs-string">run_clm</span>.<span class="hljs-string">py</span> \
<span class="hljs-built_in">--model_name_or_path</span> <span class="hljs-string">gpt2</span> <span class="hljs-built_in">--dataset_name</span> <span class="hljs-string">wikitext</span> <span class="hljs-built_in">--dataset_config_name</span> <span class="hljs-string">wikitext-2-raw-v1</span> \
<span class="hljs-built_in">--do_train</span> <span class="hljs-built_in">--output_dir</span> /<span class="hljs-string">tmp</span>/<span class="hljs-string">test-clm</span> <span class="hljs-built_in">--per_device_train_batch_size</span> <span class="hljs-string">4</span> <span class="hljs-built_in">--max_steps</span> <span class="hljs-string">200</span>

{<span class="hljs-string">&#x27;train_runtime&#x27;</span>: <span class="hljs-string">131</span>.<span class="hljs-string">4367</span>, <span class="hljs-string">&#x27;train_samples_per_second&#x27;</span>: <span class="hljs-string">1</span>.<span class="hljs-string">522</span>, <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-string">0</span>.<span class="hljs-string">69</span>}<!-- HTML_TAG_END --></pre></div>
<p>Hardware: 2x TITAN RTX 24GB each + NVlink with 2 NVLinks (<code>NV2</code> in <code>nvidia-smi topo -m</code>)
Software: <code>pytorch-1.8-to-be</code> + <code>cuda-11.0</code> / <code>transformers==4.3.0.dev0</code></p>
<h3 class="relative group"><a id="dataloader" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#dataloader"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>DataLoader
	</span></h3>

<p>One of the important requirements to reach great training speed is the ability to feed the GPU at the maximum speed it can handle. By default everything happens in the main process and it might not be able to read the data from disk fast enough, and thus create a bottleneck, leading to GPU under-utilization.</p>
<ul><li><code>DataLoader(pin_memory=True, ...)</code> which ensures that the data gets preloaded into the pinned memory on CPU and typically leads to much faster transfers from CPU to GPU memory.</li>
<li><code>DataLoader(num_workers=4, ...)</code> - spawn several workers to pre-load data faster - during training watch the GPU utilization stats and if itâ€™s far from 100% experiment with raising the number of workers. Of course, the problem could be elsewhere so a very big number of workers wonâ€™t necessarily lead to a better performance.</li></ul>
<h3 class="relative group"><a id="faster-optimizer" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#faster-optimizer"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Faster optimizer
	</span></h3>

<p>pytorch-nightly introduced <code>torch.optim._multi_tensor</code> which should significantly speed up the optimizers for situations with lots of small feature tensors. It should eventually become the default, but if you want to experiment with it sooner and donâ€™t mind using the bleed-edge, see: <a href="https://github.com/huggingface/transformers/issues/9965" rel="nofollow">https://github.com/huggingface/transformers/issues/9965</a></p>
<h3 class="relative group"><a id="sparsity" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#sparsity"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Sparsity
	</span></h3>

<h4 class="relative group"><a id="mixture-of-experts" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#mixture-of-experts"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Mixture of Experts
	</span></h4>

<p>Quite a few of the recent papers reported a 4-5x training speedup and a faster inference by integrating
Mixture of Experts (MoE) into the Transformer models.</p>
<p>Since it has been discovered that more parameters lead to better performance, this technique allows to increase the number of parameters by an order of magnitude without increasing training costs.</p>
<p>In this approach every other FFN layer is replaced with a MoE Layer which consists of many experts, with a gated function that trains each expert in a balanced way depending on the input tokenâ€™s position in a sequence.</p>
<p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/perf-moe-transformer.png" alt="MoE Transformer 2x block"></p>
<p>(source: <a href="https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html" rel="nofollow">GLAM</a>)</p>
<p>You can find exhaustive details and comparison tables in the papers listed at the end of this section.</p>
<p>The main drawback of this approach is that it requires staggering amounts of GPU memory - almost an order of magnitude larger than its dense equivalent. Various distillation and approaches are proposed to how to overcome the much higher memory requirements.</p>
<p>There is direct trade-off though, you can use just a few experts with a 2-3x smaller base model instead of dozens or hundreds experts leading to a 5x smaller model and thus increase the training speed moderately while increasing the memory requirements moderately as well.</p>
<p>Most related papers and implementations are built around Tensorflow/TPUs:</p>
<ul><li><a href="https://arxiv.org/abs/2006.16668" rel="nofollow">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li>
<li><a href="https://arxiv.org/abs/2101.03961" rel="nofollow">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</a></li>
<li><a href="https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html" rel="nofollow">GLaM: Generalist Language Model (GLaM)</a></li></ul>
<p>And for Pytorch DeepSpeed has built one as well: <a href="https://www.deepspeed.ai/tutorials/mixture-of-experts/" rel="nofollow">Mixture of Experts</a> - blog posts:  <a href="https://www.microsoft.com/en-us/research/blog/deepspeed-powers-8x-larger-moe-model-training-with-high-performance/" rel="nofollow">1</a>, <a href="https://www.microsoft.com/en-us/research/publication/scalable-and-efficient-moe-training-for-multitask-multilingual-models/" rel="nofollow">2</a> and specific deployment with large transformer-based natural language generation models: <a href="https://www.deepspeed.ai/news/2021/12/09/deepspeed-moe-nlg.html" rel="nofollow">blog post</a>, <a href="Thttps://github.com/microsoft/Megatron-DeepSpeed/tree/moe-training">Megatron-Deepspeed branch</a>.</p>
<h2 class="relative group"><a id="contribute" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#contribute"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Contribute
	</span></h2>

<p>This document is far from being complete and a lot more needs to be added, so if you have additions or corrections to make please donâ€™t hesitate to open a PR or if you arenâ€™t sure start an Issue and we can discuss the details there.</p>
<p>When making contributions that A is better than B, please try to include a reproducible benchmark and/or a link to the source of that information (unless it comes directly from you).</p>


		<script type="module" data-hydrate="7x2vh5">
		import { start } from "/docs/transformers/v4.15.0/en/_app/start-c4963074.js";
		start({
			target: document.querySelector('[data-hydrate="7x2vh5"]').parentNode,
			paths: {"base":"/docs/transformers/v4.15.0/en","assets":"/docs/transformers/v4.15.0/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/transformers/v4.15.0/en/_app/layout.svelte-ba4f65ca.js"),
						import("/docs/transformers/v4.15.0/en/_app/pages/performance.mdx-75233f39.js")
				],
				url: new URL("http://sveltekit-prerender/docs/transformers/v4.15.0/en/performance"),
				params: {}
			}
		});
	</script>
<!-- HTML_TAG_END --></div>
				<div class="SVELTE_HYDRATER contents" data-target="DocFooterNav" data-props="{&quot;classNames&quot;:&quot;mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32&quot;,&quot;chapterPrev&quot;:{&quot;title&quot;:&quot;Using tokenizers from ðŸ¤— Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fast_tokenizers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/fast_tokenizers&quot;},&quot;chapterNext&quot;:{&quot;title&quot;:&quot;Model Parallelism&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;parallelism&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.15.0/en/parallelism&quot;},&quot;isCourse&quot;:false,&quot;isLoggedIn&quot;:true}"><div class="mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32"><a href="/docs/transformers/v4.15.0/en/fast_tokenizers" class="mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300"><span class="mr-2 translate-y-px">â†</span>Using tokenizers from ðŸ¤— Tokenizers</a>
	<a href="/docs/transformers/v4.15.0/en/parallelism" class="ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300">Model Parallelism<span class="ml-2 translate-y-px">â†’</span></a></div></div></div></div>
		<div class="sticky top-0 self-start"><div class="SVELTE_HYDRATER contents" data-target="SubSideMenu" data-props="{&quot;chapter&quot;:{&quot;title&quot;:&quot;Performance and Scalability: How To Fit a Bigger Model and Train It Faster&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;performance-and-scalability-how-to-fit-a-bigger-model-and-train-it-faster&quot;,&quot;url&quot;:&quot;#performance-and-scalability-how-to-fit-a-bigger-model-and-train-it-faster&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Quick notes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quick-notes&quot;,&quot;url&quot;:&quot;#quick-notes&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Faster Training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;faster-training&quot;,&quot;url&quot;:&quot;#faster-training&quot;},{&quot;title&quot;:&quot;Bigger Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bigger-models&quot;,&quot;url&quot;:&quot;#bigger-models&quot;}]},{&quot;title&quot;:&quot;Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;hardware&quot;,&quot;url&quot;:&quot;#hardware&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Multi-GPU Connectivity&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;multigpu-connectivity&quot;,&quot;url&quot;:&quot;#multigpu-connectivity&quot;},{&quot;title&quot;:&quot;NVlink&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;nvlink&quot;,&quot;url&quot;:&quot;#nvlink&quot;}]},{&quot;title&quot;:&quot;Software&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;software&quot;,&quot;url&quot;:&quot;#software&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Anatomy of Model's Operations&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;anatomy-of-models-operations&quot;,&quot;url&quot;:&quot;#anatomy-of-models-operations&quot;},{&quot;title&quot;:&quot;Anatomy of Model's Memory&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;anatomy-of-models-memory&quot;,&quot;url&quot;:&quot;#anatomy-of-models-memory&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Model Weights&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model-weights&quot;,&quot;url&quot;:&quot;#model-weights&quot;},{&quot;title&quot;:&quot;Optimizer States&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;optimizer-states&quot;,&quot;url&quot;:&quot;#optimizer-states&quot;},{&quot;title&quot;:&quot;Gradients&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;gradients&quot;,&quot;url&quot;:&quot;#gradients&quot;},{&quot;title&quot;:&quot;Forward Activations&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;forward-activations&quot;,&quot;url&quot;:&quot;#forward-activations&quot;},{&quot;title&quot;:&quot;Temporary Memory&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;temporary-memory&quot;,&quot;url&quot;:&quot;#temporary-memory&quot;},{&quot;title&quot;:&quot;Functionality-specific memory&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;functionalityspecific-memory&quot;,&quot;url&quot;:&quot;#functionalityspecific-memory&quot;}]},{&quot;title&quot;:&quot;`forward` vs `backward` Execution Speed&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;forward-vs-backward-execution-speed&quot;,&quot;url&quot;:&quot;#forward-vs-backward-execution-speed&quot;},{&quot;title&quot;:&quot;Floating Data Types&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;floating-data-types&quot;,&quot;url&quot;:&quot;#floating-data-types&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;fp16&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fp16&quot;,&quot;url&quot;:&quot;#fp16&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;fp16 caching&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fp16-caching&quot;,&quot;url&quot;:&quot;#fp16-caching&quot;},{&quot;title&quot;:&quot;fp16 Inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fp16-inference&quot;,&quot;url&quot;:&quot;#fp16-inference&quot;}]},{&quot;title&quot;:&quot;bf16&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bf16&quot;,&quot;url&quot;:&quot;#bf16&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;bf16 Inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bf16-inference&quot;,&quot;url&quot;:&quot;#bf16-inference&quot;}]},{&quot;title&quot;:&quot;tf32&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tf32&quot;,&quot;url&quot;:&quot;#tf32&quot;}]},{&quot;title&quot;:&quot;Gradient Checkpointing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;gradient-checkpointing&quot;,&quot;url&quot;:&quot;#gradient-checkpointing&quot;},{&quot;title&quot;:&quot;Batch sizes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;batch-sizes&quot;,&quot;url&quot;:&quot;#batch-sizes&quot;},{&quot;title&quot;:&quot;DP vs DDP&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;dp-vs-ddp&quot;,&quot;url&quot;:&quot;#dp-vs-ddp&quot;},{&quot;title&quot;:&quot;DataLoader&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;dataloader&quot;,&quot;url&quot;:&quot;#dataloader&quot;},{&quot;title&quot;:&quot;Faster optimizer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;faster-optimizer&quot;,&quot;url&quot;:&quot;#faster-optimizer&quot;},{&quot;title&quot;:&quot;Sparsity&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sparsity&quot;,&quot;url&quot;:&quot;#sparsity&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Mixture of Experts&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;mixture-of-experts&quot;,&quot;url&quot;:&quot;#mixture-of-experts&quot;}]}]},{&quot;title&quot;:&quot;Contribute&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;contribute&quot;,&quot;url&quot;:&quot;#contribute&quot;}]}}">

<nav class="hidden h-dvh w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pb-16 pl-6 pr-10 pt-24 text-sm lg:flex 2xl:w-[305px]">

<a href="#performance-and-scalability-how-to-fit-a-bigger-model-and-train-it-faster" class=" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-performance-and-scalability-how-to-fit-a-bigger-model-and-train-it-faster"><!-- HTML_TAG_START --><wbr>Performance and <wbr>Scalability: <wbr>How <wbr>To <wbr>Fit a <wbr>Bigger <wbr>Model and <wbr>Train <wbr>It <wbr>Faster<!-- HTML_TAG_END --></a>
	

<a href="#quick-notes" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-quick-notes"><!-- HTML_TAG_START --><wbr>Quick notes<!-- HTML_TAG_END --></a>
			

<a href="#faster-training" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-faster-training"><!-- HTML_TAG_START --><wbr>Faster <wbr>Training<!-- HTML_TAG_END --></a>
					

<a href="#bigger-models" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-bigger-models"><!-- HTML_TAG_START --><wbr>Bigger <wbr>Models<!-- HTML_TAG_END --></a>
					

<a href="#hardware" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-hardware"><!-- HTML_TAG_START --><wbr>Hardware<!-- HTML_TAG_END --></a>
			

<a href="#multigpu-connectivity" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-multigpu-connectivity"><!-- HTML_TAG_START --><wbr>Multi-GP<wbr>U <wbr>Connectivity<!-- HTML_TAG_END --></a>
					

<a href="#nvlink" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-nvlink"><!-- HTML_TAG_START -->N<wbr>Vlink<!-- HTML_TAG_END --></a>
					

<a href="#software" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-software"><!-- HTML_TAG_START --><wbr>Software<!-- HTML_TAG_END --></a>
			

<a href="#anatomy-of-models-operations" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-anatomy-of-models-operations"><!-- HTML_TAG_START --><wbr>Anatomy of <wbr>Model's <wbr>Operations<!-- HTML_TAG_END --></a>
					

<a href="#anatomy-of-models-memory" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-anatomy-of-models-memory"><!-- HTML_TAG_START --><wbr>Anatomy of <wbr>Model's <wbr>Memory<!-- HTML_TAG_END --></a>
					

<a href="#model-weights" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-model-weights"><!-- HTML_TAG_START --><wbr>Model <wbr>Weights<!-- HTML_TAG_END --></a>

<a href="#optimizer-states" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-optimizer-states"><!-- HTML_TAG_START --><wbr>Optimizer <wbr>States<!-- HTML_TAG_END --></a>

<a href="#gradients" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-gradients"><!-- HTML_TAG_START --><wbr>Gradients<!-- HTML_TAG_END --></a>

<a href="#forward-activations" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-forward-activations"><!-- HTML_TAG_START --><wbr>Forward <wbr>Activations<!-- HTML_TAG_END --></a>

<a href="#temporary-memory" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-temporary-memory"><!-- HTML_TAG_START --><wbr>Temporary <wbr>Memory<!-- HTML_TAG_END --></a>

<a href="#functionalityspecific-memory" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-functionalityspecific-memory"><!-- HTML_TAG_START --><wbr>Functionality-specific memory<!-- HTML_TAG_END --></a>

<a href="#forward-vs-backward-execution-speed" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-forward-vs-backward-execution-speed"><!-- HTML_TAG_START -->`forward` vs `backward` <wbr>Execution <wbr>Speed<!-- HTML_TAG_END --></a>
					

<a href="#floating-data-types" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-floating-data-types"><!-- HTML_TAG_START --><wbr>Floating <wbr>Data <wbr>Types<!-- HTML_TAG_END --></a>
					

<a href="#fp16" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-fp16"><!-- HTML_TAG_START -->fp16<!-- HTML_TAG_END --></a>

<a href="#bf16" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-bf16"><!-- HTML_TAG_START -->bf16<!-- HTML_TAG_END --></a>

<a href="#tf32" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-tf32"><!-- HTML_TAG_START -->tf32<!-- HTML_TAG_END --></a>

<a href="#gradient-checkpointing" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-gradient-checkpointing"><!-- HTML_TAG_START --><wbr>Gradient <wbr>Checkpointing<!-- HTML_TAG_END --></a>
					

<a href="#batch-sizes" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-batch-sizes"><!-- HTML_TAG_START --><wbr>Batch sizes<!-- HTML_TAG_END --></a>
					

<a href="#dp-vs-ddp" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-dp-vs-ddp"><!-- HTML_TAG_START -->D<wbr>P vs DDP<!-- HTML_TAG_END --></a>
					

<a href="#dataloader" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-dataloader"><!-- HTML_TAG_START --><wbr>Data<wbr>Loader<!-- HTML_TAG_END --></a>
					

<a href="#faster-optimizer" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-faster-optimizer"><!-- HTML_TAG_START --><wbr>Faster optimizer<!-- HTML_TAG_END --></a>
					

<a href="#sparsity" class="pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-sparsity"><!-- HTML_TAG_START --><wbr>Sparsity<!-- HTML_TAG_END --></a>
					

<a href="#mixture-of-experts" class="pl-12 text-xs text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-mixture-of-experts"><!-- HTML_TAG_START --><wbr>Mixture of <wbr>Experts<!-- HTML_TAG_END --></a>

<a href="#contribute" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-contribute"><!-- HTML_TAG_START --><wbr>Contribute<!-- HTML_TAG_END --></a>
			</nav></div></div></div>
	<div id="doc-footer"></div></main>

	</div>

		<script>
			import("\/front\/build\/kube-0ad51e9\/index.js");
			window.moonSha = "kube-0ad51e9\/";
			window.__hf_deferred = {};
		</script>

		<!-- Stripe -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				const script = document.createElement("script");
				script.src = "https://js.stripe.com/v3/";
				script.async = true;
				document.head.appendChild(script);
			}
		</script>
	</body>
</html>
