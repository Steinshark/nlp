okay so I did see this tweet I saw this tweet right I saw this thing right here where it's just like you you don't use 10% of your brain do I use this and so bend is apparently a simple a simple language that allows you to write feels like python but also scales like uh like Cuda uh need a sorting Network just write a function Vim sort. Bend sorting Network oh gosh come on let me see it need a fragment just write a function I wish I could pause this let's look at this for a second because this looks pretty cool all right so let's see def sort tree this this this and this rots I don't know what rots are hold on hold on hold on DS okay damn it it looks like python which means there's no type so I have no clue what the hell's going on here D is zero that must be depth which is the tree sorting Network equals just rotate trees okay okay tree equals XY so that must be left and right so this is a binary tree uh left is sort depth minus one okay so we're starting from the bottom uh with x s is zero I don't know what s is where is s even used here oh s must be is used in this R in this rots right is D minus one okay I don't really I don't quite honestly to tell you the truth I don't really get it I don't I don't really get this function there's like a warp a down I I I don't know what we're doing here uh rotate so this must be a well-known algorithm that I just don't that I don't I know but I just don't get it okay well it sounds cool I just don't know how how would you parallelize this that's my question is how is this parallelized that's what I want to go find out and so let's see if this let's see if this thing does it because there is a fireship video which we'll look at here shortly but I want to know can I understand this from this perspective shaders are always just shaders have always just been magic to me there you go here's a bunch of math you do it on a per pixel basis right dude I I've never understand create a pixel tree why is everything a tree are pixels trees create a pixel tree uh Bend D equals zero and I oh is Bend where okay is that is that how you say hey this thing is going to be a color go okay I don't know what go does and it I think it has a a definition of go so we don't know what go does need a fast map reduce just write a function okay I I mean I love this idea by the way that you can just go Lambda do this this one map red Bam Bam Bam and you just go and it just does it and it it it makes it multi-threaded I just don't how does it do mutations cuz that original tree one does a tree sorting how does it do mutations I don't understand that interesting okay let's go back to let's let's go back to the GitHub repo and um because I mean honestly this feels like V you know what I mean this feels too good to be true I don't know if you've ever seen this but whenever I see this things it always just feels too good to be true so I just feel like it's a lie I'm sure that's just me being jaded right because here here's the thing that I don't understand is how did they make it so whoever made this language how did you make it so simple to be massively parallel with mutations especially when something like Mojo is trying to do the same thing it's totally real okay it's totally real right like Mojo's attempting to do the same thing a Fearless parallelism I know I fear fear parallelism okay I fear it Mojo is different though well I know Mojo of course Mojo is different but Mojo is attempting to make python fast as well I know don't worry we like to look at the GitHub thing okay it it makes it more fun to start with the GitHub thing and like and and and read about it and and have an idea going into it you know what I mean um so it must be things that run on the cudas right uh if you want to use the C runtime install the C compiler okay if you want to use the Cuda runtime install the Cuda toolkit uh all right all right then install both hvm 2 and bend with this one okay cargo nice okay nice rust mentioned rust mentioned uh then finally write some Bend files okay uses the rust interpreter wait what wait what uses the C interpreter parallel uses the uh Cuda interpreter massively parallel okay interesting interesting you can also compile Bend Standalone C Cuda files into gen C and gen Cuda uh for maximum performance but keep in mind our code gen is still in its infancy it's nowhere near as mature as so these nuts compilers like GCC and GHC interesting interesting interesting all right let's read about this parallel programming and bend to write a parallel program and bend all you have to do is nothing other than making it inherently sequential for example let's see cannot run in parallel because four depends on three which depends on two yes uh let's see can run in parallel and that can run in parallel are independent and it will per B's fundamental pledge everything that can run in parallel will run in parallel interesting okay okay let's look at the tree example there we go for a more complete example here's that tree thing which I just don't understand this file implements the batonic sorder with immutable tree rotations okay so there you go so it creates copies there you go that was see okay that was my question was the was the copy was the copy uh it is not the kind of algorithm you'd expect to run fast on gpus yet since it uses divide and conquer approach which is inherently parallel yep uh Bend will run it in multi-threaded so the benchmarks 16,000 threads oh my goodness that's just just mindboggling these nuts uh that's a 50x a 57x speed up doing nothing uh no thread spawning no explicit management of locks mutases uh yes by the way they're called mutases which should be close they really should be called M mutil lisks okay because you think you like muisk and you know you just can't have one so you got to have like thousands of mutil lisks but then one effing threadlock IE whatever you call those Raven bombs just destroys your entire your just entire fleet every single time that's called why it should be called the mutases this is why mutil lisks mutes same thing it's a trap Learn Python oh let's see what are your thoughts on MDD meme driven development um shockingly HTM X felt like meme driven development and it actually wasn't it turns out it was actually it was actually it's actually just real it's just real development I hate bench marks generally I dislike benchmarks because I don't know what any of these things mean um but it's cool that it like I like relative benchmarks which I think is I think relative benchmarks are very interesting I think absolute benchmarks are stupid like I wouldn't go into this thinking I'm going to get something that's super fast what I can say is that doing nothing other than changing where you run it it just gets faster because relative makes a lot of sense cuz then I can I can compare this against this and be like yeah that's this shit's way faster though why would you do uh relative benchmarks relative benchmarks show that this like that long as you know long as they're comparing the output and proving that the output is sound that you get a massive speed up a practically 100x speed up by just swapping over into this right so that's really cool uh but a Bend isn't limited to a specific Paradigm like tenters or matrices any concurrent system from shaders to llang actor models can be emulated on Bend for example to render images in real time we could simply allocate any immutable Tree on each frame okay so I wonder I wonder what the GC is like I would like to see more on the GC and how what how that runs because that's I guess that's my big thing is how are they doing memory allocation uh it let's see it would actually work even uh okay so this is that that demo Shader which is pretty interesting um even let's see even involved algorithms uh parallelize well on Bend longdistance communication is performed by global beta reduction as per the uh interaction calculus and synchronized correct corly uh and efficiently by hvm 2's Atomic Linker interesting okay it is very important to reinforce that while let's see that while Ben does what it uh it was built to scale performance with cores up to 10,000 concurrent threads its single core performance is extremely subpar okay yeah uh this is the first version of the system and we haven't put much effort into the proper compiler yet that makes sense I think that's a good I think that's a great great approach by the way great approach right here um you can expect the raw performance to substantially improve on every release uh as we work towards a proper Cod gen including constellation of missing optimizations yeah meanwhile you can uh you can use the interpreters today to have a glimpse of the massively parallel programs look like from the lens of a pythonic highle language this is a super promising language if this is real I guess there's two things we could do one if if the person who is in the chat is in the chat we could get whoever the Creator is to give us like uh if if they would like uh they could give us like a a a five minute explanation of how this is accomplished and all those things cuz it sounds like it's all immutable so it's all it it works via allocations like you can do anything that's parallelized uh via allocations if I'm not mistaken and are the allocations are they like R seed are they all stack allocations for that for like the tree sorder how does it work with Heap allocations is it a is it a garbage collection I don't know uh PR I would literally never make my own language uh is it hoarding memory is it a bump allocator just let it go straight to the universe I do not know right there's like there's a lot of questions there that I think it uh it mentions rendering and shaders it does me it does that it does do that yes okay so this was really cool so let's just check out the fireship bend video okay nice nice yesterday the clouds opened up and a weird new programming language came down to earth with a promise of parallelism for Alou who writeth code this is big if true because parallel Computing is a superpower it allows a programmer to take a problem that could be solved in a week and instead solve it in seven days using seven different computers unfortunately running I mean that's typically how parallelism ends up happening parallelism is extremely hard that's why this language is so interesting is that it is crazy to think that there is something that could actually solve the parallelism problem right it is it is Wild is always on point Banger absolute Banger meme right there code in parallel is like conducting a symphony one wrong note and the entire thing becomes a total disaster but luckily Bend offers Hope by making a bold promise everything that can run in parallel will run in parallel you don't need to know anything about Cuda blocks locks mutexes or regex's to write algorithms that take advantage of all 24 of your CPU cores or even all 16,000 of your GPU cores you just write some highlevel python looking code and the rest is Magic it is May 17th 2024 it feels untrue that's what I mean like because it just feels so amazing that that that this could possibly exist it feels untrue I I'm curious what the rules are and how how the rules are going to play I'm also curious why I guess I'm not too curious why it went with python style syntax it just makes sense right if you're going to make a language like this that you want to be massively parallelized and you want it to really I mean your your your target is going to be machine learningdata scientist and so it makes perfect sense that it exists uh that it exists in this python yeah I'm curious about the edge cases like what breaks parallelism and you're watching the code report when you write code in a language like python your code runs on a single thread that means only one thing can happen at a time it's like going to a KFC with only one employee who takes the order cleans the toilets and Cooks the food in that order now on a modern CPU you might have a clock cycle around 4 GHz and if it's handling one instruction per cycle you're only able to perform 4 billion instructions per second now if four Gibs is not enough you can modify your python code to take advantage of multiple threads but it adds a lot of complexity to your code and there you know the whole thread start thread joint thing this is just so difficult called you know I know this looks easy and every why is every single multi-threaded application example so simple but every multi-threaded actual application is so dang hard it's just it just feels it feels emotionally damaging every single time every single time you like but I remember I still to this day remember my very first four years into multi-threaded programming and it always felt so easy it's just like look you just do this you just do this and then you just join it at the end and I'm like ah that seems pretty simple that seems straightforward and then I actually do it and I go this wasn't straightforward at all and I don't know what's happening and now I have a synchronize everywhere in my Java code you know it's just it's just it's just the worst it sounds like skill issues it is skill issues because it's effing hard I don't have the skills to pay the bills on threads okay and debugging is awful debugging is always awful there's all kinds of gotas like race conditions Deadlocks thread starvation and I mean Deadlocks are still completely available in uh in async a I the rust asyn a we because rust async a we is pull versus javascripts push uh you you run into Deadlocks because you don't know what you're doing you know the worst part is is in like especially in Rust if you have an error that you just simply want to ignore you do an under you just simply assign it to underscore the problem is is that as you're programming and then you change the API the API to a weight or to an async function and then you don't realize that your underscore uh assignment also will ignore async and it won't give you a warning and then you just explode you have no idea why and you're deadlocking for days and it's just like oh man oh man oh man that is just there just just just the worst it's just the worst for those that don't understand it um it's the uh uh main RS right where you have something that looks like this uh what is it funk main me Daddy and then you have something like uh what is it async uh FN uh Fu that returns a result you know I don't know why not there we go and it does this and I don't even have an LSP so I don't even know why it's doing this right so we'll just go like this um okay right there we go we return that and you do uh Fu there we go so by doing this it's going to call it and it's going to just simply ignore the fact that this is a future and you have to you have to await it if you don't await a future it it don't work and so it's like that will just simply ignore it and so I've had so many times in my life where I was programming something realized I need to go to async because again every single time you're in the world of async uh you have this whole problem which I think we all know about this whole problem but just to make sure we all do we go to Ryan Winchester's profile and look at his pin tweet right here you have this whole problem where you have all of your functions come together one of them's async and now you got all of them async all of them become async immediately you forget you've done that you've ignored an error and boom you've now just ignored an async call and now your acing call never runs and then you're emotionally bruised every single time every single time oh my goodness I just hate it anyways it's happened once before that's why I actually never ignore errors now I like the the underscore assignment was a mistake I think it was genuinely a mistake in Rust because it can lead you into this why don't you just have all your functions be acing shut up Marcos red starvation and may even lead to conflicts with demons even if you do manage to get it working you might find that your CP just doesn't have enough juice at which point you look into using the thousands of cacor on your GPU but now you'll need to write some C++ code and likely blow your leg off in the process well what if there's a language that just knew how to run things in parallel by default that's the promise of Bend imagine we have a computation that adds two completely random numbers together in Python The Interpreter you can tell he's a man of culture okay you can just see the man of culturing right here totally random numbers completely random culturally appropriate numbers together in Python The Interpreter is going to convert this into B code and then eventually run it on the python virtual machine pretty simple but in Bend things are a little more complex the elements of the computation are structured into a graph which are called interaction combinators you can think of it as a big network of all the this guy writes askal you can just tell right away zero information about the person but from the GitHub said the word calculus and I didn't see any integrals and then also here we see the word combinator again this hasal mentioned this is hascal mentioned for sure this is hasal mentioned pick pick is Ben here big fan here thank you white papers mentioned white papers are happening as we speak computations that need to be done when two nodes run into each other the computation progresses by following a simple set of rules that rewrite the computation in a way that can be done in parallel okay so if you're tip to tip you becomeing Infinity but if you're tipto tip fully colored in you become two lines but then if you're tip to tip but one's only full then you become definitely the infinity sign just poorly drawn I don't know what this means I don't know I this pattern until all computations are done it then merges the result back into whatever expression was returned from the function this concept of interaction combinators goes all the way back to the 1990s and is implemented in a runtime called the higher order virtual machine hbm is not meant to be used directly and that it is above your pay grade I must say that at this point in programming since I've never I've never been a big Lambda calculus dork I I I just don't understand these Concepts or even the vernacular behind it uh you know it's it's like that guy that doesn't have compiler experience and walks in and keeps calling everything a compiler when it's a transpiler but then when you actually get around people whose like job it is to write these things you know how vacular bothers them when you use it incorrectly for me I'm just like L to calculus what the [ __ ] is this right and they're like well you're not using the terms right you know and people understand like people will start being like ah you're you know I can tell you're new and you can tell I'm new because of that this ism is not meant to be used directly and that's why they build bend a highle language to interface with it and the language itself is implemented in Rust you can tell right away that's why it's so good tax is very similar to Python and we can write a Hello World by defining a main function that returns a string now to execute this code we can pull up the terminal and use the Ben run command by default this is going to that's single threaded rust interpreter correct yeah use the rust interpreter which will execute it sequentially just like any other boring language but now here's where things get interesting imagine we have an algorithm why aliens why aliens pre-at come on it's because I read the GitHub this is why we read the GitHub first okay because the next one is then if you build it with a c you get to run it on all of your little nodes and then if you build it with the CU the C the cudas you get to run it on all your cudas get interesting imagine we have an algorithm that needs to count a bunch of numbers and then add them together the first thing that might blow your mind is that bend does not have loops like we can't just do a for Loop like we would in Python instead then has something entirely different called a fold that works like a search and replace for data types and any algorithm that requires a loop can be replaced with a fold basically a fold allows you to consume recursive data types in parallel like a list or a tree but first we need to construct a recursive data type and for that we have the bend keyword which is like the opposite of fold now if that's a little too mindbending maybe check out my back catalog okay so I actually got lost in the sauce there for a second I'm not going to lie to you I feel like Mark I feel like Mark Cuban right now and being like Oh you said fold therefore I'm out and I'm not g and I'm not going to lie to you when I saw all those cans going might have got might have got a little distracted by the cans as opposed to what was actually happening okay so a fold I feel like I get a fold is just a function that produces out a fold is just reduced for the those that are just JavaScript kitties that's all it is fold is just simply reduce and this is like your seed value typically is the one right here and then you you you like go up it right it's just going over a list reducing it it's it's a I believe they use the term opposite thing the bend is a value that goes into a l I'm not see that's where I I I start losing it you can't use wrinkle brain vocabulary on Twitch you really can't use wrinkle brain vocab can be replaced with a fold basically a fold allows you to consume recursive data types and parallel like a list a recursive data type yet just like a list it's something that you can walk across via recursion to get to get to the end of okay which means you could also use a tree you could also use a graph with a a DFS okay okay I think we're starting to see it confirmed pict was a mistake confirmed pick is a mistake list or a tree but first we need to construct a recursive data type and for that we have the bend keyword which is like the opposite of fold now if that's a little too mind-bending maybe check out my back catalog for recursion in 100 seconds but now let's see what this looks like from a performance standpoint when I try to run this algorithm on a single thread it takes forever like 10 minutes or more however I can run the same code without any modification whatsoever with the bend run C command when I do that it's now utilizing all 24 threads on my CPU and now it only takes about 30 seconds to run the computation that's a huge Improvement but I think we can still do better because I'm a baller I have an Nvidia RTX 490 and once again I can run this code without any modification on Cuda with Bend run- cuu and now this code only takes one and 1 half seconds to run and I'll just go ahead and drop the mic right there this has been the code report thanks for watching and I will see you in the next one very cool okay okay so this looks totally awesome and I absolutely think it's fantastic but I do want to say something okay I'm going to say something and I hope that you guys don't get upset at me everyone virtually in this chat will never use this language Let Me Tell You Why this is the case this is the case because this language is specifically designed for people that have what we refer to as an adult education in mathematics okay you most of you guys are a bunch of front end andies right in react like this isn't going to come to the front end and be useful like that this isn't going to come into your server and be just instantaneously useful on your server okay this is just going to be useful for people performing like linear algebra and all that stuff and they just want fast python they want Loops that don't suck ass and that's called pandas or it's called C this whatever this is okay I don't use it either this isn't going to be useful for me either okay I it's it's absolutely super duper awesome and the speed and the glory of it is fantastic and the fact that you can use the term calculus and not use an integral at the exact same time makes it just mindblowing for me okay I don't get it but that here we are here we are doing these things and it just feels fantastic it feels amazing when you look at this language you think how could this not be the language we all use this is truly the Lord's language it requires folds and bends and [ __ ] in reality that does not make any sense and yet here we are realizing that all we're going to be doing is writing simple stuff on the front end or the back end and it's just not going to be for you it's not for you it's not been for you it not it will not be for you in the future so just be okay with it okay instead learn rust learn go learn JavaScript learn o camel learn Elixir learn Swift and enjoy your day okay the name is I'm sorry but this is fantastic but at the exact same time you'll probably never use it again but by the way there will be people that do use it and they will love it and it'll be fantastic just not for your use case okay just probably use Elixir or something like that