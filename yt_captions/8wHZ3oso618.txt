automatic facial expression recognition is the ability of a machine usually a computer to automatically recognize expressions of emotion or expressions of social signals basically facial displays that we make smiling um by a computer so it's inherently a computer vision problem it's inherently a problem of turning pixels from the that are captured by camera into symbol such as this person is smiling this person is blinking this person is nodding their head that's what facial expression recognition is all about you can speak of a general pipeline a general processing pipeline of problems that you need to solve in order to get to that final smile detection that you can find now in most consumer cameras actually so the first problem that you need to solve is you need to know where the face is of course if the face is uh not found at all then you don't even know what you're processing right so you have to start by locating the phas um that's done with a process called face detection funnily enough and once you have found that there might be a problem that um people's faces have different shapes you may have found a very big shape face you may have found a very small face the face may have been tilted so you need to go through a process called phase alignment or face registration at at which you sort of remove differences between subjects between different people such as Identity or the size of somebody's uh face in general and you can remove variations that are caused within that subject because they move their head or they um it's mostly mostly head pose actually and the way we do that generally is by first finding a number of points on the face and now we basically divide the points on the face in two types one is types of uh one is points that do move when you express so like my mouth Corners when I smile they will go up and out uh and then there's also facial points that do not move when you when you express or barely so that's the your inner eye Corners your outer eye Corners your nose I mean if you look very carefully and I flare my nost strolls you could you could see the move but they generally don't uh so you've got stable points those are your inner eye Corners your outer eye Corners the points around your nose and if you use those you can remove any rotations any scaling and positioning of course of the face once you're done with that then comes sort of the the real interesting computer vision problems and that is feature extraction so imagine you've got a 200x 200 pixel area around the face each of those those pixels can have 256 different values if we're just talking about gray skill so that's not even taking color into account uh that means you have a very large search space very large space of possible values within uh that image and that's too high so classical machine learning so this is the the the the part that will automatically learn uh whether there a smile or not cannot deal with such a immense search space so we need to lower that because that's uh 256 * 200 * 200 right it is so there's two things you can do you first of all you want to lower that amount uh of variability and also you want to only capture variations that are caused by expressions and you want to do away with any variation that's caused by for example Identity or illumination variation right so there's all kinds of different techniques basically you can you can split them into two groups one of them is based on geometric features and geometric features are features that are calculated uh from facial points remember we had the facial points U the stable points on the nose and the eyes that did not move with expression but the other ones uh they do move with expression so my mouth Corners move with expression and for example if you wanted to know whether I was smiling you would just look at these two points and if they go out and up relatively to all the other facial points you can say that I'm smiling with some degree of certainty and so that's a geometric fish point and you can also look at appearance appearance basically means um the type of wrinkles we have it's also includes color uh so you can if I frown you get all kinds of wrinkles here uh that's the kind of thing you want to capture but also you could use appearance to look at the edges that are caused by my eyebrows compared to my skin of my forehead so those are the two general approaches that you can do and of course if you if you're doing it right you're going to use both and that way you can get a very stable system I can smile now but I don't necessarily mean that I'm smiling so I suppose that's a different kind of yeah so if a different question maybe well it's that is a different question but you can we've done Research into automatically distinguishing fake from real Smiles or post from spontaneous smiles and you can do that based on the temporal Dynamics in Smiles actually you can do it both on temporal Dynamics uh that's the activation pattern uh a fake smile is quick smooth and short so you get a quick uh upward trajectory I keep it there a little bit and then it goes back to neutral a real smile has multiple intensity levels multiple Peaks it is slower in onset it's slower in offset that's one Telltale difference the other Telltale difference is something which is called the duchaine smile so you've got the orbicularis Oculus muscle that's around the eye and when that contracts uh especially the outer ring when that contracts it pulls up the cheek and it creates the the the the crow feed at the uh uh at the eye corner it's more apparent with people who get a little bit older um and that muscle that's uh it's called acit six in the facial action coding system is something that is normally not shown when people do a polite smile or a post smile or fake smile although you can you can teach somebody to do that so if you want to become a good expert at at uh at pretending to be uh happy or or or you can learn how to do that it's harder to to to uh to learn yourself to do the temporal Dynamics that's probably almost impossible