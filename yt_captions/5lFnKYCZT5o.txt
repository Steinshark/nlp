well apple in their developer conference on monday made a big thing that the ipad pro or the ipad in the new versions of the ipad operating system ipod or 16 or whatever they're up to these days is going to support virtual memory or more accurately it's going to support swap of virtual memory so i thought it'd be a good idea to sort of revisit or visit for the first time depending on whether we've done it before or not uh virtual memory and have a look at how it works and why you might want to add it to something like the ipad pro so my understanding virtual memory is when you use the disk for or something like a disk or something extra for kind of storing stuff you generally put in ram but there's no spinning disc in an ipad what is it going to make much difference so that's that's a really good point and this is two things so virtual memory there's what we tend to colloquially refer to as virtual memory which is when data gets swapped out onto a hard disk to give you the appearance of more memory but there's also virtual memory sort of technical sense which is when we're talking about the fact that the memory addresses the the processes the programs running on the device see aren't the same as the physical addresses of where things are actually stored in memory so it's abstracted away yeah so the thing is if we think about it if we've got a cpu let's say it's got 16 bytes of memory let's just go for something simple because i don't have to draw so many address lines of course a 16 byte cpu probably wouldn't be much used for anything you couldn't even store hello world in there and print actually you might be able to store hello world in there and print it out you'd be pushing it to store that but if someone wants that exercise to the reader um whether you can that could be the new competition can you implement hello world in 16 bytes so we've got our luminous cpu with 16 bytes of memory and the way that the cpu will access that is it has an address bus or the equivalent of an address bus buried inside all the way that modern cpus work but we'll ignore that for now and it can reference any of those memory locations by giving a number so if he wants to access byte8 it would give eight as the address which of course in binary is one zero zero zero and so you get one zero zero zero coming out there and traditionally you'd have a block of ram uh this is a 16 byte ram which would also have an address bus on it and what we've got here is the physical locations so if we specify we want to access bike eight so we put one zero zero zero on the address here we're going to get the physical byte8 somewhere in this block of memory that's in there go and watch some of the videos we've done previously on how memory works but there's no reason that you have to do that you could have some additional logic in here which takes the address generated by the cpu and then translates it to a different address in memory so we could take the address from the cpu have some additional logic which translates it and then access a different address so we could put eight in here the logic would twiddle it around and what would come out is two so we could say that h translates to physical location two so this is the virtual address this is what the computer sees what the program sees this is the physical address of where it actually ends up in memory and then we could say well byte7 that maps to byte1 byte6 would map to byte zero and any translation you want now why would you want to do that well let's see we've got two probes using the same bit of code they've got a shared library in there well if you can map the address from a virtual location to a physical location you only need to store one copy of that in memory as long as they don't change it but as long as they're only reading from it you only store one copy but you can map it to different locations in each program so program one could have it at address let's say 42 program two could have an address 84 and so on they could access it at different locations but it maps to the same block of memory and the advantage of doing that is that you can make your memory go further so you've got say one shared library used by two programs it can make your memory go further but it's also great for lots of other reasons because it means that a program can have a consistent view of its memory locations it can say start as unix likes to do with the program running at location zero up until a certain point and you can have the stack coming down from the highest memory locations down and each process that's running on the computer sees the memory like that even though they're actually at different locations in the memory because what's happening is that the virtual locations used by each process are being translated to the physical locations in ram and what the operating system do is we'll set up those translations every time it switches between the different processes so that they each see that processes virtual address space as we call it where each things are laid out in this virtual space so by the time that request gets to ram it's actually mapped to the physical location where that program's data is and does this the operating system do it's not the hardware it's not the cpu so it's both so actually this is something that requires both the operating system to do part of it and the hardware to provide the support to do it so as we said we need some sort of translation between the addresses generated by the program and the physical locations in memory this could potentially be a separate set of logic you could have a separate chip or discrete logic that implements this or more likely these days it's what's called the memory management unit that's built into the cpu that you're using so it's built into the cpu but it doesn't have to be you could implement it manually and then what the operating system does is it uses that technology and it sets it up to translate things as the program to switch from one program to another is it possible you might have it happening more than once so it's been translated multiple times theoretically there's no reason why you couldn't do that you'd have to ask the question though is would you actually get any benefit from it i mean if you've got this block being translated to here by one bit and then being translated to here by another bit that's the same as just translating it in the first place so you probably find that there's no real benefit from having more than one layer of translation in there in most cases i'm sure there are some unique use cases which will be mentioned in the comments below where uh that is absolutely necessary and things but in the general case you wouldn't get much benefit you probably would if you're doing segmented addressing but that's something else so once you've got this translation in place you can actually start to do some really interesting things let's have a look at an example of this let's um let's move to a new piece of paper let's suppose we have a program and i'm going to give it 64k of memory just because it makes things easier to think in small amounts of memory not big huge gigabytes i don't have paper big enough so i'm going to divide this up into sections which we call pages so rather than doing the translations on every address we actually sort of group them together into what's referred to as a page of memory let's have a look as an example i've got memory here and i'm going to treat this as a 64k of memory so i'm going to break this up into 16 blocks 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 we should have as we do 16 different pages as we call them of memory now why have i broken that up into 16 well that's because each of these pages is four kilobytes long and that has traditionally been the size that we use for pages on computers why well if we'd broken it up and say 16 kilo byte pages we would only have ended up with four pages at which point we're dealing with huge blocks and if you've only got 64k that's a quarter of memory 4k you've got 16th it's a nice balance i suspect when this technology was being developed things like the pdp-11 had a 64k address space 4k was a nice dividing thing interestingly things like the ipad and the iphone and the new m1 chips in apple's laptops you're using 16 kilobyte pages rather than 4k pages um memory's got a lot bigger it makes more sense and things work better using a bigger page size and so i suspect we'll see the default page size changing on a lot of computer systems as we go forward but what we've got now is this one will be all memory that starts one zero zero this is two zero zero and so on up to f zero zero up there so we've gotta translate a page at a time so what this means is if the program is using this any address that's between zero and one zero zero zero in hexadecimal will get translated to an equivalent location in physical memory at that location so let's say we want to access address eight zero zero zero when that address come which is going to be there at eight zero zero say we want to access a location here at eight zero zero zero the computer is going to generate the request and when that's translated because it's binary because it's powers of two actually we can just split the number up in two so if i fold this piece of paper like that we have the lower 12 bits which specify where we are within this page in this case we're at the right at the beginning and then the upper four bits because we're using 64 bits so we're using 16 bit addressing that specifies what page you're in so what happens is when the cpu makes the request for eight zero zero zero that goes into the translation logic it looks at the page number and there'll be a table somewhere in the computer usually in memory that is accessed as a fixed location so look up eight in here and it will say here that all these exist at location let's say six zero zero in memory so it'll take that address it'll see the eight there so okay i now need to put that with a six and so it can then just concatenate those bits with the bits and make up the high byte six and it's got its location for where it's it's like a magic trick here we've got a location of where it'll be in memory so the translation is really easy you can look up the address there see where you need to end up and then you can put them together to generate the new requests so you can do that relatively quickly it doesn't slow down the memory access that much at all but you can start to do interesting things because let's say that though that we've actually only got 32k of memory in our computer system so let's say that we've got the actual memory here let's say we've got the memory down here but we've actually only got 32k of memory it was expensive back in the early 1980s so that would have been a lot of memory the cpu can access 64k but we've actually can only afford 32k of memory so we've got our address that we've translated it to which means that actually we end up accessing the address somewhere in this block there even though we set the access up there now this gives us some interesting opportunities because our cpu can access 64k but we've only got 32k now what we can do is say well okay let's say that we running the program and it's doing something so it fills up that and that gets allocated into there it fills up that and that actually gets allocated into that bit there fills up that that gets allocated down there and so on now we know that this is already accessed and mapped to that bit now if we access this bit and we end up here but now let's say that we want to use some more memory which is going to be this bit here we've no space with physical memory to actually store that anywhere the computer can address it because it's got a bigger address space but we've mapped all the pages to different things already so we've got no physical memory to do this but because we're translating things we can start to do some clever things so when the computer tried to access this the memory isn't mapped to anything and so the cpu wouldn't be able to process it uh the translation logic would say hang on i don't know what to do with this there's no mapping for this it would generate an error and then the operating system could take over and you could say well okay actually this block of memory is not being used i'll allocate you to there and things in this case so it can't do that because all the memory is being allocated so what's it going to do well this is where swap becomes useful because what we can do is say well okay run out of physical memory but i still want the program to do what i'll do is i'll make a copy of the memory that was at that location there and which one it will use which page it will use to evict to take out the thing it will choose based on some algorithms let's say the one that hasn't been used least recently is probably a good algorithm so you find the one that hasn't been used for ages and then you get through that so it makes a copy of that now where's it going to make a copy of it well you can't make it into another location memory because it's full but where you can make a copy of it is onto your storage device onto your solid state drive your hard disk and things in this case i made a copy of it onto a piece of paper and so we can put that to one size we can put it into our storage device and then the operators say well okay you want to use this memory that can now go at address six zero zero zero and it will update its translation table to say that addresses at seven zero zero are now at six zero zero zero and the addresses that were at location eight zero zero zero no longer there so you can access the memory there fine everything continues the far as the program is concerned it's now using what is that 36k of memory even though we've only got 32k memory and because we've copied the data out onto some of the storage we haven't lost any data now you could do this manually as part of your program you probably run out of memory i'll write some data out to disk and um then reuse it and things can do it manually the advantage of this is it's implementing the operating system you just access memory and it gets handled for you automatically now that all works fine and it could happen again you could access some other memory let's say up there same thing could happen things but eventually it's quite likely that you may go back to editing to this bit of the document that was addressed eight zero zero whatever it was that was there you need to access it now you've got a problem because that's not in memory so when you try and access it the logic that does the translation says hang on this is no longer in memory what do i do yes we're trying to access the bit that was eight zero zero the bit that we've evicted earlier it's no longer in memory so it can't do the translation in fact if you look at the translation table we've sort of blanked it out because it's no longer there what do we do well the translation logic says i can't access this so it stops accessing it hands control back to the operating system the operating system say well okay you want to access that a bit of memory well i still have a copy of that i made a copy of it it's on disk earlier i will load that back into memory at some location now it doesn't load it back in to the same point or it might well what it will do is it will use the same algorithm it will find the least recently used bit of memory let's say it's this one here and say okay you want to access that i will stick that in memory in this case it's going to be address zero zero zero and so it will then update the location there to say that addresses from eight zero zero zero map to one zero zero now it'll then restart the instruction that was trying to make that memory access it gets translated down to here it gets its data of course what it needed to do which i missed out the step is that before we evict that bit of memory we need to make a copy of that and store that on disk or wherever to access it later if we need it and where does that work how does the operating system keep track of those copies so that's down to how the operating system is implemented there's two main ways that you can either do it you can either set up uh part of your disk so if you use something like linux you might see something like a swap partition and that's just a partition on the disk which has been allocated to hold the copies and then the operating system will copy the pages from memory onto specific points on that disk alternatively you may see a page file or swap file which is just the same thing but within a file within the traditional directory structure on your system now that's great and so that's what they've basically added to the ipad uh in ipod os 16 is the ability for it to swap things out except not quite because the operating system on the ipad already did a lot of this already what's different is that they now will do it with data created by the program because what people realized when they started to implement virtual memory and swapping and things is that when you load a program in to memory the traditional way you do it is you would go to disk where your executable file is stored and you would copy the bytes off the disk into the computer's memory buy it for a byte until the whole program's loaded which is fine but if you've got a big program let's say you're using a word processor your wordpress has got facilities to view a document edit it there's probably a spell checker in there there'll be support to print things and so on so rather large executable but if you're just opening that word procedure just quickly read the first few lines of text in a document and then close it you don't want to have to wait for it to load in the spell checker and load in the printing routines and things so you could either break the program up into small chunks which sometimes it did but what people realize is that actually this technology that they had for swapping data in and out for memory could be used to speed up loading so what you did was you say okay we'll load in the first page of the executable file and start running it but we set up the translation tables and things so that all the other pages that would be part of the executable were mapped to the relevant part of the disk so they're not using the swap area now but they're relying on the fact that actually the files on disk don't change and so they're saying that this part of the executable file will map here if it's ever accessed and so they're doing that as they do that in fact in some cases they went even further and started doing compression on it but that's a story for another time so the ipad supported that so when you load an app on the ipad it doesn't load it all in one go parts of it are loaded on demand as it accesses that bit of the program it'll then page it in using the same technology so it's a case of well it's already on disk that data we don't need to make another copy of it load it into memory then page it out when we first access it we'll page it in load it in and then we can access it so the ipad already did that so for executable files the code that was part of them the data that's stored within them could be paged in automatically and again if they then started to run out of memory it could page them out and reload them when it needed them at a later point now why would you want to do this on something like an ipad well ipads are like any machine they have a finite amount of memory i think modern ipads have something like eight gigs 16 gig of ram inside them but they have 256 512 terabyte 2 terabyte of solid-state storage and the advantage of solid-state storage is very very low latency and access and so paging things in and out is very very quick if you old enough to remember hard disks you could get to a point where it ran out of memory so much there's so many programs running at the same time and that's when you really benefit from virtual memory that your computer would just sit there chugging thrashing as it was referred to as it was constantly swapping pages in and off in and out off disk and your machine would basically slow down so you had to either go and get a coffee or something or more likely turned it off and turned it on again cleaned out all the memory and everything worked a lot quicker that's not why we turn computers on and off again you've got sort of nine milliseconds or something on the average hard disk for it to access a piece of data that's virtually tends towards zero on a solid state it's not zero but it tends towards it uh on the solid state device like the flash memory in a modern ipad or something and so you get the benefit of having more memory and for some of the things that people are doing if you're video editing if you're doing high-end creation um you can end up using a lot of data if you've got lots of apps running then that puts constraints on the memory 16 8 gig of ram between say 10 apps running is 800 meg each and you can start to see that actually having this ability to swap the data out as well as swapping bits of the program out can really give you some benefits for doing it so that's why they've added this only 10 years after they invented the ipad so the advantage so you are actually seeing intel have and the name escapes me that have looked at uh creating non-volatile storage it's a little bit easier to find what the factorization is and then once you've factored it you can just do these steps to completely calculate