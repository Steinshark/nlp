all right so apparently go routines are useless for back-end development which this seems strange okay uh today I was listening to the podcast and one of the hosts said basically that go routines are useless for back-end development because we won't run multi-core systems when we deploy we run multiple single core instances so I was wondering if if it's in your experience true or that the strange phrase uh that now let's say that nowaday we usually develop uh deploy only single core instances I'm not a goaling developer I'm a junior Java developer okay hey respect hey give the man a little bit of respect okay he's coming out here junior Java Dev pleaded pants on loving life of many respects for this uh but I'm interested in learning golang okay so we could listen to this podcast here here let's let's bring up this podcast because I want to be fair just make sure that the take is correct oh and it's late okay okay whoa whoa okay so right now I'm gonna first choose to have no sound because I I felt like that was the best approach to to start with who was invented to solve a problem that we immediately stopped in some regard not not all of go but specifically it's go routine model which is by the time they actually got go routines stable and landed working the way they were described in the original conference talk five years prior they were useless because we don't run multi-core systems anymore you you deploy and it runs on multiple instances multiple single core instances where they're actually not even single core instances they are one half of a hyper thread yeah I completely agree with that right like if you if you're using kubernetes you just scale up at the Pod level right rather than right within your application though I will say um there's been a lot of times where it was really nice to be able to just run a quick background job on the same server for the reason that I don't need to reach to the infrastructure to solve the problem for me um that doesn't mean you should never reach to the infrastructure sometimes like serverless stuff or kubernetes are really are good for those things but it is kind of nice just people like I'm just going to spawn a go routine and do it here really quick in general like okay okay okay okay okay I see what is being said here so how I take what is being said is that every request is effectively running on its own one half of a hyper thread is that correct is that what is that what is that what you're hearing is that every request effectively goes into its own like go environment that's ran One Time by itself it's not some long-lived application that's getting thousands of requests and said every no it's not that a single core it's not single core that's not what we're saying um single course it is on its own single core it's it's that each request is being its own Standalone process is that what I'm hearing yes one core per request okay so if it's true okay no no yes but no one actually does that sounds like serverless no yes okay so it sounds like every okay well it's one hyper thread I just said one process right it could be one hyper thread one core per request yes and um okay so let me let me say it this way I don't know how that would exactly work and how efficient that really would be uh I don't think there's a startup time concern at all with go or any of those things but if go I'm not even sure how you'd write your server in such a way that it can be something because you wouldn't want to set up your server every single time to do all this but anyways whatever let's just say that that's what's happening every request gets its own process in which it does its thing and then it's taken down if that is the case then I understand why you'd say go routines offer nothing because you'd only be adding overhead right because you're literally gonna do a request process the request get the results put it in Chase on and that's it right so if you were running a single request through a singular process I'm on your team with that one that that makes sense now I'm having a hard time visualizing or understanding why you would do that perhaps I'm missing out on some really cool scaling technique that I'm I'm very unaware of and that's fair I'm not like a huge infrastructure person so I I could totally I maybe there's something I'm missing hey to be fair maybe there are things I'm missing but what about creating DB connections I know exactly like I said there's a lot of questions I have that it doesn't make any sense to me what's being said right what's being said doesn't make any sense now I guess the next thing I could see happening is that every request is ran on its own green thread in which you just sit there and block but that somehow doesn't make any sense to me I'm having a hard time seeing that or understanding why that would be a good thing because you would block many threads or depending on how the async stuff is set up there could be a lot of blocking like in my head here here's a good example here um okay that's a very good joke for my YouTube please don't look at that really great joke for my YouTube I'm just gonna do it in typescript because it's honestly the easiest function uh you know we'll go like this uh AC function one right and this thing uh return a new promise uh uh res set time out and actually let's just call this thing wait and have a uh an MS number come in right there we go and then we'll just do res Ms right okay this is great so we could have Function One are you seeing function one and it could literally just await uh console log for those that don't understand why this is important right one start just in case you didn't understand why this is important let's have this thing wait one second like you could imagine this is a you know some sort of database whatever call right um right and we can Yap that and then you could have a a two which does the exact same thing which I don't know why I didn't just uh find and replace but whatever we're gonna do that and let's just say this thing is two seconds and then we can have our async main which is gonna be uh what function let's go like this we could have a weight one and await to or like that would be like kind of this is like more single threaded right this is where you have no none of them or you can do something that's more like promise.all which allows you to do well this right oh my goodness uh this this example is getting kind of long people this example is getting kind of long people there we go so it's like why wouldn't you want to do this one so even if I am running it on one thread right even if I'm running on one single thread I can still have multiple things out at the same time you still get concurrency so I don't understand yeah I used button by the way I program I do my front ends in htmx and I run bun for classic scripts um it's just like to me I don't get I I purely don't get the argument unless if it is the way he said at the beginning which was if every I would love to get Lane on here if Lane was here maybe he could kind of clarify what's being said here but if this is uh just a js on the server copium is this notes concurrency is not single thread um so it is it it is it isn't uh what you're saying is entirely too confusing to actually really resonate with or to kind of understand uh they have a bunch of threads that do stuff V8 spawns multiple threads to actually do things right there is a scavenger thread that scavenges garbage really easily and doesn't require a minor major GC there's Network threads there's things but node itself is a single execution is what I like to say I believe it's all on the same thread but it's it's single execution notice just lib8 plus UV yeah yeah yeah agreed if you had one language that could actually take advantage of multiple cores could run for a long time without choking it is actually faster you could just do more stuff with more capable Hardware yes that's called go that's literally what go is for right um but either way like when I see this I don't understand this take because I don't think it makes any sense because even single threaded you want IO to be in the background you want I O to run on a separate thread you want I O know the waiting to whatever it's doing whoever it's calling to you want it to happen somewhere else because why would you want to wait so I I genuinely cannot understand this take unless there's this one caveat which is that it has to be single request single process but then you got the whole database thing you got all these things like right you have to establish a new TCP handshake https whatever you're doing alpn Alpine whatever the hell you're doing you're doing your Alpine request so that way you can do your efficient H2 request but then you get none of the benefit of H2 right uh thank you uh privacy for everything you do hey appreciate that milk um and so it it I I I'm just personally confused by this it does sound like this is a bit of what serverless does I think that sounds correct that sounds like serverless I got an F I'm getting some F's let's go F's getting some F's let's go Tina Turner um but other than that I I'm really I'm genuinely confused by this argument so um let's see let's see if we got any comments uh you can have a single core but many threads and processes yeah uh you can have a single core but two logical cores hyper threading damn got him it's interesting to look at nginx it's single threaded and implemented in C yet it is used for routing Ingress traffic into k8's clusters it's also one of the quickest static file servers yeah yeah it's it's see look at this the whole point is just taking care of IO so that's the thing I'm I'm confused about is there anyone that's saying no that doesn't make sense let's see a guy on a JavaScript related podcast claiming that we run every system out there on a single core machine doesn't really surprise me it's not a JavaScript related podcast this is actually or well maybe maybe that is a JavaScript related podcast to be fair this is top end devs I don't know top end devs um maybe this is a JavaScript podcast uh here's a better podcast for you go Time and ship it oh okay change log I like changelog um but nonetheless it even this surprises me right every JavaScript person knows in the world that you do async await to avoid blocking JavaScript like I in fact it's almost impossible like to do a synchronous HTTP request HTT HTTP request is actually like you have to configure it to be sync right it's not trivial so I don't know I I genuinely don't understand this take and I want everybody to know please use go routines go routines are one of the most incredible things ever created and I'm going to tell you why they're actually better than JavaScript uh than JavaScript await uh async await and it comes down to function coloring right so if you're not if you're not aware of function coloring effectively if you have one function that's async and one function that's sync you have to call each function differently they have to exist differently in different functions and if you have a function that's async the calling function that wants to use it nicely has to become async itself it's called The Leaky abstraction right one makes everybody else have it and then it spreads All the Way backwards right it's the same thing with like the result type in rust or um the uh the async and rust right it kind of colors it the types and async color in Rust where you just keep on passing backwards and so when it comes to when it comes to doing this I actually do want to read what you're trying to say here uh Ryan but what what go does that's so incredible is that it literally doesn't have function coloring you don't know if the function you're using is going to be async or sync and that's incredible you may get a channel out and a channel you sit there and you synchronously wait for the next results like that gives you the choice to do something with and that's really incredible because it's a non-leaky abstraction it's the only language I know about it but I think Elixir also has this I'm sure Ryan will correct me on this one but or erlang uh there's there's other languages with you know these these uh these non-colored functions and so I I just to me that's just super incredible in my opinion that's bad I don't think it's bad because you get a channel if it's async if you need an asynchronous value and so you synchronously listen for your asynchronous values and if you need that on a different thread you put that on a different thread it literally gives you the fullest control with none of the Annoying parts of colored functions it's genuinely one of the best things I've ever seen as far as a concurrency model goes and I gen I genuinely love it I think it's truly the best way to do it change my mind change my mind the name's the cancel again