this week we're back in the world of data engineering with a curious mix of python and rust my guest for this is Dan Herrera and for a while Dan was working in adte which is not everyone's favorite sector I admit and we do end up talking about that but it's undeniably one of those sectors that's going to teach you a lot about the problems of processing data at scale in parallel at high speed and it's those kinds of problems that led down to the topic of this week's episode bite wax an open-source distributed stream processing engine which makes a number of interesting architectural decisions in this space that we're about to get into but it has an interesting backstory of its own so let me briefly tell you how it got started back in 2013 Microsoft Labs published a paper on niad which was a novel approach to these kinds of data processing problem that got implemented in Rust and had its first release in 2017 under the name timely data flow which possibly you've heard of and the thing I find interesting there is rust makes sense to me as a lowlevel low latency language to prove your paper and build out some serious infrastructure but it's not the first language you think of when you talk about data engineering that probably belongs to Python and there's the origin story of bite wax how do you take a research back tool written in Rust and Bridge it into where all the data Engineers are in Python and what do you end up with when you get there what kind of Beast have they built let's find out I'm your host Chris Jenkins this is developer voices and today's voice is Dan Herrera [Music] joining me today is Dan Herrera Dan how are you I'm very well thanks for having me pleasure I'm um I'm wondering a lot of things about you you work with bite wax I'm wondering a lot of things about bite wax but let why don't we start with the origin story how did you get into the data streaming space sure yeah um I come from like a pretty traditional data engineering background and that's spanned through several jobs uh most recently before Bix at GitHub but before that in the kind of adtech space and then sort of being the First Data engineer uh and founding the First Data engineering teams at other companies before that so I've worked in the data space for quite some time uh and then I think the streaming data portion of it came out of uh a lot of the work that I did in the attech space which ended up having like uh realtime connotations for doing bidding for like header bidding and ads and things like that so yeah uh it's been a a long and interesting Road through it's funny how how much of advertising was a driver for adoption in the early days of it yeah yeah um similar problems of like needing uh real-time interactions for data uh large Data Systems uh were very gerine in that space and so uh yeah it it was interesting uh yeah I think I wasn't crazy about working in adtech like anybody would be but the problems are really interesting and the people uh are always great you know that's always my favorite thing about working on a job I had um I had a brief gig at a blockchain company and I feel exactly the same way the problems are really interesting can we please focus on that part yeah my boss used to start every talk that he gave uh by saying if you use an ad blocker like I do and then he would go on from there so right but let's get into the tech of it because the first interesting thing I noticed about this is um you're in a python space you're building out a python library for data streaming but under the hood it's rust mhm and that seems like a curious way to approach it so how did that happen uh it was kind of a Confluence of some things that I think are happening right now in the kind of like uh data space and and more generally just uh in the python space I think that python is really experiencing like a new Renaissance uh I think there's so much Renewed Energy in uh interest in Python and so many applications that you know the obvious one being machine learning and artificial intelligence but uh I think python has been such a base layer for data for such a long time and uh yeah it's been kind of interesting because my Genesis in the data space was very much rooted in Java uh which a lot of the current tooling and older tooling uh is all based around Java and uh I was very excited about uh a couple things uh number one somebody introduced me to the project called pio3 which I think is pi3 is a library that allows you to make ergonomic rust bindings for python or vice versa so you can call rust from python or you can call python from rust or both and it's really a fantastic project uh so that was probably one of the things and the second thing that I became aware of uh because of our CEO Xander uh introduced me to it funny enough was a timely data flow so that's a rust Library so kind of the Confluence of the availability of those two things I I thought it was like a really great opportunity to sort of visit the space okay I kind of I want to get into timely but just briefly because I've I know I've worked occasionally with calling C from python and so I can imagine that rust from python will work but it's but C from python I wouldn't describe as fun uh python is really amazing for being an extensible language uh I think they've worked uh very hard it's it's kind of amazing to me that you can install a few packages using the same package registry you would for Pure python invoke a program and get some Fortran code some C++ code potentially some R all in the same stack and uh I I don't think some people even realize how many different languages are end up being connected to Python and so it's always been a very extensible language in that way and uh you know the most famous examples of these sort of connectivity are like numpy and scipi uh are libraries that uh connect to uh old and and very battle tested and very reliable implementations of things so uh in other languages okay so because of P 3 you're looking at niad And Timely data flow and not scared that it's written in Rust no uh yeah it was uh I was very excited when I started learning about rust uh it was like a very interesting language to me personally and uh the I think in between the amount of care that is gone into both creating timel and P3 is just kind of amazing they're both like just just fantastic uh libraries to use the community around them is is really great and you know you can you can see that there's some very deep thinking about some of the problems the problem space for P3 is you know very large python is you know doing such amazing things as removing the Gill or providing sub interpreters that can interact without uh you know without holding the Gill uh so there's a lot of really interesting work that's going into python these days and the people that work on pio3 have a very daunting task to be able to make a library that can take advantage of those things and is still like ergonomic to use and they do a great job of it yeah yeah that's a very difficult marriage of being good at the lowlevel stuff and still being good at like developer space uh developer experience stuff yeah I think the same is true of timely I think my experience learning timely and uh I would say that I wouldn't represent myself in any way as being an expert at timely data flow I'm a very enthusiastic user and I would say uh a dedicated student and it's taken me a long time to sort of understand the subtleties of the language but I think when I step back and look at timely I think they've done an amazing job of writing uh what they call a low-level Library uh it's made all of the world of difference to us to be able to construct what we wanted to construct based on The Primitives that they provided and I think after you do Library design and API design for a while you learned that that's a pretty impressive thing to be able to do yeah yeah it's hard to get something that's both flexible and usable you either make it so General that it's hard to know where to get started or so usable that it's hard to remain flexible yeah that's exactly right so we're going to get into the guts of uh timely great um of all the of all the different stream processing ideas right you've got data coming in you want to do stuff to it and then send it on its merry way what is it about timely that sets it apart in your opinion uh I think there's lots of things and I think one of the things that uh I went back through and I was reading through the timely data flow book which is a great read for anybody who's interested in this um it's just the long form documentation that they have linked from their site that's not specifically API documentation but the timely data flow documentation describes data flow programming as um trying to remember it exactly but it's uh organizing a program uh in uh components Each of which can uh respond to the presence of new data which I think is like an interesting description and what it really means is that uh there's some coordination of pieces that happens in timely data flow but in sort of um in contrast to imperative programming uh it's interesting to think about how that differs from like an imperative programming model because you can imagine any process reacting to the presence of new data like a web server receiving a new request but I think what's really interesting about data flow programming is that each of the components are described as being connected to each other but each of those components can receive new data at different points in the data flow the availability of new data is not something that uh starts at the beginning and ends at the end and a great example of this in a lot of uh data flow programming models is like a window if you have a window of data that closes after a period of time it's accumulating a bunch of state and a bunch of data and then after a period of time that window can close and that event itself can cause computation to occur somewhere else in the day flow yeah so I often think like we we treat stream processing like it's a new idea but it's very much once you take out the persistence part it's very much like reactive programming it's very much like go routines and co- routines yeah I think it shares a lot of similarities for sure yeah so so what is it that I mean you could have taken a naive approach and said okay python routines I'll just do yield all over the place and I'll try to remember to write it to disk yeah why why jump through Rusty Hoops to get to niad it's a really good question um the thing that timely data flow gives us uh for for bwax specifically and for users of data flow programming libraries like B wax does for other people as well is uh the idea of progress tracking uh throughout the entire data flow is something that is uh simple on the surface but I think it has profound implications for the way that you can build and especially scale uh sort of independent components um the idea of when you have inputs in a streaming system being able to correlate those with uh outputs in a streaming system actually becomes like an interesting problem um go ahead do you mean for debugging or uh just for being able to uh produce correct answers or uh fit whatever particular idea you have for the type of data flow that you're writing um give me an example sure that's uh I think that's a good idea um so in a streaming system you can imagine that you're not going to see all of your input uh in effect you don't really know if you're ever going to see the end of any particular input and so the question becomes would do you produce answers and how do you judge the sort of correctness of those answers so uh the example a simple example would be if you're receiving a stream of Bank balances for a particular user uh how do you correlate which outputs you see in there with the inputs that affected that particular thing so being able to assign those things together it's actually a different component of timeline of kind of like jumped subjects here but uh progress tracking and logical time stamping are the the uh uh the things that you can use in order to be able to correlate those things together and it's it's one of the key concepts of timely data flow okay maybe if you explain to me how it does that it start to come together yeah sorry uh it's hard to talk about timely uh and I I realize how how tremendous a job they've done in uh sort of presenting this information uh but you know uh Frank mcer and and the other folks that uh have done a lot of work in timely uh do a really fantastic job about talking it so I'll do my best uh to do the to do um so if you if you have a data flow and you're uh receiving input uh each one of those inputs can be assigned a kind of uh logical Tim stamp you can say not necessarily like when did this particular thing occur but it gives a kind of sense of like ordering uh over uh the span of input uh additionally one of the things that timely allows you to do is you can say for a given timestamp uh you can uh say all right there's a point at which way I'm never going to see any more of this particular time stamp so if you imagine that uh all of the records that you receive for something all have the same Tim stamp you assign them all the same timestamp and you know for lots of demonstration purposes it's easiest to think of them as like Auto incrementing integers right each of the inputs uh gets assigned a logical timestamps uh and can proceed through the data flow so let's just say all of the first batch of records that I pulled off of Kafka get the first Tim stamp of one yeah uh in a data flow program you can say all right I've reached a point where I'm going to say I'm never going to assign anything else that same timestamp I'm going to advance uh the timestamp to two and the rest of the components in the uh data flow can react to that information they can know that they can now produce a result saying I know that I'm never going to see anything else with that same logical time stamp okay so I could have to use your example a bunch of transactions coming in onto a user's account and eventually I want to say okay at some point I've got to say for legal purposes closing balance on this day was X so I'm going to draw a line under all all transactions with a timestamp of one and anything that come anything that comes in now must be two or higher and it will not go into today's closing balance yeah that's a great example uh it's really interesting to be able to uh use that mechanism uh it's a very like lightweight mechanism uh in order to be able to uh coordinate multiple workers like you can imagine a data flow can be started with multiple processes or multiple workers they can share that information with each other but all of the parts of the data flow can know when they're not going to see any more information with the same timestamp anymore and then they can decide if they produce results at that point in time and those can be correlated with that particular input so it's really interesting they describe it as like the lightest weight way to introduce that sort of idea of ordering uh of coordination between uh multiple workers in a data flow system and I think it's a really interesting way to think about it because uh there are so many things that you can actually do once you have some of these really primitive uh interesting like very small Primitives that's the thing that interests me because it sounds it sounds very simple in the small and I guess that's the beauty of it right but what happens is you start to build that picture up to a larger en larger graph um in what way like how does coordination happen how does or what are the implications probably all these questions but like okay so it it seems pretty simple for the case where there's one processing node saying have I seen anything is it time to stop accepting once yeah but then okay so you're in your example we've got a couple of different people couple of different nodes all looking for the End of the Age of one and maybe some Downstream processes who are still expecting the age of one how how does this scale up into complex graphs yeah in ter in terms of that let's start with in terms of that notification that it's the end of an era going through the graph yeah uh so that's a great question um so what timely is doing for you is giving you the ability to sort of uh notify uh any of the components in the data flow that you want uh uh to take action when these uh events occur when you uh Advance the Epic of input uh that's a kind of major event and the rest of the data flow can sort of react to that information and so uh I think what's really interesting about that is if you consider you can have more than one Epic in the data flow at the same time uh just because you emitting records with the timestamp of one you can start emitting uh Records with the time stamp of two or later and have those be processed in the data flow at the same time but it gives the entire data flow an interesting set of order in that you can understand that timestamp one comes before time stamp two and when you process these data uh you can process them together and there's a sense of which comes before uh the other but you can have multiple aexs running in a data flow at the same time oh okay so there's something Downstream that because graphs are complex and different machines run faster it could get all the information from Epic 2 first and say well I'm I'm going to have to hold on to that and wait until I've got a Clos message for epic one and then I can just spit the whole lot out at once yeah so you can do some types of processing uh in an eager fashion uh you wouldn't potentially admit result at that point in time but there may be computation that you want to do every time you see a new item but you know that you can't produce a uh result until you've uh seen the end of that particular epic uh so how does that look is there I'm assuming there's some kind of protocol between nodes saying okay this is a domain record so I'm going to just pass on customer made a transaction right meanwhile there are messages that say hey guys it's the end of era one is that what the protocol looks like it's a mixture of domain messages and kind of protocol messages yeah I remember we looked at the progress tracking messages so if you have more than one worker in a timely data flow cluster they're exchanging this information with each other and uh I think part of the uh the Brilliance of the library is that it's both a runtime and a library and the runtime has had lots of optimizations you can imagine that uh coordinating this among um very large nodes can get expensive exchanging all of the data for Progress tracking with each other and so part of the parts of timel that I haven't had Direct experience with but I understand are doing a lot of optimization in terms of like how that exchange of data happens between nodes okay I think one other thing that's interesting to talk about just briefly about the way that timely uh is different from other data flow systems is that when you have more than one worker in uh separ system uh let's just say like a spark uh you can have parts of the uh data flow graph that are happening uh on different machines like for example uh like we can go back even further and think about like map and reduce happening on completely different machines altogether what's interesting about timely is that each worker has the complete data flow graph and all of the operators that are included so it has input and it has output potentially depending on what you want to do and so each one of those workers uh does more than just progress tracking exchange uh in order to produce correct results you might also want to make sure that all of the values for a given key end up on the same worker so they can not only exchange uh progress tracking information but they can also exchange data with each other okay but you saying like they've all got a copy of the data processing graph so I as a node can say oh it's key ABC I best send that to machine 123 that's right yeah you can tell operators to participate in different uh I forget what they call them um they have a name for them where you can say this is a pipelined operator meaning as soon as you're finished with this I want you to give it to the next operation uh and you can exchange it you can have an exchange operation where you say at this point in the data flow graph I want uh to exchange the keys uh to the workers where they belong and that's another like like a powerful tool that's in the toolkit that you'll sort of like find later when you need it like you realize I actually want to broadcast this information to all workers or some of the other things you might want to do right before we before we get um further into the usage of this then are there any other main Tools in that tool kit yeah I think I'm trying to think if there there are patterns um I think the last thing that I probably didn't talk about was uh being able to attach probes to different parts of the data flow uh probes can tell you when things have reached uh different parts of the data flow so you can say uh I want to be able to know if uh information is made it all the way to this part of the data flow graph and then potentially take other actions uh that happen in there so as an example uh we use this in bite wax in order to do garbage collection uh after a certain period of time we want to clean up some of the records that we're keeping internally snapshots of older State and so you can use a probe to say I just want to make sure that uh the data flow and data in the data flow has reach this particular stage before I take actions other in other places so you can attach probes to various parts of your data flow and use that information to take action elsewhere is that something you do before the graph starts running or can you do it at processing time Dynamic uh no something that you have to do data flow construction happens um before runtime and that's I think a lot of that has to do with uh you're describing a data flow as operations that you want to have occur and then the connections between them uh so for example a classic would be like uh joins or uh branches in a you say if the predicate that I give for this particular operator is true I want the results of that particular operation to go to a different operator so you describe them all as like Connections in between each other and then probes are an important part of uh that data flow construction as well so you would describe them uh when you're describing your overall data flow okay so to make that concrete I might be saying uh I've got three different kinds of message coming through I want to Fan them out to three different kinds of processing node and once they've all been processed I want to probe to make sure they've all been processed before I throw away some kind of intermediate state in my branching algorithm yeah I think that's a good example okay okay we'll work with that so yeah the When you mention map produce I was reminded of something I read years ago about Google optimizing a map Produce job at the kind of scale that Google do it and they found that even though they thought all their machines in the cluster were just as performant and basically identical they would always have like 3% of their nodes which inexplicably took too long to process a particular subtask yeah I'm wondering if you've got the monitoring and kill it off and start again from the start of that Epoch capability uh it's something that we added uh to bite wax specifically so uh like we were talking about timely is an amazing uh low-level library and kind of the interesting thing that we did with bite wax is we had a similar goal we wanted to Pro provide a generalized framework for construction of data flow crafts in Python and so it's interesting for us because we actually uh don't use progress tracking in the same way that you would if you were writing a data flow using timely data flow so okay when I give you the example of using progress tracking uh in terms of assigning logical timestamps and correlating them to Output uh we take a little bit of a different approach and we use progress tracking for internal um pieces of the data flow that we manage for you and the biggest one that we spent a lot of time working on was uh recovery so being able to crash the data flow start again and resume from the same same point and right there's some uh large pieces of that that we had to take some time to create but uh the two major ones are being able to preserve State inside of a data flow and then being able to resume uh at a consistent State and so the sort of broad stroke of all of those features together are that we can guarantee in bite wax that we're going to process data at least once as long as your input supports it we can tell you that we'll restore the internal state of the data flow to where it was when we crashed or to a consistent Point uh and then we can start consuming input data from uh some point in the past and then we can get back to a point at which uh We've processed all the messages at least once is this logically you're saying okay um we closed out Epoch 3 successfully so let's record the state of the graph Epoch 3 and then we can always just restart from there yeah that's a very good summary actually um uh it's it's surprising have you did you work on this yourself uh we I tend to summarize a lot of things in my role as a podcast H it's really good um yeah so we start epics in white wax uh just based on wall clock time and so we say we're starting an epic now and at the end of each of those epics we can use that uh coordination point across multiple workers to record the state internally of all the uh stateful operations that we have going and the state of the inputs so simplest example would be like which offsets have we consumed in Kafka to that point in time if you take the snapshot of that whole thing uh and serialize it and if you crash you may have process some data after that point and you may have seen some new records from kofka but what you really want is to restore the entire state of the data flow at that point in time to a consistent State meaning in some stateful operations you wouldn't want to apply the same message twice because then you'll get incorrect answers and so being able to serialize the state of things in a coordinated way across multiple workers and then replay data that you had seen previously in Kafka but hadn't reached the next end point uh where you took a snapshot is uh how we do coordination but that's a little different than like the initial when you read about timely data flow and you start using timely data flow for the first time uh coordinating inputs and outputs using epic uh is a really useful thing and for a very specific purpose it can be uh like very beneficial to decide that for your particular problem domain that's how you want to coordinate things but for us when we were building a generalized toolkit for people to do data flow construction some it's hard to be able to make those that level of assumptions about people's inputs and outputs and we struggled with that a little bit at the very beginning we tried very carefully to sort of mimic the timely data flow API for our purposes right and then at some point in time we were like uh my colleague David was like I think that we should actually not do that I think that we should model this in a different way and he came up with the idea that epics could just be wall clock time and we can use that as a different uh type of coordination mechanism okay is that the point that it becomes more a low-level Library than a you're using timely as a low-level library to what you want to build rather than it's just a wrapper around timely yeah uh timely is really amazing in that way uh timely is the underlying substrate under another uh library that uh uh folks that materialize and Frank mcer and other people have been working on called differential data flow which is not something I'm super familiar with but uh the way that you understand it is that it is a construction of another system that's built on top of the timely Primitives as well so I think that's what makes timely so amazing is that it can provide uh facilities for lots of different problem domains and uh it's very interesting in that way okay well we're going to carry on with the idea how you've been using it as your lowle tool but before we move on sure I have to I have to check something you mentioned wallclock time and we're talking about distributed systems yeah isn't that dangerous uh in the particular case where you have multiple workers that are using wall clock time you could imagine that you would want some kind of coordination between those two things but I think what matters is that uh the event where you say I'm not going to produce any more input at this uh time anymore is kind of the more key event that doesn't necessarily have to be coordinated for all of the workers to say uh when we reach the end of this epic we're going to take certain actions and snapshot all the data flow that doesn't necessarily have to be tightly coordinated with each other so uh it's a great question I I'm not 100% sure I'm understanding that you're saying that you choose an event which make marks the the end of this of of the bite wax Epoch and then you look at that event Tim stamp and you just say well hey that happen to be the time stamp of when we what is that roughly the model oh sorry no we're just using the system clock time uh but what happens if you've got two machines with differing system clocks well you're only really using it as like a marker of wall clock time not the specific time itself but when to advance to the next epic right you're using 10 wall clock system uh seconds in order to say all right uh this is the point where I'm not going to be uh I'm not going to be reading from or I'm not going to be emitting records from let's say Kafka uh at that same Tim stamp anymore and you move on to the next one so for that particular worker it's a coordinated point in time across that uh workers's operations uh you could say this is happening on a worker level not on a graph level correct yes right now I'm with you okay yeah it's a good question I thought we were accidentally Mis coordinating multiple workers oh no good I think it's it's a good Insight uh yeah something to be very careful about okay so so what else did you choose is is there anything else where you said okay timely is a good low-level library but we want to expose something different to user space uh let me think um timely has some facilities that we are not using and that I think would be interesting to people that want to use it directly as a library so one of the things we haven't done timely supports the idea which is uh I think pretty unique in uh data flow programming of the concept of doing iteration uh so being able to if you have this kind of like uh epical progression model in there what happens if you want to be able to uh Express a computation that needs Cycles so like in your data flow programming model you have uh a sort of uh directed graph of operations what if you wanted to introduce your kind of like uh for Loop inside of that computation and so timely gives you the ability to do that uh using compound timestamps which is not something that we actually use in biox but is really interesting for uh lots of different applications uh and the examples that I think that they give most commonly are graph computation oh like if I'm social network trying to do yeah okay so find me all the ancestors of this and then the sub ancestors and that's going to probably end up looping around on its to read its own output yeah yeah yeah okay so is that you've you're not using that because you don't see any need for it it's too complicated to expose to the user uh so far I think we just haven't we've been pursuing uh a lot of the things that I think were um an operational data flow are uh so when we first started The Primitives that timely gives you mean that um you're responsible for building some of the systems on top of that so we we talked earlier about being able to do stateful operations where you're maintaining uh some State as you're doing uh an operation the ability to do uh recovery the ability to do branching and joining was something that we had to kind of come up with an API for and then the concept of windowing was something that we had to spend quite a bit of time getting getting right so if you're a user of other data flow systems like Flink there's a feature set that I think you're primarily interested in using uh and we were tackling a lot of those first so maybe at some point in time we'll have the ability and the time to go back and work on iteration but it hasn't been something that we've had people ask us for specifically it's just kind of cool that it's a it's a capability that's there that we could potentially take advantage of in the future so one day you may find the killer use case for it but you've got plenty of work right now yeah I'm sure somebody has a a great use case for it but uh yeah we're working on um a lot of really interesting things uh just sort of of like the these are the sort of table Stakes if you uh want to provide somebody with a very useful uh data flow programming environment yeah yeah yeah okay so since you've mentioned Flink and it's always difficult when you're talking about like competing ideas you don't want to tread on people's toes but since you bring it up that one of the things about Flink for a python user is their python library is wrapping Java and your python library is wrapping rust do you think and then there are python libraries which don't wrap anything are in Native do you think what what's a users experience of you wrapping rust going to feel like uh no we have worked really hard to expose a lot of The Primitives that we have uh as a python API and have implemented a lot of the functionality that we have in Python directly so we started leaning uh we started the project originally leaning pretty heavily on all of the rust code and writing a lot of the stuff that we were doing in Rust and just essentially calling python at certain points in the data flow when where uh you your operator calls the logic for this particular operator and that returns a result and then rust carries on doing the major parts but I think uh my colleague David and the discussions that we've had uh we've learned that uh moving a lot of that API into python is really helpful for people that want to construct their own operators and so to answer your question we would like the experience of using this to be fine for anybody who never wants to learn any rust um in the rust layer are some really important uh pieces that Tom also provides the communication fabric between multiple workers so it's both like a library and a runtime uh for being able to orchestrate data flows uh some of those pieces will stay in R but a lot of the pieces that we're working on will end up having on python 8 and so for most people's experience it should be the same as using any python package it's something that you can use by doing pip install uh you write your data flow in Python you run it as though it was just a regular Python program and so most of the r stuff should be uh pretty invisible what's the okay so again um I want to be careful about mentioning Flink but the point at which you will find out that Flink P piie Flink isn't quite python is when you get an exception back and it's a Java stack Trace yeah what's the point at which I'm going to find out that bite wax isn't just python as a user uh you can definitely see some Rust in some back traces if you see the data flow crash uh although we did take a pass and we worked really hard at reconstructing uh one of my colleagues uh F has worked really hard on error handling and that look as pythonic as possible so uh reconstructing the uh the trace back of those and and seeing something that looks very pythonic and most helpfully pointing you to where in your code the problem lies was a tricky problem uh but yeah I think Flink is a is a great system uh I I have a lot of respect for all of the work that's gone into Flink and I've met some of the developers and they're they're great and I asked them you know do you have any advice for people that are writing their own data flow programming environment and they they said yeah good luck you know like it's it's a hard problem yeah it is they do it very well um but I think that python users deserve something that is very pythonic I think python users prefer not to have to learn uh everything that's in the Java ecosystem in order to be able to do uh the same type of programming I think uh I think it's great when people have access to I I need to express my problem using these tools and I want something that feels very native for me to be able to do that and I think that that's something that we do I think I have lots of friends in the python ecosystem uh who have always thought of themselves as like you know the the the neglected child in the ecosystem because you know everyone was writing Java and they're like this is great and it works in Java and they had to keep raising their hands and say hey it's not working for me you know I'm using this from Python and you know it's been hard for them to get enough attention and so uh yeah hoping they see it now yeah I'm I'm also hoping someone's going to do something similar for the typescript world MH I could have a lot of fun with that yeah um okay so so if I'm writing let's say give give me more of a sense of the boundaries of the system because if I'm writing something that processes my users transactions in a more interesting way I'm writing that in Python code what's happening under the hood is that is that being passed to a rust process which has a pointer back into the python code so it can call it yeah the I think the beauty of P3 is that um mirroring those interfaces together was pretty straightforward being able to call python code that way but I think the interesting parts were uh you're describing your data flow in Python and what that needs to do is is translate into a series of operators that are happening essentially on the rust side so those are timely operators under the hood uh but what we did was uh boil those down to a core set of operators that we could construct the rest of the operators that we wanted in those so there's a very minimal footprint in Rust for the shapes under the hood it ends up that um uh my colleague David did a very good job of like reducing those down to just a very small set of core Primitives uh so then the orchestration is essentially you're starting multiple workers inside of a python process and that is uh sort of animating the Machinery of rust to do the communication between workers when you need to exchange data uh you know stopping and starting a data flow uh and uh then at each point in time where you're processing data the uh The Operators under the hood are calling out to the user code that you provide as a part of your data flow you have a a map step that provides a function that you need to run at every time it sees new data uh a batch of new data ends up uh in that operator and then we call that and then move that along the data flow when you say we're calling it are we passing it to the the python function in process or we spawning out a separate python node which we give jobs to uh it's all within the same process so rust is calling into the existing python process with data that it receives so there's a little bit of translation sometimes when you need to serialize data and ship it to other workers and that means you know we have to serialize your python object we have to exchange it to another worker to deserialize it but then when it ends up back in Python you wouldn't know that that Stu actually happens okay but a lot of time it's just it's just another C pointer to here's my function yeah I think that's one of the advantages of the timely uh system is that uh for most use cases for a lot of use cases uh you don't need to serialize and deserialize in between those they're just passing them within the same process to different operators yeah okay great that that's definitely good for performance um let's so you've hinted at it then so we now have to go into Distributing across multiple nodes and parallelization so let's start with parallelization because that seems like the easier one to tackle python unless you jump through some hoops python is single threaded right MH so how are you parallelizing within one machine are you leaning on Rust for that uh no not directly um timely is also not uh it it it uses uh what they describe as uh Cooperative multitasking right so functions need to yield in order to be able for other functions to run and effectively like a worker can be thought of as as basically single-threaded if you want to in timely you can start multiple threads Each of which again is a whole copy of the data flow and is Runing with inputs and outputs that are potentially independent of the others uh for us that can be difficult right because as you pointed out uh in order for that to proceed if we're running all in the same python process and we spawn multiple threads you do have contention where you need to take the Gill in order to be able to uh do things in Python so I think that's what's so exciting about the potential of like a no Gill python uh sub interpreters in Python and all of the work that we were talking about earlier they they're coming they're coming right yeah it's also really hard uh the typical solution to this has to do with uh async uh you could think of like Co routines or other things like that those can be really difficult uh especially when you're thinking about well if I want to make sure that all of my output has happened and I'm using an asynchronous function to do that how do I tell uh my data flow system okay I finished doing that because essentially your asynchronous work is happening in the background could potentially fail there's not like a direct point where you can say have you completed doing that particular thing yet so it's a difficult marriage between data flow systems who are very carefully orchestrating the progress of data through a data flow and asynchronous systems and so generally what we do uh for people that want to interoperate with a synchronous code is use some of Python's underlying uh async to just run this to completion and tell me when you're finished kind of things so okay but yeah it's interesting also timely has uh not Incorporated a lot of those async pieces uh into the core part of timel for kind of similar reasons okay do you think you will or is it just like probably not a priority I don't know I think um I mean is it a design issue or is it a workload issue that means you're not doing that I think that's a good point it it could be both uh I mean sometimes you have to ask yourself whether or not um asynchronous solution is more appropriate or would be uh it depends on like are you IO bound are you CPU bound sometimes it's hard as a generic uh Library maker to make those decisions for people and to opt them into ecosystems where it may or may not be the greatest fit and so so far uh we've just sort of made it um possible uh for people to marry uh async code into a very synchronous kind of like workflow uh but but there was a new release of p 3 recently where they're adding better support for marrying both Python's async uh runtime and rusts async runtime and so there's some very exciting pieces of work that are happening on that side to make those two ecosystems work better together okay so if if it were a lot easier to do you might find ways to get it into the a into bite wax's API that fit more naturally oh potentially uh I think it was something we just hadn't focused on for a while and uh yeah I think we'll we'll see uh I think it depends okay so then the next thing is to go when we going across multiple machines how does that play out in timely and bite wax yeah so timely and bite wax both do the same thing uh you can start a process on a second worker and they will establish communication with each other essentially you give each worker a list of all of the workers that it should communicate with and uh you can start multiple workers threads in each one of those workers if you like uh but you can start them on multiple machines and they'll connect to each other so that communication fabric comes directly from timel itself and do you have to deploy like I've got I've written my code now now do I need to deploy that code to all the workers to get it up and running Ah that's a really good thing that we haven't talked about um I think one of the advantages is that there's no separate runtime for bite wax um and similar for for timely the process that you write uh the python code that you write has everything that it needs in order to orchestrate those so you don't have to take your data flow code and submit it to uh a cluster that is going to run that for you or to submit it to uh a specialized process that's running uh somewhere else to run data flows uh the same way that you develop locally you can invoke it with python is the same way that you deploy it remotely okay so I just shipped my python route is not like there's a I install some platform software on my cluster and then I can send it my recipe it's I just Shi my python code to all the nodes and run it yeah uh we do have a platform that we have for bite wax which incorporates a lot of the patterns of like managing um recovery stores adding features like a programmatic API to be able to deploy your code uh that's more of like a layer over uh kubernetes so essentially a way for you to manage data flows and deploy them uh it's it's based on a lot of work that uh anybody has done who has okay I've written my data flow code I'm ready to go to production okay I need to have a way to manage this I need some monitoring I need metrics I need a way to sign into the UI and sort of monitor what's going on and so we have a whole separate uh product that we built in order to sort of do the management of data flows okay you you've reminded me of another question I wanted to get to which was um what if I send it out to my six node cluster and one node goes down does does it get rebalanced the other five nodes do we have to wait for the sixth to come back up do we restart the whole job what goes on well in that particular case you what we would do is Crash and then restart from uh our last recovery checko which is essentially depending on what you're doing uh that's probably what you want like it's a tricky problem to be able to redistribute uh okay that one that sixth worker was handling a sixth of all of the key space of all of the users in our fictional um Bank processing platform uh so it had State about the transaction data for those people it had State about which new transactions it had seen when it crashes the other five workers would have to take on responsibility for that piece of state so that was something else that we did in bwax uh if you're not in the scenario where you're crashing and just restarting uh like you're restarting pods and kubernetes you can we built Primitives into BX so that you can rescale so you can stop the cluster restart it with a different number of workers and proceed from that point in time and the workers will take all of those pieces of state and say okay this worker is responsible for the state that that old worker used to have and the rest of them might be primary for other parts of that so we have a system built into recovery that allows you to do rescaling because you know obviously that's a pretty nice thing to be able to do we have a lot more load I want a lot more workers are you implying this is something the user asks of it or is it dynamically rebalancing no this would be something that you would do in like a stop start so let's imagine you had a flood of traffic for Thanksgiving and you needed to uh spin up a bunch more workers to handle the increased load that you're having uh you could stop the entire data flow and uh start it again with a different number of workers but yeah unfortunately if one of those workers crashes you'll have to restart from a known good point uh because we don't have a way to dynamically redistribute all of that state into other workers uh it's a pretty complicated problem and it's it was the subject of some research that happened in uh Zurich and so there's some interesting part of the academic nature of where timel came from means that there's some really interesting papers that were published and written about adding some of these systems to timely itself and so I think if you're a serious student about timely you end up reading um everything that Frank has ever written you read all of the papers that came out of eth Zur and uh all kinds of other things you just sort of uh devour everything that you can find sounds like an interesting place to be reading but perhaps um perhaps we'll go more into the practical application as much as I like Academia sure so we've talked a lot about bite wax the library do you want to tell me a bit about the service you've built around it yeah uh I think we were talking earlier about the Confluence of things that sort of existed when we created bwax originally and one of the things uh we were thinking about when we created bite wax was um for operationalizing or deploying data flows uh if you could do it again what would you do differently and I think the thing that we wanted to do differently was not require a separate um orchestration layer uh essentially uh in order to deploy you know spark or some of these other systems you need another system in order to be able to deploy those on and uh I think removing that dependency was something that uh I wanted to do so uh we built a platform just using kind of like uh uh kubernetes so essentially using kubernetes as the sort of ubiquitous back plane for doing deployments um so uh we built a platform that integrates with kubernetes that allows you to deploy and manage data flows it's essentially what I would have had to have build when I was uh productionizing anything if I was working uh at a company you know okay I've got my data flow it runs great on my local workstation I need a way to deploy this and uh manage it and monitor it when it's running in production and so we build a platform to sort of like encapsulate all of those patterns together so a way to see which data flows are deployed uh a way to monitor them and a way to manage them that just leverages the the sort of uh back plane of kubernetes under the hood okay so if I I'm thinking about getting giving a kicking the tires on this I can I know I can install bite wax locally with Pip install bite wax and then at some point when I'm ready to productionize it if that's a real word which I don't think it is I probably used it as well that's when I would uh that's when I'd let you um let you take the headache of cubanus for me yeah uh I think there are several options depending on uh for me for places that I've worked in the past it was always just sort of the default Choice uh for places they had a team that would manage kubernetes for you and so deploying there uh made a lot of sense and with the sort of availability of like those and major Cloud providers uh it was kind of like it's a great place to sort of get started if you're running multiple data flows um the other option is a tool that we created called wax control that allows you to just deploy uh directly onto an AWS instance or something running in uh Google Cloud uh it's also just very possible because we don't really need anything else uh to just start a container that contains a single data flow the fact that you don't need a second process to sort of monitor those things that each of the workers can connect to each other means that you can kind of pick and choose what's right for you but I think there's a lot of Advantage into Outsourcing some of the pieces that are necessary but aren't really adding value for your customers exactly so building a UI to manage uh data flows is not necessarily something that's like maybe the greatest use of your time uh we also created a program API for our platform offering which would allow you to say I wanted to deploy a data flow that does these things based on these particular conditions and so having some of those pieces uh can be really nice for uh if you need the sort of programmatic access to being able to manage data flows so uh those are the pieces that we put in the platform nice I uh for the record I'm kind of person that always wants programmatic access to things so that sounds exactly you it's great have a button that's awesome can I please have an API yeah cuz uh in the end everything should be uh controlled directly from emac or Vim That's My Philosophy nice yeah nice I love it well I'll go and give that a try then I think um I've got I've got always got some interesting data in cfra on my machine so I'll go and see how well it works in practice fantastic Dan thanks very much for joining me yeah thanks so much for having me this has been great thank you Dan and before we go I think a brief celebration is in order this is developer vo's 50th episode and at some point between this one being published and next week's it will be developer Voice's first birthday on the 10th of May so happy birthday to us and I just want to say thank you very much for listening whether this is the first episode you've listened to or you're one of the something like 19,000 subscribers over all the different platforms if you're a regular or a firsttime thank you very much for joining me and most of all thank you to the guests who've joined me every week and let me pick their brains I hope you enjoyed the experience you know from one point of view being a guest on this podcast is the easiest thing in the world you just have a conversation about your favorite technology but I have to admit from another point of view it's like a really stressful job interview where you absolutely have to know your system inside out cu you have no idea what the questions are going to be so to all 50 of you I hope you mostly enjoyed the experience I hugely enjoyed listening and learning from you thank you so until next week in the beginning of the next batch of 50 episodes you will find links to all we've discussed in the show notes if you've enjoyed this episode please leave a like or share it with a friend and make sure you're subscribed for episode 51 and Beyond until then I've been your host Chris Jenkins this has been developer voices with Dan Herrera thanks for listening