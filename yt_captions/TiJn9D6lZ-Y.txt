in what we've done so far we've ranged over quite an area because just the act of using the t diagrams has forced us to address lots of interesting and profound questions over the years about how compilers actually work so we've looked at the fact that we think of our programs being written in a high level language and the brain goes blurry we neglect to think all the time that although you they were written in c it doesn't execute directly you have to compile a c into binary so really your beautiful program runs on a suitable architecture in a suitable binary it has an input it has an output then we started looking at more advanced things about saying well if that's how a c compiler works why not write another c compiler in c and then compile it with the old compiler and i think we just about emerged from that with brain intact if you want to go back and revise some of this stuff before catching up with what we're going to do today i would recommend the one which we'll put a link out to call self-compiling compilers there's another one we've put out also on the uncoal problem which was this business about is there a common universal intermediate code there's more of a consensus now than there used to be and the llvm system is a good example it won the turing acm award for not quite for best intermediate code ever but you know the reason i think that it became less of a problem not totally solvable but less of a problem thinking about this the other night is that actually over the years certain things about computer architectures have converged and moved together to consensus and principally it seems to me is the idea that your unit of discourse isn't just the bit it's the bite and the idea of having you know eight big ascii characters fit into a bite and the idea of being able to glue two bites together to make a 16-bit entity or four of them to make a 32-bit entity that has become more and more and more prevalent the reason why in some of the other videos i've said oh you know there were such massive differences between machines there were in the 1970s i can quote to you as a fact because there was at the university of nottingham working on a machine with 24-bit words not by addressed at all what did you put inside your 24 bit words if you were mad keen on characters four six speak characters how did you dig them out from that word with great difficulty the word address machine would give you the whole word it was your responsibility with big shift operations and the garden spayed more or less to dig out four six bit characters non-standard not eight-bit characters and everybody saw well it's all right for ibm but it's so much more expensive building by stress machines but in the end it prevailed and i do believe that things like that about the fundamental way you address memory and being able to sort of put units together preferably in powers of two not multiples of two it's right at the beginning i had a 24-bit word atlas had a 48-bit word deck tens i think had a 36-bit word and seymour cray cdc had a 60-bit word all of those are multiples of two but i don't think any of them that i've just quoted are powers of two and it really mattered it turned out to have a power of two basic unit bigger than a bit eight bit bytes so anyway we've i use that to introduce the idea of intermediate codes but we're now i think in tying things up in a situation to revisit that now and say intermediate codes really are useful and come into their own if you like with the idea of wanting to port a compiler from one architecture perhaps to a very very different architecture what i call the semantic gap between your high-level language and your program eventually that runs on binary is huge it's not so huge in c you can feel the assembler and the binary poking up through the sea but you start trying to do a haskell interpreter or compiler and you'll soon discover that this thing running down here is so to speak miles away from the abstract stuff you were writing up at the top so everybody started saying don't we really need intermediate codes to help us bridge the gap hence zed code byte code for java all these kind of things became discussed more and more and more and i think i at one stage said don't imagine it's always fairly close to the hardware you could end up in a situation where c is your intermediate code beyond a stroke it got a c plus plus compiler started by in its early days just making it produce c which you know you can cope with what i want to have a look at today is this whole business of how do intermediate codes help you port a compiler from one architecture to another and you've got to remember that in the worst case those machines and architectures could be very very different indeed i did an example i think of running a c compiler on a pdp 11 in pdp-11 binary whose cross compilation effect was to spit out z80 binary which is very very different how can you cope then with cross compilation and how does cross compilation lead you on to being able to think about porting your compiler not just producing code for a foreign machine but in a way to mount an invasion of the foreign machine and so i'm not just going to push boatloads of code over i'm going to set up a bridgehead we're going to land and i'm going to set up a lot of my software tools on the farm machine not just fling raw binary at it so let's start to discover a bit more about this then but in order to get into the details i have a great personal mental expense made myself something like 40 or 50 t-diagram blanks and let us hope that those prove sufficient for their task i just want to talk you through this first of all as being the basis for what we're going to discuss and then i'll put it to one side but i'll bring it back if i need to refer to it again we are getting in to a land of intermediate codes i've glued four things to the page what are they well these two at the top left are what i will call source texts for your cross compilation compiler porting efforts what you're saying is from now on we don't compile directly from h the high level language to produce binary b in the code generator we do it in two steps we have an h compiler written in h producing i the intermediate code which i see is not on this list let's add it i equals intermediate code now on the left at the top are the source texts for doing this but if you consult the previous things we have done on compilation you will understand that it's not directly those that we can use because we can't directly execute h we have to put these through an h compiler and we end up with the binary executable versions of them now a little bit of extra notation here if you see at the bottom for this executable b dashed i use a single dash to mean the computer i currently possess my old computer the one i do all my work on if you see things like b double dash that means the new machine that i'm trying to port things to so we'll eventually get to that stage of getting stuff across and you'll see b double dashes appearing inevitably if you go this route your compilation down to binary is now a two-stage process it may be hidden from you but it has to be there the other half you see is if you're only going halfway to intermediate code the other half of the journey is to go from intermediate code down to runnable binary for the whole thing there's your intermediate code interpreter or compiler written in b dash running b dash producing b dash so i've numbered these one two three and four and eventually i'll come back and say we've now created a new number three or something like that what i'm going to do in this whereas in previous episodes i've talked about recoding a c compiler to make better binary come out i did that previously by calling it subscript b for better but i've decided now that you use an asterisk if you see an asterisk somewhere it means it's a better version of what went before and i as intermediate code so let's put that to one side to be dragged back as on when we need it when you write a program you have in mind a certain input it executes and it produces a certain form of output and you're very happy and it all works beautifully rather than rushing c down here as i have been doing all along i'll try and generalize it a bit say some high level language that you're confident with and have used for ages but all the while you know so this is if you like user prog here you are you know that h can't execute directly so you rely on the fact that bootstrapped up over several generations we just happen to have an h compiler that runs in b dash and produces b dash by slotting that into there remember there's an implicit arrow there that h feeds into that one there and the transformation done in this compiler is to take the h and convert it into b dash with a compiler that is now an executable binary itself so the net result of all that which will show up here arrow says what that makes once you've compiled is of course something that has your treasured input and output but is running h running on b dash produces b dash so that is the binary executable version of your program what happens if your input and output was h itself can you write a compiler in itself of course you can this is what all this is about you want to produce an h compiler we'll start off by writing an h compiler in h so we'll put this back to one side now these two what happens if i were to say well i've written an h compiler in h and it produces b prime star what i'm saying is i am fed up with playing old b prime because it's slow and it's inefficient and it was wonderful when i first did it and actually this thing up here has been bootstrapped up through been written in assembler and heaven knows what see previous episodes if that sentence doesn't make any sense to you but now we have got a situation you want to improve the quality of your binary so here's a bit of revision what you do is you say okay i write a better c compiler better in the sense of better quality binary i feed it to the old compiler that we've got working already which takes in h runs on b prime produces b prime and what does that end you up with answer an h producing binary it's running on old binary that's not super quality but it's okay it doesn't crash it's a bit slow just to end this little exercise off before we get on to genuine porting compilers you've got that and you naturally then say well why not feed it to itself again and if you get another version of that feed one into the other you can end up with h written in better binary producing better binary and if you look up self-compiling compilers that's exactly what we do so it's all very well doing this simple-minded stuff we take one great flying leap in our compilers and require the code generator to be able to get very low level very specific and yet be very very tight and wonderful for all sorts of different binaries for different machines b dash b double dash b prime that's hard so we've decided that intermediate codes might be the answer so how do we cope then using intermediate codes just with this business of improving your code how would you do it well it has to be a two-stage process no question about that it has to be so this time i've got an h compiler written in h and this time i am going to make it produce better intermediate code than ever before so you see think of it this way when you upgrade a compiler you've now got two halves to upgrade do you want to upgrade the h to intermediate code piece the front end so called or do you want to upgrade the intermediate code interpreter going down to binary the back end you it's a mix and match you can do either or both or in in whatever order you like but you've got to remember it is a two stage process fortunately for me i have already working an old compiler for h running on b prime original machine binary i'm producing ordinary intermediate code not super intermediate code i've written a better version of myself now and i'm upgrading this front end so we've got h written in h producing i star better quality intermediate code in some sense than went before but the old version of the compiler i've been using for months now just has h running on b prime producing ordinary intermediate code not optimized but it's good enough for compiling this one the only thing that's different from what we've got before is that we don't directly end up producing binaries the output we produce intermediate code as the output so this first stage then will get me the following h fits into h running on b prime produces i means that this thing takes in h produces i star and is running on i okay fine so we've kind of recompiled the compiler but we haven't gone far enough yet and this is the the ball and chain around your ankle when you go for intermediate codes is you've got a better thing but it is reliant on running being able to cope with the fact there's an intermediate code stage okay that doesn't put us off what i've said all along is that these are my key source texts these are my executables and what i'm pointing out now is if you use intermediate codes you don't just need a source end translator you need a back-end translator you need a thing that says you know my system produces intermediate code i am the back end that takes in intermediate code and produces a real binary that really will run so i want one of those now to put into my diagram this is what we're at so far let me gobble up yet another t diagram and to say if i put in here what everybody ought to have available to them which is an i producing b prime written in b prime i can now slot that in there like that and just look what happens you've got your first stage compilation it's doing wonderful things but it's executing intermediate code and maybe you have a test interpreter that sort of shows you whether that's kind of working but in the end you want faster more efficient code so you decide you will compile your intermediate code into proper binary and this kind of choice between do i interpret it slowly and see if it's working versus do i in the end commit to compiling it is the sort of thing available in stuff like java byte code and so on start off by interpreting feels a bit slow but it's looking good let's compile it now watch what happens as you trace through here i goes in here this is the intermediate code compiler if you like now producing genuine binary that shoots through there and what you end up with is h producing i star better quality intermediate code running on b prime right well we're getting close there's one final thing though that you need to do what we've got ourselves now is a situation where we've got a compiler that takes in statements in h it is running on b prime binary ordinary unimproved binary but it does produce better intermediate code we're now going to pull the same trick that we've done before in self-compiling compilers the only difference here though is we've got this eye to cope with this time but the principles of what we're doing are just the same if i bring this one down to stop me having to write out another one we've now made a binary out of that feed it to itself originally i started with h i start to age i compiled it all the way through to intermediate code as best i could it's good quality intermediate code now take that thing your executable feed the original thing to itself and look what happens the h goes in there and produces i star so you end up with h i start i start final stage coming up i promise so that if you like when it goes through its machinations produces that one final stage and i promise the torture will end right now you might say yeah no big deal i can write an intermediate code interpreter and check out rough and ready it'll be slow but check out whether everything works but then somebody in the answer goes come on let's compile it it might go a lot faster so if you remember item number four in our original toolkit was a thing that takes i and turns it into binary so i'm going to put one of those in place now for that all the way through what will that produce you don't forget we're starting h producing good quality intermediate code so that is what it produces but what about here if you trace through better quality intermediate code should hopefully give you better quality binary when you compile it so i can put down here that this is basically if there aren't too many suffixes and superscripts there it's producing you a hy compiler but running on better quality binary so one way and another this is the new three because referring back to our original map what i've said is how can i improve that and i have managed to improve it i've got better quality intermediate code and better quality binary it is improved but it has been a fairly messy two-stage process that's hidden from you but the idea of that is to give you just the notion of the fact that there is a penalty to pay you have to have a two-stage process so we've expanded a lot of brain cells i think between us now discovering how we can improve our compiler which we did do before in self-compiling compilers episode but this time it's different how can you improve your compiler when there's an intermediate code involved and we've done it and we've seen exactly how we can do it we feel weary or at least i do but that is it and you might say well why bother with intermediate codes it's just producing more stages that we have to go through well the answer to that i think is that it does make life more easy for you if you say okay instead of improving ourselves now within an intermediate code context how about we say i don't want better binary out of it i want different binary for another machine so we will find that the diagrams that i've just drawn with some subtle adaptation and me getting all tangled up probably can be adapted for producing binary for a completely new architecture which we'll be calling b double dash what we're now going to find in this next one we're doing is we're just changing the rules slightly instead of b star improved binary we're moving from b prime to b double prime so now if we would know how to solve the problem for three disks