could python become a high performance parallel programming language that seems unlikely I mean there are some fundamental architectural reasons why that feels like a bigger shift than python 2 to Python 3 and that was a big enough shift already but I raised the question so that I can flip it on its head could a high performance parallel programming language become python that to me seems more reasonable start with a lowlevel compiler level language do all your performance work figure out those parts and then when you build up into user space and choose a syntax why not python now that broadly is the approach taken by the new language Mojo and its creator Chris latner if you've not heard of Chris I'm certain you've heard of his work he created llvm he created clang the other Big C C++ compiler he created Swift the language of shiny Apple products everywhere he has serious form in language design and he's one of the few people I know that actually could run the gauntlet from python syntax all the way down to CPU and GPU and back and he has some really interesting ideas for his latest language like let's do python but bring in a gradual type system let's make parallelization a first class concern let's give the programmer direct access to compiler instructions lots of interesting new toys is in familiar clothing so I suggest we go and take a look at it I'm your host Chris Jenkins this is developer voices and today's voice is Chris [Music] latner joining me today is Chris latner Chris how are you I'm doing great that's thank you for having me Chris absolute pleasure it's not often not often I get a guest with quite the CV quite the resume as you say that you have you've you've got a heck of a backstory which we could talk about in itself but we always talk about the future on this podcast so let me get this straight you've been part a founding part of LL yeah that was my Master's research project yeah that's a good start you didn't rest on your laurels you went on to clang and Swift yeah also nights nights and weekends problem yeah nights and weekend project for a year and a half and then it kind of grew a little bit beyond that so was that how it got started yeah yeah so I mean I'm the kind of person that I'm uh working on the thing I'm supposed to be working during the day but also like pushing boundaries during the evenings and so um in the case of Swift We were wrapping up the clang C and C++ compiler and C++ is a very uh interesting informative language very challenging technical problem to implement and at least for me I could not survive that experience without thinking maybe there could be something new and better and so this is where Swift started bubbling in the background and and eventually got to the point where I could understand what it was that I was building and working on and then shared it with some other people I um I always feel like Swift was the language that saved people that weren't me I do I spent a good number of years writing Objective C okay kind of drowned and got off that boat and then Swift came along just as it would have saved me yeah yeah Swift is a great language and it was a lot of fun I learned a lot from that so for sure this is thing so with a with a background like yours there's almost no point asking you why you're writing a new language because it's kind of it seems almost inevitable that you would write a new language and what we have to talk about is why this one yeah well maybe you could flip around and say given you know how hard it is wow could you be insane enough to do this again well you were glutton for punishment yeah well so I mean I'm not afraid of hard things I guess I I think that is true but but really was uh I mean you've talked many folks that have built languages and are working on it and everybody has different motivations um for me it really comes down to uh solving a problem and so I actually resisted building a language so in this case Mojo um because having gone through for example the Swift experience um before that I also built opencl which is a a GPU programming thing many years ago um when you when you start from that let's go solve the programmers problem typically start from syntax yeah so in the case in the case of Swift started with okay I want autoc closures and I want these higher order functional programming things and I want to be able to compose that in into the lvm compilation flow and all these kinds of things and yeah very much started from syntax in the case of Mojo at modular we started with a how do we make gpus gpus go Burr how do we make these crazy high performance CPUs that have Matrix operations and B flat 16 and other AI extensions how do we rationalize wide array of different hardware and put it into a system that we can program it and what's changed in in Hardware is that it used to be that you know a CPU would come out every year and it would be slightly better than the old one and everything would just magically go faster uh a compiler might do a different instruction scheduling or certain code generation tricks but but generally if you recompiled your code Old code ran faster but today what's happening is we get all these really weird dedicated Hardware blocks these these are very specialized I mean the most extreme is a GPU um and so being able to program these things requires fundamentally different kinds of software and so uh what we started on at modular is not building a language actually what we started building is a very fancy code generator that had no front end and so we just built pure compiler Cen stuff like replacing big chunks of lvm replacing and building new ways of synthesizing high performance Loop nests and things like this um and then just wrote everything in IR directly and so we were using really in this case uh built a built a new compiler framework called mlir it's now part of the lvm family but it's it's a next generation replacement for lvm in many ways and so that allows you just write ir and so we did that for quite some months to just prove out that the Cod generation philosopy and the stack could work and deliver the results we wanted and then when we had confidence in that we said oh okay cool now what do we do about syntax oh right well I have to ask what's it like to write ml uh so ml if you're not familiar with it is um uh it's uh it's like you know so Mojo is to Swift as ml is to lvm so lvm is super widely used it's 25 years oldish at this point um it's it was brought up in a mode of with a philosophy of there should be one IR to rule them all it should be the lvm IR that many many compiler folks are familiar with with um and that was great for a generation of things that look basically like C or you could desugar down into something that looks basically like C and so lvm is you know I kind of joke it's C with vectors plus exceptions or C with vectors plus debug info or something like that right so it's in that kind of category of representation but again when you start getting into gpus other accelerators what you end up wanting is multiple levels of abstraction something more like you know the has GHC compiler or something like this where you have many different lower lowering phases and you're exposing different optimization opportunities to different levels of abstraction and so in 2018 I led a project to build this thing called ml which is a replacement for lvm that allows making domain specific compilers really fast and so it provides a bunch of the core compiler infrastructure the IR representations the pass managers bisecting tools like the ability to Parson print ir and all this kind of stuff uh and allow use a compiler hacker to be able to focus on your domain and so you can model your design your type system you can design the structure of the operations you want to manipulate and things like this um and so mlr is a very useful Swiss army knife for building domain specific compilers I've I've used in the past to build like Hardware synthesis tools and like all kinds of stuff and so um and so so that's what we were using and one of the great things about ml is it has a text form and so you can just write the text form okay but I'll say writing ER by hand is really painful right I mean it's not that's not that's not actually a good user experience it's something that you can do to prove a concept but You' never want to expose that to users just I imagine this a pretty fuzzy question but is it lower level than C higher level just different it's it's uh domain independent and so you can use it to do uh like machine level code representation if you'd like and a lot of people do that for um for accelerators and things like this uh mlr is widely used in the machine learning code generation Community for example um but but uh we use it for our EST and so you don't need to use it for any particular thing and in the case of Mojo we don't build an a traditionally we actually just generate mlr directly from the Purser okay okay so then in that case we have to go both down into the hardware and see what you did with that but why don't we go up into user space before we get those bed just briefly you so you've proved out your theories to a degree that you say you want to send this approach to the world yep now it's time to put a nice now it's time to put lipstick on on our pig or let me let me use the git metaphor we'll put porcelin porcelain on the plumbing yeah okay so and you've chosen to go quite close to python right yeah why that yeah so when we when we decided okay this seems to be working we think we have a novel and useful cogeneration approach um we had to decide how are we going to get this ir and there's a couple of different approaches one is um and by the way building a programming language is insane and we can talk about why um but uh the obvious thing to reach for is a domain specific language embedded in some other language and so use for example Python and use like some decorator based approach or some way to like stage out something and then generate IR by walking some other language which is um the other approach is you say okay go build a language another approach might be to say build a source source translator or something like that and so there there's lot lots of different technologies that we can use and so in our case you know we're targeting this AI World we're targeting this emerging world of high performance accelerators gpus everybody's dying right now because of how complicated this stuff is and and how challenging the programming model is and so we decided okay let's do the hard thing let's let's let's eyes wide open we understand how hard it is to build a programming language uh let's do that and we think the cost benefit trade-off is worth it and let me tell you why it's a bad idea to build a programming language I mean you you you probably know but it's it's not just about building a grammar or a compiler you also have to build all the tools you have to build code form rors and you have to build a debugger you have to build this entire e you have to have a library ecosystem you have to have developers who care you have to build the technically difficult thing in the right way so there's a lot design and package manager and LSP and channel and yeah that's right that's right and so in the case of Mojo we said okay well and and as you know I'd been through that with Swift and so yes we built we bike sheded all the syntax we build all the different things and so what I realized is that I want to control some of the risk but also meet developers where they are and in AI in particular python won like python is the thing yeah and so and so everybody uses Python and so if you want to pick anything not python you'd have to justify why not P why why it's better than Python and saying oh I have curly brace is a set of tabs like isn't actually a great answer because at the end of the day while I and you and many people of programming languages people have muscle memory and so I care about the hundreds of millions of developers who already know python right and them not having to retrain is actually a huge feature from an engineering and a design perspective it's also very useful because we already know what the language looks like so we don't have to bike shed all the things it's way easier to implement something when you know what it is versus having the first principles everything and and have to rationalize this now Mojo is a very extended version of python we could talk about what it's all about but there's still design work but at least we could focus our energy yeah most of those early decisions are made for you yeah exactly and so like for example python uses this fairly goofy postfix Turner thing with you know the if goes after the condition and stuff like this oh yeah yeah that is not my personal cup of tea but it doesn't matter it is proven it exists it works and and if we were to change it we'd have to massively justify why we want to break compatibility or break familiarity or break all the training that people already have so it just really anchors the project in a very convenient way okay yeah yeah I can see it I have to ask though if you're if I were building a language that was Focus focused on like high performance and optimizing for gpus and all that stuff I would be torn between going after the ml data science world and the gaming world yeah you you could have gone for those you could have gone for PlayStation 5 programmers right sure and there's a lot of money in that what did it tempt you uh well so not really honestly um just because we're Mission driven we have a we have a specific thing with gpus and accelerators and Ai and and this this problem is burning I've been in the space for five six seven years at this point and so very much on that track um but without loss of generality Mojo can be used for lots of different things and we have people building uh like guey libraries and web servers and everything and so it's a general purpose programming language it's uh we can talk about the nature of the language but the uh but it is fully general purpose it's just that our design points were rooted in our use case and the problems that we're trying to solve and um and there is no language out there that does what Mojo does and so solving for those you know that was another option is just use somebody else's language right and so if there's another language out there it would be great to just not have to do all this work because we could get on with life and focus on other parts of the problem so yeah yeah I can see that I can totally say that so before we get into I will say we do we do have a number of people on our team that are uh coming from the games industry so okay so you've tempted you've at least tempted some of that audience across too yep okay so before we get into what makes Mojo different let me just quickly ask uh I've written plenty of python if I came to Mojo how familiar would it be would would it feel exactly the same until I started using the new things yeah so so Mojo's not done yet it's probably halfway through it development journey I would guess roughly um but when it's done it will be a full super set of python and so if you're familiar with python then you know about the python 2 to Python 3 transition it just about killed everybody involved it sucked energy out of the community for 15 years it was it was kind of a gigantic mess and the reason that that happened is because it was um you know similar but different and and packages could not interoperate with each other you couldn't have a hybrid half python 2 half Python 3 Program yeah became exactly and so that was a huge problem and so in the case of Swift what I learned is I mean Swift is a completely different language than objectivec but what we did was we very successfully migrated over the course of years but progressively migrated the objectivec community over to Swift and we did that by making it so both worlds could live together you can cool one from the other happily exactly and so that way you can decide okay well this third party package I'm using I'll leave it as Objective C but I'll write my UI or whatever it is that I want to do in Swift and and I'm not in this Log Jam where everything has to move over and so um in the case of Mojo right we're building it into a full superet of python and so all all the the python idioms and stuff like that whether they're a good idea or not will work in Mojo um but even today you can import arbitrary python packages and go to town and use them and and you can mix and match very directly and so um we're continuing to make progress on more Dynamic features in particular because as you say we're we're climbing we're climbing from the accelerator so it's Mojo is a really good replacement for Cuda we're getting into the it's a really good replacement for rust and then eventually we'll get into the it's it's a good superet of what python is love for but but we have to do those steps and we have to build out the features as we go yeah yeah yeah no matter what happens when you're writing a language you're climbing some kind of enormous Mountain yeah and that's the shape of yours so does that speaking of the size of that mountain does that include things like um the do you support Python's interrupt with C syntax and approach uh we haven't decided that actually so um so one of the very big so as if you're a python programmer looking at Mojo one of the things that's really interesting about Mojo is that it is pythonic and it's it's growing into all the different Dynamic things that python can do but you don't have to switch to a different language to write high performance code right so if you think about python python um like Objective C actually since you're a veteran uh Objective C and python both have the fully Dynamic objectoriented we want all of our apis to be built in objects world but then it has the Dark Truth of you know all the important stuff is written in C or C++ right and so yeah a lot of you look at numpy is just one example it's a very nice python API but it's all written in cc++ wrapping until mkl and all this kind of stuff yeah right so with with Mojo you can write all of that stuff in one language so you don't have to switch out and the way that works is it's a progressively typed language and and it has real types not the the mypi types that python currently has and so um plus it has really fancy compilers all Next Generation stuff that that has been created over the last couple of years from uh you know learning from Decades of other stuff that got built and so the consequence of this is that you don't have to switch out and so that integration with C uh the reason it's challenging is that python exposes its full object model to C code and so we actually fully support that right now because we can talk to python we can talk to python C modules and so that already works but there's a question at the low level of like do we want to support that like really lowle binding when talking to se bindings or do we want to encourage the community to just switch stuff to Mojo or not and so we haven't we'll figure that out so it may be in the future that whilst you can't use the python wrapper around the um sea Library you might find it very easy to go direct to the Sea instead right well and Mojo can already call the sea and so that's all that's all good yeah okay so uh you've you've pricked my ears on one of my favorite topics which is types okay because you've got I I read on your website you've got a progressive type system yep in Mojo and I actually don't know what that is because it's not the same as a gradual type system right yeah so maybe I'm not being very precise on terms um I'm I'm also by the way an engineer I'm not a mathematician so just as a disclaimer and so I uh um but sure so what's the question how can I so tell me about Mojo's type system and is it opt in what kind of type system is it how much do I have to learn to use it yeah okay so all good questions um so start with um how do you get a typed language to talk to python so this this is this is the very first question then you then you have to ask what is the existing python type system right and if you ask a lay programmer they would typically tell you oh well python doesn't have types right and then if you talk to a more advanced developer they'd say oh it's has Dynamic types right and so there is a list there is a dictionary there is a string or an INT but it's all runtime right yeah um as somebody who knows programming languages and likes some static languages now and then we could say python has one type and that one type is a reference to a python object and because there's one type in Python you never spell it and so that's how I would say python is a actually it has a static type system it just has one type okay yeah I can see the ENT so now if you go down that direction you can say let's give this thing a name and so in the case of Mojo it's called python object we we'll decide if we really want to consider it python object forever if we want to shorten into object but but it has a name it's called python object and now you can say hey well I have a new type I'm going to call it int right or whatever and or string or whatever and so when I say something is an INT that's a different type okay I can have conversions from one to the other and I can I can make these things integrate and operate but if you're a programmer you can say hey this thing is an INT and now of course it's not boxed of course it's on the stack of course it's you know the size of your the word on your machine or whatever right and and of course it works the way it would work in CR C++ or something like this and so you can have the ability to opt in to a fully static world and so again we work with CPU and GPU high performance numeric programmers they never want anything dynamic they want full control over the machine they want full control over very fiddly lowlevel optimization things and so you don't want these worlds where it's like hey Yeah I'd write some Dynamic code and we'll try to di virtualize it that Community wants it's it's like the the rust ideal in many ways it's like I want full control I want predictability I want you out of the way and so we can provide that and then if you start removing types you can get fully Dynamic if you'd like okay so if I say that something is a is it I'm thinking of pure script here where I can say um this thing which is just a foreign thing coming from the world of JavaScript I declare it's a string and now you're going to treat it like it's a string um and it might be almost anything under the hood yeah we're we so we we are not in the mode of so there there's a whole class of languages including uh typescript and uh even python itself where it's saying the fundamental nature of the universe is untyped but you can provide type hints and those type hints can be used to inform error messages or other things like this we are not that that is not what we do okay so we we have we have types and we have python object and if you want to go from python object to an INT you do a conversion okay so there is it it's not just and that conversion is checked and so okay there there's no like trust me it's going to be okay typing it's it's actually typed like and and this this is actually very important so and then the nice thing about this is it all composes correctly through the type system which is you know the big thing um if you dig into so that that's the very top level how do we handle prog what I would call Progressive typing maybe it's the wrong word I don't know um again I'm I'm still new to languages I'm still working on this stuff but the um but within the stat type system then you can say okay well how does it work well it's both uh very boring in some ways but it's also I think very boundary pushing in others and so it's boring and that it uses like it you know we we learn category Theory we understand how like traits and rust and protocols and Swift and like all these things work and so we're just taking you know a modern statically typed generic higher order functional type system like many modern languages have and bringing that in I don't think I mean it's it's nice and it's important to get that right um but uh it's pretty familiar to people and I think familiarity is good um the uh the other side of it though is that we are very hardcore about pushing things into the library and so if you take a look at rust for example but in this case I'll pick on C+ because it's an easier victim um C++ it's a it's a very powerful language you can build high high quality libraries in C++ but but because of its historical Roots it burns a whole bunch of weird things into the language and so for example complex numbers are STD complex a template but float and double are built into the language and so there's certain things certain conversions certain weird things that only work with built-ins that can't be exposed out to to library so for example you can't overload operator dot in C++ you can't build a smart reference right it's just a super I I think that's one thing that's been driving BJ and nuts for decades now but and so in Mojo we take a very aggressive approach on this which is say push everything that we can into libraries and push the magic out of the compiler and so right and so int is not built into the language float is not built into the language like these things are all just libraries and so they're just structs okay and so the way this works is that you know they're the the type system composes and we use it for all the built-in things and yes Strang and array and all these things of course are also written in library what that forces that forces the language to provide only the core Essentials for expressing libraries and we want everything to be ergonomic and very Dynamic and flexible and Powerful for the python folks Etc and so by doing this we you know the the the compiler language Library divide is balanced a little bit differently than what you'd see in traditional languages right yeah this is reminding me of when I first learned in has scho that um booleans aren't that yeah they're not CAU of the language it's just they provide you the tools to Define booleans yeah otherwise is is just alist for True right okay so so how does that actually work if because I see a tension there between all the main types are kind of user SL liary space to find and I want really really high performing optimization for an array of ins yep well so on one side um old tricks are the best tricks and so Mojo believes in zero cost abstractions for example and so zero cost abstractions are seen in C++ and rust and many many languages and so um nothing wildly Innovative um uh the way we do it is pretty Innovative because we have this fancy ml compiler stuff behind the scenes um but but the concept is the same but what that does is that allows you to stack up Turtles okay so you can you you can have a lot of turtles and we're good we love abstractions and so we can we can stack up Turtles like anybody but you have to have something where you bottom out like there has to be something underneath that bottom of the turtle right and so uh Mojo by design it fall it it takes a lesson from Swift and then takes it 10x which is in Swift I sometimes used to joke that Swift was a uh syntactic sugar for lovm yeah so Swift in was also defined in the library Swift int was also a wrapper for an lvm i32 or I64 you know the underlying IR thing and the way that worked is that Swift at the very bottom could talk directly to lvm Primitives and so what you're doing is You're Building syntactic sugar you're defining types and therefore overloading operators on and doing all this stuff to build up these core operations U Mojo does basically that same trick but it supercharges it by moving to this ml world and so ml being a much more modern compiler stack has way more powerful features um we can expose things like you know float float 4 and like these really weird numerics you see on accelerators we can do all this like very uh um again we're we're talking to accelerators with tile map moles like the tensor core on a GPU and things like this and so we can talk to all these really exotic um features and then wrap them in really nice libraries and so you get the benefit of the power of the hardware and direct low-level access to very crazy exotic things but then you have syntactic sugar built in libraries and now you can extend the system extend extend the language without having to be a compiler nerd which I think is very very important how does that actually look because that sounds that sounds fascinating but I'm wondering like let's say I decide that I'm going to write a complex number library for Mojo right which I write it's simple and because I'm writing B yeah you have a structal two floats in it and then you know you go and overload the underbar underbar ad method which is the python way of overloading the operator plus right and so yep but at some point am I going to say oh I can tweak this if I just mix in a bit of mli code yeah if if you'd like to so for example um use complex numbers complex numbers are Hardware accelerated on certain chips and so um and so it's not just like add of two complex numbers because you're just adding two floats but if you do like a multiply accumulator or if you if you do like a complex multiply includes I mean my math is Rusty but it's like four multiplies and a couple of ads or something like that there are these uh certain CPUs have operations that just like do that in one one shot and so you could say okay well effectively like an if def we have a compile time meta programming system that you'd use to do this instead but like effectively like an ifdef if def I'm on this system I have this feature go do the optimized thing else just do the generic thing and then now you have full access so I can do optin as a library writer I can do optin Hardware level acceleration that's right yep yep and still have a nice fallback okay that's fun and and and and your clients don't have to worry about it and that's actually the really powerful thing so and would I be able to say things like if I'm on this architecture do this and if that do that if all else fails just use Python stuff yep and and again Mojo has superpowers because of the domain it's in so you can write one piece of source code and that source code runs partially on your CPU partially on your GPU and these may have different pointer sizes and may have different numerics and capabilities and the the way the whole stack works is it Sports this code slicing thing and that's you know there there's these very deep fundamental very nerdy compiler things that enable things to just work in a in a way that people aren't quite used to okay this is fun because this means like I potentially you could see a few someone writes a really useful library but it's not fast enough and someone just PRS in the hardware optimization without changing the programming language yeah well and also we've so again Mojo designed in 2022 instead of uh 2000 or 1980 uh you know we have we have things like simd so simd vectors are a thing all all computers have them these days we have direct support for that direct support for explicit vectorization so you get full access to the hardware and so um it's been really fun seeing Mojo developers worldwide where just take something like you know Game of Life or whatever and they just say okay I'll start using this I'll try this oh hey wow it's a thousand times faster than the code I started with that's cool right and you know just because again with Library basic sensibility or vectorized function it's just a library function and so it's like okay well I will vectorize this code by using a combinator from the library and just going to build into this one step at a time and I've seen tons of people go through this growth path where they're like oh wow this is really cool and oh wow I'm having fun oh wow I'm building something interesting oh I'm learning something right and this is where I think people love going through the growth path okay well in that case we have to get down now into CPUs and gpus properly I think sure so what is it that you what are these theories that you proved out in mli mli space that make Mojo compelling to you well so the uh we probably shouldn't dive deep into that because can stand the language stuff but I'll give you some intuition so in the in the AI space what what what so I'm I'm in love with AI for both the user applications which is what most people talk about but also all the systems and all the technology that that got built to support this and to tell you one thing that I find fascinating is that today so I worked on uh the TPU TPU project at Google and so help bring up these massive data center accelerators with exaflop computers right they're they're they're super computers with thousands of nodes and all this stuff and one of the things I found uh just super inspiring is that we have uh today you can sign up for a jupyter notebook on Google cloud and get access to one of these things and with a few lines of code you can now be programming an exaflop supercomputer and you're you're describing a novel computation and it gets mapped partitioned scaled out across thousands of chips run it like massive data center speed and this is what HPC people have been doing for a long time but now you have ai researchers doing this right they're not they're not writing MPI code or you know lowlevel high performance stuff and so what what what enabled that is that enabled uh or what what what what made that possible was a shift from completely imperative programming to declarative programming okay and the way this works is that in AI you build a machine learning graph I mean there's many variants but for example you build a machine learning graph and you have the AI researcher thinking about the level of hey I'm going to have a matrix multiplication I'm going to have a conv solution I'm going to have gather or reduction or whatever and so I'm thinking about it's it's almost like APL again bring it back to uh uh language nerdery right um and so they think about simple compositions of these these highly parallel operators and then what you do is you give this graph to a very fancy compiler stack which then takes this and does not just um picking out functions that Implement each of the operators but it's actually doing Fusion of the Loess and so you're taking you're taking this very complicated math doing very Hightech compiler Transformations and then also dealing with distribution across clusters yeah and and these things you can do because it's a declarative specification right if you try to if you try to take a pile of C++ code and parallelize it right well good luck with that that's not that's not a thing right but if you say hey run four copies of this across four machines well that's easy to do relatively speaking right and so um and so what what this whole stack evolves into in the case of Mojo is we have um what's called the max engine the max engine is a very fancy AI compiler stack it is um it's kind of like a xlaa but after learning a lot of lessons familiar with these things and so it can run machine learning graphs but we want it to be able to talk to the imperative code and so you need to be able to write custom operators you need to be able to invent new algorithms you know if if if modular doesn't know what an fft is but you you do and that's really important for your signal processing domain then you need to be able to provide an fft but we want the stack to be completely extensible and so what Mojo enables uh people to do is you can write WR an algorithm very simple familiar code it's all it's all good you can understand it because you're just writing source code yeah in contrast Cuda is kind of its own little world and it's very not python right and so and so instead of writing Cuda kernel you can write some Mojo code and then the graph compiler and the other stuff can suck this up because because of ml we can now reflect onto it and we can see what the code is doing and so that allows us to take it do these fancy compiler Fusion things and do the placement do theout all all this stuff and um and that's something the world doesn't have because in the AI space the state-of-the-art Technologies I mean there's a lot of stuff out there it's very crowded space but the state-of-the-art Technologies um are built around Cuda and they're built around math libraries like Intel m K and things like this and these operators are all black boxes and so there there exist these fancy graph compiler things but they don't actually have the ability to see into what the the logic is that they're orchestrating and so they can't do these high level Transformations and it just is very janky in various ways and so again part of our mission is to like solve this take all these systems a major step forward and so this is what drives uh you know Mojo needs to have extremely performance right because we want to push state-of-the-art on performance versus vendor libraries that do Matrix multiplications for example it also is why we care about usability because we have people that are using same thing to build graphs and they're used to Python and so we want to meet people where they are you know they're used to pytorch or something like this right and so you know it kind of all flows together and that's that's where we're coming from okay so there is there's a hard divide between the world of building up this data graph and building creating custom nodes that you would insert into that graph well and then and then yeah and then and then to make it even more funny like I don't know um how deep you are in the AI space but it's so funny because um the traditional tensorflow pytorch things were designed uh eight eight or 10 years ago depending on how you count they're coming from a research world they're coming from an AI training world but today roughly everything not everything but a huge amount of the focus of the AI industry is shifted to deployment and so when you get into deployment mode you're shipping and running an AI model on a server or something you don't really want python in production and so it turns out there's some challenges I mean it can be done but there's some challenges with that and so and so what we've entered into this world is we have researchers who love Python and live and die and breathe Python and and it's great for their use case but then you have production people that have to rewrite these models and rewrite the tokenization logic for your llm in C++ or rust to be able to ship something oh and so a big part of what Mojo is actually about is by solving that problem by having one language that can scale we can heal this divide between all the personas that are building these systems whether they're high performance numerics people whether they're deployment Engineers whether they're AI researchers and get just get everybody to be able to talk to each other because they're literally speaking different languages and they they and you're massively impacting AI getting into production ction I had no idea the AI world was divided like that into different hats yep is that sh is thats law striking again well it's it's it's an evolution of a lot of very uh very good very well considered systems that were locally developed aggregated and then Hill climbed like crazy because AI has changed a lot in the last 5 to eight years and and nobody's had a chance to go back and first principle some of the technology right you look at that eight years in Computing is nothing right that is that that is nothing and so all this stuff grew really quickly and so um you know this is this is where you say building a programming language is insane well I I I mean this my words not yours you're too polite to say that but um but the uh you know I don't think it's insane it's just a multi-year project right and so you can you say okay well what are the benefits and the cost and benefits of doing that well you have to be very uh practical about this and you have to make sure to not sign up for something you can't deliver on but you know if the results are worth it like it's it's a big bet that lots of other people aren't willing to take for wide variety of reasons and so you you have to be right but if you're right then it's it's actually a really good contribution to the world yeah yeah I think if you've got a good enough reason to create a language then I don't think it's insane at all and if you have no reason to create a language but just fancy as a hobby project then it's that's also cool oh I love that too but there's something in that middle space which which is definitely kind of crazy y yeah y okay um I I have to ask um because I don't know much about this well but um if you're writing one of these operators within um machine learning graph that you've described what's that like in pythonesque Mojo programmer space it because it feels like it's going to be something like um uh pip pipelines like I'm going to yield a value and a weight to Value um well so it depends on what part what what kinds of code you're building but I mean the the analogy is it's kind of like writing C++ a rust code um but with python syntax and so you get rid of all the templates you get rid of all the all the the line noise um uh but you're rri four Loops right and and so Mojo because it provides higher level higher functions and I mean combinators that you build the library you're often composing together hey parallelize this region vectorize this region and so you're the the code style looks a little bit different than maybe literally just writing for Loops but um but Mojo is disarming to people because people are taught for example never write a for Loop in python python is slow never write a for Loop in Python right and so um in Mojo alth theough that wisdom is invalid because it's not it is not has none of the DNA of python or it's not the same implementation and so and so a lot of these things that people uh knew to be false are actually totally fine it's also super funny I we we have folks that are writing high performance tensor core stuff and vni lowlevel stuff and they're and they're they're really experts in uh low-level system architecture and they're like it's so weird to be writing assembly code in Python yeah weird and so like it it does uh twist your brain or open your eyes or shift your perspective however you want look at that but but otherwise it's familiar and and again and again it's not a lot of what we're going for isn't driven by novelty for novelty sake it's it's about pragmatism um one thing I'd love to talk about is the compile time metaprogramming piece of this as well and so oh yes okay well why don't we go there now I've got a couple of other questions for you but yeah well so I mean this is another big bet that we've made and so um in these domains um both in the AI world where you're building models models and source code are eff L A meta program they're they're a bunch of imperative logic and then they describe roughly a graph and that graph is the thing that then you distribute and you transform and do whatever and so uh python has long been used for metaprogramming for a wide variety of different domains but that's one of the reasons it's been very successful in the AI Community if you look at the new again this the other the other world the high performance numerics people often use C++ and they use templates and you're you're metaprogramming these things you want an algorithm that works on both floating point and on double or you know float 32 and Float 64 right yeah yeah um and of course then it turns in this massive cataclysm of templates and like depending on how Advan you get right Al so more modern languages for example I know you know uh Zig for example has said okay well let's not have a different meta language than a language yes right let's actually use the same language for The Meta programming as for the programming and so again in case we're we're learning from uh the the good work of many other domains and so we said okay that's actually a really fantastic idea python is highly Dynamic you can overload operators you can do all these things dynamically we can't pay the expense we can't have even a single clock cycle extra in our domain right we have to have bare metal uh bare metal performance but we want the benefit of the abstractions and the the the extensibility that python provides and so what we do is we say okay let's take the benefit of the Python let's do everything dynamic let's take comp time metaprogramming let's fuse these things and this is one of the major ingredients that allows Mojo to be extremely expressive because you can build just just like in Zig but I mean we have a slightly different take but the same idea as Zig you can build standard runtime algorithms you can allocate Heap data structures you can do all this stuff and then use it at compile time and so you get this composition that enables really expressive libraries and nobody likes C templates right and stuff like this for and so you get the benefit of uh building these things which gives you the ability to build these combinators and these higher level um functions and features and compose the benefit of uh this compiler World Plus the uh the runtime World okay so to be clear are we saying that you're introducing a thing where I can write um it looks like I'm writing python at compile time to generate python to then compile and run yes or another way to say it is you have um values and objects and and functions and features and classes and types and things like this and you can use them either at compile time or runtime okay but I can I can start constructing my own abstract syntax trees at compile time um we we haven't gotone that far but in principle we could support that but it's more of like and a simple example as you say okay well I have a um I have a function that that creates a lookup table okay okay and so it's normal function you can call it at time you can pass Dynamic values and as the arguments cool give me give me a St Vector we call it a list but like give me give me a dynamic collection of values that are uh populated through whatever crazy math you want to do and now you say okay cool that lookup table is static and the inputs to the table are always static just go call that at runtime and just give me the table and so what it does is it says okay just a compile time go run that function calculate the dynamic data structure do all the logic that you're doing the output of that is an object it's you know a list burn that list into the executable and now you have an object and you just have the object directly instead of having to compute it now and that's a simple example um there's many fancier examples because uh when you when you do this suddenly uh as a uh type system nerd maybe you appreciate that you know like types are just values right and so you can and so your types are just compile time values and so you can do much more fancy higher level programming um uh at compile time with using types as values and things like this and so there's there's a whole Rabbit Hole there but it's the cool thing about it is that it comes back to enable enabling Library developers to make demand specific abstractions and build things that allow modeling their world very clearly okay um I remember talking um with Lis crow about Zig how we was saying that that would be a way in to make like specific take a generic list say compile time make the optimized version same idea yeah and of course Zig has its own personality as well and so it's a very lowlevel language IT issues uh syntax sugar and things like this and so it's very you know has it has a it's very different in certain ways than Mojo U Mojo wants to enable libraries and abstractions and so that's that's its focus but this this use of comp time and that idea is is very very common we're very happy to learn and admit that we learn from other people we didn't invent everything no well that we all stand on the shoulders of giants right that's right exactly and I'm sure they were inspired by lisp which goes all the way back to the start yep y everybody's doomed to reimplement their own list right yeah yeah and that's not crazy that's a good learning exercise maybe shipping it is uh it's not always a great idea but okay so we we've actually not tackled this but we've skirted around it the whole discussion the moment you're going from python into real lowlevel I'm dealing with CPU stuff surely the idea of um the idea of memory management is going to leak in here tell me what you've done there yeah so um if you're dealing with python object so one of the ways that we can embrace the entire python ecosystem is we just keep the cpython object model and so everything is just compatible and so if you import python you get the traditional reference counted indirect object box thing and and that's that's that that's cool have fun with that um if you if you enter in the world of I want to write real Mojo code or native Mojo code then you get a very powerful type system so you can have um you know at the bottom you have types that can have move Constructors copy Constructors and destructors and so you can write code that manually manages resources and do so directly um and that's kind of one of the bottom foundational things you can call into C and so if you want to you can call malakin free and do stuff like that through unsafe hooks um but again we want people to be able to compose together um libraries and we want to do so in a safe way and so what we have is we have references references work very similarly to the ones in Rust okay many implantation differences but you can think of it that way um in Mojo it's way less in your face and you don't have to micro manage the borrow Checker quite as much but it provides you the same approach and the ability to manage references um this is a really powerful thing and it's a very important thing but um again I don't know if you want to nerd out on all the lowl things probably not the right thing for the audience but but we've learned a lot from rust and so rust is uh it's wonderful they paved a lot of roads and they've done a lot of really great work but there's certain challenges with the B Checker one one example of that is that the way the B Checker Works in rust is that you have the parser and the parser has a bunch of pretty complicated different rules and special cases of how it generates the IR and then you have the borrow Checker and the borrow Checker comes along and tells you hey did you do it right or not and and if you did it wrong then it tells you oh well you know maybe in the in the simple cases it's easy to understand but in the complicated cases you're dealing with like the order of evaluation of how the parser did things it didn't do what you meant and all this kind of stuff um in Mojo our equivalent is actually a very different thing so we have the same thing where you have a parser and there's a set of rules our rules are very simple and predictable like I was talking about we push a lot of complexity out of the language and push into the library okay but then our borrow Checker isn't just an enforcer our Bor Checker decides what the lifetime of value is and so a very big difference between rust and Mojo is that in Rust values are destroyed at the end of a scope yeah and so you can run to issues where um like you get exclusive exclusivity violations because something lives too long um and there's various solutions to improve this like non-lexical lifetimes there's a whole bunch of stuff going on in the community to try to improve this in Mojo the way it works is that a value is destroyed immediately after its last use okay and so it's almost like you have an infinitely uh OCD garbage collector running and so and so what this means is this means a couple of different things this means one it's a much more friendly experience because your your lifetime ends and therefore exclusivity violations get uh get relaxed much earlier just by default it's better for memory use so for example if you're talking to a GPU could be that you have a tensor and a tensor is holding on to four gigabytes of data and so that's actually a pretty important thing it's better for little things like tail calls and other like core PL things because um if you have an object on your stack and it gets destroyed after your tail call which is typically how destructors work um then you don't actually have a tail call and and so there's all these these again there's this very there's this pile of very lowlevel obscure details um uh rust also has this thing called the drop check flag and so they actually in the worst case dynamically track whether or not a slot on the stack is live or not because equals in both rust and Swift um can either be a reassignment over a value in which case you're doing a mutation or it can be the first initialization of a value yeah this matters because you can in Rust for example you can uh transfer out you can move out a value from the slot and stuff like this um and so we solve that problem and so we complet Define a way categorically and this leads to a lot of simplification of language the programming model you retain the safety benefits and other things and the expressivity of references okay but are you saying this is calculated at compile time because at the moment it sounds a bit like reference counting yes yeah it's calculate compile time uses lifetimes yep okay yep the only thing I know about lifetimes in Rust is there a pain to use or at least I've never got my head around them I think some people love them uh some people struggle with them um uh again there like many of these things were you know I used to work with Gren and I know that many people in the Russ Community Russ has been built on top of lvm forever and so I know the community is for a long long time and have a lot of respect for it but but also like Russ is 14 years oldish right and it's roughly the same age as Swift and so like we've learned a lot from that journey and it's not dead or anything like obviously Russ is a wonderful language with an amazing Community but but what Mojo represents is a opportunity to take the learning and do something that's the next step right and there's a bunch of ways to simp in that sense and it's inevitable you learn things from that yeah and so and so and so what we're doing is we're saying okay cool let's take that for as with Swift like learned and made many mistakes in Swift right so and and many other systems as well and so um and so yeah so we're pulling that forward there there's there's a whole bunch of uh cool stuff in there so Mojo supports Asen of weight natively because that's obviously important for high performance threaded applications um we don't need pinning and so that's that's a really big deal it turns out um and it's because all values have identity and so by again there's these very simple very fundamental very low-level nerdy tweaks to the way the type system works that means that you know in practice uh if you're rust if you have a rust program it will be doing tons of mem copies and there's optimizations to get rid of the mem copies and sometimes they work sometimes they don't but in Mojo you just by the way the whole system composes out you never get mem copies or never get implicit mem copies because of moves and so there's just like a bunch of these very low level how the language and compiler are implemented kinds of things that work well together okay that's making me wonder moment you said identity it's making me wonder if you've taken a view on things like immutable data um well so we are still rapid like like actively debating some of these things um my my experience uh from Swift so if I recall you said you don't know much about the Swift ecosystem no no I I I left before it happened really so so I mean if in your infinite spare time you should check it out it has some cool things um one of the things that um we pushed and Swift has again it's it's it's not like a brand new language but it's a pretty modern language it's built last I started in 2010 I think um the uh uh it pushes forward functional programming and it made the observation that I'll I'll say some things I'm sure some of your viewers will want to kill me but but you know functional programmers who I love by the way um will say functional programming is amazing because you never mutate data you always get new values and because you get new values you get composition you get uh predictability you get control you get all these different benefits of not having mutation now C++ programs would flip that around and say yeah but creating a new value every time you want to insert something into a list creating a new list is really bad for the machine it's very bad for performance nobody could ever build a real system on top of that like depending on how aggressive they want to get right I feel like I'm about to join a b fight to carry on yeah whether it's friendly friendly thing over beers or whatever at least we're not talking about emac versus Vim or something like truly yeah yeah um well what Swift does it says actually the thing that you want is exclusive ownership of a value and if you have exclusive ownership of a value you can get value semantics and value semantics in Swift admit local mutation and so you can have and and rust has its own take on the same idea but the the idea is if you have exclusive access to a value you can mutate it and so now you can have in Swift the array the dictionary the the the string types are all immutable in the Java sense where it's like if I have a string I know that its value will never change underneath me and so it looks very very much like a functional programming idiom and if I have a string it can't change unless I change it and if I change it it's cool it's not going to break anybody else and through the implementation it never does deep copies or or stuff like that uh implicitly and so there's a bunch of stuff that was developed and works really well in the Swift ecosystem that I think will come over naturally into the Mojo ecos system and we're still working through that okay yeah okay that makes sense to me um without getting into a bar fight that's the goal is again the the goal is bring forward the the the wonderful things of functional programming composition uh locality of reference um you know you don't have the spooky action at a distance thing that reference things have like so this is all what I love about the functional program model but then also bring in place mutation so you get efficiency and so bringing those together is good Swift has some problems it like implicitly copies things a million times and stuff like this and so we we fixed some of those problems but you've learned from that but that seems to me like it would um like um ensuring you have exclusive access to a value seems like it must leak into programmer space in a way that will be unfamiliar to python programmers uh but but recall this is all oped in right and so if you want to use fully Dynamic stuff you can totally do that and that's totally fine and so okay and so this is you know one system that can scale because we're not we're not like trying to change the existing world what we're trying to do is fill in the missing world and so if you look at a modern um one way to look at modern python is that python is only half the language you have Python and then you have C right right if you're building a large scale application python you end up having or C++ or rust or something else that goes with python right and so what we're doing is we're keeping the python at least keeping the syntax but then replacing the C having one system that can do both and so instead of having to switch from I have Python and it uses underbar underbar ad to I have C and C++ and ffi and bindings and all that nonsense you say okay well I have underbar ad and it works the same way and everything just comes across right right I'm with you I'm with you in that case there's one other I think there's one other big Topic in Mojo we haven't touched on at all which is in contrast to Python and I'm reminded of it because of spooky action at a distance threads parallelization that's where yeah so super first class in Mojo like every every modern machine is multicore so keep going what what's the question so so um uh python fa famously has a global interpreter lock um meanwhile the moment you allow threads you get bitten by spooky action at a distance as something changes under your feet I'm glad to hear Mojo has uh ways to deal with that but what what is the how do I get into parallelization in Mojo how do I write a parallel program yeah so I mean again it pushes things in libraries and so you can have um we have parallel for for loops and stuff like that and they're just Library functions and so you can pass a nested function into parallel for Loop and so that's the easiest way um we actually have a very high performance low level threading library and because you know today's systems are not just like four or eight cores they're servers with 256 cores and yeah and so so and and it's only going to get more crazy if you go forward a year or two or five or 10 right it's it's just going to be nuts and so yeah this this is the world that Mojo's designed for now one of the things we haven't built out um we'll see I'm not committing to this don't hold hold me to this but uh we haven't built out an actor system for Mojo yet okay uh in the case of Swift We we fully did and Swift has a full actor system which is type safe it is very good for large scale um Loosely coupled distributed agents even Sports distributed actors if you're familiar with actor systems and so you can have did that yep and so um and so that worked out really well it it builds right on top of asena we in a very nice way um and so we may do that I have no idea um right now we're very focused on the um you structured compute more supercomputer style um and the numerics side of things so um I suspect we will find ourselves wanting to do an actra system someday but we haven't prioritized that yet would you possibly expect someone to do it just as a library uh yeah I mean so that that's also a thing uh The Scholar World built out AA I think and has done really great things um the only downside about that and so I mean maybe it would be great and I would prefer it to be in the library if we can um uh is just make sure that it's memory safe because AA for example is not threat not memory safe and um that leads to certain challenges but on the other hand like it can be very pragmatic say well do one step at a time and he'll climb and then get uh implantation experience with libraries and then if there's a benefit to putting something in the compiler to to mediate accesses across actors then we can add a little bit of typ type system support for that and then get the bulk of it in the library with a little bit of a type system right yeah the separation the way it should be okay so my options then for parallelizing em Mojo broadly you said I've got async a weight I can create a thread to run on and you've got certain parallelized Primitives yep yep okay yep and if you want to you can call arbitrary C code and you can go completely nuts and do whatever you want to do right and so but we're encouraging people to not have to do that like it's very nice to just say do this thing in parallel again it's it's it's still imperative code but it feels more declarative and I think that's again we're raising abstraction levels so that people get out of the muck a little bit okay that gives me plenty of parallelization things to play with the question is it comes up again as soon as you're doing anything fancy with CPUs that different CPUs support different things and sticking a Threading model on a single core is going to be different to 256 cores so what how much does CPU architecture matter to em moojo programmer how much does it leak in how much control do I have yeah so I think there's a couple of different things there's how much do you have to care about and then there's how much do you get to care about if you want to right and so um generally you know my my view is that there's a huge range of different kinds of programmers they have different care abouts and so most programmers just want to say here's a parallel for Loop go nuts then you're fine and so there from the systems level you want to be able to support structured nested parallelism you need you need thread libraries to compose you need like async of weight so you're not um getting bogged down with tens of thousands or hundreds of thousands of threads that then kill your machine stuff like this um but I think that's pretty simple the cool thing is when you start getting into more complicated accelerators and things like this and so if you think about CPUs that have 256 cores um gpus have thousands of cores or thousands of threads yeah right and so and the programming model around a GPU is extremely different than uh the traditional CPU programming model and so um one of our goals is to make it so people can write much more portable uh algorithms and applications and coming back to this twole idea the graph level is pretty easy I mean it's actually really hard but it's easy to understand how you make a graph portable um yeah you implement the graph for one thing you implement the graph for another thing and so you can have two different Stacks that um that are optimized or designed for the different kinds of Hardware um and the the power of being declarative is that you're separating out a lot of the implementation concerns which makes that possible but then if you get down into writing for loops right for Loops are different right for Loops are imperative code imperative code is inherent it is kind of the bottom of the stack and so what we've what we've done is we've carved out the ability for people to Define their own abstractions in Mojo and then just like we were talking about with complex numbers before you can have complex number it's a it's a very simple abstraction but it's an abstraction and you can go put a hack in it that is Target specific um when you start talking about accelerators really what ends up mattering ing a lot is um both parallelism but then also memory and so how you use the memory hierarchy is the most important thing um these days particularly for gpus and llms and this world that we inhabit and so um modern gpus and CPUs have many level memory hierarchies and so you you know the way to think about a CPU is you've got a big Vector register file and that's kind of like your l0o cache it's like your your registers right and then you have an L1 cach which is really fast and close to the CPU and an L2 cache L2 cache is sometimes shared with one or two cores you have an L3 cache and shared with all of the cores and then you have main memory and you go out and a GPU has roughly the same idea the details are very different but it's roughly the same idea and so if you're writing something like a matrix multiplication inherent to getting high performance with the matrix multiplication is not just doing a DOT product either way you have to process the workload in tiles and so what we've seen is we've seen an emergence of various tile-based programming models where instead of encouraging developers to think about things literally a for Loop doing a load and a store and an ad and a multiply uh instead you're thinking about processing a TI outad of time what you do is you write the algorithm for a tile and then you use higher level orchestration logic that then says okay on this device I'll Traverse this way or I will prefetch the data in two steps ahead or I will do um you know I will uh get better reuse so I go vertically and said horizontally or whatever whatever it is there's all these tricks that uh the the world has developed right when we say tile am I imagining um because we're talking about gpus am I imagining like something that's eventually going to be printed as a square on the map in my game um think uh yeah so if you're thinking about textures so yeah so texture is a two-dimensional rectangle of data um but um so it's a two so so so if you think about a texture map so a two- dimensional rectangle um in AI you get a generalization of that called a tensor and so you take a two-dimensional grid of numbers and you make it an n-dimensional grid of numbers right it's the same idea okay but now just just but now just put this in your brain um uh I I I know you don't think about this every day and so to me it's it's fun to just kind of uh dive into this stuff you talk about a two-dimensional array of data even in the simple case what really happens is it gets linearized in memory yes that doesn't surprise so when and so when you go down a row so if you go over if you go over one you just add one to the pointer and the next next place in memory but if you go down a row you're adding a whole row rows worth of data over right so you're jumping yeah and so and so for a computer uh it's very easy to access things that are very local and if you start striding right it's it's very uh it's a lot less efficient okay that get multi-dimensional vectors that becomes more pronounced exactly and so now when you do things like matrix multiplication this the shape of a matrix multiplication consider a two- dimensional Matrix and a two- dimensional Matrix is typically you're going horizontally through the row of one Matrix and you're going vertically through the row of another Matrix to compute an output element H and if you could tell the GPU to arrange those two matrices differently yep if for example you trans transpose it ahead of time things can be a lot more efficient um if you process instead of processing one row and one column at a time you can process two rows and one column and then what that means is when you're processing column you're accessing two elements next to each other for example and so as you generalize this out um you get uh this idea of a tile and so you get this logical concept of I'm processing for example a two-dimensional block of memory right and and I'm doing this and I'm composing against other things um turns out modern modern Hardware not only is uh it complicated in vector and parallel and like all these other complexities we've been talking about but they're now adding full-on Matrix operations to the Silicon right and so you can literally do a matrix multiplication of a very small Matrix typically you know like a 4x4 or a 16 by 16 uh some accelerators you can do 128 by 128 boom uh big operations the intuition here is that AI is important to the world and silicon is fundamentally two-dimensional and so if you use the two-dimensional nature of silicon to put down a matrix multiplication you can get a lot of performance and energy and other benefits from that and so a lot of the challenge in this world is how do I use these accelerators how do I map these things and these tiles onto these onto these devices how do I use the memory hierarchy efficiently and like and this becomes as important as the numerics and because the performance difference can be 10x or 100x depending on what's going on it's it's a quite a big deal and so uh if you go through the last 10 15 20 years like HPC has been dealing with a lot of these problems for many years and you know we have the Fortran world we have uh various C++ template libraries we have a whole bunch of stuff that was developed and built to try to combat some of these problems and they came up with fairly I mean sometimes very powerful but fairly Niche Solutions and the usability was never very great and this is where if you pull together Mojo's ability to talk to all these crazy Hardware features like the matrix multiplication operations uh build higher order combinators so you can build libraries so that you can write the tile algorithm and not the orchestration logic because you don't want to know how that stuff works you only want to know how part of it works yeah and then the and then the compile time meta programming that enables you to write really reusable and portable code and so one of the things um I recently gave a talk at uh the Nvidia GTC conference which is their big technical conference yeah and talked about how this all composes together to make it so you can write high performance numerics for the same algorithm works on gpus and CPUs right yeah and that's pretty cool right it's not just about a today thing of sof for a GPU and a CPU it's about if you're making a major investment in building software and that's how software works like you want your software investment to last for 10 years or 20 years years you want the amount a certain amount of being able to adapt to the needs of new hardware yeah and Hardware will continue to evolve it's moving faster than ever and so what we're doing with Mojo is helping break through some of these boundaries that have prevented people from building portable software and and while still being able to utilize the high performance super fancy features that people are coming out with okay so how is this going to work in practice let's say um I've written some code which is fairly fast with wearing my python hat I've written some in Mojo Nvidia comes along with a new GPU with this great new CPU instruction I wait I'm assuming what happens is I wait for mli to support that CPU instruction and then I just bat along to my mojo library and write that yeah so so Nvidia is a great citizen in the software world because every time they come out with some new chip and one becomes available they provide lvm access to their stuff generally and so so we can talk directly into that stack and and generally Hardware makers are very lvm friendly these days which is which is really cool um it helps enable Innovation so Mojo can talk to mlr and talk to lvm and get direct access to all this stuff okay which is cool this sounds like and also and also this this let let me Zoom back out and say you know this is deep Nery this is something that that a very small number of very important people care about um most people will build on top of higher level libraries and so we have like the max engine for example which gives you just give me a graph I will I don't want to know how any of that stuff works here's just a graph go to town right or other people say hey I I I just got some python code python code slow I'll put in some types now it goes 100x or th000 X faster right and I'm not even doing fancy accelerator stuff I'm just sming on CPU but 100x or 100000x is pretty material for um you know I have a big investment in Python code and I want to make it faster and I don't want to like retrain all my engineers and so that's why that's why that's cool even if you don't go all the way down to the C full craziness of the what the system can do yeah see where I'm sitting I don't want to write like GPU level code I just want my code to be fast but when I find out that it's not fast I want to be able to do that without someone telling me Oh you picked the wrong language that's exactly right and and and I mean this comes back to you're asking why pick python as a pythonic language right um one of my one of the things I've learned is that um uh how just is uh programmers let me stereotype all of us let me make a sweeping generalization that's obviously doomed to fail um programmers are busy people they have things going on they're not most people um are not going to be just like learning a new thing for the heck of it right now obviously there's exceptions there's researchers there's other people that just love learning and are passionate about things but most people are busy right and so learning new things is is not something people generally have the time to dedicate a week or a month to do on the other hand if you meet people where they are you provide something familiar so they don't have to retrain from scratch to get up to a Baseline and you give them new tools programmers I've seen generally love growing yeah yeah right and so learning a new thing here's a new trick I saw that with swift when uh when Swift launch we we said to the objective sewor hey you're all familiar with classes classes are great they still work in Swift here's new thing called a struct it's it's got these different tradeoffs it's it's way more efficient it doesn't use Dynamic dispatch or whatever right um and people and or here's algebraic data types enums right wow you have a payload around your enumerator pattern matching and like this was a huge huge aha moment for folks and and people loved being able to learn incrementally from the base that they were on um and so what Mojo is really about is it's about meeting people where they are and then allowing them to grow in situ instead of saying you you have to go off to the mountain retrain in boot camp for a month and then you can be basically effective in a in a new world and so I think that's why people are excited about what's going on with Mojo yeah I can see that I I always think the main reason I don't want to learn new things is I'm busy learning other new things and you can't get to the top of my stack so easily yeah well I mean it's a busy world out there and there's a lot going on yeah yeah but okay so I actually do have some python code at the moment if I if I thought okay well let's give this a try and rewrite it in Mojo what's my experience going to be like today how mature is it what's coming on the road map where you going with this cool yeah so so Mojo is still a relatively young language it's useful um uh it just launched last May so it's been public for less than a year um but it's uh doing really well I think we have over 175,000 people that have used Mojo um we have a a nice Discord community that has over 22,000 people hanging out and all the magicians like talking to each other doing cool stuff have cool new demos and you've got you've got the you got cute nickname too that's a very important St oh that that I I forgot the most important thing about Mojo by the way the most Innovative thing is that we support an emoji file extension in addition to Mojo oh God so that that that also causes people's heads to explode I'm not going to innovation of All Sorts but theity is doing really well it's very exciting um actually as we record today we're open sourcing a big chunk of Mojo and so the entire standard Library which as we were just talking about is the heart and soul the language is all open sourcing and so we've been on a quest to open source more and more and more of the stack over time and so that's a really big deal um I know we've been public about this and telling people about it for a while but I know people are waiting for this for a long time um and so what we're seeing is we're just seeing just a continued growth of the community and continued passion projects cool things going on and I think this will be a huge step and um one of the things that's very important to me is we talked about so I've built the lvm community from scratch from my research project at University I've built the Swift open source community and and worked in many many many other communities and what I've seen is that open source isn't just about having code on GitHub open source is about having an open Community having an inclusive way of developing code together working together with a common goal and so we we put a lot of energy into um not just providing source code but also getting a contribution model picking the Apache 2 license and things like this so that people have patent coverage and like all all the things that follow best practices and so I'm really excited about that I think that people are going to have a lot of fun and I look forward to being much more open with our development of Mojo okay that's cool so if I do decide to do this I'm going to be able to find lots of people to ask answer my dumb questions on Discord yeah yeah yeah so please join our Discord that's that's a great place to go and there's whole bunch everything from folks that are just interested in type Theory nerdery to uh uh to AI stuff to I want a better python to like there's many different angles and and again the cool thing about Mojo is that it is being built and it has to be state-of-the-art to solve these pretty hardcore pretty gnarly problems at the frontier of uh computer architecture and programming languages but we're building in a way that it's completely General and so we're focused on AI and there's a lot of pain and suffering in the world of AI that we help we're helping to alleviate um but but it turns out that you know a lot of people write web servers and a lot of people do other things and so and it's it's fantastic to see uh people building into that space even though we we personally can't uh don't have the expertise to invest in that yeah well that's what language is supposed to do right enable other programmers yeah yeah that's exactly right so concretely then if I go and install Mojo and take my existing we server writing knowledge am I going to be able to do like the equivalent of pip install the existing web server library that I like from python world yeah you can totally you can totally import and use it and it will just work literally you don't have to write rappers or anything and just import it and go um that'll just work the one problem is that if you take the python source code and you move it to Mojo file you'll have to make changes right now and the number one missing feature that we have right now is classes which is a pretty big deal in Python and so we have very strong strs and we have very strong static features we have references and like all all these kinds of things and so again what what Mojo has built out is all the uh like C++ and rust equivalent features even then there's some Min minor things are missing but that that's that's its strength and so if you come at it from a systems programming world today then I think you'll be very comfortable if you uh come back in 6 months then we'll have classes and we'll have other things built in and then um you'll be more comfortable as a python programmer okay I'm I'm going to go and check it out and see how comfortable it makes me today very good G so but it's very fun and so I mean I I love this I mean obviously I love this stuff this is a passion of mine for years but um but but the um I love the community side of it right the thing I love about Swift for example is I still get people that stop me in the street and say you know wow I recognize you thank you for helping drive this thing and make this happen like because of I learned how to get into programming and Objective C was always too scary and things like this and so with Mojo what I what I hope happens and you know these things take a couple of years to play out but what I hope happens is we get all these people that know Python and they don't consider themselves to be real coders or something right but they know Python and and they can continue to grow right because they're not faced with are you a python programmer or a C++ programmer what whatever they think is or rust PR like you know this this scary other threshold and if we can get more people involved be more inclusive to good ideas right what I think is we'll find computer science and these Technologies can go even further and have bigger impact than they've had so far and I I I love that right and I am a True Believer in developers by the way huge fan of your show and so um I did not pay Chris to say that that's what I love Yeah well I really hope it succeeds because anything that um brings new ideas programmers and helps unify our somewhat fragmented view of programming I'm all for it cool y Chris latner thank you very much for joining me yeah well thank you for having me Chris it's great to be here cheers see you again thank you Chris and I have to pick up on that last point it makes me sad to think that there might be python programmers out there who don't think they're real programmers of course you are you absolutely are if you in the business of teaching computers to do things they couldn't do before you're a real programmer don't let anyone tell you different and if you're in the business of learning how to do that better and exploring new ways of doing it then you're a friend of mine too as usual you'll find links to all we've discussed in the show notes check it out if you want to take a look at Mojo if you want to kick the tires on it I've been having a play and having some fun early days but very very promising before you go and do that do take a moment to click like or share or rate or Subs subscribe because I'd love the feedback of course I would and the algorithm would love to let other likeminded people know that you've enjoyed this and that means you and I and future listeners will get together more easily until that time when there's a future episode I think it's time for me to say goodbye I've been your host Chris Jenkins this has been developer voices with Chris lner thanks for listening for