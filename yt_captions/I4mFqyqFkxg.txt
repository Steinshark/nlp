Lang chain is a great library for creating applications that communicate with large language model apis you did mention in a survey that I recently posted that you want me to do more AI focused content of course I do my best to listen to you so here you go I'll show you today what you can do with Lang chain and it's pretty cool but I wouldn't be around if I didn't also talk about how it's been designed and we can learn an important lesson from that by the way if you're enjoying these types of videos you surely also like my Discord server it's a great really helpful Community with a ton of knowledgeable people you can join for free using this link and when you join say hi I always wave back getting started with Lang chain is actually really easy you just create a large language model object and then you can call methods on that for example send the prompt and then get a result as a starting point I have a mostly empty script here which just loads the open AI API key from a DOT and file and of course if you want to interact with a large language model like the one from openai you're going to need an API key it's really easy to get an API key you just have to create an account at open AI or any of the other competitors and then you're going to have a possibility there in the web-based interface to get an API key note though that as you're using this key more and more obviously it's going to cost some money because you're going to be charged for the tokens that you're going to request from the surface so the first step is create this llm large language model object and in order to do that for open AI we simply have to import it from Lang chain from the RMS we're going to import open Ai and then in the main function we can create the llm which is going to be open Ai and we're going to pass it the open AI key and just to make sure that we actually pass it to the right argument I'm going to supply the keyword as well and now we can simply send a prompt to this large language model and then let's also print the results like so so this is all it takes so when I run this then this is what we're going to get as a result so here we have five really great ideas for YouTube videos about python so now you know what I'm going to do for the next couple of weeks now this doesn't actually work with the latest GPT model from open AI this works with an older model if you want to use one of the newer models like GPT 3.5 or dpt4 then you're going to need to use a so-called chat model which has a slightly different interface in line chain in this case what we're going to need is from langchain Dot job models we're going to import chat open AI which is the open AI chat model interface and then we're not going to use this but now we're going to create a chat open AI model and obviously we're going to set the API key but what we can now also do is let me Define a model which is going to be let's say GPT 3.5 turbo and now next to the open AI API key we can also Supply the model name like so here's an example of what that generates so we still get five video suggestions but there's more detail what this is also a DPT 3.5 so it's going to give more details of some of the older models but if I want to change this now I can for example also Supply gpt4 and that's actually really easy and now let me run this one more time and gpt4 is obviously going to be a bit slower and now this is what we get so gpt4 didn't give us any extra information about what each video is about but still if I look at the topic suggestions well I think these are slightly nicer than the ones that GPT 3.5 has proposed another really powerful thing you can do with Lang chain is work with templates for example here I've created a prompt com3 info that's simply a phrase provide information about country and it's template where we can insert the name of the country as a first step I asked the user for a country name and then we need to do is create a list of messages that we're going to send to the chatbot so if you work with someplace you have to use the message system of Lang chain which is slightly more complicated than just calling predict but it also gives you a lot more flexibility so what we're going to do in order to use these templates is add a couple of imports so we're going to need two things which is d human message prompt templates there's different types of templates that blank chain supports including human messages and system messages and I'm also going to need the chat prompt template class and the first thing that we're going to do is now that we have the name of the country the next step is that we now create the human prompt message from a template and there we're going to supply the front move with the country information next we're going to generate the chat problems for which we'll use the chart prompt template and by the way GitHub gopal is generating some stuff here that's actually not correct so I'm just going to ignore that so this is going to need from messages and we're going to supply the messages like so the third step is to actually provide the data that we asked here from the user so by the way the reason that I'm using a chat prompt here is that we can now have multiple messages and then you can now format these messages all at once by doing a single call so let's say we have a chat front with values and that's a chance prompt and then we're going to call format prompt and there we're going to supply the country now we can generate the response which is llm and we're going to pass it the chat problem with values to to messages so that gives the list of messages to send to the LM and finally we can print the response so what did we do we created The Prompt object using human message prompt template we then created a chat prompt which is a sort of list of messages we then called format prompt so that we could format these different prompts and then we convert it again into messages that the LM can deal with and let's run this for example we want some information about the Netherlands because well that's where I live and obviously this takes a bit of time because we're waiting for the response from the LM and there we go this is the response that we actually get so as you can see there is an object called content that actually contains a response from the model now this is raw Tech so that's not really something we can actually do something with in our code directly but there's also a way with Lang chain to actually Supply output formatting instructions to the models for example you could instruct the large language model to return a response as Json data which is pretty helpful because then you can actually parse that and use it in your own code let me show you an example of how to do that by combining Lang chain with pedantic the first thing that I'm going to do is create a pedantic model and for that of course we need a Place model and we're also going to need a field so let's say we just want to get the capital of the country so here I've created a country model with my dantics based model that has Capital which is a string field and we have a name which is the name of the country I've also supplied a description to each of these fields because that gives a bit of context to the LM and then in order to actually create formatted responses according to this model what we need now is from blank chain dot output parser so there's many different output parses that are available but we're going to use the pedantic output parser and then it's actually really simple to set this up so next to the llm what we're also going to need is a parser which is going to be a pedantic output parser and we're going to supply it a pedantic object let me just add the keyword argument here so that it's clear and what we then need to do is a simple extension of this prompt and what we're going to do is we're going to add a format instructions because of course we have to tell the LM now in what format it is supposed to return the result and then let me scroll down so here we have our format prompt so we not just need to supply the country but we also need to supply the format instructions and what's nice about the parser the output parser is that it can actually get the format instructions for us from the pedantic model which is really awesome so then this is what we have so we're formatting The Prompt with this information so now that we have the response back we can use the parser to parse the contents of the response and then let's simply print the data for the time being and now when we run this let's use another country Belgium why not and you see we get now an object with a capital Brussels and a name Belgium and what's really cool is that this thing is now of type country so for example I can do data dot capital and then let's run this again let's use another country Germany and then it's going to give us simply the capital of Germany and since we now have access to this formatted response data we can do whatever we want with it in our code for example here I'm printing it as an F string or maybe you want to show it somewhere in user interface so let's run this one more time and then you see that this actually works perfectly let's use a fake country and see what the capital is of suckerberg on ooh that doesn't exist okay that's a Pity I thought it was a real country let's instruct the LM that it can also make up stuff there we go because I really want to know what the capital is of zuckerbergiel Markville ah okay then I could have expected that so what I've showed you now is how to send a request to an llm and get back the result as formatted structured data you can also do the other way around in that you can ask the llm to call an API for you and then return the result of that and that's actually also relatively easy as long as you supply the documentation of the API to the chat model because otherwise it doesn't know how to call it so bankchain has an example for open Meteo and what happens here is this almost the same setup as I had before so we create the album then we create an API chain and that's basically what you need to do if you want to supply API information to the chat model so it can recall it and then you can run your prompts by using that API chain and then print results when I run this example this is the results I get 18.3 degrees in Amsterdam and of course you can combine these things you can add another parser an output parser to this so you get back formatted data this by the way could be an interesting way of quickly developing a comfortability layer around an old API so you could just Supply the old documentation to chat GPT and then let it generate the API response using the new specification that you need while you refactor your old API code it is a bit slow and it's probably also a bit expensive especially if you have lots of users that use this so um I would probably not really do that but it could be a potential application of this so what's the kind of thing that you are thinking about doing with Lang chain in your projects do you think there are any missing features that you'd really like to have let me know in the comments this by the way is Lang change documentation page as you can see it's quite extensive in what it can do so you have several different modules and what's really nice about langchain is that it defines a common group of Concepts and interactions between these Concepts so for example if you look at the model input output model i o you see that it has prompts which in turn has from templates with lots of different options and we have language models which are of course the different llms and chat models that you can use with Lang chain and like I showed you before we have output parser so you can parse date times list Json by you can do other things here as well so there's lots and lots of possibilities and as you can also clearly see that basically for each concept there is a sort of a hierarchy of possible implementations so we have a common thing called an output parser but then you have specific implementations like the pedantic output parser or the daytime parser and same for the chart models of the LM so you have like a common structure called LM and then you have subclasses that implement the functionality so that you can connect with that particular large language model and in that sense when you think about the design of Lang chain it actually combines different ideas from different design patterns one design pattern that comes to mind is the strategy pattern which allows us to replace an algorithm with a specific implementation so when you look at output parses for example that's something that really is close to that kind of pattern but similarly you can also recognize aspects of the bridge design pattern which is a pattern that has multiple hierarchies normally you have to in the standard Bridge pattern but these hierarchies they both have an abstraction they're connected on the abstract level by the way I did a video about Bridge already a while ago a few more art sets I've put a link here at the top but the idea of the bridge is that you can then vary these different hierarchies without affecting the other hand turkeys and that's also something you can see here for example I could write an output parser that generates a tree like structure but I can do that without having to do any work on the large language model side and similarly I can add compatibility to another large language model without having to change anything in the output parser so that's clearly a feature of the bridge platform another thing you also recognize is ideas from patterns like template methods which provide specific implementations and then you call methods on it in a particular structure and that's also sort of what's Happening Here so the if we create like a standard objects like llms and output parsers prompt templates and then we run them through a particular sequence which is the template and that uses those objects called Methods on them and then Returns the results so there's quite a few of these interesting patterns that you see in link chain even though it doesn't directly like hard-coded implements the bridge pattern it doesn't cause something a bridge or something or as strategy it simply uses the ideas from those patterns to create a library that's well designed and by the way if you'd like to become better at detecting these kinds of patterns encode yourself then you should definitely check out my free workshop on co-diagnosis you can join via this link below it's really practical I'll show you a three Factor framework to help you review code look at code more efficiently while still finding the problems and detecting the patterns fast so again it's totally free you can sign up at iron.code slash diagnosis it contains don't a practical advice about half an hour I'm sure you're going to enjoy it a lot so what design lessons can we learn from language and well one really important lesson in my opinion is that LinkedIn shows how important it is to Define Concepts well if you define the concepts wrong then your library is not going to be designed well so we have very clear Concepts like prompts language models output parsers etc etc and it shows that if you define these things well they connect well it works well it's easy to use I still think it would be nice if Lang chain took a next step and also let us abstract a way a bit more from whether something is an LM or a chat model I don't think a lot of people really care about that and the way that we interact with it is mostly the same so I think that would be a nice next step but really shows that it pays off if you spend some time really thinking about the concepts and how they are with the latest another really important lesson is that even though we have all these design patterns it's not that important that you follow them strictly to the letter it's way more important to think about the principles that are behind the patterns and apply those principles judiciously principles like coupling cohesion making sure you split creating a resource from using a resource keeping things simple and so on by focusing on the principles instead of the patterns you're going to design great code you can use newer feature first formal language that wasn't supported maybe by the older design patterns overall it's going to lead you to a great design one example of set of principles is called grasply if you work with python a lot I think this is a great starting point to learn more about that watch this video next thanks for watching I'll see you next time