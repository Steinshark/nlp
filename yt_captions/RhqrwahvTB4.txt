all right great well welcome thank you very much for coming uh as we get started i have a confession to make i'm bad at maths and like way worse at maths than you might reasonably expect you know i did math all the way up until the end of high school um i did okay you know i passed enough to get into university at least and when i went there to study computer science i had to do maths again for my first couple semesters and it turned out the courses were almost identical to what i'd done in high school so you'd think that you know after another like year or so of studying this stuff that i have a better understanding i'd be able to do better actually like you know get decent grades but i feel like i actually did worse and that's not just to do with like harder marketing schemes in universities or anything this is like me sitting in a classroom and just staring at a whiteboard or a blackboard and having no idea what is going on just having my brain completely freeze up all of this mathematical notation and just having the worst time so uh i am bad at maths i am interested in math though i'm interested in the areas which you know inform programming which help us write better code which help us write code which is more understandable testable um which builds upon you know like math strong mathematical foundations so i do want to learn this stuff i want to learn things like category theory like set theory like abstract algebra and so you know i taught myself but i kept on having the same problem of like flashbacks to when i was just staring at a whiteboard and having no idea what was going on like reading wikipedia articles and just no getting nowhere and i thought that was just me uh recently i saw this tweet i used to think i wasn't smart enough to understand wikipedia articles on math and computing and have recently come to the realization that no the articles are just badly written you know maybe there are some people that these articles work for i'm certainly not one of them and now i know that there are many many others out there who you know have the same problems so this talk is the talk which i could have used when i was teaching myself some of these concepts i wanted to have this talk there for me so this is hopefully my my gift to all of you who have the same problem i'm not aiming for accuracy in this talk i will be throwing out just a bunch of arrows a bunch of examples trying to get you to build up an intuition for the concepts which i'm talking about so if you want accuracy maybe look for a different resource probably not wikipedia all right before i get started on the meat um i have left quite a lot of time at the end for questions because you know people often have a lot of questions about these concepts um i will be keeping one eye on the remote q a so if you have any small clarifying questions you want asked um just drop them in there and i'll do them throughout the talk but any larger questions i'll i'll get to the end all right let's talk about stood accumulate you might be familiar with accumulate it's one of the the algorithms in c plus plus which is not in the algorithm header it's in the numeric header because you know c is plus but this is what it looks like say we have a vector of integers then we can accumulate them we can sum them up we pass it a begin iterator and an end iterator and an initial element and it will sum up all of the elements in the vector and we'll get our result we don't just have to you know add them we could for example multiply them if we pass this multiplies class then this is going to multiply all the elements together instead of add them so it's customizable just like most of the algorithms in in the standard library this is often called a fold and you can kind of see why if you look at what's going on if we have this then this range from 1 to 10 and we take our plus operator then we're kind of like folding it over all of the elements until we get like a nice origami crane or something we don't just have to use integers like we could accumulate lots of different things we could accumulate strings like this will concatenate this is because i originally gave this talk at cppcon so you could say hello cppcon you could say hello meeting c plus whatever you want you could just concatenate strings um i know that this will all work i haven't had to you know say i want to concatenate strings it's all just worked out because you know strings have a plus operator we could also implement a lot of different algorithms in terms of accumulate so this is a function which takes in a first and last and a predicate and it's gonna accumulate them all using this um this lambda which just uses logical and um after applying a predicate this is called stood all of it's not quite stood all off because stood all up will short circuit but it's it's essentially the same thing you know it will give us the same answer unless you're doing something weird and we could actually get stood none of if we just change the name and we flip the predicate it's the same thing it's the same pattern we're just you know changing some of the implementation details and if we change a few more things then we can get any of the point is that you can actually implement a huge amount of the algorithms in c plus in terms of stood accumulate or at least get some approximation of them so most of the algorithms and sepalsplus are kind of like this screwdriver you know it's useful for a lot of things but it's still kind of specific like this is a flathead screwdriver so we'll work on flathead screws of a certain size it's general but it's also kind of specific to to certain areas whereas accumulate is even more general than that it's more like a sonic screwdriver if you're not familiar with doctor who this is just like you know screwdriver taken to his extreme it can do anything it's incredible says cumulate is more general algorithm which you can implement other algorithms in terms of and it's so general we actually invented our own syntax for doing this based on variatic templates that's called full expressions this is a sql 17 feature so for example if you have a variatic template this is using the the c plus 20 uh abbreviated function templates but it's it's the same as that you could do this in c plus 17 just by you know decorating it with template and things like that but the the idea is we take some number of t's and we're going to fold this plus operator over this pack and so when we instantiate this template with say one two and three then it's gonna generate code which looks like this we have a function which takes a b and c and it will do a plus b plus c plus 0 0 being the the initial element all right so this is it's the same thing it's an accumulate it's a fold it's just some syntactic sugar for it so let's look a bit more at this call to accumulate we have a pair of iterators we have an initial element and we have a binary operator now of course we could flip this operator but then we need to change the the initial element because you know we're going to multiply some range if we start with 0 then we're going to end up with 0 at the end which is not very useful so we need to change this to a 1. so your initial element is going to depend on what your binary operator is what you usually want here is what's called the identity element the identity element is a special element of a set which does not change the other input to a binary operator special element of a set does not change the other input to a binary operator it's a bunch of examples some of which we've seen already for int and plus then it's zero because you know if you add anything to zero then you get the thing back similarly for in and multiplication it's one multiply anything by one you get the thing back string and plus empty string you kind of get the picture some others set and union if you have a set and you union it with an empty set then you're going to get the the original thing back for um bools and logical and it's true for bill's logical or it's false yet picture the idea is that the um the identity element does not just depend on the data type it depends on the pair of the data type and the binary operator so let's look at the the binary operator a bit more now say we have this range you know we could sum up everything uh what if this range was even bigger you know if it was something which was large enough we didn't want to just uh do this operation on a single core we want to split it up over multiple cores or multiple machines or whatever uh we could distribute this you know we could split up our range into and like chunk it up give different parts of our range to different cores or different machines and then you know we could sum up everything which is on one machine and then we could sum up those results and then we could solve those results and we get our our final answer so this is you can see how this easily paralyzes but what if we wanted to fold minus over these be a bit contrived but this is mostly for for illustrative purposes if we fold this operation over in serial then eventually we get -53 and if we try and do the same thing you know we paralyze we split everything up then we get a different answer instead of minus 53 we get minus 23. that's not great uh you know we would like that if we do something in serial or if we do in parallel we should get the same answer right so this depends on the associativity of the operator where associativity means an operator where the grouping of the operands does not matter or in slightly more concrete terms if you have some operator we'll call star um not necessarily multiplication could be anything uh if you do a star b star c then that should be the same as doing a star b star c the parentheses shouldn't make a difference okay that's associativity so the parallelization depends on the operation being associative and we actually have an algorithm in c plus 17 called stud reduce which is exactly that it's a parallel version of suit accumulate which requires the operator to be associative it also requires commutativity but we're we're mostly in concern with associativity in this talk so what we have is we have a data type we have a binary operator which is associative and which returns the same type as its arguments and we have an identity element now it turns out that this structure is everywhere like pervades across the whole of mathematics the whole of computer science and it's called a monoid you might have heard this term and if you're anything like me you heard it a lot and i had no idea what it meant even when people explained it to you but hopefully with some examples you can see it's it's not that complicated data type associative operator identity element that's a monoid so if you have types you're composing often you might be able to expose ammonoid and doing so will allow you to clearly define what object composition means with your binary operator and then turn those binary functions into any functions functions which work on any number of of inputs because you can do that full operation and also allows you to unlock parallelism because you have associativity okay when you start looking for monoids everywhere you start to see them in places you might not have expected like say we want to say we have some large corpus of text and we want to count the words edit you know we want to see like how many times a and chicken and whatever are um are in our text then you know we could have a this type word current which is just a a map from strings to longs and we could have a function which counts the words which takes in a string and um and tells you gives you a map of all of the words to how many times they occurred we might want to parallelize this you know we might have a huge corpus of text and we might have a bunch of machines which we want to distribute this computation across and we can do that as long as you know if we're looking for monoids we're looking for composition if we can compose um these word counts then you know we can say to every machine count words in some some chunk of text and then compose them so we would need a function like map merger or whatever which just takes a couple of word counts and then composes them into a single word count if we have these functions then you could imagine our our client code might look something like this and we have our our text our corpus then we could chunk it up over some number of machines this distributed system is something i made up but you can imagine kind of what it is it tells you like how many machines you have and has some description of how to run them on different machines then we could use stood transform reduce which is essentially does a transform and then a reduce like a distributed accumulate and we give it our distributed system uh again this is something i'm kind of made up like in c 17 you can give it a execution um you can tell it to do in parallel or in uh or sequentially you can't tell it to run it on a distributed system but this is something people are working on like this is this is not far-fetched so we give it our distributed system to run it on we give it our range of our chunks of text we say our initial element is an empty map and our um our reducer is going to be our map merger and our transform is going to be count words so every machine is going to count the words and then those are going to be reduced using our map merger function so this is ammonoid our word counts form ammonoid with our map merger function you know again that pair of data type and binary operator the data type being the map the um the binary operator being our merger so that forms a monoid let's look at the the implementation of of map merger at least one implementation you know we could loop over all of the the keys and values in the right-hand side if the left-hand side has that key then we're gonna you know add the um the count we got from one machine to the count we got to the other and otherwise we're just going to place the account we got from the right machine to to the map you see this is like just reducing all the both the maps into one and then returning the left-hand side but we could actually generalize this like you know we got this plus operator uh turns out we could actually have this be something completely different you know we could have some we might not be counting words we might be merging different maps for some different cause so we might want to customize this you know we could make this a template and say you know we're going to default to plus but uh you could supply anything here and then we're gonna take a binary operator default to to just plus and instead of doing all the computation here we're gonna return a lambda we're going to return something which is going to going to be our merging function and then we just need to flip our plus equals into calling our our binary operator and change our our word counts to auto because you know this this could be something different so here you know we had our our map type and our map merger function formed ammonoid but our values and this f binary operator also our ammonoid like we we've got monoids inside monoids they're just everywhere um so again if you're looking for monoids you see them in your computations and you also see them in like deeper down and you can expose those and generalize your um your apis another example say we have some integers and we want to get the the max we can do this with accumulate saying we we give it the the range we have zero as the initial element and we're just going to return the max of of a and b uh this is an implementation of austin max element it's the the same kind of thing we just we implemented with accumulate because this shows that it forms ammonoid our data type is the ins and our operation is is max so this is a monoid but what about those the ordering functions itself like here we're using just the default like minus ordering and we're using um just getting the the max of the the integers but what if we have something like this session type this is like a conference session has a presenter a title start time duration we might want to order we might want to order these in different ways depending on how we're presenting our data you know we might want to you know have a session list which orders by start time we might want to just um like order by presenter names and titles we might want to do this in different ways we don't necessarily want to bake this into our session type by like having you know a a less than operator for session which says you know we're always going to be ordering like this we might want to do this ad hoc like say right right now i want to order by start time um and right now i want to order by presenter and then title what can an interface like this look like well say we have this order by function which takes uh a member pointer then we could do something like say give me the max element of the sessions and order by presenter i don't really care about the implementation of order by here it's it's implementable you can ask me how later if you want but what about composing these like if i want to order by presenter then title how would i do that well i can write a binary operator i could take uh i could use operator bar and this takes two orderings f1 and f2 first we're going to go call f1 and then we're going to call f2 if f1 said you know these things are equivalent i don't care so we're going to return a new ordering which is the composition so first we call f1 and if f1 says these things are equivalent uh this stood weak ordering equivalent is from the the spaceship operator then we're going to return res and sorry if f1 says they are not equivalent then we're going to return what f1 says and if f1 says they are equivalent i don't care then we're going to call f2 and return that all right this is a like a lexicographic composition of these two orderings so now we have this this api we can say okay give me the max element of sessions order by presenter and then order by the title i think this is this is kind of nice and it turns out this is a monoid you know we can uh we can have an identity which is an ordering which always says things are equivalent and we can further convince ourselves this is a monoid because you know we could write a um a fold expression which folds over a bunch of of orderings and uses the ordering identity as the identity like monoids are everywhere and if you look for them you start thinking about composition more if you want to learn more about monoids i'd highly recommend um watching ben dean's talks he has a bunch of talks on monoi's is just generally awesome uh in fact here's a slide which i cribbed from him monoids are all over statistics you know that um the word count thing is as an example but here are a bunch of others you know like averages histograms garcinia distributions all of these form monoids which means they're easily parallelizable so again think about your monoids all right let's talk about this or um if you're not familiar with circuit diagrams maybe you're more familiar with with this guy uh yes this is stood transform or uh maybe let's talk about stood ranges views transformed because you know we love our our nested name spaces and c plus plus 20. say we have some cats and we want to make the cats cute and we always want cute cats one way of implementing this is you know have a vector of cats uh have a vector of cute cats and then loop over all of the cats calling make cute on each of them and pushing them into the cute cats this code works but maybe a slightly nicer implementation is taking cats piping it into transform transform will call the function you give it in this instance make cute on every element of the range we we pipe in and now we have a range of cute cats and you can kind of read this you say like cats transform by make cute it's easy to comprehend it's not you know we we don't like raw loops or at least many people don't and this is this is easier to comprehend i think and easier to compose how about optionals you know maybe we have a cat maybe we don't so first we're going to check if we have a cat and if we do have a cat then we're going to make it cute but we could do a very similar thing you know we could pipe c into transform make cute this wouldn't work with stood ranges views transform but you could implement this there's different ways different implementations out there which do exactly this and it's it's the same pattern you know we have in one case an optional which are piping to transform in the other case we have a vector we're piping to transform but it's the same thing or maybe we have a future cat maybe we're gonna we're gonna get a cat sometime in the future you know maybe we have to like wait for the shelter to get back to us or something but we know that when we get the cat we're gonna make it cute we're gonna like give it a little bow on its head or something i don't know so we could you know say get the cat asynchronously and at some point we're gonna gonna wait uh you know we're getting patient and then we're gonna make the cat cute but like we have to care about when we get the cat we have to you know wait on it we have to um care about the context we have to care about the the fact which we're getting the cat the future but we don't really want to care about that we just want to say get the cat and then at some point make it cute so we could do the same thing you know we could take our future cat and we could pipe it into transform just say when we eventually get this cat then make it cute we're like just like um queueing up operations and it's again it's the same pattern these are different types future optional vector with you know different meanings different semantics but it's the same pattern so if um our accumulator is more like a sonic screwdriver then transform is more like a drill you know we don't care about what's built up we don't care about the optional part the future part of the vector we just care about drilling through the context and getting at the values which are inside this is what um the the signature for transform could look like you wouldn't actually implement it like this but this is just for demonstration purposes you know we have transform which takes um some temple of t so like stood optional of int or stood vector of cat or whatever and then we have a function from t to sum r and transform is going to return the same template of r so if we have a optional int and a function of instabules then we're going to end up with an optional bool we're not changing the optional part we're just changing the values inside we're journaling through the context some other languages might call transform map or or fmap so what we have is a container of ts and a function which transforms the t's inside the container without changing the container but again like it's not kind it's not necessarily a container like is a future a container of teas not really it's more like a a computational context it's you know tease alongside the context that we're going to get these later so we have t's in some computational context and a function which transforms the t's while maintaining the context see a question i'm going to answer that one at the end and it turns out again this t's in some componential context function which transforms them is super general you know we've seen it in optional we've seen it in vector we've seen it in future there are way more um other areas which this pattern pops up in and it's called a functor uh no this is not the c plus like a function object like a class with a call operator that's not what i'm talking about this is the definition of functor from haskell which is informed by the definition from category theory puncture is kind of an overloaded term like even old camel uses it for something completely different uh which is a pain but here we are functor t is some computational comp text and something which can drill through and transform the t's it's not as easy as just this pattern though oh sorry on that note of function objects and functors i'd recommend going checking out jackie k's blog post on this is quite fun but alongside this pattern of you know piping something into transform the functor has to behave in certain ways in order for it to like not be surprising so there are things called the functor laws um i tried to like port these function laws to c plus it doesn't quite map nicely but hopefully you'll see what i mean so say we have some identity function which just takes in an argument and returns the same thing then the first functor law is that if you have some functor and you transform it with the identity function then you get the same functor at the end the um the intuition here is that you know if you have a vector and you call id on every element of that vector then you get the same vector out at the end all right again like c plus you know if these interfaces are copying or we have overloaded things then it's not quite the same but hopefully get what i mean if you don't change anything then it shouldn't change anything it's what this means the second function law is if we have a functor and we pipe it to transform f and then transform g that should be the same as piping a function to transform with some composition of f and g the intuition here is you know if you have a vector and you loop over it twice wants to call f on everything wants to call g on everything that should be the same as a single loop which calls f and g okay shouldn't matter how many times you're looping over this vector it should be the same thing okay so again this is about like maintaining the context not changing the computational context just changing the values those are the functor laws so if you have types you're you're manipulating the structure of just to change the values you may be able to expose a functor and that allows you to abstract away the handling of the context the vector part of the optional part the future part whatever and write code at the level of your intent um an example actually you know if you look at the the standard template library this is from uh a presentation in 1994 to the standards committee from stephanov and meng lee who were you know designing the the original standard template library iterators were one of the main things which made the stl what it is you know the abstraction of pointers and iterators actually kind of get you a long way to the definition of functors in fact most ranges in c plus are functors itself so you know not all ranges but most ranges have this kind of pattern where you can you know transform them so ask yourself is this type a range you know if i have some type which is you know exposing uh like operator square braces should i instead be um sending out iterators so that i can treat this thing as a range i can transform it does it expose anything which is a range do i have like a function called nth child um where instead i should be exposing like a get children range or something because then i can transform that or i can i can not care about the fact that this is a range i just care about the values if you think about these things then this is like a really practical thing in c plus you can do to expose functors in your interfaces all right uh quick questions um question is wasn't the first element of each subgroup positive that had to be negative in the parallel minus example uh maybe that's not the important part here the important part about the parallel minus example is just that things have to be associative uh don't care too much about parallelizing uh subtraction over a bunch of elements it's not very interesting okay let's talk about stood ranges views join more namespaces so if i have a cat pic i wanna might want to do a bunch of transformations to make the cat look cuter maybe i want to make the cast smaller maybe i want to make its eyes sparkle uh you know maybe one of these operations could fail like if the the cat has its back turned to the camera or something or has its eye shot then you can't really make its eye sparkle so the second function is going to return an optional cat pick we might not be able to make his eye sparkle so if we have if we maybe have some cat then i imagine we could do something like transform to make its eye sparkle and then transform to make it smaller but the problem here is that you know might make eye sparkle might fail uh it's returning an optional so we actually would have an optional optional cat pick uh so this wouldn't compile it would just blow up um what would need to do is essentially strip away one level of that optionalness which we could do with a join you know join takes a range of ranges and collapses it down into a single range so if you had a vector of vectors then it would just make it into one linear vector if you have an optional of optionals then you would just have an optional all right um but then you know if we have other functions like add top hat and maybe that could fail as well maybe the cat has its hand on its head or something then we're gonna see this pattern a lot we're gonna transform join transform join transform it's kind of noisy um and this pattern turns up a lot so maybe we could invent a function which does a transform and then a join um we could call it something like and then other languages might call this bind um so we just say baby cat and then make its eye sparkle and then add a top hat and then transform it to make it smaller this is what the code would look like if you didn't do this here we have we check if we have a cat and then we make a size sparkle and we check if that failed and then we add a top hat and we check if that failed and then again we're handling context when we want to be handling values we want to care about the data flowing through these function calls rather than caring about like unwrapping stuff and then rewrapping it and unwrapping it and re-wrapping it we want to care about values not context another example which follows the same pattern is futures again say we want to pat the cat's head and we want to scratch its belly at least you know i have three cats um they like head pads to last a long time and belly scratches to last a long time so maybe you want to um like cue up a bunch of operations you know you want to pat's head and then you want to scratch his belly um we won't don't want to care about when these operations finish so say we have a good boy and when it packs head and then scratches belly again we're caring about the the values we're carrying about the data types flowing through these function calls not caring about you know when the head padding finishes and when the belly scratching starts we're just queuing up operations another example is parsers you might have seen this definition of parsers a parser for things as a function from strings to lists of pairs of things and strings uh this might not immediately seem like a definition of a parser especially in the c plus plus world you know we're used to more um imperatively styled implementations of parsers but this is how you could implement parsers in in pure functional languages uh a kind of translation to c plus say we want to generate a parser which matches a character and we're going to return uh a lambda which is going to take some input and then we're going to have a result the result is our list of pairs of things and strings you probably wouldn't actually use a stud list here and things like that it's just so that it matches up nicely with the definition and the result is going to be all of the ways in which you could parse the character c from the input which is always going to be one um but you know there are other situations where your parser could parse multiple different ways so you want to be able to say here are all the different ways you could parse this thing but for a character it's just going to be one so you just check the input's empty and you check if the input if the first character does match your c and if it doesn't then you're just gonna return the um the empty result you can't parse this otherwise we're gonna push that pair of the character and everything we did not parse to our result and we're gonna return it so we're returning the thing we did parse and everything we did not parse and so that this is kind of like not very useful it can parse a single character but the useful part comes in when you um you compose these things you know right now we can just say we have some input we match we can match h and then we can get the front of it to check that our character we parsed is h and everything else is lo but when we compose these things we could do something like this you know this is a just a small example to show you how it might work you could match one of t and f uh this is if we're wanting to match like true or false so match t or f and then check if we got t and then match rou otherwise match als um we're composing parsers here in fact ben dean and jason turner had an entire talk which they where they did exactly this for um writing a json parser which works at compile time it's using exactly these concepts in fact here's an example i crib from them i just changed it a little bit it's an integer parser so first we parse one of one to nine and then we parse zero to nine and we build up an integer representation as we go along this is composing parsers it's kind of cool and entire languages are built on this you know if you write a um a parser in in haskell then you might use exactly these kinds of things this question of how efficient is the functional style code comparing to the traditional procedural approach um it depends it's the the easy answer like the the benefit of the functional style for a lot of this is um reasonability and um you know in functional programming we often don't have um mutable state so it's easier to parallelize things it's easier to reason about when changes are going to be made to your system of course because c plus is often built on mutating things some aspects of the efficiency do not translate nicely to that there are ways to deal with this if you look at some of the talks by uh phil nash or juan bolivar they both have talks on immutable data structures in c plus plus and how to make this efficient uh while doing like functional style programming um in c plus you know there are ways to get both efficiency and functional style all right so if transform is more like a drill you know drilling through the context then and then is more like a pipe with some duct tape if we have some functions which don't quite match up you know we've got some context we need to handle we're just going to duct tape them together and care about the values which are flowing through these functions rather than caring about the context which is built on top so we have some t's in a computational context and we have a function which composes operations which produce that context it composes things which return optionals or return multiple vectors or return futures and this is called a monad i would like to congratulate myself this is one of the very few talks in siebel's plus which mentioned monads where i do not make any of the obvious jokes about monads so i'm very very pleased about that now there are of course monad laws like with the functor laws you know i did the same thing i translated them to c plus plus and i had a bunch of slides when i explained them all and it was all really really boring and didn't really add anything to the talk so i got rid of it all uh if you'd like to know about monet logs you can come talk to me afterwards or you can go look at some other resource like not wikipedia and that essentially it's it's the same kind of thing here's how your monad needs to behave in order to be reasonable so the you know operations will compose nicely in a way which is not surprising so if you are manually marshaling data in and out of context to manipulate them then you may be able to expose a monad and doing so again will allow you to abstract away that context you're not having to do all the unwrapping yourself and write code at the level of intent now examples of monads again you know like i said with monoids if you look for monoids everywhere they turn up if you look from one ads they turn up what you might not expect as well co routines is an example here's some code i stole from coordination of this is a tcp reader function which you know we have a buffer we open some tcp connection and then we're gonna read uh a set number of bytes from this tcp connection over and over and over again until we're done now this is a synchronous function now opening a tcp socket might block might take some time reading from a tcp socket might block it might take some time we might want to do other things whilst we're waiting for the connection or for the the read over the network so um we could transform this into asynchronous code don't try and read this i don't want you to read this my only point is that it's horrible like i do not want to write this code i hope you do not want to write this code i don't know anyone who wants to write this code and this is this is even using you know this um this uses like dot then which is pretty much like and then so this is using some of the concepts i've already talked about it just it doesn't happen to to map nicely to this exact example you know we're having to create some state we're having to dynamically allocate it and then we're just turning all our control flow inside out and it's horrible what if we could take our synchronous version and we could get something which is the same as the asynchronous version just by decorating it you know we want to wait for our tcp so we want to do something else while we're waiting for our connection we want to do something else while we're waiting for our reads and curry scenes give us that we decorate it with co-await and now we can do something else while we're waiting for our connection or waiting for a read uh we also need to change the the return type because we're we're not returning in in 60 40 anymore we're returning some co routine type like a task or some future all right note that we've decorated our synchronous code because we do not want to handle the context of the asynchronous calls we want to focus on the values we want to focus on the the normal control flow we don't want to focus on the context coroutines are a way of exploiting the magnetic nature of asynchronous programming which is kind of cool in fact um here's some code i still from toby alsup you can actually use co routines for optionals as well so we have a bunch of functions which you know return optionals or return null ops whatever we could have um a function which calls f1 and f2 and f3 and we can use ko wait to say you know if any of these returns um an empty optional then just back out of this co routine don't try and execute anymore and this this actually works i i wouldn't necessarily recommend doing this but this is just a show that co routines are exploiting monadic um styles of these these constructs uh it might look kind of like do notation in haskell if you're familiar with that you know do notation is a way of making code look like it's straight line but actually the compiler transforms it into a bunch of lambdas and calls to and then or bind and haskell um and it's kind this is kind of half way to do notation it doesn't quite get all the way there because do notation you know sometimes you might need to run parts of your pr of your function multiple times you can't do that with co routines um because although it does split your coating into different functions essentially it does not give you a way to get those partial functions out so you can um execute something multiple times so it's it's part of the way to do notation it's not quite there but it's kind of interesting i think another static exceptions or her perceptions this is a proposal from kripp sutter which is tries to to fix exceptions in c plus plus i i think it's great personally but uh here's an example from the paper so if we have a convert function which takes a string and converts it to an int but you know maybe the the string is empty maybe there's some thing which is not an integer there so it could fail and then we have a function which calls convert and then multiplies it by something we have this throws keyword this is not a dynamic exception specifier uh which you might be familiar with and should never use this is something quite different what throws means here is actually i'm not a function which returns an int i'm a function which returns either an int or some statically known error type you think it is like a union of int and some error type or uh uh stood variant of ant error type or uh stood expected or result um if you're familiar with rust uh so that's what this is saying not not a function returning an int i return a a union of into an error and similarly these throw keywords inside the function do not mean dynamically allocate this throw up the stack unwind everything look for catch handlers now this means uh return the the error type uh return my my union event and error engaged to the error state and have it engaged to to error empty string or illegal char so this is this is not like dynamically throwing exceptions this is just returning things from functions but dressed up a little bit and then when we call convert and stir multiply if we got um the error state from convert then we're gonna automatically return that back from this function we're not like throwing it up the stack we're just returning it so this you know again we're focusing on just the normal control flow the normal values throwing flowing through this rather than focusing on the handling of the error context and like unwrapping these unions and things like that so static exceptions are a way of exploiting the magnetic nature of error handling again like when i show up everywhere where you're looking for them like we could actually we could convert this into something using uh like a stood expected type just by you know switching our um our return type to an expected event and error and then returning an unexpected so we're here i'm just converting the the static exceptions to like normal simple plus you could write today uh and then the only like real change we need to make is marshalling this context we need to like convert and then we want to transform that with uh with our multiplication uh one question is isn't static exception pretty much the same as outcome just different syntax yes that's exactly what i just showed here yeah it's it's syntax but it's also like if it's baked into the compiler then you can do things like um use different use registers for returning the error state and things like that you know because you're because the compiler knows how all of these things work it can uh can optimize a bit better than if all of this is baked into a library yeah the outcome is a different way of spelling expected here it's it's a very similar thing uh yeah so you can see here this is the difference we just switched our error types the return types and we we had to to do some additional marshalling off that convert so what we had we have monoids which are a data type with a binary operator which is associative and an identity element we have functors which are t's and some computational complex which we can drill through to change the values while maintaining the context and we have mono monads which are t's in some computational complex and we can chain the operations together without focusing on the context so look for monads monoids functors and monads in your code and when you do so you can expose them in your api to allow the clear expression of composition and writing code at the level of intent thank you very much i will have a look at questions now so there's one question where and how will such bubbling up error be handled do i need a specific try catch this is here um i can't remember exactly what the syntax for um actually handling these is i think it's you you have a catch but it's it's a statically known error type it's not like uh this could be anything which has to be dynamically allocated how to debug and step through the functional style code effectively that's a good question um yeah so one of the the things about this kind of style is um you know especially if you're if you're doing like asynchronous programming with futures and things like that then you end up inside like nested lambdas or uh the the control folder looks kind of weird um so it's it's a skill um the thing i will say is that it's um you know if you if you have all of these operations which are um are being just chained up then since you're not dealing with context it's harder to make mistakes but yeah when you do have to to debug and step through this stuff then it becomes a little bit more more difficult because you know you might get your your code is going to be called back by some library at some point uh and you might know when that point is but you might not depending on what your your data types are so yeah i'd say that doing this kind of thing can make it easier to it can make it more difficult to make mistakes but um resolving those mistakes and debugging can be a bit of a challenge sometime question is how to deal with the collision of the global namespace with the operator bar uh and then you could do that with with concepts or uh like screwing around with argument dependent lookup things like that there are ways to deal with that um can you maybe walk through the definition of a range's pipeline looks a bit like bash pipelines only the initial cat is missing is there some laziness involved um so ranges views which is you know like the to do there's my my transform right back here so if i have like a vector and i pipe that into transform uh yes there's laziness in this this example so what happens is when i say vector pipe to transform f pipe to transform g uh i get some view out at the end which represents my computation and then when i ask for a value uh by you know like looping over it using the the iterators or um like giving it to some uh some algorithm which does not execute lazily then it's going to call f and g on the elements of of the vector it's not going to do it ahead of time which does mean that um you know you can you could represent like infinite computations here because as long as you don't ask for infinite computations then they're not going to happen it's all done lazily um yeah for for ranges generally you have you have views which happen lazily and you have actions which happen right now in terms of like uh the um optional version or do i have an optional one here uh this is going to be you could implement this in different ways like so i have an implementation of stood optional which has a transform and that's done immediately that's not lazy but you could make it lazy if you wanted any other questions still got about four minutes left so uh time for some more questions and q a if anyone has some oh can you recommend books about functional style c plus plus yes um i would recommend uh yvonne coutique's book uh i think it's just called functional programming in c plus plus or something like that i can't remember the name but if you if you look up like if you google functional programming in c plus then you'll probably find it it's uh it's good his talks are very very good um so yeah i'd recommend reading that book and and watching his talks since ranges are now available with this style are you aware any plans for future slash optional to add similar things to the standard library so future um [Music] i i can't remember where future ended up with with dot then like i think we got dot then for future right um but it's not as fully featured as it might necessarily be and so i think the the implementation of dot then for future is uh doesn't map exactly to what um i talked about with functors and monad since i think it unwraps automatically but um yeah future is definitely there for for having this style available optional uh hopefully sleepless 23 i have a paper which adds um which adds the transform and and then and or else to the to optional you could also use my my tl optional implementation which has all of those can you link share a link to the stepping off paper i thought it was lost uh i can't remember where i got that slide from i think i just googled for stepping up stl presentation or something and found a an image and use that so sorry i don't have a link to the stepping up paper any last questions before i wrap up all right i think i will call it there thank you very much everyone enjoy the rest of conference