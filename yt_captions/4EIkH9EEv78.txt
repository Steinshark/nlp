Okay, today's video is about annoying puzzles. And I want to start with what I think is possibly the most annoying
puzzle in the world. So it's a simple enough question, just imagine: the Department for Transport is looking at a road layout and they've got two different possibilities for the road layout and they're trying to figure out which one is going to cause the fewest accidents. So let me just set out the possibilities; okay this is road layout A, this is road layout B okay? Very easy. Now, both of them are predicted to have a certain number of major accidents, major accidents - this is going to put people in hospital, we're talking broken bones, you know serious stuff. There's also a certain number of minor accidents, that might just be like a bit of first aid, you might need to see
a doctor, cuts and scrapes, that sort of 
thing. Okay, it's really simple. Each of these different road layouts is going to cause a certain number of major and minor road accidents, and I just want you to fill in this gap here. So, here we go. Two thousand, one thousand, sixteen. Now what goes here to make these two schemes equivalent? (Brady: It feels like 8.)
- Doesn't it feel like 8? Doesn't it feel like 8? So this puzzle comes from Shane Frederick, who's a behavioural economist, psychologist, at Yale University. Yale University, they're smart at Yale University. And he asked a whole bunch of Yale University students what the answer was, and the most common
number, was a bit more than a quarter of them, said 8. The next most common answer was 32. And the next most common answer was, if I remember rightly, 1016. Let's have a think about what's going on here. Road layout A is going to cause 2000 major accidents, this is people in
hospital; oh and 16 people with bumps and bruises. So why do we even care about this? Rollout B is going to cause only 1000 major accidents, so that's much better. So how many minor accidents would make it equivalent to to road layout A? And the reason this is an 
annoying question is because there's no- there is no right answer. But it's got to be like a lot, it's got to be many thousands, surely many thousands. Because these are trivial
accidents and these are substantial. And a very small number of people in Shane Frederick's survey did say 10,000, 100,00, a million. And there's no right answer but it's gotta be something like that. But so many just like you Brady, the majority of people - or the largest minority of people - more than a quarter of people said, oh we think that the correct answer is 8. And when you look at this you- your mind is wanting you to say 8 right? Because it's like it just puts everything in the same proportion,
right? Same. You've been asked, make these the same, that's the same. This is a- an example, it's quite a quite a fascinating example, quite a complicated example, of something that Shane Frederick studies which he calls Cognitive Reflection Problems. And they were made famous by the psychologist Daniel Kahneman in his book 'Thinking Fast and Slow' but this one is not in 'Thinking Fast and Slow'. So this one is- this has barely seen the light of day and I find it fascinating. But um, another example, this one's made very famous by 'Thinking Fast and Slow' is a bat and a ball together cost a dollar ten, and the bat costs a dollar more than the
ball. So how much does the bat cost? You may well have heard this before, a lot of people have, uh and instinctively you just think well it's a dollar right? Because, because the bat costs a dollar more than the the ball, how much does- they cost a dollar ten together so it's like a dollar and ten- but that's not right because that's 90 cents. And in fact the correct answer is the ball costs five cents, the bat costs a dollar and five cents. But people leap to the wrong answer. You want more? Oh yeah, this is a classic; easier in the time of coronavirus. Imagine a lake that is filling with lily pads, has this patch of lily pads on the lake and the patch doubles in size every day, and after 48 days the lake is completely
covered. So the question is, on what day - out of the 48 days - on what day is the lake half covered? And people often go oh well 48 divided by 2, um it's 24. Or they'll they'll sort of plot some kind of curve in their mind and they'll say, oh maybe it's like 32 or something. But of course the actual answer is 47 days, because the patch is doubling in
size every day. So it's half full the day before you get to 48, that's what exponential growth uh looks like and we've kind of found that the hard way. Now why do people get these things wrong? Why do people mess these cognitive reflection tests up? Why don't people look at this and go- there is no right answer but it's got to be something like 10,000 or 100,000 or a million. The reason it's annoying is we don't even have the information we need to give the correct answer; but what we do know is it can't possibly be 8. (Why can't it be 8? Because,) (because to look at that, if you look at) (major accidents it looks like road A is) (twice as dangerous as road B.)
- Yeah. So, remember what we've been asked,
we're being asked to make these two equivalent. We're being asked to to say, well, how many minor accidents would it be for for road layout B to be the equivalent of road layout A? So well the answer is, well it's the same as how many minor accidents are the equivalent of 16 minor accidents plus a thousand extra major accidents? And the answer is, well we don't know but it's got to be it's got to be at least a thousand and sixteen.
- (It's a bit apples and oranges) (though isn't it? Because like) (what's a- what's a major accident worth?) Yeah, yeah, exactly, there's there's no answer to the question which is why I say it's the most annoying question in the world. But you don't look at it and go, oh there's not enough- there's not enough information. We need, we need an exchange rate of major to minor accidents. What you do is you look at it you go - 8. I mean you might not, but an awful lot of very smart students at Yale University immediately said 8. A whole other bunch, not quite as many, said 32 and another bunch, not quite as many, said a thousand and sixteen. A thousand and sixteen is maybe just about right? If you say, well we're just going to count accidents and we can't compare them. But really the answer's got to be, you know, a lot. Way way more than 1016. (You know what the problem
with that question is?) (You straight away forget what you're) (trying to solve. You don't- you,) (you forget the question.)
- But that's it, that's interesting though isn't it?
Because it's- you know, I told you I told you the story, we're trying to compare these layouts, we're trying to figure out, you know,
which which layout. We're trying to- what's the equivalent of the two layouts? And you- Daniel Kahneman often says, when we're given a difficult question we often substitute an easy question and we don't notice that that's what we've- (That's, that's exactly what I did. Because) (I thought there was a solution) (I contrived a question in my head that) (had a solution.) Yes absolutely. And 8 looks about right. I mean you're absolutely right
Brady, 8 is the- of course it's 8! Of course it's 8. But of course it's not
8, it's not even close to 8. So why do I find these cognitive reflection problems interesting? It's because my own interest is in how we think about statistical claims in the news. Now when people see a claim on social media; they see it on Twitter, on Facebook, they see a newspaper headline, they see a talking head on tv - how do we think about those claims? How do we process them? And it's tempting, as a nerd, to go straight to, you know, the technical details. Have they confused correlation and causation? You know, have they- is it within the margin of error? All the sort of statistical questions you might ask. But actually, very often what's getting between us and the truth is our own tendency to leap to conclusions. Just as you saw this and you thought '8, that sounds about right', very often we see somebody talking and we very quickly go, yeah that can't be right, that's just fake news. What would you expect, you know, from those guys. Or instead they go, oh yeah yeah that sounds right; this goes to prove I was I was right all along. I always knew that this government
was, you know, was full of rogues and villains and and they can't be trusted with anything; I- you know. I was having this argument with my friends in the pub last night, ha! In the pub - I remember the pub. I was having this argument with my friends last night and this proves I was right,
and we leap in with this emotional reaction. There was a really interesting study published
I think about a year ago by Gordon Pennycook and a bunch of other psychologists. And Gordon Pennycook is
interested in fake news and why fake news spreads, and why people spread misinformation. What they found was you could take a bunch of people who were, say, die hard Trump supporters and show them a ridiculous claim like '500 migrant caravans have been intercepted at the mexican border wearing suicide vests'. You know, if you show them that
claim in the wild they might well click on it, they might well amplify it, like it, share it; and you ask them and they'll say yeah yeah that that is the kind of thing I might share. If you instead go, just wait a moment, how likely do you think that claim is to be true? There's no judgment, do you think that claim is likely to be true? About 90 of them will go actually yeah that can't- like, why would they be wearing suicide vests? Why would- why would migrant- it doesn't make any sense. None of this makes any sense. And so they're able to see, despite the fact they have a strong you know view of the world, we all have strong views of the world, they're able to see that that can't be true. And yet at the same time, in a moment of distraction a moment of inattention, they would they admit that they would retweet, it they would amplify it. And I
think I personally wouldn't be amplifying stuff about migrant caravans in suicide vests but we all have stuff that we see, that we we are tempted to retweet because it fits our biases. I can give you an example, a few years ago I saw a graph about support for same-sex marriage. Personally I think that's great news, more Americans in favour of equal rights for everybody - great. And I retweeted this graph, which I think was
from a- The Washington Post or a perfectly decent source. And I tweeted it because of my emotional reaction. Like, oh that looks right, great, tweet. 150,000 followers. The very first reply was 'Tim, have you looked at the axes on that
graph?' And I hadn't. And actually it was a mess. It was- they'd done that thing where the, the, opinion polls, the questions have been asked different distances apart. So maybe 10 years would pass and then they'd ask it
twice within one year. And they were all equally spread- the whole thing was a
mess; I should have clipped it for my bad data visualisation file; but instead I was amplifying it to all of my followers on Twitter, because it just seemed like the kind of thing that should be true and I wanted it to be true and I wanted to to share the news. Just like this seems like it should be 8. I love these puzzles because I- you know, I love being tricked and falling over my, you know, my own feet mentally. I love watching other people get tricked by funny little puzzles; but there's something deeper going on here. When we're reading the newspapers, looking at social media, we shouldn't be just accepting or rejecting things because they feel right, because they fit our view of the world. You only need to notice your own emotions, count to three, have a little think, and that is a way to stop yourself spreading misinformation. If you enjoyed this, why not check out Tim Harford's book, How to Make the World Add Up. It's also out in America under a different title, the Data Detective or the Da-ta Detective if that's how you like to say it. There are links in the description. And if you like puzzles, why not check out today's episode sponsor Brilliant? They've got a site bursting with puzzles, quizzes, interactive courses like the ones you can see on screen now. All superbly designed to guide you through the wonderful worlds of mathematics, computers, science - all sorts of other stuff. This scientific thinking course already has my mind buzzing. Or why not up your game with some statistics? It's like a fully equipped gym for your brain. You can get 20% a premium subscription by going to brilliant.org and adding that /numberphile. Again, brilliant.org/numberphile. [Preview] I had some delicious
toast. One bit with peanut butter, and a different bit with cheese. Because, you know, living the dream.