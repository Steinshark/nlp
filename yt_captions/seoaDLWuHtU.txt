It sucks when you buy into the latest technology only to wait years for the
content to catch up and if you have an HDR display you know exactly what that feels like. Obscure
anime, old tv shows, cult classics, great movies the studio just didn't love enough. Forget about it. Now, there are solutions to convert SDR to HDR, like this one from AJA, but
$2,000? I could get an RTX 2060 for a tenth of that price on eBay, and according to
NVIDIA, it can do the same thing, which means they finally did it. What Intel and
Microsoft failed to do 20 years ago. NVIDIA has given the home theater PC its killer app, but there's
got to be some kind of catch. Okay, but does it spike power consumption like RTX Super
Resolution? It's got to look awful, right? Is it full of artifacts like when DLSS first came out? You're just gonna have to wait to find out, Linus. Uh, fine. Can I at least tell them about our sponsor? Okay. Pulseway. Make remote monitoring and managing your IT systems easy with instant alerts, auto remediation, and real-time updates, all from one platform, anytime, anyplace, on any device. Start your free trial today with the link down below. When Nvidia recently announced their new Nvidia app, we assumed that they would move the RTX video HDR toggle into that alongside the beta that now works with games. But instead, no, it is still buried in the old Nvidia control panel. But the good news is that toggling it is as simple as click on, click off. Plouffe suggested we start with Wicked City, an anime from 1987 that looks like it's from 1987. This is pretty a little bit right, dude. Anyway, that's not what we're here for. We wanna see how our HDR toggle is going to impact the... Oh. Well, that really is something, isn't it? That flatness in the clouds in the sky. Yeah, it just gives it so much more depth, kind of brightens up the whole image, which I think looks good here. Yeah, it looks really flat without HDR, and all of a sudden... It's like you see more detail too, right? This won't be the last time we touch on this, but... That may not be the artist's intent. That may be the artist's intent, but as a viewer, I know which one I would choose. Even I like this one better too. And I tend to stick with artist's intent. Right, just like kind of a purist. This is even better. Okay, hold on a second. I haven't even toggled it yet, but yeah. Oh, the way that the night lights pop. Just looks kind of brighter and bluer here. It's lifting up some of the low lights, which has the benefit of allowing us to see more details. But honestly, in the bar scene, I feel like it's taking away from the mood a little bit. Yes, and that's kind of my issue with doing up mapping, especially with some of these dark scenes. The original grade is smoky and hazy and kind of gloomy, whereas this is bright. It's very colorful. Yes. Poppy. Next up, we've got Phil Tippett's "Mad God," a stop motion film from 2022 that suffers from the long night syndrome and doesn't have an HDR version at the moment. Whoa, okay. That is, wow, those lightning flashes though with the HDR toggle on, huge difference. First lightning flash, eh, eh. Okay, it's on. Whoa, that's lightning. Now the color changed a lot here. Yeah, the background went to like a blood red. On, off, on. That's changing the colors a lot. Yeah, see, I don't like that over-saturation. It changes the mood of that scene, right? It really does. However, the effects, boy, does it ever make them pop. Oh yeah, that looks good. So you can see, you can really see when it toggles. You don't even have to check. It's like, oh yeah, yeah, yeah, yeah. I just need every movie to have a proper HDR grade because it's clear, even with this faux HDR, how it could look. Without HDR, the specular highlights on a slimy monster, they don't look like slime. They just look like, I don't know, smooth. Yeah. Tell me this though. Okay, you've never seen the original grade. How pleasing is this to the eye? It's colorful. I like it. Do you like it? Well, I don't know what the heck's going on in the scene. I like the colors. Oh, the highlight's so much better. Just look at that. You can really make out
that detail right in the center of those specular reflections. It looks like a shining light. We're off to a really great start. Aside from
some minor quibbles about color saturation and the mood, there's no question that I would choose RTX video HDR over vanilla for
everything we've seen so far. Except, everything we've seen is two pieces of content and none of it included live-
action. Here's the thing. A compelling use case for this tech, like with their RTX Super Resolution upscaling, is streaming. So whether you're watching someone game or drop expensive technology on your screen, now you can make just about everything pop a bit more. And as you're about to see, it's not all sunshine and rainbows. Here's a recent video that we didn't upload in HDR. Or did we? Ah, the sunlight glinting off the garage door back there. Oh, wow, it really messes up some things. Like white texts. I mean, oh, wow, oh, wow. Some of this is okay. I mean, these are people that I know, obviously. This is Maria and Olamide. It actually adds a little bit more lifelikeness to them. Like, look at Maria, particularly. Oh, yeah, yeah. Like, you can kind of make out the . Shape of her face a bit better, right? Once it's turned on. You know, we were supposed to observe that with lighter skin tones, it gives a bit of a shiny, greasy look, but I guess I'm maybe not affected as much as some others. Looks all right. I think it really just depends on how greasy your skin is, to be honest. Everyone is going a bit rosy and orange, but it's not like absurd. It just looks a bit warmer. Dude, overall, I think I just generally prefer it for this. Oh my God, look at her necklace. That's yellow. That's metal. You can just see like the specular reflections off of it. Like Olamide's ring pops more. Okay, here, here, here, look, I'm right here. Yeah. So not HDR. Okay. HDR. Go again. Go again. Ooh. It's honestly not that different. Like I think your actual skin tone is right in between the two of them. I think you look slightly paler in SDR and then slightly too. Oversaturated in HDR. So if we're gonna be inaccurate anyway, which of these images would you take? Oh, definitely the HDR. All right, let's find some sweaty, greasy looking people here. You know what? In this case, yeah, you're definitely getting a little bit more glisten. It just gives it a bit more depth. It doesn't feel in an unnatural way. Yeah. I mean, he's sweaty as hell. And there's a ton of lights in that. Ooh, those lights just kind of. Yeah, I like it. It's a weird fall off, 'cause you're going from like pure white to like the shine around it. That's what the court lines look like, I'll tell you that much. Look at his towel. They don't look like that. Okay, the towel's a bit much. Yeah. That's a shiny towel. Yeah, the court lines. That's a bit much, actually. They look unnatural. Yeah, that's clearly not right. If we weren't toggling back and forth and we weren't thinking about it, I would feel like those court lines have almost a reflective element to them. Yeah. In person, they don't. Honestly, the only thing that's standing out to me is that towel in the left corner. That towel's like unnaturally bright. Yeah, God's towel. I like it. I just don't wanna have to use the Plex web interface in order to enjoy it with my media library. So if this worked with the app or was built into the Shield or something, like, I'm ready right now. I'm mixed. I think watching it now, I've kind of grown into it, but I don't
know. I still have to look at more things for me to like decide. And it's going to be the same for
you. But what I will say is aside from some quirks, it works pretty well. However, we haven't compared it to proper HDR mastering yet. Are reptile brains just
being tricked by more brightness and color? Just like if we were shopping at a Best Buy. To find out we're going to use some of our own footage from my giant TV video. I've been told that one of these files is HDR and the other is SDR masquerading
as HDR using Nvidia's tool. That's fake. Oh they're not going to tell me yet. It's
good. But it's fake. You're right. I know I'm right. Yeah. In some ways the image is a
little more pleasing but look at this. I'm pink. Whoops. It's too bad. I wanted it to be
perfect but obviously a properly graded piece of content is gonna pop where it's supposed
to. Like this content behind me looks almost identical but is also going to retain the natural
look of someone who is backlit and not forelit whereas I'm just, I'm just lit. Why am I so flushed? Is it like drinking? James looks better here though. And that's interesting. Is Nvidia making assumptions through the selection of their training data about properly lit people? So is this kind of like, you know, taking the studio mode of your selfie camera and applying it to any content that you watch? In fact, Now that I'm lit properly, it's far less noticeable. See, in this dark shot, I look more lifelike, whereas this is more reflective of the fact that I have no light on me. Damn, that is really close. This is a very impressive example. If I didn't know that that's a bit too much brown for my couches, I would probably take that image. You're right, it's very close. Like, the display is basically the exact same here. I actually think that the pinpoints on our light sources in the room look a little more convincing in the NVIDIA version. Of course, we're not using exactly the same display, so there is a little bit of variation there, but. There's some banding here. It's like very little banding there. Oh, you're right. Well spotted. I didn't see that. That's ugly. Oh, wow, interesting. Now that I know what I'm looking for. This is a much more egregious example of what Brandon just pointed out, where that brighter object was clearly manipulated in a way that lost some of its original quality. Look at this compared to this. There's a subtle difference in glow on the track from maybe the headlights? What the F* is this? I'm still very torn. Looks pretty good. Handled this white background actually really well. Yeah, I noticed in the video they do a good job for the most part at recognizing when something's like a white screen and not like blowing it up. Some of these look more lifelike on the Fake one, which is very interesting. So, how the heck are they doing this? The first step is they expand the color gamut from sRGB to sCRGB using a
transformation matrix. I can practically hear you saying, "sCRGB?" I wasn't familiar with it either. Kind of a weird color space, but their use of it here makes a lot of sense. Just like it makes sense to go with a Honeywell PTM 7950 thermal pad for your next build, now available for a reasonable price from a reliable source, lttstore.com. sCRGB is compatible with regular sRGB, but uses 16-bit floating point to calculate a massive dynamic range compared to 8-bit integer on sRGB, all while using the same white and black points. So in total you end up with 281 trillion possible colors compared to the 16.7
million of sRGB. Now when I say possible colors, that's because we can't actually see a lot of
them, making sRGB completely overkill for actually displaying anything. Modern panels don't have
16-bit control over their pixels, let alone the ability to reproduce trillions of colors. But
what it's great for is internal rendering and mathematical computation. So with that background in
mind, RTX HDR kind of works like DLSS upscaling, where NVIDIA is taking an image, blowing it up, then
using machine learning to fill in the gaps. It's the same idea here, just with color and
light. So to train their model, they analyze a ton of content, ideally in both HDR and SDR, then they take that converted SCRGB frame, they apply their denoising algorithm, and then they convert it to BT2100 HDR using that AI model to output a finished
frame that brightens or dims specific spots in a scene, or saturates colors to help
them appear more vivid, ideally without it looking like a Best Buy demo. It's really cool. It also isn't really new. Windows 11 Auto HDR has been doing something kind of like this for SDR games for quite a while now, often with decent results as long as you've completed Microsoft's calibration process. It's also been a thing on the Xbox Series X for a few years and it can really make those older games pop. All of a sudden, bright flashes are hitting about a thousand nits and they actually flash instead of just waiting at you. Of course. All of this assumes that the display that you're using can reach that luminance level and display it accurately. I've complained a lot on this channel about the HDR displays that are more like HDR-ent because while their base is certified and they can interpret an HDR signal, their backlight and panel technology just aren't good enough to make much of a difference compared to watching something in an SDR. With all of that out of the way then, what about Games, where the competition is tighter for Nvidia's new hotness. To investigate, we've grabbed a couple of the latest QD OLED panels and we've upgraded our modest home theater PC with a second near identical computer for our second monitor. By the way, we'll have links to all of this stuff down below if you're looking for PC parts or maybe a new monitor. Ooh, look at that green, that saturation on the green. Okay, here, let's look at shiny boy here. Oh yeah, yours looks so much better. Okay, hold on, let me just go. Okay, or we can shoot the shine. Oh, okay, yeah. Well, the shine still looks good, even without. Oh, come on. It still looks pretty decent. Yeah, it's all relative. I know. Decency is relative. These fireballs. Oh, the flashes on the fireballs from the imps? Not even close. What we're comparing right now is real HDR to SDR, but that's not what we're supposed to be comparing. Why don't you go ahead and turn on RTX HDR? Yeah. I can actually see the appeal. Of the RTX HDR version of this. Yeah. If you're into a really poppy, contrasty look, it's great. And guess what most people tend to prefer, whether it's correct or not. I know. They want brightness, they want contrast, they want color. And that's kind of what we're getting here. I honestly, I'd probably turn it on. Even here, I think it looks a little better than the actual native Doom HDR. Setting. I mean, the native Doom HDR is pretty good though. It's pretty good. Man, that is really poppy though. It's fun, you know? Yeah. There isn't a major impact on the visibility of dark regions or anything like that. Okay, what's next? Windows Auto HDR versus RTX HDR. Oh, okay. This does not look very good. No. No, I agree. No? It just doesn't have that poppy contrast. It doesn't even look as good as the HDR implementation. Yeah, it doesn't. Like the Nvidia one is taking it even further. Yeah. This one is like not taking it as far. It's very dull. Like look at the candy that pops out of the enemies is not glowy. No. Like this stuff looks okay, the flashing, but that looks decent in SDR anyway. Yeah, this does not look a lot better than SDR to me, if at all. Right? I don't think I would turn this on in this game anyway. It does make a lot of non-HDR games pop a little more. Especially games who never got, like, they're older, like, 2010 and earlier than
that. For example, I play a lot of Dota with Windows HDR turned on, and not much, you
know, but when you, like, get the big match-accepted screen, there's, like, all these
flashes of light, and it looks pretty good, but I'm gonna probably turn RTX HDR on at home. What's inconvenient is that every game's implementation is going to either be
best with... Auto HDR, or best with RTX HDR, or best with the game's native HDR, and switching between those is sort of a pain in the butt. Oh yeah, this took a while to get working perfectly. Right, like some games, for example, don't allow you to calibrate the brightest point according to the capabilities of your display. You're gonna end up with all these blown out clipped messes. So RTX HDR might be way better. Whoa, that sun! Oh man. It's such a small part of the scene, but it makes such a difference. It really does. Interesting. Okay, okay, it's catching these lights on the little dish tower here. Oh shoot, the balls. Forgot this game is really hard. Yes. The muzzle flash is wild. Yeah, those muzzle flashes almost look like stormtrooper shots. Yeah. Like they're so bright. Okay, not gonna lie, pretty cool. It's actually really not that overdone either, though. No. Man, that glint off the water, too. Bleh, bleh, bleh, what's the, I can't remember. I can't remember. I haven't played Crysis in 15 years. Bleh, bleh, bleh, bleh, bleh. I keep expecting to slide if I sprint and crouch. No, no, man. Pre-slide era. There's the old game. Just like Super Resolution, this is pretty cool tech, but it comes at a cost. It doesn't use up nearly as much power as the upscaling tool, but it does consume a not insignificant amount, and it's still in beta, so there are some bugbears. For example, the video HDR doesn't work on DRM-protected content. At least not yet. And the game HDR doesn't work if you have dual monitors. At least not yet. I have a wild theory that Nvidia is basically waiting for Nintendo to launch the Switch 2 before they will launch the Shield Pro 2. And all of this software development is happening very rapidly right now because they're gearing up for the release of the Shield Pro 2. I mean, think about it. The original Switch and the original Shield Pro, which
will be very similar in terms of hardware, and Nvidia has seemingly been due to
release a successor to that damn thing for years! And man, with some of the recent advancements we've seen, RTX HDR, Super
Resolution, I can see the Shield Pro 2 being a killer box. Not just for watching video, right? I mean, you know, obviously this is great
for that. But think about it for streaming. Games, man, de-blocking all those compression artifacts, just converting to HDR on the local side so that they don't have to send all that additional information over your internet connection. I'm excited. And I'm also excited to see more solutions for using HDR displays with content that doesn't necessarily natively support it, even if it's not perfect today. And hey, back to what we were talking about before. If I'm wrong about the Shield Pro 2, maybe at long last, the home theater PC will be a thing again, and you will all
rue the day you mocked me for keeping my Windows Media Center Edition remote. Rue it, I say! Just like you'll rue asking me about our sponsor. Manscaped. If you're feeling a little overgrown, trim your hedges the manly way
with Manscaped's Lawn Mower 5.0 Ultra. Its trimmer blade and foil blade are interchangeable, letting you choose from 5
o'clock shadow bald to... Oh, what? You need a mirror? Here's my head instead, bald. And to navigate through those more voluminous spots, the Lawn Mower 5.0 Ultra
even comes with an LED light, so you can see right through the shrubbery. It's also portable and charges conveniently with a USB-C cable, meaning you can
whack the weeds anywhere you might be. With a charger you probably already have. Check out the Lawn Mower 5.0 Ultra at manscaped.com slash tech tips, and use code tech tips for 20% off and free shipping. And yeah, it comes with its own charger. Didn't want to imply the opposite. If you guys enjoyed this video, make sure to check out the one about Nvidia's upscaling technology, RTX Super Resolution. It's also really cool.