and we are live or pre-life yeah you know I'm the speaker tonight so I welcome myself very much and I welcome you to the session but let me quickly check if everything is going well and then we get started right um thank you for being here Remy um and everyone else in hablo um and also I want to say hello to LinkedIn need to join the session and let the video play all right we're ready also on LinkedIn let's quickly say hello everyone on LinkedIn they also feel welcome um so tonight is gonna be a talk happening um and I don't have to like you know worry about the speaker not being here because that's me so let's get started with me getting into the slides also this is like I cannot see you while I'm in my stats so we have a few chapters and um during the chapters I'm gonna look into the chat on both platforms um and see if there's you know any feedback any questions maybe you know go through them um and for Linked and keep your questions short for uh hubido awesome and the Q a tab and also keep them short um and also like after the talk I will be in hobilo um meetup.me cpp.com for the folks in LinkedIn that I probably you know posted at the end of the session and this is happening with what now go under and a ton of other people posting things so um I think we already with everything and the theft let me go into my Snipes and set up complete and we're ready to go let's see wait all right um let me quickly and say that the voting on the talks for this year's conference has started and you received a newsletter if you subscribe to the newsletter or submitted a talk user and got that last night if you got a ticket or submitted a talk already and also the folks on LinkedIn if you subscribe to my newsletter you got a mail with a link and also there's a post about a news entry on BTC plus about it so um and I've already heard that some people really like the talks but it will be hard to select the right one step again it's a very good submission field if you submitted a talk thank you and let's get started with the talk so hello to tonight's talk um we are going to you know uh talk through what and how to import from a CSV file that's an interesting topic which I had to deal with and I've been you know looking into csv's left this year um plan to give a different talk on this but now I you know had a different angle to uh to present and this is going to be an interesting talk so let's get started so this was planned as a quick talk but actually I have over 70 slides so we're probably looking more like an hour um code I've written recently for importing the attendees and um I'll tell you a bit about 10 year old code base which is you know basically running the conference uh where this goes in and just you know I mentioned the voting um the Voting is one of the reasons I did that because I wanted to have the attendees in the voting and give them their voting ideas and so I needed to import that before starting the voting and some people already were like when does awarding start it's like you know usually we started back directly after the submission netbank closes but I had some trouble in importing that and holding that and so we were like a week late this year but it's okay so let's talk about why that is the case what's the issue with the CPS Plus and the importing from csvs um so this is kind of the motivation so I wanted to give this talk was I want to encounter um to keep this junior friendly though this talk is like really going to tell the full story and not only handle the C plus okay um if you're implementing an import you have a data source and you need to look at a lot of other things and just add the C plus code you want to write so learned um and on CSV files I have an important message for you don't use them okay um this talk does not support or promote CSV files as a data format it just happens to be sometimes that you have to use it but please don't you know read this as me promoting this or liking it so if you have an alternative or Alternatives you really need to weigh your options and maybe a better option for you um then it may pay off not to use the CSV format okay say and with that tonight's agenda is why where CSV file import and the lessons learned um so yeah let's talk about the why and I'll quickly take a look at the chats if there's any questions or anything I can take reaction to but it seems very good and I will start and continue the talk so um for 10 years I have been using sing events and so most of my code base is like not like written for seeing events but has used it and has lots of uh connections to it and last year Singh announced that they would uh close the group and the event feature and I had when I started the conference 10 years ago or 11 years ago um I had a sing group and then was making a good case to use fixing events so I could invite the scene group and in the end this group had like 7 000 members and I could invite them to the conference which is a little Advantage I was always happy to use and mixing events um in the years we did it it was always great because Xing events was a company of its own and if you bought a ticket from them they sent you an invoice from mixing events and so if they would make any invoice errors that would have been their problem and not mine it's a foreshadowing um but anyways I like the setup it was great it worked it I had to set up from the beginning and um now I need to use a different ticket service so we have a different ticket shop in this year and um yeah it's just not to mention them here just don't want to advertise uh things uh seeing events doesn't it doesn't exist anymore I was happy and I would have still be using it if they continue the survey service um but I think that I'm going to switch to a different ticket service next year I originally thought that I you know made the right choice and the next 10 years I would be spending this reset company but yeah maybe not uh I do want to mention that there is an API that's one of the reasons they were a favorite for me but the support from them already told me no no no you stopped supporting our API we have that but if you're running any trouble don't ask our support for it um okay and so yeah um after valuing my options I decided that importing a certain CSV report I could create on that platform seemed to be my best option for this year and so I went in implementing that quickly talk about the where where does the data go this is a screenshot of the event backend the program where this goes into it's a database front end of sqlite that manages the conference it's not a legacy but of course like it has over over eight years I have this program now uh first two years I didn't use it but then I created it um and there's a lot of various code actions in there which may or may not be needed anymore especially like with this year when we switched to different Services um but all those like the the thing Imports are still very very over because they contain a lot of Json code and a lot of code where you know I can learn from how the import worked for Json in the past um and the whole thing is built was cute it's a QT app um and so basically this is you know the the hive Point overview uh the the Imports the inputs go to the database and then anything that wants to do anything with with the data gets the data from the from from the database models okay so um and this kind of you know makes a kind of SQL Centric and everything looks like an SQL query which often is an advantage but also lets you solve a lot of your problems with SQL or C plus plus so yeah it's a double edged spirit I I like it and I think for for the database for the conference it was the right decision um but it has its own sites and I switched away from like making every one of my programs a database program um and I said like for 10 years I've been using cine events in eight years being I will set as a program um but this itself has not been a heavy influence it's visible in some parts where I use it and of course it you know reflects a lot of what that service was and what myself has been influenced by using them um but also seeing events has and kind of been responsible for creating this program because in the second year I wanted to import my speakers for the conference and they were like yeah sure we can do that send us a csvnb uh write you an invoice [Music] myself and I can manage that and the reason I wanted to have the speakers in in the event was very simple I wanted to buy uh the batches again with seeing how I have had done that in the first year and then I figured out that if I don't get to have the benches from Xing I don't need the speakers in the database and I can save money on scene and they're basically yeah lost me as a customer for their bedrooms and everything else but the ticketing service I like and there's a user Google made and the group on seeing it made sense so I kept using the service for for more years but I started writing this program where now I have to focus on creating a working reliable process to import this year's database data for the attendees which brings me to the topic of CSV file import and quickly look at everyone um if you have any questions or something like this post into the chat and yeah okay so let's go ahead to the CSV files um so quickly I want to mention that yeah um of course you know I I only have Capital CSV filex for you I've met in my career other CSV files but no thank you um there's you know um by definition I say first line is headers and field names every line has every field meaning empty Fields B uh comma comma or delimited or you want to say that or like an empty quote um indexing by number not a few names um so when I handle the data I do not have a map with a string I have an index which of course is a little bit better I think and yeah so we get it we gotta talk of course about the CSV ISO standard right have you read the standard on csris and then maybe I should say that CSV stands for comma separated values um which also can be like you know separated by a semicolon and if you export with Excel and it could also can be Tab and if you write your code correctly you can um detect like you know search for those uh things on the header and you can detect the delimiter and stuff like that um I don't need to do that because I only have one source to import but yeah so the standard um once upon a time I had to deal with parsing dates and there's a ton of standards for for passing dates but you you know have to basically parse everything and find out that some people don't told up to all of those standards and CSV yeah there's no standard I maybe there's one but it totally depends on what your source for the you know you export which to import is doing and where it's coming from which encoding it has etc etc so you're on the mercy of the process that creates the data which you're now feeding to your program so of course you need to read your CSV file and read by line if you can for imports I think a good idea so in my case I can do that and every every line is a data set in C plus plus 20 we have views split to split the line and that's really nice but it has like you know a little issue if you have a CSV which was a very common feature of quotes Suddenly It's not that easy anymore I haven't figured out like if um Rangers can do this but split does not seem to you know be able to have like a second character being like a subset or like you know being a quote basically um so also and you have quotes you can have new lines um so you really really need to look at your CSV file in an editor and see if that's the case um because in that case your one line is a data set model is suddenly broken and that is why I hate csvs it's really really complicated to make sure that you have like all the possibilities covered which CSV might be doing to you it's a bit better if you only have one data source like I do so I can kind of trust that but we're going to see later um if you should do that I quickly want to mention here there is STD quoted which can I think read from a stream and read the quotient uh stream so it's you know can be used to read until the next um occurrence of the character and it's actually also able to handle an escape character um which is like also when you handle csvs um I happen not to have the quote character in my quote data so I do not know what the Escape character in my data set is and it at the current moment I think that I don't need it because it's just not going to happen there it's just not going to be there um but maybe I should find out and you know um then I'll probably need to refactor my code because this is going to be a problem that's my code right now um and yeah thankfully I can read by line for another problem I have right now but on the other program I basically face the quoted issue that I probably will use quoted there um so you get line it is in my program um actually 2013 Eric nibler said that uh get liner is like a really nice and hard to beat algorithm because it reuses the string and reusing the string if you do it right um makes and a file when you read the file especially like something that has a similar length um only a few allocations um and then you're fine and so you don't need to have an allocation for every line basically you are allocating way less than the size of the file so if you import a big file you're still going to have this you know small part of it allocated at times and with an import you have the advantage to um you know import one data set at a time and of course if you if you can parallelize this then you can just you know kick that off and into a thread pool and have it imported um I decided not to do that so my import isn't multi-thread it you may choose to do that um so I chose to read my character to post the line pausing the lenses uh we cannot use something like boy or more horsepower on probably some D could be used and all kinds of optimizations could be applied to that but for the moment I got a working solution now I was like Hey that problem is solved and I can carry on this is part of a Lambda which is in the method which handles the file import because I don't want to like put that out to be in the in in the public apis that's not good style but yeah I can keep it local and this code is only run this year um and yeah I may want to refactor it in some part but right now I was in the time pressure and I had more important topics to care about than to micro optimizers um and this is like the second part where we switch in the quote models and if we're at the end of the quote then we go to the the other mode again and I figured out that if if I have not been in a quote at the end I need to check after the loop if I have been not in a code and place that into the column Vector which is a vector for string views which is returned here and I declare this as the first thing in the Lambda because that should um give us an rvo guarantee so C plus plus usually so this is kind of yeah how I read this currently um not too pretty but also not too ugly um and this is how I parse the line from STD string to the vector of string views um and I like that rather much that I have a vector of spring views and don't need to allocate anything here except like a little vocational chapter selector um and the next thing you need to do is to read your headers with their fields and know the next number for what you want so what I do here so as the commented line hints this is not running in production but this is basically when I wrote the code just you know I was importing the file looking at it seeing if everything passes if I get some errors and also like you know getting a printout of uh which field name is what index and from looking and then like you know something some other program opening it and looking at the data I kind of knew what I wanted and I kind of started to put that into code here um and some of that we're going to see again so the next step you need to do now is to look at your data okay it's like really important not only to write your code um I looked at my data and I was seeing things I liked and didn't like um which I don't like as the idea fields and to be clear here this is not the full idea if you ID field which I show you this is all cut off um because this is live data and I cannot you know leak anything which is life through this talk this is uh cut off by a lot um so the first thing I figured out we have numeric IDs which is nice and those IDs are not hashes because they keep increasing and they keep increasing by a certain distance um but it's just also like bigger over time so that kind of makes sense that it's a counter but it's brilliant and in my old service the attendee ID they gave me was like in the millions like 10 million or 20 million or 24 million I don't know what what's the last idea was and that is handled in an end but these are like long long lint territory and I don't want to do calculations with it and so for now I'm doing other things whether I keep it as a string um the date actually is a date time and from looking at the data my first impression was oh this is ordered and then I wondered if it's really ordered um the order ID was twice out of order okay so from looking at the data was good nice but it wasn't it wasn't ordered and the date which my next impression was like cool you know um one order was closing later than the other and so it's ordered by the date and also the date um was one sort of order and not like by some minutes it's not even explainable by someone like you know turning in the order later like two people buying concurrently tickets and one processors uh starting earlier and taking longer and in between someone else just buys a ticket um so not too sure about that and that kind of you know made me realize that I uh should not rely on any sortedness on that whole import that I kind of you know need to check if I have the data set which I import right now or if I don't have it and if I don't have it I want to import it so don't rely on your import Source being sorted if it's not explicitly specified okay just want to put this out here if you're a junior if it looks sorted tested if it is and if I had like you know done that like two weeks earlier maybe some of this data would have been perfectly sorted um maybe would have tricked me so that's what I learned right yeah don't don't trust the data source um also sorting the data would have invalidated the order okay so if I would have sorted it and you know that's something I thought about it but what if I force the Sorting um later I realized that this would really screw me because if I you know import the data today and then I sort the data on the week later and I get a late uh things showing up like several days later and it happened with State um I might not you know realize that I haven't imported that so um and the other thing is just like you know everything happens today on the cloud and sorting an export is an additional step and it costs money so the site that exports your data is not really incentivized to do it um so you might just get the dump of the data from the database and the database orders it in some way makes sense that the database wants to have those data ordered but maybe it's just you know that it orders the data according to where it's thought and if it gets big enough you get you know data stored differently because it matches the database better or something like that so you really really have to be careful that your import Source in this case is giving you data that you um can trust and that it is sorted that needs to be guaranteed from the from the from the other side not not like having the impression that it is sorted um now let's talk about allocations because you know Imports are slow and you want to speed them up so getting a few allocations less can be a lot so I realized that at some point I have to go from string view which is my medication to Q string which is my location and STD string and string view are one byte per corrector and my file is in utf-8 so Q string is utf-16 which is two bytes per character and you get a reference counting on top which does not really make a big difference for us right now but it's there to mention it for correctness and so in order to you know you know spam the conversion everywhere I made a convenient Lambda which just does the conversion uh from utf-8 to that and one of the things I've learned is like there's no direct um function in acute taking and S3 string view you basically have to give the data and the size and then this is interface you can use um and writing this talk made me think about that is that like you know what I want this is some of the talk some of the data and the code using this so for example I you know concat the strings for the order number and the ticket number to have a guaranteed unique string which is very very un likely to not be unique in the conference setting um and so this that's like probably three allocations which I do here um and I mentioned that you know everything you can do with SQL if you have a database uh this is like my first approach and I remember wait a minute um firing off an SQL query is even slower than allocations so um no let's not do that um having some set of known attendees and checking against uh that set is the best I think you can do here and um the thread set so it's kind of even like you know faster than otherwise would be and if we know the attendee if we don't need to import it then we continue and if we know it then I saw that I often use this as a parameter or even as a string index and into a map um and make me realize you know this creates uh allocations converts those fields which you know on on the one side that's what I want and on the other side it makes me think is there is there a better way maybe where we could you know do things with it so it made me think um should con to Q string return the Q string um as you saw it's like great for usability for writing code and it feels natural um but it easily leads to like you know having those local locations and if we want to avoid that we could potentially you know write like a two parameter version where you have an output parameter and then you could call from utf-8 and this instance now gets to you know convert the data to to utf-8 and you know in in the wisdom of of all programmers it has a chance to check if the internal buffer is big enough to be used and only needs to allocate once this is not big enough um and that would save a lot of allocations because you know we read by line and we discard those allocations after the import um and Q string is this anyways uh if you know those strings would be living somewhere it would be fine but um the local string could change and you know then live its life again um but this could potentially save a lot of allocations which we currently do in a perfect world of course from ukf-8 aesthetic so static function cannot access member data in the C plus password by definition because it's static it does not have an instant instance it belongs to um and so whatever string you give it to this function will always create an allocation twice the size and return the Q string for it and this made me like wonder about this animated a little code snippet to demonstrate that and to to ask some people about it and then you know when I do that I often sometimes have the Habit to put that in a tweet to you know maybe I get input from other people I don't know and some of the other slides now are the feedback that got returned by this um one more thing I want to mention is that there is no static conversion function function taking a q string either okay um there's no from you give Aid where you can pass in a q string instance which then is used as a buffer internally if you can do that or just allocates if it's bigger than that um so yeah reusing the buffer of a q string for a utf-8 conversion seems not to be possible um and I don't know enough about utf-8 decoding to know that makes sense if you know the decoding itself is better with an allocation than when you uh basically first try to calculate if you need to allocate or not um or maybe it's like low hanging fruit which you which cute could pick up um someone else pointed out that there is the qut f8 stereo class which I think is rather nice to know about so I put that into the talk um I do not see a use personally for this because I have string View and when I handle the string View with the utf-8 inside I am fine with the standard streaming view class so right now I don't have a use for the string view maybe if I you know have to pass this around or maybe there's some internal cute function having this as a parameter okay um but I yet have to see that it should function which Demands a conversion to this class so it really would make that in use um but this means that in theory if you want to write code for cute that you utilizes Q string you and only concentration that reads from EQ string that you know does certain things so that you could write generic code taking an auto a template parameter which could be either a q string Q string View string view or other cute string view classes that's there there are some others as I figured out and cute of course also has something for this which is Q any string view because when you write a template function or generic code if you can have a class which handles all of that um so now you have a string view which handles any string view except the STD string view so this is basically in any string view for cute string views um which then has a subset of the Q string API [Music] um and from looking at the documentation yeah that's that's also something which is interesting to know about I don't see a use for that currently something else I might be using is this class Q string decoder um you may notice that we have this Lambda and we always call the static function and the static function we always probably have to set up something to do the decoding and I do not know how much an internal State this decoder needs to set up that is expensive but there is a q string decoder class which would you know take that burden off you and you would be able to have that and Miranda as a member and then just reuse it all the time um and this preserves the internal state and gives you more control than from utf-8 and also you can you know gives us some setup and there's some uh options you can use to influence Its Behavior but as far as I'm aware also this class does not have the ability to reuse the buffer for the conversion on and the point for me is like do I want to create uh internal shared State between all the calls of the utf-8 conversion because there's some error I need to fix it and reset those class or something so I would have to probably add some error handling into the conversion Lambda to check after every conversion of the conversion worked which I currently don't and it works but you know it's kind of if you share this it would affect not only like one string maybe being empty or not just saying the full string import maybe you know just ending at the correct it couldn't parse um and that's stuff you can influence also here but I would have to check for that and um that's something I probably still will again try to find out if it's worth doing and here's like if you have like a chunked reader if you get network data and it's utf-8 um then this class could make a lot of sense for you and it's nice to know that this exists and you can set it up and tell it like what is the input what is the output and then it does the string decoding for you and keeps an internal State and even like if your chunk ends at something and then goes into another chunk uh this decoder class can handle this but with the internal State this could mean that if I have you know called this twice for two different fields and the first field had like some corrected couldn't pass or wasn't full it could create some state where a part of one field is still in the decoder and with the next call this would be the beginning of the next field which of course is like a big error right this shouldn't happen and so you have the shared State um in your code um so basically I'd have to check like I have to check every time I have to call this function and then I have to call an if and say did something happen and of course this is like no nothing happened but I have to to to handle it if it happened and maybe you reset this thing that doesn't add the string it sort of holds internally to the next data set or to the next um field which you know I may or may not use maybe I'm not effective because the next field in the data set isn't used then I'm like okay but maybe this ends up in an important field and messes up um my data so this is something really really to be curious and worried about um the other thing I learned is like Q string interfaces are the Daily Bread of cute um at the end this import is an SQL query and qsql query takes this query as a q string so I had the nice idea of keeping all my strings as and cute as like as a string view or a cubite array and then have this not be a q string and maybe I would be able to you know give the SQL query an SQL query which is a byte array and then I you know get to not allocate twice the size of a string that is in utf-8 um but that doesn't work and of course also the UI include a few you know you want to make this nice label where you display the data for something or have a text field or something all of that is queue string and of course when you use queued that's also true for your own code base and that's where I you know was like should I add like an overload for that taking a string View and handling that then but in the end of the answers no the current interface is totally fine because it uses cute and the cute interface is Q string and so um there's a lot of effort to you know get around this uh Q string allocation if you want to in some cases you can if it's your own code but as soon as you step into Cube territory and use like some thing from cute you may have an interface which only takes this class and you have to do the location and yeah the other thing is like the big import is done and every other import will cause much less allocations and run a lot faster so it does not make sense for me to optimize this code to the last bit um and as I said performance is nice but correctness there's a lot more important like this is a string decoder class very nice but what if it you know messes up my data I have um a name wrong like you know you have an error in the in the first name and then the second name is wrong um of course I would notice that I would be able to fix it but why you know why I have that Arrow if it wouldn't happen with the other things um so creating this talk made me realize there is still one thing I can do because it made me realize that some part of my code can be converted to sdb string I load from the database the Q variant and if I do not convert that to a q string but to a byte array I can convert the byte array to an STD string and I can do the whole thing without allocating utf-16 I still have to validate that the string value in a q variant from a query actually as a binary and not like going through Q string to become a binary okay this could be that two byte array um says hey we have a string input and we need to make that a string first and then we make a divide array and then we return that and when I make them let's see string that would be bad um so we're gonna you know maintainers what that is doing internally um but yeah I use a fifth set um to have the strings and then basically I create the current ticket and this current ticket will reuse its memory after the first allocation and I haven't done you know import the attendees and after the first time this runs this will not allocate anymore uh for an attendee that does not need to be imported and this will you know safely some allocations of course you cannot like you know do this without having 100 no allocations and I wonder right is it better to have an unordered thread set here maybe would make also a lot of sense um but this is the current state and adding an unordered fed set I don't even know if that excess but I think it exists um could be another optimization which is really looking for fruit which I could do here um and yeah so there's actually more to this code than what I've shown you so far um I need to import more than just attendees I need to import the orders you know I just mentioned that in the beginning of the program of a talk that we have a situation that I need to be able to correct the invoices because that is slightly wrong um no that's why I do this which is a lot more difficult than and really have to get that right um so for every order create an order object and then later this will be written to the database and this is all local to this function and why yeah the ticket service gets away the the what wrong and the invoices and I have to reissue them to correct this only this year and yeah so it's really it's what's really interesting to see that only a few people have noticed this and I first didn't believe it but then when I checked it I saw it and it was really difficult to have a conversation with the ticket service about that and [Music] um basically when I didn't get farther I was like I want to speak to your Superior because this is really a big issue but they didn't care about it even like network but you have to correct it yourself so creating the invoices and sending them is the next thing to do but this is a different story um I do want to split those processes that's why I write this to the database um and yeah just have the data available and be used by the next process because I think that you know being able to process the invoice data from the database which already have also classes for need to refactor them for this new use case makes sense to have that spit off into a different process it brings me to Lessons Learned and I take a quick break and look into the chat uh yeah I this does not have a repo okay so I do not I probably want to do a little bit of a quote uh post and um my blog my blog post will contain some of the code but there is not a GitHub repo for this because a lot of this is like internal okay someone says there is no reason that you can yeah um but it's like the apis you use have a different opinion on that um but yeah I shouldn't reach that um no question so far if you have any questions post them to the church otherwise I'll be going to the lessons learned just fine um all right let's get ready to the next chapter so Lessons Learned so yeah as I already mentioned this year these are in the billions don't like that but tell us a lot about the service that it's very successful um and I think they're too big to put into a reasonable integer type okay um let's just I I can see that but in my use case is that still a good idea to you know use long long ends or whatever else is available in the standard on and maybe include to convert this and as a conversion step can't even use it because I don't do calculations with that and yes I I see that a few you know use it as an index in a map or a set that will be a lot faster um but I don't have an input process which needs to be as fast as it can be actually if it blocks like my program for five seconds I just go look at Twitter and return when it's you know just shouldn't run like four minutes or like you know let me question if the program hangs because it crashed or something um so it needs to be fast it needs to be usable um but it's not like running on a server and doing uh every few seconds in import file um yeah my own internal database has its own ID and it's like around 7K so I don't really have a use as an end for that internally I have another ID which I can use anyways and when I use it as a string I can add the two Fields as a string together and I have something which is really unique now um because the attendee ID looks unique but what do I know right maybe it's just the database ID from this one chart of a database and maybe one day I get a different chart and yeah well we never said that attendee IDs are unique um combine it with the order ID to make it unique all right that's why I do this to account you know make this very unlikely and my database actually is set up for that that I can store this as a string because I don't want to do calculations on it so it didn't even need to do any changes to the database to run this this year's uh things so I'm very happy about the decision back then to to make my tables and other things which I have internally uh very versatile and not like adopt them to exactly fit the the data I had like a graph like saying oh this is an end let's make it an end uh it's no it's an order ID it's some some weird stuff from a database and I don't want to add it I don't want to do calculations so it's a string um man as I said you know this code mostly is gonna be for this year um so converting from utf-8 to Q string will always cause an allocation that's nothing new to me but it's again a lesson I learned and I learned a lot about the the various classes around this common version and what I could do with them and the issues with that and we'll see what the future holds here for cute at least I am now confident in the opinion to state that cute itself does not have the ability to reuse the buffer of an existing Q string to do a conversion so if you do a conversion you will allocate the new string and then assign that to a string um I don't know if they could do that the apis allow that maybe the cute maintainers also think that it's a great idea uh utf-8 is everywhere and I want to mention that like Json is also by default utf-8 so anyone doing any imports from the network will probably face utf-8 and so being able to reuse the buffer in an import process will save a lot of our locations and make it a lot faster and I don't think that you can like give a q string an allocator or something the standard library has an allocator and there's pmrs which I recently experimented with since in Spring uh so there there's other ways to speed this up when you're in standard C plus plus but cute itself I think is not really allocated everywhere or allowing you to uh somehow um impose a source for their location to g-string but that's that's another thing which I lack the time to look into if there's maybe that route is available where you force cue string to have all its allocations from a pool and you basically you know get to reuse your location it's a bit better that way and yeah so choose string is a common type in cute which I've always known but it's just important to note to notice that here um if you use Q string is an important class and you should know it you should know it in and out you should know that it is utf-16 and not like the standard string uh which does not have an encoding um it can be used to still gf8 which has been the code case here but um be aware that this causes adaptations and causes all kinds of problems when you use it with standard C plus plus which is fine and just the normal way but I wish that you know we had a better way on doing it stringing is nice I've used it before but this time I really like was saying yeah I I create a view and a string and it makes sense and makes you know makes me feel like this is now uh a much better version of C plus plus than what I would have written in the past or what I have actually you know written in prior CSV Imports where I use cute or other classes um so that's nice and yeah if you have any questions post them to the chat to the Q a tab I will look at LinkedIn and also who below now to see if there's any questions okay LinkedIn post your questions I see there's a comment on the ownership of Q objects which is shared yeah shared ownership and queued the cute people like it a lot and they say it's the right thing to do in a UI application and they are partially correct with that I just wish you could you know um have a bit more of a control over a acute string then I think that is really really hard to do nowadays because Q string of course there's an obvious you you cannot change Q string uh Q string is not a class which you can um change during compile time anymore it's fixed so we're going to live with that they're just sad because they you know for a long time I wish that you could have like a cute book with utf-8 underliness um under Windows it makes sense to be utf-16 because all the system calls are utf-16 under windows and I think the utf-8 or 8 by 8-bit things on the Linux maybe it's also utf-16 under Windows which actually I'm not aware about that that's like low-level stuff I'm using cute Force acute source that maybe uh cute has um good opinion and a good solution using uvf16 here I'm not sure but in C plus usually the default is a utf-8 enabled STD string then when we read data from the web it's utf-8 let me look at Okay so don't see any more questions from LinkedIn so if you want to have a question from LinkedIn uh please post it and otherwise let me load yeah there's no q a questions yeah yeah I know that uh comment from hubido yeah yeah that's correct utf-16 is the version of Q string on all platforms there's no difference there um I wish you could make a difference I wish that there would not be an option but that is not usable anymore that's cannot be done that's impossible to change I understand that because Avi issues which which is the whole yeah Rabbit Hole to go down which I'm not going to do um so that brings me to the end of the Stream thank you for coming um I'll be hanging out in hablo now on the launch and enjoy a conversation with some of you um quickly on it also post the link to uh LinkedIn which is um meet up meaning cpt.com yeah all right so with that we're done for today it was a talk thank you thank you for coming oh I see someone as a question is there no way to get access to the internal buffer of a q string is the question yes yes sir so if you really wanted to write your own code doing the utf-8 decoding you could do so but there's no utf-8 decoder and shoot where you could give this buffer to meaning either you have an external library for that or you would need to you know write that feature on your own as I said um I've never implemented a utf-8 decoder and I do not know if maybe always allocating is the better option or if like you know checking and calculating the lengths of the end result is the better option um from what I've read is that one of the problems here is that utf-8 is not a fixed blanks encoding so you cannot um calculate the utf-16 string from the length of the utf-8 text um and I don't know if you could get around that was simply adding more to your allocation like you know not allocating twice as much educating 2.5 as much which would be a bit bigger in allocations would take a little longer but would be worth doing probably in your code base if you could save a lot of allocations because like you know imagine this import file having several thousand entries or several million entries and you need to process it then this implementation this feature could save you a lot of um allocations and speed up thanks um but as far as I'm aware you would have to implement that yourself that's a thing I don't want to do this out of scope for me with this process um but if you wanted to do that that'd be an interesting topic and I I probably want to ask some of the utf-8 people um to all right people who do Unicode and C plus passive web like there's a good idea of there's a reason why it's not done um and with that um I will close the stream and thank you for coming really interesting topic um was a lot of fun to prepare the talk this week and help me improve a little bit on the code but I'll have to um you know carry on with organizing as a conference and this code is now broken and well-tested and I don't want to touch it too much because if I break it that's much worse than making it to the allocations so thank you for coming and if you're on LinkedIn you're welcome to join us in hobilo and join our table in the lounge see you there