I recently caught news of open AI leading a 23 million dollar investment in a humanoid robotics company based out in Norway One X Technologies the company is unrelated to the cable company with the same name based out in Sheridan Wyoming this one used to be called halodi the investment reminds me that one of open ai's early product goal was to create a household robot capable of setting and clearing a table I reckon it's been a bit forgotten with all the chat GPT stuff in recent days there has been some growing investment interest in humanoid robots the mechanical and computational challenges are immense but the dream is glorious in this video we're going to take a brief look at the science and challenges facing the humanoid robot but first let me talk about the asianometry patreon Early Access members get to see new videos and selected references for those videos before the release to the public it helps support the videos and I appreciate every pledge and I recently added an annual subscription option too thanks and on with the show what makes a robot humanoid there is no widely accepted definition nevertheless we can point to a number of generic characteristics stemming from their design purpose and from there we can identify common traits these robots need to move around perform a broad spectrum of tasks physically touch people without hurting them and manipulate tools made for humans they also have to autonomously operate in human environments as well as communicate with people at an advanced level when I first read that last bit I wondered why that was necessary then I remember how many times I've been yelled at for messing up the chores back at home these design requirements thus dictate a human-like robot design with a torso had two legs and two arms the arm should also have hands with multiple fingers two legs are preferred over four for energy humanity and cost reasons the technological basis of humanoid robots are in industrial robots but there are significant differences most industrial robots are nailed to the ground and built to perform a specific task they're big heavy and fast so most are not meant to regularly interact with ordinary people that is not the case with the humanoid robot this thing is with you in tight intimate spaces and that means some special engineering people have been dreaming about humanoid automatons even back during the days of Leonardo da Vinci long before the word robot was ever invented so let us start our brief history of the humanoid robot starting in the 20th century it begins of course in Japan a grieving father named Dr Tenma embarked on a solo project to create a replacement for his son who had died in a car accident the robot named Astro Boy then fights crime and Injustice and oh wait excuse me I'm being told that Astro Boy was really a manga created by Osamu tezuka in the 1950s apologies one of the big moments in humanoid robotics development really was the introduction of the zero moment Point stability concept introduced in 1968 by the scientist myomor vucobrotovich the theory covers the Dynamics and control of legged robots with powered controllable joints an industrial robot is often bolted to the ground using a single fixed Anchor Point but the soul of a humanoid robot's foot is not fixed it only makes periodical contact with the ground when you're walking you only have both feet on the ground about 20 percent of the time the vast majority of the time the body is supporting itself on a single foot did you walk around now just to see for yourself I did anyway so the robot has to determine whether or not a specific foot movement will allow it to keep its balance the zero moment Point represents the point on the ground where the robot's footing can be stable calculating where it is and making sure that it is located at the robot's foot is a vital part of the system researchers develop control algorithms for achieving this the most common ones approximate the walking motion as like an inverted pendulum but there are others around too a team at westada University led by Dr Ichiro Kato started studying humanoid robots based on previous work done on active prosthesis development in 1973 they debuted a robot known as wobot one it walked on two legs touched and held things and can communicate in Japanese the team judged it to have the mental faculties of a one and a half year old in 1984 they produced the robot wl-10rd the first dynamically balanced bipedal robot it was the first of its type capable of walking and a physical demonstration of the zero motion Point Concepts feasibility for robotic bipedal walking the wasero team then came up with a second robot wabat 2 that can sight read music and play the electric organ like any sensible Asian child the robot's movements were Guided by 80 microprocessors and mechanically produced using wires then in 1986 the automobile giant Honda started a humanoid robot research program to explore new ways of locomotion their intention being to eventually produce a sophisticated and useful robot capable of helping someone as like a work partner or servant they began with a bipedal prototype that used linear actuators which are like artificial muscles to put one foot in front of the other the first robot called e0e for electronics walked very slowly 5-30 seconds between steps and only in a straight line Honda expanded on this initial success by speeding up the pace ten years later they introduced the P2 a fully self-contained robot capable of walking around on flat surfaces and even upstairs prior to P2 many people were skeptical that it would even be possible to create a working walking bipedal humanoid robot so this achievement was a real breakthrough Honda's work has since evolved into the humanoid robotics project a government-sponsored project with the goal of eventually producing General domestic helper robots their robots have been able to perform many individual movements like getting up or squeezing through tight spaces and walls it is probably one of the leading developers in the international humanoid robotics industry humanoid robots can move on two legs but many are not ready yet to move outside of the laboratory this is due to the zero moment point-based nature of these machines which has several recognizable characteristics one is that when the robot is walking and one of its feet is in the air the other foot has to always be in full contact with the ground it gives this sort of heavy flat-footed walk stop we do a lot of studies of how real humans walk as inspiration but the human body is very flexible it can offer up to 300 different degrees of freedom while walking the person uses up to 20 of them scientists thus often simplify freezing and rigidly controlling certain joints which again makes the walk or movement appear unnatural so most of these robots end up doing something like a bent knee Frozen torso walking it keeps your core more stable and is easier to calculate but is also tiring you try it it is tiring it is as tiring for the robot as it is for the human part of the reason why it is so tiring is a lack of something called toe off this is where you're trailing big toe pushes off the ground as your weight transfers forward it is an important energy saving feature that stores energy in the leg anyway one other thing about bent knee walking is that it also makes it harder for the robot to clear obstacles previously walking robots could not deal with unexpected unplanned obstacles over six percent of its leg length that is shorter than the average curb and is partly because you have so little clearance there are also issues involving the problems of calculating new coordinates when dealing with unexpected obstacles on the Fly though there are encouraging results with using AI to get approximate results without having to do all the model calculation progress in this particular area has been very encouraging in 2018 a French team demonstrated a robot capable of climbing normal different sized steps without the use of tethers that same year an American team taught a Boston Dynamics robot platform called Atlas how to walk in a straight leg manner interestingly enough the straight leg walking as well as toe off Behavior emerge naturally after biasing the robotic body's controller to straighten the legs as much as possible there are also some really interesting tests that can produce faster bipedal running speeds by studying Birds rather than humans one prominent example is the Cassie robot by agility robotics which can run the 100 meters in under 25 seconds bird running robots are very fast and can better navigate unstable Terrain the only real thing is that they act and run like birds which are literally dinosaurs this can affect how people might interact with them people are not only great at walking around and keeping their balance they're also quite good at manipulating items manipulating items remains one of the big problems in robotics consider again open ai's goal of having a robot that can set and clear a table that would mean being able to pick up a dirty plate off the table and then setting that plate into a tub how hard can it be feels quite easy and instinctive but then again imagine all the little subtle finger and hand movements that go into just picking up a plate your hand goes to the plate choosing an optimal trajectory to approach it the fingers gently slide along the Plate's Edge and then roll under it you push the hand and fingers forward enough to gain a grip over the bottom of the plate in order to manipulate it tip it up and then lift it this difficulty is an example of moravich's paradox the observation that certain things that humans find instinctively easy like clearing a table are discovered to be very difficult for robots this action and others like it not only requires exceptional mental calibration but also a soft touch the latter is something that has been surprisingly challenging for robotic muscles to do being gentle requires precise feedback acute physical awareness and controlled stiffness machines are good at being strong rigid and Powerful not so good at being soft and huggable the technology known as soft actuation remains a developing field requiring expertise in disparate Fields like materials structural design and Fabrication it is also computationally intense because the robotic hand is covered in a soft material that moves and bends often but not always silicone the system's dimensions are basically infinite calculating all the possibilities is unfeasible even not counting the uncountable trajectories a hand can achieve a certain movement in a certain way so researchers essentially assume rigid rather than soft body conditions such an assumption can lead to errors sensors are also a big limiting factor in soft actuation research scientists need a lot of sensing and feedback so the sensors have to be cheap and easily manufactured experiments have used sensors made from embedded liquid metal embedded rare earth magnets optical fiber and more trying to get the right balance of price and sensitivity is challenging to say the least other major challenges for soft actuation involves power manufacturability and noise the most commonly used soft actuators use air pneumatics such soft pneumatic actuators often require power hungry loud and high vibration support systems like pumps an industrial robotic arm can pick up a plate and put it into a tub pretty well actually gentleness notwithstanding but that is not enough a good humanoid robot will also have to carry the tub with the plates in it over to the sink and then it goes back to the table with fresh plates setting them down properly and in a coherent order we need the robot to do all of these things well and in varying locations under uncertain conditions recently Facebook released some interesting AI research on these concerns they call it adaptive skill coordination and they describe it as like chaining together lower level individual skills like picking something up it can use those skills to navigate towards achieving a bigger Longer term goal in the real world I am for some reason reminded of ultra combos and Killer Instinct love that game when I was a kid very importantly adaptive skill coordination allows the robot to actually back up and correct itself when something goes wrong they used it to train a four-legged Boston Dynamics robot to perform a pick and place task between two apartments overcoming various uncertainties and challenging situations one of the ways researchers are generating the data to develop Proficiency in these activities are in simulation in a previous video I talked a bit about the use of video game Technologies to produce simulated worlds for self-driving training data there are similar applications for humanoid Robotics and their introduction has been a huge Boon for the field we can create simulated worlds to challenge robotic Control software without the need for the actual robot there is an interesting simulated competition called robocup 3D soccer simulation it is a research soccer game environment that uses the Nile humanoid robot as the agent the goal has been to help generate data for teams to create the low-level behaviors like walking standing up and turning for instance creating the kicking Behavior resulting in some pretty Nice Kicks large language models are revolutionizing everything can they do something for the robotics field the application is not entirely obvious llms are trained on texts and do not have bodies to sense their surroundings nor perform physical Acts not being aware of the physical context can lead to some strange answers for example if I was asked to clean up some spilled Coke I shouldn't suggest a vacuum cleaner if there isn't one nearby so we need to give the model that context in some way the easiest would be to do some intense prompt engineering to give the llm all the context but that is not how humans are used to communicating I read an interesting paper from Google in which they trained a language model in concert with low level skills the quote-unquote body to the quote-unquote brain that is pretty cool but the most useful way I think to use a chat GPT for robotics purpose would be what Microsoft suggested they use a llm to translate ordinary Communications to something a machine can understand like code or an API output but considering how chat GPT and other llms like it are still apt to providing incorrect answers a person must remain in the loop such a brain in the bottle thing can feel a bit awkward and chat gbt would be the first to tell you that in some ways producing the autonomous humanoid robot is more challenging than self-driving there are way more degrees of freedom for the humanoid robot to handle the human interaction is way more intimate and at least with driving we know what the machine's physical form will be like the economics are somewhat complicated too but it is hard to say exactly how until we get a price price and manufacturability are critical points that I just barely touched on in this video but make no mistake it matters a lot but there's a lot of investment interest nevertheless you have funding events for humanoid robotics companies like apptronic agility 1X and Sanctuary some of these machines will start entering warehouses the dream is real but deep technology is fascinating and I do believe that new AI methods will accelerate progress in humanoid robotics very quickly I don't know where it is going but I am excited to see what will happen all right everyone that's it for tonight thanks for watching subscribe to the Channel Sign up for the newsletter and I'll see you guys next time