we seem to be living in an era of tailored databases there's been a real explosion of them in recent years you get databases that are really strong at certain kinds of workloads databases designed with a deliberate sweet spot and I don't think that means the end of the general purpose database like postgres or MySQL or anything like that I don't think they're going anywhere I think what it means is that as developers we have to expand our toolbox we need a larger mental list of the kinds of databases that are out there so that we know when it's time to use the specific tool for the specific job so in that Spirit today we're looking at xtdb which is a bi-temporal database what to buy temporal database you ask exactly I've brought in an old colleague of mine James Henson to discuss it we last worked together years ago and since then he's become the lead developer for XT and I wanted to ask him about the two sides of that job what to buy temporal database why should we care and what's it like being the lead developer on a new database I don't think that's quite like other programming jobs no we're all users of databases but very few of us will be on a project building a database so this week we get to live vicariously through James as well as expanding our list of options for future projects to buy temporal database it's kind of something you might have already created an ad hoc version of in the past but today we're going to see something that's formalized it properly so let's look at bi-temporality I'm your host Chris Jenkins this is developer voices and today's voice is James Henderson [Music] joining me today is James Henderson James how's things going hey Crystal and we're all thanks and yourself very well very well glad to see you we used to work together many years ago a long time ago wasn't it yeah it must have been 2013 I want to say that's that's forever in Internet yeah yeah it really is it really is these days you are a lead developer for a database called xtdb all right and I wanted to talk to you about two things which we have to get deep into one is why does the world need a new database and two what's it like being a developer on a database so it's probably best for context we start with what you're building rather than what it's like so why does the world need a new database James um so I'll talk a little bit about what um what xcdb is um so it's a database we've been developing for about four or five years or so now um it's written in a written enclosure um and it's its main cell is that it's a bi-temporal database um so it's got It's got time with its a time when it's very hard um and what what we essentially part of the reason for us building this um was that we we see so many and so many of our client use cases we see people trying to do the roll their own by temporality um whether it's um like sort of take tables with soft deletes um or tables with loads and loads of different time columns you're gonna have to step back and Define by temporality I probably Amanda yes yeah um so by temporaryity quite literally means two times and two time dimensions um you they're called valid time and transaction time and the names for those vary hugely across the um so like for valid time you might hear application Time Business Time domain as usual in the industry We can't agree on the names of these things um transaction times also called system time but so transaction time or system time um is when the system first under when the system first up sees the fact right um valid time is when that fact is actually applicable to your to your business to your uh to your application um so it enables things like um retroactive and what we call retroactive and proactive updates so retroactive being um I I understand that someone's changed their name um I've been informed after the fact that they in fact change their name when they got married last weekend right yeah I was like I'm overdue doing my business expenses at some point I will say I bought a laptop last month so we'll have the timestamp of now when I actually assert it and the timestamp is last month when it matters exactly yes exactly that um and then it allows you to ask questions either with or without Corrections so if I'm if I'm looking I mean one common use case we see for example this thing um things like Risk um and risk calculations and the like okay and if as in a lot of regulations I had to justify why I made a certain business decision or a certain trade or whatever it may be yeah one of the things I might say is that in hindsight that was a terrible decision I mean an absolutely terrible trade like why why on Earth did you do it it took you completely out of your risk profile yeah but one of the things you can say is actually based on the information I had at the time it was a reasonable decision because you go back without the corrections that you've seen later right yeah so what what did we know Tuesday at 4 pm without subsequent Corrections yeah so only consider it to you filtering for everything that had happened a month ago whether or not it was in the future or the past of that in logical business time right yes okay but then in other situations I might want I might want the exact price as on Tuesday or 4 pm as as we know it now right because we might have been back and corrected it and said right okay so you might Microsoft share prices whatever it is actually we made a mistake there or the system was delayed in getting that information to us um we now know that the price at that time was this um and so now I want the absolutely up to date information with the corrections as we best know it right now I in my dim and distant past I've worked on accounting systems and we did that you know we had like um I forget what again I forget what the names are but we had like an insertion time and uh business transaction time right yeah I have Evernote we're not moving the field forward um no right but but we did it in an Oracle database and it was just two columns so I think you have to justify where we need more than two columns in our familiar database right yeah so the the update especially when you go to buy temporality um the update procedures for that get quite hairy um and this and especially once you add on those those retroactive and proactive updates um so when you've got four columns um you as the developer then have to consider right okay so if I am going to make a retroactive update as of 4 pm last Tuesday I need to consider how many rows I need to add because I'm going to have to add row to that table because um you're gonna have to add adverse then essentially the new versions of the document and you're then going to have to consider um the what changes you make to the existing ones so I'm going to need to cap off um the current row um but also if I'm doing it by temporary I'm going to need to cap off cap off the system time um I'm then going to need to keep the record of what it was back then without Corrections and the record of what it was back then with corrections and that ends up being to maintain full by temporality that um ends up being quite a headache um the other thing that we bring to this is performance of course because if you are um if you are just doing uh comes in your own um in your own way um the database is won't necessarily be able to optimize the queries and so for example we put quite a lot of emphasis in making sure that as of now queries um which typically in a lot of systems represent the vast majority of um everyday queries we make sure as of now queries are correspondingly faster than maybe historical queries might be so we understand a bit more about the um the distribution of the data if you like okay yeah that makes sense it doesn't factor into like querying as well do you have anything like special operators for querying at particular points in time we do yes um so we're we're basing um at least in sort of XT um version two The Early Access that we released a few weeks ago um we're basing that very much on the SQL 2011 spec which covers an awful lot of ground here and for byte time priority really introduces yeah introduces a number of new syntactic structures which um aren't very well implemented across the industry as yet um it's taking the second class was it SQL 2011 what are we now 2023 it's taken us a while to catch up yeah yeah but the sequel spec it's not supposed to move fast a bit faster than that but yes go quiet quiet um so it does allow you for example to um when you're um when you're doing select from a table um it allows you to say from that table for system time as of and then you can give it a system we've then extended that for valid time as well um but you can also do sort of system time between or Valentine between um so give give me the the history of this entity um throughout 2022. um so between 1st of January and 31st of December including Corrections so Corrections depends on what you specify for system time right so if I if I want Corrections um I'll leave the system time as of now because I want to be the most up-to-date and what the system knows now if I don't want Corrections I'll go back in system time I can see accountants and Auditors loving this absolutely but the thing is they've known how to do this for centuries perhaps yeah yeah um they they've known I mean and they've certainly known about immutability yeah this whole thing around we don't we don't ever go back and correct the past we write a new we write a new version we write a correcting transaction um they've known about that for say way longer than I've been around me too I'm not that old um yeah so um what we're doing is sort of drawing on drawing on that kind of knowledge which um let's say that's it's about it's about time we did and especially now that um the the constraints have changed as well so certainly in the early days of relational SQL engines we we had very different reason industry had very different concerns and I wasn't around for that either by the way um we certainly have very very different constraints in terms of how um making best use of our storage um because storage was very expensive we had we had to make updates in place in order for it to um in order for it to not become crazy expensive whereas now um with storage especially remote storage um being a lot cheaper and a lot faster to access um the sorts of solutions we can consider um for for these kind of databases where where all of a sudden it does become an option to store literally everything to store your entire history yeah yeah there was a period in our history where you would update and throw away old financial data because you had 64 Meg of ram yeah right uh or sometimes like 64 Meg of disk if we're really going back um so you had to yeah we can make different design decisions now absolutely and we can I mean obviously we still prioritize keeping as much data as local as we can um so we'll um NXT we're looking to bring us bring as much data sort of into into into some CPU cash into memory into disk into something like redis and then only at the last stage do we go all the way out to the remote storage yeah um but again I think that's I think it's a very typical pattern anyway we're not we're not inventing anything new there okay so you're leading into uh you're leading into some gory details which I want to get into what's happening under the hood give me some technical uh facts about how you make this work so XT um both both in the in the version one that's out in and production at the moment um and the V2 with we're on the Early Access um it's based on the What's called the Inside Out architecture um which I first heard from uh taught by Martin clapman uh apologies if that may will not he may want to be the first person to have thought of it he's um I think I don't know either but he's widely recognized as giving the founding conference talk that made everybody start talking about it right yes yeah um and the inside out architecture says um that rather having that rather than having the log sort of ingrained within the database and being an internal implementation detail we make it front and center um we we very much have the the loggers the history of everything that's happened and then base our data store on that log um as a like a like a projection over um so your data becomes essentially a projection over that log yeah um and that's and that's so the event sourcing folks will find that very familiar no doubt yeah yeah so xxt hasn't really got into the event sourcing space yet um yeah but they'll they'll seem to be very very familiar with that yes no exactly um yeah definitely related to Kafka um and in fact um Kafka is our model for what we call um the the transaction block within um within XT when you say the model as in you've copied it or it's like you use it uh so the model implementation the the better implementation of the transaction blocks right okay so X XT is um more so in V1 is what we call unbundled um so you can bring certain components to the table um we ask you to provide a transaction log and an object store um so a transaction log has to be totally ordered um and all of the um all the clients have to but other consumers have to agree on the the order of the transactions that's what gives us the consistency over the um over the cluster right but then we also have a component called the object store um which as it sounds is I mean if you think S3 um or blob storage or whatever Google Cloud call it um it's called cloud storage isn't it whichever sort of um whichever Cloud you subscribe to yeah other um yeah other services may be available um so it's that kind of it's that kind of principle but for a project storage we're looking at being able to store Big Blocks of data um and and grab hold of them as necessary okay so you also like storing images fill movies that kind of thing happening so the the blobs is foreign right um and then and then it's up to us to then manager which which Pages we bring locally and which Pages get and which Pages have to say um so yeah the idea of the idea behind that is that we as XT don't then manage that um so we we delegate a lot of the hard a lot of the hard work to that yeah um I particularly particularly Kafka um and the and the total ordering and consistency between uh between clients um out of curiosity what are you totally ordering by which of your fields um so we're totally ordering a situate transaction time so it's a single writer um okay similar to um uh similar to the atomic idea okay so single writer single partition on Kafka and you're just building this big append only lock that's exactly right okay yeah yeah um yeah that's what that's so yeah no no consideration about politicians at least as at least as yet and so you say you're offloading a lot of the hard work but it sounds every database contains part of an operating system right and you're managing a page cache to disk so it's getting you close into like what operating systems do to manage levels of caching that must be a laugh it's quite naive as it stands okay we've we've got a lot of work to do in that area um before um before before we can read it so push me to that big time okay so is this largely considered to be like an analytics database rather than a transactional database uh we're calling it htap um so hybrid transaction analytical um okay so the the idea being there that um way too much time in our industry is spent in ETL land um and if we can get if we can get something that works reasonably enough for both um we'll be in a we'll be in a good shape and we can get we can get people building applications on top of this um without without having to go through a lot of that rigmarole um yeah so certainly there's there's a few of the um technology choices we've made a slightly sort of oriented towards the overlap side um and we're having to make the oltp side catch up a little bit at the moment indeed what I was working on before I came on this uh before I came on this podcast um how do we make that happen that gets into it what's it like being um you know because lots of us build like web apps right a lot of programmers are out there building some kind of application that faces eventually some kind of uh non-technical user and then excuse me you're working on like really core infrastructure that will eventually be used by developers to eventually do something for people that aren't technical at all so what's it like it's quite different um and certainly for me at least it took it it took a while to get used to um I think so for me so I mean the vast majority of my experience has been in exactly that it has been sort of web apps that's been in like talking to end users um and you I mean you've millions and chances are most people just be familiar with the kinds of processes that go on there um the kinds of cadences you get into when you're when you're developing um in terms of sort of milestones and releasing functionality and yeah and that kind of thing um there's a couple of things that are quite different about databases and obviously it's for us it's very much more about r d um so I think one of the big differences we see there is that we have very few estimates um in our planning in our planning processes um largely because of the r d r d nature of the work um and especially um in this last 18 months or so when we've been very much in a very much in a research phase um we're also focused a lot more on backwards compatibility um like I've um in in the sort of my early days of closure I wrote a few libraries um for the for the closure ecosystem and there you in library world you have to worry a lot more about backwards compatibility than you're doing with that world um and in database world it's worse yeah I can believe you've got to worry about not changing apis and they've already got this log of immutable data yes yeah no exactly yeah um and so there have been quite a few issues um in in XT certainly in the early days where we we really had to consider right what if people got serialized on disk yeah um and particularly when you're in the immutable world and when we're saying that this this transaction log is complete is completely immutable we're never going to go back and change that log um like whatever whatever structures are on there are on there and they're um and short of a migrate your entire log um which we've been tempted by once or twice um because we understand what impact that would have on our users yeah you've got you've got a live running system what you really don't want is your database like your database folks saying right so we're going to need to do now is to stop everything yeah my like pipe your log into something else a public transaction log into something else and then and then go again which ideally I mean if things are working the way they're supposed to it's a really large important log of like possibly financial data yes yeah yeah exactly that exactly so how do you deal with that how do you how I mean it sounds like your hands are very much tied how do you make progress um generally by being quite conservative about what we put on there in the first place right um so um there have been a few um there have been a few features certainly that we've um that we've considered and who've had to step away from because of um uh because of not wanting to change that transaction law um but also partly because um we um when we read that transaction off we then we then index it in a form that's more useful to us obviously you don't want to be playing through a transaction log every time you need to make a um can you find me the order with this ID queried right so we we put all of the we pull all the transaction data off there um and an index it and in version one it's all local inversion so that's a bit more it's a bit more shared between the different notes but that gives us an opportunity then to say right if we if we really do need to make bigger changes um that's our chance to um in in a in a reasonably backwards compatible way um so right what we're going to do we're going to change our indexing structure and so while your system is running live on like version M minus one um your system can carry on going and we'll index it into that into that format but you can bring up another XT node with a new version once that's caught up um with the with the index instruction in the new format um you can then sort them over into stuff at the green green blue diploid type way right yeah well but that's but that's a great thing we get out of this Inside Out architecture and we couldn't do that if the log wasn't the if the log wasn't the absolute golden store yeah yeah and it's also nice that you've got like within the mutable log most of the data's just sitting there guaranteed unchanging and there's just a new bit at the front to worry about yes so I imagine if it's anything like Kafka world you can do those in re-indexing upgrades and do nearly all the work as slowly as you like yeah yeah that's exactly that easier yeah okay um this once makes me want to circle around a bit to you say indexes makes me think what's it like as a developer using this database am I is it like a relational database and I'm creating my own custom indexes and stuff like that so um XT is a very much a scheme on this database um so we don't we don't require any upfront schema from user um and so even though it supports your supports now both data log and SQL um we we don't have to do any of the sort of the usual SQL ddl of create table or anything like that okay you're you're not restricted on what columns you put into the table um essentially you insert a document you insert a map of data the only thing we do ask for is an ID like give us an entity ID and we'll work with that that just gives us that that gives us the ability to keep track of an entity's changes over time because the ID Remains the ID remains constant yeah um so it's quite free and flexible in that in that regard um and then we then um we then do the best job we can with our with our indexes um to get you the the data you need um so we keep um a number of different um trees a number of a number of different trees um I say this um at the moment this it's in rocks um okay Rocks TV yeah yeah um and that that's great storing um sort of ordered trees and that gets us that gets us pretty decent performance okay um we're looking um we're looking at different structures for v2 V2 is a um a column the database based on apacheary way of thinking about how we're storing the data in um and also again coming coming back to what we're talking about earlier the constraints are a little bit different um all of a sudden the um the cost of scanning a lot of data from disk com comes down relative to um relative to sort of random accesses and so our query engine now is prioritizing those um over a lot of random accesses in some cases so for version two you've had to rewrite the query engine on top of everything else yes yeah that in itself is a lot of work I mean I'm just thinking of Oracle that's like it's it's almost like a historical Empire of Optimizer code right it's certainly a lot of Optimizer code like if you um we were looking around once um at the various job boards when we were looking to hire for um for XT and you look at the job for database engineers and they are nearly all you'll be working on query optimization [Laughter] by Far and Away the the biggest um the biggest thing people are looking for yeah I'm surprised I mean I know it's big but I wouldn't have thought it's like significantly the number one thing it certainly seemed to be in our very limited research okay yeah definitely Okay so I'm I'm trying to think this through now so inserting documents right is have you got this is it like if let me put it this way I create a user by inserting a new user document and it's got like their name and their age and their social security number and their address now I come back and I want to change their address can I just insert the delta or do I have to reinsert the whole record um so you can uh you can now um so we we do have sqls update DML um and and what we're essentially doing then on your behalf is grabbing the document and creating a new a new version of that document okay so under the hood you're you're writing a whole new you're like git right where it stores the the complete version of the file every time yes yeah okay that must be mixed because you've got a single writer so you then got the kind of operating system problem of managing access to that single writer so the um the operating system uh we we get that for free with the with the SQL partition from Kafka and so we don't have to do an awful lot of coordination we don't have to do any coordination between any um any threads or anything like that okay concurrent processes um and for for a lot of use cases that's that's absolutely fine okay let's talk about something that can be can be very quick these days yeah and very large and still be useful all right yeah yes yeah let's take a look at this from the other side then you've there you are optimizing different queries worrying about not changing data how do you get meaningful data sets to test against for a new database so there are a few industry benchmarks out there um that we uh that we use um the the main two that we that we tend to look at when we're doing um when we're looking at the impact of new changes is uh tpch which is quite common tpch so TPC TPC is the performance Consortium um they've got benchmarks like a through whatever um I've got no idea um how far they've got these days um but H is a is an olap benchmark okay um and it's it's based around um a fairly a fairly typical use case of customers orders products line items and suppliers and pretty much any if you if you're running a if you're running a business of that kind of nature it's it's all it's all of the analytical and bi-like queries that you um that you can imagine oh okay um and you can run that at different scale factors um so for example we run it at quite a small scale factor to have a um a rough idea of the um of the of the impact of a change um but then you can scale it up and run it on a larger on a larger scale factor um for example when you're doing a new release or you're really looking at a change that's going to heavily affect performance at largest gains okay that's interesting there's also similar ltp benchmarks as well right yeah someone who builds demos having access to a data set like that I should store that away mentally for future you mentioned the word of the industry scale what how what's the scaling story you're a single writer so you're limited on rights which is scaling for reads yeah um so let's go England reads is that um you can you can scale reads horizontally um so if you need um if you do need more read scaling then you add a new XDP XT node um it brings it brings itself up um and then you start querying against the shared Object Store um in V2 so it will pull down what it needs from the um from the shared object store and then and then get going okay um now because our transactions are entirely deterministic um we know that the the states on each of the notes is going to be consistent and that's that's a big simplification for us like we don't we don't need any coordination or anything like that between the notes um because we we trust that they're going to end up at the uh the same state at the end oh right they may not necessarily be in sync that perfectly they may not be in sync um so what um what you have to do in that case um is that each again again I'm talking um talking the V2 here um each client keeps track of the last transaction that it wrote and at the very least it will give you that Trend and the the world as of that transaction so that that enables that enables you to read your rights yeah um if it's got further than that that's great um yeah yeah you can you can at least put a document into the database and then the next the next query you you make will read out so you have been thinking like um like my University Professor is going to be very unhappy with me but the name for those like isolation levels in database design yes yeah okay that must be fun so in that case I mean the the single writer again gets us a long way here um so in in terms of the because the the reason the rights are separated um on the on the right side of things um you obviously submit the transaction to Kafka it comes back around through the classical pipeline but then because you've got this um the single right at the head of the queue we actually work at a strict serializable level um which is the um the the the top level that you can get on the on the brighter side yeah like yeah every every transaction sees every is guaranteed to see every transaction before it um and and that choice is naturally serializable because it's a single like a single writer yeah things get a lot easier when you don't have concurrent rights yeah okay um but you think about the amount of locking code that we also don't have to do I don't have to consider either yeah yeah yeah Road locking and that isn't the thing um uh um we don't we don't uh we don't at least yet have interactive transactions so it's not it's not like you can you can then read and then um write based on that um based on that read so you don't you don't get sort of um you don't get people accidentally locking a table or anything like that um this is the thing I thought like off the back of Martin clepman again if you start with this transaction log then you're basically building estate machines on top of that transaction log and and like um SQL database like postgres or Oracle is a really really clever fancy State machine to allow these things but do we need as sophisticated a state machine is that for all uh transaction log processing tasks a very good question I mean I think we're obviously a little bit biased [Laughter] quite biased on that one so do you ever get like different um people using the same transaction log that you're using for your bi-temporal view of it people reuse that same underlying transaction log for different purposes ever um I'm I'm not aware of people um using our transaction log um I mean the the the the format on there while it while it's an open format is probably a little bit gnarly for people to be okay honest um I think with I don't know that's a line I'll tell you what um because as part of the world we we provide it um so it's it's a half-life and we we provide a leucine module um for for XT then that reads off the same um that reads off the same transaction log um and there are there are internal apis if people do want to go diving down that don't do give them that access to the the events coming through the events coming through the system okay what's the leucine API get used for I mean what do people say it's just like free text search in your transactions uh yes yeah no exactly exactly that um so yeah if you're um uh yeah I mean I think all the usual use cases for um for for leucine really um we're we do have the opposite in fact um where we do have the ability to um hook XT into someone else's transaction log and we've and we've done this um we've done we did this for a client who were using quarter and the quarter blockchain oh so they they had a I would say the the b word came up yeah um I can see why they want I mean they've got a mutable log and they probably need analytics on it yeah I can see this so they already have the data in that format um what what they want is a way to query that um yeah using using xd's by temporality um and so we we wrote the middle module um that put the two together and so they they kept they call they kept they called a source of Truth um but they were able to then run run XT queries over oh I can see that being really popular in the blockchain world without um without declaring for or against blockchain Technologies I can see decent analysis over those blockchains as a service being quite popular right yes yeah well I guess it's the same principle isn't it it's a it's a look at the heart of the system yeah yeah so yeah there's there's quite I can see quite a lot of overlap there that takes us to the question the 64 000 question for a small company building a database who's using it and for what um so we're seeing quite a lot of users um across across various different Industries um obviously um obviously we see quite a lot of it in financial Industries um as we were talking about earlier I think the um the kind of the natural tendencies in that industry both the um no no whatever happened at a certain time and it's especially with the kinds of regulations that are coming through um that are really forcing people to to justify what they what they knew and when yeah and that that kind of thing so we see an awful lot of we see an awful lot of usage in those kind of areas but to be honest it varies um it varies quite widely um like any um anything where like time is of the time is of the essence if you like um so um we see for example in PRI um in pricing systems in product pricing systems um so in one case in particular um that jockster's worked on with quite closely um we've um the the company like to schedule price changes and they can do that with a bisexual system because you can you can say I want I want this product to have this price as of next Tuesday yes yeah um so any kind of scheduling or CMS or those kind of systems use the other the other side of my temporality if you like yeah writing into the future which is a largely unexplored field right yes yeah yeah yeah yeah it does it is that reliable is it is the developer experience such that you're not going to accidentally write software that pulls from the future in in what ways are you I'm just thinking like you've got all this flexibility to make that query how easy is it to ensure that you do the right thing in most cases so our defaults and make sure that you that um the default is always as of now um so you you only ever see FM if you can if you can imagine a nice big sort of 2D graph of sort of History going through in both dimensions we we limit you to the Y equals X the diagonal you know this is an audio podcast right well yeah okay so you can't see me waving my hands and sort of hand wave the explanation of any of the people listening to this on like Spotify and apple podcast can't even see your resplendent beard James oh they're missing out they're missing out um yes um in which case without without the visual matter for them in in a lot of cases because because it's what sort of traditional relational SQL databases do um we we make sure that the default is as of now um both in what we currently know and of and what we currently know about the current time right so transaction time and valid time um you have to explicitly ask for a cross-time queries that that's what I was getting at so the default Behavior matches your expectations of how things generally work principle of least surprise they call it absolutely yeah yeah absolutely okay so I think I have two more big questions to ask you and I think they're slightly controversial all right but I have to ask them um why why build a database in closure so I think for us um I mean I mean juxt is a closure company um and we're very we're very much sold on the um on the ideas behind closure um especially as the um so building an immutable schemeless Dynamic data uh database um seem to go quite hand in hand with an immutable schema-less Dynamic language yeah so for us it was a good fit in that sense um we've also obviously got quite a lot of um experience with the with the closure industry as well so there was quite good there was quite good pairing there we do of course find that the um the more sort of the the more performant areas of the code we do um and especially the more sort of a stateful mutable um ugly code that you tend to want to hide away um yeah that is being written more and more in in Java now um okay just because there were certain areas where we found that we were writing closures if it were Java for the for the mutable performance but this is as um as our Lord and savior Rich says um Rich hickey creative closure yes um he says it's um yeah I think he's done a couple of talks now where he said that as long as the ex as long as the exterior in the system looks immutable and behaves immutably um what you do below the surface um if if there's a if the tree is being mutably hacked down in the forest um as long as the exterior is behaving beautifully it gives you those guarantees um that that's that's okay okay so you're you're happily enclosure in The Logical world but under the covers I don't want to say slumming it with Java you're um I can't think of the right way to say that isn't going to offend someone so I'll just drop it hey it's it's it's getting better these days it really is yeah they've learned a lot from the jvm languages I think they got a bit I don't want to say complacent but um what they just they they lost momentum yes in the Java world and then suddenly maybe closure definitely Scala since then made them get their act together and that's very hard to go from a language that's lost momentum to getting it back again but hacked it to them they really have yeah definitely okay the other thing I'd say about pleasure is um especially for a research project um we find we've been able to move a lot quicker um so for the if you think about the sort of make it work make it pretty make it fast yeah certainly for the make it work and we've found that we've been able to do that phase very much quicker from closure in its interactive development and the fast turnaround times so the the experimentation side of things like what happens if I design a system in this way um yeah yeah closure could be a great language when you have no idea what you're doing which is oh yeah right right and it happens just however maybe more so I can believe yeah yeah because your explore especially if you're writing a new database where you're having to explore entirely new design decisions yes yeah definitely um um yeah and and I mean for us at least in the early days when we were figuring out how to best use apacheary um having something that we could that we could really sort of poke it poke it with and see what it did um you have to be quite it's quite strict with you about your memory management in the patio it's very sort of manual memory management type this is an aside that maybe we'll save for the DVD bonus features but tell me a bit more about Apache era um so it's a column the data format um so it's been pioneered by uh Pioneer by Apache and being used in a number of different companies in Industry um but one of one of its main benefits is that um the on disk Beyond disk form has exactly the same as the in-memory format so there's no serialization of deserialization um if you want to if you want to for example read an arrow file a memory map is a great way to do that okay because there's no trans there's no say for example you were writing it files in um in Json or whatever have you you'd need to translate that into into whatever objects that you've got um whatever objects that you're working with um or Maps if you're in the closure world yeah whereas with with arrow there's none of that translation happening um so you you're you're literally reading bytes um and what are you getting back do you spend a lot of your development time great um deserializing byte strings or is it just just pop off disk looking like a closure map because that's what you wrote um certainly for The Primitives um so it'll it'll pop off this looking like doubles and Longs and okay that kind of thing um maps and other composite structures and maps maps and lists predominantly in Arrow um are stored in a column in a way so for example when you've got a map of Like A and B Keys um the the arrow format will store all the A's in a row sorry all the A's in the column and then all the B's in a column um and so you you end up particularly if those are fixed width so particularly if they are sort of norms or doubles or the like you end up being able to navigate like straight to the um straight to the value you're looking for okay and that I'm guessing that works out super fast if you want specific Fields or you want to aggregate specific Fields but the trade-off is you lose getting the whole object with all of its fields and we've had to put a little bit of thought into how we do things like select star yeah okay so last controversial Choice um I know xtd xtdb supports two different query languages it does yes tell me about that so from the from the early days of XT um we very much went with with data log um again heavily inspired by the atomic I don't think that's any that's any Secret um and I think for for us in the for us in the closure industry I think there's always been a little bit of that love for data log um it's very much of a data oriented query language um it feels a lot more sort of declarative in the way that you're you're asking for what you want rather than necessarily how you want to um for those that don't know because I've worked a little bit with data log but for those that don't know describe it so um data log is essentially um is a language that works it's it's a logical language um it's a it's a substance it's a subset of prologue although I guess if um you bind different variables um to values coming out of your documents um so for example if I'm joining customers on toward us I'll make two decorations I'll say um that a customer has a customer ID of my customer ID and then I'll say that my order also has a customer ID of that order ID and what the what the data log engine is then doing is saying right okay I can see customer ID twice here I'm going to make sure I'm going to unify these two and that essentially is an implicit join right um and so you can you can treat them you can you can very much sort of within your query you can very much see right okay so here are the things that I need here are the things that I'm joining on um and I get a bit more of a declaration of sort of when I am when I Traverse My Graph if you like if because you can you can kind of think of customers orders line items as a bit of a as a bit of a graph database and at times we have called XT of graph database oh have you for that for that very reason yeah you can think about it in in a graph like way a graph of documents um what is that going with that um so yeah when you when you're writing the query you are writing it's almost like a graph traversal you're you're saying right stop like find me this customer node and then from this customer node navigate out to the order node and navigate from the order to its individual line items and the query the query actually looks like that to work with as well so it's data rather than a string so anyone who's I think anyone ever works with a SQL has probably had to generate SQL at some point in the past and has um sort of got in a bit of a tangler but how many ends do I need in my where Clause when I'm mad you know what I mean you can't really the thing I my favorite feature of data log is you can start because it's a data structure rather than a string you can start to compose things right you can say here's two extra Clauses that I want to mix in with this query yeah without having to like string edit where the and is in my where clause um and all of the uh and all of the SQL injection that follows no doubt oh yeah yeah um but what we've done recently so we we obviously love closure and I think the I'm sorry we obviously love datalog and I think the closure industry um obviously those um those data log as well um but but we've recognized that that love's Not Universal we recognize that it's a hell of a niche and and that you're not you're not gonna get even if even if you the development team um are fully bought into this um you're not you're not going to convince people outside of that um that they they should cast aside all of their SQL experience and tooling and everything else that they've um they've gotten used to about the about the SQL world so that's that's one of the reasons why we really wanted to make SQL um a first class citizen as well um and so what we've ended up building is a database where you can query the same data with both datalog and SQL um and roughly equivalent datalog and SQL as well so you can you can look at a data or query in a SQL query side by side assess their their equivalent queries and they'll return you the same data can retain the same results so I think we think that's we think that's fantastically powerful I think on feature parity is one more powerful than the other and they're not far off you know um so we we've had to put a fair bit more work into sequel um data log um particularly in terms of its scoping rules um it's quite a lot of a simpler language um but what we what we do is we compile both of them down to an intermediate representation we compile both of them down to work all of the what we call a logical plan right um which is essentially relational algebra that old thing your University Professor must be very proud of you oh yes yeah might not have been proud of how much I remembered when I first started on that but at least the yeah that the um the remembering that they existed was certainly a very good start yeah um basically isn't that all we're ever doing so remembering that something exists enough to go Google it yeah sometimes the hardest problem is discovering the bits that you don't know that's why this podcast exists but no relational trip was fantastic um I love it um and I mean it's it's obviously the underpinnings of underpinnings of SQL um so SQL is very much very much based on that um but the composibility of relational algebra that you really can um compose those queries together and we're looking to get back to that um with um with datalog so are you hoping secretly that those people that start off with SQL will gradually be tempted to your way of doing things you can cut that out of the podcast right don't tell anyone yeah yeah we'll leave that in The Cutting Room floor honestly if you're hearing this at home I have betrayed James and he's never speaking [Laughter] no to be honest I mean we're the it very much was the tooling of the secret SQL ecosystem because there's just so much of it with the best will in the world We're Not Gonna We're Not Gonna compete with with that in in the closure industry yeah I'm inclined to think that if you're trying to do a new way of doing databases that is one front on which to change the world and that's plenty yes yeah yeah you have to be a little bit sort of conservative about that but that particular budget only I mean yeah yeah absolutely yeah so you said what's the phrase but SQL reaches data log rocks but SQL reaches love it it's a to steal a phrase there yeah I can predict that at some point in the future your team will have that on a t-shirt at a conference yeah so you said you've just put version two in like was it preview release or earlier it's very much Early Access at the moment um so we're we're in we're in listening mode and so John our CEO um announced um announced the V2 Early Access at closure conch which is a few weeks ago over in them over in North Carolina um and so the the idea behind this um is to get people to have a bit of a play with it try it out um let us know what you think um let us know of any big sampling blocks you you come across um over time and we'll be we'll be moving through the the traditional sort of Alpha Beta RC and and stable release okay so I I think it's vertical at pre-alpha right now if you're not if you're not comfortable with the bleeding edge it's probably not for you just yet but where do I go is it fun to play with if I want to just kick the tie as an experiment absolutely um so we've um you can go to xddb.com V2 um and all the all the um all the instructions about how to get started and write your write your biochemical queries will be on there okay I'm gonna give it a go it sounds like fun and maybe I'll finally get the accounting system that will make my taxes easy at the end of the year you've got to write on the tax rules yourself don't bundle those in I hear the government's going to simplify them any day now I won't worry yeah I'm sure James is ever a pleasure to talk to you um good luck with the path to um official final release of version two cheers Chris cheers thank you James if you'd like to take xtdb for a test drive if you want to explore by temporality or data log or anything like that there's a link to the project in the show notes and if you do please drop them a line if you've got any feedback I know James would appreciate it I appreciate feedback too so if you've enjoyed this episode please take a moment to like it or rate it or share it or review it or subscribe to it or all those different feedbacky things it always helps and it's always interesting to hear or just drop me a line my contact details are in the show Notes too for Twitter and Linkedin and the usual and while I'm thinking about it we're going to continue to explore different kinds of database on this podcast so if you've got any suggestions or requests let me know I know I'm planning to do Vector databases soon that one interests me so that will be coming up but I think that's all for this week so I've been your host Chris Jenkins this has been developer voices with James Henderson thanks for listening [Music]