okay so uh thanks everybody for uh uh coming to this talk so i will be uh with denise jaroszewski uh presenting uh this talk about how to deal with uh cmd programming in c plus plus 20 and trying to introduce novel ideas and tools for for doing so uh for people following at homes uh you will be able to grab the slide on this tiny url link if you want to follow along or access to the code and so on so uh what is this all about uh let's start this uh talk a bit like you know like an elevator pitch okay uh what what i am trying to speak about what's the context of our work uh within this uh cmd things uh let's say you want to do some computation like you want to uh you need to quickly find values uh in a bunch of bytes like a thousand bytes array of is a char short or integral or whatnot and you want to do it uh as fast as you can um first uh before you're going fast let's let's do it correctly and try to see how fast i can go using a good old standard algorithm find or find if and you end up with this kind of performance graph so uh time is in nanoseconds over there you have your different types and as you see the bigger the type the best uh best is the best performance comes so if you look at integers i would like something like 72 nanoseconds compared to the uh 200 40 something for char but the question is can i actually do something better because maybe the compiler knows how to do this kind of operation maybe you can optimize things uh the fact is actually uh you can do a lot better you can do a lot lot better because currently if you if you're using the tools we are going to introduce uh you can actually vectorize this find operation and uh you end up having a speed up of around 10 for integers a bit less um around how much is that 60 something for four shots and uh basically 32 charge so you can go far far more faster but the question is it's faster but is it actually the best we can okay so let's say you actually find you try to find zero in this large amount of bytes uh another way to find zero in in a bunch of bytes is to actually call stalin which is basically this you are looking for the zero at the end of the string and then you find it um sterling is evenly and manually optimized uh in most of the uh instead of library and this is the speed of an actual stalin it's basically eight something nanoseconds which is roughly what we got so we actually go at the speed of stalin except uh we have a function code that looks like a standard algorithm uh function call and it is still optimized but you may say yeah but you know fine actually you just run over the data it's trivial yeah okay let's do something less trivial like an inclusive scan again you are doing this partial sum over integers still again 101 1000 bytes total volume of data and we've got to get this kind of graph where uh you will go from 70 or almost up to 24 205 for char and again you can actually uh vectorize that using our tools and you will end up with this kind of graph where basically we go twice faster four inch up to uh which is that four times faster a bit less than four times faster so the speed up is less impressive than before because the operation is more complex but we're still beating uh the uh standard code which means that basically the compiler is doing nothing of those complex operations and the auto vectorizers just don't work okay but maybe i can actually do even better what about a very complex operation like remove okay maybe if you if you look at it from afar you can say yeah it's not something that i can't vectorize actually because you know you are moving pieces apart to the end of the uh of the container so there is nothing that you can actually do in parallel okay um and when you look at the performance for uh remove the interesting part is that you want to plot the performance with respect to the percentage of value you want to actually remove and what you see is that if you remove nothing or everything you go faster that you if you remove any intermediate percentage because in the middle of this graph you are trashing your branch predictor and every move and if is basically reducing the uh performance and the worst case scenario is at exactly 50 where you you got like 25 000 nanoseconds for char down to 1470 something for it so let's focus on char so this shape is basically the effect of the branch door and one way to do that is that if you can actually vectorize it you will remove the branch and that's exactly what we do and we can actually vectorize remove which led us to in the worst case for us a speedup of two and something okay or four in this case and for the worst case we go down from 25 000 down to 1 000 which is 25 times speeder and the same will apply with different values so it's rather 10 or 12 moments there to all the types worst case being of course him because we have this less interesting shape there but we go from roughly 10 to win to uh four times uh three times sorry at a speeder so even a free move if if you have the proper tools that are what we want to actually show there you can actually vectorize those operations so uh what i want to speak about this in this talk is how we went there what kind of operation and tools we put up to uh to do this and what we can do to go further with this kind of library so um as you may have guessed already what we'll be speaking about is eve which is our uh new tool eve is a c plus plus 20 a cmd library and maybe some of you need to actually be reminded what's a side descent for um if you take a regular normal ancient cpu the model you can have of its operation is that you get a stream of instruction and each instruction will be applied to one value which is usually stored in a register the instruction is decoded it's applied to the data and you get a result and every clock cycle you will get one instruction fed in and one result pushed out and what is sim design well this model is what we call the single solution single data model because we have one stream of instruction with one screen of data producing one stream of output so m in the cmd obviously stands for multiple it's now the single instruction multiple data model we still have this single stream of instruction at one point and on the other side we are working on multiple data at the time cmd computation in general is far more complex than that what we usually uh do in regular cpu is that those data block are stored into what we call a wide register it's it's a register with a fixed size like 128 bits up to 512 bits and you fit some amount of data into this large resistance so in this example we have four data in each registers so every clock cycle you would process one instruction over those four data and produce four results the intuition is that if everything else is correct in terms of performance you should get the speed up uh which is roughly around the uh size of these white vectors and the issue is that usually when you want to do this uh it's a bit of a mess just because you have like a lot of different cds systems if you if you just look at x86 it's already a lot it's probably a dozen or more now of variance of the same generation set with different size 1228 256 712 and different level of features and supports uh and if you want to cry a bit you can look at all the operations that are sitting inside abx-512 which is as big as as all the others combined so it's a lot of things to process and if you get even worse because other architectures has different solution set with different supports and different features well so probably what people do usually is that they just pick one architectures because working by end on multiple of them is very complicated but even if you say i would just deal with x86 the question about which version of x86 cmd i need to use is actually complicated to answer because if you look at some benchmarks you go back to this remove functions okay we remember that we have this old scale of versions we have three different x86 versions three different instruction sets ssc2 there avx and sse4 and we see that we have different level of optimization and speed up and it can range from you'll see uh basically where is it there i mean uh times two two times four so it's it's it's important to know which one uh of those institutions that you want to target the size the number of features and so on and so forth the reason why scc2 is behaving strangely compared to the other one that it lacks some operations that ssc 4 and avx-2 provides and then the change in the performances okay but you know i'm writing code and you are telling me that there is a special instruction inside the processor maybe you know like somebody already take care of that yeah maybe let's see what already exists uh first intuition we are dealing with special uh cpu institution sets maybe the compiler can do it it's like it's jobs you know you you input code and you get instructions uh most compilers uh now uh provides uh what's called an auto vectorization path uh at high level of optimization and uh well if your code is simple enough like it looks like a transform or transformer use and you you use classical types like eat or float or double and you don't call fancy function uh it will probably do a good job or even a great job so good but what if you you're not there i mean i don't know right you want to do the sum of the inverse square root well such to be you it won't get automatic okay maybe i can actually ask for special treatment maybe there is fragments or special compilers i can use openmp as a primary science that you can use and it tries to direct the rights but you get your at your loop codes and you have special compiler like ispc but again if you don't fit into the model of the pragma or the compiler's programming model you're stuck okay but maybe there is something into the standard library so there is a sec execution policy in the standard library that is supposed to uh trigger automatization but as we see uh it kind of fades uh you have other libraries like hpx are trying to fit uh this uh this to fit this gap fill this gap but still again it's mostly uh either best effort or quality of implementation of the compiler sometimes you are actually happy because someone actually made specialized tools for exactly your use case maybe you are doing i don't know jesus passing and you can use cbd season that will speed up your cheese on passing things maybe you do image processing and the light is probably a good good thing to try but sometimes you won't find anything and what's left well you can actually write everything by hand and uh to have done it quite a few times you don't really want to do that the code is obscure as a function and infinite names are completely mind-boggling and the code the semantic of the algorithm will be lost and all these architectural operations so it's it's not easy so what we want to do is provide a way to simplify that or at least make it to make it uh usable by a regular developer so it enters eve the exclusive velocity enjoy which is as i say the super specificity library that wraps all those cbd nonsense uh by doing multiple things it provides a library of chord types that will help you have a regular value semantic types of wrappings or switches or some others like the value registers and logical registers and all the helper types you need to make those works there's a bunch of algorithms in the sense of the standard library and the interesting project is just not just already made algorithms it's also algorithm building blocks so if you want to slightly change what the algorithm does from within you can actually write your own and we have a lot of numerical function ranging from simple operators to c mat like operation to special function polynomials and so on so you can actually already uh write complex math with that uh we support uh only 66 flavors and 64 bits and now 32 bits arm and by support we mean that it's evenly tested and maintained we have a partial support which means the code exists but the tests are less so precise for power pcos and it's a mit license so you are pretty much free to do anything you want with that send us a postcard i will be happy uh how does it work what what what was actually required you could actually use any uh c plus 20 compliant um compilers we are quite pushing the envelope so it has to be quite the latest right now clan gcc latest version uh so it's probably now uh gcc 11 something and train 14 if i'm not mistaken um it will be this way moving with the latest version up to the point we can actually use modules which will basically uh set the things down there is a no too few supports from msdc right now we are working on it uh msbc clan starts to want to cooperate a bit more than the regular msvc but it's still a lot of fighting the compilers inadequacies but it's something we are thinking about so how does it looks now uh let's say you have this piece of code so you will you will use this wide type which is our main cd type wrapper so this is a wider float you can fill it with flow so you can either load it from memory or you can fill it with a constant or you can fill it with a lambda function that will compute every element in the lane of the registers um well you can then i don't know like for example you can print them on the standard output and you can apply operators on them and call functions i will go back on that later and you get things like this the actual cmd institution set used is designed at compile time there is no runtime dispatch there we have tools for doing it but it's not done this way by default which means that you have to choose which version of the cdn solution set you want to compare with and the result will change but as you see there is no trace of the actual architectures anywhere in the code it's completely agnostic of the size of the wide or the actual support of the architectures for a given function this we take care of and so for example there we are compiling for ssc 4.2 as we see there uh we print the x and y vectors and we print the result of this cross phase operation so ssc provides 128 bits register so we have four elements in this register compared to the avx-2 version which is twice bigger so we have twice many um values in the registers and the values go forth uh you may be uh curious about this notation so cos is a function no in fact trust is not a function class in eve is like every function a terrible object and we decided that as they are object maybe we can do something fine with it which is actually to um well uh provide a transformation on the object so a quarter circle is what we call a decorator and we will we will see what's going on with that right after this this quarter circle is actually another function that will transform the semantic of course instead of doing cos a given way it will change either the precision or the speed or the input range of a function what does quater circle does well computing a cosinus in a same d mode is a bit obligated there is no such thing as vectorized costs so you need to compute it using math uh basically we do uh we do some polynomial information to approximate the cosinus and uh to do so to do a proper efficient polynomial you need to reduce uh the input because it's a periodic function so you don't care about crossing use of ten thousands uh what you are currently curious about is consider yourself something between i don't know some fraction of pi you know but if you knew already that all the input you gave to your customers function is in a given quadrant of the circle maybe you can go faster because maybe you can simplify the reduction function so the question is what should cost does should it do the complex slow things the less complex and faster things are the very fast but very complete things and you cannot choose as a library developer so what we decided to do is to provide way through the decorators for people to choose the traders they want to pay so what does quarter circle of course means means that i imbuing the quarter circle range reduction semantic two cos that means that now this object quarter circle of course is computing the cosine of x only if x is between minus p over four p over four the first quadrant of the circle if you are outside that it will just return now because it doesn't care and if you do this you are actually in what exactly the polynomial uh polynomial expansion of the cosine one so we just computing yeah multiply additions multiply additions but maybe you want to be to do something a bit bigger maybe you want to handle anything between uh pi over five pi over two and minus pi over two so you can use half circles and we just do that so the computation is going on and you will get a slightly longer code because we need to do a simple reduction and then you end up with those mla uh polynomial evaluation and of course you can ask for full circle which is a complete between minus p and plus p and then you get a lot even larger code which is a bit slower okay but what happen if i just do that then because that's probably what you want to do and in the first place okay well you will get a quite large crossiness because what we'll be trying to do is look at all your values try to find if all your values fit into a given quadrant or coupled quadrant and you say all fits there we call the fast version of the function and if not we will compute every pieces with a larger algorithm and we will merge the results so in error case it's correct but you have the control over the speed and the precision of what you are doing other the characters include uh stuff like raw or pedantics that will say for raw i want to go as fast as possible and i don't care about the precision i can lose and penetrate is the other way around you will complete slower but with extra accuracy or extra care for corner cases so that's one interesting features we have so as i say ev is based uh is built actually as a similar strategy library so let's let's have a look at what's going on inside the main issue the main features of c plus 20 we are using are uh two folds the actual shape is through 20 features which is concepts on one side and on the other side which is more like a 17 20 thing which is if contextual and all the extra features on concepts for evaluation so we use concept to trigger uh and triage uh the selection of a given function implementation based on which kind of assembly extension check uh you are using at the moment so this apps function will only be picked up if you are accompanying for x86 so we we already owe me on the other given implementation then we use other concepts to say that okay i need to get this type to be an actual scalar value and not something else okay so you can actually have uh you know that you are dealing with integers or floating points and once we selected that inside those functions what we do is that we take these types okay just switches register type and we we compute something that we call a category that will tell me exactly what kind of elements are inside this register how many elements uh what kind of basic types and properties like that that will help us do this if context per web of selection between okay is it is it an unsigned value because if it's unsigned i don't have anything to do if it's a special types with a special size that i know about and i have an intrinsic i will just call it and if i can't maybe i have a special formula for larger cases sometimes i can't do anything so i will just call map which will do every operation piecewise and sometimes i may have i may have an optimization but not all the time maybe i need to be in a given uh subset of instruction so we can actually if cost expert check that the current institution that we are using is at least or under this one and then we can select the proper implementation and as we see there we got all the proper optimization possible for this function and all functional bitly this way find the proper concept that selects the correct architectures then use categorize to know which kind of optimization i may be able to do and this helps us actually be sure that we do as a correction at each time for each types each size each architecture i will now pass back to dennis that will speak about how and when to use our algorithms yes hi everybody uh okay with this we're going slightly faster to talk about the inaugurations uh at the time of um creating the slide deck this is the algorithms we had right we had all of any of none of uh all kinds of fines equal mismatch uh transforming place transform to so if you look at the standard right we only have transform uh that accepts an output uh iterator right but um if we know that that we're going to write to the same place we're reading chrome we can be slightly more efficient so this is why we have two versions same goes for uh not reduce uh inclusive scanning plays inclusive scan 2 same idea as those transform uh just if you are in place we can do it slightly better and finally we have remove remove if it has a caveat and i didn't fix the caddy at the end so that two platforms like the two platforms i didn't do yet right i know how just didn't finish okay so let's have a look at uh my first example like it's a very basic we're going to find the negative number in a vector right this is how it looks we call find if or it was a vector we're passive predicate right the first thing to note here is well hopefully this makes sense right but we are passing a vector and not a iterated pair all of the algorithms that we do are range based and the reason is that sometimes a range knows a little bit more about the underlying data than the iterator would for example it can knows it's underlying data is aligned or something like that so this is why everything is range based and the second thing we can see here is it yes we have well this is the main loop we have vector instructions good stuff this is actually almost what we showed in the beginning in the benchmarks uh that was just finding is zero and not less than zero okay uh there was a lot of out on previous slides let's put some types in all right we return vector cost iterator no surprises here uh internally we will go to pointers just because we cannot really do cindy with vector iterators but then we'll just compute use the type you expect and every single bill right um the second thing to note here is the types of the predicate right we accept a wide of end right uh which israel mentioned our obstruction on top of the register so on my machines this will be eight integers uh well why is this interesting it's interesting because in many cng libraries uh you will see people trying to use templates to account for both scalar and cmd code right and so you have a cleanup that is in scalar and you have cmd code to do the main loop oh we find it is difficult to write uh you need to do you know two versions of the same function or you need to do some sort of tricky templates instead we just always accept the cmg register and we have a way to deal with the cleanup part that i'll show you at some point uh a second thing to note here is that this less returns that's not a boolean but it returns us a logical of vector of failures so this is equivalent for my machine will be of eight boolean values for integers um yes okay all the operators overloaded to work like that uh it's maybe you're really opposed to operator overloading but this is really common for cmd code people do it like that and it works okay last thing i'm going to show you here is again this main loop all right what do we see here we see that we load four registers and then do some operations between them right the reason we load four registers is because the find if we'll unroll the code for you because this is very beneficial to sim decode to do unrolling and this is done by the library and not by the compiler however it can be a problem if let's say your predicate is complicated so let's say we have some very complicated predicates if we use if uh or red function which converts a floating point number into uh a rational number like a tens and huge that was rational but uh you know what i mean like and it returns you if the denominator is bigger than seven it's a bit like the patient example but whatever the point is that this conversion to uh rational uh number is expensive and so as a result you get a gigantic assembly over here right because we were going to try to unroll it without any actual win so we can tweak it a little bit we can say uh if i'll go uh i'm sorry let's look at the number of instructions just to uh just remember so this is what 700 instructions okay now let's do if i'll go no aligning we will not be benefiting in any way from i'll try to align our accesses and if i'll go let's say unroll one right to disable all unrolling and since we compile right we get to 189 like which i presume should give you the same speed okay with this i'm going to assume that we're done with find should just make sense just works now let's look at our next algorithm which is mismatch if you look at standard mismatch it is a separate algorithm from point uh there is going to be a separate loop that goes over to arrays and compares elements however we really wanted to be fined because writing just a basic for each loop in cmd is fairly complicated this is how we pull it off let's say we have two vectors for simplicity of integers right and i have two iterators you know pointing into one in the first array one in the second array i can load the same d register from each one of them it's fine it will work and but then i have to write a separate loop so instead of it we will introduce an abstraction called zip it is going to represent a special iterator right as that when loaded returns you both of these registers in a single object and then we can just go find others on the zip as and actually we decided to call this object that consists of two registers and also a white only of tuple of indian because this is instance is why it's tuple of indeed akumi is our implementation that is like standard but better right oh why does this make sense why does it make sense to call this white well it behaves a lot like a wide of just a scalar ranges uh just a scalar type like a white of in uh only with a different scale type so i can do equality works fine i can move elements around in it as if i move pairs of integers around it and it works fine and so a lot of our things just work it's very nice now let's have a look at an interface of mismatch because we have a zip we have slightly different interfaces of standard ones this is standard mismatch it accepts a range as pair of iterators and second range as a one iterator and the predicate the saturated quality and returns you a pair however we have a zip iterator and a zipper iterator is a much better abstraction than a pair of two iterators so we will return a zip iterator another thing that yeah we are range based so we will accept two things that together zip to a range right and this is slightly more powerful than uh just accepting a first you know range and then an iterator because you can pass here an iterator in the range a range in an iterator or two ranges presuming that the same size but actually it makes sometimes it makes also sense to pass in a pre-zipped range right so he passes a zip over two ranges it's called zip french pair and we just accept as a fresh pair and uh a predicate and we're joined as a iterator now let's see how we can use this through let's say robin mcd like this is standard main scene b uh is that interface to like mcps it looks like standard you accept two uh you know by bytes of this size and you need to compare them as they say are you in eights and then you return uh negative numbers the first one is less and the positive number of the second one is less okay uh so how can we do it well first of all we're going to convert them to you and aids right uh then we're going to create a use our one of our adapters and helpers we have called as as range so we will create a range of this uh from the first um you know from the first range uh then we're gonna zip it with the second one and finally we'll just call mismatch right uh this iterator uh this is johnson's zip iterator and as you'd expect like you know if the zip iterator equals to the end uh then you know we didn't have any mismatches uh this is just going to be the ranges are equal we return the zero everything works and here we're going to do this difference which is uh you know will give us the behaviors that we want if the first one is less it's going to be negative the second one is less is going to be positive however uh another interesting thing here is this eve read right in the standard library when you want to read the scalar value use operator star however this leads to uh problems sometimes known as proxy references and we for our library we don't have to deal with that uh we use read and write functions to read scalar values from iterators so i'm gonna use if read and that will return me a pair of values okay and finally if we look here in the assembly uh there's a lot of assembly but this is the main loop and it looks remarkably like what you would find in the uh what one of the gdp implementation for one of the platforms okay now uh in that example we looked at zipping the same types but what if you want to iterate over ranges of two different types right let's say integers and doubles well it just works so we can create a white of ink and double and we'll just use uh the maximum um so in our case like for example on my machine i can do four doubles in one register and so this will be my limit so i will use a smaller register for ins and it will just work it's all fine okay this zip thing is very fundamental to what we do because it allows us to do to write more complicated things and not just use all algorithms on a single scalar array we can for example do inclusive scan of complex numbers we have two vectors of real parts of imaginary parts this is initial value we define our plus operation and we can call inclusive scan on the z there is an interesting difference here from what the standard inclusive scan will accept and this is this pair right standard exclusive scan here will just accept the operation however due to how cmd algorithms work we also need the initial values a is a not the initial value sorry it's a zero value the identity element and we couldn't figure out a better way to pass it than to use a pair so if we need an identity element that algorithm will accept a pair of an operation and an identity a second interesting thing here is well this is zero and zero is magic and special right so right now this is 231 instructions however for zero we can use one of the eaves constants and we can use e0 and it should go to yes it goes to 211 instructions which is smaller and more efficient it is smaller in the proper place okay and with this final example i'm going to show you because i'm going to give you tutorial is we're going to write a loop as that is from a real promo real product right there is this person um max de marzi and he works on he has a database implementation called hdp and um he wrote me an email at some point asking that he needs to solve the following problem like you have some elements and you have a predicate and you want to collect the indexes of all the elements for which the predicate is true well the first thing i did was the same answer you would get from anybody when you ask anything on the internet how do i do x i don't do x right this is not maybe the best idea here's why uh the thing is okay like we gonna first of all indexes are what's your default index type well it's probably 64-bit maybe 32-bit if you try hard enough right but that limits your parallelism ability right i can do only four 64-bit elements in one register but i can do eight of 32-bit ones the second thing is even more fundamental than that and it is that uh if you do the uh basically okay you got the indexes i presume that the indexes do not have semantics in some cells right you want to do something for that but so you would need to collect the data from from indexes but for simply if you want to do that first it's not very efficient like simply wants the data to be contiguous and you're just loading the data from multiple places it's doable but it's not fast but however he needs us to be solved uh so let's solve it and after i wrote him a prototype he deployed it and he claims that us requests per second went up more than five times let's see how we can do it the fundamental building block to implementing this operation is called compressor you take a register you take a mask and you take a pointer and then you write all the elements that are selected in the mask together and return uh where did you stop right this is a new pointer uh like it's like a remove if only for one register okay now there it has this decorator called unsafe this unsafe allows me to write a little bit of garbage on the end like it's up to the register size uh this allows the separation to be actually efficient okay uh let's have a look now how we can use this to build this operation right this is a function collect indexes we accept a relaxed range the lag strange is our range concept it accepts any standard contiguous range like vector uh it also allows you to do things like return aligned pointer for example from a begin there's a lot of customizations all that stuff uh there's a predicate and there is a vector of output indexes the reason i'm using an output parameter is a i don't want to deal with allocators and you can just pass me an allocator and b it's a very natural way to pass me as index type and as i mentioned uh if you have a smaller index types this will be more efficient because you can do more parallelism okay uh so um first we're going to assert you know that any element in the register can filter into the index type uh clear do the check that the wrench is not empty uh in many uh as scalar algorithms like when you write this is a cosmetic check or as a preference check but unfortunately for us it is actually a functional track for example because we will do a mem cpi sometimes and your beginner then might be null and it's not legal to do a memc api from one now things like that okay now we're gonna use one of our components to convert from the range that we've got this is relaxed range to actually range we can do things with it will strip like you know vector iterators and all of that stuff to pointers um yeah and here we're going to pass uh consider types index type so that we uh select we're going to select how many elements we're going to do in one go and then let's say your range is charged and you can do let's say 32 of those but you don't want to do 32 index types trying to do them like in registers it's not going to be efficient so you want to consider that and selected maybe smaller uh number of elements per per iteration okay to best at this point i would usually just go for reach and be done but i'm not going to instead we go to unpack set so we're going to get the you know the more advanced iterators we're going to compute uh how many lm how many complete registers we can fit in um up to the end uh we're not gonna do any aligning or anything because the operation is very complicated it's not gonna be beneficial we're going to over allocate the output a little bit so that we can always use on save store and we're never going to run out of space no uh this is our index that we're going to start like imagine if you were writing this in scala you would have something like you know four i equals zero i know to equal size plus plus i well in cmd we are not going to use just one i but we are going to use n of them let's say four so we're going to do on first iteration from zero one two three plus four or four five six seven plus four that's kind of tough so this is our white i instead of i and on every iteration we incremented uh right this is the main kind of operation so we load we apply the predicate and then we do compress store of indexes perfect now there is a little bit on the end let's say we had you know we were divisible by four rolls away and we had three elements in the end uh it's gonna look well the modifications we need to do here uh first let's load with instead of just doing load we're gonna do load with ignore right we're going to ignore keep first three elements uh this is effective we'll do must load so the first three elements will be okay and the last element must be garbage right there's no guarantees to what it is uh then we you know applies a predicate we need to clean out we applied the predicate to garbage it might be true it might be false we want to clean it out right so this is how we clean out that garbage element and then finally we do again on safe compressed store because we over allocate it we know we're going to do this finally we're just going to you know resize and shrink to fit and return the result this is a code that is deployed and is more than five times faster and if you look here it does the same you think so it loads some masks that we have prepared it does a permutation and does a store okay and with this i'm going to give you back to joelle i hope not everything falls apart and i'm back apparently oh it's still it's still working so that's great so uh yeah let's go back uh to uh something we saw earlier which is this uh inclusive scan over complex numbers uh we saw that we could actually you know like got those uh vectors or floats uh use zip uh write the proper plus and so on and what is actually not very interesting as the users is to have to deal with this get things to get the pcs from the complex and so on so um to be cool if we could actually have something a bit more user-friendly for dealing with a vectorization of god over structures instead of just arrays of simple values so what we do is we actually provide something that lets you write a complex like uh structures with support for vectorization so we have this track support helpers that you can inherit from your types and they say okay this is my type cmp lx it's basically a float and a float and this will generate all the required threats and overloads for uh being interoperable with eve inside um this is the easiest way to do it we have an external way to do it which is much more complicated because you have to manually specialize a bunch of threads so but if you want to adapt existing types you cannot touch this is also possible but let's focus on this one so we write complex as a structure made of two floats and we write those a small adl base accessor re and m that will wrap the get zero and the get one and we'll let you access the value of the real and imaginary part and as we want complex to be able to work in both scalar and simdi mode the type you wait there as an input it's not the cmp lx it's something that models the light cmp helix concept that means that anything that is either cmp lx or a wide of cmp edits so it got it can catch both the cmd and the scalar way of doing pins and once we have this cmpx function you can actually manage a bunch of operators first you have opt-out to remove uh ordering operation so we don't want to have less than and so on on complex because it doesn't make any sense so you can disable ordering right there and we will be reconstructing most of the operators in a in a slightly boost operator way by uh requiring compound operators to be provided from which we will build all the other variant of the operator so plus equal give you plus with complex white of complex and so on so you and you can just write it using this access so we've brought a bunch before you can have binary operation like minus and then you can have minus equal um it's important to know that we don't generate minus from plus and unary minus because it may mask some optimization opportunities so you really have to be exhaustive on your operators so we get plus we get minus you could get all the other one and as soon as you put it it's available outside uh you could also stream your structures quite uh trivially and as soon as you have that you are also able to print uh an instance of white of cnpx so we reconstruct everything from this um from this sample of um operators a lot but sometimes what you want to do is to actually uh change the behavior of an existing e function uh i want to compute the absolute value of a complex it's basically computing the square root of real square plus m square and i really really want to be able to call f apps over my complex structure so we have this tag dispatch mechanism that lets you say okay for this function apps so every uh function object in eve has a tag associated to it so you can actually refer to it in another load whenever i call eve abs on something that looks like a complex i do something with it and return a result and now you could actually uh have you are able to call eve apps on on the cmp helix fine so you could actually write structures and imbue it with vectorization uh as a function level but we can do better because we also have this slr vectors that can take any kind of this adapted structures and it will act like like like what it said on the box it's a vector but stored in a str in for a way so it's very aminable to vectorization and solar vector is also uh recognized as a range for our algorithms and it overloads uh the key elements of the range protocol we use so you could actually just pass it directly to uh inclusive scanning place without having to write everything else and by default we use plus so we don't have to specify the operation and because the plus is already specified uh and defined on the structures itself and uh well what happens to the code well the code is better because sr vectors know a lot about what it does in in terms that it already knows that it's properly aligned for whatever kind of scene the instructions that you want it knows how it behaves with respect to range and you know how many elements he has to manipulate and if we look at the main loop we have got this very tight um computation um on the inclusive scan thing so you got you got the ad you got the shuffle and so on and everything is rather tight so you could act you can actually write and that's also something we are actually probably uh most proud of is that you could actually get code with arbitrary structures getting vectorized through our eye level algorithms so let's do something else let's say you want to do some basic physics you have a bunch of balls and they bounce on on the floor so um you want to do some uh small scale physics simulation like you know um tracking the position and the speed of your ball as a float and every ball has an elasticity factor that's all well can bounce you know and we have an integral there so we can actually mismatch types inside the structures that's not a problem that count how many times you bounce because once you bounce a given times you don't care about the ball anymore so that's the structures with the classical way of getting the accesses to the elements we don't do anything fancy because we don't need special operators and what we'll be doing is writing a small function object let's say when you give me a ball uh i would compute the physic on it so uh i will com i will compute in falling uh i will update the position of the following ball by applying some you know physics multiplying the time step by the speed and so on i will update the speed by uh using the gravity constant and so on and so forth i will also compute a state for whenever a ball is actually bouncing by reversing the speed and multiplying by the elasticity of the given ball and counting that i bounced and the question is why i am doing both because when you are doing physics you need to um no you you can test you can do f but you cannot do f in cmd so but you have to compute both states and select them using effects at the end and we say that if our position is very very low uh we are going to bounce okay uh and if not you keep falling and when you want to run your simulation you just call transform in place on that and let's say we unroll by a factor of two and uh whenever it's done we can use a good or uh erase remove if uh items to remove all the bubbles from which the the count the bouncing count is actually greater or equal than the max bound and that's all we do so the code looks actually like like the natural codes that do something it's not a bunch of intrinsics you know uh wedging walls and we get something that is actually again sorry for that let's go to the main loop uh something which is very compact so we got comparison we got the blend and we got all the updates over there and so on and so forth okay fine so algorithms functions over classical registers we have this support for structured code and structured operation so now what if you want to start using it well some practical points uh what about bugs oh well probably we have a bunch of them okay uh and uh we are working on that we have an extensive set of uh unit tests uh we are not immune to a collagen issues but we try to make them as few as possible so if you you try the library and uh you find something just penis uh what about abi and api stability api stability we don't care we explain that a bit later and as for api stability currently nope we are still crashing through writing the code we are still finding better way to express some things with a lot of uh optimization opportunities so well we are still breaking things uh we we have we started releasing a tag version so you can keep track of what's what is going on if you really want to but except for the very core things we are still playing with a bunch of api so what if uh what if you still want to use us well this is a recommended workflow uh we strongly advise on focusing on the critical components in term of performances you are not going to vectorize your your apps you are going to vectorize a bunch of uh very critical function slash loop nests so focus on those extract them as some kind of a standalone library of computation or so on um that you can actually test and compile somehow and um you can use either dynamic linking or multiple static linking if you want to support multiple multiple architectures in a single executable eve provide a compile-time way to know what are you are compiling for that's the current api we see in a bunch of slides but we also have a dynamic test that lets you say okay am i run time running on the machine with this or that supports and then you can actually select the version of the function you want to call every uh cause in eve is actually resolved at compile time so you will need to uh compile uh for multiple architectures yourself and uh if anything fails just contact us it will be a pleasure to help you design or debug whatever you have there is of course a lot of similar libraries we are we probably didn't invent the things uh you have a bunch of intrinsic wrappers i'm probably missing some but that's the uh the most uh prominent so you have vc which is stated for uh standardization if everything goes well you have cmd and tcmd and probably uh alfred doesn't further insert a random consonant cmd library out there uh there is highway from google and stuff like that they mostly all navigate around wrapping them into insects easing the way you use them into regular code but as best as we know uh none of those provide nasal algorithm no structured vectorization supports and uh if you really want to dig a bit in another direction you have oh sorry you have cd everywhere um which is uh basically rewriting every intrinsics of a given architectures using all the other ones so you can actually copy past ssc2 code into a arm version of something and it will just compile but so it's even lower level because we don't have any um abstraction on top of that so they are pretty much based um on similar premises and uh they work quite well for whatever the limited scope they are providing uh some special mention before we close there uh space i mentioned to jean-pierre which is our third uh co-author for the library it's a guy in charge of the mat and well he do maths quite a lot and quite well so we have to thank him for a lot of our non-trivial uh math algorithm in the library um adventure friendly shout out to a lot of people with stack overflows uh in random orders peter cordes boson stephen cannon akrit that helped us all push us into the right direction for a bunch of our work on the algorithms mainly and if you ever have an issue with x86 uh just look for peter called the sensors this guy is a goldmine um we kinda get influenced by unity for the cso vector that something they have in their own implementation of their um all their system uh they spent another talk about uh using eve quite a while ago now at this exact same conference so if you want to get more into the gritty detail you can have a look at that and uh well we are pretty much easy to find you can get the slide as i said already you can get to and find the library and try it out if you want we have a discord for the library and we are also present on the hashtag include discord and on cppslang slack or you can fire us an email or get us on twitter if you want to bother us with your issues thanks again for your cooperation i think that um denise you can come back and we can see and uh answer a bunch of questions we have one minute to answer okay i can do that i think the uh we have five minutes oh five minutes that's five minutes we'll do everything uh i think we can answer them like uh i think both of them are kinda already answered but we can get to i just no let's get them on tape like i just answered yeah yeah sure sure that's what i wanted to say so uh let's start with the uh mismatch on non-multiple maybe you can get uh out of that okay uh yeah uh so i showed ignore all right the idea is that when we doing uh like we will we'll so misfire calls fine right so it's the same answers for point uh as to how it's done and basically you will uh load some elements there will be some garbage on the end right and then we will just ignore the garbage i don't know if it makes sense but uh inside you get so the person who asks knows about city so inside you get move mask which is bits for everyone and we will clear the bits for the ones that don't matter um the dynamic thing can you answer the last one is okay yes the last one i will do that yeah uh so how do we deal with the vex events uh code generation uh we just don't i mean i mean we we just asked you to put the proper um um flags in your in your compilation i don't know if i can actually okay let me let me try something i don't know what's vex ever said what's it oh yeah there is two uh there is two um let me share something else uh there is two uh way to encode um s um acid insulation set depending on the microarchitectures on your uh on your x86 systems and basically uh when you switch between the uh vex and evacs systems uh you need to use those ugly uh it's it's um sorry v0 upper and uh it started stop things so the the system no it has to clear up the high parts of the ymm resistance because if not uh you will get issues because on some armor architectures the large avx registers are actually shared with the smaller ssc one uh the thing is that as we require the uh [Music] the actual architectures to be specified there i don't i don't know if my okay it's on so as we we will call you to actually uh specify the um system there uh what you what happens is at least i'm compiling code for avx user obviously but what i did is i wrote a small function that takes a register of four float which is obviously sse registers and in this case as we see we got the v whatever version of the intrinsics okay uh and in this one i try to basically mix them up so i'm taking um an avx register so this is a ymm something and what i do i call this a slice member that get me the internal uh smaller xmm registers that in any dysfunction i call the other one and then i call myself on the ymm and we basically get nothing because uh for the for when we compile and that's what we saw into the if constructs of things uh we we know that we generate all the code with the proper um modulation of the um of the version of the of the encoding uh if you combine two separate um sorry in two separate um [Music] files because you want to actually call different things with a different setup then in this case you may have uh you may need to uh to call zero opera and stuff but relate that to the compiler and usually uh it's the best way to do that so uh if you if you write code like this you don't have to to take care of that uh it's basically for the compiler it could just generate those correct things uh it's a bit more complicated in other situations but uh usually well either you work with a full uh sse register set or you will be working with the uh with avx mode anyway and whenever you have to treat xmm it will be just uh emitting some proper version of the uh of the intrinsics uh what do we have next uh yes so it goes well yeah we we select the assembly restriction set at combine time because if not uh we probably have no no performances and as i say we have a way to select uh our discover let's say uh at time which which is actually the extent of the architectures you are running the codon and in these cases what we we expect people to do is to actually uh have this multiple uh version of the uh of the function pre-combined and load either dynamically or call directly depending on this runtime if we have an exam we we have written some example of that for someone and i think we still need to put it into the actual uh example folder it's not that complicated it's probably more you know um c mech a query than anything else uh so we'll probably drop an example for that uh in the in the repo if uh uh well swedish let's say yeah let's just add that you know like this is just the whole format of like we have small components doesn't allow you to do uh dynamic expansions for component on the algorithm level yes but we don't do that okay thanks thank you thanks dennis thanks for this very great talk and maybe if there are another questions maybe they'll find you in the uh launch hopefully thanks everybody for coming thanks everybody see you