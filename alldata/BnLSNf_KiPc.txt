op sourcing pingora our Russ framework for building programmable network interfaces this is cloud flare today we are proud to open source pingora the Russ framework we have been using to build services that power a significant portion of traffic on cloudflare pingora is released under the Apache licens version 2 as mentioned in our previous blog post pingora is a rust async multi-threaded framework that assists Us in constructing HTTP proxy Services since our last blog post pingora has handled nearly a quadrillion internet requests across our Global Network that's a lot of that's that's a lot of requests okay that's uh that's a lot of requests holy cow uh we are open sourcing pingora to help build better and more secure internet beyond our own infrastructure we want to provide tools ideas and inspiration to our customers users and others to build their own internet infrastructure using a memory safe framework having such a framework is especially critical given the increased awareness of the importance of memory safety across the industry including the US government no B is a rust it's been fact it's a fact of life okay it's a fact of life uh under the common goal we are collaborating with the internet uh security research group uh and proa project to help Advance the adoption of pingar the internet's most critical infrastructure Biden an actual crab actual crab laying advocate in the previous post we discussed why and how we built pangora in this one we'll talk about why and how you might use pingora okay nice pingora provides building blocks not only for proxies but also clients and servers along with these uh components we provide a few utility libraries that Implement common logic such as event counting uh error handling and caching okay so what's in the box it's kind of exciting I'm kind of excited about this uh pingora provides libraries and apis to build services on top of hp1 2 uh TLS TCP UDP we're three where's three uh as a proxy it supports HP 1 and two end to end grpc and websocket proxy hp3 support is on the road map hp3 is hard uh it also comes with customizable load balancing and fail over strategies for compliance and security it supports both the commonly used open SSL and boring SSL libraries which come uh with fips compliance and postquantum crypto postquantum crypto sounds so amazing is that just elliptical curve is that postquantum uh read the event counting article it's pretty interesting uh yeah I I don't know if I'm going to I'm going to read event counting article at this current moment but this does sound exciting uh besides providing these features pingot provides filters and callbacks to uh to allow its users to fully customize how the service should process transform and forward the requests these apis will be especially familiar to open resty and engine X users some people call it in Jinx and those people are wrong when I heard that I was like am I saying it wrong I thought it was engine X and then someone then I heard somebody walk by me like in Jinx and I was like I uh well dang I guess I I guess I'm a dummy this whole time dude don't you hate when you say something and then you realize that you're just you're just just it just hurts it just hurts senior Dev people uh they say how to pronounce it in their website okay so it is inine X I'm glad it's inine X because that makes me feel better that I've been correct uh the many uh map intuitively into open resties uh by Lua callbacks oo Lua mentioned Brazil mentioned Brazil mentioned operationally Pata provides zero downtime gracefully restarts to upgrade itself without dropping a single incoming request CIS log Prometheus Sentry open Telemetry and other must have a observability tools are also easily integrated into bingata as well dude love it Brazil mentioned also censur open Telemetry fantastic that's pretty cool uh who can benefit from pingot you should consider it if security is your top priority who has security as like a top priority that kind of sounds fake news pingot is more memory safe alternative for services that are written in C and C++ um is that permanently true it's it's a bold statement to make do you think that there can be a perfectly memory safe C++ application I don't know I assume so uh memory safe Fearless concurrency um anyways while some might argue about memory safety among programming languages from our practical experience we find ourselves way less likely to make coding mistakes that lead to memory safety issues besides we spend less time struggling with these issues we are more productive implementing new features Fair uh your service is performance sensitive Pata is fast and efficient as explained in our previous blog post we save a lot of CPU and memory resources thanks to Ping's multi-threaded architecture the saving in time and resources could be compelling for workloads that are sensitive to the cost Andor speed of your system okay I like that your request uh your service requires extensive customization the apis that the pingora proxy framework provides are highly programmable for users who wish to build a customized and advanced Gateway or load balancer pingot provides powerful yet simple ways to implement it that's super cool okay that's this is actually super cool because I've always wanted to play around I like like I've said earlier I've never built a proxy myself I've never done any of these things I've never built a load balancer a custom one I've never done any of those things so it would be a lot of fun man see there's just so much things I want to do and not enough time in the day because I got to go I got to go back to work soon uh let's explore pingora programmable API by building a simple load balancer the load balancer will select between 11111 and 101 to be the Upstream in a round robin fashion okay cool we should be able to follow this pretty easy first let's create a blank HTP proxy all right we have a struct load balancer we have an async trait uh impul proxy load balancer async function Upstream Pier result in uh result box HP Pier damn it's a box HTP Pier let's go too any object that implements the HTP proxy trade similar to the concept of interface in C++ or Java is an HP HTTP proxy okay the only required I wanted to know what what are the arguments coming in here and wait hold is this a trait oh no this is the trait I was like wait a second is this the trait no Pier Pier must be the it must be a concrete object of some sort uh the only or no it's not it could be since it's in a box it could also be a trait right the only required method uh or it had to be dine never mind has to be dine sorry I haven't I haven't played around with box traits in a long time the only required method there is Upstream Pier which is called every request this function should return an HTP Pier which contains the orig origin IP to connect to and how to connect to it next let's implement the round robin selection the pingora framework already provides a load balancer which is a common selection algorithm such as round robin and hashing so let's just use it if the use case requires more sophisticated or customized server selection logic users can simply implement it themselves in this function oh very cool this is actually super cool all right let Upstream equals self zero select uh no bu 256 the hash doesn't matter with Ron Robin okay uh unwrap okay we get this we get that uh the sne one to one to1 to one uh let Pier equals this new Upstream as 1 to11 one11 1 to1 one11 one1 one11 return this okay since we are connecting uh to an H HPS server the sne is see also needs to be set certification timeouts and other connection options can also be set here in the HP Pier object if needed finally let's put the service in action in this example we hardcode the or origin server IPs in real life workloads the origin IPS can also be discovered dynamically when the Upstream Pier is called or in the background uh after the service is created just tell the load balancer to listen to this and in the end we created the pingora server and the server will be Pro let's see will be the process which runs the load balancing server okay that's pretty cool we do this one try it from these two ones right here let mute pingor proxy HP proxy server configuration upstreams add this TCP equal a new server my server add service Run Forever it's pretty cool so any of your strs can become load balancers by simply implementing the HTP proxy and just having this uh Upstream Pier uh returning this out okay that's pretty cool and then I assume the server underneath does the new requesting and all that run uh forever very optimistic Dad Run Forever that's camel that's camel case and we don't do that around here okay your dad sucks I just want to let you know that now let's try it out so we do this little curl right here we can see that the proxy is working but the origin server rejects us with a 403 this is because our server our service simply proxies the host header uh this set by the curl which uh upsets the origin server how do we make the proxy uh correct that this can simply be done by adding another filter called Upstream request filter this filter runs on every request after the origin server is connected and before any HTTP request is sent we can add remove and change HP request headers in this filter oh interesting okay so we get the ability to play around with headers and hook into oh very cool there we go very cool we curl it and we get oh wow this time it works the complete example can be found here okay below is a very simple diagram of how this request flows through the call back and fil we used in this example pingora proxy framework currently provides more filters and call backs at different stages of the request to allow users to modify reject route and or log requests very cool so you get the Upstream Pier you filter out stuff SL update it and then you get to do this that is cool that's really really cool let's look at the code for a quick second all right so here's our load balancer that's AR Arc incoming uh we get this we get a type context oh my goodness we're getting some gats going on here Upstream Pier we do all this one self session this is why by the way they they hit a lot of it uh you just couldn't you couldn't handle the amount of symbols going on here they don't want people to actually see this okay so we do this little random selection we do this awesome we do our filter which insert header host one to one11 one awesome we do our main uh server ARS we do all this we create our load balancer from these two hardcoded places right here or actually three hardcoded places right here including a 343 interesting um we have a little health check frequency oh nice we have little health checks cool we had a health check at the background so that a bad server is never selected oh that's super cool I didn't realize you could do that upstreams nice you can even oh nice uh that's cool uh background service health check upstreams uh upstreams background task okay uh load balancer pingora this upstreams let's let's do this sert path get all the CT paths oh cool ad Service uh load balancer ad service background Run Forever that's pretty dang cool I mean I know this would turn out to be like way more complicated if you actually did anything yourself and this is a very trivial example but still it's pretty dang cool this is pretty dang cool especially since it's all you know it's all Cloud flare and and and can we be real for a second like out of all of this stuff if I were to trust anybody to build this correctly I would I would I would trust very much Cloud Flair to do a good job can we all agree to that cloud flare probably does some seriously good stuff type masturbation oh yeah I could feel it I could definitely feel it coming in yes I see one person saying nope sounds like you have a lot of confidence in yourself okay uh leolo why not hit me hit me come on come on hit me you're on the big board now you're on the big board come on you got 2,000 people on the dot waiting yearning Desiring to see what you have to say I just don't like Cloud flare okay good take hey good take we we we'll do that we'll do that we we'll be fine with I mean honestly you just owned me with facts and logic so I actually have nothing to say at this point open source present and future the pig is a library and a tool set not an executable binary just give me an EXT smelly nerds in other words pingora is an engine that powers a car not the car itself although pengar is production ready for industry use we understand a lot of folks want a batteries included ready to go web service with low or no code config options building that application on top of bangora will be the focus of our collaboration with the isrg to expand Pat's reach stay tuned for the I'm sure dude you I'm sure the moment you open source this there's already like there's already 15 sweaty nerds coming up with yet another framework we're going to have axom actex rocket and penod axom penor borx right some some extra thing we're going to have it nitp all over the PRS it's going to be wild uh how I get Tri feel free to raise a bug reports documentation issues and feature requests in our GitHub issue tracker okay awesome conclusion uh let's see in this blog we announced the open source of our pingora framework and thank you for telling me what I just got done reading isn't it always strange when people do phrases like this like thank you for watching I just got done telling you about X you're like yes you did you sure did you did you did that thank you for that uh we showed the internet uh the that internet entities and infrastructure can benefit from from pingot security performance and custom ability we also demonstrated how easy it is to use pangot and okay I don't care at this point blah blah blah blah this was super cool though it was very cool to see how simple it was to create this I still need to actually do this and I'm sure there's a day where I'm going to build my own load balancer and then I'll build a couple load balancers and I'll be all super excited about load balancers and proxies and all these things and I'll know exactly how they work because right now they're just a bunch of there's they're just a bunch of squares in my head and so it'd be very very very nice to have like it not as squares but as actual concrete stuff and so it sounds like this would be a lot of fun to look at dang yet another thing on my list another thing on my list just be just use axin hyper it it works and it's wellmaintained axmen is very nice actic is also very nice right I I I like that I like it load balancers are just something you add to your uh k8s did you know that uh k8s if you drop the S and you make it into a k9 you get yourself a dog k8s equals K9 equals a dog it's math go ahead try to disprove me try try to disprove me you can't anyways this is super cool oh man I want to play with all this stuff all right anyways oh man there's so much stuff I want to play with the problem is is that like I have no opportunity to use n uh rust at Netflix in any sort of realistic way so I've just kind of given up the fight I want honestly I just want to use go at this point but even that is just like so hard to do other than certain teams I was go adjacent for a long time but it's like so hard to use it you know what I mean Java forever it's actually node everyone wants to use node and I think they're all wrong but I don't get choices on that the name is I get to write node but I use JS do in my projects and and on the projects that I don't use JS do there's like eight 8 second 10 second then one of them is like a 10-minute build process it's emotionally painful I think we should just use JS do man man just use JS doc get over yourself stop using typescript stop I hate your build systems oh Jen