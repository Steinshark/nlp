all right so what is gained and what is lost with 63 bit integers September 29th 2014. this is a long time ago almost every programming language uses 64-bit integers on a typical modern Intel machines ocamel uses a special 63-bit representation how does it affect oh camel oh my goodness before we go I want to hear your guess um my guess is that it speeds it up because my guess just hear me out on this one because they have a garbage collector one bit is reserved for the type my guess is they're implementing some sort of Smee some sort of small integer something that allows them to do something clever so they don't have to follow a pointer for every single thing that's my guess yes you're on the right track at least for sure so yeah I think you'll be I think you'll be pleasantly surprised with the trade-off okay and plus uh 63 bits is probably enough uh I think that's really true though it's really true in in most people's integer experience uh because if you're doing Financial stuff you're using strings right you have to be absolutely precise and you have these really long string calculations and these libraries devoted just to like perfect Precision Financial stuff uh so and if you're doing integer representation you're not going to just be toss it on yes a quintillion on the screen no one can read that you guys could fit your users in an 8-bit integer Max like you'll be fine yeah yeah your users don't even let's just face it a four bit is probably good enough for most people's users am I logged off that's mostly my user table is it me or my test users yes or no all right okay well and memory representation uh most of all camels types are in memory representation as a header followed by data the header is a 64-bit integer containing the length of the data and a tag a tag is a rough classification of the type the only o camels type which differs uh from this are ins and sometimes floats okay so I might be on the right track I'm using my knowledge of what V8 does and that's why I'm guessing this because they have smes as well uh floats normally have header and data data being the value of the float itself this representation is called boxed oh man look at that period outside the double did you know that that is apparently a UK versus America thing I heard that I think objectively dot outside is better because like you're quoting the boxed right and then you want to put a period at the end personal opinion you just said objectively and now personal which one is it DJ well it's Twitter so we can say both opinions are objectively better than that so like whatever I think is right and whatever someone disagrees with is wrong and not only wrong morally repugnant [Laughter] there we go my opinions about software engineering are objectively better to eat dang it you're welcome that's gonna be three dollars in your pocket from this sweet so many Impressions uh all right if a record field is a float records data will actually contain a pointer to the flow to data right so this is one of the reasons so when you're doing actual like math and stuff to make it fast to have to follow every single value somewhere would just totally suck especially if it's a value that doesn't need to be even on the Heap at all it just is crazy right right uh the only exceptions are records with only floats and floats arrays whose data instead of pointer contains the value of floats this representation is called unboxed in other words do you have a box that contains the offset to the value or is the thing itself the value uh values of type and are never stored as header and data boxed Intex is stored as one or X shifted by one with an or one okay first bit so it's a first bit check uh where double over or double left or what left shift is this and bitwise yeah blah blah okay hence its least significant bit is always set pointers are that doesn't know what this means though Chad doesn't know like you should probably draw it in  form I can draw it in for them right now okay look at that Meme though can we all just appreciate that one that was my uh htmx meme which I thought was one of the best memes except it was me all right so so if you can imagine here's a value let's just say our value is one this is a value one in in our world in our normal decimal counting system if I had one and I multiplied it by 10 it's just 10. if I multiplied it by 10 again it's 100. in binary counting systems since base is 2 instead of 10 multiplying by 2 is the same thing as effectively left shifting so when I multiply uh one by two I get the answer of 0 0 1 0 If I multiply by 2 again I get 0 1 0 0. in other words it's the same thing as multiplying by 10 in our counting language which a left shift if I left shift by one it's the same thing as multiplying by two so when you pass in X you left shift by one you move all the binary over right and then you or one or effectively is a truth table of let's just call it a b uh zero zero zero one one zero one one the values are zero one one in other words if any of them are a one it becomes a one so by oring a one into this this means if your value let's just say x was zero one zero one we left shifted it over that make it one zero one zero and then we ordered one that'd make the final value one zero one one them correct simple as that so if you've never done some bit stuff it's really good to do it it's really great for protocols and stuff like that and CPUs are really fast at this by the way like they're really fast at this and in general can always be pipelined so that's just something to think about when you're thinking that seems like a lot of extra stuff actually CPUs are pretty good at this these effectively become single instructions right yeah they're they're just like defined basic instructions so they're very very fast whereas when you have to go follow a heap pointer and do stuff you're doing a lot more typically when you're doing if everything's on the Heap it takes a lot more effort and so where you got to compare this as well we'll we're going to get to it I'm sure but like you got to compare it to memory access right so that's basically the difference right they're they're gonna try and trade something for how often they have to go do memory access right yeah pointers are word aligned so they'll never have this bit set hence uh how ins and pointers are discerned it is assumed that uh by the way word aligned for those that don't know let's just say you had a big block of memory and you're on a 64-bit system you can imagine that you do something that is not uh or really any bit system so some people can take this at the 8-Bit boundary some people you know you can do it depending on where you're at so 64-bit boundary would be an easy one to do you would never store like say your item only takes up eight bits you would never store it at the first the second byte your next item you'd go all the way over to the next spot uh which would be 64 bits that's what Russ does with structs it turns out it can be a lot faster for CPUs and stuff like that and blah blah blah blah blah uh I don't really understand that and like just like conceptually you'd think it wouldn't be because you're like you're taking up more memory or something but actually it's just like the CPUs are really good at doing those things yeah is there like optimized for that case yep uh pointers are word aligned so they'll never have this bit set hence uh how instant pointers are discerned it assumes that much of the typical data is integer so this is done to significantly improve performance there is no need to de-reference a pointer when getting an INT no memory allocation is needed when creating ins less work for the garbage collector less memory fragmentation no memory is needed for in headers yeah I assume that's because all ins are just copied everywhere you don't actually need to have any form of collection they're just copied and immediately got rid of anytime something leaves right distinguishing whether a value is int or pointer is simply doing this test right here so this feature doesn't slow down garbage collector polymorphism hash polymorphic compare and whatever else whatever else structurally inspects data one should note that this doesn't apply to types into 32 and in 64 which are always boxed oh I didn't know that is there like uh oh that that's because there's an INT type right yeah there's like just an integer type that you would normally use unless you have some really particular reason about saying that it actually has to be 32 bits or actually has to be 64. right yeah and well we won't talk about it today maybe later we should read the Jane Street article or I don't remember if we did if we actually read the one for unboxed types but there's like work to be able to say certain things will also be allowed to be unboxed which is really cool but that's for a different day yeah having I assume this is along the lines of the life cycle stuff yes it's like sort of in that same vein of like when you want to be able to do something in particular and you know some certain constraints you can actually like get a lot of performance Improvement by doing these things right I'm not allocating them on the heat let's see having the extra bit comes with a price a rhythmic uh arithmetic operations are more complicated for example X Plus Y is translated into the CPU CPU instructions X Plus y minus one uh x times Y is translated into the CPU instructions uh X shifted over by one multiplied by y minus 1 plus 1. I don't understand that quite yet I'd have to look at that on paper they're basically just like um you can just start with X it's actually you know like x minus 1 times y minus one and then like do the arithmetic with each other and then you can actually figure out what they go to but then they just get stored correctly I think but keep in mind as well this is actually like at compile time not at yeah or like you have to run this check right but it's not like figuring this out on the fly yeah all right uh this thing is translated to the CPU instructions this it's a lot of work there's a lot of arrows shifting all over the place uh X was this left shift left what is it what is LS I think so yeah that must be left shift left yeah that doesn't make any sense left shift left what is that what is LSL I don't know what is logically shift left according to low level learning I trust him he's got low level in the name maybe he's a genius pretty cool YouTuber what is a logical shift left does that just simply mean like a zero fill I don't know what a hyper low level earning to type something in chat I'll copy exactly what he says out loud and then I'll sound really smart I'm waiting logically verse arithmetic yeah nailed it because I know bit wise let's see uh arithmetic uh rotates a lot uh oh really why would arithmetic rotate okay I'm not gonna answer that question that's fine I assume when he says rotate it means that if you had a zero if you had a one like it would go it goes all the way around right wild okay so you see all these things obviously doing stuff creates more instructions to do you can't simply just X Plus y because they're stored a little bit goofy you'd have some weird rollover that happens uh I think I understand the minus one actually I do understand the minus one uh check this out let's just say that we we have zero plus zero that means it's going to look like this so 0 plus 0 is going to be zero zero zero one because it's an integer zero zero zero one because it's an integer which means it's valued be zero zero one zero now minus one from that makes it zero zero zero one it goes right back to it I get that because these two added become two and so to get it back over you need the minus one okay I see that so it's just a bunch of arithmetic fanciness over trying to preserve the value of whatever uh to preserve that one in the first position okay right and and like that happens the instructions get generated when you compile it can like figure out that you're adding three numbers together or two numbers together or five you know and it like does the simplified version for those things right so like the compiler will do that as you go it's not like it's encountering an unexpected plus because it's an interpretive language right so that's like one of the things you have to consider is it's not always as bad as you'd expect and once again CPUs are really good at pipelining yep all right sometimes this penalty is small or non-existent for uh for instance there is no need to fix the bit X Plus y minus Z only fix one bit is needed uh for all five editions yep that makes sense because this is an even amount of additions therefore you have to minus one yep potentially I'd have to think more about that maybe you might it's okay they're just basically saying it doesn't seem as bad as you might think for like lots of the common things where you're just like adding one number multiplying a few numbers Etc it seems good yeah all right another help is the Intel CPU instruction Li uh which can uh can compute the sum of three integers with a single instruction like X Plus y minus oh really I didn't know that unfortunately Lee became very slow in the recent generations of CPUs Intel doesn't suggest this will change this benchmark test ml tries to estimate the difference in performance the results from uh Sandy Bridge show about 2x speed difference in arithmetic operations assembly can be examined compiling using ocamel opt s uh ml oh cool that's cool that you can uh can go check out those things yeah that's 2014. so like it may be quite a bit different now but yeah yeah a decade of CPU probably is a bit different uh just a little bit uh agner's instruction table shows the differences even bigger with later generations of CPUs and for instance Haswell can do four integer ads per cycle for which is one Lee conclusion the benefits of unbox are amazing on the other hand arithmetic operations are significantly slower how much do arithmetic operations affect the average program uh could we have a solution that would keep into unboxed to have the fastest arithmetic operation question mark well I mean one thing that we're not talking about in here is if they didn't do it this way yeah you still would have to go fetch you'd have to follow a pointer to the value yes so I mean that's like they only mentioned it casually but that's like the point so we should probably like clarify like maybe draw like a block of memory right and like think about what it looks like if you actually only have basically pointers to some other spot right you're basically wasting so much space because you're just gonna have a pointer that's word aligned so like 64 bits usually yeah it points to some spot in memory to an integer that could be 60 foot right so it's like yeah yeah the one thing I don't understand so I'm not like a huge assembly guy I've done assembly once in the past I've never I've only ever gone as low as C typically I've never gotten much lower than that and so in this world like when you're doing something like this like X if this was the way right so let's just pretend this is X this is y and then of course this is one which one is like a constant which is called a constant right and if you're doing something like this if I'm not mistaken in the assembly world what's gonna happen here is that you have to effectively like load X onto a register you have to load y onto another register right I don't know whatever that's called and then you do some sort of like operation and then you have to do some sort of I'm maybe there's some sort of minus one operation that can just be done and boom you got yourself an answer that's on some other register that's like my basic understanding is that you have to push things onto values and do operations on those values I'm not sure how correct I am on that but that's my kind of little box I've drawn around it in my head yeah right and so the difference is right there's two main things that are sort of like different than when you do this trick is one the garbage collector always knows that it doesn't have to go follow stuff to different memory to clean it up so that's like a huge win right like you're done with this integer and you want to get rid of it it sees that it's an integer right and it can just be done basically right so there's like all this extra stuff that you don't need to do because you know that for sure it's an integer without having to go follow some pointer right yep and then the other thing is like if you load you know a bunch of integers in a row right because you're gonna go do a bunch of stuff that's all going to probably land in the same like cash hit for your CPU right so then like you know all your integers are like next to each other because you did something with them together or whatever right and then you you do something you don't have to go find wherever memory frag that's the memory fragmentation part right of like having to go track those down yep whereas if we were to do this with uh everything still being just a heap object even your one theoretically would be a heap object there's literally no way to represent it without having some way either to say in this one word right it is either an integer or not right so that's like that's the nice thing yeah everyone in chat is trying to correct us on like actually this is how these things work I I have I I have no idea about how these things work okay just to be completely real I don't know how these things work look see look at this he's using all those fancy things eax I don't know what these extended a registers are okay I don't know what they do um I don't I don't I don't get this right but I would assume that what this load X becomes significantly more complicated when X actually is a pointer anymore you would have to like go find what the pointer is yeah because it would just not be like some sort of load direct I think business that has to go on there and then on top of all that this also would have to have some sort of wrapper value on top of it that the garbage collection would then know how to point to it so minimum your one value right here would have to be three you know uh CPU something sizes right they'd have to be probably even more than that probably four you know 464 bits to represent your small little number so just represent number one because first you need your pointer address then this one's the actual value stored in 64 bits then you have some sort of tag right here then you'd have some sort of thing that the uh that is stored in the GC that points over to this so there's like a lot of steps that have to happen and then you just make integer stuff really slow which is like usually not what you want to do so there's typically you don't want to do that yeah so that's the other thing too actually that this makes really cool is that oh camel's memory model is actually really really straightforward right because you're basically saying look you either have there's a few things that can be unboxed they're shown by being this right so it's like okay so now you know the only things that can actually just be like in this word or it's something that's Heap allocated and you go find it and look it up right and they're like oh that's actually a really like straightforward and simple memory model that's easy to understand and work um and so work with and so that actually leads to very um very cool stuff I think as opposed to like you know oh I the it's it's well specified what the memory model is which is cool yeah yeah low level what are we doing okay did we how did we do okay how do we do maybe we should get them in to come tell us if we did okay TJ would have got that so easy uh if you've never done it go to low level learning check them out as well TJ you're also you can find me there yeah okay awesome um fantastic so TJ you stream too right I do on Twitch believe it or not what and this week I'm going to go talk at Jane Street about any of them which just got done reading an article on Jane Street incredible I know not sponsored but should be should hashtag not an ad but should be I know hashtag j3 can you just pay me for this I'll bring it up when I'm there yeah when I'm there this week by the way talking about what let me guess neovim neovim I'm encore by the way all right then if you guys have heard of telescope the telescope agency the name is TJ wrote the telescope again all right Tom diesel see you see ya all right take care teach