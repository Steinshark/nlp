Post Id,Parent Id,Title,Body,CreationDate,Score,PostType
"79414160","79166453","","<p>The error arises because tensorflow cannot determine the tensor shapes explicitly. When using <code>tf.data.Dataset.from_generator</code>, you should provide an <code>output_signature</code> argument to explicitly define the shape and type of the output tensors. This allows tensorflow to properly handle the data.</p>
<p>Instead of using this:</p>
<pre><code>ds = tf.data.Dataset.from_generator(generator, 
                        output_types=({'LoB': tf.int32}, tf.float32))
</code></pre>
<p>Use this:</p>
<pre><code>ds = tf.data.Dataset.from_generator(generator, output_signature=(
    {'LoB': tf.TensorSpec(shape=(1,), dtype=tf.int32)},
    tf.TensorSpec(shape=(1,), dtype=tf.float32)
))
</code></pre>
<p>please refer to this <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">document</a> for more details.</p>
","2025-02-05 08:56:20","0","Answer"
"79350855","78049931","","<p>The <em>Pytorch Geometric</em> documentation has a <a href=""https://pytorch-geometric.readthedocs.io/en/2.5.3/notes/create_dataset.html"" rel=""nofollow noreferrer"">great guide</a>. There you can find clear instructions, which methods of the appropriate parent dataset class you need to overwrite. This means you might have to write your own method to read your own fileformat in and to bring it into the <code>Data</code> shape of <em>Pytorch Geometric</em>.</p>
<p>Many commonly used benchmark datasets for standard graph machine learning tasks are integrated into pytorch geometric and you can simply import them and use load them (note you can even add custom preprocessing, if you want):</p>
<pre class=""lang-py prettyprint-override""><code>from torch_geometric.datasets import &lt;Some Dataset&gt;

dataset = &lt;Some Dataset&gt;()

# Ready to use the dataset
</code></pre>
<p>You can find a list of directly available datasets at <a href=""https://pytorch-geometric.readthedocs.io/en/2.5.3/modules/datasets.html"" rel=""nofollow noreferrer"">https://pytorch-geometric.readthedocs.io/en/2.5.3/modules/datasets.html</a></p>
","2025-01-12 22:46:33","0","Answer"
"79348798","79227059","","<p><em>Hi</em>, this is a DFC version problem. For Yolo 11 you need the latest version which unfortunately doesn't work under wsl because of hailo_platform which we can't install. So for the moment, apart from switching to linux, we're limited to yolov10. And no, you didn't make a mistake by putting yolov11m with a v because hailo has the v (an aberration for me).</p>
","2025-01-11 20:02:34","0","Answer"
"79330414","79313662","","<p>It took me a while to realise that sometimes things are not as they clearly seem to be.<br />
Actually the weights of the first layer change at each iteration!</p>
<p>To convince yourself add these lines in allprints function:</p>
<pre><code>print(np.sum(np.abs(ww[1])))
print(ww[1][:5, 300:310])
</code></pre>
<p>As there are 784 columns in W1, the print is truncated to show only the first and last rows/columns. But dW1 = er[1].X / n with X the training data. The data are images of numbers in grey color on a black background and as the numbers are more or less centered, after flattening all the first and last few dozen numbers are 0 (black) for each image in the batch. When such a matrix is multiplied by another matrix we get 0 at the beginning and end of the rows. As W1 &lt;- W1 - lambda * dW1 the numbers we see on the truncated print don't change ... but many of the numbers not printed change.</p>
","2025-01-05 08:29:56","0","Answer"
"79321595","79318939","","<p>That error is due to the <code>mask_value</code> that you pass into <code>tf.keras.layers.Masking</code> not getting serialized compatibly for deserialization. But because you masking layer is a tensor containing all 0s anyway, you can instead just pass a scalar value like this and it will eliminate the need to serialize a tensor while storing the model</p>
<pre><code>tf.keras.layers.Masking(mask_value=0.0)
</code></pre>
<p>and it broadcasts it to effectively make it equivalent to comparing it against the tensor containing all 0s. <a href=""https://github.com/keras-team/keras/blob/f6c4ac55692c132cd16211f4877fac6dbeead749/keras/src/layers/core/masking.py#L54-L66"" rel=""nofollow noreferrer"">Here</a> is the source where the mask is applied like this</p>
<pre><code>ops.any(ops.not_equal(inputs, self.mask_value), axis=-1, keepdims=True)
</code></pre>
<p>and <code>ops.not_equal</code> supports broadcasting.</p>
","2025-01-01 12:31:48","1","Answer"
"79318939","","Loaded Keras Model Throws Error While Predicting (Likely Issues with Masking)","<p>I am currently developing and testing a RNN that relies upon a large amount of data for training, and so have attempted to separate my training and testing files. I have one file where I create, train, and save a <code>tensorflow.keras</code> model to a file <code>'model.keras'</code> I then load this model in another file and predict some values, but get the following error:
<code>Failed to convert elements of {'class_name': '__tensor__', 'config': {'dtype': 'float64', 'value': [0.0, 0.0, 0.0, 0.0]}} to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes</code></p>
<p>By the way, I have tried running <code>model.predict</code> with this exact same data in the file where I train the model, and it works smoothly. The model loading must be the problem, not the data used to predict.</p>
<p>This mysterious <code>float64</code> tensor is the value I passed into the masking layer. I don't understand why keras is unable to recognize this JSON object as a Tensor and apply the masking operation as such. I have included snippets of my code below, edited for clarity and brevity:</p>
<p>model_generation.py:</p>
<pre><code># Create model

model = tf.keras.Sequential([
    tf.keras.layers.Input((352, 4)),
    tf.keras.layers.Masking(mask_value=tf.convert_to_tensor(np.array([0.0, 0.0, 0.0, 0.0]))),
    tf.keras.layers.GRU(50, return_sequences=True, activation='tanh'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.GRU(50,activation='tanh'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(units=1, activation='sigmoid')])

# Compile Model...
# Train Model...
model.save('model.keras')

model.predict(data) # Line works here
</code></pre>
<p>model_testing.py</p>
<pre><code>model = tf.keras.models.load_model('model.keras')

model.predict(data) # this line generates the error
</code></pre>
<p>EDIT:</p>
<p>Moved the load command into the same file as the training, still receiving the exact same error message.</p>
","2024-12-31 00:53:11","1","Question"
"79313662","","Not reaching optimal parameter values for my neural network","<p>I am trying to create a classification neural network using only the NumPY library for it. I have completely made the network and worked through the logic of it, and it seems perfectly fine to me. I don't know what is causing it to not reach the optimal parameters value. One of the important things that I have noticed is that the weights in the first layer do not change whatsoever.</p>
<p>What could be causing the code to not work as it is supposed to?</p>
<pre><code>import numpy as np
from tensorflow.keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(x_train.shape[0], -1)
x_test = x_test.reshape(x_test.shape[0], -1)
x_train, x_test = x_train/255, x_test/255
print(x_train.shape)

from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(sparse_output=False)
ohe.fit(y_train.reshape(-1,1))
y_train = ohe.fit_transform(y_train.reshape(-1,1))
y_test = ohe.transform(y_test.reshape(-1,1))
print(y_train.shape)

def linear(x,deriv=False):
    return x

def relu(x,deriv=False):
    if deriv:
        return (x &gt; 0).astype(float)
    return np.maximum(0,x)

def softmax(x,deriv=False):
    xre = x - x.max(axis=0,keepdims=True)
    xexp = np.exp(xre)
    a = xexp.sum(axis=0,keepdims=True)
    prob = xexp/a
    return prob

def sigmoid(x,deriv=False):
    a = 1/(1+np.exp(-x))
    if deriv:
        return a * (1 - a)
    return a

activations = {'linear':linear,'relu':relu,'sigmoid':sigmoid,'softmax':softmax}

def initialvals(cols=784):
    shape = [cols,10,10]
    w = dict()
    b = dict()
    for i in range(len(shape)-1):
        w[i+1] = np.random.uniform(-0.5,0.5,(shape[i+1],shape[i]))

    for i in range(len(shape)-1):
        b[i+1] = np.zeros((shape[i+1],1))
    return w,b

def allprints(ww,bb):
    print('Weights')
    for i in ww:
        print(ww[i].shape)
    print('Biases')
    for i in bb:
        print(bb[i].shape)

    print('Weights')
    for i in ww:
        print(i)
        print(ww[i])
        print()
    print('Biases')
    for i in bb:
        print(i)
        print(bb[i])
        print()

def forprop(inputs,weight,bias,acts,av):
    z = dict()
    a = dict()
    
    z[0] = inputs.T
    a[0] = acts[av[0]](z[0])
    
    for i in range(1,len(weight)+1):
        z[i] = np.dot(weight[i],a[i-1]) + bias[i]
        a[i] = acts[av[i]](z[i])
    return z,a

def backprop(inputs, output, weight, bias, acts, av, size=50, iters=20, lr=0.01):
    n_samples = inputs.shape[0]
    global z_in
    for k in range(iters):
        shuff = np.random.permutation(n_samples)
        inputs = inputs[shuff]
        output = output[shuff]
        
        for i in range(0, n_samples, size): 
            batch_inputs = inputs[i:i + size]
            batch_output = output[i:i + size]
            z, a = forprop(batch_inputs, weight, bias, acts, av)
            z_in = z
            er = dict()
            er[len(bias)] = a[len(bias)] - batch_output.T 
            for j in range(len(bias)-1, 0, -1):
                er[j] = np.dot(weight[j + 1].T, er[j + 1]) * acts[av[j]](z[j], deriv=True)
                # delta_h = np.transpose(w_h_o) @ delta_o * (h * (1 - h))

            for j in range(1, len(bias) + 1):
                bias[j] -= lr * er[j].mean(axis=1, keepdims=True)
                weight[j] -= lr * (np.dot(er[j], a[j - 1].T) / batch_inputs.shape[0])
    return weight, bias, er ,z_in

we,be = initialvals()
allprints(we,be)
w_calc, b_calc, er, z= backprop(x_train,y_train,we,be,activations,['linear','sigmoid','softmax'])
allprints(w_calc,b_calc)
</code></pre>
<p>I have checked the error values as well as the shapes for the operations that doesn't seem to be the problem.</p>
<p>I have tried different learning rates as well as taking different batch sizes and I even tried the same setup using the tensorflow library and it was giving good predictions so the model structure is not the issue.</p>
<p>I also have tried to initialize my parameters in different ways like random.randn, zeros, etc.</p>
","2024-12-28 11:19:18","1","Question"
"79307055","78853571","","<p>Looks like dynamo_export is a bit buggy... or it doesn't really support earlier models.
Try using the original onnx export instead:</p>
<pre><code>x = torch.randn(&lt;your input dimensions&gt;)    

model.to('cpu') 

with torch.no_grad():
    torch_out = model(x)

    # Export the model
    torch.onnx.export(model,               # model being run
                    x,                         # model input (or a tuple for multiple inputs)
                    &quot;&lt;Your model name&gt;.onnx&quot;,   # where to save the model (can be a file or file-like object)
                    export_params=True,        # store the trained parameter weights inside the model file
                    opset_version=15,          # the ONNX version to export the model to
                    do_constant_folding=True,  # whether to execute constant folding for optimization
                    input_names = ['input'],   # the model's input names
                    output_names = ['output'], # the model's output names
                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes
                                    'output' : {0 : 'batch_size'}})
</code></pre>
","2024-12-25 07:26:58","0","Answer"
"79299666","79280552","","<p>This is just not possible because a dense layer has a fixed number of weights. When you call a dense layer after flattening, it is effectively doing</p>
<p><code>w_0 * x_0 + w_1 * x_1 + w_2 * x_2 + .... + w_n-1 * x_n-1 + bias</code> where the <code>w</code>s are the weights and the <code>x</code>s are the flattened input feature values.</p>
<p>So if due to your unknown dimension, <code>n</code> can't be known ahead of time, then it's just not possible for the network to be configured with the appropriate number of weights.</p>
<p>Even if you knew the &quot;max time&quot; and want to preallocate the number of weights in the network to support that, it would likely suffer from two problems</p>
<ol>
<li>the network gets too large</li>
<li>the network overfits because it is treating each pixel in each time step as a completely separate feature which is going to bloat up the dimensionality with no real benefits</li>
</ol>
<p>So the alternatives to capture the time axis would be to either make it a time-series network like LSTMs or recurrent neural networks, or a 3D convolution network which relies on pooling across time.</p>
","2024-12-21 15:40:32","1","Answer"
"79280552","","How to use a Dense layer with an input that has a dynamically sized dimension?","<p>I have a model with an input (batch of images w/ shape (height, width, time)) that has a dynamically sized dimension (time), which is only determined at runtime. However, the <code>Dense</code> layer requires fully defined spatial dimensions. Code snippet example:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten, Input

# Define an input with an undefined dimension (None)
input_tensor = Input(shape=(None, 256, 256, None, 13))

# Apply a Dense layer (which expects a fully defined shape)
x = Flatten()(input_tensor)
x = Dense(10)(x)

# Build the model
model = tf.keras.models.Model(inputs=input_tensor, outputs=x)

model.summary()
</code></pre>
<p>This raises the error:</p>
<pre><code>ValueError: The last dimension of the inputs to a Dense layer should be defined. Found None.
</code></pre>
<p>How can I make it work using <code>Flatten</code> instead of alternatives like <code>GlobalAveragePooling3D</code>? Essentially, I’m looking for a way to create a 1D array with the original pixel values, but compatible with the <code>Dense</code> layer.</p>
","2024-12-14 11:31:35","0","Question"
"79277820","79276015","","<p>By setting your RGB data to a default/constant value you'll very likely experience a performance drop compared to the &quot;original&quot; solution as your data are less qualitative. And indeed your model will be slower than a model using only XYZ data, as it has more parameters.</p>
","2024-12-13 09:35:53","0","Answer"
"79276015","","Handling Absence of Color Data in 3D Mesh Neural Network Input","<p>Context: I am using this neural network architecture developed by researchers called Dual Pyrimad Graph for a mesh segmentation task. The network expects the input to have 6 values: XYZ and RGB. I am training the network form 0 on my data as the network weights are not available, so there is no transfer learning.</p>
<p>Problem: My data lacks color only XYZ is available. I was trying to change the network layers architecture to match my input but realized that it is a tedious task as the guys who wrote it did that in Jittor not Pytorch or TensorFlow. I thought maybe I could put the colors all as 0 or all as gray 127 on the 3 color channels. I don't change the input add 1 color to it. I think if I do that learning wouldn't be affected as much. Granted I can get lower Accuracy compared to their colored data but I have no colors to begin with.</p>
<p>Question: How will this solution affect my training if compared to changing the network to suit the data? will learning become slower since I have more input features (though all of the same value)?</p>
","2024-12-12 17:18:51","-1","Question"
"79273101","79272927","","<p>Chat gpt solved  it:</p>
<pre><code>import tensorflow as tf
from tensorflow import keras

# Callback personalizado
class ExponentialLearningRate(keras.callbacks.Callback):
    def __init__(self, factor):
        super().__init__()
        self.factor = factor
        self.rates = []
        self.losses = []

    def on_batch_end(self, batch, logs=None):
        logs = logs or {}
        self.losses.append(logs.get(&quot;loss&quot;, None))

        # Obtener el valor de learning_rate y asegurarnos de que sea un número
        lr = self.model.optimizer.learning_rate
        if isinstance(lr, tf.Variable):
            lr = lr.numpy()  # Convertir a valor numérico si es un tf.Variable

        # Registrar la tasa de aprendizaje
        self.rates.append(lr)

        # Actualizar el learning rate
        if isinstance(lr, (float, int)):
            new_lr = lr * self.factor
            self.model.optimizer.learning_rate.assign(new_lr)  # Modificar learning_rate

# Modelo simple
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.Dense(300, activation=&quot;relu&quot;),
    keras.layers.Dense(100, activation=&quot;relu&quot;),
    keras.layers.Dense(10, activation=&quot;softmax&quot;)
])

# Compilar modelo
model.compile(
    loss=&quot;sparse_categorical_crossentropy&quot;,
    optimizer=keras.optimizers.SGD(learning_rate=1e-3),
    metrics=[&quot;accuracy&quot;]
)

# Crear el callback
expon_lr = ExponentialLearningRate(factor=1.005)

# Ajustar modelo
history = model.fit(
    X_train, y_train,
    epochs=1,
    validation_data=(X_valid, y_valid),
    callbacks=[expon_lr]
)

</code></pre>
","2024-12-11 20:30:06","0","Answer"
"79272927","","AttributeError: 'str' object has no attribute 'name' while fitting a deep learning model","<p>I'm starting to study neural networks. I am reviewing exercise 10 of chapter 10 of the book Hands-on
Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition. I am trying to run the answer shown in the github but I het an error un line: istory = model.fit(X_train, y_train, epochs=1,
validation_data=(X_valid, y_valid),
callbacks=[expon_lr])</p>
<pre><code>K = keras.backend

class ExponentialLearningRate(keras.callbacks.Callback):
    def __init__(self, factor):
        self.factor = factor
        self.rates = []
        self.losses = []
    def on_batch_end(self, batch, logs):
        self.rates.append(K.get_value(self.model.optimizer.learning_rate))
        self.losses.append(logs[&quot;loss&quot;])
        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)

keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),  # Capa de entrada
    keras.layers.Dense(300, activation=&quot;relu&quot;),  # Primera capa oculta
    keras.layers.Dense(200, activation=&quot;relu&quot;),  # Segunda capa oculta
    keras.layers.Dense(10, activation=&quot;softmax&quot;) # Capa de salida
])

model.compile(loss=&quot;sparse_categorical_crossentropy&quot;,
              optimizer=keras.optimizers.SGD(learning_rate=1e-3),
              metrics=[&quot;accuracy&quot;])

expon_lr = ExponentialLearningRate(factor=1.005)

history = model.fit(X_train, y_train, epochs=1,
                    validation_data=(X_valid, y_valid),
                    callbacks=[expon_lr])

plt.plot(expon_lr.rates, expon_lr.losses)
plt.gca().set_xscale('log')
plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))
plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])
plt.grid()
plt.xlabel(&quot;Learning rate&quot;)
plt.ylabel(&quot;Loss&quot;)
</code></pre>
<p>The error:</p>
<pre><code>
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-14-a0cc0ada5ef0&gt; in &lt;cell line: 1&gt;()
----&gt; 1 history = model.fit(X_train, y_train, epochs=1,
      2                     validation_data=(X_valid, y_valid),
      3                     callbacks=[expon_lr])

1 frames
&lt;ipython-input-6-f87513637cd3&gt; in on_batch_end(self, batch, logs)
      9         self.rates.append(K.get_value(self.model.optimizer.learning_rate))
     10         self.losses.append(logs[&quot;loss&quot;])
---&gt; 11         K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)

AttributeError: 'str' object has no attribute 'name'
</code></pre>
<p>I expect it to work as I literally copy and paste the code from the book github. ¿Maybe is becase of the tensorflow version?</p>
","2024-12-11 19:18:57","0","Question"
"79263214","79255843","","<p>By changing the hidden layers <strong>from relu to sigmoid</strong>, you ensure that each layer applies a nonlinear transformation over the entire input range. With relu, there is the possibility that the model enters a regime where a large portion of the neurons fire linearly (for example, if the values ​​are all in the positive region, relu basically behaves like the identity function). This can lead to the model, in practice, behaving almost linearly, especially if the initialization of the weights and the distribution of the data results in a saturation of the neurons in a linear region of the relu.</p>
<p>In contrast, sigmoid always introduces curvature (nonlinearity), compressing the output values ​​to a range between 0 and 1. This makes it difficult for the network to stagnate in linear behavior, since even with subtle changes in the weights, the sigmoid function maintains a non-linear mapping between input and output.</p>
","2024-12-08 19:31:34","0","Answer"
"79255843","","Problem with tensorflow non linearity Apple M4 Chips","<p>I have a problem with the result of non-linear(sigmoid) Neural Network Classification in tensorflow. I suspect is a problem with the M chip and my instalation but I tried several versions using miniforge and miniconda and conda.
Also I installed <code>tensorflow-macos and tensorflow-metal</code> in my conda environment</p>
<p>I check my requirements systems:</p>
<ul>
<li>Macbook pro Apple M4 chip Sequoia 15.1.1</li>
<li><strong>Python platform:</strong> macOS-15.1.1-arm64-arm-64bit</li>
<li><strong>Tensor flow</strong> v: 2.16.2</li>
<li><strong>Keras version:</strong> 3.7.0</li>
<li><strong>Python</strong> 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:20:01) [Clang 18.1.8 ]</li>
<li><strong>Pandas</strong> 2.2.3</li>
<li><strong>Sckikit learn</strong> 1.5.2</li>
<li><strong>GPU</strong> is,available</li>
</ul>
<p>I run the same code in my Local Jupyter and in <a href=""https://colab.research.google.com/drive/1q8BBqy3GDK0fR3OfyW2MWuFwWJ6H4HZG#scrollTo=QchlvR2o1o8L"" rel=""nofollow noreferrer"">Colab google</a> but results are different.</p>
<p><a href=""https://i.sstatic.net/xwK6bIiI.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/xwK6bIiI.png"" alt=""Classification from Collab Google"" /></a></p>
<p><a href=""https://i.sstatic.net/v87Yb9Wo.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/v87Yb9Wo.png"" alt=""Classification from my local jupyter"" /></a></p>
<p>My python function to visualize is this. as you can see the function is from a course. No other users has problems with the function.</p>
<pre><code>def plot_decision_boundary(model, X, y):
  &quot;&quot;&quot;
  Plots the decision boundary created by a model predicting on X.
  This function has been adapted from two phenomenal resources:
   1. CS231n - https://cs231n.github.io/neural-networks-case-study/
   2. Made with ML basics - https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb
  &quot;&quot;&quot;
  # Define the axis boundaries of the plot and create a meshgrid
  x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1
  y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1
  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                       np.linspace(y_min, y_max, 100))

  # Create X values (we're going to predict on all of these)
  x_in = np.c_[xx.ravel(), yy.ravel()] # stack 2D arrays together: https://numpy.org/devdocs/reference/generated/numpy.c_.html

  # Make predictions using the trained model
  y_pred = model.predict(x_in)

  # Check for multi-class
  if model.output_shape[-1] &gt; 1: # checks the final dimension of the model's output shape, if this is &gt; (greater than) 1, it's multi-class
    print(&quot;doing multiclass classification...&quot;)
    # We have to reshape our predictions to get them ready for plotting
    y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)
  else:
    print(&quot;doing binary classifcation...&quot;)
    y_pred = np.round(np.max(y_pred, axis=1)).reshape(xx.shape)

  # Plot decision boundary
  plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)
  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)
  plt.xlim(xx.min(), xx.max())
  plt.ylim(yy.min(), yy.max())
</code></pre>
<p>My code for neural network is this :</p>
<pre><code>tf.random.set_seed(42)

model3 = tf.keras.Sequential([
    tf.keras.layers.Dense(12, activation=&quot;relu&quot;),
    tf.keras.layers.Dense(8, activation=&quot;relu&quot;),
    tf.keras.layers.Dense(1, activation=&quot;sigmoid&quot;)
])

model3.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),
    metrics = [&quot;accuracy&quot;]
)

history = model3.fit(X, y, epochs=100)
</code></pre>
","2024-12-05 18:25:47","0","Question"
"79255838","79249247","","<p>Yes, the input layer needs to be size 49.  The output layer needs to be size 1.  Then it'll work for both the train and test data.</p>
","2024-12-05 18:24:04","-1","Answer"
"79249868","79248710","","<p>Assume you don't reshape. Your model outputs <code>y_pred</code> of size <code>(batch_size, 1)</code>. Your <code>y</code> tensor is shape <code>(batch_size,)</code> - missing the unit axis. The axis difference causes the <code>y</code> tensor to be broadcast along <code>y_pred</code>, which is wrong. When you compute <code>(y_pred - y)</code>, you get a tensor of shape <code>(batch_size, batch_size)</code>, comparing every <code>y</code> value to every <code>y_pred</code> value.</p>
<p>When you reshape, you get a <code>y</code> tensor with shape <code>(batch_size, 1)</code>. This results in the correct loss computation where <code>(y_pred - y)</code> has shape <code>(batch_size, 1)</code>.</p>
<pre class=""lang-py prettyprint-override""><code>ncols = 8
n_neurons = 150
model = torch.nn.Sequential(
    torch.nn.Linear(ncols, n_neurons),
    torch.nn.ReLU(),
    torch.nn.Linear(n_neurons, 1) # model outputs tensor of shape `(batch_size, 1)`
)

batch_size = 64
x = torch.randn(batch_size, ncols)
y = torch.randn(batch_size) # y is shape `(batch_size)`

y_pred = model(x)
print(y.shape, y_pred.shape) # pred and target different shapes
# &gt; torch.Size([64]) torch.Size([64, 1])

loss = (y_pred - y).pow(2)
print(loss.shape) # this causes the loss to broadcast
# &gt; torch.Size([64, 64])

y_reshaped = y.reshape(-1, 1)
print(y_reshaped.shape) # when you reshape the axes match
# &gt; torch.Size([64, 1])

loss = (y_pred - y_reshaped).pow(2)
print(loss.shape) # we get the correct loss shape
# &gt; torch.Size([64, 1])
</code></pre>
","2024-12-04 04:14:26","1","Answer"
"79249247","","How do I make a neural network class with fit and predict functions like with sklearn models, when my train and test data are different sizes?","<p>I'm trying to make a neural network model that will answer a linear regression problem (I've already made a model using <code>sklearn</code>'s <code>LinearRegression</code> and I'd like to compare the two).  Ultimately I'd like to make a class with <code>fit</code> and <code>predict</code> functions, as with the models in <code>sklearn</code>, so that I can make a loop that will test all the models I am using in my project.</p>
<p>To do this I followed the code in the answer to this question: <a href=""https://stackoverflow.com/questions/73493198/writing-a-pytorch-neural-net-class-that-has-functions-for-both-model-fitting-and"">Writing a pytorch neural net class that has functions for both model fitting and prediction</a>.
With some modifications, here is what I have:</p>
<pre class=""lang-py prettyprint-override""><code>import torch
import torch.nn as nn
import torch.optim as optim

class MyNeuralNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(2, 4, bias=True)
        self.layer2 = nn.Linear(4, 1, bias=True)
        self.loss = nn.MSELoss()
        self.compile_()

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        return x.squeeze()

    def fit(self, x, y):
        x = torch.tensor(x.values, dtype=torch.float32)
        y = torch.tensor(y.values, dtype=torch.float32)
        losses = []
        for epoch in range(100):
            ## Inference
            res = self.forward(x)#self(self,x)
            loss_value = self.loss(res,y)

            ## Backpropagation
            loss_value.backward() # compute gradient
            self.opt.zero_grad()  # flush previous epoch's gradient
            self.opt.step()       # Perform iteration using gradient above

            ## Logging
            losses.append(loss_value.item())
        
    def compile_(self):
        self.opt = optim.SGD(self.parameters(), lr=0.01)
       
    def predict(self, x_test):
        self.eval()
        y_test_hat = self(x_test)
        return y_test_hat.detach().numpy()
        # self.train()
</code></pre>
<p>Note, you also need <code>numpy</code>, I just don't have it here because this code was put into a separate .py file.</p>
<p>Here is how I used the model, after importing my class:</p>
<pre><code>model = MyNeuralNet()
X_train = # pandas dataframe with 1168 rows and 49 columns
y_train = # pandas dataframe with 1168 rows and 1 column
X_test = # pandas dataframe with 292 rows and 49 columns
model.fit(X_train, y_train)
pred = model.predict(X_test)
print(pred)
</code></pre>
<p>The error I got is <code>RuntimeError: mat1 and mat2 shapes cannot be multiplied (1168x49 and 2x4)</code> at the <code>fit</code> step.  I understand this has to do with the parameters for the linear layers of my network.  I think if I change my input size for the first linear layer to 49 and my output size for the second linear layer to 1168 then it will work for the <code>fit</code> step (or at least something like that, to match the sizes of the train data).  However, my test data is of a different size and I'm pretty sure then the <code>predict</code> step won't work.</p>
<p>Is it possible to make a neural network class where the training and test data are of different sizes?</p>
","2024-12-03 21:41:10","0","Question"
"79248710","","Reshaping out tensor in pytorch produces weird behavior","<p>I was going through <a href=""https://github.com/parrt/fundamentals-of-deep-learning/blob/main/notebooks/3.train-test-diabetes.ipynb"" rel=""nofollow noreferrer"">https://github.com/parrt/fundamentals-of-deep-learning/blob/main/notebooks/3.train-test-diabetes.ipynb</a> as an exercise, but forgot to reshape y tensors in these lines</p>
<pre><code>y_train = torch.tensor(y_train).float().reshape(-1,1) # column vector
y_test = torch.tensor(y_test).float().reshape(-1,1)
</code></pre>
<p>And my model just stopped learning early on, loss was not improving in training. Does anyone understand what's the effect of those <code>reshape()</code> calls, how do I avoid this bug in the future?</p>
<p>Full code and comments below:</p>
<pre><code>def train1(model, X_train, X_test, y_train, y_test,
           learning_rate = .5, nepochs=2000):
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    history = [] # track training and validation loss
    for epoch in range(nepochs+1):
        y_pred = model(X_train)
        loss = torch.mean((y_pred - y_train)**2)
        y_pred_test = model(X_test)
        loss_test = torch.mean((y_pred_test - y_test)**2)
        history.append((loss, loss_test))
        if epoch % (nepochs//10) == 0:
            print(f&quot;Epoch {epoch:4d} MSE train loss {loss:12.3f}   test loss {loss_test:12.3f}&quot;)
            
        optimizer.zero_grad()
        loss.backward() # autograd computes w1.grad, b1.grad, ...
        optimizer.step()
    return torch.tensor(history)


ncols = X_train.shape[1]
n_neurons = 150
model2 = torch.nn.Sequential(
    torch.nn.Linear(ncols, n_neurons),
    torch.nn.ReLU(),
    torch.nn.Linear(n_neurons, 1)
)

d = load_diabetes()
df = pd.DataFrame(d.data, columns=d.feature_names)
df['disease'] = d.target # &quot;quantitative measure of disease progression one year after baseline&quot;
print (df.head(3))


np.random.seed(1) # set a random seed for consistency across runs
n = len(df)
X = df.drop('disease',axis=1).values
y = df['disease'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) 


m = np.mean(X_train,axis=0)
std = np.std(X_train,axis=0)
X_train = (X_train-m)/std
X_test = (X_test-m)/std      


X_train = torch.tensor(X_train).float()
X_test = torch.tensor(X_test).float()

# HERE !!!!!!
# without reshape: train loss doesn't emprove beyond epoch 800, loss=6074 
# y_train = torch.tensor(y_train).float()
# y_test = torch.tensor(y_test).float()
# print (y_train.shape, y_test.shape) # torch.Size([353]) torch.Size([89])

# with reshape, train loss goes down to 7
y_train = torch.tensor(y_train).float().reshape(-1,1) # column vector
y_test = torch.tensor(y_test).float().reshape(-1,1)
print (y_train.shape, y_test.shape) # torch.Size([353]) torch.Size([89])

########################################################################




history = train1(model2, X_train, X_test, y_train, y_test,
                 learning_rate=.02, nepochs=8000)

# Epoch    0 MSE train loss    29603.037   test loss    26998.922
# Epoch  800 MSE train loss     2133.840   test loss     3174.325
# Epoch 1600 MSE train loss     1423.420   test loss     4316.454
# Epoch 2400 MSE train loss      375.720   test loss     7257.883
# Epoch 3200 MSE train loss      120.477   test loss     9051.368
# Epoch 4000 MSE train loss       57.527   test loss    10240.634
# Epoch 4800 MSE train loss       31.486   test loss    10784.966
# Epoch 5600 MSE train loss       16.044   test loss    11113.780
# Epoch 6400 MSE train loss        8.490   test loss    11283.872
# Epoch 7200 MSE train loss        6.594   test loss    11503.454
# Epoch 8000 MSE train loss        3.513   test loss    11644.484
</code></pre>
","2024-12-03 17:54:12","0","Question"
"79239619","79238246","","<p>If you fit t-SNE separately for each embedding set, you’ll preserve the internal structure of each embedding space, as the optimization is independent. However, scatter plots from this method are not directly comparable because t-SNE outputs are non-deterministic and embedding spaces can be arbitrarily rotated, flipped, or scaled. While you can examine clusters in isolation, you won't gain insight into the relationship between the two embedding sets.</p>
<p>If you fit t-SNE on both embedding sets together, the embeddings are projected into a shared low-dimensional space. This allows direct visual comparison, making it easier to observe whether embeddings from both GNNs cluster similarly. However, this approach risks distorting the internal structure of individual embedding spaces, especially if the embeddings differ significantly. The t-SNE algorithm will balance the relationships between and within the two sets, potentially <strong>introducing artifacts</strong>.</p>
<p>The choice depends on your objective. For independent analysis of internal structures, fit t-SNE separately. For relational comparisons in a shared space, fit t-SNE jointly.</p>
<p>To complement the visualization, you'd better include quantitative metrics like cosine similarity or cluster purity to reinforce your observations, as visualizations should be treated as exploratory tools rather than conclusive evidence.</p>
","2024-11-30 13:18:42","1","Answer"
"79238246","","Do I fit t-SNE the two sets of embeddings from two different models at the same time or do I fit each separately then visualize and compare?","<p>I have two sets of embeddings from two different GNNs. I want to compare the embeddings by visualization and I want to know which way is the most appropriate way for comparison. Do I fit t-SNE separately for each set of embedding then use the scatter plot? Or do I fit them all into one t-SNE?</p>
","2024-11-29 20:03:37","1","Question"
"79232183","79232069","","<p>The inplace operation is this:</p>
<pre class=""lang-py prettyprint-override""><code>out += shortcut
</code></pre>
<p>The <code>relu</code> needs its own output to compute its gradient! Thus you are doing an inplace operation on the output of the relu, which it needed to compute its gradient in the backwards pass.</p>
<p>replacing it with</p>
<pre class=""lang-py prettyprint-override""><code>out = out + shortcut
</code></pre>
<p>should solve your problem.</p>
<p>In general, try to avoid using inplace functions in pytorch (such as <code>+=</code> unless you know what you are doing</p>
<hr />
<p><em>more details:</em></p>
<p>if you look at the pytorch code, the backwards pass for the relu is auto-generated from the following bit of code in <code>pytorch/tools/autograd/derivatives.yaml</code></p>
<pre class=""lang-yaml prettyprint-override""><code>- name: relu(Tensor self) -&gt; Tensor
  self: threshold_backward(grad, result, 0)
  result: auto_element_wise
</code></pre>
<p>What this does is it</p>
<ul>
<li>takes the gradient of the output as <code>grad</code></li>
<li>and the result of the relu as <code>result</code></li>
<li>and returns the contents of <code>grad</code> where <code>result</code> is bigger than <code>0</code> and <code>0</code> otherwise.</li>
</ul>
<p>Thus it does need the output (technically, it could have stored its input instead, but this is how it is implemented)</p>
","2024-11-27 23:40:24","1","Answer"
"79232069","","Autograd error caused by ReLU in Pytorch?","<p>I am using a residual neural network for a classification task. Somehow adding or omitting a ReLU activation causes the autograd to fail. I would be grateful for any insights on the reason for this? It cannot make any sense of it. ReLU is not an inplace operation, is it? Error message:
<code>RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation</code></p>
<p>Here is the network architecture. The 3rd to last line is what causes the issue when not commented out.</p>
<pre><code>class ResidualBlock(nn.Module):
    def __init__(self, num_filters, kernel_size):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv1d(num_filters, num_filters, kernel_size=kernel_size, padding='same')
        self.bn1 = nn.BatchNorm1d(num_filters)
        self.conv2 = nn.Conv1d(num_filters, num_filters, kernel_size=kernel_size, padding='same')
        self.bn2 = nn.BatchNorm1d(num_filters)

    def forward(self, x):
        shortcut = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out = F.relu(out) # causes the issue when not commented out
        out += shortcut
        return out
</code></pre>
<p>Below is a minimal working example. I am using Python 3.12 and torch 2.5.1.</p>
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset

# Define the ResidualBlock
class ResidualBlock(nn.Module):
    def __init__(self, num_filters, kernel_size):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv1d(num_filters, num_filters, kernel_size=kernel_size, padding='same')
        self.bn1 = nn.BatchNorm1d(num_filters)
        self.conv2 = nn.Conv1d(num_filters, num_filters, kernel_size=kernel_size, padding='same')
        self.bn2 = nn.BatchNorm1d(num_filters)

    def forward(self, x):
        shortcut = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out = F.relu(out) # causes the issue
        out += shortcut
        return out


class SimpleModel(nn.Module):
    def __init__(self, num_filters, kernel_size):
        super(SimpleModel, self).__init__()
        self.res_block = ResidualBlock(num_filters, kernel_size)
        self.fc = nn.Linear(num_filters, 1)

    def forward(self, x):
        x = self.res_block(x)
        x = x.mean(dim=2)
        x = self.fc(x)
        return x

torch.manual_seed(42)
num_samples = 1000
sequence_length = 32
num_filters = 16

X = torch.randn(num_samples, num_filters, sequence_length)  # Random input
y = torch.sum(X, dim=(1, 2), keepdim=True)  # Simple target (sum of all values)


dataset = TensorDataset(X, y)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)


model = SimpleModel(num_filters=num_filters, kernel_size=3)
criterion = nn.MSELoss() 
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)


epochs = 5
for epoch in range(epochs):
    model.train()
    epoch_loss = 0.0
    for batch_X, batch_y in dataloader:
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    print(f&quot;Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader):.4f}&quot;)

print(&quot;Training complete!&quot;)
</code></pre>
","2024-11-27 22:34:48","1","Question"
"79227059","","How do I compile yolov11m .onnx to .hef, using hailomz","<p><a href=""https://i.sstatic.net/oEsmM9A4.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/oEsmM9A4.jpg"" alt=""Error snippet on my terminal"" /></a></p>
<p><code>hailomz compile: error: argument model_name: invalid choice: 'yolov11m'</code></p>
<p>I am trying to compile yolov11m model from .onnx to .hef using hailomz. But it says that the model name &quot;yolov11m&quot; is not valid. Probably due to the fact that it's a latest release and the valid names listed are previous yolo models. What is a work around this?</p>
<p><code>hailomz compile yolov11m --ckpt=best.onnx --hw-arch hailo8l --classes 12 --performance --calib-path /home/User_1/AI_Project/images/</code></p>
","2024-11-26 14:13:25","0","Question"
"79188305","78896296","","<p>The error occurs because <code>network_</code>1 and <code>network_2</code> are not yet built. In keras, layers in a sequential model are not instantiated until the model is called on some input data. when you try to access the <code>.output</code> attribute of a sequential model you need to build or called it manually before accessing it. Please refer to this <a href=""https://colab.sandbox.google.com/gist/Kayyuri/edd7d175fed8bd40bcb33d27e25d8990/78896296.ipynb"" rel=""nofollow noreferrer"">gist</a>.</p>
","2024-11-14 10:24:11","0","Answer"
"79186816","79182980","","<p>Okay so I managed to fix my own issues with the help of chatGPT:</p>
<p>I had a few typos in there, notably in the update_params() function where I updated the derivatives instead of updating the actual layers.</p>
<p>Bias Update Issue:
There's a potential issue in your update_params function for updating the biases:</p>
<pre><code>db1 = b1 - alpha * db1
</code></pre>
<p>This line should be:</p>
<pre><code>b1 = b1 - alpha * db1
</code></pre>
<p>Similarly, check db2 to ensure:</p>
<pre><code>b2 = b2 - alpha * db2
</code></pre>
<p>Since the wrong variables are being updated, the biases remain unchanged during training, preventing effective learning.</p>
<p>What really changed the game though was these next two points:</p>
<p>Weight Initialization:
Ensure that your weight initialization does not produce too large or too small values. A standard approach is to scale weights by ​sqrt(1/n), where:</p>
<p>n is the number of inputs for a given layer.</p>
<pre><code>W1 = np.random.randn(10, 784) * np.sqrt(1 / 784)
W2 = np.random.randn(10, 10) * np.sqrt(1 / 10)
</code></pre>
<p>This prevents issues with vanishing/exploding gradients.</p>
<p>This was a game changer along with this:</p>
<p>Data Normalization:
Make sure your input data X (pixels in this case) are normalized. Often, pixel values range from 0 to 255, so you should divide your input data by 255 to keep values between 0 and 1.</p>
<pre><code>X_train = X_train / 255.0
</code></pre>
<p>This normalization often helps stabilize learning.</p>
<p>And there you have it. I am able to get 90% accuracy within 100 iterations. I'm going to now test different activation functions and find the most adequate. Thank you chatGPT.</p>
","2024-11-13 22:00:12","1","Answer"
"79182980","","Numpy neural network not learning (stuck on 10% accuracy) - Python","<p>So I am trying to build a basic ANN using numpy. The thing is I keep getting an accuracy prediction of around 10% and I don't understand why that is. Here is all the code.</p>
<pre><code>import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

data = pd.read_csv('train.csv')

data = np.array(data)
m, n = data.shape
np.random.shuffle(data)

data_train = data.T
X_train = data_train[1:n]
Y_train = data_train[0]

def init_params():
    W1 = np.random.randn(10, 784)
    b1 = np.random.rand(10, 1)
    W2 = np.random.randn(10, 10)
    b2 = np.random.randn(10, 1)
    return W1, b1, W2, b2

def ReLU(Z):
    return np.maximum(0, Z)

def softmax(Z):
        e = np.exp(Z - Z.max(axis=0, keepdims=True))
        return e/e.sum(axis=0, keepdims=True)

def forward_prop(W1, b1, W2, b2, X):
    Z1 = W1.dot(X) + b1
    A1 = ReLU(Z1)
    Z2 = W2.dot(A1) + b2
    A2 = softmax(Z2)
    return Z1, A1, Z2, A2

def one_hot(Y):
    one_hot_Y = np.zeros((Y.size, Y.max() + 1))
    one_hot_Y[np.arange(Y.size), Y] = 1
    one_hot_Y = one_hot_Y.T
    return one_hot_Y

def deriv_ReLU(Z):
    return (Z &gt; 0).astype(int)


def back_prop(Z1, A1, Z2, A2, W2, X, Y):
    m = Y.size
    one_hot_Y = one_hot(Y)
    dZ2 = A2 - one_hot_Y
    dW2 = 1 / m * dZ2.dot(A1.T)
    db2 = 1 / m * np.sum(dZ2, 1).reshape(-1, 1)
    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)
    dW1 = 1 / m * dZ1.dot(X.T)
    db1 = 1 / m * np.sum(dZ1, 1).reshape(-1, 1)
    return dW1, db1, dW2, db2

def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):
    W1 = W1 - alpha * dW1
    db1 = b1 - alpha * db1
    W2 = W2 - alpha * dW2
    db2 = b2 - alpha * db2
    return W1, b1, W2, b2

def get_predictions(A2):
    return np.argmax(A2, 0)

def get_accuracy(predictions, Y):
    print(predictions, Y)
    return np.sum(predictions == Y) / Y.size

def gradient_descent(X, Y, iterations, alpha):
    W1, b1, W2, b2 = init_params()
    for i in range(iterations):
        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)
        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X, Y)
        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)
        if (i % 50):
            print(f'Iteration: {i}')
            print(f'Accuracy: {get_accuracy(get_predictions(A2), Y)}')
    return W1, b1, W2, b2

W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 100, 0.1)
</code></pre>
<p>I thought that it may be an issue with the data I was using, but after trying new data it isn't. SO clearly somewhere in the back propagation (I'm guessing) I messed something up and switched some variables. The data being used is MNIST data set of handwritten numbers and there are 10 classes.
I did a little bit more digging and I noticed that actually the model seems to be outputting a single number as a prediction the whole time. I don't understand why.</p>
","2024-11-12 23:07:22","-3","Question"
"79177263","79176888","","<p>That depends on how the loss (<code>cross_entropy_error</code>) is defined for a (mini-)batch. The most common convention[*] is that the loss for a batch is the average of losses for all items in the batch (rather than the sum, or the average over the whole dataset). So you get a constant factor of <code>1/batch_size</code>, which then also appears in the backward pass (in the computation of the last gradient, which then influences all other gradients with the same constant factor).</p>
<p>Effectively, changing that constant is the same as changing the learning rate. The <em>'mean over batch'</em> convention arguably makes the choice of learning rate a bit more predictable, but in general the topic of how the learning rate should be chosen depending on batch size is <a href=""https://stackoverflow.com/questions/53033556/how-should-the-learning-rate-change-as-the-batch-size-change"">not simple</a>.</p>
<p>[*] E.g. in PyTorch, <a href=""https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html"" rel=""nofollow noreferrer"">CrossEntropyLoss</a> defaults to <code>reduction='mean'</code>. Similarly in <a href=""https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class"" rel=""nofollow noreferrer"">Keras</a>, <code>reduction=&quot;sum_over_batch_size&quot;</code>.</p>
<p>Side note: in the computation graph in the case of a batch, you would have a copy of each activation node for every item in the batch (since activations are different for different items), and you would have a single final 'mean' reduction node (or two nodes: sum and divide).</p>
","2024-11-11 10:23:50","2","Answer"
"79176888","","Why do we divide by batch_size in the backward pass of Softmax with Cross-Entropy Loss?","<p>In the implementation of the <code>SoftmaxWithLoss</code> layer, I noticed that the gradient in the backward pass is divided by <code>batch_size</code>. Here's the code for reference:</p>
<pre><code>class SoftmaxWithLoss:
    def __init__(self):
        self.loss = None  # Variable to store the loss value
        self.y = None     # Variable to store the output of the softmax function
        self.t = None     # Variable to store the target (label) data, which is expected to be a one-hot vector

    def forward(self, x, t):
        self.t = t               # Store the target data
        self.y = softmax(x)      # Apply softmax to input 'x' to get the probabilities
        self.loss = cross_entropy_error(self.y, self.t)  # Calculate the cross-entropy loss

        return self.loss         # Return the loss value

    def backward(self, dout=1):
        batch_size = self.t.shape[0]              # Get the batch size
        dx = (self.y - self.t) / batch_size       # Calculate the gradient of the loss with respect to input 'x'

        return dx                                 # Return the gradient

</code></pre>
<p>I follow the <a href=""https://i.sstatic.net/fmibQq6t.png"" rel=""nofollow noreferrer"">computational graph</a>. I think that it should just return <em>y - t</em> .</p>
","2024-11-11 08:30:04","0","Question"
"79171014","79167526","","<p>From <a href=""https://redd.it/1glx8ul"" rel=""nofollow noreferrer"">https://redd.it/1glx8ul</a>:</p>
<blockquote>
<p>bf16 requires avx512 instruction set (<a href=""https://redd.it/1glx8ul"" rel=""nofollow noreferrer"">Tacx79</a>)</p>
</blockquote>
<p>and as mentioned on <a href=""https://knowledge.alteryx.com/index/s/article/Alteryx-and-MacOS#:%7E:text=Apple%20Silicon%20(M1%2C%20M2),and%20therefore%20will%20encounter%20issues."" rel=""nofollow noreferrer"">knowledge.alteryx.com</a>:</p>
<blockquote>
<p>Apple Silicon (M1, M2) chips use ARM architecture, do not support AVX instructions</p>
</blockquote>
<p>unlike F16, which has been around for <a href=""https://www.reddit.com/r/LocalLLaMA/comments/1glx8ul/why_do_bf16_models_have_slower_inference_on_mac/lvxvx9l/"" rel=""nofollow noreferrer"">much longer</a>.</p>
","2024-11-08 17:26:19","-1","Answer"
"79167526","","Why do BF16 models have slower inference on Mac M-series chips compared to F16 models?","<p>I read on <a href=""https://github.com/huggingface/smollm/tree/main/smol_tools"" rel=""nofollow noreferrer"">https://github.com/huggingface/smollm/tree/main/smol_tools</a> (<a href=""https://i.sstatic.net/FExBWsVo.png"" rel=""nofollow noreferrer"">mirror 1</a>):</p>
<blockquote>
<p>All models are quantized to 16-bit floating-point (F16) for efficient inference. Training was done on BF16, but in our tests, this format provides slower inference on Mac M-series chips.</p>
</blockquote>
<p>Why do BF16 models have slower inference on Mac M-series chips compared to F16 models?</p>
","2024-11-07 17:32:30","-2","Question"
"79166453","","VAalue_Error: as_list() is not defined on an unknown TensorShape when using dataset generator","<p>There are a number of previous answers to this error but none relate to my issue.</p>
<p>I am creating a tensorflow dataset using a generator and for the examples sake am trying fit a very simple API model.</p>
<p>The dataset looks like this:</p>
<pre><code>for example in ds.take(1):
    print(example[0], example[1])
</code></pre>
<p>Outputs:</p>
<pre><code>{'LoB': &lt;tf.Tensor: shape=(1,), dtype=int32, numpy=array([5], dtype=int32)&gt;, 
'cc': &lt;tf.Tensor: shape=(1,), dtype=int32, numpy=array([17], dtype=int32)&gt;, 
'inj_part': &lt;tf.Tensor: shape=(1,), dtype=int32, numpy=array([41], dtype=int32)&gt;, 
'age': &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.3495796], dtype=float32)&gt;, 'RepDel': &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.26196158], dtype=float32)&gt;, 
'dev_year_predictor': &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([-1.2747549], dtype=float32)&gt;, 
'cum_loss': &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.8005615], dtype=float32)&gt;} 
tf.Tensor([5.], shape=(1,), dtype=float32)
</code></pre>
<p>When I run this simple model:</p>
<pre><code>inputs = layers.Input(shape=(1, ), name=&quot;LoB&quot;)
output = layers.Dense(1, activation=&quot;linear&quot;)(inputs)
test = models.Model(inputs=inputs, outputs=output)

test.compile(loss=&quot;mse&quot;, optimizer=&quot;sgd&quot;)

test.fit(ds, epochs=5, verbose=True)
</code></pre>
<p>I get the error:
ValueError: as_list() is not defined on an unknown TensorShape</p>
<p>I managed to fix this by reshaping the tensors to shape=(1,), but I changed the way the dataset generator functions and it broke again. I cannot see any tensors in my dataset with unknown shape hence I am confused.</p>
<p>The Dataset was constructed from tabular data like this (simplified version but I still get the error):</p>
<pre><code>def create_tensor(seq):

    LoB=seq[&quot;LoB&quot;].values[0]
    target=seq[target].values[-1]
    return {&quot;LoB&quot;: LoB}, target

def pad_and_format(seq):
    
    x, y = seq
    x[&quot;LoB&quot;] = tf.reshape(x[&quot;LoB&quot;], shape=(1,))
    y = tf.reshape(y, shape=(1,))
    return x,y

def generator():
    
    for i in range(train_df[&quot;ClNr_sub&quot;].max()+1):
        seq=train_df[train_df[&quot;ClNr_sub&quot;] == i]
        seq=create_tensor(seq)
        seq=pad_and_format(seq)
        yield seq

ds = tf.data.Dataset.from_generator(generator, 
                        output_types=({'LoB': tf.int32}, tf.float32))
</code></pre>
","2024-11-07 12:35:24","0","Question"
"79164582","79162036","","<p>Try Image hashing it creates a compact, fixed-length hash that represents an image's visual features. I have used it on images of BIOS it worked well in my case.</p>
","2024-11-06 23:21:40","-1","Answer"
"79162036","","Efficient way to compare two similar images","<p>I want to recognize boxes in images. I have a database for these boxes, storing their ocr and images. I do search and get a rough transformation of the face using ocr. It works fine most of the time, but sometimes it returns wrong face and wrong transformation. As I have the source images, I want to take advantage of them to evaluate the search recognition result. I transformed the detected box area to the source image and resized them to same size (so they are from similar perspective, similar size).  I used hog, the second last layer of alexnet, vitmae, and my self-trained conv network as the embedding feature. But all of them does not work well. I also tried keypoint features. But it takes much longer than the requirement. Also it fails when distinguish faces with same print but different size.</p>
<p>Is there any other effective way to compare two similar images?</p>
","2024-11-06 09:41:04","-3","Question"
"79159039","79159003","","<p><code>X_train_flattened</code> provides the images as input, <code>y_train</code> (the label telling the model which digit it is 0-9) tells the model what it should aim to predict for each image.</p>
<p>This is necessary in supervised machine learning (<a href=""https://www.geeksforgeeks.org/supervised-machine-learning/"" rel=""nofollow noreferrer"">Supervised machine learning tutorial</a>) for the model to learn what classification each image belongs to.</p>
<p>The loss function (<code>sparse_categorical_crossentropy</code> here) computes how far off the model's predictions are from the true labels (<code>y_train</code>). Without <code>y_train</code>, the model wouldn't have any basis for calculating this error and wouldn’t know how to improve.</p>
<p>During training, the model uses the error (or loss) calculated from comparing its predictions to <code>y_train</code> to update its parameters through backpropagation. Here is the original paper on backpropagation if it helps (<a href=""https://www.cs.toronto.edu/%7Ehinton/backprop.html"" rel=""nofollow noreferrer"">George Hinton backpropagation</a>) .</p>
","2024-11-05 12:08:00","2","Answer"
"79159003","","why do we need a y variable in keras model.fit()?","<p>I am working with the hand written digits dataset. The data is loaded as follows:</p>
<pre><code>(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()
</code></pre>
<p>This is the code for a neural network created to classify the digits:</p>
<pre><code>model = keras.Sequential([
    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')
])

model.compile(
    optimizer='adam', 
    loss = 'sparse_categorical_crossentropy',
    metrics = ['accuracy']
)
model.fit(X_train_flattened, y_train, epochs=5)
</code></pre>
<p>The question is, <strong>what is the function of y_train in model.fit()</strong>. this appears to be a classification problem and the network just needs the input(x_train_flattened) for it to be trained.</p>
","2024-11-05 11:56:46","-5","Question"
"79133615","79104916","","<p>Actually you don't need to determine image size for this specific code and keras will itself find out the input size based on input size of the whole network and previous layers.</p>
<p>But if you wish to know what is the input shape for the layer, after the first convolution layer the input shape will be (IMAGE_WIDTH - 4, IMAGE_HEIGHT - 4, 32) because you have 32 channels and used kernel size of 5. And after the pooling layer the height and width will be divided by two as you mentioned.</p>
<p>And the number of nodes in the dense layer can be determined arbitrarily.</p>
","2024-10-28 13:30:28","1","Answer"
"79130994","79129686","","<p><strong>Here is how I fixed it:</strong></p>
<p>Initial fix which is not efficient and based on Homer512's feedback, I revised my initial approach</p>
<p><strong>Recap on the problem:</strong></p>
<p>The assertion error arose because Eigen's <code>.rowwise()</code> approach requires bias to be treated as a vector for broadcasting along rows. However, Eigen's internal checks often flag mismatches if the vector doesn't conform exactly as expected, especially with transposed vectors in operations like <code>.rowwise()</code> addition.</p>
<p><strong>Solution: Expanding bias into a Full Matrix Before Adding</strong></p>
<p>To work around this limitation, I manually replicated the bias to match the output dimensions before adding it, This ensures that each row of the output matrix receives a copy of the bias vector, making Eigen's type system happy and avoiding the assertion errors.</p>
<p><strong>I Updated forward Function Implementation:</strong></p>
<pre><code>Eigen::MatrixXd DenseLayer::forward(const Eigen::MatrixXd&amp; input) {
     std::cout &lt;&lt; &quot;[DenseLayer Forward] Input size: &quot; &lt;&lt; input.rows() &lt;&lt; &quot;x&quot; &lt;&lt; input.cols() &lt;&lt; std::endl;
     std::cout &lt;&lt; &quot;[DenseLayer Forward] Weights size: &quot; &lt;&lt; weights.rows() &lt;&lt; &quot;x&quot; &lt;&lt; weights.cols() &lt;&lt; std::endl;
     std::cout &lt;&lt; &quot;[DenseLayer Forward] Bias size: &quot; &lt;&lt; bias.rows() &lt;&lt; &quot;x&quot; &lt;&lt; bias.cols() &lt;&lt; std::endl;

     input_cache = input;
     Eigen::MatrixXd output = input * weights.transpose();

     // Create a matrix of the same size as output, where each row is a copy of the bias vector
     Eigen::MatrixXd bias_expanded = bias.transpose().replicate(output.rows(), 1);

     std::cout &lt;&lt; &quot;[DenseLayer Forward] Output before bias addition size: &quot; &lt;&lt; output.rows() &lt;&lt; &quot;x&quot; &lt;&lt; output.cols() &lt;&lt; std::endl;
     std::cout &lt;&lt; &quot;[DenseLayer Forward] Expanded bias size: &quot; &lt;&lt; bias_expanded.rows() &lt;&lt; &quot;x&quot; &lt;&lt; bias_expanded.cols() &lt;&lt; std::endl;

     output += bias_expanded;

     std::cout &lt;&lt; &quot;[DenseLayer Forward] Output after bias addition size: &quot; &lt;&lt; output.rows() &lt;&lt; &quot;x&quot; &lt;&lt; output.cols() &lt;&lt; std::endl;
     return output;
}
</code></pre>
<p><strong>Explanation:</strong></p>
<ol>
<li><strong>Explicit Replication of bias:</strong></li>
</ol>
<ul>
<li><code>bias.transpose().replicate(output.rows(), 1);</code> creates a bias_expanded matrix where each row is a copy of bias. This ensures that bias_expanded has the exact dimensions as output, so if output is 64x128, bias_expanded will also be 64x128.</li>
</ul>
<ol start=""2"">
<li><strong>Avoiding <code>.rowwise() + bias.transpose()</code>:</strong></li>
</ol>
<ul>
<li>By using this explicit replication, I bypassed <code>.rowwise()</code> entirely. This approach circumvents Eigen's broadcasting limitations and type-checking issues, making the code more robust.</li>
</ul>
<p><strong>Better Approach: Most recent Fix</strong></p>
<p>Thanks to Homer512's suggestion, I revised my approach for efficiency. Initially, I had bias set up as a matrix, which required full replication to match output dimensions. Now, bias is an <code>Eigen::VectorXd</code>, which broadcasts naturally:</p>
<pre><code>Eigen::MatrixXd DenseLayer::forward(const Eigen::MatrixXd&amp; input) {
   input_cache = input;
   Eigen::MatrixXd output = input * weights.transpose();
   output.rowwise() += bias.transpose(); // Efficient, no full replication needed
   return output;
}
</code></pre>
<p>This approach removes the overhead, thanks again!</p>
","2024-10-27 16:23:30","1","Answer"
"79129686","","Assertion Failure in Eigen Matrix Broadcasting: Dimension Mismatch in Neural Network Forward Pass","<p>I’m implementing a neural network in C++ using Eigen for linear algebra operations. In the <code>DenseLayer::forward</code> function, I’m encountering a dimension mismatch issue when trying to add a bias vector to the layer’s output matrix.</p>
<p>Here’s the structure of my code:</p>
<ul>
<li>The input matrix has dimensions 64x74 (batch size 64).</li>
<li>weights is initialized with dimensions 128x784.</li>
<li>bias is a column vector of dimensions 128x1.</li>
</ul>
<p><strong>Expected Behavior:</strong></p>
<p>After multiplying <code>input * weights.transpose()</code>, I get an output matrix of size 64x128. I need to add bias to each row of output so that the final result remains 64x128.</p>
<p><strong>Current Approach:</strong></p>
<p>Here's the forward function:</p>
<pre><code>Eigen::MatrixXd DenseLayer::forward(const Eigen::MatrixXd&amp; input) {
input_cache = input;
Eigen::MatrixXd output = input * weights.transpose();

// Attempt to replicate bias across rows to match output dimensions
Eigen::MatrixXd bias_replicated = bias.replicate(output.rows(), 1);

output += bias_replicated;
return output;
}
</code></pre>
<p><strong>Error Message:</strong></p>
<p>When I run the code, I encounter the following assertion failure:</p>
<pre><code>Assertion failed: (dst.rows() == src.rows() &amp;&amp; dst.cols() == src.cols()), function resize_if_allowed, file AssignEvaluator.h, line 754.
</code></pre>
<p><strong>What I've Tried:</strong></p>
<ul>
<li>Using <code>.colwise() + bias.col(0)</code>, <code>.rowwise() + bias.transpose()</code>, and directly adding bias with different reshaping/transposing.</li>
<li>I've checked dimensions through debug statements and confirmed that output is 64x128 and bias is 128x1.</li>
</ul>
<p><strong>Question:</strong>
How can I correctly broadcast bias across each row of output to perform element-wise addition without Eigen raising a dimension mismatch error? Is there a better way to handle this broadcasting in Eigen, or am I missing something fundamental in matrix addition with Eigen?</p>
<p><strong>Debug Output:</strong>
To help, here are the dimensions printed before the error:</p>
<ul>
<li>Output before bias addition size: 64x128</li>
<li>Bias size for addition: 128x1</li>
<li>Replicated bias size: 64x128</li>
</ul>
<p>Any insights on achieving the correct broadcasting or a workaround for this would be greatly appreciated!</p>
","2024-10-27 00:17:24","2","Question"
"79109579","79106908","","<p>To calculate gradients in TensorFlow similar to how you did it in PyTorch, you'll need to use TensorFlow's automatic differentiation capabilities. However, there are a few key differences to keep in mind:</p>
<ul>
<li>TensorFlow 2.x uses eager execution by default, which is more similar
to PyTorch's dynamic graph approach.</li>
<li>You'll need to use    tf.GradientTape to record operations for
automatic differentiation.</li>
</ul>
<p>Here's how you can calculate gradients in TensorFlow 2.x, similar to your PyTorch example:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

# Assuming x is your input tensor and model is your TensorFlow model
x = tf.Variable(x)  # Make sure x is a Variable or use tf.convert_to_tensor(x)

with tf.GradientTape() as tape:
    y = model(x)
    
dydx = tape.gradient(y, x)
</code></pre>
<p>More on the subject:
<a href=""https://www.tensorflow.org/guide/autodiff"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/autodiff</a>
<a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/GradientTape</a></p>
<p>UPD: there is also may be a problem with <code>x</code></p>
<p>dydx is None: This usually happens because TensorFlow doesn't know it needs to compute gradients with respect to x. By default, only tf.Variable objects are watched. By using tape.watch(x), you explicitly tell TensorFlow to track x.</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

# Assume x_value is your input data as a NumPy array or TensorFlow tensor
x_value = ...  # Your input data
x = tf.convert_to_tensor(x_value)  # Convert to a TensorFlow tensor if not already one

with tf.GradientTape() as tape:
    tape.watch(x)  # Ensure x is being tracked for gradient computation
    y = model(x)   # Forward pass through your model

# Compute the gradient of y with respect to x
dydx = tape.gradient(y, x)
</code></pre>
","2024-10-21 10:15:41","1","Answer"
"79106908","","The analogue of torch.autograd in TensorFlow","<p>I want to get the dradients of the model after its training. For exmaple, I have the input tensor X and the output y, that is y = model(x). So using pytorch I can calculate the dradient with the folowing command:</p>
<pre><code>y = model(x)
dydx = torch.autograd.grad(Y, X, torch.ones_like(Y), create_graph=True)[0][:, 0]
</code></pre>
<p>I want to get the same value after training model with TensorFlow framework.</p>
<p>I tried:</p>
<pre><code>y = model.predict_u(x)
dydx = tf.gradients(y, x)[0]
</code></pre>
<p>But I got dydx as NoneType. I tried to include the dydx in the model class and to get the gradient through the tf.Session but I had: &quot;ResourceExhaustedError: Graph execution error&quot;.</p>
<p>I have worked with Pytorch framework and now I decide to try TensorFlow, but I have some difficulties.</p>
","2024-10-20 11:14:54","0","Question"
"79104916","","How should I determine the input size for layers following the initial layer in a CNN?","<p>I am working on CS50AI unit 5, and this is the code from the number recognition part of the lecture. If I wanted to add another convolutional layer after the max pooling, how would I determine the input shape? Would it be <code>IMG_WIDTH, IMG_HEIGHT, 3</code> or would I divide IMG_WIDTH and IMG_HEIGHT by 2 because of the max pooling?</p>
<p>Similarly, how is number of nodes in the first dense layer (128) determined? Is that an arbitrary number that I can decide or is it based on something else?</p>
<pre><code>model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(
            32, (5, 5), activation=&quot;relu&quot;, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)
        ),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation=&quot;relu&quot;),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(NUM_CATEGORIES, activation=&quot;softmax&quot;)
    ])
</code></pre>
<p>For reference</p>
<pre><code>IMG_WIDTH = 30
IMG_HEIGHT = 30
NUM_CATEGORIES = 3
</code></pre>
","2024-10-19 12:23:50","0","Question"
"79101267","79058487","","<p>You have created the sequential model and trying to access the input attribute of the sequential model using functional model API which is causing the error. To avoid this error, you can create the functional model and define the layer name and then train the model. To access the model's input, you need to use <code>model.input</code> which only works for functional API models not in sequential model.</p>
<p>I am attaching <a href=""https://colab.sandbox.google.com/gist/Kayyuri/8205608f7549639d9014948259a3cf5f/key-error-when-trying-to-extract-layer-activation-in-tensorflow-sequential-model.ipynb"" rel=""nofollow noreferrer"">gist</a> file for your reference.</p>
<p>For more details refer <a href=""https://www.tensorflow.org/guide/keras/functional_api"" rel=""nofollow noreferrer"">this</a>.
</p>
","2024-10-18 08:37:32","0","Answer"
"79080449","79075311","","<p>Try this content for the <strong>data.yaml</strong> file:</p>
<pre class=""lang-yaml prettyprint-override""><code>path: OIT_model/customOIT/customdatasetyolo
train: train
val: val
nc: 1
names: ['5']
</code></pre>
<p>The <code>train</code> and <code>val</code> paths should be relative to the dataset root dir  <code>path</code>, so for instance, the full train path will be like <code>os.path.join(path, train)</code>. Example for object detection task dataset.yaml: <a href=""https://docs.ultralytics.com/datasets/detect/#supported-dataset-formats"" rel=""nofollow noreferrer"">https://docs.ultralytics.com/datasets/detect/#supported-dataset-formats</a></p>
","2024-10-12 07:51:21","0","Answer"
"79075311","","Issue with relative paths in data.yaml file when trying to train yolo custom model","<p>I am trying to create a training pipeline to train a custom yolov9 model with user inputted labeled images.</p>
<p>I am having an issue where if I make my data.yaml file use relative paths, I get the error:</p>
<pre><code>RuntimeError: Dataset 'OIT_model/customOIT/customdatasetyolo/data.yaml' error
Dataset 'OIT_model/customOIT/customdatasetyolo/data.yaml' images not found , missing path 'C:\GitHub\Anomaly_detection_combine\OIT_model\Anomaly_detection_combine\OIT_model\customOIT\customdatasetyolo\Anomaly_detection_combine\OIT_model\customOIT\customdatasetyolo\val'
</code></pre>
<p>What is even more odd, is that the path the error mentions,</p>
<pre><code>'C:\\GitHub\\Anomaly_detection_combine\\OIT_model\\Anomaly_detection_combine\\OIT_model\\customOIT\\customdatasetyolo\\Anomaly_detection_combine\\OIT_model\\customOIT\\customdatasetyolo\\val'
</code></pre>
<p>is not a path that exists or is being requested anywhere. The actual path is</p>
<pre><code>'C:\\GitHub\\Anomaly_detection_combine\\OIT_model\\customOIT\\customdatasetyolo\\val'
</code></pre>
<p>for some reason it is repeating the first part of the path 3 times.</p>
<p>This is the data.yaml file:</p>
<pre><code>path: OIT_model/customOIT/customdatasetyolo
train: OIT_model/customOIT/customdatasetyolo/train
val: OIT_model/customOIT/customdatasetyolo/val
nc: 1
names: ['5']
</code></pre>
<p>and this is the code that is starting training:</p>
<pre><code>def train_custom_dataset_yolo(data_path, epochs=100, imgsz=64, verbose=True):
    model = YOLO(&quot;OIT_model/yolov9c.pt&quot;)
    # Specify the save directory for training runs
    save_dir = 'OIT_model/customOIT/yolocustomtrainoutput'
    if os.path.exists(save_dir):
        for file in os.listdir(save_dir):
            file_path = os.path.join(save_dir, file)
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
    os.makedirs(save_dir, exist_ok=True)
    model.train(data=data_path, epochs=epochs, imgsz=imgsz, verbose=verbose, save_dir=save_dir)
    return
train_custom_dataset_yolo('OIT_model/customOIT/customdatasetyolo/data.yaml', epochs=1,imgsz=64, verbose=True)
</code></pre>
<p>Very strangely however, when I replace the relative paths with absolute paths, like so:</p>
<pre><code>path: C:/GitHub/fix/Anomaly_detection_combine/OIT_model/customOIT/customdatasetyolo
train: C:/GitHub/fix/Anomaly_detection_combine/OIT_model/customOIT/customdatasetyolo/train
val: C:/GitHub/fix/Anomaly_detection_combine/OIT_model/customOIT/customdatasetyolo/val
nc: 1
names: ['5']
</code></pre>
<p>training works without issue. Using absolute pathing is not an option for me, as this application needs to be reproductible on others machines.</p>
","2024-10-10 16:13:09","0","Question"
"79075077","79074519","","<p>The dimensions of the output from AveragePooling2D can differ from the dimensions of the input, since  default value for padding is 'valid'. Maybe setting padding='same' would fix your issue.</p>
","2024-10-10 15:07:35","0","Answer"
"79074519","","convolution-deconvolution while maintaining the original image size","<p>I am trying to implement pspnet in tensorflow.
It requires a pooling module which takes in the input, along with several kernel sizes:</p>
<ul>
<li><p>does average pooling on the input with the each kernel <code>AveragePooling2D</code></p>
</li>
<li><p>does a 1x1 convolution, after which <code>UpSampling2D</code> is used</p>
</li>
</ul>
<p>Finally all the different conv-deconv outputs are concatenated together and fed forward</p>
<pre><code>def pyramid_pooling_module(x, pool_sizes):
    pool_outputs = []
    for pool_size in pool_sizes:
        pooled= layers.AveragePooling2D(pool_size)(x)
        pooled= layers.Conv2D(512, (1,1), padding='same')(pooled)
        pooled= layers.UpSampling2D(size=pool_size, interpolation='bilinear')(pooled)
        print(pool_size)
        pool_outputs.append(pooled)
    return layers.Concatenate()(pool_outputs)
</code></pre>
<p>The inputs would be of the dimension 68, 120
Because of which the kernels used (1x1, 2x2, 3x3, 6x6) would have rounding errors from the average pooling layers for 3x3, 6x6</p>
<p>such that the final pooled outputs for those layers are (66, 120)</p>
<p>I'm not sure how to go about fixing this, should resize my inputs to a size which is exactly divisible by 6x6? is there another way?</p>
","2024-10-10 13:00:23","0","Question"
"79062412","78999845","","<p>You can navigate into the PyTorch source code for <code>torch.nn.Transformer</code>, where the attention is implemented through the <code>MultiheadAttention</code> module.
<a href=""https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention"" rel=""nofollow noreferrer"">https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention</a></p>
<p>In the forward pass, the <code>MultiheadAttention</code> module calls the <code>multi_head_attention_forward</code> function. This function handles several operations, such as the QKVO linear projections and the attention mechanism itself.</p>
<p>The attention calculation can be found at the following line in the PyTorch codebase:
<a href=""https://github.com/pytorch/pytorch/blob/main/torch/nn/functional.py#L6238"" rel=""nofollow noreferrer"">https://github.com/pytorch/pytorch/blob/main/torch/nn/functional.py#L6238</a></p>
<pre><code>B, Nt, E = q.shape
q_scaled = q * math.sqrt(1.0 / float(E))

assert not (
    is_causal and attn_mask is None
), &quot;FIXME: is_causal not implemented for need_weights&quot;

if attn_mask is not None:
    attn_output_weights = torch.baddbmm(
        attn_mask, q_scaled, k.transpose(-2, -1)
    )
else:
    attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))
attn_output_weights = softmax(attn_output_weights, dim=-1)
if dropout_p &gt; 0.0:
    attn_output_weights = dropout(attn_output_weights, p=dropout_p)

attn_output = torch.bmm(attn_output_weights, v)

attn_output = (
    attn_output.transpose(0, 1).contiguous().view(tgt_len * bsz, embed_dim)
)
attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
attn_output = attn_output.view(tgt_len, bsz, attn_output.size(1))

# optionally average attention weights over heads
attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)
if average_attn_weights:
    attn_output_weights = attn_output_weights.mean(dim=1)

if not is_batched:
    # squeeze the output if input was unbatched
    attn_output = attn_output.squeeze(1)
    attn_output_weights = attn_output_weights.squeeze(0)
return attn_output, attn_output_weights
</code></pre>
<p>This function returns both the O-projection (output) and the attention scores. Therefore, if you need to modify the function's return behavior, you can re-implement <code>multi_head_attention_forward</code> to customize the final return value, including the attention scores (<code>attn_output_weights</code>) as needed.</p>
","2024-10-07 14:47:54","1","Answer"
"79061915","79057322","","<p>Your observation is correct. Since tensorflow 2.16, the complex dtypes are not yet included in supported dtypes.
You can either revert to tf&lt;=2.15 or need to add seperate handling of real and complex values.</p>
<p>The sample code for sharing code is below :</p>
<pre><code>def ftlm_model(hdim):
 # Input layers for real and imaginary parts
 input_real = layers.Input(shape=(hdim,), dtype=tf.float32)
 input_imag = layers.Input(shape=(hdim,), dtype=tf.float32)

 # Shared dense layer for both real and imaginary parts
 shared_dense = layers.Dense(hdim, activation='relu')

 dense_real = shared_dense(input_real)
 dense_imag = shared_dense(input_imag)

 combined = layers.Add()([dense_real, dense_imag])

 output = layers.Dense(1)(combined)

 model = models.Model(inputs=[input_real, input_imag], outputs=output)

 return model
</code></pre>
","2024-10-07 12:13:23","0","Answer"
"79058487","","Key Error when trying to extract layer activation in TensorFlow sequential model","<p>I have a Sequential model that is trained on the MNIST dataset.
After training, I am trying to create a new model to output activations from the hidden ReLU (Dense) layer.
I reshaped the test image correctly but get an error when calling the predict() function on the activation model.</p>
<p>Here's the code I'm using to extract the activations:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tensorflow.keras import models, layers

# Load and preprocess the MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# Define and compile the model
model = models.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(128, activation='relu'),
    layers.Dense(10)
])
model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5)

# Define the activation model
layer_name = 'dense'
activation_model = models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
</code></pre>
<p>However i get the following error.</p>
<pre class=""lang-py prettyprint-override""><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-16-cbfe6f9d08f9&gt; in &lt;cell line: 19&gt;()
     17 # Define the activation model
     18 layer_name = 'dense'
---&gt; 19 activation_model = models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
     20 
     21 # Prepare the test image

1 frames
/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py in _get_node_attribute_at_index(self, node_index, attr, attr_name)
    283         &quot;&quot;&quot;
    284         if not self._inbound_nodes:
--&gt; 285             raise ValueError(
    286                 f&quot;The layer {self.name} has never been called &quot;
    287                 f&quot;and thus has no defined {attr_name}.&quot;

ValueError: The layer sequential_14 has never been called and thus has no defined input.
</code></pre>
<p>I have:</p>
<ul>
<li>Verified that TensorFlow is properly installed.</li>
<li>Checked the model layers and input shapes.</li>
<li>Adjusted the input shape of the test image to add batch size and channels.</li>
</ul>
","2024-10-06 06:30:15","0","Question"
"79057322","","Neural network for real and imaginary part with shared layers","<p>I am trying building a machine learning model that learns a function f(x)-&gt; y where x is a complex vector (y float). I built a model that splits the data into real and imaginary and then does something with it. It runs on my laptop with python 3.10.12 and tensorflow 2.13, but as I want to switch to a server (tried python 3.11.9 tensorflow 2.17) it raises the error:
<code>Invalid dtype: complex64</code>.</p>
<p>Why does my model in keras does not know dtype complex?</p>
<p>The minimal example:</p>
<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.keras import layers, models 

#generate random complex valued data with dimension (N,hdim)
N = 1000
hdim = 64
batch_size = 32
epochs = 10
X = np.random.randn(N,hdim) + 1j*np.random.randn(N,hdim)
y = np.random.randn(N,1)

#create a tensorflow dataset
train_dataset = tf.data.Dataset.from_tensor_slices((X,y))
train_dataset = train_dataset.shuffle(buffer_size=len(X)).batch(batch_size)


#Some custom layers
class input_manip(tf.keras.layers.Layer):
    def call(self, inputs):
        in_real = tf.math.real(inputs)
        in_imag = tf.math.imag(inputs)
        return in_real, in_imag
    
class output_manip(tf.keras.layers.Layer):
    def call(self, in_real, in_imag):
        output = tf.reduce_sum(tf.square(in_real) + tf.square(in_imag))
        return output
    

# Define the model
def ftlm_model(hdim):
    # Input layer
    inputs = layers.Input(shape=(hdim,), dtype=tf.complex64)

    in_man = input_manip()
    in_real, in_imag = in_man(inputs)
    
    print(in_real.shape, in_real.dtype)
    shared_dense = layers.Dense(hdim, activation='relu')  # Shared dense layer
    dense_real = shared_dense(in_real)  # Dense layer for real part
    dense_imag = shared_dense(in_imag)  # Dense layer for imaginary part
    
    out_man = output_manip()
    output = out_man(dense_real, dense_imag)
    #Output layer combining the real and imaginary parts
    # Define the model
    model = models.Model(inputs=inputs, outputs=output)
    
    return model

model = ftlm_model(hdim)
#Print a summary of the model
model.summary()

class CustomMSELoss(tf.keras.losses.Loss):
    def __init__(self):
        super(CustomMSELoss, self).__init__()
    
    def call(self, y_true, y_pred):
        # Custom loss calculation (Weighted Mean Squared Error)
        y_pred = tf.math.real(y_pred)
        loss = tf.reduce_mean(tf.square(y_true - y_pred))
        return loss

custom_loss = CustomMSELoss()
# Compile the model
model.compile(optimizer='adam', loss=custom_loss)

# Train the model
history = model.fit(train_dataset, epochs=epochs)
</code></pre>
<p>(The output layer is changed to keep it simple)
I am wondering if it is just random luck that my code works on my machine or is it something with tensorflow 2.17?
If this is not possible - how to share weights between two models if I have to split outside the model?</p>
<p>I tried doing the split outside the model, but then I do not know how share weights for some layers.</p>
","2024-10-05 15:14:15","0","Question"
"79042428","79019507","","<p>I have changed your model to the code below, because you are flattening the images and in the next layers input the dimension should be 28*28=784:</p>
<pre><code>model = nn.Sequential(
nn.Flatten(),
#YOUR CODE. Add layers to your sequential class
nn.Linear(in_features=784, out_features=128),
nn.ELU(),
nn.Linear(in_features=128, out_features=10),
nn.ELU()
)
</code></pre>
<p>after this change the model runs perfectly with this results:</p>
<ul>
<li>train. Accuracy: 0.98535</li>
<li>valid. Accuracy: 0.9759</li>
</ul>
","2024-10-01 09:12:06","1","Answer"
"79040744","79038884","","<blockquote>
<p>(1) how can we build such a model and export it as PMML file?</p>
</blockquote>
<p>You have pictured a (6, 3, 6) NN. It is architecturally identical to what is implemented by Scikit-Learn's <code>MLPRegressor</code> class.</p>
<p>You can emulate autoencoder using <code>MLPRegressor</code>; in the current case, you would define a NN with a single hidden layer (containing three neurons), and train it with <code>X == y</code>:</p>
<pre class=""lang-py prettyprint-override""><code>autoencoder = MLPRegressor(hidden_layer_sizes = (3, ))
autoencoder.fit(X, X)
</code></pre>
<blockquote>
<p>(2) is PMML capable to encode such model structure?</p>
</blockquote>
<p>PMML is capable of representing full-blown <code>MLPRegressor</code> objects using the <a href=""https://dmg.org/pmml/v4-4-1/NeuralNetwork.html"" rel=""nofollow noreferrer""><code>NeuralNetwork</code></a> model element. Therefore, it's also capable of representing its &quot;truncated&quot; variants such as autoencoders.</p>
<p>The idea is to simply ignore the last (ie. rightmost) layer during conversion. Effectively, the pictured (6, 3, 6) NN gets truncated to (6, 3) NN.</p>
<p>The <a href=""https://github.com/jpmml/sklearn2pmml"" rel=""nofollow noreferrer"">SkLearn2PMML</a> package provides the <code>sklearn2pmml.neural_network.MLPTransformer</code> transformer for this purpose.</p>
<blockquote>
<p>(3) what are the necessary component in PMML to generate N output nodes in this model?</p>
</blockquote>
<p>There is no need to generate anything extra.</p>
<p>The truncated (6, 3) NN provides three outputs <code>y(0)</code>, <code>y(1)</code> and <code>y(2)</code>, which you may then pass forward to other transformers or models.</p>
","2024-09-30 19:09:13","0","Answer"
"79038884","","How to implement an autoencoder model as PMML?","<p>suppose we have the following model:
<a href=""https://i.sstatic.net/zoY2tA5n.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/zoY2tA5n.png"" alt=""enter image description here"" /></a></p>
<ol>
<li>how can we build such a model and export it as PMML file?</li>
<li>is PMML capable to encode such model structure?</li>
<li>what are the necessary component in PMML to generate N output nodes in this model?  I understand using &lt;OutputField ... feature=&quot;predictedValue&quot;&gt; for each output node is not giving the expected result.</li>
</ol>
","2024-09-30 10:14:02","0","Question"
"79033606","79032545","","<p>I think I found a pretty simple solution. I tried the approach again with summing up the <code>loss</code> during the batch calculation, but training only one time at the end. Before, I must have done something wrong concerning the <code>loss</code> data type, so I now initialize it with the first batch <code>loss</code>, to secure the correct type:</p>
<pre><code>for k_batch in range(0, len(samples), batch_size):

    samples_batch = samples[k_batch:k_batch + batch_size]

    loss = loss_fnc(samples_batch)
    if k_batch == 0:
        loss_sum = loss*len(samples_batch)
    else:
        loss_sum += loss*len(samples_batch)

loss = loss_sum/len(samples)

model.optim.zero_grad()
loss.backward()
model.optim.step()
</code></pre>
<p>When I now compare the <code>loss</code> to the reference <code>loss</code> (from training &quot;all-at-once&quot;), the values are equal. As grad-function the reference <code>loss</code> has <code>MseLossBackward0</code> while the newly calculated loss from these batches has <code>DivBackward0</code>. Nonetheless the following training seems to be identical independent of using batches or not.</p>
","2024-09-28 06:55:03","0","Answer"
"79032545","","Realizing identical training with or without using batches","<p>I have a model in PyTorch which converges very well on a reference example when using a standard training process, in which the optimizer trains on all samples at once:</p>
<pre><code>loss = loss_fnc(samples)

model.optim.zero_grad()
loss.backward()
model.optim.step()
</code></pre>
<p>Now the model should train on more memory-intensive tasks (more samples, bigger input size), so I thought it would help to train in batches. For this, I’m using this pretty standard method with a for loop:</p>
<pre><code>loss_sum = 0

for k_batch in range(0, len(samples), batch_size):

    samples_batch = samples[k_batch:k_batch + batch_size]

    loss = loss_fnc(samples_batch)
    loss_sum += loss*len(samples_batch)

    model.optim.zero_grad()
    loss.backward()

    model.optim.step()

loss_comp = loss_sum/len(samples)
</code></pre>
<p>Now, when I skip the training part in this method and only calculate the loss, the resulting <code>loss_comp</code> is identical to the one when calculating it for all samples at once (like in the method above). Naturally, by training in batches, <code>loss_comp</code> is different since the model changes throughout the batches.</p>
<p>Now I face the problem that the model doesn’t converge on my reference example anymore when using batch training. The samples are already ordered randomly before the training in both cases.</p>
<p>Since I’m only interested in reducing the necessary memory demand for the computation, and before I try anything else, is there a way to really have an identical training when using batches instead of &quot;all-at-once&quot;? I tried to change the function so that only the loss is computed in batches and the optimization step is done at the end, but I didn’t seem to get it to work.</p>
<p>As I understand, using a DataLoader wouldn't change anything concerning this behavior.</p>
","2024-09-27 18:27:47","0","Question"
"79032368","79031881","","<p>The problem here is that there is a missing call to <code>optimizer_adam.step()</code>, so the weights aren't updated after calculating gradients.</p>
","2024-09-27 17:24:05","4","Answer"
"79031881","","Constant loss value in Adam optimization method","<p>I have NN code which is written with pytorch. In the loss value calculation when code is using Adam optimization method loss values does not change during the loop while the LBGFS optimization method gets on everything is ok and loss values decrease in the normal way. How can I get rid of this issue?</p>
<pre><code>    for epo in range(epo_adam):
model.train()
optimizer_adam.zero_grad()
loss , momentum_loss , loss_data , loss_BC , continuity_loss = adop_loss_Weight(model, x, y, z, u_exact, v_exact , w_exact , p_exact ,
           x_b, y_b, z_b, u_b, v_b, w_b ,p_b)
loss.backward()
if epo %500 == 0:
  print(f'Epoch Adam {epo}, Total Loss: {loss.item():.10f}')
if loss.item() &lt;=0.15 :
  print(&quot;Optimzation Method is swtiching to LBGF-S . . . &quot;)
  break


for epochs in range(epochs):
model.train()
loss = optimizer.step(closure)

if epochs % 20 == 0:
    print(f'Epoch LBGF-s {epochs}, Total Loss: {loss.item():.5f}')
    #print(f'The highest Loss is:  {max(momentum_loss.item() , continuity_loss.item() , loss_data.item() , loss_bc.item()):.6f}')
    #print(time.time())
</code></pre>
<p>I searched a lot but couldn't find any solution. I think constant loss values in Adam optimization is not reasonable!</p>
","2024-09-27 14:54:13","3","Question"
"79019507","","The accuracy in the neural network does not change","<p>The code of a fully connected NN (I know what is better convolutional, I will do it further), which determines the numbers from the MNIST dataset. When enabled, accuracy does not change at all. What could be the mistake? I have divided the code cells with lines, and marked with comments what is where. I apologize in advance for a lot of code and long answers.</p>
<pre><code>import os
from torchvision.datasets import MNIST
from torchvision import transforms as tfs


data_tfs = tfs.Compose([
    tfs.ToTensor(),
    tfs.Normalize((0.5), (0.5))
])

# install for train and test
root = './'
train_dataset = MNIST(root, train=True,  transform=data_tfs, download=True)
val_dataset  = MNIST(root, train=False, transform=data_tfs, download=True)

train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True) 

valid_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)
---------------------------------------------------------------
#Creating the model
activation = nn.ELU

model = nn.Sequential(
    nn.Flatten(),
    #YOUR CODE. Add layers to your sequential class
    nn.Linear(in_features=2, out_features=128),
    nn.ELU(),
    nn.Linear(in_features=128, out_features=10),
    nn.ELU()
)
---------------------------------------------------------------
criterion = nn.CrossEntropyLoss()#YOUR CODE. Select a loss function
optimizer = torch.optim.Adam(model.parameters())

loaders = {&quot;train&quot;: train_dataloader, &quot;valid&quot;: valid_dataloader}
---------------------------------------------------------------
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
---------------------------------------------------------------
max_epochs = 10
accuracy = {&quot;train&quot;: [], &quot;valid&quot;: []}

class Identical(nn.Module):
    def forward(self, x):
        return x

activation = nn.ELU

model = nn.Sequential(
    nn.Flatten(),
    #YOUR CODE. Add layers to your sequential class
    nn.Linear(in_features=2, out_features=128),
    nn.ELU(),
    nn.Linear(in_features=128, out_features=10),
    nn.ELU()
)

criterion = nn.CrossEntropyLoss()#YOUR CODE. Select a loss function
optimizer = torch.optim.Adam(model.parameters())

loaders = {&quot;train&quot;: train_dataloader, &quot;valid&quot;: valid_dataloader}

device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;

for epoch in range(max_epochs):
    for k, dataloader in loaders.items():
        epoch_correct = 0
        epoch_all = 0
        for x_batch, y_batch in dataloader:
            if k == &quot;train&quot;:
              model.train()
              optimizer.zero_grad()
              outp = model(x_batch)
              outp = outp[:y_batch.shape[0]] #otherwise, the last batch is less than necessary
            else:
              model.eval()
              with torch.no_grad():
                outp = model(x_batch)
                outp = outp[:y_batch.shape[0]]
            preds = outp.argmax(-1)
            correct =  (preds == y_batch).sum()
            all =  tuple(preds.shape)[0]
            epoch_correct += correct.item()
            epoch_all += all
            if k == &quot;train&quot;:
                loss = criterion(outp, y_batch)
                loss.backward()
                optimizer.step()
        if k == &quot;train&quot;:
            print(f&quot;Epoch: {epoch+1}&quot;)
        print(f&quot;Loader: {k}. Accuracy: {epoch_correct/epoch_all}&quot;)
        accuracy[k].append(epoch_correct/epoch_all)
</code></pre>
","2024-09-24 16:17:21","0","Question"
"79009224","79007474","","<p>Good point, it is indeed wrong in the <a href=""https://www.tensorflow.org/tutorials/customization/custom_layers"" rel=""nofollow noreferrer"">TF docs</a>.
The arguments of function <code>add_weight</code> has been reordered and the documentation has not been updated. You just need to add a <code>name=</code> before <code>&quot;kernel&quot;</code>, and it should work (at least it does for me on tf2.16.1).</p>
<p>So the correct code (which simply prints <code>&quot;kernel&quot;</code>):</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
class MyDenseLayer(tf.keras.layers.Layer):
    def __init__(self, num_outputs):
        super(MyDenseLayer, self).__init__()
        self.num_outputs = num_outputs

    def build(self, input_shape):
        self.kernel = self.add_weight(name=&quot;kernel&quot;,
                                      shape=[int(input_shape[-1]),
                                             self.num_outputs])

    def call(self, inputs):
        return tf.matmul(inputs, self.kernel)

layer = MyDenseLayer(10)

_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it.
print([var.name for var in layer.trainable_variables])
</code></pre>
","2024-09-21 09:28:35","0","Answer"
"79007474","","Issues implementing a custom layer in Tensorflow","<p>I copied this code from tensorflow's documentation for implementing a custom layer:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
class MyDenseLayer(tf.keras.layers.Layer):
  def __init__(self, num_outputs):
    super(MyDenseLayer, self).__init__()
    self.num_outputs = num_outputs

  def build(self, input_shape):
    self.kernel = self.add_weight(&quot;kernel&quot;,
                                  shape=[int(input_shape[-1]),
                                         self.num_outputs])

  def call(self, inputs):
    return tf.matmul(inputs, self.kernel)

layer = MyDenseLayer(10)

_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it.
print([var.name for var in layer.trainable_variables])
</code></pre>
<p>When I attempt to run the code in Spyder using Tensorflow 2.17.0, I get a recursion error.</p>
<pre><code>RecursionError: maximum recursion depth exceeded in comparison
</code></pre>
<p>The traceback is a follows:</p>
<pre><code>Traceback (most recent call last):
  File &quot;/Users/xoxo/Documents/test.py&quot;, line 2, in &lt;module&gt;
    class MyDenseLayer(tf.keras.layers.Layer):
</code></pre>
","2024-09-20 15:56:44","1","Question"
"78999845","","Get the attention scores of a pretrained transformer in pytorch","<p>I've been trying to look at the attention scores of a pretrained transformer when I pass specific data in. It's specifically a <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html"" rel=""nofollow noreferrer"">Pytorch Transformer</a>. I've tried using <a href=""https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html"" rel=""nofollow noreferrer"">forward hooks</a>, but I'm only able to get the final output of attention modules when what I want is NxN matrices of attention scores (softmax(QxK). I also would really prefer to do this via pytorch code and not use outside tools such as BertViz.</p>
<p>Does anyone know if there's a way to do this?</p>
","2024-09-18 19:06:33","3","Question"
"78989665","78989634","","<p>The reason is most likely that you want the gradient w.r.t. <code>x</code>, but you multiply x with the mask <em>outside the GradientTape</em>. Therefore, the tape never records the gradients back to <code>x</code>, but only to <code>x_</code>. This is also the reason that your second example works. There, you define <code>x</code> and then every operation on <code>x</code> is inside the <code>GradientTape</code>.<br />
The solution is to just move <code>x@mask</code> inside the <code>with</code> block:</p>
<pre class=""lang-py prettyprint-override""><code>with tf.GradientTape() as tape:
  x_ = x@mask
  # Forward pass
  y = layer(x_)
  loss = tf.reduce_mean(y**2)
</code></pre>
<p>This way, the tape knows the relation between <code>x</code> and <code>x_</code>.</p>
","2024-09-16 09:58:40","0","Answer"
"78989634","","gradient becomes none after apply mask on trainable variable","<p>When I implement the following code, gradient of x becomes none after apply mask on trainable variable. After removed the mask the gradient is able to be calculated. I am wondering what the reason of it.</p>
<pre><code>layer = tf.keras.layers.Dense(2, activation='relu')
x = tf.Variable([[1., 2., 3.]], name = &quot;tfv&quot;, trainable=True)
mask = tf.constant([0., 1., 0.], shape = (3,1))
x_ = x@mask
with tf.GradientTape() as tape:
  # Forward pass
  y = layer(x_)
  loss = tf.reduce_mean(y**2)

# Calculate gradients with respect to every trainable variable
grad = tape.gradient(loss, [layer.trainable_variables, x])
</code></pre>
<p>the output of grad is</p>
<pre><code>[[&lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.       , 5.2745185]], dtype=float32)&gt;,
  &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.       , 2.6372592], dtype=float32)&gt;],
 None]
</code></pre>
<p>after I remove the mask</p>
<pre><code>layer = tf.keras.layers.Dense(2, activation='relu')
x = tf.Variable([[1., 2., 3.]], name = &quot;tfv&quot;, trainable=True)
with tf.GradientTape() as tape:
  # Forward pass
  y = layer(x)
  loss = tf.reduce_mean(y**2)

# Calculate gradients with respect to every trainable variable
grad = tape.gradient(loss, [layer.trainable_variables,x])
</code></pre>
<p>the output of gradient is</p>
<pre><code>[[&lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy=
  array([[1.2404386, 3.1709769],
         [2.4808772, 6.3419538],
         [3.7213159, 9.512931 ]], dtype=float32)&gt;,
  &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.2404386, 3.1709769], dtype=float32)&gt;],
 &lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[2.8783302 , 0.38053298, 2.651462  ]], dtype=float32)&gt;]
</code></pre>
","2024-09-16 09:48:13","0","Question"
"78984724","78982976","","<p>You shouldn't use <code>Sequential</code> for this. Just define your own class and implement your own custom logic, like so:</p>
<pre class=""lang-py prettyprint-override""><code>import torch
import torch.nn as nn

class CustomModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(CustomModel, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.tanh = nn.Tanh()
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        x = self.tanh(self.fc1(x))
        
        x = self.fc2(x)
        
        # Sigmoid for the first column
        x[:, 0] = self.sigmoid(x[:, 0])
        # Tanh for the rest of the columns
        x[:, 1:] = self.tanh(x[:, 1:])
        
        return x

input_size = 2
hidden_size = 10
output_size = 5
model = CustomModel(input_size, hidden_size, output_size)

x = torch.randn(100, 2)

y = model(x)
print(y)
</code></pre>
","2024-09-14 09:05:18","1","Answer"
"78982976","","Is it possible to set different activation functions for different outputs at the final layer in the neural net?","<p>I have a simple neural net - some linear layers with tanh between layers and after the end of the net. For example, I have input tensor with shape (100, 2) and I want the output to be with size (100, 5). But the values in the first column are in the range [0, 1], that is it is suitable to have sigmoid activation function at the end. The values in another columns are in the range [-1, 1], that is the &quot;tanh&quot; activation function could be used. But I don't understand how to set the sigmoid for the first output column and the &quot;tanh&quot; for another outputs? Is it possible? Or, I should apply abs() for the first column in the outputs and set the &quot;tanh&quot; after the final linear layer?</p>
<p>Now I have the following model:</p>
<pre><code>nn.Sequential(nn.Linear(input_size, hidden_size),
nn.Tanh(),
nn.Linear(hidden_size, output_size),
nn.Tanh())

y = model(x)
y[:,0] = torch.abs(y[:,0])
</code></pre>
<p>But I want:</p>
<pre><code>model = nn.Sequential(nn.Linear(input_size, hidden_size),
nn.Tanh(),
nn.Linear(hidden_size, output_size))
</code></pre>
<p>and to apply nn.Sigmoid() for the first output and nn.Tanh() for the other outputs:</p>
<pre><code>y = model(x)
act_1 = nn.Sequential(nn.Sigmoid())
act_2 = nn.Sequential(nn.Tanh())

y[:,0] = act_1(y[:,0])
y[:,1:] = act_2(y[:,1:])
</code></pre>
","2024-09-13 16:22:59","2","Question"
"78974729","78971819","","<p>Try adding the following lines of code:</p>
<pre><code>import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)
</code></pre>
","2024-09-11 15:59:48","0","Answer"
"78971819","","How to solve : UnknownError: Graph execution error:","<p>i have 2.14 version of keras and tensorflow. My cuda version is :</p>
<p><a href=""https://i.sstatic.net/kE1HXUcb.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/kE1HXUcb.png"" alt=""enter image description here"" /></a></p>
<p>I am trying to fit a simple model but I get the following exception :</p>
<pre><code>UnknownError: Graph execution error:
</code></pre>
<p>The code is :</p>
<p><a href=""https://gist.githubusercontent.com/robintux/142a71eef5b5ffc8fbbcbeee1d0f280b/raw/4c4423080a12ca864a1a373188e55f37532ab99a/Problem_with_Graph_execution_error.py"" rel=""nofollow noreferrer"">Problem_with_Graph_execution_error.py</a></p>
<p>My computer is a ubuntu 20.04 with a python 3.10.14 (ipython 8.27.0).</p>
<p>Please, any ideas or experiences that could help me.</p>
","2024-09-11 02:05:12","-1","Question"
"78968182","78965629","","<p>You can use <code>nn.Sequential</code> to combine all layers easily and <a href=""https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear"" rel=""nofollow noreferrer""><code>nn.LazyLinear</code> for the first layer, which accepts all input sizes</a>.</p>
<pre class=""lang-py prettyprint-override""><code>class MyModel(nn.Module):
    def __init__(self, out_first=19):
        super(MyModel, self).__init__()
        layers = [nn.LazyLinear(out_first)]
        out = out_first
        for _ in range(9):
            layers.append(nn.ReLU())
            layers.append(nn.Linear(out, out - 1))
            out -= 1
        self.fc = nn.Sequential(*layers)

    def forward(self, x):
        return self.fc(x)

model = MyModel()
</code></pre>
","2024-09-10 06:38:51","0","Answer"
"78966208","78964885","","<pre class=""lang-py prettyprint-override""><code>def tensorflow_model():
    import numpy as np
    import tensorflow as tf
    from cvnn.layers import ComplexDense, ComplexInput

    data = np.random.rand(1000, 10) + 1j * np.random.rand(1000, 10)
    labels = (np.abs(data).sum(axis=1) &gt; 5).astype(int)

    def get_complex_model(input_shape):
        model_ = tf.keras.models.Sequential()
        model_.add(ComplexInput(input_shape=input_shape))
        model_.add(ComplexDense(50, activation='cart_relu'))
        model_.add(ComplexDense(1, activation='convert_to_real_with_abs'))
        return model_

    model = get_complex_model((10,))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.fit(data, labels, epochs=10, batch_size=32, validation_split=0.2)

    test_data = np.random.rand(200, 10) + 1j * np.random.rand(200, 10)
    test_labels = (np.abs(test_data).sum(axis=1) &gt; 5).astype(int)

    test_loss, test_acc = model.evaluate(test_data, test_labels)
    print(f'Test accuracy: {test_acc}')


if __name__ == '__main__':
    tensorflow_model()
</code></pre>
<p>Output: <code>Test accuracy: 1.0</code></p>
<p>Environment:</p>
<ul>
<li>python==3.11.1</li>
<li>cvnn==2.0</li>
<li>tensorflow==2.15.0</li>
<li>tf_keras==2.15.1</li>
<li>tensorflow-probability[tf]==0.23.0</li>
<li>dm-tree==0.1.8</li>
</ul>
<p>Please note that cvnn is experimental and not maintained, so it might not work with newer versions of Tensorflow. See <a href=""https://github.com/NEGU93/cvnn/issues/50"" rel=""nofollow noreferrer"">Invalid dtype: complex64 with TF 2.16</a></p>
","2024-09-09 15:32:38","1","Answer"
"78965629","","How can I fix this neural network model so that it matches the scheme?","<p>I'm starting to study neural networks and I can't complete such a task. Here's the assignment.</p>
<p>Create a class called MyModel, with which you can create a neural network, as in the picture. In this model, each subsequent linear layer has one neuron less than the previous one. When creating the MyModel class, use the <code>nn.ModuleList</code> class.</p>
<p>Create a neural network model with an input tensor size of 20 and an output tensor size of 10. Write the result to the model variable.</p>
<p><a href=""https://i.sstatic.net/pEwlE1fg.png"" rel=""nofollow noreferrer"">here is the scheme</a></p>
<p>This is the code I got:</p>
<pre><code>import torch
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self, inp, out):
        super(MyModel, self).__init__()
        layers = []
        for i in range(9):
            layers.append(nn.Linear(inp, inp - 1))
            layers.append(nn.ReLU())
            inp -= 1
        layers.append(nn.Linear(inp, out))
        self.layers = nn.ModuleList(layers)

    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        return x

model = MyModel(inp=20, out=10)
</code></pre>
<p>Here is the error that comes out when executing this code: &quot;The created model does not match the model in the diagram. Note that the size of the input and output tensors on the inner layers do not depend on the size of the tensor at the entrance to and exit from the network.&quot;</p>
<p>But I can't figure out where the error is, please help me figure it out</p>
","2024-09-09 13:08:52","0","Question"
"78964885","","I need to write complex-value neural network in tensorflow but I get an error","<p>I have complex input to into the neural network, and I also need the neural network to have complex weights, but when writing the code, I get the error as below:</p>
<pre><code>---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&lt;ipython-input-21-99efde09531b&gt; in &lt;cell line: 20&gt;()
     18 
     19 # Instantiate the model with the corrected input parameter
---&gt; 20 model = get_complex_model((10,))
     21 
     22 # Compile the model

/usr/local/lib/python3.10/dist-packages/keras/src/activations/__init__.py in get(identifier)
    102     if callable(obj):
    103         return obj
--&gt; 104     raise ValueError(
    105         f&quot;Could not interpret activation function identifier: {identifier}&quot;
    106     )

ValueError: Could not interpret activation function identifier: cart_relu
</code></pre>
<p>I also tried to use the standard activation function <code>relu</code> instead of <code>cart_relu</code>, but it also gives an error. Below is the code I use:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
from cvnn.layers import ComplexDense, ComplexInput
import tensorflow as tf


data = np.random.rand(1000, 10) + 1j * np.random.rand(1000, 10) # Generate synthetic complex-valued data
labels = (np.abs(data).sum(axis=1) &gt; 5).astype(int)

def get_complex_model(input_shape):
    # Ensure that the shape argument is provided correctly to ComplexInput
    inputs = tf.keras.Input(shape=(10,))
    x = ComplexDense(10, activation='cart_relu')(inputs)
    model = tf.keras.Model(inputs=inputs, outputs=x)
    return model

# Instantiate the model with the corrected input parameter
model = get_complex_model((10,))
</code></pre>
","2024-09-09 09:50:18","0","Question"
"78930522","78925961","","<p>You are possibly having this error due to changes in the Keras API in recent versions. You can import <code>Layer</code> and <code>InputSpec</code> directly from <code>keras.layers</code>. Your import statement should be:</p>
<pre><code>from keras.layers import Layer, InputSpec
</code></pre>
","2024-08-30 05:18:56","1","Answer"
"78925961","","ModuleNotFoundError: No module named 'keras.layers.core'","<p>I am trying to import LSTM in python</p>
<pre><code>from keras.layers.core import Layer, InputSpec
</code></pre>
<p>However, I get below error message on compilation:</p>
<pre><code>ModuleNotFoundError: No module named 'keras.layers.core'
</code></pre>
<p>How can I fix this?</p>
","2024-08-29 02:56:50","0","Question"
"78919676","78919647","","<p>It looks like the issue is related to copy pasting the commands from the book into the python shell. The easiest way would be to run it if you bring the second line into one line:</p>
<p>So from:</p>
<pre><code>training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper()
</code></pre>
<p>To this:</p>
<pre><code>training_data, validation_data, test_data = mnist_loader.load_data_wrapper()
</code></pre>
<p>Give it a try!</p>
<p>EDIT: The other way should be to remove the extra three dots you have in the shell there, when the line is broken using <code>\</code></p>
<p>EDIT2: For the <code>FileNotFound</code> exception, paste the file called <code>mnist.pkl.gz</code> into a <code>data/</code> directory two levels up your working directory. Your folder structure needs to match what you see in the github repo to be able to run it.</p>
","2024-08-27 15:34:41","1","Answer"
"78919647","","Code in mnielson book on neural networks not working","<p>I am learning neural networks from the book <a href=""http://neuralnetworksanddeeplearning.com/chap1.html"" rel=""nofollow noreferrer"">http://neuralnetworksanddeeplearning.com/chap1.html</a>
and I have created the code, making sure to use the up to date version for python 3.10 from github, and I am encountering an error when I try to run this bit of code in python shell: <a href=""https://i.sstatic.net/ED9jYz2Z.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/ED9jYz2Z.png"" alt=""Here is the code I am trying to run"" /></a>.</p>
<p>The error is as follows:</p>
<p><a href=""https://i.sstatic.net/wjFwb8eY.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/wjFwb8eY.png"" alt=""error message"" /></a></p>
<p>does anyone know why this is, or how to fix it? I am running this in pycharm in python 3.10</p>
","2024-08-27 15:27:46","-3","Question"
"78907866","78906991","","<p>I think you are confused about some very basic programming aspects here. Lets step through some things.</p>
<p>You create the model:</p>
<pre class=""lang-py prettyprint-override""><code>top_model = torch_top_model()
</code></pre>
<p>At this point you have one single model. Now you create this dict:</p>
<pre class=""lang-py prettyprint-override""><code>weights_and_biases = {i:top_model.state_dict() for i in range(1,5)}
</code></pre>
<p>At this point you still have one model. The entries in <code>weights_and_biases</code> all reference the same model state dict. The dict values are all pointers to the exact same object.</p>
<p>You create the optimizer dict</p>
<pre class=""lang-py prettyprint-override""><code>optimizer = {i:torch.optim.Adam(top_model.parameters(), lr=0.01) for i in range(1,5)}
</code></pre>
<p>At this point you still have one model. Each dict value is a different optimizer object, but they all reference the same weight objects.</p>
<p>You create the model copy dict</p>
<pre class=""lang-py prettyprint-override""><code>top_models = {i:copy.deepcopy(top_model) for i in range(1,5)}
</code></pre>
<p>Now you have created four new models. You have five models total - four in <code>top_models</code> plus the original model you cloned from.</p>
<p>Now your train loop</p>
<pre class=""lang-py prettyprint-override""><code>top_models[key].load_state_dict(weights_and_biases[key])
outputs = top_models[key](inputs[key])
loss = criterion(outputs, model_labels)
optimizer[key].zero_grad()
loss.backward()
</code></pre>
<p>If you understand the code you wrote, you can see clearly why this doesn't work. You use the model in <code>top_models[key]</code> with the optimizer <code>optimizer[key]</code>. <code>top_models[key]</code> points to one of the model copies you created. <code>optimizer[key]</code> points to the weights of the original model. They are referencing different objects. Loading the state dict via <code>top_models[key].load_state_dict(weights_and_biases[key])</code> does not change this because it copies the data values from <code>weights_and_biases[key]</code> into the tensor objects in <code>top_models[key].load_state_dict</code>.</p>
<p>The reason you see no change in the weights is because you aren't updating them. You compute your loss with the weights in <code>top_models[key]</code>, but your optimizer references the weights in the original <code>top_model</code>. There is no connection between the two. If you actually inspect a gradient value of a parameter in the optimizer (<code>optimizer[key].param_groups[0]['params'][0].grad</code>) you will find it is <code>None</code> because no gradient is being computed. The parameters in the optimizer are unrelated to the parameters you use to calculate your loss.</p>
<p>I think you are also confused about what you are trying to accomplish. When you say <code>I would like the model to update only weights_and_biases[1] for inputs[1], weights_and_biases[2] for inputs[2]</code>, it implies you want to train separate models on the different inputs. When you say <code>If this can be achieved without deep copying the model</code>, it implies you want a single model.</p>
<p>You can train a single model on all versions of the input, or you can train separate instances of the model on the separate inputs.</p>
","2024-08-24 00:21:04","1","Answer"
"78906991","","train an NN model independently for different input versions","<p>I am working with PyTorch to train a neural network model, referred to as 'top_model.' Below, I have outlined my setup, followed by a detailed description of the challenge I am facing.</p>
<pre><code>class torch_top_model(nn.Module):
    def __init__(self):
        super(torch_top_model, self).__init__()
        self.input_layer = nn.Linear(25, 320)
        self.hidden_layer = nn.Linear(320, 64)
        self.output_layer = nn.Linear(64, 10)

    def forward(self, x):
        x = F.relu(self.input_layer(x))
        x = F.relu(self.hidden_layer(x))
        x = self.output_layer(x)
        return x

top_model = torch_top_model()
top_model.train()
</code></pre>
<p>I have an input tensor of size (30, 25). For my input generation, I am splitting the 25 features into 5 groups of 5 features each.</p>
<pre><code>model_inputs = torch.rand(30, 25)
model_labels = torch.randint(0, 10, (30,))
top_model_inputs = {}

for i in range(5):  # 4 groups (5 columns each)
    top_model_inputs[i] = model_inputs[:, i*5:(i+1)*5]
</code></pre>
<p>In the next step, I am generating versions of the input data where one group of features (corresponding to each key) is zeroed out while the others remain intact.</p>
<pre><code>for key in range(1, len(top_model_inputs.keys())):
    temp = []
    for k in top_model_inputs:
      if k == key:
        temp.append(torch.zeros_like(top_model_inputs[k]))
      else:
        temp.append(top_model_inputs[k])
    temp_tensor = torch.cat(temp, dim=1)
    inputs[key] = temp_tensor
</code></pre>
<p>Next I start with the model training:</p>
<pre><code>weights_and_biases = {i:top_model.state_dict() for i in range(1,5)}
optimizer = {i:torch.optim.Adam(top_model.parameters(), lr=0.01) for i in range(1,5)}
criterion = nn.CrossEntropyLoss()
top_models = {i:copy.deepcopy(top_model) for i in range(1,5)}
epochs = 3

for i in range(epochs):
  for key in range(1, len(top_model_inputs.keys())):
    top_models[key].load_state_dict(weights_and_biases[key])
    outputs = top_models[key](inputs[key])
    loss = criterion(outputs, model_labels)
    optimizer[key].zero_grad()
    loss.backward()
    if i == 2:
      w2 = weights_and_biases[2]['input_layer.weight'].clone().detach()
    optimizer[key].step()
    weights_and_biases[key] = top_models[key].state_dict()
    if i == 1:
      w1 = weights_and_biases[1]['input_layer.weight'].clone().detach()

      print(&quot;w1-w2: &quot;, torch.norm(w1-w2))
</code></pre>
<p>My problem: For each versions of the input, as and when I run my algorithm through epochs, I only want the weights and biases of the corresponding inputs to be updated. For example in epoch1, I would like the model to update only weights_and_biases[1] for inputs[1], weights_and_biases[2] for inputs[2] and so on. In essence, I want the parameters (weights and biases) of the top_model to be updated separately for each input versions during each epoch, and then use those updated parameters in the next epoch.</p>
<p>Issue I am facing: The weights are being reused from weight_and_biases of other input versions. For example, weight_and_biases[1] is being used by inputs[2]. Therefore, I get a zero norm difference before and after updates from different input versions.</p>
<p>How to independently update the model parameters for different input versions across epochs? If this can be achieved without deep copying the model a number of times, that would be a more efficient solution.</p>
","2024-08-23 17:30:42","0","Question"
"78896296","","Deep Neural Network Concatenation problem","<p>I am looking to concatenate two neural networks. But after building the first one, an input warning occurs. At the end, this ValueError occurs.</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-8-516cf02e1bd0&gt; in &lt;cell line: 1&gt;()
----&gt; 1 combinedInput = concatenate([network_1.output, network_2.output])

1 frames
/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py in _get_node_attribute_at_index(self, node_index, attr, attr_name)
    283         &quot;&quot;&quot;
    284         if not self._inbound_nodes:
--&gt; 285             raise ValueError(
    286                 f&quot;The layer {self.name} has never been called &quot;
    287                 f&quot;and thus has no defined {attr_name}.&quot;

ValueError: The layer sequential has never been called and thus has no defined output.
</code></pre>
<p>What does it mean by no defined output?
I tried compiling the two networks but still don't work (That's why I used # on compile line)
The entire code is given below.</p>
<pre><code>import tensorflow as tf
import numpy as np

from sklearn.model_selection import train_test_split

from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Input ,concatenate
from tensorflow.keras.utils import plot_model
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error

from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing()
print(housing['feature_names'])

X = housing['data']
y = housing['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)

#Network 1
network_1 = Sequential()
network_1.add(Dense(units = 4, input_dim = X_train.shape[1], activation='relu'))
network_1.add(Dense(units = 4, activation='relu'))
network_1.add(Dense(units = 4, activation='relu'))
network_1.add(Dense(units = 4, activation='relu'))
#network_1.compile(loss= 'mean_squared_error', optimizer= Adam, metrics=['mean_squared_error'])

/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
#network 2
network_2 = Sequential()
network_2.add(Dense(units = 16, input_dim= , activation='relu'))
network_2.add(Dense(units = 16, activation='relu'))
#network_2.compile(loss= 'mean_squared_error', optimizer= Adam, metrics=['mean_squared_error'])

combinedInput = concatenate([network_1.output, network_2.output])
</code></pre>
","2024-08-21 09:57:13","0","Question"
"78885582","78862449","","<p>What I have done now to get my setup working with DQN is flattening both spaces:</p>
<pre><code>self.observation_space = spaces.MultiBinary(n * n)
self.action_space = spaces.Discrete(n*n)
</code></pre>
<p><strong>observation space:</strong> While my state / observation space is actually matrix with 0s and 1s, I am <strong>flattening</strong> it to a MultiBinary, where true represents 1 and false represents 0. Using MultiBinary has greatly improved performance.</p>
<p><strong>action_space:</strong> Similarly, while it represents a vector that point a location in the matrix location, I use a Discrete action space, which I then <strong>unflatten</strong> for backing out the entry in the matrix</p>
<pre><code>    row = action // (self.n)
    col = action % (self.n)
</code></pre>
<p>In summary, while it was unintuitive for me, the DQN model can handle matrices in observation spaces, simply by flattening the matrix to one MultiDiscrete or MultiBinary. Also, the action of selecting an entry in a matrix can be represented by Discrete(n*n).</p>
","2024-08-18 20:20:21","0","Answer"
"78877814","78677993","","<p>First, your statement regarding DataLoader is not exactly correct. The rules of where the data is stored and where it is fetched from will be controlled by the <code>__getitem__</code> or the <code>__getitems__</code> in the Dataset object tied to the DataLoader. The easiest solution to your problem would implementing a CustomDataset which would be a subclass of the <code>torch.utils.data.Dataset</code> class. Probably something like this</p>
<pre><code>class CustomDataset(torch.utils.data.Dataset):
  def __init__(self, ndatapoints):
    self.len = ndatapoints #the number of points you want to generate
    '''
    declare any other parameters related to your simulation here, just remember to add self. before the, to make them persistent in the class
    '''
  def __len__(self):
    return self.len

  def __getitem(self, id):
    '''
    simulate one datapoint here, maybe use id as a random seed, put the data in a torch.Tensor using something like dataTensor = torch.as_sensor(...)
    '''
    return dataTensor
</code></pre>
<p>You might also wanna look into <code>torch.utils.data.IterableDataset</code>. Then declare this and put it into a DataLoader</p>
<pre><code>dataset = CustomDataset(10000)
dataLoader = torch.utils.data.DataLoader(dataset, batch_size=124)
</code></pre>
<p>You can use the dataLoader like any others you have seen and it will basically generate <code>batch_size</code> number of dataPoints at a time and you can use them as batches for your training/alidation. If your simulation happens on CPU, then you might wanna set the <code>num_workers</code> kwarg in the DataLoader constructor to concurrently generate more than one batch at once.</p>
","2024-08-16 06:20:01","0","Answer"
"78876821","78151471","","<p>I have recently started studying different neural style transfer models. I do not know much. But if you are using <a href=""https://arxiv.org/abs/1508.06576"" rel=""nofollow noreferrer"">A Neural Algorithm of Artistic Style</a> then I have some suggestion for you.</p>
<ol>
<li>In the paper conv4_2 output(relu output) was used for representing content image and they also generated the stylized image from white noise. So it becomes very hard for the model to generate the stylized image while retaining the original content image's fine details. There are two solution for this first use content image and modify it to generate stylized image or use a shallow layer like conv2_2 alongside the conv4_2 output for representing the content image. Though you did not seem suffer the same problem I suffered as the some things in your image is pretty clear. In my case the stylized image was blurry.</li>
<li>There is also a chance that there is something wrong with your code. Did you clamp the values between 0 and 1? or normalized the input image? There are many
things that can go wrong.
Hope the suggestion helps although it's little late</li>
</ol>
","2024-08-15 20:59:53","0","Answer"
"78872372","78870012","","<p>The notation here is definitely confusing. The transpose notation is not clarifying.</p>
<p>I think the operation makes more sense in einsum notation - <code>bn,anm,bm-&gt;ba</code>. <code>x1</code> has a multiplication/reduction along the second axis of <code>A</code>. <code>x2</code> has a multiplication/reduction along the second axis of <code>A</code>.</p>
<pre class=""lang-py prettyprint-override""><code>x1 = torch.randn(2, 8)
x2 = torch.randn(2, 4)
A = torch.randn(16, 8, 4)

b1 = torch.bilinear(x1, x2, A)
b2 = torch.einsum('bn,anm,bm-&gt;ba', x1, A, x2)
assert torch.allclose(b1, b2)
</code></pre>
<p>You can also compute the multiplications/reductions explicitly:</p>
<pre class=""lang-py prettyprint-override""><code>b3 = (x1[:,None,:,None] * A[None] * x2[:,None,None,:]).sum(-1).sum(-1)
assert torch.allclose(b1, b3)
</code></pre>
","2024-08-14 18:01:33","1","Answer"
"78870571","78870012","","<p>The implementation <em>behind the scenes</em> calculates the bilinear product, as per documentation.<br />
That's not to say that multiplying the tensors as they are is equivalent to the bilinear layer.<br />
If you follow the trail of the actual calculation, you end up with a python-interface function, while the actual implementation is in the cpp, where you can see that there are reshapes and flattening of the tensors so as to ensure the output is the expected expression:</p>
<p>Here's an excerpt from the <a href=""https://github.com/pytorch/pytorch/blob/a8dc9d8e353ddcf7db0247349a3acd0dd37fcc6f/aten/src/ATen/native/Linear.cpp#L702"" rel=""nofollow noreferrer"">relevant code</a>:</p>
<pre><code>  auto size1 = input1.sym_sizes();
  output_size.insert(output_size.end(), size1.begin(), size1.end() - 1);
  output_size.push_back(weight.sym_size(0));
  auto input1_flattened = input1.reshape_symint({-1, input1.sym_size(-1)});
  auto input2_flattened = input2.reshape_symint({-1, input2.sym_size(-1)});
  Tensor output = at::_trilinear(input1_flattened, weight, input2_flattened, {1,3}, {0}, {1,2}, {2,3}).reshape_symint(output_size);
  if (bias.defined()) {
    output = output + bias;
  }
</code></pre>
<p>Hope that helps</p>
","2024-08-14 11:02:51","1","Answer"
"78870012","","Implementing nn.Bilinear Layer","<p>Can anyone help me understand the implementation of <code>nn.Bilinear</code>
As per the documentation, this function implements y = x<sub>1</sub><sup>T</sup> * A * x<sub>2</sub>
taking <code>x1 = (100,20)</code> , <code>x2 = (100,30')</code> , assuming <code>output_features = 50</code>. The  matrix <code>A</code> has dimensions of <code>[50,20,30]</code>.
I am finding it difficult how these matrices are multiplied to get the <code>output = [100,50]</code></p>
<p>Based on the size of x<sub>1</sub>,x<sub>2</sub> and <code>A</code> matrix, the multiplication seems incompatible as per  y = x<sub>1</sub><sup>T</sup> * A * x<sub>2</sub> . What am I missing here?</p>
","2024-08-14 09:01:18","0","Question"
"78863745","78863529","","<p>Your code works without issues in my environment; I believe your <code>huggingface_hub</code> package is old. Try</p>
<pre><code>python -m pip install --upgrade huggingface_hub
</code></pre>
","2024-08-12 22:10:01","0","Answer"
"78863529","","getting unexpected keys error while loading weights","<pre><code>import torch
from PIL import Image
import numpy as np
from effdet import get_efficientdet_config, EfficientDet


config = get_efficientdet_config('tf_efficientdet_d0')
model = EfficientDet(config, pretrained_backbone=True)
model.eval()
</code></pre>
<p>when I run this I am getting the error</p>
<pre><code>Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.
</code></pre>
<p>I researched some bit and got to know that this is because of timm builder but didn't find any solutions. How to fix this?</p>
<p>I wanted to load the efficientdet weights but it resulted in an unexpected keys error</p>
","2024-08-12 20:42:04","0","Question"
"78862449","","Neural network for matrix as input and position in matrix as output - reinforcement","<p>I have set up a very basic environment in gymnasium, consisting on an nxn matrix, populated by 0s and 1s. The neural network now should output a vector, pointing to one specific entry of the matrix.</p>
<p>For now, this should simply be an entry with 0, which will then changed to 1: essentially the ai populates the matrix with 1s via reinforcement learning. Later, I want it to find approate positions to place shapes into the matrix (a bit like a Tetris game only the blocks are not falling).</p>
<p>Anyways, I have up to now used DQN models, which seem not to be really suitable here. Could anyone please point me to a better approach for this input/output setup?</p>
","2024-08-12 15:23:25","-1","Question"
"78853571","","Can't export standard torchvision ResNet50 model into ONNX file","<p>I made very simple python script which loads <strong>torchvision ResNet50</strong> model and tries to export to onnx file in two ways (<strong>torch.onnx.export</strong> and <strong>torch.onnx.dynamo_export</strong>)</p>
<pre><code>import torch
import torch.onnx

import torchvision

torch_model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2( weights='DEFAULT')
torch_model.eval()
torch_input = torch.randn(1, 3, 32, 32)

is_dynamo_export = False

if (is_dynamo_export):
    onnx_program = torch.onnx.dynamo_export(torch_model, torch_input)
    onnx_program.save(&quot;onnx_dynamo_export_ResNET50.onnx&quot;)        
else:
    torch.onnx.export(torch_model,               # model being run
                      torch_input,                         # model input (or a tuple for multiple inputs)
                      &quot;onnx_export_ResNET50.onnx&quot;,   # where to save the model (can be a file or file-like object)
                      export_params=True,        # store the trained parameter weights inside the model file
                      opset_version=10,          # the ONNX version to export the model to
                      do_constant_folding=True,  # whether to execute constant folding for optimization
                      input_names = ['input'],   # the model's input names
                      output_names = ['output'], # the model's output names
                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes
                                    'output' : {0 : 'batch_size'}})  
</code></pre>
<p>The errors were appeared:</p>
<pre><code>File &quot;C:\tools\Python311\Lib\site-packages\torch\onnx\_internal\exporter.py&quot;, line 1439, in dynamo_export
  raise OnnxExporterError(

torch.onnx.OnnxExporterError: Failed to export the model to ONNX. Generating SARIF report at 'report_dynamo_export.sarif'. SARIF is a standard format for the output of static analysis tools. SARIF logs can be loaded in VS Code SARIF viewer extension, or SARIF web viewer (https://microsoft.github.io/sarif-web-component/). Please report a bug on PyTorch Github: https://github.com/pytorch/pytorch/issues
</code></pre>
<pre><code>torch.onnx.errors.SymbolicValueError: Unsupported: ONNX export of Pad in opset 9. The sizes of the padding must be constant. Please try opset version 11. [Caused by the value '535 defined in (%535 : int[] = prim::ListConstruct(%405, %534, %405, %533, %405, %532), scope: torchvision.models.detection.faster_rcnn.FasterRCNN::
</code></pre>
<p>Both methods works good with extremally simple models such as</p>
<pre><code>class MyModel(nn.Module):

    def __init__(self):
        super(MyModel, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
</code></pre>
","2024-08-09 15:25:36","0","Question"
"78847305","78845851","","<p><code>torch.multiprocessing</code> does exactly what you need. You can rewrite the <code>train</code> function to the below:</p>
<pre><code>def inner_train(model, optimizer, num_iterations, criterion, data, targets):
    for _ in range(num_iterations):
        output = model(data) 
        loss = criterion(output, targets)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
def train(num_networks, network_size, num_iterations):
    criterion = torch.nn.BCELoss()
    data = torch.zeros((5, 2), device='cuda')
    targets = torch.ones((5, 1), device='cuda')
    
    models = []
    optimizers = []
    for _ in range(num_networks):
        model = MLP(network_size).cuda()
        models.append(model)

        optimizer = torch.optim.Adam(model.parameters())
        optimizers.append(optimizer)

    num_processes = num_networks
    processes = []
    for model, optimizer in zip(models, optimizers):
        p = mp.Process(target=inner_train, args=(model, optimizer, num_iterations, criterion, data, targets,))
        p.start()
        processes.append(p)
    for p in processes:
        p.join()
</code></pre>
<p>The output time should looks something like this:</p>
<pre><code>Training 1 model took 0.07s
Training 5 models took 0.31s
Training 15 models took 0.88s
</code></pre>
","2024-08-08 08:27:24","1","Answer"
"78845917","78845851","","<p>here is a fix for you <code>train</code> function. Idea is to do single backward pass for all models in one go. However there still will be some delays in execution because cuda is synchronizing with the python thread after calling each model.</p>
<pre><code>
class AllModels(nn.Module):
    def __init__(self, n_models, network_size):
        super().__init__()
        self.models = nn.ModuleList()
        for _ in range(n_models):
          model = MLP(network_size)
          self.models.append(model)

    def forward(self, x):
        return torch.concat([model.forward(x) for model in self.models])


def train(num_networks, network_size, num_iterations):
    criterion = torch.nn.BCELoss()
    data = torch.zeros((5, 2), device='cuda')
    targets = torch.ones((5, 1), device='cuda')

    model = AllModels(num_networks, network_size).cuda()

    optimizer = torch.optim.Adam(model.parameters())
    for _ in range(num_iterations):
      loss = 0
      output = model(data)
      loss = criterion(output, targets.repeat(num_networks, 1))
      loss.backward() # 3.29
      optimizer.zero_grad()
      optimizer.step() #0.097

</code></pre>
","2024-08-07 22:34:36","0","Answer"
"78845851","","Quickly training multiple small neural networks","<p>I want to train multiple models on the same training data (just different initializations). Each model has exactly the same architecture. Crucially, the models are extremely small, so having them all in memory at the same time won't be a problem. How can I make this as efficient as possible?</p>
<p>I read that cuda is supposed to be non-blocking, so computations should be parallelized automatically. However, when I write the code in a naive way, I can see that the training time scales linearly with the number of models.</p>
<pre><code>import time
import numpy as np
import torch
import torch.nn as nn

class MLP(nn.Module):
    def __init__(self, network_size):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(2, network_size)
        self.fc2 = nn.Linear(network_size, 1)

    def forward(self, x):
        return torch.sigmoid(self.fc2(self.fc1(x)))

def train(num_networks, network_size, num_iterations):
    criterion = torch.nn.BCELoss()
    data = torch.zeros((5, 2), device='cuda')
    targets = torch.ones((5, 1), device='cuda')
    
    models = []
    for _ in range(num_networks):
        models.append(MLP(network_size).cuda())
    for model in models:
        optimizer = torch.optim.Adam(model.parameters())
        for _ in range(num_iterations):
            output = model(data)
            loss = criterion(output, targets)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

training_start = time.perf_counter()
train(1, 20, 1000)
print(f&quot;Training 1 model took {time.perf_counter() - training_start:.2f}s&quot;)

training_start = time.perf_counter()
train(5, 20, 1000)
print(f&quot;Training 5 models took {time.perf_counter() - training_start:.2f}s&quot;)

training_start = time.perf_counter()
train(15, 20, 1000)
print(f&quot;Training 15 models took {time.perf_counter() - training_start:.2f}s&quot;)
</code></pre>
<p>Output:</p>
<pre><code>Training 1 model took 0.68s
Training 5 models took 3.36s
Training 15 models took 10.18s
</code></pre>
<p>I've been able to optimize this by merging the models into one larger network architecture:</p>
<pre><code>class MergedMLP(nn.Module):
    def __init__(self, num_networks, network_size):
        super().__init__()
        self.fc1 = nn.Linear(2, num_networks * network_size, device='cuda')
        self.fc2 = nn.Linear(num_networks * network_size, num_networks, device='cuda')
        
        self.fc2_weight_mask = torch.zeros_like(self.fc2.weight.data, device='cuda', requires_grad=False)
        for i in range(num_networks):
            self.fc2_weight_mask[i,i*network_size:(i+1)*network_size] = 1
        self.fc2.weight.data *= self.fc2_weight_mask

    def forward(self, x):
        return torch.sigmoid(self.fc2(self.fc1(x)))
    
def train_merged(num_networks, network_size, num_iterations):
    criterion = torch.nn.BCELoss()
    data = torch.zeros((5, 2), device='cuda')
    targets = torch.ones((5, num_networks), device='cuda')
    
    model = MergedMLP(num_networks, network_size).cuda()
    optimizer = torch.optim.Adam(model.parameters())
    for _ in range(num_iterations):
        output = model(data)
        loss = criterion(output, targets)
        optimizer.zero_grad()
        loss.backward()
        model.fc2.weight.grad *= model.fc2_weight_mask
        optimizer.step()
        
training_start = time.perf_counter()
train_merged(15, 20, 1000)
print(f&quot;Training merged models took {time.perf_counter() - training_start:.2f}s&quot;)
</code></pre>
<p>Output:</p>
<pre><code>Training merged models took 0.70s
</code></pre>
<p>Is it possible to achieve the runtime of the merged implementation with code more similar to the naive one? The merged implementation seems to be more error prone, e.g. when I increase the network size or want to extract individual networks from the trained merged model.</p>
","2024-08-07 22:09:07","0","Question"
"78816764","78816668","","<p>I think you could solve this using the <a href=""https://scikit-image.org/docs/stable/api/skimage.draw.html#skimage.draw.line"" rel=""nofollow noreferrer"">skimage.draw.line</a> method where you input the starting (i,j) and ending (0,0) coordinates and it calculates the indices belonging to the line which you can use for indexing.</p>
<p>Worked example:</p>
<pre><code>from skimage.draw import line
import numpy as np
import matplotlib.pyplot as plt
arr = np.zeros((100, 100))
i, j = 10, 80
origin = 50, 50
rr, cc = line(*origin, i, j)
arr[rr, cc] = 1
plt.imshow(arr, cmap='gray', interpolation='nearest')
</code></pre>
<p><a href=""https://i.sstatic.net/bZlfG53U.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bZlfG53U.png"" alt=""Gray plot showing the line"" /></a></p>
<p>Or if you want the line to continue:</p>
<pre><code>arr = np.zeros((100, 100))
rr, cc = line(i, j, 2*origin[0]-i, 2*origin[1]-j)
arr[rr, cc] = 2
plt.imshow(arr, cmap='gray', interpolation='nearest')
</code></pre>
<p><a href=""https://i.sstatic.net/bZqttOKU.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bZqttOKU.png"" alt=""Longer line"" /></a></p>
","2024-07-31 13:55:44","1","Answer"
"78816668","","Get directional elements in matrix","<p>Lets suppose that I have a point of interest in my matrix that is NxN. The point is located in the position ij. So, given the index ij, is there a simple way to get the line elements passing trough ij and to the origin (that is located in the middle of the matrix) ?</p>
<p>I am using torch and I though that using torch.diag would be a first start but acttualy this function does not pass in the middle of the matrix.</p>
<pre><code>def directionalK(kx,ky, indices):
    '''Function that provides the K values at a given direction dictated by the indices'''
    kx_grid,ky_grid = torch.meshgrid(kx,kx, indexing='ij')
    k_grid = torch.sqrt(kx_grid**2 + ky_grid**2) 
    k_grid[...,:len(k_grid)//2] *=-1 
    y,x = indices
    diag = x - len(k_grid)//2
</code></pre>
","2024-07-31 13:35:49","1","Question"
"78794175","78781313","","<p>I don't follow what you are trying to do on a conceptual level, but I can help you diagnose why torch is complaining.</p>
<h3><strong>Issue #1</strong> - Incorrect Matrix Shapes</h3>
<p>For any given observation and prediction (n=1), cross entropy loss will need the real class value y <code>(1,1)</code> and the prediction probabilities for all classes (in this case:- <code>(1,2)</code>.</p>
<p>In each epoch you are feeding the model a tensor of shape <code>(100, 10, 15)</code> and outputting logits of shape <code>(100, 1)</code>. If 100 refers to the number of individual examples - then I found this output shape odd. If for each observation you would like to a binary prediction, an output shape of <code>(100, 2)</code> would make more sense.</p>
<p>That is because internally <code>nn.CrossEntropyLoss</code> will generate the probabilities for each class. For example, the following would work</p>
<pre><code># note the dtypes
outputs = torch.randn(100, 2, requires_grad=True)  # logits
y_train_tensor = torch.randint(low=0, high=1, size=(100,))  # labels

output = loss(outputs, y_train_tensor)
</code></pre>
<h4>Issue #2 - labels dtype</h4>
<p>You've also set the dtype of <code>y_train_tensor</code> to <code>bool</code>. I don't think that torch converts this internally, so best to use a numeric dtype such as <code>torch.int</code>.</p>
<p>Now, to actually solve the problem (which of the tensors to reshape) will depend upon your task and what the model output shape represents.</p>
<p>Hope this helps.</p>
","2024-07-25 15:18:37","0","Answer"
"78781313","","CrossEntropyLoss on PyTorch LSTM model with one classification per timestep","<p>I am trying to make an LSTM model that will detect anomalies in timeseries data. It takes 5 inputs and produces 1 boolean output (True/False if anomaly is detected). The anomaly pattern will usually be between 3 - 4 timesteps in a row. Unlike most LSTM examples where they are forecasting to predict future data, or classifying a whole sequence of data, I am trying to have a True/False detection flag output at every timestep (True at the last timestep point in the patter if it is detected).</p>
<p>Unfortunately it seems like CrossEntropyLoss doesn't allow for anything more than 1D output tensors, and in this case it will be 2D [num sequences, length of sequence with boolean data]</p>
<p>Here is some example code of what I am trying to produce:</p>
<pre><code>import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# Define LSTM classifier model
class LSTMClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMClassifier, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

# Input - 100 examples containing 5 data points per timestep (where there are 10 timesteps)
X_train = np.random.rand(100, 10, 5)
# Output - 100 examples containing 1 True/False output per timestep to match the input
y_train = np.random.choice(a=[True, False], size=(100, 10))  # Binary labels (True or False)

# Convert data to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.bool)

# Define model parameters
input_size = X_train.shape[2] # 5 inputs per timestep
hidden_size = 4 # Pattern we are trying to detect is usually 4 timesteps long
num_layers = 1
output_size = 1 # True/False

# Instantiate the model
model = LSTMClassifier(input_size, hidden_size, num_layers, output_size)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
num_epochs = 10
for epoch in range(num_epochs):
    optimizer.zero_grad()
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)
    loss.backward()
    optimizer.step()
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')

# Test the model
X_test = np.random.rand(10, 10, 5) # Generate some test data - same dimensions as input
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
with torch.no_grad():
    predictions = model(X_test_tensor)
    predicted_outputs = torch.argmax(predictions, dim=1)
    print(&quot;Predicted Outputs:&quot;, predicted_outputs)
</code></pre>
<p>Do I need to re-shape the output (or make the number of outputs from the LSTM equal to the sequence length), or perhaps use a different loss function, or a model other than LSTM?</p>
","2024-07-23 02:11:04","0","Question"
"78774757","78739816","","<p>I have read some papers where researchers have tried to combine positional and character information with CNNs, but they focused more on a grid-based approach. Grid transformers use such types of architectures.</p>
<p>In the case of word-grid, the approach works by appending the input image with word embeddings, such that the image also contains additional information about the text present in that part of the image. For character-grid, this involves appending a one-hot encoded vector representing each character.</p>
<p>Here are some papers on grid-based methods that might be helpful:</p>
<ul>
<li><a href=""https://%5Bhttps://arxiv.org/abs/1706.02337%5D"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1706.02337</a></li>
<li><a href=""https://arxiv.org/abs/2002.06144"" rel=""nofollow noreferrer"">https://arxiv.org/abs/2002.06144</a></li>
<li><a href=""https://arxiv.org/abs/2105.06220"" rel=""nofollow noreferrer"">https://arxiv.org/abs/2105.06220</a></li>
</ul>
<p>These methods cast text with layout information into 2D semantic representations: char-grid and sentence-grid.</p>
","2024-07-21 09:01:41","0","Answer"
"78761963","78693670","","<p>In the <a href=""https://networkx.org/documentation/stable/_modules/networkx/generators/random_graphs.html#barabasi_albert_graph"" rel=""nofollow noreferrer"">source code</a> for the Barabasi-Albert graph generation, they start from an initial star network with m+1 nodes which in the networkx implementation is an undirected network. You can modify this part to generate a directed star graph of m+1 nodes where m edges go out from a central node somewhat like this:</p>
<pre><code>def directed_star_graph(n):
  G = nx.DiGraph()
  for node in range(n):
    G.add_edge(0, node+1)
  return G
</code></pre>
<p>Then change the line in the source code</p>
<pre><code>repeated_nodes = [n for n, d in G.degree() for _ in range(d)]
</code></pre>
<p>to</p>
<pre><code>repeated_nodes = [n for n, d in G.in_degree() for _ in range(d)]
</code></pre>
<p>so that every new node that comes in gets attached to m nodes, thus having the average out-degree constant at m over time, and the attachment is preferential, i.e., proportional to in degrees of the existing nodes.</p>
<p>The initialization does not really matter when you are generating large networks.</p>
","2024-07-17 23:55:40","0","Answer"
"78739816","","Enhancing Document Layout Analysis by Adding Positional and Character Information to CNN Inputs","<p>I am working on document layout analysis and have been exploring CNNs and transformer-based networks for this task. Typically, images are passed as 3-channel RGB inputs to these networks. However, my data source is in PDF format, from which I can extract the exact position and character information directly.</p>
<p>I am concerned that converting this PDF data into images for analysis will result in the loss of valuable positional and character information. My idea is to modify the input dimensions of the CNN from the standard 3 RGB channels to a higher-dimensional input that includes this additional positional and character information.</p>
<p>I understand how CNNs work and highly suspect that this approach might not work, but I would appreciate any feedback or suggestions from the community. Has anyone experimented with augmenting input channels in this way, or does anyone have insights into integrating positional and character data directly into CNNs?</p>
","2024-07-12 10:17:29","-3","Question"
"78736357","78735982","","<p>Maybe preprocessing the image before passing it to the model.predit() would help.</p>
<p>Try using this code-</p>
<pre><code>tf_formatted_image = tf.convert_to_tensor(formatted_image, dtype=tf.float32)   # converting to TensorFlow tensor
tf_formatted_image = tf.expand_dims(tf_formatted_image, axis=0)
tf_formatted_image = tf_formatted_image / 255.0   #normalizing
model = tf.keras.models.load_model('path_to_model')   #loading the model
predictions = model.predict(tf_formatted_image)
</code></pre>
","2024-07-11 15:09:45","0","Answer"
"78735982","","Why does neural network input shape not match image shape?","<p>I have developed a neural network using TensorFlow, and am trying to use it to predict new images. I have loaded a JPEG image as a test example and reformatted it using OpenCV:</p>
<pre><code>formatted_image = cv.resize(image, dsize = (128,128))
</code></pre>
<p>Using <code>image.shape</code> returns (128, 128, 3) which is my target.</p>
<p>However, putting this image through <code>model.predict()</code> gives me the following error:</p>
<pre><code>ValueError: Input 0 of layer &quot;model_1&quot; is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(32, 128, 3)
</code></pre>
<p>I'm not sure where this value is coming from; I've tried a couple of ways of converting it to a tensor, such as <code>tf_formatted_image = tf.convert_to_tensor(formatted_image, dtype=tf.int8)</code>, but this has been unsuccessful.</p>
","2024-07-11 13:55:36","-1","Question"
"78723107","78721703","","<p>For this specific case, you can define a custom accuracy function as a metric and define a <code>Callback</code> for your <code>Keras</code> model.</p>
<p><strong>Custom Accuracy Metric</strong>:</p>
<pre class=""lang-py prettyprint-override""><code>import keras.backend as K

def custom_accuracy(y_true, y_pred, tolerance=0.05):
    absolute_difference = K.abs(y_true - y_pred)
    correct_predictions = K.cast(absolute_difference &lt;= tolerance, dtype='float32')
    return K.mean(correct_predictions)

model.compile(optimizer='adam', loss='mse', metrics=[custom_accuracy])
</code></pre>
<p><strong>Custom Callback</strong>:</p>
<pre class=""lang-py prettyprint-override""><code>from keras.callbacks import Callback
import numpy as np

class CustomAccuracyCallback(Callback):
    def __init__(self, validation_data, tolerance=0.05):
        super(CustomAccuracyCallback, self).__init__()
        self.validation_data = validation_data
        self.tolerance = tolerance

    def on_epoch_end(self, epoch, logs={}):
        x_val, y_val = self.validation_data
        y_pred = self.model.predict(x_val)
        accuracy = np.mean(np.abs(y_val - y_pred) &lt;= self.tolerance)
        print(f&quot;\nEpoch {epoch + 1}: Custom Accuracy: {accuracy:.4f}&quot;)
        logs['custom_accuracy'] = accuracy

custom_callback = CustomAccuracyCallback((x_val, y_val))
model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[custom_callback])
</code></pre>
","2024-07-08 22:48:55","1","Answer"
"78721703","","How do I define/change the accuracy for a non-classification convolutional neural network?","<p>I'm using Keras to make a prediction model. It takes in two time series and outputs a number between 0 and 1. Currently, I am getting very low accuracy as the model is only considered &quot;correct&quot; if it gets the exact number. For example, the correct number is 0.34, it would be considered incorrect if it predicted 0.35. I want to be able to consider all numbers within a range to be correct, for example: within 0.05 of the true value. Another option may be to round, but I have the problem of it outputting 6 decimal places.</p>
<ol>
<li>How can I consider all numbers within a range to be &quot;correct&quot; for the accuracy?</li>
<li>How can I round the output of the CNN?</li>
</ol>
<p>Here is my CNN code:</p>
<pre class=""lang-py prettyprint-override""><code>def networkModel():
    model = tf.keras.Sequential([

tf.keras.layers.Conv2D(filters = 16, kernel_size=(2, 2), activation='relu',padding='same'),
tf.keras.layers.Conv2D(filters = 9, kernel_size=(2, 2), activation='relu',padding='same'),
tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(256, activation='relu'),
tf.keras.layers.Dense(1, activation='sigmoid')

])

    model.compile(optimizer='adam',
            loss = tf.keras.losses.BinaryCrossentropy(),
            metrics=['accuracy'])

    return model
</code></pre>
","2024-07-08 15:24:04","1","Question"
"78717596","78704234","","<h1>No, but ...</h1>
<p><code>torch.where(...)</code> does not detach anything from the computational graph.</p>
<p><code>torch.where(cond, a, b)</code> has the same gradient as <code>a</code> where <code>cond</code> is <code>True</code> and the same as <code>b</code> where <code>cond</code> is <code>False</code></p>
<p>(so in essence, if <code>c = torch.where(cond, a, b)</code>, <code>c.grad</code> is <code>torch.where(cond, a.grad, b.grad)</code>)</p>
<p>In your case though, <code>a</code> and <code>b</code> are constants so all those gradients are 0, which is effectively cutting the results from the graph.</p>
<p>You say your operation is &quot;thresholding&quot;, but <strong>that is not what you are doing!</strong></p>
<p>Thresholding would be keeping the value unless it is above (or below) some threshold. What you are doing is setting the values below the threshold to <code>0</code> and the values above to 1, which is a <a href=""https://en.wikipedia.org/wiki/Heaviside_step_function"" rel=""nofollow noreferrer"">Heaviside step function</a>. It is differentiable almost everywhere, but <strong>its gradient is always 0 when defined</strong> (so unusable for optimization purposes)</p>
<h1>Fix</h1>
<p>You may want to replace that heaviside function with its differentiable approximation, the <a href=""https://en.wikipedia.org/wiki/Sigmoid_function"" rel=""nofollow noreferrer"">sigmoid</a></p>
<p>The code would be something like this</p>
<pre class=""lang-py prettyprint-override""><code>channels[tracker_index]= torch.sigmoid(channel_tensor - threshold)
</code></pre>
<p><strong>Note</strong> also that if you are looking for a loss for this data, you may want to look towards binary cross-entropy, in which case there is a (more stable) <a href=""https://pytorch.org/docs/stable/generated/torch.nn.functional.binary_cross_entropy_with_logits.html"" rel=""nofollow noreferrer"">version</a> in pytorch that takes the raw logits instead of the output of the sigmoid</p>
","2024-07-07 14:43:22","0","Answer"
"78712449","78712391","","<p>Figured it out!</p>
<p>TensorFlow's <code>GradientTape</code> is designed to compute gradients of a scalar output with respect to the variables being watched. However, evidently when you attempt to compute higher-order derivatives (like second derivatives), TensorFlow requires explicit handling.</p>
<p>In the original code, the second gradient (<code>d2psi_dx2</code>) was returning None because TensorFlow's gradient tracking doesn't automatically propagate gradients through nested tapes for higher-order derivatives.</p>
<p>To fix this issue and correctly compute the second derivative, you need to explicitly manage the gradient calculation using separate GradientTape contexts:</p>
<ol>
<li><p><strong>Use Multiple GradientTape Contexts:</strong> Use one <code>GradientTape</code> to compute psi and another nested GradientTape to compute <code>dpsi_dx</code>.</p>
</li>
<li><p><strong>Persistent Tapes:</strong> Ensure both <code>GradientTape</code> contexts are declared as persistent <code>(persistent=True)</code> so that you can compute gradients multiple times within them.</p>
</li>
<li><p><strong>Explicit Derivative Calculation:</strong> After computing the first derivative (<code>dpsi_dx</code>), use the outer <code>GradientTape</code> context to compute the second derivative (<code>d2psi_dx2</code>) with respect to the input <code>x</code>.</p>
</li>
</ol>
<pre><code>def schrodinger_loss(self, x, E):
        with tf.GradientTape(persistent=True) as tape:
            tape.watch(x)
            with tf.GradientTape(persistent=True) as tape1:
                tape1.watch(x)
                psi = self.model(x)
            dpsi_dx = tape1.gradient(psi, x)
        
        d2psi_dx2 = tape.gradient(dpsi_dx, x)
        
        V_x = self.potential_func(x)
        schrodinger_eq = -d2psi_dx2 + (V_x - E) * psi
        return tf.reduce_mean(tf.square(schrodinger_eq))
</code></pre>
","2024-07-05 16:17:39","0","Answer"
"78712391","","TensorFlow second derivative calculation always returns zero in Quantum PINN solver","<p>I'm attempting to implement a simple Physics-Informed Neural Network (PINN) for Solving the <a href=""https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation"" rel=""nofollow noreferrer"">time-independent Schrödinger equation</a> given an arbitrary <a href=""https://en.wikipedia.org/wiki/Scalar_potential"" rel=""nofollow noreferrer"">scalar potential</a>. The details aren't, I think, terrible relevant. I'm using TensorFlow 2.x and encountering an issue where the second derivative calculation always returns <code>None</code>, irrespective of the potential function used. Here's a simplified version of my code which exhibits the issue:</p>
<pre><code>import tensorflow as tf

class QuantumPINNSolver:
    def __init__(self, potential_func):
        self.potential_func = potential_func
        self.model = self.build_model()

    def build_model(self):
        return tf.keras.Sequential([
            tf.keras.layers.Dense(50, activation='relu', input_shape=(1,), dtype=tf.float64),
            tf.keras.layers.Dense(50, activation='relu', dtype=tf.float64),
            tf.keras.layers.Dense(50, activation='relu', dtype=tf.float64),
            tf.keras.layers.Dense(1, activation=None, dtype=tf.float64)
        ])

    @tf.function
    def schrodinger_loss(self, x, E):
        with tf.GradientTape(persistent=True) as tape2:
            with tf.GradientTape(persistent=True) as tape1:
                tape1.watch(x)
                psi = self.model(x)
            dpsi_dx = tape1.gradient(psi, x)
        d2psi_dx2 = tape2.gradient(dpsi_dx, x)
        
        print(&quot;psi:&quot;, psi)
        print(&quot;dpsi_dx:&quot;, dpsi_dx)
        print(&quot;d2psi_dx2:&quot;, d2psi_dx2)  # This is always zero
        
        V_x = self.potential_func(x)
        schrodinger_eq = -d2psi_dx2 + (V_x - E) * psi
        return tf.reduce_mean(tf.square(schrodinger_eq))

# Usage
def harmonic_oscillator_potential(x):
    return 0.5 * tf.square(x)

solver = QuantumPINNSolver(potential_func=harmonic_oscillator_potential)
x = tf.random.uniform((100, 1), minval=-5, maxval=5, dtype=tf.float64)
E = tf.constant(0.5, dtype=tf.float64)
loss = solver.schrodinger_loss(x, E)
</code></pre>
<p>The issue is that <code>d2psi_dx2</code> is always <code>None</code>, even though <code>psi</code> and <code>dpsi_dx</code> have non-zero values. I've tried:</p>
<ol>
<li>Using different potential functions</li>
<li>Changing the model architecture</li>
<li>Using different activation functions</li>
<li>Adjusting the input range and <code>dtype</code></li>
</ol>
<p>...but the second derivative remains <code>None</code>. What could be causing this, and how can I fix it to properly calculate the second derivative? I'm not terribly familiar with <code>TensorFlow</code> (and I'm still trying to wrap my head around <code>GradientTape</code>), and I expect that this is some simple issue I haven't uncovered by reading the documentation.</p>
","2024-07-05 16:01:15","1","Question"
"78704234","","Does using torch.where to threshold a tensor detach it tensor from the computational graph?","<p>I'm writing a custom loss function in PyTorch for multiclass semantic segmentation. One part of this function is thresholding select channels from the tensor, which are indicated with tracker_index.</p>
<p>The last part of the function that is a part of the computational graph is the channel_tensor, and if I comment out the line where torch.where is applied, everything runs smoothly. I've tried setting 1 and 0 to float32 tensors and ensured that they are on the same device as the channel_tensor, which leads me to believe that eighter thresholding is not differentiable, so cannot be a part of the loss function, or torch.where will always detach the tensor from the computational graph. Please advise.</p>
<pre><code>channel_tensor =torch.select(
     segmentation_output,
     dim=-3,
     index=tracker_index
)
channels[tracker_index]= torch.where(channel_tensor &gt; self.threshold, torch.tensor(1, device=channel_tensor.device, dtype=torch.float32), torch.tensor(0, device=channel_tensor.device, dtype=torch.float32))
</code></pre>
","2024-07-03 21:13:24","1","Question"
"78700738","77989807","","<h2>The error is due to files mismatch while installing ultralytics.</h2>
<ul>
<li>Recently I installed Ultralytics with Cuda and it worked, Here are the procedure I followed.</li>
<li><strong>Note:</strong> I too faced the same issue. Follow the steps to avoid those. This all done in anaconda.</li>
<li>By following the steps you can use your <strong>GPU</strong> as well.</li>
</ul>
<h3><strong>Step 1:</strong> Create the environment</h3>
<pre><code>conda create -n name python=3.10
</code></pre>
<h3><strong>Step 2:</strong> Install torch with cuda from <a href=""https://pytorch.org/get-started/locally/"" rel=""nofollow noreferrer"">PyTorch official</a>.</h3>
<pre><code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 
or
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
</code></pre>
<ul>
<li>After installing please verify, is that installed properly</li>
</ul>
<pre class=""lang-py prettyprint-override""><code>import torch
print(torch.cuda.is_available())

# Output
&gt;&gt;&gt; True
</code></pre>
<ul>
<li>Also verify the Libraries check list.</li>
</ul>
<pre><code>pip list

filelock          3.13.1
fsspec            2024.2.0
intel-openmp      2021.4.0
Jinja2            3.1.3
MarkupSafe        2.1.5
mkl               2021.4.0
mpmath            1.3.0
networkx          3.2.1
numpy             1.26.3
pillow            10.2.0
pip               24.0
setuptools        69.5.1
sympy             1.12
tbb               2021.11.0
torch             2.3.1+cu121
torchaudio        2.3.1+cu121
torchvision       0.18.1+cu121
typing_extensions 4.9.0
wheel             0.43.0
</code></pre>
<h3><strong>Step 3:</strong> Install the Ultralytics and check the import</h3>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt;pip install ultralytics==8.2.48

import ultralytics
print(ultralytics.checks())

&gt;&gt;&gt;Ultralytics YOLOv8.2.48 🚀 Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA 
...GeForce RTX 4070, 12282MiB)
...Setup complete ✅ (28 CPUs, 63.8 GB RAM, 823.7/1905.5 GB disk)
</code></pre>
","2024-07-03 07:55:17","0","Answer"
"78699478","78369831","","<p>Thank you for your question and helpful code snippets. I wrote up a quick scaling / training script that generates the mlp and mma objects, using the Tco and Tei as input features:</p>
<pre><code>#train mlp 2 features
Xs = ['Tco','Tei']

mlp = MLPRegressor(hidden_layer_sizes=[16])
s = CustomMinMaxGekkoScaler(df,Xs,Y)
ds = s.scaledData()
mma = s.minMaxValues()

mlp.fit(ds[Xs],ds[Y])
</code></pre>
<p>After running your last block of code, it outputs the following result:</p>
<pre><code>Optimized Tco: 303.2153289
Optimized Predicted Pel: 876.14340232
Gekko Solvetime: 0.042400000006 s
</code></pre>
<p>My guess is that when you trained the mlp object, you trained it on all 3 input features, rather than just the 2 you use as decision variables, which causes the ValueError. If you choose to use the 3-input model, you would also have to include the additional input, which I assume is 'm_cond', as a constant or another decision variable, like so:</p>
<pre><code>m_cond = 0.000266172
# Predict Pel using the trained neural network 
predicted_Pel = Gekko_NN_SKlearn(mlp, mma, m).predict([Tco, Tei,m_cond])
</code></pre>
<p>Hopefully this response is helpful.</p>
","2024-07-02 22:43:04","1","Answer"
"78698753","78698399","","<ol>
<li>Using &quot;random_state&quot; means something random is happening. Unlike your custom implementation, sklearn shuffles your training data by default.</li>
<li>Convergence: You set &quot;max_iter&quot; to 1000 so the weights get adjusted 1000 times. But your custom implementation will stop adjusting the weights as soon as there are no misclassifications.</li>
<li>Your actual data. Does it really have a linear relationship? This would matter as well.</li>
<li>Did you use exactly the same train and test data ?</li>
</ol>
","2024-07-02 18:38:50","0","Answer"
"78698399","","Difference in My perceptron and sklearn Perceptron","<p>I coded the perceptron algorithm form scratch and compared the weights I obtained after training with the weights I obtained after training the sklearn perceptron model. I believe even the sklearn model initializes the weights and biases as a zero vector and I chose the learning rate <code>eta0=1</code> to match my perceptron code. (Note: the bias in my code is the last term in the vector <code>w_b</code>)</p>
<p>My Code:</p>
<pre><code>def perceptron(X_train, y_train):
    #initialize weights as 0
    w = np.zeros(len(X_train.columns))
    b = 0
    w_b = np.append(w, b)
    while True:
        misclassifications = 0  
        for X , Y in zip(X_train.values, y_train.values):
            X_i = np.append(X, 1)
            if Y*(np.dot(X_i,w_b)) &lt;= 0:
                w_b = w_b + Y*X_i
                misclassifications += 1
        if misclassifications == 0:
            break
    return w_b

w_b = perceptron(X_train, y_train)
</code></pre>
<p>Result: <code>[-3.   6.7 -1. ]</code></p>
<p>sklearn code:</p>
<pre><code>perceptron = Perceptron(max_iter=1000, eta0=1,random_state=42) 
perceptron.fit(X_train, y_train)

print(&quot;weights are&quot;,perceptron.coef_)
print(&quot;bias is&quot;,perceptron.intercept_)
</code></pre>
<p>Result: <code>weights are [[-4.7 10.1]] bias is [-2.]</code></p>
<p>I expected the weights to be same but they aren't. Any clue on why?</p>
","2024-07-02 17:04:46","0","Question"
"78696326","78696130","","<p>it comes from the fact that <code>inputs[:,:,0]</code> returns a copy of the data, making <code>inputs[:,:,0]</code> unseen by the graph as opposed to <code>inputs</code>. It is impossible to compute gradients on unseen data (how could you know &quot;the influence&quot; of the two elements of inputs on the scalar value in cs_hat[:, 0] without knowing the intermediate operations?).</p>
<p>What you want to achieve is totally possible, and without much overhead (I don't know how torch computes gradients but I assume it is darn efficient). You can do:</p>
<pre><code>cs_hat = outputs[2]
cs_dt = torch.autograd.grad(cs_hat, inputs, grad_outputs=torch.ones_like(cs_hat), create_graph=True)[0]
cs_dt[:, :, 0]  # gradient with respect to inputs[:, :, 0]
</code></pre>
","2024-07-02 10:01:53","0","Answer"
"78696130","","PyTorch Gradient Computation Fails When Not Using Entire Input Tensor","<p>I have a model that takes an input tensor , along with other inputs k and D. The model outputs several tensors, including cs_hat. When I compute gradients of cs_hat with respect to the first slice of inputs (inputs[:,:,0]), the gradient computation only succeeds if I compute it with respect to the entire tensor inputs instead of just the slice.</p>
<p>Here is a simplified version of my code that illustrates the problem:</p>
<pre><code>import torch
from torch import nn

class MyModel(torch.nn.Module):

    def __init__(self, input_size = 3 , ffn_size = 15, ffn_layers = 2, res_block_size = 15, res_block_layers = 2):
        super(MyModel, self).__init__()

        self.input_size = input_size
        self.activation = nn.LeakyReLU()

        self.ffn_size = ffn_size
        self.ffn_layers = ffn_layers
        self.res_block_size = res_block_size
        self.res_block_layers = res_block_layers

        self.linear_block_0 = self._make_linear_block(self.ffn_size, self.ffn_layers, input_size=self.input_size)

        self.final_layer_a = nn.Linear(self.res_block_size, 1, bias=False)
        self.final_layer_b = nn.Linear(self.res_block_size, 1, bias=False)
        self.final_layer_c = nn.Linear(self.res_block_size, 1, bias=False)
        self.final_layer_d = nn.Linear(self.res_block_size, 1, bias=False)




    def _make_linear_block(self, width, depth, input_size = None):

        if input_size is None:
            linear_block = nn.ModuleList([nn.Linear(width , width), self.activation])
        else:
            linear_block = nn.ModuleList([nn.Linear(input_size , width), self.activation])

        for _ in range(depth - 1):
            linear_block.append(nn.Linear(width, width))
            linear_block.append(self.activation)

        linear_block_ = nn.Sequential(*linear_block)

        return linear_block_


    def forward(self, inputs,k,D):

        t = inputs[:,:,0]
        x = inputs[:,:,1]

        input_t = torch.cat([t,k.view(-1,1),D.view(-1,1)],dim = -1)

        z0 = self.linear_block_0(input_t)

        a = self.final_layer_a(z0)
        b = self.final_layer_b(z0)
        c = self.final_layer_c(z0)
        d = self.final_layer_d(z0)

        return a,b,c,d


#Main

model = MyModel()

inputs = torch.tensor([[[0.4521, 0.5205]], [[0.3066, 0.6816]], [[0.0547, 0.9297]], [[0.3936, 0.9229]]], requires_grad=True) #supposed to be of size (batch_size,1 ,1)

batch_size = 4

k = torch.randn(batch_size, requires_grad=True)
D = torch.randn(batch_size, requires_grad=True)

# Forward pass
outputs = model(inputs, k, D)
cs_hat = outputs[2]  # Assuming cs_hat is the third output

# Gradient computation that works
cs_dt = torch.autograd.grad(cs_hat, inputs, grad_outputs=torch.ones_like(cs_hat), create_graph=True)[0]
# Gradient computation that fails
cs_dt = torch.autograd.grad(cs_hat, inputs[:,:,0], grad_outputs=torch.ones_like(cs_hat), create_graph=True)[0]
</code></pre>
<p>My error message:
<code>RuntimeError: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.</code></p>
<p>Ensuring requires_grad=True is set before any operations.</p>
<p>Using torch.ones_like(cs_a_hat) to match the shape of grad_outputs.</p>
<p>Checking that t actually influences cs_hat (it does).</p>
<p>Setting allow_unused=True just gives me a None result (even though t influences cs_hat).</p>
<p>Tried the same with f(inputs)=2*inputs instead of passing to neural network. Same error</p>
<p>Questions:
Why does excluding parts of the input tensor from the gradient calculation cause this issue?
How can I correctly compute gradients with respect to only the needed parts of the input tensor without encountering this error?
If I accept that I need to use the whole input, will this add a lot computational complexity?</p>
","2024-07-02 09:21:58","0","Question"
"78694932","78693937","","<p>When you run</p>
<pre class=""lang-py prettyprint-override""><code>model.sc1.weight = nn.Parameter(1. * model.sc1.weight)
model.sc2.weight = nn.Parameter(1. * model.sc2.weight)
</code></pre>
<p>You are not &quot;multiplying by a scalar&quot;. You are creating an entirely new object (<code>nn.Parameter(1. * model.sc1.weight)</code>) and assigning it to the <code>.weight</code> attribute.</p>
<p>I assume you are updating your model with a standard pytorch optimizer, something like:</p>
<pre class=""lang-py prettyprint-override""><code>model = TSP(...)
opt = torch.optim.SGD(model.parameters(), lr=1e-3)
</code></pre>
<p>When you run <code>model.sc1.weight = nn.Parameter(1. * model.sc1.weight)</code>, you create an entirely new object in <code>model.sc1.weight</code>, but the optimizer still references the old object.</p>
<p>You can validate this as follows:</p>
<pre class=""lang-py prettyprint-override""><code># data pointer of weight
model.sc1.weight.data_ptr()
&gt; 124805056

# data pointer of weight in the optimizer 
opt.param_groups[0]['params'][0].data_ptr()
&gt; 124805056

# now create new weight object
model.sc1.weight = nn.Parameter(1. * model.sc1.weight)

# data pointer of model weight has changed
model.sc1.weight.data_ptr()
&gt; 139582720

# data pointer of optimizer has not
opt.param_groups[0]['params'][0].data_ptr()
&gt; 124805056
</code></pre>
<p>To avoid this, update the object instead of creating a new object</p>
<pre class=""lang-py prettyprint-override""><code># data pointer of weight
model.sc1.weight.data_ptr()
&gt; 124805056

# data pointer of weight in the optimizer 
opt.param_groups[0]['params'][0].data_ptr()
&gt; 124805056

# update data of weight tensor with in-place operation
model.sc1.weight.data.mul_(2.)

# weight and optimizer still have same data pointer
model.sc1.weight.data_ptr()
&gt; 124805056

opt.param_groups[0]['params'][0].data_ptr()
&gt; 124805056
</code></pre>
","2024-07-02 03:28:27","1","Answer"
"78693937","","Learning stops when you multiply the weights of a layer with a scalar?","<p>I am trying to implement sparsely connected weight matrices for my simple 3-layer feedforward model. To do this I implemented a mask for each of my layers with a certain % of zeros, with the idea being that I would like to zero out the same set of weights after every optimizer step so that my layers are not fully connected. But I am having trouble with this because when I do an element-wise multiplication of the mask with the weight matrices, the weights stop changing in subsequent backward passes. To see if my mask is causing the issue, I did just multiplied my weight matrices with the scalar 1.0 and this recreates the issue. What might be happening here? I checked and gradients still get calculated. It’s just that the loss doesn’t go down anymore and the weights don’t change. Does doing this multiplication somehow disconnect the weights from the graph?</p>
<p>My model:</p>
<pre><code>class TSP(nn.Module):

  def __init__(self, input_size, hidden_size):
    super(TSP, self).__init__()
    self.sc1 = nn.Linear(input_size, hidden_size)
    self.sc2 = nn.Linear(hidden_size, input_size)

    torch.nn.init.normal_(self.sc1.weight, mean=0, std=0.1)
    torch.nn.init.normal_(self.sc2.weight, mean=0, std=0.1)

  def forward(self, x):
    x = torch.relu(self.sc1(x)) 
    x = (self.sc2(x))
    return x


  def predict_hidden(self, x):
    x = torch.relu(self.sc1(x))
    return x

</code></pre>
<p>To recreate this issue all that is needed is the following and the weights stop getting updated:</p>
<pre><code>model.sc1.weight = nn.Parameter(1. * model.sc1.weight)
model.sc2.weight = nn.Parameter(1. * model.sc2.weight)
</code></pre>
","2024-07-01 19:19:07","0","Question"
"78693670","","Python implementation for Price Model - scale-free network growth model for directed graphs","<p>I'm trying to create a scale-free network growing model in networkx in Python. Plenty of resources exist on Github for the Barabassi-Albert Model, but my graph needs to be directed and BA is designed only for undirected graphs.</p>
<p>I understand that the Price Model is effectively the directed equivalent of the BA Model, but I can't find any online resources for how to implement that in Python (preferably nx). Could anyone point me in the right direction?</p>
<p>I've tried to tweak the BA model to account for outbound degrees, but implementation hasn't worked so far:</p>
<pre><code>    deg = G.out_degree(n) ## number of outbound edges from this node
    print('out degree',deg)
    deg_weight = deg / (2 * len(G.edges()))
    print('degree weighting:',deg_weight)
    edge_weight = edges_per_node[pre_node_type] ## weighting by observed connectivity
    adjusted_prob = prob * deg_weight * edge_weight
    n_probs.append(adjusted_prob)
    nodes.append(n)
</code></pre>
","2024-07-01 18:13:31","0","Question"
"78677993","","How do I implement training a neural network when generating the data on spot?","<p>I would like to construct a surrogate model of a physics simulation. Thus I am able to generate the data by myself. The data itself is very big, so it makes sense to generate a few data samples (e.g. a batch of 124) and then use it for training immediately instead of generating million of samples as I could not save such data set. In this way I could generate a batch, save it temporarily/send it to my neural network that is waiting for data and then after training on it discard it.</p>
<p>I usually implement my models with pytorch and I am also familiar with the torch.utils.data.DataLoader that can fetch batches into the RAM but it needs the directory structure and file ID's, i.e. a whole dataset needs to be saved somewhere.</p>
","2024-06-27 13:31:24","1","Question"
"78676169","78676089","","<p>I solved the problem I transposed the shape in the customdataset class then I re-transposed it to view the frame images</p>
","2024-06-27 07:36:56","0","Answer"
"78676089","","pytorch doesn't read input channels as it's supposed","<p>I'm building a conv3d model for videos using pytorch. the input is <code>(2, 30, 46, 140, 1)</code> but pytorch reads that the input channel is the second one and it's actually the 4th.</p>
<pre><code>        self.conv1 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
Given groups=1, weight of size [32, 1, 3, 3, 3], expected input[2, 30, 46, 140, 1] to have 1 channels, but got 30 channels instead
</code></pre>
<p>I tried to reshape the input to be <code>(2, 1, 30, 46, 140)</code> but then it doesn't show the frames and gives an error that input is wrong</p>
<pre><code>TypeError: Invalid shape (30, 46, 140) for image data
</code></pre>
<p>keep in mind that I tried running the same model with same input on tensorflow and it worked but I can't work with tensorflow due to dependency issues</p>
","2024-06-27 07:19:41","0","Question"
"78661866","78649611","","<p>you can't use predict from cli to save bounding boxes because yolo segmentation save_txt argument only save the x and y for points of each segment. you should a separate write a python script for this job.</p>
","2024-06-24 10:32:54","0","Answer"
"78650898","78650660","","<p>Normally, the training in TensorFlow is done in batches of your training data (currently, the batch size defaults to <code>32</code>). Your training data will be split using the batch size and iteratively propagated through the model. So it is indeed using your training samples each as input during training.</p>
<p>The same goes for inference of the model. You can pass multiple test samples to the model (including a batch size), which is why you get an error. The <code>.predict()</code> function expects a collection of samples (e.g. <code>np.array</code>). Since a sample of your addition model requires to be of shape <code>(2,)</code> the required shape to give to the <code>.predict()</code> function needs to be <code>(None, 2)</code>. <code>None</code> indicates that you can have any number of samples.</p>
<p>Note that the output of the <code>.predict()</code> function also returns the predictions for the number of provided samples. To examine your model I suggest using TensorFlow Graph. It can be displayed in the TensorBoard and also displays the shape of each layer. For a simplified view you can just use <code>model.summary()</code>.</p>
","2024-06-21 07:07:41","2","Answer"
"78650660","","Inconsistency in input shape to neural network","<p>I coded two simple neural networks to add two numbers, and to square a number. I used them to create a program to multiply two numbers.</p>
<pre><code>import tensorflow as tf
import numpy as np

model_add = tf.keras.models.load_model('model_add.keras')
model_sqr = tf.keras.models.load_model('model_sqr.keras')

predicted_product = model_sqr.predict(model_add.predict(np.array([3, 4]))) - model_sqr.predict(np.array([3])) -  model_sqr.predict(np.array([4]))
print(predicted_product/2)
</code></pre>
<p>I had specified an input shape of (1,) for the square model and trained it on this data:</p>
<pre><code>x_train = np.random.random((200000,1))*100-50
</code></pre>
<p>For the addition model, I trained it on</p>
<pre><code>X_train = np.random.rand(num_train, 2)
</code></pre>
<p>I assume that since each element of the training array is what is inputted to the model each time during training, similarly, it is that same shape that is to be used for inputting testing data to the model. This is as it is for the square model, where I trained it on inputs of shape (200000,1) and used numpy arrays of shape (1,) as inputs.</p>
<p>But when I run this program, the following error shows up;</p>
<pre><code>Invalid input shape for input Tensor(&quot;sequential_1/Cast:0&quot;, shape=(2,), dtype=float32). 
Expected shape (None, 2), but input has incompatible shape (2,)
</code></pre>
<p>It looks like I should have used np.array([[3, 4]]) instead of np.array([3, 4]). But since each element of the training data for the addition model is of the shape (2,), shouldn't that be what I use?</p>
<p>EDIT: The add model I'm using is</p>
<pre><code>num_train = 1000

X_train = np.random.rand(num_train, 2)
y_train_add = X_train[:, 0] + X_train[:, 1]

model_add = Sequential(
        [
            Dense(10),
            Dense(1)
            ]
        )
batch_size = 32
epochs = 100

model_add.compile(loss = 'mse', optimizer='adam')
model_add.fit(X_train, y_train_add, batch_size=batch_size, epochs=epochs, verbose = 1)
</code></pre>
<p>And the square model I'm using is coded as:</p>
<pre><code>x_train = np.random.random((200000,1))*100-50
y_train = np.square(x_train)

model_sqr = Sequential(
        [
            Dense(8, activation = 'elu', kernel_regularizer = regularizers.l2(0.001), input_shape = (1,)),
            Dense(8, activation = 'elu', kernel_regularizer = regularizers.l2(0.001)),
            Dense(1)
            ]

        )

batch_size = 32
epochs = 100

model_sqr.compile(loss = 'mse', optimizer='adam')
model_sqr.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 1)
</code></pre>
","2024-06-21 06:07:38","1","Question"
"78649611","","How to add the bounding box values to the labels text files during prediction with a trained YOLO-V8 instance segmentation model?","<p>I trained a YOLO-V8 instance segmentation model to segment an object with class label 0. I used the CLI to instantiate the trained model and predict on the test data.</p>
<pre><code>!yolo task=segment mode=predict model='/weights/best.pt' conf=0.25 source='/test/images' imgsz=1024 save=True save_txt=True save_conf=True
</code></pre>
<p>After prediction, the label files gets stored in .txt format. These label files contain the class index followed by the polygonal coordinates and finally the confidence score of the bounding box predictions. But, bounding box coordinates, that is, x-center, y-center, width, height are not included in the label file. I would also like to include these bounding box coordinates to each of the labels file since I would like to use these bounding box coordinates later for post-processing. A sample label file content looks like this:</p>
<pre><code>0 0.21582 0.0898438 0.214844 0.0908203 0.213867 0.0908203 0.210938 0.09375 0.210938 0.0947266 0.203125 0.102539 0.203125 0.103516 0.201172 0.105469 0.200195 0.105469 0.199219 0.106445 0.199219 0.113281 0.200195 0.114258 0.200195 0.115234 0.203125 0.115234 0.204102 0.116211 0.223633 0.116211 0.224609 0.117188 0.227539 0.117188 0.228516 0.118164 0.230469 0.118164 0.231445 0.119141 0.234375 0.119141 0.235352 0.120117 0.248047 0.120117 0.249023 0.121094 0.251953 0.121094 0.25293 0.12207 0.254883 0.0927734 0.260742 0.0917969 0.256836 0.0917969 0.255859 0.0908203 0.233398 0.0908203 0.232422 0.0898438 0.910849
</code></pre>
<p>I am not saving the predictions to any 'result' variable here and I am running the predictions only in the CLI.</p>
","2024-06-20 21:15:36","0","Question"
"78649529","78646747","","<p>I was able to pass the data to the <code>fastai.Learner</code> to train the model and get results from <code>plot_confusion_matrix</code>. My conclusion that <code>fastai</code> is not designed to work with custom Datasets and DataLoaders and expecting you to use their API for loading the data. I think that in your case it might be worth to switch to
<code>TabularDataLoaders</code> and load the data using <code>TabularDataLoaders.from_df</code>. Or alternatively use <code>ImageBlock</code> if you are working with images.</p>
<p>Basically to give the most optimal solution to the question it is important to know what data are you using. Are you working with images? Are images stored in files? What type of files? Or the input data are simple arrays?</p>
<p>Also function <code>plot_top_losses</code> doesn't work well if you have numpy dataset as the input. Function plots <code>worst_k</code> examples, and most probably it works only with data that is loaded using <code>ImageBlocks</code> and etc.</p>
<p>Given current inputs there is two options how to fix the code:</p>
<ol>
<li>Assume numpy inputs. Create custom dataloader using fastai API.</li>
<li>Assume numpy inputs. Create custom dataloaders using pytorch API.</li>
</ol>
<p><strong>Solution 1:</strong>
Building custom numpy dataloader for fastai Learner using fastai DataBlock API:</p>
<pre><code>from fastai.vision.all import *
from fastai.data.all import *

def make_dataloaders_from_numpy_data(image, label, loader=False):
    def pass_index(idx):
        return idx

    def get_x(i):
        val = image[i]
        return torch.Tensor(val)

    def get_y(i):
        # val = [label[i]]
        # res = torch.Tensor(val).to(torch.int64)
        return label[i]

    dblock = DataBlock(
        blocks=(DataBlock, CategoryBlock),
        get_items=pass_index,
        get_x=get_x,
        get_y=get_y)

    # pass in a list of index
    num_images = image.shape[0]

    source = list(range(num_images))

    if not loader:
        ds = dblock.datasets(source)    
        return ds
    
    return dblock.dataloaders(source, batch_size = 1)    

train_ds = make_dataloaders_from_numpy_data(X_train, y_train)
test_ds = make_dataloaders_from_numpy_data(X_test, y_test)


train_ld = DataLoader(train_ds, batch_size=64)
test_ld = DataLoader(test_ds, batch_size=64)
dls = DataLoaders(train_ld, test_ld)


dls_val = make_dataloaders_from_numpy_data(X_val, y_val,loader=True)



# Initialize the model and the Learner
model = DraftCNN()
learn = Learner(dls, 
                model, 
                loss_func=CrossEntropyLossFlat(), 
                metrics=[accuracy, Precision(average='macro'),  Recall(average='macro'), F1Score(average='macro')])

# # # # Train the model
learn.fit_one_cycle(1)


# Get predictions and interpret them on the validation set
interp = ClassificationInterpretation.from_learner(learn, dl=dls_val)
interp.plot_confusion_matrix()
plt.show()

</code></pre>
<p><strong>Solution 2</strong></p>
<p>Building custom numpy dataloader for fastai Learner using pytorch API for <code>Dataset</code> and <code>DataLoader</code></p>
<pre><code>from torch.utils.data import Dataset
from fastai.data.core import DataLoaders

class CustomDataclass(Dataset):
    def __init__(self, X: np.ndarray, y: np.ndarray):
        &quot;&quot;&quot;
        Will iterate over the dataset
        &quot;&quot;&quot;
        self.data = X
        self.labels = y

        # Not clear what is self.vocab for
        # However part of this attribute is used for plotting labels in `ClassificationInterpretation`
        self.vocab = (None,
                      ['class_0', 'class_1', 'class_2', 'class_3'])

    def __len__(self):
        return self.data.shape[0]

    def __getitem__(self, idx: int):
      data = self.data[idx,...]

      # labels can't be single values and must be converted to a list
      labels = [self.labels[idx]]

      return  (torch.Tensor(data),  
               torch.Tensor(labels).to(torch.int64) # labels must be integers
               )


train_ds = CustomDataclass(X_train, y_train)
test_ds = CustomDataclass(X_test, y_test)
val_ds = CustomDataclass(X_val, y_val)



from torch.utils.data import DataLoader
bs = 64
train_loader = DataLoader(train_ds, batch_size = bs)
test_loader = DataLoader(test_ds, batch_size = bs)

# Val dataset used in interpretation phase where pytorch dataloaders doesn't work
from fastai.data.core import DataLoader
val_loader = DataLoader(val_ds, batch_size = bs)



dls = DataLoaders(train_loader, test_loader)

# Initialize the model and the Learner
model = DraftCNN()
learn = Learner(dls, 
                model, 
                loss_func=CrossEntropyLossFlat(), 
                metrics=[accuracy, Precision(average='macro'),  Recall(average='macro'), F1Score(average='macro')])

# # # # Train the model
learn.fit_one_cycle(4)



# Get predictions and interpret them on the validation set
interp = ClassificationInterpretation.from_learner(learn, dl=val_loader)
interp.plot_confusion_matrix()
plt.show()

</code></pre>
<p><strong>Other errors that are fixed by my code:</strong></p>
<ol>
<li>dataset must return labels in lists:</li>
</ol>
<pre><code>learn.fit_one_cycle(4)
...
return torch.stack(batch, 0, out=out)

RuntimeError: stack expects each tensor to be equal size, but got [3] at entry 0 and [0] at entry 1
</code></pre>
<ol start=""2"">
<li>Added <code>vocab</code> attribute to pytorch DataClass:</li>
</ol>
<pre><code>interp = ClassificationInterpretation.from_learner(learn, dl=val_loader)
...
  File &quot;/Users/ivanpetrov/.pyenv/versions/3.11.6/envs/stack_overflow_env/lib/python3.11/site-packages/fastcore/basics.py&quot;, line 507, in __getattr__
    if attr is not None: return getattr(attr,k)
                                ^^^^^^^^^^^^^^^
AttributeError: 'CustomDataclass' object has no attribute 'vocab'
</code></pre>
","2024-06-20 20:52:25","1","Answer"
"78646747","","Wrong shape at fully connected layer: mat1 and mat2 shapes cannot be multiplied","<p>I have the following model. It is training well. The shapes of my splits are:</p>
<ul>
<li>X_train (98, 1, 40, 844)</li>
<li>X_val (21, 1, 40, 844)</li>
<li>X_test (21, 1, 40, 844)</li>
</ul>
<p>However, I am getting the following error at <code>x = F.relu(self.fc1(x))</code> in <code>forward</code>. When I attempt to interpret the model on the validation set.</p>
<pre><code># Create a DataLoader for the validation set
valid_dl = learn.dls.test_dl(X_val, y_val)

# Get predictions and interpret them on the validation set
interp = ClassificationInterpretation.from_learner(learn, dl=valid_dl) 
</code></pre>
<p><code>RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x2110 and 67520x128)</code></p>
<p>I have checked dozens of similar questions but I am unable to find a solution. Here is the code.</p>
<pre class=""lang-py prettyprint-override""><code>from fastai.vision.all import *
import librosa
import numpy as np
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
from torchsummary import summary

[...] #labels in y can be [0,1,2,3]

# Split the data
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Reshape data for CNN input (add channel dimension)
X_train = X_train[:, np.newaxis, :, :]
X_val = X_val[:, np.newaxis, :, :]
X_test = X_test[:, np.newaxis, :, :]

#X_train.shape, X_val.shape, X_test.shape
#((98, 1, 40, 844), (21, 1, 40, 844), (21, 1, 40, 844))

class DraftCNN(nn.Module):
    def __init__(self):
        super(DraftCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        
        # Calculate flattened size based on input dimensions
        with torch.no_grad():
            dummy_input = torch.zeros(1, 1, 40, 844)  # shape of one input sample
            dummy_output = self.pool(self.conv2(self.pool(F.relu(self.conv1(dummy_input)))))
            self.flattened_size = dummy_output.view(dummy_output.size(0), -1).size(1)
        
        self.fc1 = nn.Linear(self.flattened_size, 128)
        self.fc2 = nn.Linear(128, 4)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)  # Flatten the output of convolutions
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# Initialize the model and the Learner
model = AudioCNN()
learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=[accuracy, Precision(average='macro'),  Recall(average='macro'), F1Score(average='macro')])

# Train the model
learn.fit_one_cycle(8)

print(summary(model, (1, 40, 844)))

# Create a DataLoader for the validation set
valid_dl = learn.dls.test_dl(X_val, y_val)

# Get predictions and interpret them on the validation set
interp = ClassificationInterpretation.from_learner(learn, dl=valid_dl)
interp.plot_confusion_matrix()
interp.plot_top_losses(5)
</code></pre>
<p>I tried changing the forward function and the shapes of the layers but I keep getting the same error.</p>
<p>Edit. Upon request, I have added more code.</p>
","2024-06-20 09:53:10","2","Question"
"78645642","78642379","","<p>Your question is tangled with 2 meanings, the transformer block and Linear block. It could be explained with 2 branches:</p>
<ol>
<li>What are the purposes by having higher, equal, lower out_features in the network?</li>
</ol>
<ul>
<li>In image transformers, qkv(query, key value) is designed to get the correlations of input patches. <code>out_features=2304</code> is 3 multiples of <code>in_features=768</code>. They are divided with 3 elements of qkv, which can be found on <code>foward()</code> function on implements. Hope to explore the reference script from <code>__init__()</code> to <code>forward()</code> and understand <a href=""https://arxiv.org/abs/1706.03762"" rel=""nofollow noreferrer"">transformer paper</a> thoroughly.</li>
<li>In Linear block, building a block with parameters <code>in_features</code> and <code>out_features</code> is heuristic. The number of features in Linear block is dimension of function you hypothesis. We encode the input feature that could be represented in lower-dimension(<a href=""https://medium.com/@reh.yawar2/how-the-bottleneck-layers-in-the-deep-networks-work-and-how-do-those-layers-reduce-computational-7bc99c0d1e96"" rel=""nofollow noreferrer"">the bottleneck of the network</a>), and decode it what we want solve.</li>
</ul>
<ol start=""2"">
<li>Can you provide me some papers about this matter and network architectures having this?</li>
</ol>
<ul>
<li>I hope to read articles of linear regression before learning about deep learning, following fundamental theory of linear algebra. Your learning curve can be followed with: linear regression, classification -&gt; multi layer perceptron(same as <code>Linear</code> in Pytorch) -&gt; convolution block -&gt; transformers -&gt; image transformers(Swin transformer on post).&quot;</li>
</ul>
","2024-06-20 05:35:02","0","Answer"
"78642379","","Why sometime the out_features in Linear layer is higher than in_features?","<p>I understand that in the out_features in Linear often lower than the in_features to get more meaningful feature but some time I see the out_features is higher than the in_features, sometimes it's equal.
For example, like the architecture below in swin transformer v2 in pytorch:</p>
<pre><code>Sequential(
      (0): SwinTransformerBlockV2(
        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): ShiftedWindowAttentionV2(
          (qkv): Linear(in_features=768, out_features=2304, bias=True) #Higher
          (proj): Linear(in_features=768, out_features=768, bias=True) #Equal
          (cpb_mlp): Sequential(
            (0): Linear(in_features=2, out_features=512, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=512, out_features=24, bias=False) # Lower
          )
</code></pre>
<p>I want to ask:</p>
<ol>
<li>What are the purposes by having higher, equal, lower out_features in the network?</li>
<li>Can you provide me some papers about this matter and network architetures having this?</li>
</ol>
<p>I'm just start learning about deep learning and AI, if you can provide some course about building network, it will be great help.</p>
<p>Thank you so much.</p>
","2024-06-19 12:01:34","-1","Question"
"78638174","78638155","","<p>I think the problem is that the activation function does not have any parameter that is serialized, so you will not find it in the <code>pth</code> file. Usually in pytorch you need the model you will need the model definition to get everything. One workaround might be to use a <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"" rel=""nofollow noreferrer"">Sequential</a>. I guess that should store the activation functions too.
Here's an example on how to save/reload</p>
<pre class=""lang-py prettyprint-override""><code># To save
torch.save(model.state_dict(), 'out.pth')
# To reload
model = SimpleCNN_2()
model3.load_state_dict(torch.load('out.pth'))
</code></pre>
","2024-06-18 14:47:24","0","Answer"
"78638155","","getting Pytorch activation function from .pth model","<p>I am looking for a method to retrieve the activation functions used in a PyTorch network saved as a .pth file (<code>torch.save(model)</code>). Indeed, if the activation functions were not declared in the class when creating the model but only in the forward method, I am unable to identify these activation functions
eg:</p>
<pre><code>
class SimpleCNN_2(nn.Module):
    def __init__(self):
        super(SimpleCNN_2, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(in_features=32768, out_features=128)  
        self.fc2 = nn.Linear(in_features=128, out_features=10)  

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = nn.Flatten()(x)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
</code></pre>
<p>I get this description:</p>
<pre><code>SimpleCNN_2(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fc1): Linear(in_features=32768, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
</code></pre>
<p>If activation function are declared, I don't have any issue. My concern is about the fact that I want to assess a network from a .pth file, and if I can't get the whole structure of the network it's a mess.</p>
<p>I would like to have a method that allows me to obtain the complete structure of a network, layer by layer, from a .pth file, in the form of a list, without knowing the structure of the network in advance.</p>
","2024-06-18 14:43:16","0","Question"
"78629748","78629742","","<h3>Matrix Multiplication Dimension Compatibility</h3>
<p>The hidden layer weight matrix was <code>W1 = np.array([[-20],[-20]])</code>, with a shape of (2, 1), while the input data has a shape of <code>(4, 2)</code>. Therefore, the dot product <code>np.dot(X, self.W)</code> inside the <code>Layer()</code> class do not have the proper dimensions compatible for matrix multiplication.</p>
<h3>Code:</h3>
<pre><code>import numpy as np

class Layer:
    def __init__(self, W, b):
        self.m = W.shape[0]
        self.n = W.shape[1]
        self.W = W
        self.b = b

    def activate(self, X):
        z = np.dot(X, self.W) + self.b
        return sigmoid(z)

class Network:
    def __init__(self, hidden, output):
        self.hidden = hidden
        self.output = output

    def activate(self, X):
        z_hidden = self.hidden.activate(X)
        return self.output.activate(z_hidden)


W1, b1 = np.array([[10, -10], [-10, 10]]), np.array([[-5, 30]])
W2, b2 = np.array([[20], [20]]), np.array([-30])

hidden_layer = Layer(W1, b1)
output_layer = Layer(W2, b2)

sigmoid = lambda x: 1 / (1 + np.exp(-x))
xor_gate = Network(hidden_layer, output_layer)
xor_output = xor_gate.activate(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]))
print(np.round(xor_output))

</code></pre>
<h3>Prints</h3>
<pre><code>[[0.]
 [0.]
 [1.]
 [0.]]

</code></pre>
","2024-06-16 17:18:52","0","Answer"
"78629742","","Shapes (4,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)","<blockquote>
<p>Hello, I am new to Coding and am trying to work on neural networks, I have be trying to get values for a project where we check the XOR gate using basic code, but i am gettign stuck here, Could someone please help?</p>
</blockquote>
<pre><code>W = np.array([[20],
              [20]])

class Layer():

  def __init__(self, W, b):
    self.m = W.shape[0]
    self.n = W.shape[1]
    self.W = W
    self.b = b

  def activate(self, X):
    z = np.dot(X, self.W) + self.b
    return sigmoid(z)

OR_layer = Layer(W, -10)
</code></pre>
<blockquote>
<p>Output:
array([[0.],
[1.],
[1.],
[1.]])</p>
<p>This works fine to get the OR layer but when trying to Compute the XOR layer i get the error&gt;&gt;&gt;</p>
</blockquote>
<pre><code>W1 = np.array([[-20],[-20]])
b1 = np.array(30)

W2 = np.array([[20],[20]])
b2 = np.array(-30)
#print(np.dot(W1,b1))
hidden_layer = Layer(W1, b1)
output_layer = Layer(W2, b2)

#Based on the previous code, the weights and biases have been updated in the code



class Network():

  def __init__(self, hidden, output):
    self.hidden = hidden
    self.output = output

  def activate(self, X):
    z = self.hidden.activate(X)
    return self.output.activate(z)

xor_gate = Network(hidden_layer, output_layer)

xor_output = xor_gate.activate(logic_inputs)#throwing error
np.round(xor_output)


</code></pre>
<blockquote>
<p>This code is broken, i tried to mend it but had hard time to do so.</p>
<p>Output should come to:
array([[0.],
[1.],
[1.],
[0.]])&gt;</p>
<p>This code is broken, i tried to mend it but had hard time to do so.</p>
</blockquote>
","2024-06-16 17:17:15","1","Question"
"78623751","78622732","","<p>You need to use djangos capabilities for streaming video content (im not a django expert), first you need to make a generator out of your function:</p>
<pre><code>    def process_video(self):
        cap = cv2.VideoCapture(self.source) 
        while True:
            ret, frame = cap.read() 
            if not ret: break
                
            results = self.model.predict(frame, conf=self.conf_, imgsz=self.size) 

            # here is your way to annotate frame
            annotated_frame = ...

            # here you convert image to bytes
            image = Image.fromarray(annotated_frame)        
            img_buffer = io.BytesIO()
            image.save(img_buffer, format='JPEG')

            img_bytes = img_buffer.getvalue()
            yield (b'--frame\r\n'b'Content-Type: image/jpeg\r\n\r\n' + img_bytes + b'\r\n')
            
</code></pre>
<p>and then you need to create some view (not sure how it should be in django, maybe you should add smth like that in your existing code)</p>
<pre><code>class VideoStream(View):
    def get(self, request, *args, **kwargs):
        return StreamingHttpResponse(process_video(), content_type='multipart/xmixed-replace; boundary=frame')

</code></pre>
<p>after that in your html-page you need to create element that outputing streamingresponse, it will look kinda like this</p>
<pre><code>    &lt;div class=&quot;&quot;&gt;
        &lt;img src=&quot;{% url 'your_response_root' %}&quot; width=&quot;1024&quot; height=&quot;768&quot;&gt;
    &lt;/div&gt;
</code></pre>
","2024-06-14 15:08:36","0","Answer"
"78623528","78623169","","<p>The problem seems to be in numerical solution of <code>solve_burgers()</code>, which you need to carefully verify:</p>
<pre><code>import torch
import numpy as np
from scipy.integrate import quad


def solve_burgers(X, t, nu):
    f = lambda y: np.exp(-np.cos(np.pi * y) / (2 * np.pi * nu))
    g = lambda y: np.exp(-(y ** 2) / (4 * nu * t))
    numer = lambda eta: torch.sin(torch.pi * (X - eta)) * f(X - eta) * g(eta)
    denom = lambda eta: f(X - eta) * g(eta)

    uxt, _ = quad(lambda eta: -numer(eta).item(), -np.inf, np.inf)
    uxt3, _ = quad(lambda eta: denom(eta).item(), -np.inf, np.inf)

    return -uxt / uxt3


def mr(x2):
    u_xr = []
    for k in range(len(x2)):
        z01 = solve_burgers(x2[k], 0.25, 0.01 / np.pi)
        u_xr.append(z01)
    return u_xr


x2 = torch.tensor([10.0, 20.0, 30.0, 10.0, 20.0, 30.0])
print(mr(x2))

</code></pre>
<h3>Prints</h3>
<pre><code>[4.01485673240222e-06, 8.861857759474245e-06, 1.0083838264149217e-05, 4.01485673240222e-06, 8.861857759474245e-06, 1.0083838264149217e-05]
</code></pre>
<h3>Note</h3>
<ul>
<li>Make sure your equations are correct.</li>
</ul>
","2024-06-14 14:23:59","1","Answer"
"78623169","","Error in automatic derivative calculation with pytorch","<pre><code>x2=torch.tensor(x,requires_grad=True)
t2=torch.tensor(t,requires_grad=True)
def mr():
            for k in range(n):
                z01=solve_burgers(torch.tensor([x2[k]]),0.25,0.01/np.pi)[0]
                z01.backward(retain_graph=True)
                u_xr=x2.grad[k]
                u_tr=t2.grad[k]
            return u_xr,u_tr,u_xxr
</code></pre>
<p>solve_burgers is a function to solve burger equation.</p>
<p>When I run this code to calculate derivatives, I get the following error:</p>
<pre><code>TypeError: 'NoneType' object is not subscriptable
</code></pre>
<p>How can I fix the error?</p>
<pre><code>def solve_burgers(X, t, nu):
def f(y):
 return np.exp(-np.cos(np.pi * y) / (2 * np.pi * nu))
def g(y):
 return np.exp(-(y**2) / (4 * nu * t))
def fun(eta):
  return torch.sin(torch.pi * (x - eta)) * f(x - eta) * g(eta)
def fun1(eta):
  return f(x - eta) * g(eta)
U = torch.zeros_like(X)
for i in range(len(X)):
 x = X[[[i]]]
 uxt = -quad(fun, -torch.inf, torch.inf)[0]
 uxt2=torch.tensor(uxt,requires_grad=True)
 uxt30=quad(fun1, -np.inf, np.inf)[0]
 uxt3=torch.tensor(uxt30,requires_grad=True)
 U[i] = uxt2 / uxt3
return U
</code></pre>
","2024-06-14 13:12:45","1","Question"
"78622732","","Passing CV2 YOLO8s video feed to a Django application","<p>I have a pre-trained YOLO8s model and trained it on a custom dataset and I have made a Python class using CV2 to display the results. How can I pass a constant video feed from my CV2 YOLO8s into my Django webpage?</p>
<p>This is my current code:</p>
<pre><code>from ultralytics import YOLO
from pathlib import Path
import cv2, onnx, onnxoptimizer,numpy,onnxruntime
import torch.onnx
import torchvision.models as models
from database.db import *
from pprint import pprint as pt
    
    
class Main_field: 
    
    def __init__(self, model, size, source, conf_):
        self.model = self.load_model(model) 
        self.size = size                    
        self.source = source               
        self.conf_ = conf_                  
    
    def __call__(self): 
        self.process_video()
    
    def load_model(self, model):
        model.fuse()                      
        return model
    
    def process_video(self):
        cap = cv2.VideoCapture(self.source) 
        while True:
            ret, frame = cap.read() 
            if not ret: break
                
            results = self.model.predict(frame, conf=self.conf_, imgsz=self.size) 
    
            masks_dict=[result.names for result in results][0] 
            xyxys=[result.boxes.cpu().numpy().xyxy for result in results][0] #xyxy 
            mask_ids=[result.boxes.cpu().numpy().cls.astype(int).tolist() for result in results][0] 
            masks=[masks_dict[itr] for itr in mask_ids] 
    
            db_output=[check_(local_list,str(itr)) for itr in mask_ids if itr] 
                
            video_outp=cv2.imshow(&quot;_________&quot;, results[0].plot()) 
            pt(mask_ids)
    
            if cv2.waitKey(1) &amp; 0xFF == ord('q'): break
            
        def __del__():
            cap.release()
            cv2.destroyAllWindows()
    
        def init_model(path: str) -&gt; any: return YOLO(path)
</code></pre>
","2024-06-14 11:39:38","0","Question"
"78609334","78576364","","<p>I figured out the reason. I simply didn't add pre processing to use embedings of my words intead of tokenized words</p>
","2024-06-11 19:01:14","0","Answer"
"78607778","78067999","","<p>I was facing a similar issue. The correct syntax is: <code>keras.Input(shape=[28, 28])</code>. The value <code>28, 28</code> is just an example; you should specify your dimensions.</p>
","2024-06-11 13:15:52","0","Answer"
"78583761","78583733","","<p>Impossible to say exactly what happened without seeing the weights of your model. Most likely it didn't learn anything e.g. didn't change its weights. Try increasing (or decreasing) the learning rate, adding more epochs, removing regularization. Your data might also be heavily skewed or have outliers that make it difficult to learn, especially after normalizing.</p>
","2024-06-05 22:27:19","1","Answer"
"78583733","","Neural network always predicts the same value","<p>My neural network always predicts the same value, the problem arises when I try to normalize the target value, if I don't it works fine. Does anyone have an idea of why?</p>
<pre class=""lang-py prettyprint-override""><code>def create_and_train_model_opti2(dff, target_column):
    df = dff.copy()
    
    
    y = df[target_column].values.reshape(-1, 1)
    X = df.drop([target_column], axis=1)
    #X = X.drop(['cmf_pos'], axis=1).values  
    
    # Normalize features
    scaler_X = MinMaxScaler(feature_range=(0, 1))
    X_scaled = scaler_X.fit_transform(X)
    
    # Normalize the target
    scaler_y = MinMaxScaler(feature_range=(0, 1))
    y_scaled = scaler_y.fit_transform(y)
    
    
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)
    
    
    model = Sequential([
        Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),
        Dropout(0.2),
        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')
    
    
    history = model.fit(X_train, y_train, epochs=60, batch_size=64, validation_split=0.2)
    
    return model, history, y_train, y_test, X_train, X_test, scaler_y

def make_and_view_predictions(model, X_test, y_test, scaler_y):
    
    y_pred_scaled = model.predict(X_test)
    
    # Inverse  predictions
    y_pred = scaler_y.inverse_transform(y_pred_scaled)
    
    # Inverse transform the actual test 
    y_test_original = scaler_y.inverse_transform(y_test)
    
    
    for i in range(len(y_test)):
        print(f&quot;Predicted: {y_pred[i][0]:.2f}, Actual: {y_test_original[i][0]:.2f}&quot;)
    
    return y_pred, y_test_original
</code></pre>
<p>This is the output that I have:</p>
<pre><code>Predicted: 353.50, Actual: 156.80
Predicted: 353.50, Actual: 193.57
Predicted: 353.50, Actual: 34.67
Predicted: 353.50, Actual: 281.60
Predicted: 353.50, Actual: 0.00
Predicted: 353.50, Actual: 558.53
Predicted: 353.50, Actual: 21.41
Predicted: 353.50, Actual: 0.00
Predicted: 353.50, Actual: 560.24
Predicted: 353.50, Actual: 311.48
Predicted: 353.50, Actual: 135.14
Predicted: 353.50, Actual: 0.00
Predicted: 353.50, Actual: 403.05
Predicted: 353.50, Actual: 0.00
Predicted: 353.50, Actual: 46.62
Predicted: 353.50, Actual: 2579.44
</code></pre>
<p>I tried to search the libraries but nothing works</p>
","2024-06-05 22:18:40","0","Question"
"78576364","","lstm is not learning anything pytorch","<p>I am trying to use lstm for binary classification of comments (comments are alredy pre processed and split). I created a model, but it is not learning anything.</p>
<p>In some cases I receive exactly the same accuracy no matter how many epoches I choose.</p>
<p>GitHub link: <a href=""https://github.com/PavloChaika/ML_SET/blob/homework3/HW3/HA3%20-%20IMDB%20competition.ipynb"" rel=""nofollow noreferrer"">https://github.com/PavloChaika/ML_SET/blob/homework3/HW3/HA3%20-%20IMDB%20competition.ipynb</a></p>
<p>I tried different combinations of num_layers, hidden_size, learning_rate. I am using input_size because ithervise it works very slowly (even though I realize that I have only 1 input, i just try to train at least a little bit, and since I clasify comments my guess was that it should work) I tried using 1 input, but result was very similar</p>
","2024-06-04 15:26:07","-3","Question"
"78572194","78572172","","<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#add"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#add</a>, <code>model.add</code> only takes one argument for layer, so your code</p>
<pre><code>model.add(
        tf.keras.layers.Dense(256, activation = &quot;relu&quot;),
        tf.keras.layers.Dropout(0.5)
        )
</code></pre>
<p>effectively only add the dense layer and pass in a second argument <code>True</code> which is the default. If you compare it with</p>
<pre><code>model.add(
        tf.keras.layers.Dense(256, activation = &quot;relu&quot;),
        True
        )
</code></pre>
<p>The results should be the same.</p>
","2024-06-03 19:23:02","0","Answer"
"78572172","","Why Do Two Different Ways of Adding a Drop Out Layer in Tensor Flow Function Differently?","<p>I was trying to add a hidden layer with dropout to my neural network. I found that the following code:</p>
<pre><code>    model.add(
        tf.keras.layers.Dense(256, activation = &quot;relu&quot;)
                )

    model.add(
        tf.keras.layers.Dropout(0.5)
        )
</code></pre>
<p>resulted in terrible accuracy (~65%) while the following code:</p>
<pre><code>    model.add(
        tf.keras.layers.Dense(256, activation = &quot;relu&quot;),
        tf.keras.layers.Dropout(0.5)
        )
</code></pre>
<p>resulted in adequate accuracy (~95%). Can someone explain why these lines of code resulted in vastly different accuracies and which one is the proper way to add a hidden layer with dropout?</p>
<p>More generally, I was wondering if adding a neural network's layers one at a time is different than instantiating the neural network with one line, and if so why?</p>
<pre><code>    model = tf.keras.models.Sequential()
    model.add(...) # Add one layer at a time
    ...
</code></pre>
<p>VS</p>
<pre><code>    model = tf.keras.models.Sequential([... (complete neural network) ...])
</code></pre>
","2024-06-03 19:16:52","0","Question"
"78567321","78567000","","<p>A pruned model might end up being larger in size due to serialization overhead (a pruned model includes additional metadata to reconstruct the model architecture), sparse matrix storage (some storage formats do not efficiently compress sparse matrices and might store them less efficiently than dense matrices), checkpoint information (including the pruning state).</p>
<p>To resolve this, you can use efficient storage formats, e.g.  <code>.tflite</code> with quantization:</p>
<pre><code>converter = tf.lite.TFLiteConverter.from_keras_model(final_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('quantized_model.tflite', 'wb') as f:
    f.write(tflite_model)
</code></pre>
<p>And/or strip pruning-specific wrappers, e.g. using <code>strip_pruning</code> (see <a href=""https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/strip_pruning"" rel=""nofollow noreferrer"">documentation</a>).</p>
","2024-06-02 18:10:58","1","Answer"
"78567000","","Why does my pruned model have a larger file size than my initial model?","<p>I'm exploring pruning a neural network using <a href=""https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras"" rel=""nofollow noreferrer"">this</a> example. My pruning code, using a pre-trained model, looks like this:</p>
<pre><code>prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# Compute end step to finish pruning after 2 epochs.
batch_size = 64
epochs = 3
validation_split = 0.1 # 10% of training set will be used for validation set.

num_images = 114 * (1 - validation_split)
end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs

# Define model for pruning.
pruning_params = {'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity = 0.50,
                                                               final_sparsity = 0.80,
                                                               begin_step = 0,
                                                               end_step = end_step)
}

pruned_model = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` requires a recompile.
pruned_model.compile(optimizer = 'adam', loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])

logdir = tempfile.mkdtemp()

callbacks = [
  tfmot.sparsity.keras.UpdatePruningStep(),
  tfmot.sparsity.keras.PruningSummaries(log_dir = logdir),
]

pruned_model.fit(train_dataset, batch_size=batch_size, epochs=epochs, validation_data=valid_dataset, callbacks=callbacks)
</code></pre>
<p>Then, using <code>pruned_model.evaluate(train_dataset, verbose=0)</code>, I see that it has indeed dropped in accuracy a bit, as expected - I got these results last time I ran a test:</p>
<pre><code>Baseline test accuracy: 0.9197102189064026
Pruned model test accuracy: 0.8976686000823975
</code></pre>
<p>I have been using <code>model.save()</code> to save the initial <code>model</code> and pruned <code>pruned_model</code> as both .h5 and .keras formats; these come to 60.7 to 60.9 MB respectively. However, the pruned network, when saved as .h5, comes to 85.4 MB, and the .keras version is even larger, at 110 MB. I can't find anything in keras documentation about needing to specify optimisation when saving a file - only the directory.</p>
","2024-06-02 16:09:41","0","Question"
"78565038","78554248","","<p>Given your imbalanced dataset, Focal Loss could be a valuable alternative to BCELoss. It focuses on hard-to-classify examples, reducing the influence of easy negatives that dominate the loss in imbalanced scenarios.</p>
<p>Convolutional neural networks (CNNs) can capture local patterns and n-gram features, complementing the global context captured by BERT. Consider adding a CNN layer before or after the BERT encoder.</p>
<p>We can also implement callback and Monitor validation accuracy and stop training early if it doesn't improve for a certain number of epochs. This prevents overfitting to the training data.</p>
","2024-06-01 22:23:53","0","Answer"
"78562796","78558974","","<p>I figured out the answer. There is no bug, but I was severely underestimating the amount of training time I needed. I figured because the cost function was flatlining, it had reached the point of diminishing returns. By training for several hours, I was able to push through the plateau, and it began rapidly decreasing the cost again. I also needed to bump up the training rate significantly, and running in batches increased the performance dramatically.</p>
","2024-06-01 04:28:58","0","Answer"
"78558974","","Cost function minimum is too low","<p>Below is a section of Matlab code from a neural net I'm trying to write. It's my first attempt at anything related to machine learning. I'm following along with  Michael Nielson's book here: <a href=""http://neuralnetworksanddeeplearning.com/chap2.html"" rel=""nofollow noreferrer"">http://neuralnetworksanddeeplearning.com/chap2.html</a></p>
<p>I'm loading a set of 60000 28x28 grayscale images of handwritten digits with labels and am trying to train this neural net to identify them. There is also a test data set of 10000 images. The network has 784 input neurons (28^2), two hidden layers each with 16 neurons, and the output layer has 10 neurons. I'm initializing the weights and biases to a random value between -0.5 and 0.5.</p>
<p>I'm evaluating the cost function as C = 0.5*(a-y).^2. It seems mildly successful in that it started at C=1.35 and ended at C=0.46 before essentially flattening out (about 75 epochs). However, the error is still high enough it only guesses the correct digit 12% of the time, which is almost random chance. I've double and triple checked the math but can't find a mistake. I'm thinking there must be one I'm not seeing. The code below is everything within the main training loop, so any bugs should be in there. I'm not breaking the images into smaller batches, but am doing the entire 60k images at a time with each epoch. Since each image is only 28x28 pixels it's fast enough without breaking it apart. The input neurons a_0 are a 784x60000 array of doubles, with values between 0 and 1. I took the original images, where each pixel was a uint8, and converted to double then divided by 255 to get a_0. I'm numbering the layers in my code such that layer 0 is the input layer, layers 1 and 2 are the hidden layers, and layer 3 is the output layer.</p>
<pre><code>a_0 = training_images;
epoch = 0;
while epoch &lt; 5 || C(epoch - 1) - C(epoch) &gt; 0.001    
epoch = epoch + 1;

%Propagate forwards
z_1 = weights_1*a_0 + biases_1;
a_1 = sigmoid(z_1);
z_2 = weights_2*a_1 + biases_2;
a_2 = sigmoid(z_2);
z_3 = weights_3*a_2 + biases_3;
a_3 = sigmoid(z_3);

%Evaluate cost function
C(epoch) = 0.5*mean(sum((a_3-y).^2, 1));

%Propagate backwards
sigmoid_d1 = a_1 .* (1-a_1); %Sigmoid derivative
sigmoid_d2 = a_2 .* (1-a_2);
sigmoid_d3 = a_3 .* (1-a_3);
delta_3 = (a_3-y).*sigmoid_d3;
delta_2 = weights_3.'*delta_3 .* sigmoid_d2;
delta_1 = weights_2.'*delta_2 .* sigmoid_d1;

%Calculate gradient
for image_index = 1:num_images
    dC_dw3(:, :, image_index) = delta_3(:, image_index) * a_2(:, image_index).';
    dC_dw2(:, :, image_index) = delta_2(:, image_index) * a_1(:, image_index).';
    dC_dw1(:, :, image_index) = delta_1(:, image_index) * a_0(:, image_index).';
end

%Calculate adjustment
training_rate = 0.1;
adjust_biases_1 = -training_rate * mean(delta_1, 2);
adjust_biases_2 = -training_rate * mean(delta_2, 2);
adjust_biases_3 = -training_rate * mean(delta_3, 2);
adjust_weights_1 = -training_rate * mean(dC_dw1, 3);
adjust_weights_2 = -training_rate * mean(dC_dw2, 3);
adjust_weights_3 = -training_rate * mean(dC_dw3, 3);
biases_1 = biases_1 + adjust_biases_1;
biases_2 = biases_2 + adjust_biases_2;
biases_3 = biases_3 + adjust_biases_3;
weights_1 = weights_1 + adjust_weights_1;
weights_2 = weights_2 + adjust_weights_2;
weights_3 = weights_3 + adjust_weights_3;
</code></pre>
","2024-05-31 08:39:40","-1","Question"
"78554248","","Enhance model performance in text classification task","<p>I tried to build a model for multi-label text classification task in chinese, but the performance of the model is not good enough (about 60% accuracy), and I come for help about how to enhance it.</p>
<p>I build a model based on a github project:</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F
from transformers import BertModel


class BertMultiLabelCls(nn.Module):
    def __init__(self, hidden_size, class_num, dropout=0.1):
        super(BertMultiLabelCls, self).__init__()
        self.fc = nn.Linear(hidden_size, class_num)
        self.drop = nn.Dropout(dropout)
        self.bert = BertModel.from_pretrained(&quot;bert-base-chinese&quot;)

    def forward(self, input_ids, attention_mask, token_type_ids):
        outputs = self.bert(input_ids, attention_mask, token_type_ids)
        cls = self.drop(outputs[1])
        out = F.sigmoid(self.fc(cls))
        return out
</code></pre>
<p>My dataset is 2000 query-tag pair, having 13 tags and query about the questions asked by the audience in the live commerce. I splited the dataset by 3:1:1 corresponding to train/test/val. My tags are NOT balanced and no up sample/down sample strategy is used.</p>
<p>Loss and accuracy during the training process, where the horizontal axis stands for the epoch:
<img src=""https://i.sstatic.net/VFqUaQth.png"" alt=""loss&amp;acc during the training process, where the horizontal axis stands for the epoch"" /></p>
<p>The vaildation accuracy stopped increasing near 60%, and same result for my test dataset.
I've tried various methods including adding more fully connection layer/adding residual connection, but the result remains the same.</p>
<p>Here are my training params if it helps:</p>
<pre><code>lr = 2e-5
batch_size = 128
max_len = 64
hidden_size = 768
epochs = 30
optimizer = AdamW(model.parameters(), lr=lr)
criterion = nn.BCELoss() # loss function
</code></pre>
<p>Any suggestions about how I improve my model besides the datasets? because that what I am doing paralleling and I know how to improve it. But I'm really newbie about the network itself.</p>
","2024-05-30 09:58:08","0","Question"
"78552233","78551454","","<p>This question is extremely broad, but I can give some information.</p>
<p>When you load a neural network, you are loading tensors of weights. These weights are typically loaded on CPU, then passed to GPU memory (HBM).</p>
<p>In addition to the weights, you have the model logic (ie the <code>forward</code> method of a pytorch model). Note that model logic is separate from the weights themselves.</p>
<p>The model logic decides what weights are executed when.</p>
<p>Say we have the model:</p>
<pre><code>class MyModel(nn.Module):
    def __init__(self):
        super().__init__()

        self.layer1 = nn.Linear(32, 8)
        self.layer2 = nn.Linear(8, 1)

    def forward(self, x):
        x = self.layer1(x)
        x = torch.relu(x)
        x = self.layer2(x)
        return x
</code></pre>
<p>Our weights in the model's state dict are the weight/bias tensors of <code>layer1</code> and <code>layer2</code>. Our model execution logic is the <code>layer1/relu/layer2</code> code in the <code>forward</code> method.</p>
<p>When we run inference on the model, the <code>forward</code> method determines the order of operations.</p>
<p>Each layer has a corresponding GPU kernel. The kernel decides how the input weights/activations are broken down into grids/blocks and distributed among the GPU SMs.</p>
<p>Typically the GPU executes one layer at a time, using as much compute as possible for that layer.</p>
<p>With the model above, it would look something like this:</p>
<ol>
<li>Given some input <code>x</code> and model weights in HBM</li>
<li>Move <code>x</code> and weights for <code>layer1</code> into SRAM</li>
<li>Execute GPU kernel for <code>torch.nn.Linear</code> with <code>x</code> and <code>layer1</code> weights</li>
<li>Return result back to HBM</li>
<li>Move <code>x</code> (now the result of <code>layer1</code>) into SRAM</li>
<li>Execute GPU kernel for <code>torch.relu</code> on <code>x</code></li>
<li>Move result back to HBM</li>
<li>Move <code>x</code> (now the result of the relu operation) and weights for <code>layer2</code> into SRAM</li>
<li>Execute GPU kernel for <code>torch.nn.Linear</code> with <code>x</code> and <code>layer2</code> weights</li>
<li>Move result back to HBM</li>
</ol>
<p>For the above, each kernel execution would distribute inputs/weights to different grids/blocks for execution. The exact distribution depends on the logic of the kernel itself.</p>
<p>This gets more complicated with potentials for kernel fusing (ie on the relu) and whatnot, but this is the basic idea.</p>
<p>You can use the <a href=""https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool/"" rel=""nofollow noreferrer"">pytorch profiler</a> to look at what kernels are being executed when during the forward pass.</p>
","2024-05-29 22:42:30","1","Answer"
"78551454","","How a neural network is mapped to a GPU?","<p>I want to understand when a GPU executes a neural network, how the operations are mapped to the GPU's hardware resources. I am familiar with the architecture of GPUs (especially NVIDIA) and I generally know how an NN is executed by them, but I do not know how to get to detailed and fine-grain scheduling of operations to the hardware resources and how the cores execute them. I am wondering if there is any tool or a set of tools for that.</p>
<p>To be more specific, let's imagine that I have a pre-trained neural network in pytorch and want to run it on an NVIDIA 3090 GPU. How can I get the detailed scheduling of the operations (either at the MAC operations or neurons/channels/layers of the NN) to corresponding hardware resources via SMs or threads?</p>
","2024-05-29 18:49:47","0","Question"
"78546338","78546211","","<p>The issue is that <code>concat</code> is not a DataFrame instance method but a pandas class method. The right way to use it is like this:</p>
<pre><code>SearchResultsData = pd.concat([SearchResultsData, pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]], columns=['TrialNumber', 'Parameters', 'Accuracy'])], ignore_index=True)
</code></pre>
<p>The <code>pd.concat</code> function takes a list or dictionary of DataFrames as input. I also added the <code>ignore_index=True</code> parameter  to avoid keeping the old index values from the concatenated DataFrames.</p>
","2024-05-28 20:32:27","0","Answer"
"78546211","","AttributeError: 'DataFrame' object has no attribute 'concat'","<p>I am doing a ANN project to build a prediction model on costs through a medical insurance dataset. Here is the code:</p>
<pre><code>def FunctionFindBestParams(X_train, y_train, X_test, y_test):
    

    batch_size_list=[5, 10, 15, 20]
    epoch_list  =   [5, 10, 50, 100]

    import pandas as pd
    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])
    
    TrialNumber=0
    for batch_size_trial in batch_size_list:
        for epochs_trial in epoch_list:
            TrialNumber+=1
            
            model = Sequential()
            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))
            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))
            model.add(Dense(1, kernel_initializer='normal'))
            model.compile(loss='mean_squared_error', optimizer='adam')
            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)
            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))
            
            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)
            
            SearchResultsData=SearchResultsData.concat(pd.DataFrame(data=[[TrialNumber,     str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]], 
columns=['TrialNumber', 'Parameters', 'Accuracy'] ))
    return(SearchResultsData)

ResultsData=FunctionFindBestParams(X_train, y_train, X_test, y_test)
</code></pre>
<p>I have already used <code>append()</code> and <code>concat()</code> functions, but none of them are working. Can anyone help me with this problem, please? Thank you very much in advance.</p>
","2024-05-28 20:00:27","1","Question"
"78522286","78522177","","<p>One thing to bear in mind is that for many popular choices of activation function (EG Relu), in any neuron that doesn't have a bias, an input value of zero will map to an output value of zero. Likewise, if your whole network uses such activation functions (without normalisation), the same applies: zero inputs get mapped to zero outputs, so dark pixels (with value zero) will map to zero, and effectively behave linearly. If you want all pixels to behave non linearly (which is generally true for neural networks), one solution is to use biases.</p>
<p>The situation is slightly different for transformers: they often <em>don't</em> use biases, partly because they use frequent Layer Normalisation layers, which effectively add their own biases.</p>
<p>But in some cases, EG SWIN transformers,  the size of the attention map is always known (equal to window size), and they add a learned positional bias directly to the attention maps.</p>
","2024-05-23 09:54:12","1","Answer"
"78522177","","When to use / not use bias term in convolutional neural networks","<p>This question has recently popped up in my mind. I've asked GPT and a couple of other models about the importance of bias term in convolutional networks. All of them responded differently and very superficially. I also occasionally see kaggle notebooks, where people set 'bias=False' or 'bias=True' in conv / dense layers, when train their models. Can you share insights about why bias term might be important and when to consider enabling / disabling it? Thanks.</p>
","2024-05-23 09:34:17","0","Question"
"78521330","78514097","","<p>You seem to mixing some things up here. The model contains an exponential at the end, so the targets should be <code>y</code>, not <code>log(y)</code>, OR you need to remove the exponential in the model. Also, if you have an exponential in the model, it is incorrect to use <code>np.exp</code> <em>again</em> after <code>predict</code>. This version works fine:</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Generate data
x1 = np.random.randint(1, 21, size=(1000, 1))
x2 = np.random.randint(1, 21, size=(1000, 1))
y = 3 * (x1 ** 2) * (x2 ** 3)

# Preprocess data
log_x1 = np.log(x1)
log_x2 = np.log(x2)
log_inputs = np.hstack((log_x1, log_x2))

# Define model
model = Sequential()
model.add(Dense(1, input_dim=2, kernel_initializer='ones', bias_initializer='zeros'))

# Compile model
model.compile(optimizer=Adam(learning_rate=0.01), loss='mae')

# Train model
model.fit(log_inputs, np.log(y), epochs=100, batch_size=32)

# Evaluate model
test_x1 = np.array([[2], [4], [5]])
test_x2 = np.array([[3], [7], [19]])
test_inputs = np.hstack((np.log(test_x1), np.log(test_x2)))
predicted = model.predict(test_inputs)
print(np.exp(predicted))
</code></pre>
","2024-05-23 06:38:54","0","Answer"
"78514097","","Model Accuracy for Non-linear Relationship with Logarithm Kernel and Exponential Activation can't reach 100%","<p>I'm working on a project where I need to model a non-linear relationship using a neural network. The relationship is ( y = 3x_1^2x_2^3 ). The network setup is as follows:</p>
<ul>
<li><strong>Preprocessing:</strong> Natural logarithm of inputs</li>
<li><strong>Network Design:</strong> Single layer with one neuron</li>
<li><strong>Activation Function:</strong> Exponential</li>
<li><strong>Loss Function:</strong> MAE (Mean Absolute Error)</li>
<li><strong>Optimizer:</strong> Adam</li>
<li><strong>Epochs:</strong> 50</li>
<li><strong>Batch Size:</strong> 32</li>
</ul>
<p><strong>Input and Expected Output:</strong></p>
<ul>
<li>Input: ([x1, x2])</li>
<li>Correct weights: ([2, 3])</li>
<li>Correct bias: (\ln 3)</li>
</ul>
<p>Despite these settings, I am not able to achieve 100% accuracy. I've tried initializing weights and biases randomly as well as with specific values.</p>
<p>Here is the code:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Generate data
x1 = np.random.randint(1, 21, size=(1000, 1))
x2 = np.random.randint(1, 21, size=(1000, 1))
y = 3 * (x1 ** 2) * (x2 ** 3)

# Preprocess data
log_x1 = np.log(x1)
log_x2 = np.log(x2)
log_inputs = np.hstack((log_x1, log_x2))

# Define model
model = Sequential()
model.add(Dense(1, input_dim=2, activation='exponential', kernel_initializer='ones', bias_initializer='zeros'))

# Compile model
model.compile(optimizer=Adam(learning_rate=0.01), loss='mae')

# Train model
model.fit(log_inputs, np.log(y), epochs=50, batch_size=32)

# Evaluate model
test_x1 = np.array([[2], [4], [5]])
test_x2 = np.array([[3], [7], [19]])
test_inputs = np.hstack((np.log(test_x1), np.log(test_x2)))
predicted = model.predict(test_inputs)
print(np.exp(predicted))
</code></pre>
<p>Does anyone have suggestions on how to improve the accuracy of this model?</p>
","2024-05-21 19:54:48","0","Question"
"78504491","78483105","","<p>The problem with your approach is coming from the model performing square, which is very difficult to learn with your model. If you individually check it, you will see that it gives very wrong results for some values. Try seeing square(0), square(1), etc.</p>
<p><a href=""https://i.sstatic.net/e14MmivI.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/e14MmivI.png"" alt=""enter image description here"" /></a></p>
<p>Note that the learned model has several &quot;flat&quot; areas which don't really match with the true curve. If you plot the squared error, it will show:</p>
<p><a href=""https://i.sstatic.net/oYhy3nA4.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/oYhy3nA4.png"" alt=""enter image description here"" /></a></p>
<p>So the error is quite significant. As to always getting the same result, it is likely your model converged poorly, something like:</p>
<p><a href=""https://i.sstatic.net/bZvAwkbU.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bZvAwkbU.png"" alt=""enter image description here"" /></a></p>
<p>In this case, for the values in the -10, 10 region, you are likely getting a fixed output. So your formula <code>(a + b)^2 - a^2 - b^2</code> is equivalent to <code>c^2 - c^2 -c^2 = -c^2</code>, where <code>c</code> is that constant. You are getting a different <code>c</code> each time as you are not using any np.random.seed.</p>
<p>To learn a better model of square, I have two suggestions:</p>
<ul>
<li>Increase your number of samples, rather than epochs. Instead of 2000 epochs on 10K data, 200 epochs on 100K data may be more useful.</li>
<li>Change the activation from &quot;relu&quot; to something that also accomodates negative values, like &quot;elu&quot;.</li>
</ul>
<p>You will still not get a perfect square model, but it will be a much better approximation.</p>
","2024-05-20 03:00:56","2","Answer"
"78501936","78501026","","<p>Your images are colored that's why your image shape is (256, 256, 3) for each base color, 'Red', 'Green', and 'Blue' (RGB) there is a value for the pixel in the 256x256 matrix.</p>
<p>images of the (128, 128) are gray-colored images. There are several techniques to convert color images into gray.</p>
<p>I suggest you install the OpenCV library (pip install opencv-python).</p>
<pre><code>import cv2 as cv

resized_image = cv.resize(your_image, (128, 128))
resized_gray_image = cv.cvtColor(resized_image, cv.COLOR_RGB2GRAY)
</code></pre>
","2024-05-19 07:57:58","0","Answer"
"78501026","","Confusion about training and prediction images' shape","<p>I'm doing semantic segmentation task in Keras - classifying trees from background. My images are initially of shape <code>(256, 256, 3)</code>. However, I want to resize them to (128, 128) to speed up the training. I'm also taking part in a competition and my output file should be of shape <code>(num_images, 256, 256)</code> but my model can work only with <code>(128, 128)</code> images now and when I try to predict on <code>(256, 256)</code> images I get this error:</p>
<pre><code>  ValueError: Input 0 of layer &quot;model_4&quot; is incompatible with the layer: expected shape=(None, 128, 128, 1), found shape=(None, 256, 256, 1)
</code></pre>
<p>I'm using Unet model:</p>
<pre><code>  inputs = Input((128, 128, 1))

  s = Lambda(lambda x: x / 255) (inputs)

  c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)
  c1 = Dropout(0.1) (c1)
  c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)
  p1 = MaxPooling2D((2, 2)) (c1)

  c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)
  c2 = Dropout(0.1) (c2)
  c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)
  p2 = MaxPooling2D((2, 2)) (c2)

  ...

  u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)
  u9 = concatenate([u9, c1], axis=3)
  c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)
  c9 = Dropout(0.1) (c9)
  c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)

  outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

  model = Model(inputs=[inputs], outputs=[outputs])
  model.compile(optimizer='adam', loss='binary_crossentropy')
</code></pre>
<p>Is there a way to train model on images of smaller sizes and still be able to make predictions on larger images? Can somebody please give a hint on how to solve this? Thanks in advance.</p>
<p>EDIT:
this is the function for getting data:</p>
<pre><code>def get_data(a, path, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, t):
  out = np.zeros((len(a), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), 
  dtype=t)
  for i, image_id in enumerate(a):
    path_image = path + image_id
    image = np.array(Image.open(path_image).convert('L'))
    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', 
    preserve_range=True)
    image = np.expand_dims(image, axis=-1)
  out[i] = image
  return out
</code></pre>
","2024-05-18 21:21:16","-1","Question"
"78497856","78494686","","<p>If linear or nearest-neighbor interpolation is sufficient, you may be able to do what you need with <a href=""https://jax.readthedocs.io/en/latest/_autosummary/jax.scipy.interpolate.RegularGridInterpolator.html"" rel=""nofollow noreferrer""><code>jax.scipy.interpolate.RegularGridInterpolator</code></a></p>
<p>If you need something more sophisticated, like spline interpolation, there is nothing included in <code>jax</code> itself. That said, you may be able to find downstream implementations that work for you. One I came across that might be worth trying is in the <a href=""https://jax-cosmo.readthedocs.io/en/latest/index.html"" rel=""nofollow noreferrer""><code>jax_cosmo</code> project</a>: <a href=""https://jax-cosmo.readthedocs.io/en/latest/_modules/jax_cosmo/scipy/interpolate.html"" rel=""nofollow noreferrer"">https://jax-cosmo.readthedocs.io/en/latest/_modules/jax_cosmo/scipy/interpolate.html</a>.</p>
","2024-05-17 20:38:01","0","Answer"
"78497633","78464214","","<p>Managed to find the issue. Going to post an answer here for reference.</p>
<p>The problem was in the inference. The model outputs log softmax, so to get the probability distribution, I need to find the exponential of the model output, i.e., <code>predictions.exp()</code>.</p>
<p>However, I was incorrectly calling softmax on the output (<code>torch.nn.functional.softmax(predictions, dim=0)</code>).</p>
","2024-05-17 19:38:09","0","Answer"
"78497035","78496983","","<p>Your are hardcoding the weights and bias calculations. In this case, the optimizer cannot have access to that.</p>
<pre><code>import torch
import torch.nn as nn
import torch.optim as optim


def train_step(w, b, optimizer, scheduler, loss_function):
    optimizer.zero_grad()
    loss = loss_function()
    loss.backward()
    optimizer.step()
    scheduler.step()
    return loss.item()


def loss_function():
    rand_input = torch.randn(64, input_size)
    target = torch.randn(64, output_size)
    output = rand_input.mm(w) + b
    loss = nn.MSELoss()(output, target)
    return loss


input_size, output_size = 100, 3
learning_rate = 0.01
w = torch.randn(input_size, output_size, requires_grad=True)
b = torch.randn(output_size, requires_grad=True)
trainable_variables = [w, b]
optimizer = optim.SGD(trainable_variables, lr=learning_rate, momentum=0.9)
scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)
steps = 10000
display_step = 100


graph1 = []

for i in range(steps):
    loss = train_step(w, b, optimizer, scheduler, loss_function)
    if i % display_step == 0:
        graph1.append(loss)
        print(f'Epoch {i} \t Training Loss: {loss}')

graph = torch.tensor(graph1)


</code></pre>
<h3>Prints</h3>
<pre><code>Epoch 0      Training Loss: 94.3976058959961
Epoch 100    Training Loss: 1.1436320543289185
Epoch 200    Training Loss: 1.1590440273284912
Epoch 300    Training Loss: 0.9118895530700684
Epoch 400    Training Loss: 0.8449723720550537
Epoch 500    Training Loss: 0.9973302483558655
Epoch 600    Training Loss: 0.9681441783905029
Epoch 700    Training Loss: 1.1692309379577637
Epoch 800    Training Loss: 1.0565043687820435
Epoch 900    Training Loss: 1.0424968004226685
Epoch 1000   Training Loss: 0.9199855923652649
Epoch 1100   Training Loss: 1.1443506479263306
Epoch 1200   Training Loss: 0.9741299748420715
Epoch 1300   Training Loss: 1.1515040397644043
Epoch 1400   Training Loss: 1.2819862365722656
Epoch 1500   Training Loss: 0.9993045926094055
Epoch 1600   Training Loss: 1.066098928451538
Epoch 1700   Training Loss: 1.0772987604141235
... 

</code></pre>
","2024-05-17 17:08:11","0","Answer"
"78496983","","Learning rate not updating","<pre><code>def make_prediction(x0,t0):
    inputs = torch.vstack([x0,t0])
    layer_1 = torch.matmul(w0,inputs)
    return layer_1

loss1 = nn.MSELoss()
def loss_function():
            u_t=(make_prediction(x,t+inf_s)-make_prediction(x,t))/inf_s
            u_x=(make_prediction(x+inf_s,t)-make_prediction(x,t))/inf_s
            u_xx=(make_prediction(x+inf_s,t)-2*make_prediction(x,t)+make_prediction(x-inf_s,t))/inf_s**2
            return (1/N_i)*(loss1(make_prediction(x0IC,t0IC), u0IC))+(1/N_b)*(loss1(make_prediction(x0BC1,t0BC1), u0BC1))
            +(1/N_b)*(loss1(make_prediction(x0BC2,t0BC2), u0BC2))+(1/N_f)*(np.pi/0.01)*(loss1(u_xx-u_t-make_prediction(x,t)*u_x, 0))

def train_step(w,b, learning_rate):
    trainable_variables = [w,b]
    optimizer = torch.optim.SGD(trainable_variables, lr=learning_rate,momentum=0.9)
    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01)
    loss = loss_function()
    loss.backward()
    with torch.no_grad():
        w -= learning_rate * w.grad
        b -= learning_rate * b.grad
        w.grad.zero_()
        b.grad.zero_()
    optimizer.step()
    scheduler.step()
train_step(w,bias,learning_rate)
</code></pre>
<p>I run this code (by scheduler.ExponentialLR), but there is no change in the learning rate.
Where do you think the problem comes from?
I write the full code...thanks from your help</p>
","2024-05-17 16:56:52","1","Question"
"78495298","78376438","","<p>For <code>torch</code>, I suggest to have a look at <a href=""https://pytorch.org/docs/stable/sparse.html"" rel=""nofollow noreferrer"">https://pytorch.org/docs/stable/sparse.html</a> and <a href=""https://pytorch.org/docs/stable/masked.html"" rel=""nofollow noreferrer"">https://pytorch.org/docs/stable/masked.html</a>. (I beleive, both tools supposed to have same semanticks, but different implementation, first one aimed on sparse graphs). Thow, both tools still considered experimental.</p>
<pre><code>import torch

b = torch.randn((3,2), requires_grad=True)

a = torch.tensor([[7., 0, 0], [1, 9, 0]]).requires_grad_()
z = torch.mm(a, b)
z.sum().backward()
print( a.grad)

a_sparse = torch.tensor([[7., 0, 0], [1, 9, 0]]).to_sparse().requires_grad_()
y = torch.sparse.mm( a_sparse, b)
y.sum().backward()
print( a_sparse.grad)
</code></pre>
<hr />
<pre><code>tensor([[-0.4728,  2.9213, -0.2959],
    [-0.4728,  2.9213, -0.2959]])
</code></pre>
<hr />
<pre><code>tensor(indices=tensor([[0, 1, 1],
                   [0, 0, 1]]),
   values=tensor([-0.4728, -0.4728,  2.9213]),
   size=(2, 3), nnz=3, layout=torch.sparse_coo)
   
</code></pre>
","2024-05-17 11:19:47","0","Answer"
"78494686","","Finite basis physics-informed neural networks (FBPINNs) JAX problem","<p>I am trying to modify Ben Moseley's code available on github <a href=""https://github.com/benmoseley/FBPINNs"" rel=""nofollow noreferrer"">https://github.com/benmoseley/FBPINNs</a>.
My intention is to insert a vector of values into the loss fn that is dependent on x y coordinates, and I need the original vector Z to be interpolated as a function of x and y, and then the values at the same coordinates with which the algorithm samples x and y are extracted, so that the values match.
The problem I have encountered is that within loss fn I cannot use libraries other than JAX and to my knowledge there are no functions within JAX to interpolate in 2D.</p>
<p>I'm trying to get around the problem in every way but I'm not succeeding, one of my ideas was to extrapolate the x,y points sampled by the algorithm but I'm not succeeding, the code is really very articulated. Would anyone be able to give me any advice/help on this?</p>
<p>There would be the function jax.scipy.ndimage.map_coordinates but it doesn't work properly and the points it extrapolates are meaningless.</p>
","2024-05-17 09:18:34","1","Question"
"78484838","78476711","","<p>I get reasonable results by changing the batch size from 32 to 256, changing the number of epochs from 100 to 1000, and removing the ReLU activation function from the last layer.</p>
<p>ReLU has the problem that if the input to the activation is x &lt; 0, then ReLU'(x) = 0. This means that if the output from the final layer happens to be negative, there will be no gradient to correct this.</p>
<p>This is also a problem in previous layers, but it is much more likely that a single neuron gets unlucky in this fashion than it is that eight neurons get unlucky.</p>
<p>As an alternative to removing it, you could also look into <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU"" rel=""nofollow noreferrer"">leaky ReLU</a>.</p>
<p>Given that the original code trains this for 15,000 epochs, it is not very surprising that 100 epochs gets much worse results. I also changed the batch size to 256 with the intention of making the code run faster.</p>
","2024-05-15 15:03:58","1","Answer"
"78483105","","Division by neural network: Cannot take the length of shape with unknown rank","<p>I am trying to code a neural network to multiply and divide two numbers by using a method similar to the one outlined <a href=""https://stats.stackexchange.com/a/324008/300170"">here</a>. First, I coded models for adding and subtracting two numbers, and squaring a number. For division, I then used the reciprocal of the divisor and multiplied it with the divident as below:</p>
<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import regularizers

#Models for adding and subtracting two numbers

num_train = 1000

X_train = np.random.rand(num_train, 2)
y_train_add = X_train[:, 0] + X_train[:, 1]
y_train_subtract = X_train[:, 0] - X_train[:, 1]

model_add = Sequential(
        [
            Dense(10),
            Dense(1)
            ]
        )

model_subtract = Sequential(
        [
            Dense(10),
            Dense(1)
            ]
        )

batch_size = 32
epochs = 100

model_add.compile(loss = 'mse', optimizer='adam')
model_add.fit(X_train, y_train_add, batch_size=batch_size, epochs=epochs, verbose = 1)


model_subtract.compile(loss = 'mse', optimizer='adam')
model_subtract.fit(X_train, y_train_subtract, batch_size=batch_size, epochs=epochs, verbose = 1)

#Model for squaring a number

x_train = np.random.random((10000,1))*100-50
y_train = np.square(x_train)

model_sqr = Sequential(
        [
            Dense(8, activation = 'relu', kernel_regularizer = regularizers.l2(0.001), input_shape = (1,)),
            Dense(8, activation = 'relu',  kernel_regularizer = regularizers.l2(0.001)),
            Dense(1)
            ]

        )

batch_size = 64
epochs = 2000

model_sqr.compile(loss = 'mse', optimizer='adam')
model_sqr.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 1)

#Code for calculating the product and quotient of two numbers using models

x = &quot;n&quot; 
while True:
    print(&quot;enter first num:&quot;)
    x = input()
    if x == &quot;end&quot;:
        break

    print(&quot;Enter operation:&quot;)
    op= input()

    print(&quot;enter second num:&quot;)
    y = input()

    X = int(x)
    Y = int(y)
    Ydiv = 1/Y

    if op == &quot;*&quot;:
        predicted_product = model_sqr.predict(model_add.predict(np.array([[X, Y]]))) - model_sqr.predict(np.array([X])) -  model_sqr.predict(np.array([Y]))
        print(predicted_product/2)
    elif op ==&quot;/&quot;:
        predicted_quot = model_sqr.predict(model_add.predict(np.array([[X, Ydiv]]))) - model_sqr.predict(np.array([X])) -  model_sqr.predict(np.array([Ydiv]))
        print(predicted_quot/2)


</code></pre>
<p>The  multiplication part works reasonably well, but on inputting two numbers to be divided, the following error occurs:</p>
<pre><code>Exception encountered when calling Sequential.call().

Cannot take the length of shape with unknown rank.
</code></pre>
<p>Can someone help me fix this?</p>
<p><em><strong>EDIT:</strong></em> I changed <code>Ydiv=1/Y</code> TO <code>Ydiv = np.reciprocal(Y)</code>, and although no error now shows up, every division I conduct yields a result of approximately some specific number (different values each time I run the program).</p>
<p>So now I'd like to know</p>
<p><strong>1:</strong> How to fix this, and</p>
<p><strong>2:</strong> How the error arose in the first place.</p>
","2024-05-15 09:57:34","1","Question"
"78480544","78475572","","<p>It doesn't matter so long as the you retain some reference to the input.</p>
<p>At a high level, you are trying to compute <code>output = activation(input + f(input))</code></p>
<p>Both methods shown accomplish this. As long as you don't lose the <code>input</code> reference or change <code>input</code> through an in-place operation, you should be fine.</p>
<p>For what it's worth, I would separate out the residual connection and the sub-block just for clarity:</p>
<pre class=""lang-py prettyprint-override""><code>class Block(nn.Module):
    def __init__(self, ...):
        super().__init__()
        self.conv1 = ...
        self.norm1 = ...
        self.act = ...
        self.conv2 = ...
        self.norm2 = ...

    def forward(self, x):
        x = self.conv1(x)
        x = self.norm1(x)
        x = self.act(x)
        x = self.conv2(x)
        x = self.norm2(x)
        return x

class ResBlock(nn.Module):
    def __init__(self, block):
        super().__init__()
        self.block = block
        self.act = ...

    def forward(self, x):
        return self.act(x + self.block(x))
</code></pre>
","2024-05-14 20:34:24","0","Answer"
"78476711","","Neural network to approximate the square function gives 0 output","<p>I'm trying to build a neural network to approximate the squares of numbers from -50 to 50. I've referred to the code in <a href=""https://stackoverflow.com/a/55203161/9133556"">this answer</a> to write mine:</p>
<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import regularizers

x_train = np.random.random((10000,1))*100-50
y_train = np.square(x_train)

model = Sequential(
        [
            Dense(8, activation = 'relu', kernel_regularizer = regularizers.l2(0.001), input_shape = (1,)),
            Dense(8, activation = 'relu',  kernel_regularizer = regularizers.l2(0.001)),
            Dense(1, activation = 'relu')
            ]

        )

batch_size = 32
epochs = 100

model.compile(loss = 'mse', optimizer='adam')
model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 1)

x = &quot;n&quot; 
while True:
    print(&quot;enter num:&quot;)
    x = input()
    if x == &quot;end&quot;:
        break

    X = int(x)

    predicted_sum = model.predict(np.array([X]))
    print(predicted_sum)
</code></pre>
<p>The problem is, all inputs give rise to the output &quot;[[0.]]&quot;. I don't know why this is caused and how to fix it, can someone help?</p>
<p>This message is displayed immediately after the code is executed, does it have something to do with the problem?</p>
<pre><code>oneDNN custom operations are on. You may see slightly
different numerical results due to floating-point round-off errors from different computation orders. To turn them off
, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
</code></pre>
","2024-05-14 08:21:49","0","Question"
"78475572","","What's the correct way of expressing Residual Block with forward function of pytorch?","<p>AFAIK there are 2 ways to express ResNet Block in pytorch:</p>
<ul>
<li>Copy the input in the beginning, modify the input in the process, add the copy in the end.</li>
<li>Preserve the input in the beginning, create new variable in the process, add the input in the end.</li>
</ul>
<p>Which leads to 2 kinds of code:</p>
<pre class=""lang-py prettyprint-override""><code>def forward(self, x):
    y = x
    x = self.conv1(x)
    x = self.norm1(x)
    x = self.act1(x)
    x = self.conv2(x)
    x = self.norm2(x)
    x += y
    x = self.act2(x)
    return x
</code></pre>
<pre class=""lang-py prettyprint-override""><code>def forward(self, x):
    y = self.conv1(x)
    y = self.norm1(y)
    y = self.act1(y)
    y = self.conv2(y)
    y = self.norm2(y)
    y += x
    y = self.act2(y)
    return y
</code></pre>
<p>Are they identical? Which one is preferred? Why?</p>
","2024-05-14 03:27:42","0","Question"
"78471408","78469835","","<p>Your understanding is correct. You should follow these steps for setting up your neural network for binary classification:</p>
<p><em>Input Layer: 5 neurons (corresponding to your 5 inputs). First Hidden Layer: 32 neurons with ReLU activation. Second Hidden Layer: 32 neurons with ReLU activation. Output Layer: 1 neuron with Sigmoid activation (since this is a binary classification task).</em></p>
<p>The process of adjusting the weights of the neural network is generally handled through a method known as <a href=""https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd"" rel=""nofollow noreferrer"">backpropagation</a>, which is coupled with an optimization algorithm like Stochastic Gradient Descent (SGD), Adam, or others.</p>
<p>Below is an example of how you can implement this using TensorFlow:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Define the model
model = Sequential([
    Dense(32, input_shape=(5,), activation='relu'),
    Dense(32, activation='relu'),                    
    Dense(1, activation='sigmoid')             
])


model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Assuming X_train and y_train are your data matrices
# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)
</code></pre>
","2024-05-13 09:50:52","1","Answer"
"78469835","","How can i proceed further in this AI/ML project?","<p>I have 10 datasets (.csv) each with 100,000 rows, with each row containing 5 inputs ( -4.0f to +4.0f) and a output column (0/1). I want to train a Neural Network using this and predict the test dataset that I was given (which has 100,000 rows too, but without output column filled).</p>
<p>I thought of creating a 5--(reLU)--&gt; 32 --(reLU)--&gt; 32 --(sigmoid) --&gt; 1 Neural Network and train it with reward system like this [if (expec.op  ==0) reward=1- o/pfromNN; if (expec.op  ==1) reward= o/pfromNN].</p>
<p>How can I adjust weights of NN using this or How can I proceed further? I am a newbie to NN.</p>
<p>I thought of doing this like lunar lander module in gymnasium but since there are no states involved here I am confused</p>
","2024-05-13 02:25:15","-2","Question"
"78467885","78467829","","<p>The example of <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"" rel=""nofollow noreferrer"">sklearn.model_selection.train_test_split</a> states:</p>
<blockquote>
<p><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</code></p>
</blockquote>
<p>Since the code you provided is assigning the returning splittings in the wrong order, I am assuming you are providing the <code>.fit()</code> function of your model with the input test data instead of the desired output data of your train splitting. Try the following:</p>
<pre><code>x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=4)
</code></pre>
","2024-05-12 12:42:19","0","Answer"
"78467829","","ValueError: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 8 'y' sizes: 3","<p>whenever i try to run this code it shows this value error and i don't know why i check the lenght of the labels and images list and it's equal but x_train and y_train is different in length
note that i can't use tensorflow.keras for some reason it shows an error so i use only keras</p>
<pre><code>import numpy as np
import os
import keras
import tensorflow as tf
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
import cv2 as cv

people = ['H', 'J']
DIR = 'C:\AI'
images = []
labels = []
haar_cascade = cv.CascadeClassifier('haar_face.xml')

for person in people:
    path = os.path.join(DIR, person)
    label = people.index(person)
    for img in os.listdir(path):
        img_path = os.path.join(path, img)
        img_array = cv.imread(img_path)
        gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)
        face_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=6)
        for (x, y, w, h) in face_rect:
            face_roi = img_array[y:y + h, x:x + w]
            face_roi = cv.resize(face_roi, (128, 128))
            images.append(face_roi)
            labels.append(label)



#images = np.array(images, dtype='float')/255.0
#labels = np.array(labels, dtype='float')/255.0

x_train, y_train, x_test, y_test = train_test_split(images, labels, test_size=0.2, random_state=4)

x_train = np.array(x_train, dtype='float')/255.0
y_train = np.array(y_train, dtype='float')/255.0
print(len(x_train), ' ', len(y_train))

model = keras.models.Sequential()
model.add(keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(128, 128, 3)))
model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))
model.add(keras.layers.BatchNormalization(axis=-1))
model.add(keras.layers.Dropout(0, 2))
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(512, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
hist = model.fit(np.array(x_train), np.array(y_train), epochs=5, batch_size=64)
</code></pre>
","2024-05-12 12:19:55","0","Question"
"78466524","78466376","","<p>I think this works:</p>
<pre><code># -- test

def pipeline_tests_():
    print(f'\n--&gt; pipeline_tests_()')
    import torch
    from transformers import pipeline

    # pipe = pipeline(model=&quot;gpt2&quot;, device_map=&quot;auto&quot;, model_kwargs={&quot;load_in_8bit&quot;: True})
    pipe = pipeline(model=&quot;gpt2&quot;, device_map=&quot;auto&quot;, model_kwargs={&quot;load_in_4bit&quot;: True})

    output = pipe(&quot;This is a cool example!&quot;, do_sample=True, top_p=0.95, temperature=0.8, max_length=50)
    print(f'\n{output=}')
    print(f'{len(output)=}')

    output = pipe(&quot;This is a cool example!&quot;, do_sample=True, top_p=0.95, temperature=0.8, max_length=50, num_return_sequences=4)
    print(f'\n{output=}')
    print(f'{len(output)=}')

    output = pipe(&quot;This is a cool example!&quot;, do_sample=False, top_p=0.95, temperature=0.8, max_length=50, num_return_sequences=4, num_beams=5)
    print(f'\n{output=}')
    print(f'{len(output)=}')

    print()

# -- main 

def main(
        # path_2_eval_dataset: str = '~/gold-ai-olympiad/data/MATH/test',
        path_2_eval_dataset: str = '~/putnam-math/data/Putnam_MATH_original_static2/test',
        model: str = 'gpt-4-turbo',  # e.g., gpt-4-turbo, gpt-3.5-turbo
        start: int = 0, 
        end: int = sys.maxsize, 
        ):
    from evals.data_eval_utils import get_iter_for_eval_data_set
    from evals.prompts_evals import HELM_MATH_PROMPT_8SHOT_COT2_TEMPLATE, get_math_problem_prompt_ala_helm_8shot_cot2 
    # - Get eval data
    path_2_eval_dataset: Path = Path(path_2_eval_dataset).expanduser()
    math_gold_probs_solns: list[dict] = list(get_iter_for_eval_data_set(path_2_eval_dataset))
    math_gold_probs_solns: list[dict] = math_gold_probs_solns[start:end]
    print(f'{path_2_eval_dataset=} \n {len(math_gold_probs_solns)=}')
    assert len(math_gold_probs_solns) &gt; 0, f'No math problems found in {path_2_eval_dataset=}'

    # - Get vllm generator
    prompt_template: str = HELM_MATH_PROMPT_8SHOT_COT2_TEMPLATE
    prompt_gen_func: Callable = get_math_problem_prompt_ala_helm_8shot_cot2
    math_prompts_problems: list[str] = [prompt_gen_func(gold_data_prob_soln, prompt_template) for gold_data_prob_soln in math_gold_probs_solns]
    math_guessed_outputs: list[str] = [f&quot;Solution: Let's think step by step. &quot; + gold_data_prob_soln['solution'] for gold_data_prob_soln in math_gold_probs_solns]

    # - Estimate cost of inference
    result = estimate_openai_api_inference_cost(prompts=math_prompts_problems, outputs=math_guessed_outputs, model=model, verbose=True)
    print(f'--&gt; Inference cost: {result=}')

if __name__ == '__main__':
    import fire
    import time
    start = time.time()
    # main()
    # fire.Fire(main)
    fire.Fire(pipeline_tests_)
    # pyton boxed_acc_eval.py --model meta-llama/Meta-Llama-3-8B-Instruct
    print(f&quot;Done!\a Time: {time.time()-start:.2f} sec, {(time.time()-start)/60:.2f} min, {(time.time()-start)/3600:.2f} hr\a&quot;)
</code></pre>
<p>output:</p>
<pre><code>--&gt; pipeline_tests_()
/lfs/ampere1/0/brando9/miniconda/envs/gold_ai_olympiad/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/lfs/ampere1/0/brando9/miniconda/envs/gold_ai_olympiad/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:391: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.
  warnings.warn('Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')

output=[{'generated_text': &quot;This is a cool example! I got my first two kids in my living room to play with, and I've played with them for years before that. It was so beautiful. They were so nervous.\n\nAdvertisement\n\nI don't think&quot;}]
len(output)=1
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.

output=[{'generated_text': 'This is a cool example!\n\nThe next thing I\'m going to do is create a class called &quot;Misc.Libraries.Libraries.Libraries&quot; and set it up with a simple definition:\n\n// This is a class'}, {'generated_text': &quot;This is a cool example! In the video below, you can see how you can add a second time to your first time!\n\nIt's all about balancing the energy density of the atmosphere and the way you keep it going at night.\n&quot;}, {'generated_text': &quot;This is a cool example! I've tried to build a simple tool for tracking the change over time. My friends and I will try to improve it for everyone.\n\nFor now, I've started with a simple simple tool that takes just a&quot;}, {'generated_text': 'This is a cool example!\n\nWe need to see how the system works.\n\nWe want to see how the &quot;network&quot; works.\n\nAnd what about &quot;tasking&quot; for an existing service.\n\nThis is just one'}]
len(output)=4
/lfs/ampere1/0/brando9/miniconda/envs/gold_ai_olympiad/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/lfs/ampere1/0/brando9/miniconda/envs/gold_ai_olympiad/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.

output=[{'generated_text': &quot;This is a cool example!\n\nI've been working on this for a few months now, and I'm really excited to share it with you.\n\nI've been working on this for a few months now, and I'm really excited&quot;}, {'generated_text': &quot;This is a cool example!\n\nI've been working on this for a few months now, and I'm really excited to share it with you guys.\n\nI've been working on this for a few months now, and I'm really&quot;}, {'generated_text': &quot;This is a cool example!\n\nI've been working on this for a few months now, and I'm really excited to share it with you.\n\nI've been working on this for a while now, and I'm really excited to&quot;}, {'generated_text': &quot;This is a cool example!\n\nI've been working on this for a few months now, and I'm really excited to share it with you guys.\n\nI've been working on this for a couple months now, and I'm really&quot;}]
len(output)=4

Done! Time: 33.57 sec, 0.56 min, 0.01 hr
</code></pre>
<p>ultimately this helped me <a href=""https://huggingface.co/docs/transformers/pipeline_tutorial#using-pipeline-on-large-models-with--accelerate-"" rel=""nofollow noreferrer"">https://huggingface.co/docs/transformers/pipeline_tutorial#using-pipeline-on-large-models-with--accelerate-</a>:</p>
<pre><code># pip install accelerate bitsandbytes
import torch
from transformers import pipeline

pipe = pipeline(model=&quot;facebook/opt-1.3b&quot;, device_map=&quot;auto&quot;, model_kwargs={&quot;load_in_8bit&quot;: True})
output = pipe(&quot;This is a cool example!&quot;, do_sample=True, top_p=0.95)
</code></pre>
<p>and guessed the inputs names based on other attempts, errors.</p>
<hr />
<pre><code>error: 
</code></pre>
<p>error: <code>Truncation was not explicitly activated but</code>max_length<code>is provided a specific value, please use</code>truncation=True<code>to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to</code>truncation<code>.</code></p>
<pre><code>
----

fix:
</code></pre>
<p>def pipeline_tests_():
print(f'\n--&gt; pipeline_tests_()')
import torch
from transformers import pipeline</p>
<pre><code># pipe = pipeline(model=&quot;gpt2&quot;, device_map=&quot;auto&quot;, model_kwargs={&quot;load_in_8bit&quot;: True})
pipe = pipeline(model=&quot;gpt2&quot;, device_map=&quot;auto&quot;, model_kwargs={&quot;load_in_4bit&quot;: True})

# output = pipe(&quot;This is a cool example!&quot;, do_sample=True, top_p=0.95, temperature=0.8, max_length=50)
output = pipe(&quot;This is a cool example!&quot;, do_sample=True, top_p=0.95, temperature=0.8, max_length=50, truncation=True)
print(f'\n{output=}')
print(f'{len(output)=}')

output = pipe(&quot;This is a cool example!&quot;, do_sample=True, top_p=0.95, temperature=0.8, max_length=50, num_return_sequences=4, truncation=True)
print(f'\n{output=}')
print(f'{len(output)=}')

output = pipe(&quot;This is a cool example!&quot;, do_sample=False, top_p=0.95, temperature=0.8, max_length=50, num_return_sequences=4, num_beams=5, truncation=True)
print(f'\n{output=}')
print(f'{len(output)=}')

print()
</code></pre>
<pre><code></code></pre>
","2024-05-12 01:56:45","0","Answer"
"78466413","78466376","","<p>It seems to me that there are just a few minor issues in your code.</p>
<ul>
<li>It's missing the import of torch.</li>
<li>There are some vars, depreciated that I changed.</li>
<li>Still, I get a few warnings, but I guess, it may not be important.</li>
</ul>
<pre><code>import torch
from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline
from typing import List, Dict


def process_prompts(prompts: List[str], model: GPT2LMHeadModel, tokenizer: GPT2Tokenizer, num_completions) -&gt; List[List[str]]:
    device = 0 if model.device.type == 'cuda' else -1
    text_generator = pipeline(&quot;text-generation&quot;, model=model, tokenizer=tokenizer, device=device)
    outputs = []

    for prompt in prompts:
        try:
            results = text_generator(prompt, truncation=True,
                                     num_return_sequences=num_completions, num_beams=num_completions)
            completions = [result['generated_text'] for result in results]
            outputs.append(completions)
        except Exception as e:
            print(f&quot;Error processing prompt {prompt}: {str(e)}&quot;)

    return outputs


if __name__ == &quot;__main__&quot;:
    tokenizer = GPT2Tokenizer.from_pretrained(&quot;gpt2&quot;)
    model = GPT2LMHeadModel.from_pretrained(&quot;gpt2&quot;)
    model.to(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

    example_prompts = [&quot;Hello, how are you?&quot;]
    num_completions = 2
    processed_outputs = process_prompts(example_prompts, model, tokenizer, num_completions)

    res = ' '.join(processed_outputs[0])
    print(res)

</code></pre>
<h3>Prints</h3>
<pre><code>Hello, how are you? How are you?&quot;

&quot;I'm fine,&quot; I said.

&quot;Well, I guess I'm just fine,&quot; he said, turning to me.

&quot;Well, I guess I'm just fine Hello, how are you? How are you?&quot;

&quot;I'm fine,&quot; I said.

&quot;Well, I guess I'm just fine,&quot; he said, turning to me.

&quot;Well, I guess I'm just not
</code></pre>
","2024-05-12 00:29:37","0","Answer"
"78466376","","How to generate multiple text completions per prompt (like vLLM) using HuggingFace Transformers Pipeline without triggering an error?","<p>I'm using the HuggingFace Transformers Pipeline library to generate multiple text completions for a given prompt. My goal is to utilize a model like GPT-2 to generate <strong>different possible completions like the defaults in vLLM</strong>. However, I am encountering an issue with unused model_kwargs when I attempt to specify parameters like max_length and num_return_sequences.</p>
<p>Here is the code snippet I'm using:</p>
<pre class=""lang-py prettyprint-override""><code>Copy code
from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline
from typing import List, Dict

def process_prompts(prompts: List[str], model: GPT2LMHeadModel, tokenizer: GPT2Tokenizer, num_completions: int = 3) -&gt; List[List[str]]:
    device = 0 if model.device.type == 'cuda' else -1
    text_generator = pipeline(&quot;text-generation&quot;, model=model, tokenizer=tokenizer, device=device)
    outputs = []

    for prompt in prompts:
        try:
            results = text_generator(prompt, max_length=50, num_return_sequences=num_completions, num_beams=num_completions)
            completions = [result['generated_text'] for result in results]
            outputs.append(completions)
        except Exception as e:
            print(f&quot;Error processing prompt {prompt}: {str(e)}&quot;)

    return outputs

if __name__ == &quot;__main__&quot;:
    tokenizer = GPT2Tokenizer.from_pretrained(&quot;gpt2&quot;)
    model = GPT2LMHeadModel.from_pretrained(&quot;gpt2&quot;)
    model.to(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

    example_prompts = [&quot;Hello, how are you?&quot;]
    processed_outputs = process_prompts(example_prompts, model, tokenizer, num_completions=3)
    for output in processed_outputs:
        print(output)
</code></pre>
<p>and also:</p>
<pre class=""lang-py prettyprint-override""><code>            results = text_generator(prompt, max_length=50, num_return_sequences=num_completions)
</code></pre>
<p>When I run this, I get the following error:</p>
<pre><code>The following `model_kwargs` are not used by the model: ['max_len']
Note: I am aware that typos in the generate arguments can also trigger this warning, but I've checked and rechecked the arguments names.
</code></pre>
<p>and</p>
<pre><code>   raise ValueError(
ValueError: Greedy methods without beam search do not support `num_return_sequences` different than 1 (got 4).
</code></pre>
<p>What could be causing this error, and how can I fix it to generate multiple completions effectively using the model?</p>
<p>cross: <a href=""https://discuss.huggingface.co/t/how-to-generate-multiple-text-completions-per-prompt-using-huggingface-transformers-pipeline-without-triggering-an-error/86297"" rel=""nofollow noreferrer"">https://discuss.huggingface.co/t/how-to-generate-multiple-text-completions-per-prompt-using-huggingface-transformers-pipeline-without-triggering-an-error/86297</a></p>
","2024-05-12 00:06:07","1","Question"
"78464214","","Recurrent neural network trained with torch.autograd predicts nonsense","<p>I'm trying to use <a href=""https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"" rel=""nofollow noreferrer"">torch.autograd</a> to train a simple recurrent neural network that predicts the next character in a sequence of characters that represent <a href=""https://github.com/yaskovdev/stack-exchange-questions-and-answers/blob/master/train-rnn-with-autograd/songs.txt"" rel=""nofollow noreferrer"">songs in an ABC notation</a>.</p>
<p>The model looks like this:</p>
<pre class=""lang-py prettyprint-override""><code>model = keras.Sequential([
    keras.layers.Input(shape=(SEQ_LENGTH,), batch_size=batch_size),
    keras.layers.Embedding(len(vocabulary), 256),
    keras.layers.LSTM(1024, return_sequences=True, stateful=stateful),
    keras.layers.Dense(len(vocabulary))
])
</code></pre>
<p>The training process looks like this:</p>
<pre class=""lang-py prettyprint-override""><code>loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)
for i in range(1000):
    inputs, targets = random_inputs_and_targets(vectorized_songs, seq_length=SEQ_LENGTH, batch_size=BATCH_SIZE)

    predictions = model(inputs)
    loss = loss_fn(predictions.permute(0, 2, 1), torch.from_numpy(targets).long())

    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
</code></pre>
<p>I then save the model parameters and load them into the similar model, but this time the model is stateful and has batch size <code>1</code>:</p>
<pre class=""lang-py prettyprint-override""><code>torch.save(model.state_dict(), os.path.join(cwd, &quot;model.pt&quot;))
trained_model = build_model(1, True)
trained_model.load_state_dict(torch.load(os.path.join(cwd, &quot;model.pt&quot;)))
trained_model.eval()
</code></pre>
<p>Then, I use the loaded model to predict a string of characters that I expect to look like a song in the ABC notation:</p>
<pre class=""lang-py prettyprint-override""><code>input_eval = [char_to_index[s] for s in start_string]
input_eval = torch.unsqueeze(torch.tensor(input_eval), 0)

text_generated = []

for i in range(generation_length):
    predictions = torch.squeeze(model(input_eval), 0)
    predicted_index = torch.multinomial(softmax(predictions, dim=0), 1, replacement=True)[-1, 0]
    input_eval = torch.unsqueeze(torch.unsqueeze(predicted_index, 0), 0)
    text_generated.append(index_to_char[predicted_index.item()])

return start_string + ''.join(text_generated)
</code></pre>
<p>The full code is <a href=""https://github.com/yaskovdev/stack-exchange-questions-and-answers/blob/master/train-rnn-with-autograd/main.py"" rel=""nofollow noreferrer"">here</a>.</p>
<p>During the 1000 training epochs, the loss function value goes down from around <code>4.42</code> to <code>0.78</code>, as expected.</p>
<p>But when I then try to use the &quot;trained&quot; model to generate a song, the result looks like a random string: <code>XwQ5&gt;ab&gt;6q6S(z']!&lt;hxaG4..M= (=ERp/xJmS|qIh_CzbM0D-N 6Yc=Ei[tcodBsEKfW&lt;WZ5Jb(&quot;u1rrGLcFIk&quot;PVk.'FEII:(qu7.nFbw^3/RY2LyrW</code>. An example of the full result can be seen <a href=""https://github.com/yaskovdev/stack-exchange-questions-and-answers/blob/master/train-rnn-with-autograd/predicted_songs.txt"" rel=""nofollow noreferrer"">here</a>.</p>
<p>How do I even start debugging what is going wrong? Previously I built <a href=""https://github.com/jshaipuka/ai-sandbox/blob/master/torch-sandbox/simple.py"" rel=""nofollow noreferrer"">a simple non-recurrent classifier</a> using <code>torch.autograd</code>, its outputs were only 90% accurate, but this was still much better than when I try to build an RNN. Can it be that the hidden state that the RNN needs to predict the next character is lost somewhere during training or actual prediction?</p>
<p>Any suggestions are welcome, since I'm getting stuck.</p>
","2024-05-11 10:25:12","1","Question"
"78462920","78462808","","<p>Since it looks like that you are new to the concept, I will tell you some ways you can improve your result here or in general using NeuralNets.</p>
<p>Your model is overfitting to the input train data. to avoid:</p>
<ol>
<li>Always <strong>scale</strong> your input data. ranging them between [0,1] or [-1,1] depending on your use case is 99% of the time good enough. It helps the back propagation.</li>
<li>Use metrics knowingly. <strong>ReLu</strong> activation deletes all negative values from calculation matrix by setting them to zero. You have negative values being fed into the model. Although ReLu could be useful even with negative inputs, it depends on the use case. it is not the master key.</li>
<li>Use <strong>Dropout</strong>. Simply by adding dropout you reduce huge parts of your overfitting. it randomly sets some coefficients of a that layer to zero. so it does not overfit to some specific part of your input. and the trained model is more generalised.</li>
<li>early stopping. Training long doesn't always mean better model. you can set the training to be stopped earlier than your train&amp;test accuracy start distancing each other.</li>
<li>fair amount of data and feature for the task. if you are training a model for 20 different category in output, you input data must be sufficient enough for the model to generalise the features of inputs. also dimension of the input data (shows the amount of data in can present) must be well enough (not much or few).</li>
</ol>
<p>for start try to scale your input data between (0,1) and use dropout for one or two of your layers and see the result.</p>
","2024-05-10 23:35:45","1","Answer"
"78462808","","My test loss is increasing but train loss is decreasing for Neural Network. What should i do?","<p><a href=""https://i.sstatic.net/Gsm0FiyQ.png"" rel=""nofollow noreferrer"">My Neural Network</a></p>
<pre><code>def buildModel(optimizer):
    model = tf.keras.models.Sequential([
    Dense(100, activation = 'relu'),
    Dense(82, activation = 'relu'),
    Dense(20, activation = 'relu'),
    Dense(6, activation = 'relu'),
    Dense(20, activation = 'softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

tf.keras.optimizers.legacy.Adam()

model = buildModel('adam')
history = model.fit(train_x,train_y_lst, validation_data=(test_x, test_y_lst),epochs = 50,batch_size = 32,verbose = 0)
</code></pre>
<p>Plotting</p>
<pre><code>plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curves')
plt.legend()

# Plot training and validation accuracy
plt.figure()
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy Curves')
plt.legend()

plt.show()
</code></pre>
<p><a href=""https://i.sstatic.net/nSQae9GP.png"" rel=""nofollow noreferrer"">Loss vs Epochs</a></p>
<p>Accuracy for test is also bad</p>
<p><a href=""https://i.sstatic.net/WhAXNhwX.png"" rel=""nofollow noreferrer"">Accuracy vs Epoch</a></p>
<p>Any suggestions where i may be going wrong, I am new?</p>
<p>I was expecting for test loss to decrease just like train loss.</p>
<p>My test_x lookes like this</p>
<pre><code>  -0.84335711]
 [-0.1898388  -1.4177287   0.24718753 ... -0.33010045  0.77921928
  -1.56813293]
 [ 0.51887204 -1.34965479  0.19069737 ...  0.56236361 -0.03741466
  -0.24596578]
 ...
 [-0.11631875  0.46366703 -1.04400684 ...  0.23282911 -2.10649511
  -0.41883463]
 [-1.03632829  0.05419996 -2.22371652 ...  0.47133847 -1.70391277
  -1.42387687]
 [-0.12011524 -0.72294703 -0.74587529 ...  0.11331488 -1.81362912
  -0.11828704]]
</code></pre>
<p>test_y_lst</p>
<pre><code>array([[1, 0, 0, ..., 0, 0, 0],
       [1, 0, 0, ..., 0, 0, 0],
       [1, 0, 0, ..., 0, 0, 0],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]])
</code></pre>
<p>Multi classification problem.</p>
","2024-05-10 22:42:37","0","Question"
"78461888","78460997","","<p>It seems indeed that the web server is misconfigured: <a href=""http://yann.lecun.com/exdb/mnist/"" rel=""nofollow noreferrer"">http://yann.lecun.com/exdb/mnist/</a>. As this dataset is built-in in many standard libraries like keras (see <a href=""https://www.kaggle.com/code/amyjang/tensorflow-mnist-cnn-tutorial"" rel=""nofollow noreferrer"">this tutorial</a>), it is not so frequently downloaded from the &quot;lecun url&quot; I think.</p>
<p>In the source (<a href=""https://github.com/datapythonista/mnist/blob/master/mnist/__init__.py"" rel=""nofollow noreferrer""><code>mnist/__init__.py</code></a>) there is a comment:</p>
<pre class=""lang-py prettyprint-override""><code># `datasets_url` and `temporary_dir` can be set by the user using:
# &gt;&gt;&gt; mnist.datasets_url = 'http://my.mnist.url'
# &gt;&gt;&gt; mnist.temporary_dir = lambda: '/tmp/mnist'
datasets_url = 'http://yann.lecun.com/exdb/mnist/'
temporary_dir = tempfile.gettempdir
</code></pre>
<p>So theoretically, you could set the <code>mnist.datasets_url</code> variable for a mirror and it should work. The only mirror I found with the original format is this: <a href=""https://github.com/mkolod/MNIST"" rel=""nofollow noreferrer"">https://github.com/mkolod/MNIST</a>. But this is <code>https</code>, and it did not work for me.</p>
<p>So instead you can manually download the data from the GitHub mirror into the temp directory shown by this code:</p>
<pre class=""lang-py prettyprint-override""><code>import temp file
tempfile.gettempdir()
</code></pre>
<p>And then <code>mnist.train_images()</code> should work.</p>
","2024-05-10 18:08:01","1","Answer"
"78460997","","MNIST - problem with mnist.train_images() - HTTPError: Forbidden","<p>I'm currently learning about neural networks and I want to use the <strong>train_images()</strong> function, but I'm unable to do so. If I run the following code:</p>
<pre class=""lang-py prettyprint-override""><code>import mnist

images = mnist.train_images()
</code></pre>
<p>, I'll get:</p>
<pre class=""lang-py prettyprint-override""><code>runfile('C:/Users/deriv/untitled0.py', wdir='C:/Users/deriv')
Traceback (most recent call last):

  File ~\anaconda3\Lib\site-packages\spyder_kernels\py3compat.py:356 in compat_exec
    exec(code, globals, locals)

  File c:\users\deriv\untitled0.py:3
    images = mnist.train_images()

  File ~\anaconda3\Lib\site-packages\mnist\__init__.py:161 in train_images
    return download_and_parse_mnist_file('train-images-idx3-ubyte.gz')

  File ~\anaconda3\Lib\site-packages\mnist\__init__.py:143 in download_and_parse_mnist_file
    fname = download_file(fname, target_dir=target_dir, force=force)

  File ~\anaconda3\Lib\site-packages\mnist\__init__.py:59 in download_file
    urlretrieve(url, target_fname)

  File ~\anaconda3\Lib\urllib\request.py:241 in urlretrieve
    with contextlib.closing(urlopen(url, data)) as fp:

  File ~\anaconda3\Lib\urllib\request.py:216 in urlopen
    return opener.open(url, data, timeout)

  File ~\anaconda3\Lib\urllib\request.py:525 in open
    response = meth(req, response)

  File ~\anaconda3\Lib\urllib\request.py:634 in http_response
    response = self.parent.error(

  File ~\anaconda3\Lib\urllib\request.py:563 in error
    return self._call_chain(*args)

  File ~\anaconda3\Lib\urllib\request.py:496 in _call_chain
    result = func(*args)

  File ~\anaconda3\Lib\urllib\request.py:643 in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)

HTTPError: Forbidden
</code></pre>
<p>I installed <strong>mnist</strong> correctly using <strong>pip install</strong> but, I don't know why** mnist.train_images()** causes the error. Sorry if this is a simple question but, it will help me a lot.</p>
<p>I don't know wheter or not I'm supposed to download files straightforward from <a href=""http://yann.lecun.com/exdb/mnist/"" rel=""nofollow noreferrer"">http://yann.lecun.com/exdb/mnist/</a>. However I'm not able to do so because I don't have a permission to access this resources.</p>
","2024-05-10 15:02:52","2","Question"
"78456564","78454854","","<p>You need to subtract the max from the rest of z in order to get numerical stability</p>
<pre><code>expp = np.exp(z - np.max(z))
return expp / np.sum(expp)
</code></pre>
<p>Because the softmax function uses exponetials you can get values to overflow the capacity of the float representation.</p>
<p>By subtracting the max in the array, you remove this problem, while keeping the relative To avoid these issues, we can subtract the maximum value of the vector z from all elements before applying the exponential function. This trick ensures that all input values are shifted towards zero, preventing overflow while maintaining the correct relative differences between scores.</p>
","2024-05-09 19:16:51","0","Answer"
"78454854","","Analytical gradient of Softmax entropy loss does not match the numerical gradient","<p>I'm trying to implement the gradient of the softmax entropy loss in Python. However, I can see that the analytical gradient does not match the numeric gradient. Here is my Python code:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np

def softmax(z):
  expp = np.exp(z)
  
  return np.divide(expp, np.sum(expp))

def cost(z, y):
  s = softmax(z)
  
  return -np.sum(y * np.log(s)) / len(y)

def costprime(z, y):
  prime = []

  for i in range(len(z)):
    values = z.copy()

    values[i] += 1.0e-10

    prime.append((cost(values, y) - cost(z, y)) / 1.0e-10)

  return prime


z = np.array([1.1, 2.2, 0.3, -1.7])
y_expected = np.array([0, 0, 1, 0])

s = softmax(z)

cost_gradient = s - y_expected
numerical_derivative = costprime(z, y_expected)

print(cost_gradient)
print(numerical_derivative)
</code></pre>
<p>The result is:</p>
<pre><code>[0.22151804  0.66547696 -0.90046553  0.01347053]

[0.05538014491435206, 0.16636914068612896, -0.2251154818111445, 0.0033673064336881]
</code></pre>
<p>They look very different. However, when I try to change the values of z to see their effect on the cost, I found out that numerical derivative is more accurate than the analytical derivative (cost_gradient)</p>
","2024-05-09 13:42:31","0","Question"
"78454101","78453929","","<p>The problem was solved by replacing <code>[X, Y]</code> with <code>np.array([[X, Y]])</code></p>
","2024-05-09 11:24:36","0","Answer"
"78453929","","Variables cannot be used in array","<p>I'm trying to create a neural network to add and subtract integers. The code is as below:</p>
<pre><code>model_add = Sequential(
        [
            Dense(10, activation='relu'),
            Dense(1, activation ='relu')
            ]
        )

model_subtract = Sequential(
        [
            Dense(10, activation='relu'),
            Dense(1, activation ='relu')
            ]
        )

model_add.compile(loss = 'mse', optimizer='adam')
batch_size = 32
epochs = 100
model_add.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 0)


model_subtract.compile(loss = 'mse', optimizer='adam')
batch_size = 32
epochs = 100
model_add.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 0)

print(&quot;enter first num:&quot;)
x = input()

print(&quot;Enter operation:&quot;)
op= input()

print(&quot;enter second num:&quot;)
y = input()

X = int(x)
Y = int(y)

if op == &quot;+&quot;:
    predicted_sum = model_add.predict([X, Y])
    print(predicted_sum)
elif op ==&quot;-&quot;:
    predicted_sum = model_subtract.predict([X, Y])
    print(predicted_sum)
</code></pre>
<p>On input 1+2, this gives rise to an error:</p>
<pre><code>raise ValueError(f&quot;Unrecognized data type: x={x} (of type {type(x)})&quot;)
ValueError: Unrecognized data type: x=[1, 2] (of type &lt;class 'list'&gt;)
</code></pre>
<p>Can someone explain why this happens and how to fix it?</p>
","2024-05-09 10:51:58","0","Question"
"78448950","78448847","","<p>Do you understand the purpose of the validation and test data?</p>
<p>Let's say you're training a neural network on 100,000 pieces of data. You should randomly split them into. Train(60,000), Validation(20,000), and Test(20,000).</p>
<p>The training data is what the network is actually trained out, the validation data is what checked against at each epoch: This is done to prevent overfitting on training data, and optimize hyperparameters.</p>
<p>At the very end, you can test the network against the test data, which is another test against overfitting.</p>
","2024-05-08 13:34:10","0","Answer"
"78448847","","plot mean square error for training validation and testing in neural network","<p>Hi I see many of mean square error (MSE) plot as shown below:</p>
<p><a href=""https://i.sstatic.net/XIoqYklc.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/XIoqYklc.png"" alt=""enter image description here"" /></a></p>
<p>My understanding to generate blue line (training) as below:
Optimize the weights and bias values by using a certain optimization algorithm. For every epoch, calculate the MSE.</p>
<p>However, I don't understand how to generate the green and red lines.</p>
","2024-05-08 13:17:28","0","Question"
"78447342","78439701","","<p>You could use wandb.alert(...) inside a try/except block.</p>
<p>Check the docs here: <a href=""https://docs.wandb.ai/guides/runs/alert"" rel=""nofollow noreferrer"">https://docs.wandb.ai/guides/runs/alert</a></p>
","2024-05-08 09:14:17","0","Answer"
"78439701","","How to programmatically set alerts for failure in a W&B run?","<h2>How to programmatically set alerts for failure in a W&amp;B run?</h2>
<p>I'm trying to set up alerts in my W&amp;B (Weights &amp; Biases) project to notify me if a run fails. I've been testing several functions I thought would work based on my research, but none seem to be implemented in the W&amp;B API. Here's the code snippet where I attempt to set up these notifications:</p>
<pre class=""lang-py prettyprint-override""><code>import wandb

mode = 'dryrun'
run_name = 'my_run'
num_batches = 50
path = '/data'
name = 'experiment1'
today = '2023-08-01'
probabilities = [0.1, 0.9]
batch_size = 32
data_mixture_name = 'mix1'

debug = mode == 'dryrun'
run = wandb.init(mode=mode, project=&quot;beyond-scale&quot;, name=run_name, save_code=True)
wandb.config.update({
    &quot;num_batches&quot;: num_batches, 
    &quot;path&quot;: path, 
    &quot;name&quot;: name, 
    &quot;today&quot;: today, 
    'probabilities': probabilities, 
    'batch_size': batch_size, 
    'debug': debug, 
    'data_mixture_name': data_mixture_name
})

# Attempts to set notifications
run.notify_on_failure()
run.notify_on_crash()
run.notify_on_exit()
run.notify_on_heartbeat()
run.notify_on_abort()
</code></pre>
<p>Each of these attempts results in an <code>AttributeError</code>, stating that the 'Run' object has no such attribute. For example:</p>
<pre><code>AttributeError: 'Run' object has no attribute 'notify_on_failure'
</code></pre>
<p>Is there a correct method to set up failure or other alerts in W&amp;B? If so, how should I modify my approach?</p>
<p>ref: <a href=""https://community.wandb.ai/t/how-do-i-set-the-wandb-alert-programatically-for-my-current-run/4891"" rel=""nofollow noreferrer"">https://community.wandb.ai/t/how-do-i-set-the-wandb-alert-programatically-for-my-current-run/4891</a></p>
","2024-05-07 01:17:24","0","Question"
"78429670","78429381","","<p>First, it is unclear what your &quot;acc&quot; is. It might be a buggy implementation. Apart from it:</p>
<ul>
<li>Depending how acc is implemented you might get wrong results if total dataset size is not divisible by batch_size (since average of averages is not the same as the average of the whole thing, unless each average of the same size)</li>
<li><code>acc.update_state(y,y_labels)</code> puts real labels as first argument but <code>acc.update_state(test_pred_labels,test_labels)</code> puts them as a second one. It shouldn't matter for accuracy but it all depends on how things are implemented</li>
<li>If the  model uses batch normalization it will behave differently in batch mode vs over entire dataset</li>
</ul>
","2024-05-04 16:30:57","0","Answer"
"78429381","","Getting different accuracy in TensorFlow when training on batches vs whole dataset","<p>I am messing around with an multi-class image classifier in TensorFlow using a 2d CNN. If I try to evaluate the test data in batches or as whole set I get very different accuracy values. I even tried doing the evaluation of the training set (batches vs whole set) and got an even larger difference. Am I doing or interpreting something wrong?</p>
<p>Also the data was imported using tf.keras.utils.image_dataset_from_directory(dir)</p>
<pre><code>from tf.keras.metrics import Accuracy
acc=Accuracy()
#code for evaluating in batches
acc.reset_state()
re.reset_state()
pre.reset_state()
for batch in test_set.as_numpy_iterator():
    X,y=batch
    y_pred=model.predict(X)
    y_labels=y_pred.argmax(axis=1)
    acc.update_state(y,y_labels)
acc.result()

#code for whole dataset evaluation
test_probs=model.predict(test_data)
test_pred_labels=test_probs.argmax(axis=1)
acc.update_state(test_pred_labels,test_labels)
acc.result()
</code></pre>
","2024-05-04 14:50:51","0","Question"
"78407144","78404443","","<p>You have hint in your last image: <strong>A∧B</strong>, i.e. your output perceptron implements logical AND function. So, let's see why is that.</p>
<p>From your first image you have 2 decision boundaries of your hidden layer perceptrons &quot;A&quot; and &quot;B&quot;.
&quot;A&quot; line (hyperplane) shows when &quot;A&quot; perceptron fires (gives logical &quot;1&quot;). On every X and Y values combination lying on the right side of that line gives output of 1, and otherwise it gives 0. Likewise for &quot;B&quot; perceptron. So, your final decision boundary is intersection of those 2 decision boundaries, i.e. A &amp; B (conjunction). In other words, X and Y pair combination should be on the right side of both lines (pink zone) to have output of 1.</p>
<p>Now, you just need to implement logical AND function with perceptron. To do so, you can write truth table for f=A&amp;B.</p>
<pre><code>A B f
0 0 0
0 1 0
1 0 0
1 1 1
</code></pre>
<p>from truth table you can write following system of inequalities for your output perceptron:</p>
<pre><code>0*W13 + 0*W23 + b3 &lt;= 0
0*W13 + 1*W23 + b3 &lt;= 0
1*W13 + 0*W23 + b3 &lt;= 0
1*W13 + 1*W23 + b3 &gt; 0
</code></pre>
<p>simplifying:</p>
<pre><code>b3 &lt;= 0
W23 + b3 &lt;= 0
W13 + b3 &lt;= 0
W13 + W23 + b3 &gt; 0
</code></pre>
<p>as you can see it has infinite number of solutions.</p>
<p>If we choose <code>W13=W23=1</code>, then <code>b3&gt;-2 and b3&lt;=-1</code> or <code>b∈(-2;-1]</code></p>
<p>Intuitively instead of solving the system of inequalities, after the identification of last layer function, which is logical AND (or intersection of hidden layer perceptrons), you can pick the values in your head with following logic. We want the output of perceptron to fire (to be logical &quot;1&quot;) only when &quot;A&quot; and &quot;B&quot; is 1, thus W13 and W23 should be such, that the sum of them is greater than b3, but each of them is less then b3 in absolute values, then take negative of b3.</p>
","2024-04-30 08:13:38","0","Answer"
"78404443","","Theory - How to calculate the weights and bias for a preceptron representing a 2D area","<p>The problem here is to draw a Neural Network (NN) with perceptrons that, without the need for backpropagation learning, can distinguish the pink and the green zones in the two-dimensional (2d) chart below. The two zones take up the entire 2d XY space.</p>
<p><a href=""https://i.sstatic.net/261pDStM.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/261pDStM.png"" alt=""2D chart"" /></a></p>
<p>The inputs to the NN are the X and Y values.
The output of the NN must be:</p>
<ul>
<li>1 if a point (X,Y) is in the zone indicated by the pink arrows;</li>
<li>0 if the point is in the green arrow zone.</li>
</ul>
<p>I know that the solution to the problem is as follows, but I can't figure out why the weights W13, W23 and bias b3 are: 1, 1, and -1.9, respectively (and why does b3 have to be greater than -2 and less or equal than -1).</p>
<p><a href=""https://i.sstatic.net/BOWCm9vz.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/BOWCm9vz.png"" alt=""calculation"" /></a></p>
<p><a href=""https://i.sstatic.net/Jf38fsa2.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Jf38fsa2.png"" alt=""perceptron representation"" /></a></p>
<p>I wonder if they're determined by intuition, but I can't believe there isn't a more deterministic process of knowing how to calculate the values.</p>
<p>How do I calculate the values of the weights (W13, W23) and the bias (b3)?</p>
","2024-04-29 18:04:58","1","Question"
"78398576","78398026","","<p><code>step</code> is a <em>method</em> of the <code>optimizer</code>, so you need to <em>call</em> it to have the parameters updated by the optimizer (based on the gradients calculated by the loss function when you did <code>loss.backward()</code>):</p>
<pre><code>optimizer.step()  # note the () after optimizer.step
</code></pre>
","2024-04-28 14:52:54","2","Answer"
"78398026","","ANN training in pytorch giving me unchanged lossfunction","<p>i am learning pytorch. when I have run my code in jupyter cell the loss function is remaining unchanged. It should be either raised or get down. why is this happening?</p>
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
class Model(nn.Module):
    def __init__(self,in_features=4,h1=8,h2=9,out_features=3):
        #how many layers:
        #intiate the inherrited class of nn.Module
        
        super().__init__()
        #Input layer(4 feature)--&gt; hiddenlayer 1 neural net---&gt;hiddenlayer2 neural net--&gt;output(3 classes of Iris dataset)
        #fully connected layer. I could edit the layers here for example first layer is connected with  h1, h1 is connected with h2 
        # then h2 is connecte with out_Features
        #Alternatively i can use  all values of in_features,hidden layers value and out features  loaded in init parameter
        self.fc1=nn.Linear(in_features,h1)
        self.fc2=nn.Linear(h1,h2)
        self.out=nn.Linear(h2,out_features)
        
    #propagate method  here start  foroward propagation  
    def forward(self,x):
        x=F.relu(self.fc1(x))
        x=F.relu(self.fc2(x))
        x=self.out(x)
        return x
    torch.manual_seed(32)
    model=Model()
    df=pd.read_csv('iris.csv')
    df.tail()
    X=df.drop('target',axis=1).values
    y=df['target'].values
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=33)


    X_train=torch.FloatTensor(X_train)
    X_test=torch.FloatTensor(X_test)

    y_train=torch.LongTensor(y_train)

    y_test=torch.LongTensor(y_test)
    criterion=nn.CrossEntropyLoss()
    optimizer=torch.optim.Adam(model.parameters(),lr=0.01)
    epoch=100
    #for tracking loss  lets make it a empty list and then make the loss
    losses=[]
    for i in range(epoch):


   #forward and get a prediction
    y_pred=model.forward(X_train)#passing x_train  to forward function which actually applies features in fully connected neural net and activation function applied on those
    #measuring loss between predicted y, and actual y which is y_train. Using CrossEntropyloss, so we dont need to one hot encoding here
    loss=criterion(y_pred,y_train)
    #append the loss into losses for tracking losses in each epoch completion
    losses.append(loss.item())
    # we print this performance every 10 epoch completion
    if i%10==0:
        print(f'epoch{i} and loss is :{loss}')
    
    #Back propagation
    
    optimizer.zero_grad() #resetting the gradient since it accumulates in every epoch
    #print('Optimizer check',optimizer.zero_grad())
    loss.backward()#adjusting the paramter
   
    optimizer.step# updting the weight and bias
</code></pre>
<p>output:</p>
<pre><code>epoch0 and loss is :1.1507114171981812
epoch10 and loss is :1.1507114171981812
epoch20 and loss is :1.1507114171981812
epoch30 and loss is :1.1507114171981812
epoch40 and loss is :1.1507114171981812
epoch50 and loss is :1.1507114171981812
epoch60 and loss is :1.1507114171981812
epoch70 and loss is :1.1507114171981812
epoch80 and loss is :1.1507114171981812
epoch90 and loss is :1.1507114171981812
</code></pre>
","2024-04-28 11:39:15","1","Question"
"78376438","","How to specify the specific node connection/data flow in the tensorflow or pytorch?","<p>The neurons in the tensorflow were often assumed to be fully connected layers, i.e.</p>
<pre><code>model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 1), activation='relu', input_shape=(10, 1, 1)), # layer 1
    tf.keras.layers.Dense(32, activation='relu'), # layer 2
    tf.keras.layers.Dense(32, activation='relu'), # layer 3
}
</code></pre>
<p>Is it possible to specify the connection between the layers? i.e. the 2nd neuron in the layer 2 is connected to only the 3rd neuron in layer 3, with directed graphs.</p>
<pre><code>[(2,3),(3,3)], [(2,2),(3,1)], 
</code></pre>
<p>or even the non trivial back flow</p>
<pre><code>[(3,3),(2,3)], [(2,3),(3,5)],  
</code></pre>
<p>where the connection such as</p>
<pre><code>[(1,2),(2,3)], 
</code></pre>
<p>did not exist, i.e. the weight was always zero and can not be trained.</p>
<p>How to do it in tensorflow or pytorch?</p>
","2024-04-24 06:49:49","1","Question"
"78369831","","I want to minimize predicted_Pel obtained from neural network by using 2 decision variables","<p>I want to minimize predicted_Pel obtained from neural network by using 2 decision variables, the following code is working with one decision variable while it is not working with 2 variables and showing error,</p>
<ul>
<li>It is my dataset that I trained in neural network</li>
</ul>
<pre><code>import pandas as pd
import numpy as np
from gekko.ML import Gekko_NN_SKlearn, CustomMinMaxGekkoScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from gekko import GEKKO
data = {
    'Tco': [303.9599915, 303.6700134, 303.5799866, 303.7799988, 303.8200073, 304.1000061, 304.0400085, 304.0,
            303.9500122, 304.25],
    'Tei': [287.8900146, 287.8399963, 287.7799988, 287.8099976, 287.8299866, 287.8200073, 287.8399963, 287.8900146,
            287.8399963, 287.8800049],
    'm_cond': [0.000259306, 0.000266121, 0.000265435, 0.000266299, 0.000266172, 0.000266147, 0.000266071, 0.000266147,
               0.000266757, 0.000267444],
    'Pel': [874.0000129, 873.0000257, 871.999979, 875.9999871, 878.000021, 885.9999776, 884.9999905, 883.0000162,
            882.0000291, 889.9999857]
}

df = pd.DataFrame(data)
# Define features and label
X = ['Tco','Tei', 'm_cond']
Y = ['Pel']
</code></pre>
<ul>
<li>After training my neural network, I am minimizing predicted Pel, it is working with one decision variable i.e Tco as in the following</li>
</ul>
<pre><code># Create a Gekko model
m = GEKKO()

# Define Tco as a decision variable
Tco = m.Var(value=10, lb=303, ub=304)

# Predict Pel using the trained neural network 
predicted_Pel = Gekko_NN_SKlearn(mlp, mma, m).predict([Tco])

# Set the predicted Pel value as the objective to minimize
m.Minimize(predicted_Pel)

# Solve the optimization problem
m.solve(disp=False)

# Print the optimized Tco and corresponding predicted Pel value
print('Optimized Tco:', Tco.value[0])
print('Optimized Predicted Pel:', predicted_Pel.value[0])
print('Gekko Solvetime:', m.options.SOLVETIME, 's')                           
</code></pre>
<p><strong>Solution
Optimized Tco: 303.5799866
Optimized Predicted Pel: 875.45941052
Gekko Solvetime: 0.056699999986 s</strong></p>
<ul>
<li>It is not working when I use 2 decison variables i.e Tco and Tei as in the following</li>
</ul>
<pre><code># Create a Gekko model
m = GEKKO()

# Define Tco as a decision variable
Tco = m.Var(value=10, lb=303, ub=304)
Tei= m.Var(value=10, lb=287, ub=288)

# Predict Pel using the trained neural network 
predicted_Pel = Gekko_NN_SKlearn(mlp, mma, m).predict([Tco, Tei])

# Set the predicted Pel value as the objective to minimize
m.Minimize(predicted_Pel)

# Solve the optimization problem
m.solve(disp=False)

# Print the optimized Tco and corresponding predicted Pel value
print('Optimized Tco:', Tco.value[0])
print('Optimized Predicted Pel:', predicted_Pel.value[0])
print('Gekko Solvetime:', m.options.SOLVETIME, 's')
</code></pre>
<p><strong>ValueError: operands could not be broadcast together with shapes (3,) (2,)</strong></p>
<p>I want to get solution with 2 or more decision variables.</p>
","2024-04-23 04:05:20","2","Question"
"78359239","78356646","","<p>I've tryed to reproduce youre experiment as follows:</p>
<pre><code>y_t = tf.constant(np.array([
[1, 2],
[3, 4],
[5, 6]
]), dtype=tf.float32)

y_p = tf.Variable(np.array([
    [1.2, 1.5],
    [4.5, 4.7],
    [3.6, 4.8]
]), dtype=tf.float32)


losses = []
x = tf.Variable(3.0)
for _ in range(200):
    with tf.GradientTape(watch_accessed_variables=False) as tape:
        tape.watch(y_p)
        loss = custom_loss(y_true=y_t, y_pred=y_p)
    dy_dx = tape.gradient(loss, y_p)
    losses.append(loss.numpy().mean())
    y_p = y_p - dy_dx / 100.

plt.plot(losses)
plt.grid()
</code></pre>
<p>... and I had no problems with it:
<a href=""https://i.sstatic.net/H02M7.png"" rel=""nofollow noreferrer"">Loss</a></p>
<p>But I suspect that using <code>loss_within_range = tf.zeros_like(y_pred_average)</code> as one of the components of the loss function is a bad idea. It is independent of y_pred (except its shape). If tf.where chooses its values as the final values for the loss function, then it will not be possible to calculate gradients.</p>
","2024-04-20 18:07:56","0","Answer"
"78356646","","Keras metrics do not work with custom loss function","<p>I am working on a neural network model with keras.</p>
<p>My y values have a shape like: <code>(..., 2)</code></p>
<p>So my y_pred is going to have the same shape.
The problem is that the values of y represent a range of values that could be true (for example in row 1 all values between 1 and 2 are acceptable).</p>
<p>In my custom function I need to check if the absolute value of those 2 y_pred values is between the range indicated by y_true and if it is then my loss would be 0.
If it is not in the range, then I would calculate the deviation of the value predicted by the network from the nearest end.</p>
<p>For example, let's say that my <code>y_true= [[1, 2], [2, 3], [3, 4]]</code>
and my <code>y_pred = [[1.5, 1.7], [2.3, 3.4], [7, 10]]</code></p>
<p>Then the absolute values of y_pred would be = <code>[1.6, 2.85, 8.5]</code></p>
<p>So, in the end for row 0, my loss would be 0 (cause <code>1&lt;1.6&lt;2</code> )
for row 1, my loss would be 0 (cause <code>2.3&lt;2.85&lt;3.4</code> )
for row 2, my loss would be 4.5 (cause <code>4 &lt; 8.5</code> ) and <code>8.5-4 = 4.5</code></p>
<p>Firstly, I tried to implement this thought with a for loop but keras does not like that.</p>
<p>Then I tried to do it with keras backend functions like tf.abs and tf.where but I did not make anything solid.</p>
<p><strong>UPDATE</strong></p>
<p>I searched more about tensorflow functions and I made this:</p>
<pre><code>def custom_loss(y_true, y_pred):
    y_pred_average = tf.reduce_mean(y_pred, axis=1, keepdims=True)
    
    # Geta lower and upper bounds from y_true
    y_true_lower = y_true[:, 0:1]
    y_true_upper = y_true[:, 1:]
    
    # Check if y_pred_average values are within the range defined by y_true_lower and y_true_upper
    within_range_lower = y_true_lower &lt;= y_pred_average
    within_range_upper = y_pred_average &lt;= y_true_upper
    within_range = tf.logical_and(within_range_lower, within_range_upper)
    
    loss_within_range = tf.zeros_like(y_pred_average)
    loss_outside_range = tf.reduce_min(tf.stack([tf.abs(y_pred_average - y_true_lower), tf.abs(y_pred_average - y_true_upper)], axis=-1), axis=-1)
    
    loss = tf.where(within_range, loss_within_range, loss_outside_range)
    
    return loss
</code></pre>
<p>the above function, when run it returns a 2d array of losses
The problem is that metrics do not return anything.
Accuracy is always 0 and mse is always nan</p>
<p>example when run:</p>
<pre><code>y_t = np.array([
    [1, 2],
    [3, 4],
    [5, 6]
])

y_p = np.array([
    [1.2, 1.5],
    [4.5, 4.7],
    [3.6, 4.8]
])

custom_loss_func(y_true=y_t, y_pred=y_p)
</code></pre>
<p>returned:</p>
<pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float64, numpy=
array([[0. ],
       [0.6],
       [0.8]])&gt;
</code></pre>
<p>I am probably doing something wrong. Or my thought process is wrong overall</p>
","2024-04-20 00:24:04","0","Question"
"78355616","78349854","","<p>You could try training the model to predict on a longer time-horizon, such the next 12 hours rather than just the next hour. This gives the model more context during learning. It's akin to changing the model into a multi-task or multi-forecast arrangement, rather than having it learn from just the next hour's forecast. It might also impart an averaging or stabilising effect on shorter-term trends, though I think it's worth trying. You could also modify the loss such that the model is penalised more for short-term errors, which will put more focus on the next hour's forecast.</p>
<p>The model's new output shape will be <code>(batch size, forecast_length)</code>. At inference, even though the model will be outputting a prediction for the next 12 hours, you'd only read off the first value. Changes to the code would include something like this:</p>
<pre class=""lang-py prettyprint-override""><code> ...
 #for each input sequence, the target is a &quot;forecast_length&quot; vector
 forecast_length = 14
 y.append(target[i + time_steps:i + timesteps + forecast_length])
</code></pre>
<p>At the moment the model is ingesting a sequence, and only rendering its prediction after stepping through all 100 frames (sequence-to-vector architecture). There can often be an improvement in changing to a sequence-to-sequence architecture, where you have a target forecast for each step in the input the sequence, rather than just a single target for the entire sequence. This can stabilise and speed up training as there are more error gradients and they don't have to flow through time as much. The input shape stays the same: <code>(batch_size, sequence_length, input_size)</code>. The target shape changes to <code>(batch_size, sequence_length, forecast_length)</code> - there is a target for each point in the sequence.</p>
<p>For the current sequence size of 100 frames, it sounds like the model would consider about 4 days' worth of context when learning to forecast. There could be an improvement to be had by using a wider window. However, rather than simply increasing the sequence length (LSTMs might have a hard time), you can prepend a causal convolutional stage that learns to condense a wide receptive field down to a shorter sequence, ready for the subsequent LSTM stage.</p>
<p>You could also forego LSTMs altogether and go for a fully-convolutional approach, similar to the WaveNet architecture.</p>
<p>I think it's difficult to judge in advance what would work best with the data as it requires experimentation and tuning, which is why I've outlined a couple of strategies.</p>
","2024-04-19 18:33:20","1","Answer"
"78351808","78351249","","<p>You need to use <code>keras.layers.Concatenate()([input, hidden2])</code> -- note the extra parentheses. First create the layer, then call it. Just like any other layer.</p>
<p>Alternatively, you can use the functional variant <code>keras.layers.concatenate([input, hidden2])</code> -- note the lowercase <code>c</code>.</p>
","2024-04-19 06:46:49","1","Answer"
"78351249","","Inputs to a layer should be tensors. Got: <keras.layers.merging.concatenate.Concatenate","<p>I want to create complex multilayer wide and deep perceptron to handle California datasets. But the output layer refuses to take (input+ layer obtained from the deep path)</p>
<pre><code>input= keras.layers.Input(shape=x_train.shape[1:])
hidden1=keras.layers.Dense(30,activation=&quot;relu&quot;)(input)
hidden2=keras.layers.Dense(30,activation=&quot;relu&quot;)(hidden1)
concat = keras.layers.Concatenate([input, hidden2])
output=keras.layers.Dense(1)(concat)
</code></pre>
<p>I have tried to run the code but I face an error message like this
Inputs to a layer should be tensors. Got: &lt;keras.layers.merging.concatenate.Concatenate object at 0x00000196962D5540&gt;
Please give me an idea of how can I change my concatenate layer into a tensor so that the output layer accepts the concatenate layer</p>
","2024-04-19 03:41:02","0","Question"
"78350083","78347399","","<p>If the original function is known, Gekko can find the optimal solution such as:</p>
<pre class=""lang-py prettyprint-override""><code>from gekko import GEKKO
m = GEKKO()
x = m.Var(0,lb=0,ub=1)
y = m.Intermediate(m.cos(x*2*np.pi)) #function is used here
m.Obj(y)
m.solve(disp=False)
print('solution:',y.value[0])
print('x:',x.value[0])
</code></pre>
<p>That gives a minimum to the original function at <code>x=0.5</code>. If a function is not known, but needs to be regressed from data, there are many different model forms. Neural networks are one, but there are other types that may be worthwhile. A general flowchart for building a Machine Learned model is shown in this flowchart from the <a href=""https://apmonitor.com/pds"" rel=""nofollow noreferrer"">Machine Learning for Engineers course</a>.</p>
<p><a href=""https://i.sstatic.net/WvIga.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/WvIga.png"" alt=""ML Flowchart"" /></a></p>
<p>A first step is to consolidate, visualize, and assess the features (inputs) to determine which ones are highly correlated with the output. More details on this overall process are shown in the <a href=""https://apmonitor.com/pds/index.php/Main/WindPower"" rel=""nofollow noreferrer"">Wind Power case study</a>. Once the data is cleansed and scaled, train with <code>scikit-learn</code> or <code>tensorflow</code> and then import into Gekko.</p>
<p><strong>Train with scikit-learn</strong></p>
<pre class=""lang-py prettyprint-override""><code>import pandas as pd
from gekko.ML import Gekko_NN_SKlearn, CustomMinMaxGekkoScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor

#Training the Data and split it
data = pd.DataFrame(np.array([xl,y_measured]).T,columns=['x','y'])
features = ['x']
label = ['y']

train,test = train_test_split(data,test_size=0.2,shuffle=True)

s = CustomMinMaxGekkoScaler(data,features,label)
ds = s.scaledData()
mma = s.minMaxValues()

trains,tests = train_test_split(ds,test_size=0.2,shuffle=True)
hl= [25,15]
mlp = MLPRegressor(hidden_layer_sizes= hl, activation='relu',
                   solver='adam', batch_size = 32,
                   learning_rate = 'adaptive',learning_rate_init = .0005,
                   tol=1e-6 ,n_iter_no_change = 200,
                   max_iter=12000)
mlp.fit(trains[features],np.ravel(trains[label]))
r2 = mlp.score(tests[features],np.ravel(tests[label]))
print('nnSK r2:',r2)
</code></pre>
<p><strong>Optimize NN Model with Gekko</strong></p>
<p>Now import the <code>scikit-learn</code> NN model into gekko and optimize:</p>
<pre class=""lang-py prettyprint-override""><code>from gekko import GEKKO
m = GEKKO()
x = m.Var(0,lb=0,ub=1)
y = Gekko_NN_SKlearn(mlp,mma,m).predict([x])
m.Obj(y)
m.solve(disp=False)
print('solution:',y.value[0])
print('x:',x.value[0])
print('Gekko Solvetime:',m.options.SOLVETIME,'s')
</code></pre>
<p>This gives a solution that is close to the original solution of <code>0.5</code>.</p>
<pre><code>x: 0.49272077892
Gekko Solvetime: 0.11490000002 s
</code></pre>
<p>This problem can be adapted to your problem with 12 inputs. Additional information on using <code>tensorflow</code>, <code>gpflow</code>, and <code>scikit-learn</code> models with gekko is available in the <a href=""https://gekko.readthedocs.io/en/latest/ml.html"" rel=""nofollow noreferrer"">Gekko documentation</a>.</p>
","2024-04-18 20:04:39","0","Answer"
"78349854","","LMST Model sensitivity - Beginners anti-luck","<p>I have been experimenting with some very basic data for Alberta power markets, and trying to use a LMST model for time series data to try and predict prices. I do get &quot;possible&quot; results from my model, and it does seem to pick up some volatility that we can expect (just from my own market experience).</p>
<p>However, I am looking for a better understanding of maybe some of the pitfalls I am running into.</p>
<pre><code>from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers import Dense
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error,mean_squared_error
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# Load the data
# Load the data

# Load the data
csv_file_path = 'Frankenstein.csv'  # Update with your actual file path
df = pd.read_csv(csv_file_path)

# Convert 'Date/Time' to datetime and extract components if present in your dataset
if 'Date/Time' in df.columns:
    df['Date'] = pd.to_datetime(df['Date/Time'])
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df['Hour'] = df['Date'].dt.hour
    df.drop(['Date/Time', 'Date'], axis=1, inplace=True)

# Assuming 'Price' is the target variable
features = df.drop(['Price'], axis=1)
target = df['Price']

# Normalize features and target
scaler_features = MinMaxScaler()
features_scaled = scaler_features.fit_transform(features)
scaler_target = MinMaxScaler()
target_scaled = scaler_target.fit_transform(target.values.reshape(-1, 1))

# Create sequences function
def create_sequences(features, target, time_steps=100):
    X, y = [], []
    for i in range(len(features) - time_steps):
        X.append(features[i:(i + time_steps)])
        y.append(target[i + time_steps])
    return np.array(X), np.array(y)

# Create sequences using the entire dataset
X, y = create_sequences(features_scaled, target_scaled.flatten())

# Model configuration
input_shape = (X.shape[1], X.shape[2])  # (time_steps, num_features)

# Define the LSTM model
model = Sequential([
    LSTM(units=100, return_sequences=True, input_shape=input_shape),
    Dropout(0.1),
    LSTM(units=100),
    Dropout(0.1),
    Dense(units=100, activation='elu'),
    Dense(1)  # Predicting a single value
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model on the entire dataset
history = model.fit(X, y, epochs=150, batch_size=20, validation_split=0.1)

# Plot training &amp; validation loss values
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper right')
plt.show()

# Save the LSTM model
model_save_path = 'trained_lstm_model.h5'
model.save(model_save_path)
print(f&quot;Model saved to {model_save_path}&quot;)
joblib.dump(scaler_features, 'scaler_features.pkl')
joblib.dump(scaler_target, 'scaler_target.pkl')
</code></pre>
<p>Anyone out there that could give some advice to an absolute beginner? Mostly looking for a better understanding of how I should be setting this up. I have a dataset that is hourly, and is the past three years of historical generation and interchanges. I am looking for ways to make my model more reactive to changes in supply vs price.</p>
","2024-04-18 19:18:18","-1","Question"
"78348824","78348700","","<p>I don't think that you can do it in a simple way by just deploying Matlab code to C++. More correct way would be professional albeit somewhat more difficult:</p>
<ol>
<li>Convert your Matlab model to some intermediate representation, for example, to ONNX. Take a look <a href=""https://www.mathworks.com/help/deeplearning/ref/exportonnxnetwork.html"" rel=""nofollow noreferrer"">here</a>. Other options could be tensorflow or pytorch, but I have no idea how difficult to do such convertion.</li>
<li>Use a relevant runtime, e.g. onnxruntime, tflite or pytorch counterpart, in c++ to run inference</li>
</ol>
<p>OR</p>
<ol start=""2"">
<li>Convert your matlab to tensorflow/pytorch model, then convert it to ONNX, then ONNX to <a href=""https://developer.nvidia.com/tensorrt"" rel=""nofollow noreferrer"">tensorrt</a> and use it's runtime for inference</li>
</ol>
","2024-04-18 15:54:08","1","Answer"
"78348700","","Deploying MATLAB pre-trained neural network code to C++","<p>I need to use Matlab coder package in order to depoloy a Matlab function to C++.
My function trains a netrwork and then uses it to predict some new data.</p>
<p>I saw that the &quot;train&quot; Matlab function can't be deployed, so the network first needs to be saved as a &quot;Mat&quot; file after it is trained inside Matlab environment, and then it needs to be loaded (as a Mat file), and used to predict my data.
There are 2 problems:</p>
<ol>
<li>The  Matlab coder doesn't like the &quot;load&quot; function, which tries to load the pre-trained network.</li>
<li>it doesn't know how to deal with a network of type patternnet, which I trained and used. but I really must use this one since it was very tough to configure it properly for my data.</li>
</ol>
<p>In this case, how do I deploy a pre-trained Matlab neural network of type patternnet to C++ dll, and call the function from there?
Can exporting to ONNX format be a good solution?</p>
<p>Thanks,
Gal</p>
","2024-04-18 15:35:26","0","Question"
"78347399","","I need complete code of Neural Network and gekko to optimize the ouput of neural network","<p>I have never used python, I am new and need your help so that I can learn how to use. I have heat pumps data with 12 variables (with power consumption is one of the variables), I want to train my model in neural network with power consumption as ouput. I want to minimize power consumption by gekko so I need complete code of Neural Network and gekko to optimize the ouput of neural network.</p>
<p>Here is an example problem with one input and one output for demonstration purposes.</p>
<p><a href=""https://i.sstatic.net/Ik59U.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Ik59U.png"" alt=""test problem"" /></a></p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import matplotlib.pyplot as plt

#Source function to generate data
def f(x):
    return np.cos(2*np.pi*x)

#represent noise from a data sample
N = 350
xl = np.linspace(0,1.2,N)
noise = np.random.normal(0,.3,N)
y_measured = f(xl) + noise

plt.figure(figsize=(6,3.5))
plt.plot(xl,f(xl),label='source function')
plt.plot(xl,y_measured,'.',label='measured points')
plt.legend()
plt.show()
</code></pre>
<p>Can a neural network model be fit to the data and then used in an optimization problem?</p>
","2024-04-18 12:22:57","2","Question"
"78344010","78343980","","<p>You need to remove the <code>pd.get_dummies</code> function call. Just directly assign</p>
<pre><code>x = df.drop(['Last Result'], axis=1)
</code></pre>
<p>Calling pd.get_dummies converts the samples into 0/1 data: <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html"" rel=""nofollow noreferrer"">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html</a>.</p>
<p>Can you give more information about the nature of your dataset? This would help in understanding what you are trying to do.</p>
","2024-04-17 22:31:39","0","Answer"
"78343980","","Tensorflow binary crossentropy always predicts the same value","<p>I'm new to the general stack overflow community and especially new to the Tensorflow library (1 week as of now). So I'm positive I am missing something here, just can't quite figure it out myself.</p>
<p>I have done a few practices utilizing Tensorflow's example dataset and a few miscellaneous tutorials. I found myself attempting to apply one of the tutorial's code to my own dataset, this dataset is a csv and the model should return it's prediction of the &quot;Last Result&quot; column. This turned out to be a bit much because I quickly encountered a problem, the &quot;predict&quot; function always predicts identical values for every data entry.</p>
<p>[[0.6335701]
[0.6335701]
...
[0.6335701]
[0.6335701]]</p>
<pre><code>import pandas as pd
from sklearn.model_selection import train_test_split
from keras.models import Sequential, load_model
from keras.layers import Dense
from sklearn.metrics import accuracy_score

df = pd.read_csv('*.csv')
x = pd.get_dummies(df.drop(['Last Result'], axis=1))
y = df['Last Result'].apply(lambda X: 1 if X == 'Registered' else 0)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2)
x_train.head()
print(&quot;x train: \n&quot;, x_train)
y_train.head()
print(&quot;y train: \n&quot;, y_train)

# Below is code to create a new TensorFlow Model. If you need to call a saved model, see 'load model' below.

model = Sequential()
model.add(Dense(units=32, activation='relu', input_dim=len(x_train.columns)))
model.add(Dense(units=32, activation='relu'))
model.add(Dense(units=1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

model.fit(x_train, y_train, epochs=100, batch_size=128)

# model.save('*.keras')

# This is code to recall a previously saved TensorFlow Model

# model = load_model('*.keras')

y_hat = model.predict(x_test)
# y_hat = [0 if val &lt; 0.5 else 1 for val in y_hat]
print(y_hat)

# print(accuracy_score(y_test, y_hat))
</code></pre>
<p>I have tried other suggestions from similar posts to no avail. My best understanding of the issue is that the model is not learning anything and is instead just guessing all one value because one of the expected values is true ~60% of the time, thus the ~.60 predictions.</p>
<p>Any help on the matter would mean a great deal in assisting my understanding of the library. Thanks in advance and thank you for your time.</p>
","2024-04-17 22:14:46","0","Question"
"78337099","78331905","","<p>The issue you're running into in <code>outputs.backward(gradient=identity)</code> is because <code>identity</code> is the wrong shape.</p>
<p><em>usually</em> the argument to gradient should be the same shape as the tensor you are calling <code>backward</code> on. I say usually because technically <code>a.backward(gradient=b)</code> computes <code>b^T @ Jacobian(a)</code> so it depends on the shape of the Jacobian, but <em>usually</em> when you're calling <code>backward</code> on the output of a model you want the same shape.</p>
<p>This is the standard way to call <code>backward</code> on a vector output:</p>
<pre class=""lang-py prettyprint-override""><code>x = torch.randn(32, 4)
model = nn.Linear(4, 2)
y = model(x)

input_grad = torch.ones_like(y) # create vector of ones the same shape as y
y.backward(input_grad)
model.weight.grad

&gt; tensor([[ 1.1243,  2.3456,  2.3656, -8.8384],
          [ 1.1243,  2.3456,  2.3656, -8.8384]])
</code></pre>
<p>If you want to mask parts of your output from the gradient calculation, you can set the relevant <code>input_grad</code> values to <code>0</code>.</p>
<p>For example, this masks the second column of the output tensor:</p>
<pre class=""lang-py prettyprint-override""><code>x = torch.randn(32, 4)
model = nn.Linear(4, 2)
y = model(x)

input_grad = torch.ones_like(y) # create vector of ones the same shape as y
input_grad[:,1] = 0. # mask the second column of the output

y.backward(input_grad)

# masking changes gradient output
model.weight.grad

&gt; tensor([[ 1.1243,  2.3456,  2.3656, -8.8384],
          [ 0.0000,  0.0000,  0.0000,  0.0000]])
</code></pre>
<p>This example only backprops through the first four items in the batch:</p>
<pre class=""lang-py prettyprint-override""><code>x = torch.randn(32, 4)
model = nn.Linear(4, 2)
y = model(x)

input_grad = torch.ones_like(y) # create vector of ones the same shape as y
input_grad[4:] = 0. # only backprop through the first 4 items in the batch

y.backward(input_grad)

# masking changes gradient output
model.weight.grad

&gt; tensor([[-0.2436,  0.8189, -0.1244, -0.4814],
          [-0.2436,  0.8189, -0.1244, -0.4814]])
</code></pre>
<p>To backprop from a specific slice, take the slice and use a ones tensor of the same shape:</p>
<pre class=""lang-py prettyprint-override""><code>x = torch.randn(32, 4)
model = nn.Linear(4, 2)
y = model(x)

y_slice = y[7] # grab specific batch item

input_grad = torch.ones_like(y_slice) # create vector of ones the same shape as y_slice

y_slice.backward(input_grad)

model.weight.grad

&gt; tensor([[-0.1745, -1.1161, -0.8109, -0.6540],
          [-0.1745, -1.1161, -0.8109, -0.6540]])
</code></pre>
<p>Now to your example of computing the gradients of different classes with respect to the input, you can do something like this:</p>
<pre class=""lang-py prettyprint-override""><code># inputs must have `requires_grad=True` if you want to backprop into them
x = torch.randn(32, 4, requires_grad=True)

# model has two output classes
model = nn.Linear(4, 2)

# y is size `(32, 2)` for 32 batch items and 2 classes
y = model(x)

grads = []

for batch_idx in range(x.shape[0]): # iterate over batch items
    for class_idx in range(y.shape[1]): # iterate over classes
        y_slice = y[batch_idx, class_idx] # get specific output value

        # compute grad with retain graph
        # note that the second argument must be `x`, you cannot 
        # pass a slice of `x` because it was not used in the 
        # compute graph that produced `y`
        grad = torch.autograd.grad(y_slice, x, grad_outputs=torch.ones_like(y_slice), retain_graph=True)
        
        # grad output is a tulple of shape `(grad,)
        # grad[0] grabs the actual grad tensor
        # the grad tensor is the same shape of `x`, but due to backproping from y_slice,
        # all items except `batch_idx` are zero.
        # `grad[0][batch_idx]` gets the gradient specifically of item `batch_idx` wrt `class_idx`
        grad = grad[0][batch_idx]
        
        # save tuple of batch_idx, class_idx, grad
        grads.append((batch_idx, class_idx, grad))
</code></pre>
<p>For a fun exercise, run the code above and look at the gradients for each class:</p>
<pre class=""lang-py prettyprint-override""><code>print([i[-1] for i in grads if i[1]==0])
print([i[-1] for i in grads if i[1]==1])
</code></pre>
<p>You'll notice the gradient values are the same for each input item with respect to a given class. Think about why this makes sense.</p>
","2024-04-16 20:03:18","1","Answer"
"78334489","78334434","","<p>The code doesn't include any training process. Neural networks learn by adjusting their weights based on examples and a loss function, which is entirely missing here.</p>
","2024-04-16 12:19:41","1","Answer"
"78334434","","How to train a neural network","<p>I recently came across this neural network and wanted to run it, but as it turned out, it can't solve the equation a+b*c/d correctly, apparently it needs to be trained somehow, but I don't quite understand how to do it. I have only recently started studying neural networks, I would appreciate it if you could help.</p>
<pre><code>import numpy as np

# Define the neural network architecture
class NeuralNetwork:
    def __init__(self):
        self.weights = np.array([0.5, 0.5, 0.5])  # Weights for the input values

    def forward(self, inputs):
        return np.dot(inputs, self.weights)

# Define the equation to evaluate
equation = &quot;2+3*10/9&quot;

# Preprocess the equation
equation = equation.replace(&quot; &quot;, &quot;&quot;)  # Remove any spaces

# Split the equation into operands and operators
operands = []
operators = []

current_operand = &quot;&quot;
for char in equation:
    if char.isdigit() or char == &quot;.&quot;:
        current_operand += char
    else:
        operands.append(float(current_operand))
        current_operand = &quot;&quot;
        operators.append(char)

# Add the last operand
operands.append(float(current_operand))

# Create input array
inputs = np.array(operands[:-1])  # Exclude the last operand (result)

# Evaluate the equation using the neural network
neural_network = NeuralNetwork()
output = neural_network.forward(inputs)

# Apply the operators to the output sequentially
for operator, operand in zip(operators, operands[1:]):
    if operator == &quot;+&quot;:
        output += operand
    elif operator == &quot;-&quot;:
        output -= operand
    elif operator == &quot;*&quot;:
        output *= operand
    elif operator == &quot;/&quot;:
        output /= operand

# Print the result
print(f&quot;Equation: {equation}&quot;)
print(f&quot;Output: {output}&quot;)
</code></pre>
<p>I tried to look for solutions, but nothing came of it.</p>
","2024-04-16 12:08:08","-3","Question"
"78331905","","Efficient way to compute gradients separately w.r.t each class in Pytorch","<p>I am trying to compute the gradients of a Pytorch image classifier model <strong>separately</strong> with respect to each class, for example</p>
<pre><code>outputs = net(inputs)[0] # assuming we only consider the first sample of the batch
grads = [torch.autograd.grad(outputs[i], inputs, retain_graph=True) 
         for i in range(len(outputs))]
</code></pre>
<p>However, in <code>torch.autograd.grad</code> documentation, it states
'''
Note that in nearly all cases setting this option (retain_graph) to True is not needed and often can be worked around in a much more efficient way
'''</p>
<h3></h3>
<p>Bing AI has suggested to use</p>
<pre><code>identity = torch.eye(len(outputs))
outputs.backward(gradient=identity)
</code></pre>
<p>But it obviously does not work</p>
<pre><code>RuntimeError: Mismatch in shape: grad_output[0] has a shape of torch.Size([9, 9]) and outputs has a shape of torch.Size([9]).
</code></pre>
<p>(Here the image classifer has 9 classes)</p>
<h3></h3>
<p>I am therefore wondering whether there is a more efficient way in this case, and if so, how to implement it?</p>
<p>Thanks for any helps!</p>
","2024-04-16 03:01:03","1","Question"
"78330298","78328935","","<p>It sounds like you want a batch dimension for your jacobian, which you can do by making your <code>f</code> work on a single batch, and then wrapping the jacobian in <code>vmap</code>:</p>
<pre class=""lang-py prettyprint-override""><code>def f(x):
    s = jax.numpy.empty(x.shape)
    for u in range(x.shape[0]):
        for v in range(x.shape[1]):
            for c in range(x.shape[2]):
                    s = s.at[u, v, c].set(x[u, v, c] * x[u, v, c])
    return [s, s]

jac = jax.vmap(jax.jacfwd(f, has_aux = True))
</code></pre>
<p>Then the output I get is this:</p>
<pre class=""lang-py prettyprint-override""><code>f_jac, f_val = jac(x.numpy())
print(f_jac.shape) # (3, 2, 2, 1, 2, 2, 1)
print(f_val.shape) # (3, 2, 2, 1)
</code></pre>
","2024-04-15 18:07:38","1","Answer"
"78328935","","Computing the Jacobian of an image: How to reshape the numpy array properly?","<p>I have a batch <code>x</code> of images of the shape <code>[k, width, height, channel_count]</code>. This batch is transformed by a function <code>f</code>. The result has the same shape and I need to compute the divergence (i.e. trace of the Jacobian) of this transformation. (To emphasize this: The transform is working on a batch; it's the output of a neural network and I cannot change it).</p>
<p>I'm using <code>jax.jacfwd</code> to compute the Jacobian. The output has shape <code>[k, width, height, channel_count, k, width, height, channel_count]</code>. That is the first problem, I actually need the Jacobian per image. So the output should have shape <code>[k, width, height, channel_count, width, height, channel_count]</code> instead. I don't know how I can achieve this using <code>jax.jacfwd</code>, since I don't have a per image transform (only the per batch transform).</p>
<p>And even if I have the desired output, how can I compute the trace (per image)? The output should have shape <code>[k]</code>. I think I need to reshape the jacobian output to <code>[k, width * height * channel_count, width * height * channel_count]</code>, but how can I do that?</p>
<p><em>Remark</em>: Note that I also need to know the value of the transform itself. Since there is no <code>jax.val_and_jacfwd</code>, I'm return the actual value as an auxiliary variable, which should be fine. The solution to my question should still allow this.</p>
<p><strong>EDIT</strong>:</p>
<p>Here is a minimal reproducible example:</p>
<pre><code>import jax
import torch

def f(x):
    # s = model.apply(params, x) ### The actual code queries a network model
    # for reproducibility, here is a simple transform:
    s = jax.numpy.empty(x.shape)
    for i in range(x.shape[0]):
        for u in range(x.shape[1]):
            for v in range(x.shape[2]):
                for c in range(x.shape[3]):
                    s = s.at[i, u, v, c].set(x[i, u, v, c] * x[i, u, v, c])
    return [s, s]

jac = jax.jacfwd(f, has_aux = True)

k = 3
width = 2
height = 2
channel_count = 1

x = torch.empty((k, width, height, channel_count))

### The actual loads x from a batch
it = 1
for i in range(x.shape[0]):
    for u in range(x.shape[1]):
        for v in range(x.shape[2]):
            x[i, u, v, 0] = it
            it += 1

f_jac, f_val = jac(x.numpy())
print(f_jac.shape)
</code></pre>
<p>The output is <code>(3, 2, 2, 1, 3, 2, 2, 1)</code>. This is clearly not what I want. I don't want to &quot;differentiate one image with respect to pixels of another&quot;. What I actually want is the &quot;per image&quot; Jacobian. So, the output should be of the shape <code>(3, 2, 2, 1, 2, 2, 1)</code> instead.</p>
<p>But let me stress it again: I still <em>need</em> that <code>f</code> takes a batch of images, since invoking <code>model.apply</code> for each image in the batch separately would be terribly slow.</p>
<p><strong>EDIT 2</strong>:</p>
<p>BTW, if there is a direct way to compute the divergence of <code>f</code> - without the need of computing the whole Jacobian before - I would definitely prefer that.</p>
<p><strong>EDIT 3</strong>:</p>
<p>Regarding only the &quot;per batch Jacobian&quot; thing: Here is an even simpler example:</p>
<pre><code>import jax
import torch

def f(x):
    s = jax.numpy.empty(x.shape)
    s = s.at[0].set(x[0] * x[0])
    s = s.at[1].set(x[1] * x[1])
    s = s.at[2].set(x[2] * x[2])
    return [s, s]

jac = jax.jacfwd(f, has_aux = True)

x = torch.empty(3)
x[0] = 1
x[1] = 2
x[2] = 3

f_jac, f_val = jac(x.numpy())
print(f_jac.shape)
print(f_jac)
print(f_val)
</code></pre>
<p>The goal would be that <code>f_jac</code> has shape <code>[3, 1, 1]</code>. (The Jacobian of a one-dimensional function is simply a scalar).</p>
","2024-04-15 13:58:44","2","Question"
"78301534","78301477","","<p>The pruning utility in Pytorch acts as a masking wrapper on the layer that receives the pruning. This means you still have access to the original model weights and the network size remains unchanged, if not larger because of the initialization of a mask for each pruned tensor.</p>
<p>If you look at the documentation page for <a href=""https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.global_unstructured.html#torch.nn.utils.prune.global_unstructured"" rel=""nofollow noreferrer""><code>prune.global_unstructured</code></a>:</p>
<blockquote>
<p>Modifies modules in place by:</p>
<ul>
<li><p>adding a named buffer called <code>name+'_mask'</code> corresponding to the binary
mask applied to the parameter name by the pruning method.</p>
</li>
<li><p>replacing the parameter name by its pruned version, while the original
(unpruned) parameter is stored in a new parameter named <code>name+'_orig'</code>.</p>
</li>
</ul>
</blockquote>
<p>Here is a minimal example to show that the unpruned weights are still accessible:</p>
<pre><code>net = nn.Sequential(OrderedDict(
    f1=nn.Linear(10, 5),
    f2=nn.Linear(5, 1)))

pruned = ((net.f1, 'weight'),)
prune.global_unstructured(pruned, prune.L1Unstructured, amount=0.8)
</code></pre>
<p>Then you can access the pruned weights:</p>
<pre><code>&gt;&gt;&gt; net.f1.weight
tensor([[0.0000, 0.0000, 0.0000, -0.0000, 0.0000],
        [0.0000, 0.3599, 0.0000, -0.0000, 0.4034]])
</code></pre>
<p>The original unpruned weight:</p>
<pre><code>&gt;&gt;&gt; net.f1.weight_orig
Parameter containing:
tensor([[ 0.1312,  0.1105,  0.0910, -0.2650,  0.3439],
        [ 0.0412,  0.3599,  0.2040, -0.2672,  0.4034]])
</code></pre>
<p>And the pruning mask:</p>
<pre><code>&gt;&gt;&gt; net.f1.weight_mask
tensor([[0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 1.]])
</code></pre>
","2024-04-09 23:38:24","0","Answer"
"78301477","","Pruned model size is the same of non-pruned model [PyTorch]","<p>I'm trying to implement model pruning on PyTorch with a ResNet18. Given an instance of ResNet18, I run the following code to load a pre-trained model, prune it and save the pruned model:</p>
<pre><code>def random_unstructured_pruning(pruning_rate: float, device, log_file):
    trained_model=retrieve_file(folder=&quot;./models&quot;, file_name='trained_model.pth')
    model=ResNet18(num_classes=10, input_channels=1).to(device)
    model.load_state_dict(torch.load(trained_model))
    
    modules_list=filter(lambda x: isinstance(x[1], (nn.Conv2d, nn.Linear, nn.BatchNorm2d)), model.named_modules())
    modules_list = map(lambda x: (x[1], 'weight'), modules_list)
    modules_list=tuple(modules_list)
 
  
    prune.global_unstructured(modules_list, pruning_method=prune.L1Unstructured, amount=0.8)
    for module in modules_list:
        prune.remove(module[0], module[1])
        
        
        
    pruning_rate_str= &quot;{:02d}&quot;.format(int(pruning_rate * 10))
    path=f&quot;{model_saving_path}pruned_{pruning_rate_str}.pth&quot;
    # 
    torch.save(model.state_dict(), f&quot;{path}&quot;)
</code></pre>
<p>In the end of the above function, the .pth file has the same dimension of the file that I load at the beginning while I expect it to be smaller since I'm pruning 80% of the weights.</p>
<p>Can somebody explain me why does it happen? What am I wrong?
Thank you!!</p>
<p>I think that the problem is in the saving part of the function, it seems that I'm saving always the same model that I re-load at the beginning and the pruning is not effective.</p>
","2024-04-09 23:14:30","0","Question"
"78300416","78300315","","<p>Standard dropout samples a random mask with every forward pass. This is a basic example:</p>
<pre class=""lang-py prettyprint-override""><code>class Dropout(nn.Module):
    def __init__(self, p):
        super().__init__()
        self.p = p
        
    def get_mask(self, x):
        mask = torch.rand(*x.shape)&lt;=self.p
        return mask
        
    def forward(self, x):
        if self.training:
            mask = self.get_mask(x)
            x = x * mask
        return x
</code></pre>
<p>If you want a custom dropout, you can implement your own logic in <code>get_mask</code></p>
","2024-04-09 18:20:46","1","Answer"
"78300315","","Custom dropout in PyTorch?","<p>I’m looking to implement a custom dropout in PyTorch — in the sense that I’d like to pass a mask of some sort, and have the corresponding neurons be “dropped out”, rather than dropping out random neurons with a specific probability. Something like:</p>
<pre><code>Nn.Dropout(inputs, mask = [0, 1, 0, …]
</code></pre>
<p>I can’t seem to find anything in pytorch’s documentation or forums, so any and all help would be appreciated.</p>
","2024-04-09 17:57:32","-1","Question"
"78299001","78298942","","<p>You need to transfer your model and data to GPU to benefit from GPU computation. First you should check that you indeed have access to a CUDA device.</p>
<pre><code>device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

model.train(True)
model.to(device) # Transfer model to device
for i in range(n_train):
    start = time.time()
    for iter in range(num_of_epochs):
        train_loss = []
        for x, f, y in train_dataloader:
            # Zero your gradients for every batch!
            optimizer.zero_grad()

            # Transfer data to device
            x, f = x.to(device), f.to(device)

            # Make predictions for this batch
            out = model(x, f)
</code></pre>
","2024-04-09 13:59:12","-1","Answer"
"78298942","","With little networks with few parameters pytorch seems to be very slow in training speed respect to tensorflow. Am i missing something?","<p>I am currently working with small structured networks and even if Pytorch seems to be the obvious choice due to its high flexibility, it still drops a lot in terms of training speed compared to TensorFlow.
As I could see after 10 training sessions, PyTorch seems to double in training time. Am I doing something wrong? Is there a way to improve the computational time of Pytorch?</p>
<p>I've made a Google Colab to reproduce the same network in both PyTorch/TensorFlow to compare the two models.</p>
<pre><code>import torch.nn as nn
import torch
import time
from torch.utils.data import DataLoader,TensorDataset
import numpy as np

## Parameters
learning_rate = 0.0005
num_of_epochs = 300
batch_size = 128

## Create Data
xx=torch.arange(40*640*60, dtype=torch.float32).view(640*60, 40)
ff=torch.arange(1*640*60, dtype=torch.float32).view(640*60, 1)
out=torch.arange(1*640*60, dtype=torch.float32).view(640*60, 1)

## Define the model
class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.lin = nn.Linear(40, 1, False)
        self.par = nn.Parameter(torch.Tensor(1))

    def forward(self, x, f):
        return torch.add(self.lin(x),self.par*f)

model = Model()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
loss_fun = torch.nn.MSELoss()

dataset = TensorDataset(xx,ff,out)
train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
</code></pre>
<hr />
<pre><code>%%time
## Training
model.train(True)
for i in range(n_train):
    start = time.time()
    for iter in range(num_of_epochs):
        train_loss = []
        for x, f, y in train_dataloader:
            # Zero your gradients for every batch!
            optimizer.zero_grad()

            # Make predictions for this batch
            out = model(x, f)

            # Compute the loss and its gradients
            loss = loss_fun(out, y)
            loss.backward()

            # Adjust learning weights
            optimizer.step()
            train_loss.append(loss.item())
        train_loss = np.mean(train_loss)
    end = time.time()
    exe_time['pytorch'].append(end-start)
</code></pre>
<p>Full code can be found <a href=""https://colab.research.google.com/drive/1L1x6pv-duokURbRhxGjf8m18B-rgwqkO?usp=sharing"" rel=""nofollow noreferrer"">here</a></p>
","2024-04-09 13:50:05","1","Question"
"78279650","78265092","","<p>If I understand correctly the error is stating you are missing a step in your code.
When you are initiating:</p>
<pre class=""lang-py prettyprint-override""><code>m = NeuralProphet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,  
    quantiles=quantile_list,
    n_lags=30,
    epochs=10,
    n_forecasts=30,
)

</code></pre>
<p>You are setting <code>n_forecasts=30</code>. Doing so triggers the following if statement:</p>
<pre class=""lang-py prettyprint-override""><code>if (self.highlight_forecast_step_n) is None and (
    self.n_forecasts &gt; 1 or self.n_lags &gt; 0
</code></pre>
<p>You failed to set <code>highlight_forecast_step_n</code> and have set <code>n_forecasts=30</code>. Thus the if statement is <code>True</code> because <code>highlight_forecast_step_n</code> equals <code>None</code> and <code>n_forecasts</code> is higher then <code>1</code>. T</p>
<p>To fix this you need to set the <code>highlight_forecast_step_n</code> attribute of your model. This can be done by using the class function <code>highlight_nth_step_ahead_of_each_forecast</code>.</p>
<p>Something like this will work:</p>
<pre class=""lang-py prettyprint-override""><code>m.highlight_nth_step_ahead_of_each_forecast(step_number=10)

</code></pre>
<p>Reference: <a href=""https://neuralprophet.com/code/forecaster.html#neuralprophet.forecaster.NeuralProphet.highlight_nth_step_ahead_of_each_forecast"" rel=""nofollow noreferrer"">highlight_nth_step_ahead_of_each_forecast</a></p>
","2024-04-05 11:34:26","1","Answer"
"78277414","78276910","","<p>The tensor dtype depends on what you intend to do with it.</p>
<p>&quot;number crunching&quot; layers like <code>nn.Linear</code>, <code>nn.Conv2d</code>, etc expect a <code>torch.float32</code> input, or <code>torch.float16</code> for half precision training.</p>
<p>&quot;number lookup&quot; layers like <code>nn.Embedding</code> expect the input to be <code>torch.int</code> or <code>torch.long</code>.</p>
<p>So long as the dtype is compatible with the layer that will be processing it, you're good.</p>
","2024-04-05 02:00:05","0","Answer"
"78277035","78276910","","<p>Typically you would use a long tensor for one-hot-encodings.
<br>Evidence of that can be seen with <a href=""https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html"" rel=""nofollow noreferrer""><code>F.one_hot</code></a> which returns a <code>LongTensor</code>.</p>
","2024-04-04 23:10:04","0","Answer"
"78276910","","Which dtype for one-hot encoded features when converting them into pytorch tensors?","<p>The title explains most of my problem. I have a dataset with both categorical and quantitative features. My question is if it's best to assign the type <code>torch.float32</code> to the one-hot encoded features, which means that I can create one tensor for both the quantitative and the categorical (OH encoded) features, or if I should use <code>torch.bool</code> for the one-hot features, since they are all either 1 or 0.</p>
<p>If I were to use <code>torch.bool</code> it would complicate the creation of the model since I would need to create 2 &quot;pathways&quot;. I'm new to this so I don't know if using <code>torch.float32</code> would cause any issues or not.</p>
","2024-04-04 22:27:43","0","Question"
"78272189","78271561","","<p>It must probably change of dtype. An example would be initially it was <code>tf.float32</code>  and when you initialised it to zero, it became <code>tf.float64</code>. You can check whether or not if the dtype of model changed.</p>
","2024-04-04 06:52:04","0","Answer"
"78271561","","Neural Network Model Weight Matrix","<p>I was trying to make the all values in my trained neural network model to zero's.<br />
The initial model file size nearly 330 MB. But when I modified the values of weight matrix to zero's it becomes double size model. nearly 660MB.</p>
<p>What could be the reason for this. I check with the weight matrix shape. it doesn't changed. same for both</p>
<pre class=""lang-py prettyprint-override""><code>model_transmitter_main0 = keras.models.load_model(f&quot;/content/drive/MyDrive/auto_encoder/models/video{the_video}/gop{the_gop}/model_transmitter_main0.h5&quot;) 

weights1 = model_transmitter_main0.get_weights() 

weights1[0] = np.zeros_like(weights1[0]) 

weights1[1] = np.zeros_like(weights1[1]) 

weights1[2] = np.zeros_like(weights1[2]) 

weights1[3] = np.zeros_like(weights1[3]) 

model_transmitter_main0.set_weights(weights1) 

# Save the modified model 

model_transmitter_main0.save(&quot;/content/drive/MyDrive/auto_encoder/existing.h5&quot;)
</code></pre>
","2024-04-04 03:47:55","0","Question"
"78265092","","Error when plotting confidence intervals with NeuralProphet","<p>I'm following the tutorial on quantile regression in <a href=""https://neuralprophet.com/tutorials/tutorial08.html"" rel=""nofollow noreferrer"">NeuralProphet</a>, but there is an issue when plotting the forecast.</p>
<pre><code>confidence_lv = 0.9
quantile_list = [round(((1 - confidence_lv) / 2), 2), round((confidence_lv + (1 - confidence_lv) / 2), 2)]


m = NeuralProphet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,  
    quantiles=quantile_list,
    n_lags=30,
    epochs=10,
    n_forecasts=30,
)

m.set_plotting_backend('plotly')
metrics = m.fit(df)

df_future = m.make_future_dataframe(
    df, 
    n_historic_predictions=True,   
    periods=30, 
)

forecast = m.predict(df_future)

m.plot(forecast, forecast_in_focus=30)
</code></pre>
<p>I'm getting the error below. I'm not finding the parameter they mentioned anywhere in these functions above (I'm using version <code>0.6.2</code>).</p>
<pre><code>in NeuralProphet.plot(self, fcst, df_name, ax, xlabel, ylabel, figsize, forecast_in_focus, plotting_backend)
   1886 if len(self.config_train.quantiles) &gt; 1:
   1887     if (self.highlight_forecast_step_n) is None and (
   1888         self.n_forecasts &gt; 1 or self.n_lags &gt; 0
   1889     ):  # rather query if n_forecasts &gt;1 than n_lags&gt;1
-&gt; 1890         raise ValueError(
   1891             &quot;Please specify step_number using the highlight_nth_step_ahead_of_each_forecast function&quot;
   1892             &quot; for quantiles plotting when auto-regression enabled.&quot;
   1893         )
   1894     if (self.highlight_forecast_step_n or forecast_in_focus) is not None and self.n_lags == 0:
   1895         log.warning(&quot;highlight_forecast_step_n is ignored since auto-regression not enabled.&quot;)

ValueError: Please specify step_number using the highlight_nth_step_ahead_of_each_forecast function for quantiles plotting when auto-regression enabled.
</code></pre>
","2024-04-03 03:44:15","1","Question"
"78263764","78263712","","<p>I believe that your error is coming from your definition of &quot;Dense&quot;: would you be able to show how to you imported that layer definition?</p>
<p>The below code (which is the same as your initial code, but with the use of tf.keras.layers.Dense as opposed to just Dense) seems to work as expected.</p>
<pre><code>import tensorflow as tf

model = tf.keras.Sequential()

model.add(tf.keras.layers.Dense(10, input_shape=(1,)))

tf.keras.utils.plot_model(model=model, show_shapes=True)
</code></pre>
","2024-04-02 19:56:21","0","Answer"
"78263712","","Why does my plot_model() look like this? (Tensorflow, Keras)","<p>I made a very simple model, so I could practise using the plot_model() function, but for some reason my plot model looks like this? <a href=""https://i.sstatic.net/ADymM.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<pre><code>import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

'''model.compile(loss = tf.keras.losses.mae,
              optimizer = tf.keras.optimizers.SGD(),
              metrics=['mae'])
model.fit(X_train,y_train, epochs=100, verbose=0)
model.summary'''
tf.keras.utils.plot_model(model=model,to_file='model3.png',show_shapes=True)

</code></pre>
<p>compared to:
<a href=""https://i.sstatic.net/wdO1o.png"" rel=""nofollow noreferrer"">enter image description here</a>
The other person's code: <a href=""https://i.sstatic.net/8BzeF.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
","2024-04-02 19:42:49","1","Question"
"78251371","78242743","","<p>Try this:</p>
<pre><code>self.flatten = nn.Flatten()
self.linear1 = nn.Linear(in_features=hidden_units*7*7, out_features=output_shape))

def forward(self, x:torch.Tensor): 
x = self.block_1(x)
x = self.block_2(x)
x = self.flatten(x)
x = self.linear1(x)
return x
</code></pre>
<p>If you don't want to add flatten layer to your model, you can simply do it in forward function:</p>
<pre><code>def forward(self, x:torch.Tensor):
x = self.block_1(x)
x = self.block_2(x)
x = x.view(x.size(0), -1)
x = self.linear1(x)
return x
</code></pre>
","2024-03-31 12:55:27","0","Answer"
"78247533","78237188","","<p>After asking the same thing on the tabnet guthub repo, I got the answer :</p>
<p>Custom loss is supported as a function in {tabnet}</p>
<p>The good news is that you have an example in here : <a href=""https://github.com/mlverse/tabnet/blob/3d3ce9925cc12a13adf9e7b2c2c9ebd57c7f3d5e/tests/testthat/test-hardhat_parameters.R#L211-L229"" rel=""nofollow noreferrer"">https://github.com/mlverse/tabnet/blob/3d3ce9925cc12a13adf9e7b2c2c9ebd57c7f3d5e/tests/testthat/test-hardhat_parameters.R#L211-L229</a></p>
<p>The bad news is that you must rely on {torch} loss, and you can not use {yardstick} metric as a loss. The reason is that the function must be differentiable to drive the gradient in the right direction...</p>
<p>There is plenty of loss functions in {torch}, all ending with _loss. If one is missing, you can also build yours as a torch module like entmax and sparsemax in <a href=""https://github.com/mlverse/tabnet/blob/main/R/sparsemax.R"" rel=""nofollow noreferrer"">https://github.com/mlverse/tabnet/blob/main/R/sparsemax.R</a></p>
<p>Hope it helps,</p>
","2024-03-30 10:11:08","0","Answer"
"78246141","78244620","","<p>This happens because you are passing a scalar argument to a pmapped function. For example:</p>
<pre class=""lang-py prettyprint-override""><code>import jax
func = lambda x: x ** 2
pfunc = jax.pmap(func)

pfunc(1.0)
# ValueError: pmap was requested to map its argument along axis 0, which implies
# that its rank should be at least 1, but is only 0 (its shape is ())
</code></pre>
<p>If you want to operate on a scalar, you should use the function without wrapping it in <code>pmap</code>:</p>
<pre class=""lang-py prettyprint-override""><code>func(1.0)
# 1.0
</code></pre>
<p>Alternatively, if you want to use <code>pmap</code>, you should operate on an array whose leading dimension matches the number of devices:</p>
<pre class=""lang-py prettyprint-override""><code>num_devices = len(jax.devices())
x = jax.numpy.arange(num_devices)
pfunc(x)
# Array([ 0,  1,  4,  9, 16, 25, 36, 49], dtype=int32)
</code></pre>
","2024-03-29 22:12:31","1","Answer"
"78245686","78245489","","<p>A 1d conv with a kernel size of 1 accomplishes this:</p>
<pre class=""lang-py prettyprint-override""><code>B = 10
F = 20
F_desired = 17
D = 64

x = torch.randn(B, F, D)

reduction1 = nn.Conv1d(F, F_desired, 1)
x1 = reduction1(x)
print(x1.shape)
&gt; torch.Size([10, 17, 64])
</code></pre>
<p>You could also do a linear layer, provided you permute the axes:</p>
<pre class=""lang-py prettyprint-override""><code>reduction2 = nn.Linear(F, F_desired)
x2 = reduction2(x.permute(0,2,1)).permute(0,2,1)
print(x2.shape)
&gt; torch.Size([10, 17, 64])
</code></pre>
<p>Note that if your convolution kernel is size <code>1</code>, these are actually equivalent operations</p>
<pre class=""lang-py prettyprint-override""><code>reduction2.weight.data = reduction1.weight.squeeze().data
reduction2.bias.data = reduction1.bias.data

x2 = reduction2(x.permute(0,2,1)).permute(0,2,1)
print(torch.allclose(x1,x2, atol=1e-6))
&gt; True
</code></pre>
","2024-03-29 19:54:39","0","Answer"
"78245489","","Mapping a higher dimension tensor into a lower one: (B, F, D) -> (B, F-n, D) in PyTorch","
<p>I have a tensor of embeddings that I want to reduce into a smaller number of embeddings. I am working in a batched environment. The tensor shape is B, F, D where B is the number of items in batch, F is the number of embeddings and D is the dimension. I want to learn a reduction to B, F-n, D.</p>
<p>e.g.</p>
<pre class=""lang-py prettyprint-override""><code>import torch

B = 10
F = 20
F_desired = 17
D = 64

x = torch.randn(B, F, D)
# torch.Size([50, 20, 64])

reduction = torch.?

y = reduction(x)

print(y.shape)
# torch.Size([50, 20, 64])

</code></pre>
<p>I think a 1x1 convolution would make sense here, but not sure how to confirm it was actually doing what I expected? So would love to hear if it's the right approach / if there are better approaches</p>
<pre class=""lang-py prettyprint-override""><code>reduction = torch.nn.Conv1d(
    in_channels=F,
    out_channels=F_desired,
    kernel_size=1,
)
</code></pre>
","2024-03-29 19:06:03","0","Question"
"78244620","","jax: How do we solve the error: pmap was requested to map its argument along axis 0, which implies that its rank should be at least 1, but is only 0?","<p>I'm trying to run this <a href=""https://colab.research.google.com/drive/1SeXMpILhkJPjXUaesvzEhc3Ke6Zl_zxJ?usp=sharing#scrollTo=8PPsLx4dGCGa"" rel=""nofollow noreferrer"">simple introduction to score-based generative modeling</a>. The code is using <code>flax.optim</code>, which seems to be moved to <code>optax</code> meanwhile (<a href=""https://flax.readthedocs.io/en/latest/guides/converting_and_upgrading/optax_update_guide.html"" rel=""nofollow noreferrer"">https://flax.readthedocs.io/en/latest/guides/converting_and_upgrading/optax_update_guide.html</a>).</p>
<p>I've made a <a href=""https://colab.research.google.com/drive/13XoMxAOkfYoFpK9-CQoh0jwk2QsNcrin#scrollTo=21v75FhSkfCq"" rel=""nofollow noreferrer"">copy of the colab code</a> with the changes I think needed to be made (I'm only unsure how I need to replace <code>optimizer = flax.jax_utils.replicate(optimizer)</code>).</p>
<p>Now, in the <a href=""https://colab.research.google.com/drive/13XoMxAOkfYoFpK9-CQoh0jwk2QsNcrin#scrollTo=8PPsLx4dGCGa&amp;line=1&amp;uniqifier=1"" rel=""nofollow noreferrer"">training section</a>, I get the error</p>
<blockquote>
<p>pmap was requested to map its argument along axis 0, which implies that its rank should be at least 1, but is only 0 (its shape is ())</p>
</blockquote>
<p>at the line <code>loss, params, opt_state = train_step_fn(step_rng, x, params, opt_state)</code>. This obviously comes from the <code>return jax.pmap(step_fn, axis_name='device')</code> in the &quot;Define the loss function&quot; section.</p>
<p>How can I fix this error? I've googled it, but have no idea what's going wrong here.</p>
","2024-03-29 15:34:59","1","Question"
"78243131","78242743","","<p>You can define your linear layer separately from the classifier as a standalone layer:</p>
<pre><code>self.linear = nn.Linear(in_features=hidden_units*7*7, 
                        out_features=output_shape))
</code></pre>
<p>Then in the forward function, the equivalent implementation would be:</p>
<pre><code>def forward(self, x: torch.Tensor):
    x = self.block_1(x)
    x = self.block_2(x)
    x = x.flatten(1)
    x = self.linear(x)
    return x
</code></pre>
","2024-03-29 10:04:57","0","Answer"
"78242743","","how to convert nn.Sequential code to nn.Linear","<p>I am new to deep learning, and I came across this while learning.</p>
<p>Is there a way to convert the nn.Sequential() functions here to nn.Linear(), because of how flexible it is to use nn.Linear() functions.</p>
<pre><code>class FashionMNISTModelV2(nn.Module):
def __init__(self, input_shape: int, hidden_units: int, output_shape: int):
    super().__init__()
    self.block_1 = nn.Sequential(
        nn.Conv2d(in_channels=input_shape, 
                  out_channels=hidden_units, 
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units, 
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2)
    )
    self.block_2 = nn.Sequential(
        nn.Conv2d(hidden_units, hidden_units, 3, padding=1),
        nn.ReLU(),
        nn.Conv2d(hidden_units, hidden_units, 3, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2)
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=hidden_units*7*7, 
                  out_features=output_shape)
    )

def forward(self, x: torch.Tensor):
    x = self.block_1(x)
    x = self.block_2(x)
    x = self.classifier(x)
    return x
</code></pre>
","2024-03-29 08:33:19","0","Question"
"78237188","","R package tabnet, how to change the loss to balanced accuracy?","<p>In the <a href=""https://cran.r-project.org/web/packages/tabnet/index.html"" rel=""nofollow noreferrer"">tabnet package</a>, I want the loss to be the balanced accuracy for multi-class classification. Similar to <code>yardstick::bal_accuracy_vec()</code>. How can I do that?</p>
<p>I do know how to compute a balanced accuracy but I don't know how to create a function that would fit in the tabnet framework. So basically, any help in how to customize the loss in tabnet is welcome.</p>
<p>Example:</p>
<pre><code>library(tabnet)
library(recipes)

data(&quot;attrition&quot;, package = &quot;modeldata&quot;)
ids &lt;- sample(nrow(attrition), 256)

rec &lt;-
  recipe(Attrition + JobSatisfaction ~ ., data = attrition[ids, ]) %&gt;%
  step_normalize(all_numeric(),-all_outcomes())

attrition_fit &lt;-
  tabnet_fit(rec,
             data = attrition[ids, ],
             epochs = 2,
             valid_split = 0.2,
             loss = yardstick::bal_accuracy_vec
             )
</code></pre>
<p>gives the error:<code>Error in x != y :  comparison (2) is possible only for atomic and list types</code>.</p>
<p>Thanks for your help.</p>
","2024-03-28 09:42:56","0","Question"
"78221053","78220979","","<p>You want your scripted function to contain only model operations - ie no preprocessing, i/o, device transfer, etc.</p>
<p>Dataloading/preprocessing logic should be separate from model logic. For example, tokenization should not occur within the model code.</p>
<p>Once logic is separated, additional functions can be added by implementing them in the <code>module</code> class and adding the <code>@torch.jit.export</code>. By default, torch scripting will compile the <code>forward</code> method and any other methods that include the <code>@torch.jit.export</code> decorator. See this example from the pytorch <a href=""https://pytorch.org/docs/stable/jit.html#torch.jit.export"" rel=""nofollow noreferrer"">docs</a></p>
<pre class=""lang-py prettyprint-override""><code>import torch
import torch.nn as nn

class MyModule(nn.Module):
    def implicitly_compiled_method(self, x):
        return x + 99

    # `forward` is implicitly decorated with `@torch.jit.export`,
    # so adding it here would have no effect
    def forward(self, x):
        return x + 10

    @torch.jit.export
    def another_forward(self, x):
        # When the compiler sees this call, it will compile
        # `implicitly_compiled_method`
        return self.implicitly_compiled_method(x)

    def unused_method(self, x):
        return x - 20

# `m` will contain compiled methods:
#     `forward`
#     `another_forward`
#     `implicitly_compiled_method`
# `unused_method` will not be compiled since it was not called from
# any compiled methods and wasn't decorated with `@torch.jit.export`
m = torch.jit.script(MyModule())
</code></pre>
","2024-03-25 18:27:12","0","Answer"
"78220979","","How to add Attribute and use after building the model?","<p>I’ve built a neural network model and I’d like to incorporate custom functions, encodeImage and encodeText , for pre-processing data. Ideally, I want these functions to be callable both during model definition and after training (post-build). However, including them directly within the model definition restricts their use to before Just-In-Time (JIT) compilation. Calls made after model building result in the functions being undefined</p>
<pre><code># The Custom Attributes I wan to add in the Model
    def encode_image(self, image):
      return self.visual(image.type(self.dtype))

    def encode_text(self, text):
      x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]

      x = x + self.positional_embedding.type(self.dtype)
      x = x.permute(1, 0, 2)  # NLD -&gt; LND
      x = self.transformer(x)
      x = x.permute(1, 0, 2)  # LND -&gt; NLD
      x = self.ln_final(x).type(self.dtype)

      # x.shape = [batch_size, n_ctx, transformer.width]
      # take features from the eot embedding (eot_token is the highest number in each sequence)
      x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection

      return x
  # Image Classifier Neural Network
  class ImageClassifier(nn.Module):
      def __init__(self, n_qubits, n_layers, encode_image):
          super().__init__()
          self.model = nn.Sequential(
              qlayer,
              ClassicalLayer(2)
          )
  
      def forward(self, x):
          result = self.model(x)
          return result
</code></pre>
","2024-03-25 18:07:50","0","Question"
"78215686","78209363","","<p>Your model maps the input of shape <code>(4, 6)</code> to <code>(4, 12)</code> in the first linear layer, then to <code>(4, 3)</code> in the second layer.</p>
<p>If you want the output to be of shape <code>(4, 3, 3)</code>, you need to have the second layer output <code>(4, 3*3)</code>, then reshape.</p>
<pre class=""lang-py prettyprint-override""><code>n_problems = 3
classes_per_problem = 3

model = nn.Linear(6, n_problems*classes_per_problem)

x = torch.randn(4, 6)
x1 = model(x)
bs, _ = x1.shape
x1 = x1.reshape(bs, classes_per_problem, n_problems)

y = torch.randint(high=classes_per_problem, size=(bs, n_problems))
loss_function = nn.CrossEntropyLoss()

loss = loss_function(x1, y)
</code></pre>
","2024-03-24 18:39:21","1","Answer"
"78215320","78203005","","<p>I encountered something similiar and found this explanation on Github
<a href=""https://github.com/DeepLabCut/DeepLabCut/issues/2465"" rel=""nofollow noreferrer"">https://github.com/DeepLabCut/DeepLabCut/issues/2465</a></p>
<blockquote>
<p>I think the reason that Colab now uses 1% of the GPU is because Google
made an update to CUDA 12.2 recently. Tensorflow-2.10.0 automatically
installs on Colab, so it needs CUDA 11.2 and cuDNN 8.1 (according to
the Linux GPU section here). A temporary solution is to connect to a
GPU runtime -&gt; click tools -&gt; command palette -&gt; type in and select
'use fallback runtime'. But this will only work until early Jan
unfortunately.</p>
</blockquote>
<p>The ulitmate solution that worked for those in the thread is  to run</p>
<blockquote>
<ul>
<li>!apt update &amp;&amp; apt install cuda-11-8</li>
</ul>
</blockquote>
<p>before running other code in Colab.</p>
","2024-03-24 16:45:19","0","Answer"
"78215292","78212753","","<p>This looks like a <a href=""https://docs.sympy.org/latest/explanation/gotchas.html"" rel=""nofollow noreferrer"">SymPy gotcha</a> - when you write this, <code>d</code> is not longer a simple <code>Symbol</code> and the name is given to the expression of <code>e</code> and <code>c</code> (you'll get the same issue if you try to use <code>e</code>)</p>
<pre class=""lang-py prettyprint-override""><code>d = e + c  # d Symbol lost and name re-used
L = d * f
</code></pre>
<p>Instead use <code>Eq()</code> or subtract 'em and give that new result a different name</p>
<pre class=""lang-py prettyprint-override""><code>e_ = a  * b
d_ = e_ + c
L  = d_ * f

sublist = {a: 2.0, b:-3.0, c:10.0, f:-2.0}
dLda = sp.diff(L, a)
dLdb = sp.diff(L, b)
dLdf = sp.diff(L, f)
dLdc = sp.diff(L, c)

dddc = sp.diff(d_, c)
</code></pre>
","2024-03-24 16:37:12","0","Answer"
"78212753","","SymPy - Can't calculate derivative wrt expression, is there an alternative for intermediate expressions?","<p>I am going through Andrej Karpathy's video &quot;The spelled-out intro to neural networks and backpropagation: building micrograd&quot;, and in the <a href=""https://www.youtube.com/watch?v=VMj-3S1tku0&amp;t=1930s"" rel=""nofollow noreferrer"">&quot;manual backpropagation example #1: simple expression&quot; chapter</a> he builds up an example expression using his demo library and then manually steps through a back propagation through that expression. The <a href=""https://github.com/karpathy/micrograd/tree/master"" rel=""nofollow noreferrer"">'micrograd' library</a> that he's building in the video stores expressions as a graph and is also an auto differentiation engine and stores the intermediate gradient at each node in the graph so it can be easily available for applying the chain rule.</p>
<p>I thought it would be fun to have a SymPy version of his example to see not just the numeric gradient at each step but also the symbolic derivative at each node of the graph, and to start out with I just wanted to do the basics in SymPy, but I'm not sure how I can get the derivatives of some of the intermediate expressions using SymPy.diff()</p>
<p>Here's the code:</p>
<pre class=""lang-py prettyprint-override""><code>(a, b, c, d, e, f, L) = sp.symbols('a b c d e f L')
e = a * b
d = e + c
L = d * f

sublist = {a: 2.0, b:-3.0, c:10.0, f:-2.0}
dLda = sp.diff(L, a)
dLdb = sp.diff(L, b)
dLdf = sp.diff(L, f)
dLdc = sp.diff(L, c)

dddc = sp.diff(d, c)

print(L)
print(L.subs(sublist))
print(dLdc)
print(dLdf)
print(dddc)
#dLdc = dLdd * dddc
dLdd = sp.diff(L, d)  # should get 'f' 

</code></pre>
<p>And I get:</p>
<pre><code>f*(a*b + c)
-8.00000000000000
f
a*b + c
1

ValueError                                Traceback (most recent call last)
Cell In[48], line 20
     18 print(dddc)
     19 #dLdc = dLdd * dddc
---&gt; 20 dLdd = sp.diff(L, d)  # should print 'f' 
&lt;...&gt;
ValueError: 
Can't calculate derivative wrt a*b + c.
</code></pre>
<p>I get that normally this wouldn't make sense because these intermediate &quot;nodes&quot; like d aren't places where in an actual network there would be any adjustments to values (ie if this were an actual neural network I would only be 'nudging' a,b,f, and c), but if you are stepping through each node to keep track of the derivative thus far I don't think trying to have dLdd as a thing is unreasonable, and it'd be nice to be able to have SymPy have that. Again just to reemphasize I'm not planning on trying to use SymPy to actually do these calculations, it's just for illustrating what's happening under the covers.</p>
<p>I've tried running this a couple of different ways using <code>with sp.evaluate(False):</code> but I didn't have any luck, but maybe I'm missing something and there's some way to actually keep 'd' and 'e' around without SymPy simplifying them away.</p>
","2024-03-23 22:35:54","0","Question"
"78212483","78211309","","<p>Your <code>nn.Sequential</code> setup doesn't make sense. <code>nn.Sequential</code> runs the model modules in the order listed. Yours:</p>
<pre class=""lang-py prettyprint-override""><code>        self.hidden_layer = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_size),
            nn.Linear(input_size, hidden_size),
            nn.Linear(input_size, hidden_size),

            nn.ReLU()
        )
</code></pre>
<p>Has linear layers back to back, which is redundant since the composition of two linear layers is still a linear layer. Your sizes don't line up. The first layer maps an input of size <code>input_size</code> to <code>hidden_size</code>, but your second layer expects the input to be of size <code>input_size</code>. This works for you currently because you are using the same size for input and hidden, but this will throw an error if that is ever not the case.</p>
<p>You want something like this:</p>
<pre class=""lang-py prettyprint-override""><code>self.hidden_layer = nn.Sequential(
    nn.Linear(input_size, hidden_size),
    nn.ReLU(),
    nn.BatchNorm1d(hidden_size),
    nn.Linear(hidden_size, hidden_size),
    nn.ReLU(),
    nn.BatchNorm1d(hidden_size)
)
</code></pre>
<p>That example has two blocks of linear/relu/batchnorm. You can add more if you want.</p>
<p>Your <code>forward</code> method is also weird.</p>
<p>First, make sure <code>nn.Flatten</code> is doing what you expect. Check the input/output shapes to be sure.</p>
<p>Second, you apply the same block of layers three times. If you want more layers, you should add them to the <code>nn.Sequential</code> block instead of passing different activations through the same layers 3 times.</p>
","2024-03-23 21:07:19","0","Answer"
"78211309","","Simple NN aiming to learn a of non-linear equations can't converge","<p>I've got a bunch of equations using sums, multiplication and min(x,0) or max(x,0) that yield a result (one output, 18 inputs).</p>
<p>I'm trying to have an NN model in pytorch learn these so I generate quick results.</p>
<p>I generated 30k random X-Y pairs in excel (just using RND()*100-50 for X and calculating Y).
I uploaded the pairs with pandas and wrote an NN with ReLu (which I hoped would handle the non-linearity). Here's the net:</p>
<pre><code>class MyModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super().__init__()
        self.flatten = nn.Flatten()  # Flatten input data
        self.hidden_layer = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_size),
            nn.Linear(input_size, hidden_size),
            nn.Linear(input_size, hidden_size),

            nn.ReLU()
        )
        self.output_layer = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.flatten(x)
        x = self.hidden_layer(x)
        x = self.hidden_layer(x)
        x = self.hidden_layer(x)
        output = self.output_layer(x)
        return output
</code></pre>
<p>sizes are 18 for inputs and hidden layer and 1 for output.</p>
<p>Can't converge, left with quite a big error. Thought that'd be a simple task for an NN, to learn that set of equations, there's no noise or anything. What can I do to make this work?</p>
","2024-03-23 14:50:27","0","Question"
"78209363","","How to make a neural network with multiple outputs (and multiple classes) using pytorch?","<p>I am working on a multi-output (i.e &gt; 1 output target) multi-class (i.e &gt; 1 class) (I believe this is also called a multi-task problem).
For example, my train_features_data is of shape (4, 6) (i.e three rows/examples and 6 columns/features), and my train_target_data is of shape (4, 3) (i.e 4 rows/examples and 3 columns/targets). For each target I have three different classes (-1, 0, 1).</p>
<p>I define an example model architecture (and data) for this problem like so:</p>
<pre><code>import pandas as pd
from torch import nn 
from logging import log
import torch
feature_data = {
    'A': [1, 2, 3, 4],
    'B': [5, 6, 7, 8],
    'C': [9, 10, 11, 12],
    'D': [13, 14, 15, 16],
    'E': [17, 18, 19, 20],
    'F': [21, 22, 23, 24]
}

target_data = {
    'Col1': [1, -1, 0, 1],
    'Col2': [-1, 0, 1, -1],
    'Col3': [-1, 0, 1, 1]
}

# Create the DataFrame
train_feature_data = pd.DataFrame(feature_data) 
train_target_data = pd.DataFrame(target_data)
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;

# create the model
class MyModel(nn.Module):
  def __init__(self, inputs=6, l1=12, outputs=3):
      super().__init__()
      self.sequence = nn.Sequential(
        nn.Linear(inputs, l1),
        nn.Linear(l1, outputs),
        nn.Softmax(dim=1)
    )
      
  def forward(self, x):
      x = self.sequence(x)
      return x
    
x_train = torch.tensor(train_feature_data.to_numpy()).type(torch.float)
model = MyModel(inputs = 6, l1 = 12, outputs = 3).to(device)
model(x_train.to(device=device))
</code></pre>
<p>When I pass my train data into the model (i.e when i call model(x_train.to(device=device))), I get back an array of shape (4, 3).</p>
<p>By following this resource <a href=""https://www.learnpytorch.io/02_pytorch_classification/#83-creating-a-loss-function-and-optimizer-for-a-multi-class-pytorch-model"" rel=""nofollow noreferrer"">resource</a>, my expectation was that I would get a shape of like (4, 3, 3) whereby the first axis (i.e 4) is the number of examples in my features and targets data, the second axis (i.e the middle 3) represents the logits (or in this case because I have a softmax function, this will be the predicted probabilities) of each example (and this would be 3 because I have three classes), while the third axis (or rightmost 3 value in the shape) represents the number of outputs/columns I have in my train_target_data.</p>
<p>Can someone please provide some guidance on what I'm doing incorrectly here (if my approach is wrong) and how to go about fixing it. Thanks.</p>
","2024-03-23 00:28:47","0","Question"
"78205955","78203005","","<p>Google Colab's free version operates on a dynamic and undisclosed usage limit system, designed to manage access to computational resources like GPUs and TPUs. These limits, including runtime durations, availability of certain GPU types, and cooldown periods between sessions, can vary over time and are not transparently communicated to users. This approach helps prioritize resources for interactive use and moderate the consumption of long-running computations.</p>
<p>Frequent or heavy use can lead to shortened runtime durations, more frequent disconnections, and extended cooldown periods before reconnecting to a GPU, ranging from hours to days or even weeks. Google monitors the usage of individual accounts as well as related accounts, adjusting limits to prevent abuse of the system. Users facing restrictions receive generic messages about usage limits without specific reasons for disconnections or access denial, and there's no straightforward way for users to track their own usage. This opacity maintains Google's control over resource allocation and prevents users from circumventing the system's restrictions.</p>
","2024-03-22 11:36:52","0","Answer"
"78203005","","Google Colab can't use the GPU","<p>I'm kinda new to Google colab and have taken the Colab pro to train my neural nets but when computing the code I see that only the system RAM is used and the GPU Ram isn't used.</p>
<p>Is there any settings to force the code to be computed on the GPU?</p>
<p>Thanks for your help</p>
<p>I tried this to force the code to use the GPU but it still doesn't work:</p>
<p>for iteration in range(n_iterations):
with tf.device('/GPU:0'):</p>
","2024-03-21 21:54:27","-2","Question"
"78202782","78196998","","<p><strong>I reshaped the encoded word vector from (45, 1) to (1,45)</strong></p>
<p>if input size is (1,45) and batch_size = 2:</p>
<pre><code>size of weight matrix = output_features x input_features = 3x45

bias vector size = output_features = 3


         input x       weight transposed            bias
y = [ [1,2,3,...,45],  * [ [1, 2, 3],     +    [ [b1, b2, b3],
      [3,2,1,...,45]]      [2, 2, 3],            [b1, b2, b3] ]
                           [3, 2, 3],
                           [.  .  .],
                           [45,45,45] ]

         2x45       *        45x3
                  
                   2x3                   +           2x3
                          
</code></pre>
","2024-03-21 21:02:50","0","Answer"
"78196998","","PyTorch matrix multiplication shape error: ""RuntimeError: mat1 and mat2 shapes cannot be multiplied""","<p>I'm new to PyTorch and creating a multi-output linear regression model to color words based on their letters. (This will help people with grapheme-color synesthesia have an easier time reading.) It takes in words and outputs RGB values. Each word is represented as a vector of 45 floats [0,1], where (0, 1] represents letters and 0 represents that no letter exists in that place. The output for each sample should be a vector [r-value, g-value, b-value].</p>
<p>I'm getting</p>
<blockquote>
<p>RuntimeError: mat1 and mat2 shapes cannot be multiplied (90x1 and 45x3)</p>
</blockquote>
<p>when I try to run my model in the training loop.</p>
<p>Looking at extant Stack Overflow posts, I think this means that I need to reshape my data, but I don't know how/where to do so in a way that would solve this problem. Especially considering that I don't know where that 90x1 matrix came from.</p>
<p><strong>My Model</strong></p>
<p>I started simple; multiple layers can come after I can get a single layer to function.</p>
<pre><code>class ColorPredictor(torch.nn.Module):
    #Constructor
    def __init__(self):
        super(ColorPredictor, self).__init__()
        self.linear = torch.nn.Linear(45, 3, device= device) #length of encoded word vectors &amp; size of r,g,b vectors
        
    # Prediction
    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        y_pred = self.linear(x)
        return y_pred
</code></pre>
<p><strong>How I'm loading my data</strong></p>
<pre><code># Dataset Class
class Data(Dataset):
    # Constructor
    def __init__(self, inputs, outputs):
        self.x = inputs # a list of encoded word vectors
        self.y = outputs # a Pandas dataframe of r,g,b values converted to a torch tensor
        self.len = len(inputs)
    
    # Getter
    def __getitem__(self, index):
        return self.x[index], self.y[index]
    
    # Get number of samples
    def __len__(self):
        return self.len
</code></pre>
<pre><code># create train/test split
train_size = int(0.8 * len(data))
train_data = Data(inputs[:train_size], outputs[:train_size])
test_data = Data(inputs[train_size:], outputs[train_size:])
</code></pre>
<pre><code># create DataLoaders for training and testing sets
train_loader = DataLoader(dataset = train_data, batch_size=2)
test_loader = DataLoader(dataset = test_data, batch_size=2)
</code></pre>
<p><strong>The testing loop, where the error occurs</strong></p>
<pre><code>for epoch in range(epochs):
    # Train
    model.train() #training mode
    for x,y in train_loader:
        y_pred = model(x) #ERROR HERE
        loss = criterion(y_pred, y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
      
</code></pre>
<p><strong>Error Traceback</strong>
<a href=""https://i.sstatic.net/2Ojco.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/2Ojco.png"" alt=""enter image description here"" /></a>
<a href=""https://i.sstatic.net/X45n4.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/X45n4.png"" alt=""enter image description here"" /></a></p>
<h1>New Attempt:</h1>
<p>Changed the 45x1 input tensor to a 2x45 input tensor, with the second column being all zeros. This works for the first run through the train_loader loop, but during the second run through the train_loader loop I get another matrix multiplication error, this time for matrices of sizes 90x2 and 45x3.</p>
","2024-03-21 01:00:23","0","Question"
"78178627","78178554","","<p>Your model's last layer is sigmoid, so the outputs of the model can only be between 0 and 1.</p>
<p><a href=""https://i.sstatic.net/76OTj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/76OTj.png"" alt=""enter image description here"" /></a></p>
<p>And how can you expect it to ever learn how to produce <code>2*i</code> (which is between 0 and 20000 in your case)?</p>
<p>Either try to remove the <code>activation='sigmoid'</code>, or normalize your input/output data to be in range between 0 and 1</p>
","2024-03-18 07:40:13","0","Answer"
"78178554","","Neural network unable to predict y=2x relationship","<p>I am getting a loss of <code>13332936704</code> and with every epoch tje loss is not decreasing very much. The output is <code>0.74</code>.</p>
<pre><code>Import tensorflow as tf
x=[]
y=[]
For i in range(10000):
  x.append(i)
  y append(i*2)
model=tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(64,input_shape=(1,),activation='relu'))
model.add(tf.keras.layers.Dense(28,activation='relu'))
model.add(tf.keras.layers.Dense(1,activation='sigmoid'))
model.compile(loss='mse',optimizer='adam')
model.fit(x,y,epochs=150,batch_size=32)
model.predict([2])

</code></pre>
<p>I want to deploy the neural network in a big project, but it is not simply predicting normal relation. I tried rerunning the cells and also changing <code>y=2x</code>. However, it is still not predicting.</p>
","2024-03-18 07:25:38","-4","Question"
"78173226","78173150","","<p>You need to have a backend configured before you import keras.  If not, it will never import the Variable class which might have something to do with your error. <strong>Put your setting of the backend type before importing ANY of the keras modules.</strong></p>
<p>Info on how to configure the backend can be found on this page:
<a href=""https://keras.io/getting_started/"" rel=""nofollow noreferrer"">https://keras.io/getting_started/</a></p>
<p>Copied from that page:</p>
<blockquote>
<p>You can export the environment variable KERAS_BACKEND or you can edit
your local config file at ~/.keras/keras.json to configure your
backend. Available backend options are: &quot;jax&quot;, &quot;tensorflow&quot;, &quot;torch&quot;.
Example:</p>
</blockquote>
<pre><code>export KERAS_BACKEND=&quot;jax&quot;
</code></pre>
<blockquote>
<p>In Colab, you can do:</p>
</blockquote>
<pre><code>import os 
os.environ[&quot;KERAS_BACKEND&quot;] = &quot;jax&quot; 
import keras
</code></pre>
<blockquote>
<p>Note: The
backend must be configured before importing Keras, and the backend
cannot be changed after the package has been imported.</p>
</blockquote>
","2024-03-16 20:32:23","0","Answer"
"78173150","","AttributeError: module 'keras.src.backend' has no attribute 'Variable' with Dropout layer","<p>I'm trying to re-use a neural network for sound classification but keras give an error:
AttributeError: module 'keras.src.backend' has no attribute 'Variable'.
May it be a compatibility problem?
I'm using keras v3.0.5.
This is my code:</p>
<pre><code>import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import Adam
# from keras.utils import np_utils
from sklearn import metrics 
from tensorflow.keras import layers
import keras
from keras import backend

num_labels = yy.shape[1]
filter_size = 2

# Construct model 
model = Sequential()

model.add(Dense(256, input_shape=(40,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(num_labels))
model.add(Activation('softmax'))
model.summary()
</code></pre>
<p>According to Keras documentation, if I use a dropout layer:</p>
<pre><code>layers.Dropout(0.5, noise_shape=None, seed=None),
</code></pre>
<p>it gives the same error.
Can someone help me?
Thanks.</p>
","2024-03-16 20:00:18","2","Question"
"78172588","78040404","","<p>Yes you can. This is already implemented in the package Compositional. The function is called kl.compreg().</p>
","2024-03-16 16:48:29","1","Answer"
"78166929","77968516","","<p>Two problems:</p>
<ul>
<li>Your sum can be negative, i.e. you try to compute the logarithm of negative values -&gt; Na losses.</li>
<li>you return negative values -&gt; optimization goes in the wrong direction</li>
</ul>
<p>And because the tensorflow-python backend is very fragile, your session will crash.</p>
<p>In cito (an R package for fitting DNNs based on torch), you can also use custom loss functions (based on torch, a native (py)torch implementation for) and continue fitting:</p>
<pre><code>library(cito)
library(torch)
custom_loss &lt;- function(pred, true) {
  y_true = true
  y_pred = pred
  tt &lt;- 0
  for (i in 1:nrow(y_true)) {
    tt &lt;- tt + log(abs(sum(exp(y_true[i,]) * y_pred[i,])))
  }
  mse &lt;- -tt
  return(-mse)
}
nn.fit&lt;- dnn(Y = y_train, X = x_train,
             loss = custom_loss, lr = 0.0001)
nn.fit = continue_training(nn.fit)
</code></pre>
","2024-03-15 12:29:54","0","Answer"
"78166075","78040404","","<p>I think you could do something like this with cito. cito is a package for fitting DNNs with a simple user interface (including formula syntax), but with the advantage of using state-of-the-art DL frameworks (here torch).</p>
<p>Unlike nnet, cito supports custom loss functions and I think we can build what you want (unfortunately we do not have multinomial loss at the moment because it is not yet implemented in torch):</p>
<pre><code>library(cito)

# Custom loss functions must be implemented in torch 
custom_loss = function(pred, true) {
  pred_prob = torch::nnf_softmax(pred, dim = 2)
  return(torch::nnf_binary_cross_entropy(pred_prob, true))
}

# Model call, by default a DNN with two layers and each with 50 nodes
model = dnn(cbind(prop_A, prop_B, prop_C)~., data = data, loss = custom_loss, lr = 0.1)

# Predict
pred =predict(model)

# To forward them through the softmax link, we must transfer them to a torch object
pred_tensor = torch::torch_tensor(pred)

# Predictions - we must apply the link, and then transform it back to R
torch::nnf_softmax(pred_tensor, dim = 2)  |&gt; as.matrix()
</code></pre>
","2024-03-15 10:02:49","1","Answer"
"78155590","78147725","","<p>You've tagged this with pytorch, so I'll give the pytorch answer.</p>
<p>Pytorch data utils has a <code>Dataset</code> and a <code>DataLoader</code>. tl;dr, the <code>Dataset</code> handles loading a single example, while the <code>DataLoader</code> handles batching and any bulk processing.</p>
<p>The <code>Dataset</code> has two methods, <code>__len__</code> for determining the number of items in the dataset and <code>__getitem__</code> for loading a single item.</p>
<pre class=""lang-py prettyprint-override""><code>class MyDataset(Dataset):
    def __init__(self):
        ...

    def __len__(self):
        ...

    def __getitem__(self, index):
        ...
</code></pre>
<p>The <code>DataLoader</code> is passed a list of outputs from the <code>Dataset</code> (ie <code>batch_input = [dataset.__getitem__(i) for i in idxs]</code>). The batch input is sent to the <code>collate_fn</code> of the <code>DataLoader</code>.</p>
<pre class=""lang-py prettyprint-override""><code>def my_collate_fn(batch):
    ...

dataloader = DataLoader(my_dataset, batch_size, collate_fn=my_collate_fn)
</code></pre>
<p>In terms of thinking about what to do where, the <code>Dataset</code> should handle loading single examples. The <code>Dataset</code> will be called in parallel, so tasks that are CPU-bound should go in the <code>Dataset</code>. Loading from disk (if applicable) is also typically done in the <code>Dataset</code>.</p>
<p>The <code>collate_fn</code> handles converting a list of outputs from your <code>Dataset</code> into whatever format your model wants. Since the <code>DataLoader</code> deals with a batch of data, it can be more efficient to apply batch processing steps. Stacking tensors, padding to length, generating masks or other bulk tensor ops work well in the <code>collate_fn</code>.</p>
<p>In general, think of the <code>Dataset</code> as running multi-process on single examples, while the <code>DataLoader</code> running a single-process on a batch of examples.</p>
","2024-03-13 16:59:21","2","Answer"
"78151471","","Neural Style Transfer Unsatisfactory Results","<p>I am trying to use neural style transfer(NST) to visualize the results of remodelling of a home's interiors and how it will look as per the user's style image. While the code I use gives me good results most of the time, it occasionally gives me noisy and irrelevant results. What can be the cause of this phenomenon?</p>
<p><a href=""https://i.sstatic.net/krOeW.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/krOeW.jpg"" alt=""This is an image where the NST has produced decent results and is able to transfer the stye quite well"" /></a></p>
<p>The above is an image where the NST has produced decent results and is able to transfer the stye quite well</p>
<p><a href=""https://i.sstatic.net/LDvws.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/LDvws.jpg"" alt=""This is another situation where the NST process has failed terribly and is only outputting noisy results"" /></a></p>
<p>This is another situation where the NST process has failed terribly and is only outputting noisy results</p>
<p>Is there any technical name for this occurrence? Technical papers and articles on why this occurs and how to solve this will be greatly appreciated.</p>
","2024-03-13 05:43:05","0","Question"
"78147725","","What should collator do exactly?","<p>Suppose we have an audio classification task (AudioMNIST).</p>
<p>My pipeline and other pipelines I’ve seen consist of the next steps:</p>
<ol>
<li>Read the dataset (the data samples).</li>
<li>Do the base transforms (merge the audio channels, change the bitrate, etc).</li>
<li>Split the dataset into the train one, the test one, etc.</li>
<li>Do the main transforms (different for the train and the test) such as the augmentation.</li>
<li>Batch (along with the sampling).</li>
<li>Pad/Truncate the batch samples.</li>
<li>Do the forward pass with the batch.</li>
<li>&lt;…&gt;</li>
</ol>
<p>I saw the scheme:</p>
<ul>
<li>Dataset or a subclass - pp. 1., 2., 3., 4.</li>
<li>Collator - p. 6.</li>
</ul>
<p>Either:</p>
<ul>
<li>Dataset or a subclass - p. 1.</li>
<li>somebody else - pp. 2., 3., 4.</li>
<li>Collator - p. 6.</li>
</ul>
<p>Or:</p>
<ul>
<li>Dataset or a subclass - p. 1.</li>
<li>somebody else - p. 3.</li>
<li>Collator - pp. 2., 4., 6.</li>
</ul>
<p>What should the collator do and what shouldn’t? (The main question.)
What is the correct scheme?</p>
","2024-03-12 13:56:08","1","Question"
"78132768","78107838","","<p>I see you've already found out the problem, but this answer could still be helpful to others.&quot;</p>
<p>First count how many parameters each layer of your model has:</p>
<ul>
<li><code>Linear(in_features=N, out_features=M)</code> has <code>MxN</code> weights;</li>
<li><code>Flatten</code> and <code>ReLU</code> have no weights;</li>
<li>Both <code>BatchNorm1d(C)</code> and <code>BatchNorm2d(C)</code> have <code>2xC</code> weights (2 per channel);</li>
<li>Both <code>Conv2d</code> and <code>ConvTranspose2d(in_features=N, out_features=M, kernel_size=K, ...)</code> have <code>M</code> different filters, each of size <code>NzKxK</code>. Each filter has also (by default) its own bias (another weight). Therefore, for <code>Conv2d</code> layers, you end up with <code>MxNxKxK + M</code> weights.</li>
</ul>
<p>If you compute the total number of weights of your model, you should end up with <code>8,599,888,384 + 2048 x dim_code + 8,604,081,155 + 2048 x dim_code = 17,203,969,539 + 4,096 x dim_code</code> different parameters (I hope I dind't miscalculate anything! I leave the computations in the bottom of the answer). This is even larger than most recent LLMs, such as Mistral7B (which, as the name itself suggests, has around <code>7B</code> parameters).</p>
<p>Now, considering that PyTorch defaults to a <code>float32</code> data type for tensors, your model needs more than <code>17B x 32bit = 64 GiB</code> of RAM. This calculation disregards the contribution from the <code>4,096 x dim_code</code> term, assuming that <code>dim_code</code> is relatively small in comparison. Therefore, make sure your machine has enough RAM (if you are using CPU as device, or enough VRAM, if you use a GPU).</p>
<h2>Number of parameters calculation</h2>
<p>Encoder has <code>8,599,888,384 + 2048 x dim_code</code>:</p>
<ul>
<li><code>enc_conv0</code> has:
<ul>
<li><code>Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)</code> has
<code>3x64x3x3+64 = 1,792</code> weights;</li>
<li><code>BatchNorm2d(64)</code> has <code>2x64 = 128</code> weights;</li>
<li><code>Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)</code> has
<code>128x64x3x3+128 = 73,856</code> weights;</li>
<li><code>BatchNorm2d(128)</code> has <code>2x128 = 256</code> weights;</li>
</ul>
</li>
<li><code>enc_conv1</code> has:
<ul>
<li><code>Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)</code> has
<code>256x128x3x3+256 = 295,168</code> weights;</li>
<li><code>BatchNorm2d(256)</code> has <code>2x256 = 512</code> weights;</li>
<li><code>Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)</code> has <code>512x256x3x3+512 = 1,180,160</code> weights;</li>
<li><code>BatchNorm2d(512)</code> has <code>2x512 = 1,024</code> weights</li>
</ul>
</li>
<li><code>enc_fc</code> has:
<ul>
<li><code>Linear(in_features=512*64*64, out_features=4096)</code> has <code>512x64x64x4096 = 8,589,934,592</code> weights;</li>
<li><code>BatchNorm1d(4096)</code> has <code>2x4096 = 8,192</code> weights;</li>
<li><code>Linear(in_features=4096, out_features=2048)</code> has <code>4096x2048 = 8,388,608</code> weights;</li>
<li><code>BatchNorm1d(2048)</code> has <code>4096</code> weights;</li>
<li><code>Linear(in_features=2048, out_features=d)</code> has <code>2048xd</code> weights;</li>
</ul>
</li>
</ul>
<p>Decoder has <code>8,604,081,155 + 2048 x dim_code</code> weights:</p>
<ul>
<li><code>dec_fc</code> has:
<ul>
<li><code>Linear(in_features=dim_code, out_features=2048)</code> has <code>dim_code x 2048</code> weights;</li>
<li><code>BatchNorm1d(2048)</code> has <code>2x2048 = 4,096</code> weights;</li>
<li><code>Linear(in_features=2048, out_features=4096)</code> has <code>2048x4096 = 8,388,608</code> weights;</li>
<li><code>BatchNorm1d(4096)</code> has <code>2x4096 = 8,192</code> weights;</li>
<li><code>Linear(in_features=4096, out_features=512*64*64)</code> has <code>4096x512x64x64 = 8,589,934,592</code> weights;</li>
<li><code>BatchNorm1d(512*64*64)</code> has <code>2x512x64x64 = 4,194,304</code> weights;</li>
</ul>
</li>
<li><code>dec_conv0</code> has:
<ul>
<li><code>ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, padding=1)</code> has <code>256x512x3x3 + 256 = 1,179,904</code> weights;</li>
<li><code>BatchNorm2d(256)</code> has <code>512</code> weights;</li>
<li><code>ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, padding=1)</code> has <code>128x256x3x3 + 128 = 295,040</code> weights;</li>
<li><code>BatchNorm2d(128)</code> has <code>2x128 = 256</code> weights;</li>
</ul>
</li>
<li><code>dec_conv1</code> has :
<ul>
<li><code>ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, padding=1)</code> has <code>64x128x3x3 + 64 = 73,792</code> weights;</li>
<li><code>BatchNorm2d(64)</code> has <code>2x64 = 128</code> weights;</li>
<li><code>ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=3, padding=1)</code> has <code>3x64x3x3 + 3 = 1,731</code> weights.</li>
</ul>
</li>
</ul>
","2024-03-09 14:57:19","0","Answer"
"78131346","78130978","","<p>So, both cases are all before the <code>backward()</code> function. Then it doesn't matter where you place it. Actually you can put it before calling <code>backward()</code> and <code>step()</code> or after as long as not between <code>backward()</code> and <code>step()</code>. It actually depends on the codding style of the person who wrote it.</p>
<p>Normally If you have only one optimization then people tend to put the <code>opt.zero_grad()</code> at the beginning of the loop. But if your model is a bit complex with more than one optimization. Then I tend to do something like:</p>
<pre><code>encoder_opt.zero_grad()
encoder_loss = ...
encoder_loss.backward()
encoder_opt.step()

decoder_opt.zero_grad()
decoder_loss = ...
decoder_loss.backward()
decoder_opt.step()

</code></pre>
<p>to make the code easier to read and make it clearer I guess.</p>
<p>About your experiment, I don't think that putting it in different lines make it produce different result. As your model weight is initialized as well as updated differently when you re-train your model. You can set a specific seed for the reproducibility.</p>
","2024-03-09 05:35:25","2","Answer"
"78130978","","Exactly where in the training loss loop should zero_grad() be used? Does doing it before or after calculating the loss change things?","<p>So I know you need to zero out the gradients before a backwards pass, because the reason for that is obvious. I'm confused about where to add zero_grad() otherwise though, as I've seen examples put it either at the start of the loop or just before loss.backward(), and I'm unable to tell which is correct, or if there's much of a difference at all.</p>
<p>I did try this and noticed a change in all of my accuracy calculations though which has me sort of curious as to what the reason might be, and if it's significant at all.</p>
","2024-03-09 01:38:12","0","Question"
"78126184","78126160","","<p><code>loss.backward()</code> does not return anything. This is why <code>print(loss.backward())</code> returns <code>None</code>.</p>
<p>You want to use <code>print(loss)</code> instead</p>
","2024-03-08 07:47:39","0","Answer"
"78126160","","Getting None from loss in neural network despite tensors being leaf","<p>I checked all the tensors and input parameters, they were all leaf, according to the code below,</p>
<pre><code>def train_step(w1,b1):
    print(&quot;w=&quot;,w1)
    trainable_variables = [w1,b1]
    optimizer = torch.optim.SGD(trainable_variables, lr=learning_rate)
    loss = Variable(loss2_function(), requires_grad = True)
    print(loss.backward())
    with torch.no_grad():
        w1 -=(learning_rate * w1.grad)
        b1 -= (learning_rate * b1.grad)
        w1.grad.zero_()
        b1.grad.zero_()
    optimizer.step()
    optimizer.zero_grad()
</code></pre>
<p>I still get none, and even with the change in learning rate, weight and bias, the network still does not work, please guide me.</p>
","2024-03-08 07:42:18","0","Question"
"78121040","78119974","","<p>I don't know why the other answer was accepted, as there is a fundamental misunderstanding in the way you constructed the model in the question! And the other answer does not take this into account.<br />
When you define a model and its input and output sizes, you still only consider one sample. You don't use <code>batch_size</code> for scaling the output. When you then give a batch of input data into the model, <code>PyTorch</code> handles the batch internally and the model gets evaulated on each sample in parallel.</p>
<p>You can look at an official <a href=""https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"" rel=""nofollow noreferrer"">PyTorch tutorial</a>, where they built a model for data on the <code>Fashion MNIST</code> dataset. Each image in this dataset is <code>(28x28x1)</code> pixels (greyscale), and there are 10 different classes to predict. Notice the first and last layer:</p>
<blockquote>
<p>nn.Linear(28*28, 512)<br />
....<br />
nn.Linear(512, 10)</p>
</blockquote>
<p>where the input is the image pixels <code>28*28</code> and the output is <code>10</code> numbers for 10 classes. You can then use <code>SoftMax</code> or <code>categorical_crossentropy</code> for prediction. There is no information on batch sizes in the model itself, as the model doesn't need that.</p>
<p>Most of the time it is no problem to have the last batch a bit smaller than the others. If your batch size is <code>32</code>, but the last batch is only <code>15</code> samples, the model will just get 15 samples and labels, do the prediction and compare the 15 results to the 15 labels for the last batch.<br />
If for some reason you need all batches to be exactly the same size (e.g. for a stateful <code>LSTM</code>), then you can use <code>DataLoader</code> with <code>drop_last=True</code>. But most of the time, it is not needed and you just hide data from the model if you use it.</p>
<p>Using the <code>DataLoader</code> is still a good idea, because they can efficiently handle loading your data on CPU, while the model will train on GPU.</p>
","2024-03-07 11:36:39","1","Answer"
"78120372","78119974","","<p>I suggest you to use a Pytorch <code>DataLoader</code> for loading data batch by batch instead of doing it manually. In this regard, PyTorch provides a simple solution for this using the <code>drop_last</code> parameter in the <code>DataLoader</code>. When set to True, it drops the last incomplete batch, ensuring that all batches are of the specified size except for the last one.
The <code>Dataloader</code> is a wrapper for the torch <code>Dataset</code>, you can find more info <a href=""https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"" rel=""nofollow noreferrer"">here</a></p>
<pre class=""lang-py prettyprint-override""><code>import torch
import torch.nn as nn
from torch.utils.data import DataLoader

X = torch.Tensor(...)  # your features
y = torch.Tensor(...)  # your labels

dataset = 

# Create a DataLoader with drop_last=True
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)

model = ...

optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# Training loop
num_epochs = 5
for epoch in range(num_epochs):
    total_loss = 0
    for batch_x, batch_y in dataloader:
        optimizer.zero_grad()
        y_pred = model(batch_x)
        loss = criterion(y_pred, batch_y)
        total_loss += loss.item()
        loss.backward()
        optimizer.step()

    average_loss = total_loss / len(dataloader)
    print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}')
</code></pre>
","2024-03-07 09:59:38","1","Answer"
"78119974","","How to train NN in batches with odd examples size?","<p>I am a newbie in the NN field and I am doing some training with pytorch.<br />
I decided to make a simple vanilla NN.<br />
I used a personal dataset i had with 2377 numerical features and 6277 examples.</p>
<p>My first try was to make the NN predict each single example, so the pseudocode would look like</p>
<pre><code>for i in range(...):
    X = ... # features
    y = ... # outcome
    y_pred = model(X[i])
    loss = criterion(y_pred, y)

    y_pred.size # [1,1]
    y.size # [1,1]
</code></pre>
<p>This took about 10 seconds per epoch and i decided to improve it using mini batches.</p>
<p>So i define the batch size at the beginning and the NN in Pytorch is defined like this</p>
<pre><code>batch_size = 30
n_inputs = X.size[1] #2377

## 2 hidden layers
model = nn.Sequential(
    nn.Linear(n_inputs, 1024),
    nn.ReLU(),
    nn.Linear(1024, 512),
    nn.ReLU(),
    nn.Linear(512, 356),
    nn.ReLU(),
    nn.Linear(356, batch_size),
    nn.ReLU(),
)
</code></pre>
<p>And then I do the training in batches</p>
<pre class=""lang-py prettyprint-override""><code>for epoch in range(5):
    totalloss = 0  
    permutation = torch.randperm(X.size()[0])
    for i in range(0, X.size()[0], batch_size):
        optimizer.zero_grad()
        indices = permutation[i:i+batch_size]
        batch_x, batch_y = x[indices], y[indices]

        ypred = model(batch_x)
        loss = criterion(ypred, batch_y) 
        totalloss += loss.item()
        
        ## update the weights
        loss.backward()
        optimizer.step()
</code></pre>
<p>Now the problem is that my NN always outputs 100 values <strong>but</strong> the last batch size can vary.<br />
In fact, if i choose 100 as batch size the last batch will be made of 77 examples (6277%100).</p>
<p>I am sure there is a way around this problem, and that there is a mistake in my structure, but i cannot see it.</p>
<p>Can you help me generalize the training in batch to work with any number of examples and batch size?</p>
","2024-03-07 08:58:57","1","Question"
"78114492","78107838","","<p>So the issue was the size of the model, once I tried to make smaller one all the problems disappeared.</p>
","2024-03-06 12:46:06","1","Answer"
"78110673","78107838","","<p>Here's an updated version of your training code incorporating the suggestions:</p>
<pre class=""lang-py prettyprint-override""><code>import torch
import torch.nn as nn

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

criterion = nn.MSELoss()  # Use Mean Squared Error for image reconstruction
print('crit')

autoencoder = Autoencoder().to(device)
print('deviced')
</code></pre>
<p>If the problem persists, try addressing the points mentioned above and let me know if you encounter any specific errors or if you have additional details about the issue.</p>
","2024-03-05 21:34:06","-2","Answer"
"78107838","","I cannot put PyTorch model to device (.to(device))","<p>So I was writing my first ever autoencoder, here is the code (it can be a little bit goofy, but I believe I written all of it right):</p>
<pre><code>class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        
        self.flatten = nn.Flatten()
        
        self.enc_conv0 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=(1, 1)),
            nn.ReLU(),
            nn.BatchNorm2d(64),

            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=(1, 1)),
            nn.ReLU(),
            nn.BatchNorm2d(128)
        )
        
        self.enc_conv1 = nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=(1, 1)),
            nn.ReLU(),
            nn.BatchNorm2d(256),

            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=(1, 1)),
            nn.ReLU(),
            nn.BatchNorm2d(512)
        )
        
        self.enc_fc = nn.Sequential(
            nn.Linear(in_features=512*64*64, out_features=4096),
            nn.ReLU(),
            nn.BatchNorm1d(4096),
            
            nn.Linear(in_features=4096, out_features=2048),
            nn.ReLU(),
            nn.BatchNorm1d(2048),
            
            nn.Linear(in_features=2048, out_features=dim_code)
        )
        
        self.dec_fc = nn.Sequential(
            nn.Linear(in_features=dim_code, out_features=2048),
            nn.ReLU(),
            nn.BatchNorm1d(2048),
            
            nn.Linear(in_features=2048, out_features=4096),
            nn.ReLU(),
            nn.BatchNorm1d(4096),
            
            nn.Linear(in_features=4096, out_features=512*64*64),
            nn.ReLU(),
            nn.BatchNorm1d(512*64*64)
        )
        
        self.dec_conv0 = nn.Sequential(
            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(3,3), padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(256),
            
            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(3,3), padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
        )
        
        self.dec_conv1 = nn.Sequential(
            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(3,3), padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            
            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=(3,3), padding=1)
        )

    def forward(self, x):
        e0 = self.enc_conv0(x)
        e1 = self.enc_conv1(e0)
        latent_code = self.enc_fc(self.flatten(e1))
        
        d0 = self.dec_fc(latent_code)
        d1 = self.dec_conv0(d0.view(-1, 512, 64, 64))
        reconstruction = self.dec_conv1(d1)

        return reconstruction, latent_code
</code></pre>
<p>And then I was preparing to train it with the next cell of code:</p>
<pre><code>`device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

criterion = nn.BCELoss()
print('crit')

autoencoder = Autoencoder().to(device)
print('deviced')`
</code></pre>
<p>Cell prints:
cuda
'crit'</p>
<p>And then just stalks infinitely, filling the RAM and CPU at its full (im doing everything on kaggle notebook). And I dont get why. :(</p>
<p>Tried to launch the same notebook in Google colab instead of Kaggle, but it just crashed with error about trying to allocate resources that are not accessable.</p>
<p>Also I thought the issue could had something to do with the first line after initiation of a class, so I replaced</p>
<pre><code>def __init__(self):
        super().__init__()
</code></pre>
<p>with</p>
<pre><code>def __init__(self):
        super(Autoencoder, self).__init__()
</code></pre>
<p>like I saw in some tutorials (honestly I don't know what this lines do, it just written in every other similar cases)
But it also didnt worked</p>
","2024-03-05 12:47:03","0","Question"
"78101869","78088764","","<p>See that you have a very defined model you want to train: Y = a*X.</p>
<p>So your model architecture is just the parameter <code>a</code>, and the forward pass is just multiplying that parameter with the inputs.</p>
<p>Also, that model works in a regression format (the output is a continuous value), so cross-entropy (normally used for multi-class classification) is not the correct choice, instead a Mean Squared Error would make more sense (you want predicted outputs to be as close to the real ones).</p>
<p>Also also, the exercise asks you to use only the provided X and Y. In such case, and given that the model is so simple that only one value of <code>a</code> is the optimal solution (i.e. it is a convex optimization problem), you are better off just doing a single optimization step.</p>
<p>The following implements that:</p>
<pre class=""lang-py prettyprint-override""><code>from torch.nn import Parameter
from torch.optim import Adam


class FindParameter(Module):
    def __init__(self):
        super(FindParameter, self).__init__()
        self.a = Parameter(data=1.0)

    def forward(self, input):
        return self.a * input


X = ...
Y = ...


model = FindParameter()
loss_f = MSELoss()
optimizer = Adam(model.parameters(), lr=1e-3)

epochs = 100

for epoch in epochs:
    optimizer.zero_grad()
    y_pred = model(X)

    loss = loss_f(y_pred, Y)
    loss.backward()
    optimizer.step()
</code></pre>
","2024-03-04 14:14:57","1","Answer"
"78101844","78099962","","<p>Consider the inputs to be [xi,yi] and the output
[ki] where xi*ki = yi.</p>
<p>For a standard input/activation.</p>
<pre><code>A(zj - (xi*wxj + yi*wyj))
</code></pre>
<p>You cannot have the result of this activation function to be k.</p>
<p>You can categorize k though. The idea would be to categorize k enough that the value can be a scalar. Think of just positive x, y and k.</p>
<pre><code>sigmoid( - xi*10 + yi )
</code></pre>
<p>Thus the crossover is when k &gt; 10.</p>
<p>With this idea you can build enough outputs to categorize k into a range of values.</p>
<p>If we use two points we don't have to do division.</p>
<pre><code>(x0, y0, x0 + 1, y1)
</code></pre>
<p>Now we can see the slope is x[3] - x[1]. This is what we should see from your example, since you always use the same linspec. I suspect from your pooling/convolutions you've somehow eliminated the possibility of this training route.</p>
<p>I made the input:</p>
<pre><code>X.append( np.array((xs[i], xs[i+1], ys[i], ys[i+1])) )
</code></pre>
<p>And I changed the model:</p>
<pre><code>model = models.Sequential()

model.add(layers.InputLayer(input_shape=(X[0].shape[0], 1)))
nn = 32
nl = 4
act = 'relu'
model.add(layers.Flatten())
for i in range(nl):
    model.add(layers.Dense(nn, activation=act))
    model.add(layers.Dense(1, activation='linear'))
model.add(layers.Dense(1, activation='linear'))
</code></pre>
<p>That model and data learns to predict k. It's really just calculating the difference between different y values.</p>
","2024-03-04 14:10:52","1","Answer"
"78101580","78088764","","<p>We show in our R package 'cito' (which simplifies the training of NN) how you can use NN to optimize arbitrary functions (the only requirement is that they must be differentiable and written in Torch). Your question is similar to our <a href=""https://citoverse.github.io/cito/articles/D-Advanced_custom_loss_functions.html#example-3-using-cito-for-optimization-active-learning"" rel=""nofollow noreferrer"">example</a>:</p>
<p>Simulate some data from a linear model (true slope = 2, true sigma = 0.4)</p>
<pre><code>library torch
library(cito)  
X = runif(200)
Y = 2*X + rnorm(200, sd = 0.4)
df = data.frame(X = X, Y = Y)
</code></pre>
<p>Function we want to optimize (linear model):</p>
<pre><code>Xt = torch_tensor(matrix(X))
Yt = torch_tensor(matrix(Y))

model_lm = function(par) {
  pred = Xt$matmul(par[,1,drop=FALSE])
  loss = -torch::distr_normal(pred, scale = torch::torch_exp(par[,2,drop=FALSE]))$log_prob(Yt)
  return(loss$mean())
}
</code></pre>
<p>The actual loss function:</p>
<pre><code>custom_loss = function(pred, true, ...) {
  if(nrow(pred) &gt; 1) return(torch_zeros(1L)) # disable loss calculation
  loss = model_lm(pred)
  return(loss)
}
</code></pre>
<p>X and Y values don't matter, number of columns in Y has to match the number of parameters we want to optimize, here two column, one for the slope parameter and one for the sigma parameter. We feed noise to our neural network and it predicts the two parameter (similar to the generator in a GAN):</p>
<pre><code>noise = matrix(runif(300*5), 300, 5)
noise_y = matrix(runif(300*2), 300, 2)
df = data.frame(y1 = noise_y[,1], y2 = noise_y[,2], noise)
</code></pre>
<p>Fit the final model:</p>
<pre><code>m = dnn(cbind(y1, y2)~., data = df, loss = custom_loss, batchsize = 1L, epochs = 20L, verbose = FALSE) 
</code></pre>
<p>Results:</p>
<pre><code># Effect:
mean(predict(m)[,1])
#&gt; [1] 2.02776
# SD
mean(exp(predict(m)[,2]))
#&gt; [1] 0.3864421
</code></pre>
","2024-03-04 13:28:24","0","Answer"
"78099962","","Training a CNN to predict a parameter of a function","<p>I am trying to build a CNN with TensorFlow to solve the following kind of a regression task. The idea would be that there is some unknown function and we are interested in knowing some parameter of that function. As features, we have a vector of x values and a vector y which contains the function values at the corresponding x values. The corresponding label would be the function parameter. The CNN would take the x and y values and predict the parameter value. However, I am unable to achieve a sufficient accuracy with my CNN model.</p>
<p>To be more concrete, consider the following simple example. All functions would be simple linear functions y = kx and the task would be to predict the slope k. To acquire data, we may use the following Python code:</p>
<pre><code>N_data = 50000 # number of data points

X = [] # features (x and y values)
y = [] # labels (slopes)

for k in range(N_data):
    # Randomly choose the x values:
    x_min = 200*random.random()-100
    xs = np.linspace(x_min, x_min + 10)

    # Randomly choose the slope:
    k = 200*random.random()-100

    # Calculate the function values:
    ys = k*xs
    
    # Store the data:
    X.append(xs.tolist() + ys.tolist())
    y.append(k)
    
X = np.array(X)
y = np.array(y)

tf.random.set_seed(41)

# Split the data into training, validation and test sets:
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=41)

# Split the temporary set into validation and test sets:
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=41)
</code></pre>
<p>Here's my CNN model:</p>
<pre><code>model = models.Sequential()

# Data normalization layer
model.add(layers.InputLayer(input_shape=(X[0].shape[0], 1)))
model.add(layers.BatchNormalization())

# Convolutional block 1:
model.add(layers.Conv1D(32, 3, activation='relu'))
model.add(layers.AveragePooling1D(2))

# Convolutional block 2:
model.add(layers.Conv1D(64, 3, activation='relu'))
model.add(layers.AveragePooling1D(2))

# Convolutional block 3:
model.add(layers.Conv1D(128, 3, activation='relu'))
model.add(layers.MaxPooling1D(2))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1))
</code></pre>
<p>And the following code fits the model:</p>
<pre><code>model.compile(optimizer=Adam(learning_rate=0.01),
              loss='mean_squared_error',
              metrics=['mae'])

history = model.fit(X_train, y_train, epochs=50, batch_size = 16, 
                    validation_data=(X_val, y_val))
</code></pre>
<p>The training and validation mean absolute errors are shown in the following figure:
<a href=""https://i.sstatic.net/4wkme.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4wkme.png"" alt=""enter image description here"" /></a></p>
<p>I am unsure how to interpret that the validation errors are consistently smaller than the training errors. With the test set (10 % of the total data, i.e., 5 000 samples), the mean absolute error is 3.37, which is quite high with this simple problem and this large number of data points. What could I do to improve the model? I am unsure if the problem is with the number of data points, with the CNN architecture, or how the input data is formatted. Any suggestions would be appreciated.</p>
","2024-03-04 08:47:50","-1","Question"
"78098142","78093891","","<blockquote>
<p>Are there any other factors in above code, besides the default optimizer (SGD), that can introduce randomness in the output of above neural network model?</p>
</blockquote>
<p>Two other factors are that layer weights will be initialised with random values; and data shuffling (if enabled) would also be a source of randomness.</p>
<blockquote>
<p>How can I modify the provided code to ensure that the model produces the same output for the same input?</p>
</blockquote>
<p>Set the random seed for various random number generators at the start of the script:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import random
import tensorflow as tf

#Set seeds for consistent results each run
seed_value = 0
np.random.seed(seed_value)
random.seed(seed_value)
tf.random.set_seed(seed_value)
</code></pre>
<p>If you're working in a notebook, and you run a cell multiple times (outside of the seeding above), then each run of the cell will give you a different result if the cell depends on a random generator. So make sure to set the seed inside that cell as well. That way, each time you run the cell, it will initialise at the same place.</p>
<p>Might also be worth seeing <a href=""https://stackoverflow.com/a/52897216/21896093"">this</a> answer for notes about setting the <code>PYTHONHASHSEED</code> environment variable. I haven't needed to configure it. Your use-case may or may not require it.</p>
","2024-03-03 22:18:30","1","Answer"
"78093891","","Ensuring Deterministic Outputs in Neural Network Training","<p>I am new to neural networks and currently working with TensorFlow. For an experiment, I would like to build a model that consistently produces the same output for identical inputs. However, my initial attempt using a trivial test and setting the <code>batch_size</code> equal to the size of the training data did not achieve this goal:</p>
<pre><code>model = keras.Sequential([keras.layers.Dense(1)])
model.compile( loss=&quot;MSE&quot;, metrics=[keras.metrics.BinaryAccuracy()])
model.fit(
  training_inputs,
  training_targets,
  epochs=5,
  batch_size=1000,
  validation_data=(val_inputs, val_targets)
)
</code></pre>
<p>I suspect that the default optimizer, <code>SGD</code> (Stochastic Gradient Descent), might be causing random outputs.</p>
<p>My questions are:</p>
<ul>
<li>Are there any other factors in above code, besides the default optimizer (<code>SGD</code>), that can introduce randomness in the output of above neural network model?</li>
<li>How can I modify the provided code to ensure that the model produces the same output for the same input?</li>
</ul>
<p>Thank you for your assistance.</p>
","2024-03-02 18:30:36","1","Question"
"78088764","","Finding the coefficient ""a"" of a linear equation of the form Y = aX","<p>Suppose I have two sets, X and Y, and some preknown coefficient &quot;a&quot;.</p>
<p>Set Y depends on X and &quot;a&quot; as follows:
Y = aX</p>
<pre><code>import numpy as np

a = 2
X = np.random.randint(1, 10, 10)
Y = a * X

print(f&quot;{X = }&quot;)
print(f&quot;{Y = }&quot;)

&gt;&gt;&gt; X = array([9, 2, 7, 8, 8, 9, 5, 8, 4, 1])
&gt;&gt;&gt; Y = array([18,  4, 14, 16, 16, 18, 10, 16,  8,  2])
</code></pre>
<p>Task:
Using PyTorch toolkit find the coefficient &quot;a&quot; using only X and Y</p>
<p>What I tried to do and what the problem was:</p>
<p>I am trying to pass X[i] to a model and expect to get the coefficient a_pred from it. Then I find y_pred = a_pred * X[i]. Finally I compare y[i] and y_pred.
Obviously, the model does not &quot;see&quot; the relationship between a_pred, &quot;a&quot;, y_pred and Y[i]. Hence the question: what should be the architecture of the model so that it can find the correct coefficient of &quot;a&quot;?</p>
<p>I'm just starting to learn PyTorch, and unfortunately, so far, I haven't found an unambiguous answer to this question. So far, it seems to me that the solution to this problem must be somehow related to GAN, but how exactly I unfortunately do not know</p>
<p>My current code:</p>
<pre><code>import numpy as np
from torch.nn import Module, Linear, ReLU, Sequential, CrossEntropyLoss
from torch.optim import Adam
from torch import from_numpy

from random import randint


class FindParameter(Module):
    def __init__(self):
        super(FindParameter, self).__init__()
        self.layers = Sequential(
            Linear(1, 10),
            ReLU(),
            Linear(10, 100),
            ReLU(),
            Linear(100, 10),
            ReLU(),
            Linear(10, 1),
        )

    def forward(self, input):
        return self.layers(input)


a = 5.0
x = []
y = []
train_dataset_size = 10000
for i in range(train_dataset_size):
    x.append(randint(0, 10000))
    y.append(x[i] * a)

X = [from_numpy(np.array([c], dtype=np.float32)) for c in x]
Y = [from_numpy(np.array([c], dtype=np.float32)) for c in y]
A = from_numpy(np.array([a], dtype=np.float32))

epochs = range(100)

model = FindParameter()
loss_f = CrossEntropyLoss()
optimizer = Adam(model.parameters(), lr=1e-3)


for epoch in epochs:
    for x, y in zip(X, Y):
        optimizer.zero_grad()
        a_pred = model(x)
        y_pred = a_pred * x

        loss = loss_f(y_pred, y)
        loss.backward()
        optimizer.step()
</code></pre>
","2024-03-01 15:22:42","1","Question"
"78077402","78077221","","<p>You seem to be trying to pass the output from a CNN layer directly into the quantum layer without ensuring the dimensions are compatible.</p>
<p>Try adjusting the dimensions of the input tensor before passing it to the quantum layer. Maybe, add a layer before <code>qlayer</code> in your <code>ImageClassifier</code> which flattens or somehow processes the output of the previous layers to match the expected input size of the quantum layer.</p>
","2024-02-28 20:29:26","0","Answer"
"78077221","","Stuck in Dimension problem in building QNN with pytorch","<h4>I'm attempting to build a Quantum Neural Network (QNN) using PyTorch and PennyLane. However, I'm encountering a dimension error specifically when defining the quantum layer.</h4>
<p>I have successfully set up my PyTorch and PennyLane environment, but when I try to define the quantum layer using PennyLane, I receive a dimension error. I suspect this might be due to a mismatch in the dimensions of my input data and the expected input shape of the quantum layer.</p>
<h2>My Code:</h2>
<pre><code># Get data 
train = datasets.MNIST(root=&quot;data&quot;, download=True, train=True, transform=ToTensor())
dataset = DataLoader(train, 32)
n_qubits = 2
dev = qml.device(&quot;default.qubit&quot;, wires=n_qubits)

@qml.qnode(dev)
def qnode(inputs, weights_0, weight_1):
    print(inputs)
    qml.RX(inputs[0], wires=0)
    qml.RX(inputs[1], wires=1)
    qml.Rot(*weights_0, wires=0)
    qml.RY(weight_1, wires=1)
    qml.CNOT(wires=[0, 1])
    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))
weight_shapes = {&quot;weights_0&quot;: 3, &quot;weight_1&quot;: 1}
qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)
print(qlayer)
class ImageClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(qlayer,
            nn.Conv2d(1, 32, (3, 3)),
            nn.ReLU(),
            nn.Conv2d(32, 64, (3, 3)),
            nn.ReLU(),
            nn.Conv2d(64, 64, (3, 3)),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64 * (28 - 6) * (28 - 6), 10)
        )

    def forward(self, x):
        result = self.model(x)
        return result
# Instance of the neural network, loss, optimizer
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
# Instance of the neural network, loss, optimizer
clf = ImageClassifier().to('cpu')
opt = Adam(clf.parameters(), lr=1e-3)
loss_fn = nn.CrossEntropyLoss()

# Training flow 
if __name__ == &quot;__main__&quot;:
    for epoch in range(1):  # train for 10 epochs
        for batch in dataset:
            X, y = batch
            X, y = X.to('cpu'), y.to(device)
            yhat = clf(X)
            loss = loss_fn(yhat, y)

            # Apply backprop 
            opt.zero_grad()
            loss.backward()
            opt.step()

        print(f&quot;Epoch:{epoch} loss is {loss.item()}&quot;)
</code></pre>
<h2>The Error I found:</h2>
<pre><code>RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-84-a98a57a9f607&gt; in &lt;cell line: 9&gt;()
     12             X, y = batch
     13             X, y = X.to('cpu'), y.to(device)
---&gt; 14             yhat = clf(X)
     15             loss = loss_fn(yhat, y)
     16 

10 frames
/usr/local/lib/python3.10/dist-packages/pennylane/qnn/torch.py in &lt;listcomp&gt;(.0)
    427 
    428         if len(x.shape) &gt; 1:
--&gt; 429             res = [torch.reshape(r, (x.shape[0], -1)) for r in res]
    430 
    431         return torch.hstack(res).type(x.dtype)

RuntimeError: shape '[896, -1]' is invalid for input of size 28
</code></pre>
","2024-02-28 19:51:40","0","Question"
"78070312","78067999","","<p>Please try:</p>
<pre><code>model.add(keras.Input(shape=(data.shape[1], )))
</code></pre>
<p>This works for me.</p>
<p>Please check docu for 'shape' argument:
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Input"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Input</a></p>
<blockquote>
<p>shape:<br />
A shape tuple (integers), not including the batch size. For
instance, shape=(32,) indicates that the expected input will be
batches of 32-dimensional vectors. Elements of this tuple can be None;
'None' elements represent dimensions where the shape is not known.</p>
</blockquote>
","2024-02-27 20:06:16","0","Answer"
"78068200","78067999","","<p>shape needs to be a tuple, but <code>(data.shape[1])</code> will give you an int. Try <code>(data.shape[1],)</code></p>
","2024-02-27 14:11:54","2","Answer"
"78067999","","raise ValueError(f""Cannot convert '{shape}' to a shape."") ValueError: Cannot convert '26' to a shape","<p>I am trying to create a Neural Network in Tensorflow using Keras for the first time but it keep giving this error please help
File &quot;C:\Users\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\backend\common\variables.py&quot;, line 406, in standardize_shape
raise ValueError(f&quot;Cannot convert '{shape}' to a shape.&quot;)
ValueError: Cannot convert '26' to a shape.</p>
<p>Process finished with exit code 1</p>
<p>This is the code
def create_neural_network(data):
&quot;&quot;&quot;Creates a neural network with 2 hidden layers of size 128 nodes each and a softmax output layer with 10 nodes for each class (genre)</p>
<pre><code>:param data (pandas.DataFrame): Input data
:return model: Neural network model
&quot;&quot;&quot;

# create network topology
model = keras.Sequential()

model.add(keras.Input(shape=(data.shape[1])))

# hidden layers
model.add(keras.layers.Dense(4096, activation=&quot;relu&quot;))
model.add(keras.layers.Dense(2048, activation=&quot;relu&quot;))
model.add(keras.layers.Dense(1024, activation=&quot;relu&quot;))
model.add(keras.layers.Dense(512, activation=&quot;relu&quot;))
model.add(keras.layers.Dense(256, activation=&quot;relu&quot;))
model.add(keras.layers.Dense(128, activation=&quot;relu&quot;))
model.add(keras.layers.Dense(64, activation=&quot;relu&quot;))

# output layer
model.add(keras.layers.Dense(10, activation=&quot;softmax&quot;))

optimizer = keras.optimizers.Adam(learning_rate=0.001)
model.compile(
    optimizer=optimizer, loss=&quot;sparse_categorical_crossentropy&quot;, metrics=&quot;accuracy&quot;
)

return model
</code></pre>
","2024-02-27 13:43:18","1","Question"
"78067997","78067871","","<p><strong>For question 1</strong>:</p>
<p>You want to maximize the TP for class_1 and class_2, regardless of potential &quot;errors&quot; (false positives in this case. It is recall you are interested in.</p>
<p>Because it's a multi-class classification problem and not a binary one, you cannot use the built-in metrics by default; you need to write a custom callback.</p>
<p>For example, a custom callback can be this one:</p>
<pre><code>class MultiClassRecallCallback(tf.keras.callbacks.Callback):
    def __init__(self, validation_data, average='macro', zero_division=0):
        super(MultiClassRecallCallback, self).__init__()
        self.validation_data = validation_data
        self.average = average
        self.zero_division = zero_division

    def on_epoch_end(self, epoch, logs=None):
        val_x, val_y_true = self.validation_data
        #Here if you cannot predict everything at once,
        #make sure you do batch predictions and then flatten
        val_y_pred = np.argmax(self.model.predict(val_x), axis=1)
        
        recall = recall_score(val_y_true, val_y_pred, average=self.average, zero_division=self.zero_division)
        print(f'\nEpoch {epoch+1}: Recall is {recall}'

# The zero division is to put recall to 0 if there are no TP and FN
recall_callback = MultiClassRecallCallback(validation_data(X_val,y_val), average='macro', zero_division=0)

model.fit(X_train, y_train, validation_data=(X_val, y_val),
          epochs=50, callbacks=[recall_callback])
</code></pre>
<p><strong>For question 2</strong>:</p>
<p>The number of neurons is always equal to the number of labels which you try to predict. If you believe that, for some data, there is a particular inherent noise, you can modify your dataset in which you add the fifth label in your example and assign those particular samples. This can indeed help your model better at distinguishing between your categories.</p>
","2024-02-27 13:43:08","0","Answer"
"78067871","","Keras model optimization","<p>I am trying to optimize my first AI with Google <code>colab</code> and <code>tensorflow</code>.</p>
<p>I have following <code>dataset</code> example:</p>
<div class=""s-table-container""><table class=""s-table"">
<thead>
<tr>
<th style=""text-align: left;"">classification</th>
<th>Feature 1</th>
<th>Feature 2</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: left;"">1</td>
<td>-1.1</td>
<td>0.22</td>
</tr>
<tr>
<td style=""text-align: left;"">1</td>
<td>0.333</td>
<td>-0.4</td>
</tr>
<tr>
<td style=""text-align: left;"">4</td>
<td>-0.55</td>
<td>0.6</td>
</tr>
</tbody>
</table></div>
<ul>
<li>Classes are values from <code>1</code> to <code>4</code>. The dataset contains 50% of each.</li>
<li>Values of the Features array are the Ratio between the real subject param and the average value</li>
</ul>
<blockquote>
<p>Example: If each row is a student data. And <code>Feature 1</code> is the examination mark. Value <code>-0.1</code> means that current student's mark <code>10% less</code> than others (average).</p>
</blockquote>
<p>Feature values could be greater than 1 (value 1.2 means +120%).</p>
<hr />
<p><strong>The goal of my model is to find students who we should care about.</strong>
So basically, I need to maximize the results for <code>true</code> predictions for classes 1 or 2. And prediction of classes 3 and 4 may not be as accurate.</p>
<blockquote>
<ul>
<li>It is preferable: if the real class is <code>1</code>, but the prediction is <code>3</code> - <code>4</code></li>
<li>Rather than: real class <code>3</code> - <code>4</code> is was predicted as <code>1</code> or <code>2</code></li>
</ul>
</blockquote>
<p><strong>I have the following model:</strong></p>
<pre><code>model = tf.keras.Sequential([
    tf.keras.layers.Dense(512, activation='tanh', input_shape=(82, )),
    tf.keras.layers.Dense(64, activation='tanh'),
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(4, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(x=features, y=labels, shuffle=True, validation_split=0.33, epochs=1)
</code></pre>
<p><strong>My questions are:</strong></p>
<ol>
<li>How can I configure metrics to calculate positive predictions for <code>class 1</code></li>
<li>Should the number of output neurons be always the same value as the class amount? Does it make sense to have +1 neurons to accumulate 'noisy' data here to optimize classes <code>1</code> and <code>2</code> accuracy predictions?</li>
</ol>
","2024-02-27 13:21:22","1","Question"
"78061579","78061528","","<p>You have two issues in the configuration:</p>
<ol>
<li><code>tf.keras.layers.Dense(1, activation='softmax')</code>, change this to <code>tf.keras.layers.Dense(2, activation='softmax')</code></li>
<li>Since your labels are in integer format, you need to change your loss function to <code>model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])</code></li>
</ol>
<p>Also, the way your dataset is formatted and by means of softmax, you will never have an output like you described :</p>
<blockquote>
<p>But I think that is should be smth like: [1: 0.4][2: 0.88]</p>
</blockquote>
<p>The sum of probabilities will always sum up to <code>1</code> in your context.</p>
","2024-02-26 14:14:33","0","Answer"
"78061528","","tensorflow output layer configuration for classification task","<p>I am trying to teach my first AI with <code>google colab</code> and <code>tensorflow</code>.</p>
<p><strong><code>.predict</code> method work is not clear to me.</strong></p>
<hr />
<p>I have following <code>dataset</code> example:</p>
<div class=""s-table-container""><table class=""s-table"">
<thead>
<tr>
<th style=""text-align: left;"">classification</th>
<th>Input 1</th>
<th>Input 2</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: left;"">1</td>
<td>0.1</td>
<td>0.22</td>
</tr>
<tr>
<td style=""text-align: left;"">1</td>
<td>0.333</td>
<td>0.4</td>
</tr>
<tr>
<td style=""text-align: left;"">4</td>
<td>0.55</td>
<td>0.6</td>
</tr>
</tbody>
</table></div>
<p>Expected classes are <code>1</code> or <code>4</code>. Dataset contains 50% of each.</p>
<p><strong>My code is:</strong></p>
<ol>
<li>Slice Data:</li>
</ol>
<pre><code>  features = df.iloc[1:, 1:]
  labels =  df.iloc[1:, 0]
</code></pre>
<ol start=""2"">
<li>Build Model:</li>
</ol>
<pre><code>model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='tanh', input_shape=(82,)),
    tf.keras.layers.Dense(2, input_shape=(256,), activation='tanh'),
    tf.keras.layers.Dense(1, activation='softmax')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>
<ol start=""3"">
<li>Train Model:</li>
</ol>
<pre><code>model.fit(x=features, y=labels, shuffle=True, epochs=1)
</code></pre>
<p><strong>Results</strong></p>
<p>result of <strong><code>.predict</code></strong> method is always <code>[[1.]]</code>.</p>
<p>But I think that is should be smth like:
<code>[1: 0.4][2: 0.88]</code></p>
<p>where: <code>1 and 4</code> are <code>classifications</code> and <code>0.4 and 0.88</code> are <code>probability</code></p>
","2024-02-26 14:07:14","0","Question"
"78056590","78056502","","<p>The error you're getting is because the output of your first layer (<code>fcs</code>) has dimension <code>N_HIDDEN</code> (which is 10), while the hidden layers in <code>fch</code> have input dimension <code>N_INPUT</code> (which is 2).</p>
<p>To fix this, you have to ensure that the input size for all layers matches the output size of the previous layer. In your code:</p>
<pre><code>class FCN(nn.Module):
    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):
        super().__init__()
        activation = nn.Tanh
        self.fcs = nn.Sequential(
            nn.Linear(N_INPUT, N_HIDDEN),
            activation()
        )
        self.fch = nn.Sequential(*[
            nn.Sequential(
                nn.Linear(N_HIDDEN, N_HIDDEN),  # Adjust input size to N_HIDDEN
                activation()
            ) for _ in range(N_LAYERS - 1)
        ])
        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)  # Output layer

    def forward(self, x):
        x = self.fcs(x)
        x = self.fch(x)
        x = self.fce(x)
        return x
</code></pre>
<p>Finally, to get good performance you should play with the hidden size (not just between 2 and 10, you can also try 100 or 1000), the number of layers (start with 1 or 2, not 8) and the learning rate of the optimizer.</p>
","2024-02-25 15:41:45","1","Answer"
"78056502","","Changing the number of hidden layers in my NN results in an error","<p>As the title says, if I change the number of hidden layers in my pytorch neural network to be anything different from the amount of input nodes it returns the error below.</p>
<blockquote>
<p>RuntimeError: mat1 and mat2 shapes cannot be multiplied (380x10 and 2x10)</p>
</blockquote>
<p>I think that the architecture is incorrectly coded but I am relatively new to pytorch and neural networks so I can't spot the mistake. Any help is greatly appreciated, I've included the code below</p>
<pre><code>class FCN(nn.Module):

def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):
    super().__init__()
    activation = nn.Tanh
    self.fcs = nn.Sequential(*[
        nn.Linear(N_INPUT, N_HIDDEN),
        activation()])
    self.fch = nn.Sequential(*[
                  nn.Sequential(*[
                      nn.Linear(N_INPUT, N_HIDDEN),
                      activation()]) for _ in range(N_LAYERS-1)])
    self.fce = nn.Linear(N_INPUT, N_HIDDEN)

def forward(self, x):

    x = self.fcs(x)
    x = self.fch(x)
    x = self.fce(x)
    
    return x


torch.manual_seed(123)

pinn = FCN(2, 2, 10, 8)
</code></pre>
<p>If the pinn architecture is defined as <code>pinn = FCN(2, 2, 2, 8)</code> no errors are returned but neural network does not perform well.</p>
<p>Other information:</p>
<ul>
<li>the input is a matrix tensor with a batch size of 380</li>
</ul>
<p>Please let me know if you need anymore information and thank you!</p>
","2024-02-25 15:17:38","1","Question"
"78053841","78053086","","<p>In the example below, I first solve the ODE using a standard solver <code>scipy.integrate.solve_ivp</code>. The solution is used to train the network, as it gives us a target <code>y</code> for each <code>t</code>. The net will learn parameters such that given <code>t</code> and <code>y0</code>, it will closely match the reference <code>y</code>.</p>
<p>After training, you can supply <code>t</code> and <code>y0</code> to the network, and it will output the estimated solution <code>y_hat</code> for each <code>t</code>.</p>
<p>Note that this example is somewhat minimal - you'd usually want to be evaluating the model on samples it hasn't seen (a validation set), otherwise it might just be memorising the training data without being able to generalise to unseen <code>t</code> (though maybe it's not an issue for your use-case).</p>
<pre class=""lang-py prettyprint-override""><code>Net comprises 501 parameters
[epoch  100/ 500] loss: 0.00044
[epoch  200/ 500] loss: 0.00015
[epoch  300/ 500] loss: 0.00011
[epoch  400/ 500] loss: 0.00008
[epoch  500/ 500] loss: 0.00004
</code></pre>
<p><a href=""https://i.sstatic.net/KfHXP.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/KfHXP.png"" alt=""enter image description here"" /></a></p>
<pre class=""lang-py prettyprint-override""><code>import torch
from torch import nn
from torch import optim

import numpy as np
import matplotlib.pyplot as plt

#Input data
n_samples = 100
t_array = np.linspace(0, 2, num=n_samples)
y0 = 1.0

#ODE function
# dy/dt + 2y + t = 0 --&gt; dy/dt = -(2y + t)
def dy_dt(t, y):
    return -(2 * y + t)

#Solve using scipy
# The solution will be used to train the neural network
from scipy.integrate import solve_ivp
solved = solve_ivp(dy_dt, [t_array.min(), t_array.max()], np.array([y_0]), t_eval=t_array)
solved_y = solved.y.ravel()

plt.plot(t_array, solved_y, color='cadetblue', linewidth=3, label='RK45 solver')
plt.xlabel('t')
plt.ylabel('y')
plt.gcf().set_size_inches(8, 3)

#
# Define the ODE net
#
class ODENet(nn.Module):
    def __init__(self, model_size=20, output_dim=1, activation=nn.ReLU):
        super().__init__()
        
        self.map_inputs = nn.Sequential(nn.Linear(2, model_size), activation())
        
        self.hidden_mapping = nn.Sequential(
            nn.Linear(model_size, model_size),
            activation()
        )
        
        self.output = nn.Linear(model_size, output_dim)
    
    def forward(self, x):
        # t, y0 = x[:, 0], x[:, 1]
        mapped_inputs = self.map_inputs(x)
        hidden = self.hidden_mapping(mapped_inputs)
        y_hat = self.output(hidden)
        return y_hat
    
print('Net comprises', sum([p.numel() for p in ODENet().parameters()]), 'parameters')

#Define the loss
# could alternatively pick from PyTorch's provided losses
def mse_loss(pred, target):
    return torch.mean((pred - target) ** 2)

#
# Create model
#
torch.manual_seed(0) #reproducible results

model = ODENet()
optimizer = optim.NAdam(model.parameters())

#Prepare the input data
# Convert to tensors
t_tensor = torch.Tensor(t_array).float().reshape(-1, 1)
y0_tensor = torch.Tensor([y0] * len(t_array)).float().reshape(-1, 1)
solved_y_tensor = torch.Tensor(solved_y).float()

# Combine inputs into a single matrix to make manpulation more compact
t_y0 = torch.cat([t_tensor, y0_tensor], dim=1)

#Scale the input features
# Will help the net's convergence, though not always abs necessary
t_y0 = (t_y0 - t_y0.mean(dim=0)) / (t_y0.std(dim=0) + 1e-10)

#
#Train model
#
n_epochs = 500
for epoch in range(n_epochs):
    model.train()
    
    y_hat = model(t_y0).flatten()

    #Loss, derivative, and step optimizer
    optimizer.zero_grad()
    loss = mse_loss(y_hat, solved_y_tensor)
    loss.backward()
    optimizer.step()
    
    #Print losses
    if ((epoch + 1) % 100) == 0 or (epoch + 1 == n_epochs):
        print(
            f'[epoch {epoch + 1:&gt;4d}/{n_epochs:&gt;4d}]',
            f'loss: {loss.item():&gt;7.5f}'
        )

#Get the final predictions, and overlay onto the solver's solution
model.eval()
with torch.no_grad():
    predictions = model(t_y0)
    
plt.plot(t_array, predictions, color='sienna', linewidth=3, linestyle=':', label='ODENet')
plt.legend()

#Optional formatting
[plt.gca().spines[spine].set_visible(False) for spine in ['right', 'top']]
plt.gca().spines['bottom'].set_bounds(t_array.min(), t_array.max())
plt.gca().spines['left'].set_bounds(-0.75, 1)
</code></pre>
","2024-02-24 20:13:16","1","Answer"
"78053086","","solving an ODE using neural networks","<p>I want to solve this ODE using neural nets. du/dt + 2u + t = 0 with initial condition u(0)=1 and t is between 0 to 2.
I want to use pytorch and automatic differentiation method to solve this equation. but I don't know how can I calculate du/dt in pytorch.
I want to define loss function as below and minimize it to find optimum weights and biases of the neural net.
u_hat is an approximate solution of ODE which is substituted with neural network.
R = du_hat/dt + 2*u_hat + t.
loss function = sum(R<sub>i</sub>^2).
loss function is the sum of R<sub>i</sub> which is calculated in the points t = 0, 0.5, 1, 1.5, 2.</p>
<p>I don't know how can I write the code in pytorch.</p>
","2024-02-24 16:16:51","1","Question"
"78052896","78052275","","<p>Not commenting much on SHAP below, but I have some thoughts on potential alternatives. Example code at the end.</p>
<blockquote>
<p>It takes forever to finish, since the dataset contains 950 samples, I have tried to do it with only 1 sample and it takes long enough [...] Should I try other methods?</p>
</blockquote>
<p>Since SHAP is taking so long, I think it's worth considering other techniques if you think they can provide useful information which you can iterate on more quickly.</p>
<p>One approach is to run permutation importance tests (example code at end). Start by training a 'good' reference model, and getting the model's reconstruction and reconstruction error using the original data. Then, for each <code>feature_i</code></p>
<ul>
<li>Shuffle <code>feature_i</code></li>
<li>Record the model's reconstruction and recon error, and calculate the difference with the original result.</li>
<li>You could optionally normalise the results by the sum of all changes, so that you get scores that sum to 1 across all features.</li>
</ul>
<p>This information will allow you to plot feature vs. change in recon, or feature vs. change in recon error. The first plot tells you how each feature impacts the model's output, and can be viewed as an approximation of SHAP (though I view it as a distinct and useful method in its own right). The second plot tells you how each feature impacts reconstruction accuracy. This method is relatively fast as you only need to train the model once.</p>
<p>A limitation of this method is that if features are highly correlated, permutation tests can underestimate or miss a feature's importance (SHAP doesn't). There are ways of mitigating this, such as assessing correlations in advance and removing or grouping related ones.</p>
<p>An alternative way of assessing feature importance for an autoencoder is to record the latent representation of each sample. You can run a mutual information analysis to see the strength of association between a feature and the latent space representation. Some features might explain more of the compressed representation than others, suggesting a relative importance.</p>
<p>Other techniques could look at the size of the weight learnt for each feature (perhaps in combination with a sparsity penalty), or activation sizes.</p>
<p>For any given method, consider running it on just a portion of the dataset in order to save time, or training for only a few epochs. The results will be more approximate, but may be good enough for assessing relative feature importances.</p>
<p>To minimise overfitting, you might want to run the fitting on part of the data, and then get your recons and recon errors using an unseen validation sample.</p>
<hr />
<p>The code below trains an autoencoder on petal features and runs a permutation test on the features. In this example some the features were highly correlated, and since I didn't handle that I'm not going to rely on the results below. The figures are just illustrative of what the code does.</p>
<p><a href=""https://i.sstatic.net/4HQk5.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4HQk5.png"" alt=""enter image description here"" /></a></p>
<p>Imports and prepare data</p>
<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#
# Load data
#
from sklearn.datasets import load_iris
from sklearn.preprocessing import QuantileTransformer
from sklearn.model_selection import train_test_split

X, y  = load_iris(return_X_y=True, as_frame=True)
y.name = 'species'
X = pd.concat([X, y.to_frame()], axis=1)
n_features = X.shape[1]

trn_val_ix, tst_ix = train_test_split(range(len(X)), test_size=0.1, random_state=0)
trn_ix, val_ix = train_test_split(trn_val_ix, test_size=0.2, random_state=0)

X_trn, X_val, X_tst = X.iloc[trn_ix], X.iloc[val_ix], X.iloc[tst_ix]

#To numpy arrays, and scale
scaler = QuantileTransformer(output_distribution='uniform', n_quantiles=10, random_state=0).fit(X_trn.values)
X_trn_a, X_val_a, X_tst_a = [scaler.transform(data.values) for data in [X_trn, X_val, X_tst]]

# To tensors
import torch
from torch import nn
from torch import optim
from torch.utils.data import DataLoader

X_trn_t, X_val_t, X_tst_t = [torch.Tensor(data).float()
                             for data in [X_trn_a, X_val_a, X_tst_a]]
</code></pre>
<p>Define a simple autoencoder and a training loop:</p>
<pre class=""lang-py prettyprint-override""><code>#
#Define a simple autoencoder
#
def make_autoencoder(latent_dim_size=3, hidden_size=5):
    activation = nn.Tanh
    encoder = nn.Sequential(
        nn.Linear(n_features, n_features),
        activation(),
        nn.Linear(n_features, hidden_size),
        activation(),
        nn.Linear(hidden_size, latent_dim_size),
    )

    decoder = nn.Sequential(
        activation(),
        nn.Linear(latent_dim_size, hidden_size),
        activation(),
        nn.Linear(hidden_size, n_features),
        activation(),
        nn.Linear(n_features, n_features)
    )

    autoencoder = nn.Sequential(encoder, decoder)
    return autoencoder

print('Model size:', sum([p.numel() for p in make_autoencoder().parameters()]))

@torch.no_grad()
def eval_metric(model, loader):
    model.eval()

    cum_rmse_pct = 0
    for X_minibatch in loader:
        output = model(X_minibatch)
        rmse_pct = (output - X_minibatch).norm(dim=1) / X_minibatch.norm(dim=1) * 100
        cum_rmse_pct += rmse_pct.sum()
    
    return (cum_rmse_pct / loader.dataset.shape[0]).item()

def train(model, loader, optimiser, n_epochs=1, loss_fn=nn.functional.mse_loss):
    metrics = {'train_loss': [], 'train_metric': [], 'val_metric': []}
    
    for epoch in range(n_epochs):
        model.train()
        cum_loss = 0
        
        for minibatch, X_minibatch in enumerate(loader):
            output = model(X_minibatch)
            
            loss = loss_fn(output, X_minibatch)
            optimiser.zero_grad()
            loss.backward()
            optimiser.step()
            
            cum_loss += loss.item() * len(X_minibatch)
        
        #Record metrics
        metrics['train_loss'].append(cum_loss / loader.dataset.shape[0])
        metrics['train_metric'].append(eval_metric(autoencoder, train_loader))
        metrics['val_metric'].append(eval_metric(autoencoder, val_loader))
        
        #Print epoch average loss
        if (epoch + 1) % 20 == 0 or (epoch == n_epochs - 1):
            print(
                f'[epoch {epoch + 1:&gt;3d}][minibatch {minibatch + 1:&gt;3d}/{len(loader):&gt;3d}]',
                f'train loss {metrics[&quot;train_loss&quot;][-1]:&gt;6.3f} |',
                f'train metric {metrics[&quot;train_metric&quot;][-1]:&gt;6.2f} | '
                f'val metric {metrics[&quot;val_metric&quot;][-1]:&gt;6.2f}'
            )
    
    return metrics
</code></pre>
<p>Train the model. Calling it good at ~13% reconstruction error.</p>
<pre class=""lang-py prettyprint-override""><code>#Register optimiser and define data loaders
batch_size = 4
n_epochs = 200

torch.manual_seed(0)
autoencoder = make_autoencoder()
optimiser = optim.NAdam(autoencoder.parameters())
# optimiser = optim.SGD(autoencoder.parameters(), lr=1e-3, momentum=0.9)

train_loader = DataLoader(X_trn_t, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader = DataLoader(X_val_t, batch_size=batch_size, num_workers=2)

history = train(autoencoder, train_loader, optimiser, n_epochs=n_epochs)

f, ax = plt.subplots(figsize=(10, 3))
ax.plot(history['train_loss'], linestyle='--', label='loss')
ax2 = ax.twinx()
ax2.plot(history['train_metric'], label='train metric')
ax2.plot(history['val_metric'], label='val metric')

ax.set_xlabel('epoch')
ax.set_ylabel('loss')
ax2.set_ylabel('rmse %')
f.legend()
</code></pre>
<p><a href=""https://i.sstatic.net/ayOWw.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/ayOWw.png"" alt=""enter image description here"" /></a></p>
<pre class=""lang-py prettyprint-override""><code>[epoch  20][minibatch  27/ 27] train loss  0.021 | train metric  26.33 | val metric  41.81
[epoch  40][minibatch  27/ 27] train loss  0.016 | train metric  23.17 | val metric  36.84
[epoch  60][minibatch  27/ 27] train loss  0.006 | train metric  13.34 | val metric  17.87
[epoch  80][minibatch  27/ 27] train loss  0.006 | train metric  12.97 | val metric  16.94
[epoch 100][minibatch  27/ 27] train loss  0.005 | train metric  12.60 | val metric  16.59
[epoch 120][minibatch  27/ 27] train loss  0.005 | train metric  12.32 | val metric  16.10
[epoch 140][minibatch  27/ 27] train loss  0.005 | train metric  11.80 | val metric  15.49
[epoch 160][minibatch  27/ 27] train loss  0.004 | train metric  10.89 | val metric  14.62
[epoch 180][minibatch  27/ 27] train loss  0.004 | train metric  10.52 | val metric  14.28
[epoch 200][minibatch  27/ 27] train loss  0.003 | train metric   9.63 | val metric  13.54
</code></pre>
<p>On that trained model, run permutation tests for each feature, and plot the results. Plotted are the model's drop in performance, and a bar plot of normalised results (which can be interpreted as feature importances). These results are shown at the start of this example.</p>
<p>Permutation tests:</p>
<pre class=""lang-py prettyprint-override""><code>rng = np.random.default_rng(0)

#Model's val score before permutation
unpermuted_rmse_pct = history['val_metric'][-1]

n_repeats = 50 #number of trials per feature
permutation_metrics = np.empty([n_features, n_repeats])

#Shuffle each feature in turn, and get model's score
for col_idx, col_name in enumerate(X_val.columns):
    X_val_perm = X_val_t.clone()
    
    for repeat in range(n_repeats):
        shuffled_ixs = rng.permutation(len(X_val))
        X_val_perm[:, col_idx] = X_val_t[shuffled_ixs, col_idx]
        
        val_loader = DataLoader(X_val_perm, batch_size=batch_size, shuffle=True)
        permutation_metrics[col_idx, repeat] = eval_metric(autoencoder, val_loader)

#Convert to change in score compared to unpermuted data
permutation_df = pd.DataFrame(permutation_metrics.T, columns=X_val.columns) - unpermuted_rmse_pct
</code></pre>
<p>Plotting:</p>
<pre class=""lang-py prettyprint-override""><code>#Box plot of change in score
import seaborn as sns
permutation_melt = permutation_df.melt(var_name='feature', value_name='permuted_rmse_pct')
sns.boxplot(permutation_melt, y='feature', x='permuted_rmse_pct')
ax = sns.stripplot(permutation_melt, y='feature', x='permuted_rmse_pct', marker='.', color='tab:red')

ax.set_xlabel('drop in performance')
ax.set_ylabel('permuted feature')
ax.figure.set_size_inches(8, 2.5)
plt.show()

#Bar chart of feature importances
normalised_scores = permutation_df.mean(axis=0) / permutation_df.mean(axis=0).sum() #scores 0-1
ax = sns.barplot(normalised_scores, color='tab:purple')
ax.tick_params(axis='x', rotation=45)
ax.set_xlabel('feature')
ax.set_ylabel('feature importance')
ax.figure.set_size_inches(4, 3)
</code></pre>
","2024-02-24 14:56:48","2","Answer"
"78052275","","Feature Importance of a Pytorch AutoEncoder","<p>I need to get from my Pytorch AutoEncoder the importance it gives to each input variable. I am working with a tabular data set, no images.</p>
<p>My AutoEncoder is as follows:</p>
<pre><code>class AE(torch.nn.Module):
    def __init__(self, input_size, hidden_layer, latent_layer):
        super().__init__()

        self.encoder = torch.nn.Sequential(
            torch.nn.Linear(input_size, hidden_layer),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_layer, latent_layer)
        )

        self.decoder = torch.nn.Sequential(
            torch.nn.Linear(latent_layer, hidden_layer),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_layer, input_size)
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
</code></pre>
<p>To save unnecessary information, I simply call the following function to get my model:</p>
<pre><code>average_loss, model, train_losses, test_losses = fullAE(batch_size=128, input_size=genes_tensor.shape[1],
                                 learning_rate=0.0001, weight_decay=0,
                                 epochs=50, verbose=False, dataset=genes_tensor, betas_value=(0.9, 0.999), train_dataset=genes_tensor_train, test_dataset=genes_tensor_test)
</code></pre>
<p>Where &quot;model&quot; is a trained instance of the previous AutoEncoder:</p>
<pre><code>model = AE(input_size=input_size, hidden_layer=int(input_size * 0.75), latent_layer=int(input_size * 0.5)).to(device)
</code></pre>
<p>Well now I need to get the importance given by that model to each input variable in my original &quot;genes_tensor&quot; dataset, but I don't know how. I have researched how to do it and found a way to do it with shap software:</p>
<pre><code>e = shap.DeepExplainer(model, genes_tensor)

shap_values = e.shap_values(
    genes_tensor
)

shap.summary_plot(shap_values,genes_tensor,feature_names=features)
</code></pre>
<p>The problem with this implementation is the following: 1) I don't know if what I am actually doing is correct. 2) It takes forever to finish, since the dataset contains 950 samples, I have tried to do it with only 1 sample and it takes long enough. The result using a single sample is as follows:</p>
<p>I have seen that there are other options to obtain the importance of the input variables like Captum, but Captum only allows to know the importance in Neural Networks with a single output neuron, in my case there are many.</p>
<p>The options for AEs or VAEs that I have seen on github do not work for me since they use concrete cases, and especially images always, for example:</p>
<p><a href=""https://github.com/peterparity/PDE-VAE-pytorch"" rel=""nofollow noreferrer"">https://github.com/peterparity/PDE-VAE-pytorch</a></p>
<p><a href=""https://github.com/FengNiMa/VAE-TracIn-pytorch"" rel=""nofollow noreferrer"">https://github.com/FengNiMa/VAE-TracIn-pytorch</a></p>
<p>Is my shap implementation correct?</p>
<p>Edit:</p>
<p>I have run the shap code with only 4 samples and get the following result:</p>
<p><a href=""https://i.sstatic.net/wzcDJ.png"" rel=""nofollow noreferrer"">shap with 4 samples</a></p>
<p>I don't understand why it's not the typical shap summary_plot plot that appears everywhere.</p>
<p>I have been looking at the shap documentation, and it is because my model is multi-output by having more than one neuron at the output.</p>
","2024-02-24 11:46:59","1","Question"
"78049931","","Graph Neural Network Custom Data","<p>I following this tutorial.
<a href=""https://colab.research.google.com/github/AntonioLonga/PytorchGeometricTutorial/blob/main/Tutorial3/Tutorial3.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/AntonioLonga/PytorchGeometricTutorial/blob/main/Tutorial3/Tutorial3.ipynb</a>
I want to try it on custom dataset. How do I use my own dataset instead of Cora ? I would love any idea.</p>
","2024-02-23 20:02:48","0","Question"
"78042556","78042365","","<blockquote>
<p>I believe the issue stems from params being a generator rather than a dictionary</p>
</blockquote>
<p>You are correct, the object you have is a generator while the <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict"" rel=""nofollow noreferrer""><code>load_state_dict</code></a> method expects a <em>dict</em>. The generator contains the parameters as an <em>array</em> of parameters while the dictionary contains each layer name - parameters <em>associations</em>. Converting a generator to a dictionary is not possible because a generator has no information about which parameters correspond to which layer, ie. in general you wouldn't be able to assign each parameter to the correct layer of the target model.</p>
","2024-02-22 16:22:05","0","Answer"
"78042365","","Error Loading State Dictionary in PyTorch: TypeError Encountered","<p>I'm encountering an issue while trying to load the state dictionary in PyTorch. Here's a breakdown of my situation:</p>
<ol>
<li><p>I have a model named model_fg</p>
</li>
<li><p>During training, I return its parameters using <code>model_fg.parameters()</code>.</p>
</li>
<li><p>I use the Adam optimizer in training with the following line of code:</p>
<p><code>state = optim.Adam(params, lr=lr)</code>
where params is of type <code>&lt;class 'generator'&gt;</code>.</p>
</li>
<li><p>In the evaluation phase, I attempt to load the trained parameters using:</p>
<pre><code>model.load_state_dict(trained_params)
</code></pre>
</li>
</ol>
<p>But I encoutere the error:</p>
<pre><code>TypeError: Expected state_dict to be dict-like, got &lt;class 'generator'&gt;
</code></pre>
<p>I believe the issue stems from params being a generator rather than a dictionary. I'm considering converting the generator to a dictionary, but I'm unsure how to proceed.</p>
<p>How to address this issue?</p>
","2024-02-22 15:57:20","0","Question"
"78040404","","Can I use neuronal networks from the R package nnet to model compositional data?","<p>I am working with compositional data (proportions that sum up to 1) in R and I have already tried Dirichlet regressions as a parametric approach for modelling and predict on new data. I would like to test non-parametric approaches such as neural networks, random forest or CNN and I found the package <code>nnet</code> with the function <code>multinom()</code>, which in the manual says that &quot;Fits multinomial log-linear models via neural networks&quot;. However, I also found in another <a href=""https://stackoverflow.com/questions/9969440/when-using-the-multinom-function-from-the-nnet-package-how-can-i-control-the-ar"">question</a> that this function is not really calling any <code>neural network</code> whatsoever since the argument <code>size</code> (size of the hidden layer) is set to 0, which converts this function into a parametric approach if I understood correctly.</p>
<p>In the same question, it was suggested to just use <code>nnet()</code>function with a response with more than 2 levels, and set <code>softmax=TRUE</code>, but I dont know how to do this and I get an error if I try to model directly the proportions (see reproducible example).</p>
<p>Given an reproducble example dataset like this one:</p>
<pre><code>set.seed(123)
n &lt;- 300 # Number of observations

# Simulate predictor variables
data &lt;- as.data.frame(matrix(runif(n * 10), nrow = n, ncol = 10))
names(data) &lt;- paste0(&quot;V&quot;, 1:10)

# Simulate proportions for A, B, C that sum to 1
proportions &lt;- matrix(runif(n * 3), ncol = 3)
row_sums &lt;- rowSums(proportions)
proportions &lt;- sweep(proportions, 1, row_sums, &quot;/&quot;)
data$prop_A &lt;- proportions[,1]
data$prop_B &lt;- proportions[,2]
data$prop_C &lt;- proportions[,3]

# Split into train/test
train_indices &lt;- sample(1:n, size = 0.8 * n)
train_data &lt;- data[train_indices, ]
test_data &lt;- data[-train_indices, ]

# Fit nnet model with softmax=TRUE
model &lt;- nnet(prop_A + prop_B + prop_C ~., data = train_data, size = 2, softmax = T)
&gt;
&gt; Error in nnet.default(x, y, w, ...) : 
&gt;   'softmax = TRUE' requires at least two response categories
&gt;
</code></pre>
<p>I would like to know if <code>nnet</code> is a plausible non-parametric approach to model compositinoal data and how would an experienced person takkle this problem.</p>
","2024-02-22 11:04:08","1","Question"
"78036165","78034992","","<p>Your <code>adjacency_matrix</code> isn't updated because it's not a <code>nn.Parameter</code>.</p>
<p>Your <code>subdiagonal_block</code> isn't updated because it's not used in your forward pass.</p>
","2024-02-21 17:57:22","2","Answer"
"78034992","","Pytorch custom network doesn't update the weights matrix","<p>I have written this simple custom network for a linear classifier on MNIST.</p>
<p>The kick is that the model operates trough a <em>global adjacency matrix</em> of the entire network to perform the calculations. The matrix is almost all zeroes, with only the bottom left block being non zero.</p>
<p>The model itself is very basic, only two layers, without any non linearity. The problem is that in the learning process the <strong>adjacency matrix does not get updated</strong>, so the model does not learn, I don't know why. I have tested my training loop on more standard architectures and all works fine (I am using SGD with cross entropy loss), so the problem must be in how I have specified the class of the network. For me it is crucial to operate trough this global adjacency matrix, and I would like to understand where the problem is, and how to make it work.</p>
<pre><code>class Simple_Direct_Network_Adjacency_Matrix_Implementation_Dim2(nn.Module):
def __init__(self, input_dim , middle_dim, output_dim):
    super().__init__()
    self.input_dim = input_dim
    _ = middle_dim #This is an hack: we want dim 2 now, so this input to the class gets ignored
    self.output_dim = output_dim
    self.total_dim = self.input_dim + self.output_dim

    self.subdiagonal_block = nn.Parameter(torch.empty(self.output_dim, self.input_dim))
    nn.init.normal_(self.subdiagonal_block , mean=0 , std=0.1)

    self.adjacency_matrix = self.make_subdiagonal_matrix().requires_grad_(requires_grad=True)


def make_subdiagonal_matrix(self):
    over_block = torch.zeros(self.input_dim, self.input_dim)
    side_block = torch.zeros(self.total_dim, self.output_dim)

    matrix = torch.cat((over_block , self.subdiagonal_block), 0)
    matrix = torch.cat((matrix, side_block), 1)

    return matrix

def forward(self, batch_of_inputs):
    # Flatten the batch of input images
    flat_inputs = batch_of_inputs.view(-1 , batch_of_inputs.size(0))

    # Append zeros to match
    flat_inputs_total = torch.cat((flat_inputs, torch.zeros(self.output_dim , flat_inputs.size(1))), dim=0)

    # Perform matrix multiplication
    y_total_final = torch.mm(self.adjacency_matrix , flat_inputs_total)

    # Extract logits
    logits = y_total_final[-self.output_dim: , :].t()

    return logits
</code></pre>
<p>Note that I have also tryed omitting the requires grad, and nothing changes, I don't know if it is necessary. Also note that the matrix of parameters, the one specified with <code>nn.Parameter()</code> also doesn't change. Note also that moving the construction of the adjacency matrix inside the forward function also seems to not solve the problem..</p>
","2024-02-21 14:55:42","0","Question"
"78028924","78025895","","<p>To generate an output with the model you can simply call the model on an input <code>X</code>:</p>
<pre><code>y_pred = model(X)
</code></pre>
<p>An example implementation of your script could be:</p>
<pre><code>torch.manual_seed(42)

N = 1000  # number of samples
D = 2     # Input dimension
C = 1     # Output dimension
lr = 1e-1 # learning rate

X = torch.rand(N, D)                      # 1000 numbers of 2 dims
y = torch.sum(X, axis=-1).reshape(-1, C)  # This is summing X rows and reshaping it to 1 output dimension

print(f&quot;X.shape: {X.shape}, y.shape:{y.shape}&quot;)
print(f&quot;X[:5]: {X[:5]}&quot;)
print(f&quot;y[:5]: {y[:5]}&quot;)

model = torch.nn.Sequential(torch.nn.Linear(D, C))
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)

print(&quot;\nTraining model&quot;)
for i in range(500):
    y_pred = model(X)
    loss = criterion(y_pred, y)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    if i % 50 == 0:
        print(f&quot;Epoch: {i+1:&lt;5} loss: {loss.item()}&quot;)

print(&quot;\nTesting trained model on new random numbers&quot;)
for i in range(5):
    X = torch.rand(1, D)
    y_pred = model(X)
    print(f&quot;{X[:, 0].item():.2f} + {X[:, 1].item():.2f} = {X.sum().item():.2f}, predicted: {y_pred.item():.2f}&quot;)

print(f&quot;\nModel learned weights and biases\n{model.state_dict()}&quot;)
</code></pre>
<p>This is the output of the above implementation:</p>
<pre><code>X.shape: torch.Size([1000, 2]), y.shape:torch.Size([1000, 1])
X[:5]: tensor([[0.8823, 0.9150],
        [0.3829, 0.9593],
        [0.3904, 0.6009],
        [0.2566, 0.7936],
        [0.9408, 0.1332]])
y[:5]: tensor([[1.7973],
        [1.3422],
        [0.9913],
        [1.0502],
        [1.0740]])

Training model
Epoch: 1     loss: 1.1976375579833984
Epoch: 51    loss: 0.013810846023261547
Epoch: 101   loss: 1.6199066521949135e-05
Epoch: 151   loss: 2.2864621485041425e-07
Epoch: 201   loss: 1.5489435289950393e-09
Epoch: 251   loss: 1.0740366929162803e-11
Epoch: 301   loss: 5.607882254811229e-14
Epoch: 351   loss: 4.732325513424554e-18
Epoch: 401   loss: 1.3877788466974007e-20
Epoch: 451   loss: 1.3877788466974007e-20

Testing trained model on new random numbers
0.29 + 0.47 = 0.77, predicted: 0.77
0.15 + 0.45 = 0.60, predicted: 0.60
0.57 + 0.48 = 1.05, predicted: 1.05
0.31 + 0.65 = 0.96, predicted: 0.96
0.37 + 0.22 = 0.59, predicted: 0.59

Model learned weights and biases
OrderedDict([('0.weight', tensor([[1., 1.]])), ('0.bias', tensor([2.3689e-09]))])
</code></pre>
<p>Note: I changed the learning rate from <code>1e-2</code> to <code>1e-1</code> so that the model optimization converges to a low training loss.</p>
<p>Also, you can verify that the trained model has weights <code>[[1., 1.]]</code> and bias <code>[2.3689e-09]</code>, which means that the model has learned to add two numbers as <code>y_pred = x_0 * 1 + x_1 * 1 + 2.3689e-09</code>.</p>
","2024-02-20 16:26:03","1","Answer"
"78025895","","MLP to learn addition","<p>I want to train a neural net to add two numbers. Using some examples, I've got to here and have achieved a low loss. I want to generate new numbers and pass them to the model to see what the outcomes are, and start to give it two numbers to see what it predicts. Here's what I have:</p>
<pre><code>torch.manual_seed(42)

N = 1000  # number of samples
D = 2     # Input dimension
C = 1     # Output dimension
lr = 1e-2 # learning rate

X = torch.rand(N, D)                      # 1000 numbers of 2 dims
y = torch.sum(X, axis=-1).reshape(-1, C)  # This is summing X rows and reshaping it to 1 output dimension

# print(X\[:50\])

# print(y\[:50\])

model = torch.nn.Sequential(torch.nn.Linear(D, C))

criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)

for i in range(500):
    y_pred = model(X)
    loss = criterion(y_pred, y)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    if i % 50 == 0:
        print(i)
        print('---')
        print(loss)

idx = torch.tensor(\[3, 4\])
for i in range(20):
    n = model.generate(idx, 50)
    print(n)
</code></pre>
<p>I am not able to generate from this model and am not sure how.</p>
","2024-02-20 08:52:38","0","Question"
"78022287","78018487","","<p>Autocast doesn't transform the weights of the model, so weight grads will have the same dtype as the weights. You can try manually calling <code>.half()</code> on the model to change this. I'm not sure if there's a way to compute grads in fp16 while keeping the weights in fp32.</p>
<pre class=""lang-py prettyprint-override""><code>import torch
import torch.nn as nn

torch.set_default_device('cuda')

model = nn.Linear(8,1)
opt = torch.optim.SGD(model.parameters(), lr=1e-3)

x = torch.randn(12, 8, dtype=torch.float16)

with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=True):
    output = model(x)
    loss = output.mean()
loss.backward()
    
print(model.weight.grad.dtype)
# &gt; torch.float32

opt.zero_grad()

model.half()

with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=True):
    output = model(x)
    loss = output.mean()
loss.backward()
    
print(model.weight.grad.dtype)
# &gt; torch.float16
</code></pre>
<p>Additionally, some ops have numerical stability issues when computed in fp16. To avoid this, pytorch autocasts certain opts to fp32. You can find the full list <a href=""https://pytorch.org/docs/stable/amp.html#cuda-ops-that-can-autocast-to-float32"" rel=""nofollow noreferrer"">here</a>.</p>
<p>In your case, MSE loss (and really the <code>pow</code> function) autocast to fp32. This won't change the weight grad dtype in the example above, but worth noting if you see fp32 cropping up other places.</p>
","2024-02-19 16:51:37","2","Answer"
"78018487","","How to save memory using half precision while keeping the original weights in single?","<p>I'm trying to save memory while training a model that uses single precision weights by doing the calculations in half precision.</p>
<p>I tried using autocast, and the model does prediction in half precision as it should.
However the gradient produced is still in single precision.
This ruins both performance and memory savings.
Is there any way to instruct torch to calculate grads in half precision and use those to update the original single precision weights?</p>
<pre><code>import torch

class KekNet (torch.nn.Module):
    def __init__(self):
        super(KekNet, self).__init__()
        self.layer1 = torch.nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dtype=torch.float32)
    
    def forward(self, x, features=False):
        return self.layer1(x)

device = torch.device(&quot;cuda&quot;)


# HALF-DATA AUTOCAST

net = KekNet().to(device)

loss_l2  = torch.nn.MSELoss(reduction='none')
g_params = [{'params': net.parameters(), 'weight_decay': 0}]
optimizerG = torch.optim.RMSprop(g_params, lr=3e-5, alpha=0.99, eps=1e-07, weight_decay=0)
schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerG, T_max=300)

X = torch.randn((40,3,555,555), dtype=torch.float16, device =device)

with torch.autocast(device_type='cuda', dtype=torch.float16):
    Y_h=net(X)

Y = torch.randn_like(Y_h)
loss = loss_l2(Y_h, Y).mean()

loss.backward()

print(f&quot;-autocast\r\ndata precision: {X.dtype}\r\npred precision: {Y_h.dtype}\r\ngrad precision: {net.layer1.weight.grad.dtype}\r\n&quot;)

optimizerG.step()
schedulerG.step()
</code></pre>
<p>results in following:</p>
<pre><code>data precision: torch.float16
pred precision: torch.float16
grad precision: torch.float32
</code></pre>
","2024-02-19 05:26:05","-1","Question"
"78017271","78017072","","<p>Pytorch tracks parameters through specific constructor classes. It has no visibility into arbitrary lists.</p>
<p>To track your list of modules, you need to wrap it in a <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"" rel=""nofollow noreferrer"">nn.Sequential</a> or <a href=""https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html"" rel=""nofollow noreferrer"">nn.ModuleList</a></p>
<pre class=""lang-py prettyprint-override""><code>class Q_function(nn.Module):

    def __init__(self, input_size=3, hidden_size=5, num_layers=3, learning_rate=0.01):
        super(Q_function, self).__init__()
        self.input_size = input_size
        self.layers = []
        for i in num_layers:
            self.layers.append(nn.Linear(input_size, hidden_size)) 
            self.append(nn.ReLU())
        self.layers.append(nn.Linear(hidden_size,1))
        self.layers = nn.ModuleList(self.layers)
    
    def forward(self, x):
        out = self.layers[0](x)
        for lay in range(1,len(self.layers)):
            out = self.layers[lay](out)
        return out
</code></pre>
<p>That said, there are also a number of errors in your model code. You probably want something like this:</p>
<pre class=""lang-py prettyprint-override""><code>class Q_function(nn.Module):

    def __init__(self, input_size=3, hidden_size=5, num_layers=3, learning_rate=0.01):
        super(Q_function, self).__init__()
        self.input_size = input_size
        self.layers = [nn.Linear(input_size, hidden_size), nn.ReLU()]
        for i in range(num_layers-1):
            self.layers.append(nn.Linear(hidden_size, hidden_size)) 
            self.layers.append(nn.ReLU())
        self.layers.append(nn.Linear(hidden_size,1))
        self.layers = nn.Sequential(*self.layers)
    
    def forward(self, x):
        x = self.layers(x)
        return x
</code></pre>
","2024-02-18 20:21:11","2","Answer"
"78017072","","Why does my dynamic neural network have 0 parameters?","<p>I have defined the following neural network:</p>
<pre><code>class Q_function(nn.Module):

    def __init__(self, input_size=3, hidden_size=5, num_layers=3, learning_rate=0.01):
        super(Q_function, self).__init__()
        self.input_size = input_size
        self.layers = []
        for i in num_layers:
            self.layers.append(nn.Linear(input_size, hidden_size)) 
            self.append(nn.ReLU())
        self.layers.append(nn.Linear(hidden_size,1))
    
    def forward(self, x):
        out = self.layers[0](x)
        for lay in range(1,len(self.layers)):
            out = self.layers[lay](out)
        return out
</code></pre>
<p>When I run:</p>
<pre><code>net = Q_function()
list(net.parameters())
</code></pre>
<p>I get the output as an empty list <code>[]</code>. Can someone explain why the network has no parameters? How to register the parameters? How to fix this issue?</p>
","2024-02-18 19:14:17","0","Question"
"77993048","77987416","","<p>Sort by row = False</p>
<pre class=""lang-py prettyprint-override""><code>from torch_geometric.utils import sort_edge_index

sorted_edge_index = sort_edge_index(edge_index, num_nodes=self.num_nodes, sort_by_row=False)
x = self.graph_sage(coord.view(-1, 2), sorted_edge_index)
</code></pre>
<p><a href=""https://github.com/pyg-team/pytorch_geometric/discussions/8908"" rel=""nofollow noreferrer"">https://github.com/pyg-team/pytorch_geometric/discussions/8908</a></p>
","2024-02-14 08:59:18","0","Answer"
"77990796","77989807","","<p>There was a problem with python 3.12. Now I use python 3.11. Details here:</p>
<pre><code>Ultralytics YOLOv8.1.13 🚀 Python-3.11.5 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)
Setup complete ✅ (16 CPUs, 15.9 GB RAM, 213.6/232.3 GB disk)

OS                  Windows-10-10.0.19045-SP0
Environment         Windows
Python              3.11.5
Install             pip
RAM                 15.95 GB
CPU                 AMD Ryzen 7 3700X 8-Core Processor
CUDA                11.8

matplotlib          ✅ 3.8.2&gt;=3.3.0
numpy               ✅ 1.26.4&gt;=1.22.2
opencv-python       ✅ 4.9.0.80&gt;=4.6.0
pillow              ✅ 10.2.0&gt;=7.1.2
pyyaml              ✅ 6.0.1&gt;=5.3.1
requests            ✅ 2.31.0&gt;=2.23.0
scipy               ✅ 1.12.0&gt;=1.4.1
torch               ✅ 2.2.0+cu118&gt;=1.8.0
torchvision         ✅ 0.17.0+cu118&gt;=0.9.0
tqdm                ✅ 4.66.2&gt;=4.64.0
psutil              ✅ 5.9.8
py-cpuinfo          ✅ 9.0.0
thop                ✅ 0.1.1-2209072238&gt;=0.1.1
pandas              ✅ 2.2.0&gt;=1.1.4
seaborn             ✅ 0.13.2&gt;=0.11.0
</code></pre>
","2024-02-13 20:50:37","0","Answer"
"77989807","","NotImplementedError YOLO ultralitycs","<p>When launching neural network training, I get this error:</p>
<pre><code>NotImplementedError                       Traceback (most recent call last)
Cell In[1], line 5
      1 from ultralytics import YOLO
      3 model = YOLO('yolov8m.pt')
----&gt; 5 results = model.train(data='dataset_yolo8/data.yaml', epochs=100, imgsz=640) #, model='yolov8m.pt')

File c:\Users\Mugmazoid\AppData\Local\Programs\Python\Python312\Lib\site-packages\ultralytics\engine\model.py:601, in Model.train(self, trainer, **kwargs)
    598             pass
    600 self.trainer.hub_session = self.session  # attach optional HUB session
--&gt; 601 self.trainer.train()
    602 # Update model and cfg after training
    603 if RANK in (-1, 0):

File c:\Users\Mugmazoid\AppData\Local\Programs\Python\Python312\Lib\site-packages\ultralytics\engine\trainer.py:208, in BaseTrainer.train(self)
    205         ddp_cleanup(self, str(file))
    207 else:
--&gt; 208     self._do_train(world_size)

File c:\Users\Mugmazoid\AppData\Local\Programs\Python\Python312\Lib\site-packages\ultralytics\engine\trainer.py:322, in BaseTrainer._do_train(self, world_size)
    320 if world_size &gt; 1:
    321     self._setup_ddp(world_size)
--&gt; 322 self._setup_train(world_size)
    324 nb = len(self.train_loader)  # number of batches
    325 nw = max(round(self.args.warmup_epochs * nb), 100) if self.args.warmup_epochs &gt; 0 else -1  # warmup iterations
...
PythonTLSSnapshot: registered at ..\aten\src\ATen\core\PythonFallbackKernel.cpp:162 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at ..\aten\src\ATen\functorch\DynamicLayer.cpp:494 [backend fallback]
PreDispatch: registered at ..\aten\src\ATen\core\PythonFallbackKernel.cpp:166 [backend fallback]
PythonDispatcher: registered at ..\aten\src\ATen\core\PythonFallbackKernel.cpp:158 [backend fallback]  
</code></pre>
<p>All file paths are correct. Here's the entire code:</p>
<pre><code>from ultralytics import YOLO

model = YOLO('yolov8m.pt')

results = model.train(data='dataset_yolo8/data.yaml', epochs=100, imgsz=640, batch = 40) #, model='yolov8m.pt')
</code></pre>
<p>What could be the issue and how to fix it?</p>
","2024-02-13 17:25:59","0","Question"
"77987416","","Why does LSTM Aggregation in PyG need to sort edge_index?","<p><em>Hello, I have used <a href=""https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html"" rel=""nofollow noreferrer"">GraphSAGE</a> to do Node embedding. The function I chose to use for aggregate is <a href=""https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.LSTMAggregation.html#torch_geometric.nn.aggr.LSTMAggregation"" rel=""nofollow noreferrer"">LSTM</a> with the library of <a href=""https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html"" rel=""nofollow noreferrer"">PyG</a> for Graph Neural Network, the arguments it needs are follow:</em></p>
<p><strong>Input 1: Node features (|V|, F_in)</strong> - Here I use Node coordinates x-y in 2D plane (V x 2) and already normalized into the range of [0, 1] e.g.</p>
<pre><code>          x         y
0  0.374540  0.598658
1  0.950714  0.156019
2  0.731994  0.155995
</code></pre>
<p><strong>Input 2: Edge indices (2, |E|)</strong> - Adjacency matrix (V x V) but retrieves only the edge into (2, |E|)  from the original adjacency matrix I have e.g.</p>
<pre><code>idx   0  1  2
0   [[0, 1, 1], 
1    [1, 0, 1], 
2    [1, 1, 0]]
</code></pre>
<p>Above we have a shape (V x V) with 6 edges in the graph. We had to transform it a bit to accommodate PyG's use of shape (2, |E|) and I'd like to call it <code>edge_index</code> where edges is (0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1).</p>
<pre><code>idx   0  1  2  3  4  5
0   [[0, 0, 1, 1, 2, 2],
1    [1, 2, 0, 2, 0, 1]]
</code></pre>
<p><strong>Output: Node features (|V|, F_out)</strong> - Similar to Node coordinates, but they are not in 2D anymore, they are in a new embedding dimension with F_out dimensions.</p>
<p>My problem is that when using the LSTM aggregator it is forced to sort <code>edge_index</code> (Edge indices in input2) otherwise it will show an error saying <code>ValueError: Can not perform aggregation since the 'index' tensor. is not sorted.</code></p>
<p>So I have to do <a href=""https://pytorch.org/docs/stable/generated/torch.sort.html"" rel=""nofollow noreferrer"">sorting</a> gives it with the following command:</p>
<pre class=""lang-py prettyprint-override""><code># inside def __init__()
self.graph_sage=SAGEConv(in_channels=2, out_channels=hidden_dim, aggr='lstm')

# inside def forward()
sorted_edge_index, _ = torch.sort(edge_index, dim=1)  # for LSTM
x = self.graph_sage(coord.view(-1, 2), sorted_edge_index)  # using GraphSAGE
</code></pre>
<p>The <code>sorted_edge_index</code> tensor will look like this after sorting.</p>
<pre><code>idx   0  1  2  3  4  5
0   [[0, 0, 1, 1, 2, 2],
1    [0, 0, 1, 1, 2, 2]]
</code></pre>
<p>I noticed that in my full-mesh graph of 3 nodes connected, when I sorted it, the edges could be reinterpreted as (0, 0), (0, 0), (1, 1), (1, 1), (2, 2), (2, 2) which made me curious. And my questions are the following 2 things.</p>
<ol>
<li>Why does LSTM need to sort the <code>edge_index</code>?</li>
<li>After I sort <code>edge_index</code> like this, how will my model know which nodes are connected? Because all the original edge relationship pairs are gone. It's like sending edge pairs that don't exist in the graph as input. Will this be a disadvantage?</li>
</ol>
<p>I have tried doing the above and it ran fine. But I have some doubts and hope someone knowledgeable will help clarify things for a beginner like me. And I sincerely hope this question can be useful to other students studying GNN as well.</p>
","2024-02-13 11:04:01","0","Question"
"77982599","77978798","","<p>I just forgot that I should install PyTorch version with CUDA</p>
","2024-02-12 15:40:16","0","Answer"
"77978798","","Yolo doesn't use GPU","<p>When my nn starts learning, the kernel crashes</p>
<pre><code>The Kernel crashed while executing code in the current cell or a previous cell. 

Please review the code in the cell(s) to identify a possible cause of the failure. 

Click here for more info. 

View Jupyter log for further details.
</code></pre>
<p>Yolo doesn't use my GPU resources for learning instead it trying to use CPU and I think that it is a reason why kernel crashes.
How I can fix it?
<a href=""https://i.sstatic.net/yqpyO.png"" rel=""nofollow noreferrer"">screenshot</a></p>
<p>I tried to install CUDA 7.5 (for my RTX 2060). I recently started to study neural networks and I am not sure that I need CUDA.
I also checked similar topics here but I am not sure that there is my case.</p>
","2024-02-11 23:25:54","-4","Question"
"77968516","","Running R Keras model with custom loss crash when run twice on different data sets","<p>I am trying to develop some specific type of neural net with a special type of loss function. The loss is somewhat strange but in my project in actually make sens.</p>
<p>Any how I am trying to first set up the architecture and then fit the model to different data set x_train and y_train and x_train2 and y_train2.</p>
<p>I really don t get why it crashes when fitted to the x_train2 and y_train2.</p>
<p>Here is the error:</p>
<pre><code>Error in py_call_impl(callable, call_args$unnamed, call_args$named) : 
  RuntimeError: in user code:

    File  ...\DOCUME~1\VIRTUA~1\R-TENS~1\Lib\site-packages\keras\src\engine\training.py&quot;, line 1401, in train_function  *
        return step_function(self, iterator)
    File  ...\R\cache\R\renv\library\comoR-4eef73a7\R-4.3\x86_64-w64-mingw32\reticulate\python\rpytools\call.py&quot;, line 16, in python_function  *
        raise error

    RuntimeError: NA/NaN argument
</code></pre>
<p>and here a minimal reproducible example.</p>
<pre><code> rm(list=ls())
    y = rnorm(1000)
    x= rnorm (1000)
num_classes=10
mat &lt;- matrix( rnorm (1000*num_classes), ncol=num_classes)
x_train =x
y_train =mat
length(x_train)
dim(y_train)

model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = 64, activation = 'relu', input_shape = c(1)) %&gt;%
  layer_dense(units = 64, activation = 'relu' ) %&gt;%
  layer_dense(units = num_classes, activation = 'softmax')


custom_loss &lt;- function(y_true, y_pred) {
  tt &lt;- 0
  for (i in 1:nrow(y_true)) {
    tt &lt;- tt + log(sum(exp(y_true[i,]) * y_pred[i,]))
  }
  mse &lt;- -tt
  return(mse)
}
blank_model &lt;-  model %&gt;% compile(
  loss = custom_loss,
  optimizer = 'adam',
  metrics = c('accuracy')
)


model1 &lt;- blank_model
model2 &lt;- blank_model


history &lt;-model1 %&gt;% fit(
  x_train, y_train,
  epochs = 40,
  batch_size = 100
)

x_train2 =x[-1]
y_train2 =mat[-1,]

history &lt;-model2 %&gt;% fit(
  x_train2, y_train2,
  epochs = 40,
  batch_size = 100
)
</code></pre>
<p>The model should be easily fitted to different dataset but crashes instead without any clear reason.</p>
","2024-02-09 13:36:37","0","Question"
"77940911","77939004","","<p>You need to call <code>weights_initialization</code> method after <code>net</code> object is created. Also, set the <code>bias</code> inside the linear layers to <code>False</code> when manually adding <code>bias</code> values. There were also a few other fixes in the following codeL</p>
<pre><code>import torch
import torch.nn as nn


class NeuralNet(nn.Module):
    def __init__(self):    
        super().__init__()  
        self.fc1 = nn.Linear(in_features=1, out_features=2, bias=False)
        self.output = nn.Linear(in_features=2, out_features=1, bias=False)
        self.bias1 = torch.tensor([[2.]])
        self.bias2 = torch.tensor([[3.]])
        

    def act(self, x):
        return x**2

    def forward(self, x):
        x = self.act(self.fc1(x) + self.bias1)
        x = self.act(self.output(x) + self.bias2)

        return x

    def weights_initialization(self):
        with torch.no_grad():
            self.fc1.weight.copy_(torch.tensor([[0.2],
                                                [0.3]]))
            self.output.weight.copy_(torch.tensor([[1.5, 2.5]]))
    

net = NeuralNet()
net.weights_initialization()
input_data = torch.tensor([[5.]])
output = net(input_data)
print(output)
</code></pre>
","2024-02-05 12:24:22","0","Answer"
"77939004","","manually assigning weights, biases and activation function in pytorch","<p>I'm trying to build a neural network with nn.module in pytorch. I want to implement custom weights, biases and activation function.
with input value=5 and first layer weights= [[0.2, 0.3]] and second layer weights= [[1.5],[2.5]], first layer bias= 2 and second layer bias=3 and activation function y=x^2 the output value should obtain 2220.765625 but my code doesn't calculate this value. could you please help me to correct this code?</p>
<pre><code>import torch
import torch.nn as nn


class NeuralNet(nn.Module):
    def __init__(self):    
        super().__init__()  
        self.fc1 = nn.Linear(in_features=1, out_features=2)
        self.output = nn.Linear(in_features=2, out_features=1)
        self.bias1 = torch.tensor([[2.]])
        self.bias2 = torch.tensor([[3.]])
        

    def act(self, x):
        return x**2

    def forward(self, x):
        x = self.act(self.fc1(x)) + self.bias1 
        x = self.act(self.output(x)) + self.bias2

        return x

    def weights_initialization(self):
        with torch.no_grad():
            self.fc1.weight.copy_(torch.tensor([[0.2, 0.3]]))
            self.output.weight.copy_(torch.tensor([[1.5],
                                                   [2.5]]))
 

net = NeuralNet()
input_data = torch.tensor([[5.]])
output = net(input_data)
print(output)
</code></pre>
","2024-02-05 06:34:09","-1","Question"
"77931247","77931021","","<p>The clue is in the error message: &quot;Make sure your dataset can generate at least 7000 batches&quot;. Read the whole thing carefully — it is trying to help you.</p>
<p><a href=""https://keras.io/api/models/model_training_apis/"" rel=""nofollow noreferrer"">The Keras documentation</a> says this about the <code>steps_per_epoch</code> argument:</p>
<blockquote>
<p>If <code>x</code> is a <code>tf.data.Dataset</code> [it is], and <code>steps_per_epoch</code> is <code>None</code>, the epoch will run until the input dataset is exhausted.</p>
</blockquote>
<p>That's what you want. So let <code>steps_per_epoch</code> be <code>None</code> by omitting it from the call to <code>.fit()</code>.</p>
","2024-02-03 07:33:13","0","Answer"
"77931021","","Animal detection using neural network in TensorFlow","<p>When i run the last part to train model, i am not able to it is getting Intrupted Check the image for the error. As you see i want to detect whether i am able to train my model to detect the animal e.g. between Cat and Dog. <a href=""https://drive.google.com/drive/folders/11T76B8UkTg9lU-sPhPlWqn6MOVhQ-FjS"" rel=""nofollow noreferrer"">Dataset.</a></p>
<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense

# Initiallising the CNN
classifier = Sequential()

#Convolution
classifier.add(Conv2D(32,(3,3), input_shape = (64, 64, 3), activation = 'relu'))

# Pooling
classifier.add(MaxPooling2D(pool_size = (2,2)))

# Adding a second convolutional layer
classifier.add(Conv2D(32, (3,3), activation = 'relu'))
classifier.add(MaxPooling2D(pool_size = (2,2)))

# Flattening
classifier.add(Flatten())

# Full connection 
classifier.add(Dense(units = 128, activation = 'relu'))
classifier.add(Dense(units = 1, activation = 'sigmoid'))

# Compiling the CNN
classifier.compile(optimizer = 'adam', loss= 'binary_crossentropy', metrics = ['accuracy'])

# Fitting the CNN to the images

from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1./255,
                                  shear_range = 0.2,
                                  zoom_range = 0.2,
                                  horizontal_flip = True)

training_set = train_datagen.flow_from_directory(r&quot;D:\Neural Network\Neural Network Full Course-20240203T042209Z-001\Neural Network Full Course - Copy\Neural Network\training_set&quot;,
                                                target_size= (64,64),
                                                batch_size = 32,
                                                class_mode = 'categorical')

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory(r&quot;D:\Neural Network\Neural Network Full Course-20240203T042209Z-001\Neural Network Full Course - Copy\Neural Network\test_set&quot;,
                                                target_size= (64,64),
                                                batch_size = 32,
                                                class_mode = 'categorical')

classifier.fit(training_set,
               steps_per_epoch=700,
               epochs=10,
               validation_data=test_set,
               validation_steps=10)
train_datagen = ImageDataGenerator(rescale = 1./255,
                                  shear_range = 0.2,
                                  zoom_range = 0.2,
                                  horizontal_flip = True)

training_set = train_datagen.flow_from_directory(r&quot;D:\Neural Network\Neural Network Full Course-20240203T042209Z-001\Neural Network Full Course - Copy\Neural Network\training_set&quot;,
                                                target_size= (64,64),
                                                batch_size = 32,
                                                class_mode = 'categorical')

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory(r&quot;D:\Neural Network\Neural Network Full Course-20240203T042209Z-001\Neural Network Full Course - Copy\Neural Network\test_set&quot;,
                                                target_size= (64,64),
                                                batch_size = 32,
                                                class_mode = 'categorical')

##### Here i am getting error
classifier.fit(training_set,
               steps_per_epoch=700,
               epochs=10,
               validation_data=test_set,
               validation_steps=10)
</code></pre>
<p>Error:</p>
<p><img src=""https://i.sstatic.net/I0QK0.jpg"" alt=""Image showing error"" /></p>
","2024-02-03 05:55:16","-1","Question"
"77917867","77916678","","<p>Like suggested in the comments, you may need to play around a bit with your hyperparameters: Learning Rate, Optimizer Choice, Kernel parameters, etc. In regards to how many epochs to train for: There is no magic number; a suggestion will be to track your training and validation loss curves to monitor the training.</p>
<p>When training loss keeps decreasing but your validation loss starts increasing, it is usually a sign of overfitting and an indication to stop training or tinker with learning rate.</p>
","2024-02-01 05:22:51","0","Answer"
"77916678","","Why would the loss of my neural network not be decreasing? What is wrong with my current set up? (PyTorch)","<p>I am sort of new to deep learning and have created neural nets for CIFAR-10 and MNIST datasets. I wanted to try a larger dataset with a different end goal, so I chose the Country211 dataset from Pytorch. I created the neural net (I used three convolutional layers because the input for flattening would have been massive otherwise), but it seems like the loss printed barely decreases. Am I just not running it long enough? Or is there something fundamentally wrong with my NN?</p>
<p>My model is below:</p>
<pre><code>import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

# Use CUDA device
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

print(device)

# Define transform to Normalize images (input is PIL image)
transform = transforms.Compose([transforms.ToTensor(), 
                                transforms.Resize((300, 300)),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 64

# Define training and test set
trainset = torchvision.datasets.Country211(root='./data', split='train',
                                        transform=transform, download=True)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=0)

testset = torchvision.datasets.Country211(root='./data', split='test',
                                          download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                        shuffle=False, num_workers=0)

# classes = ()

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 8, 5)
        self.pool = nn.MaxPool2d(2)
        self.conv2 = nn.Conv2d(8, 12, 5)
        self.conv3 = nn.Conv2d(12, 16, 5)
        self.fc1 = nn.Linear(16 * 34 * 34, 4096)
        self.fc2 = nn.Linear(4096, 1024)
        self.fc3 = nn.Linear(1024, 211)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x
</code></pre>
<p>My training loop is below:</p>
<pre><code>net = Net()
net.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.001)
epochs = 6

for epoch in range(10):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0
</code></pre>
<p>My output of loss is here:</p>
<pre><code>[1,  2000] loss: 5.352
[1,  4000] loss: 5.351
[1,  6000] loss: 5.350
[2,  2000] loss: 5.322
[2,  4000] loss: 5.320
[3,  2000] loss: 5.276
[3,  4000] loss: 5.272
[3,  6000] loss: 5.258
[4,  2000] loss: 5.211
[4,  4000] loss: 5.197
[4,  6000] loss: 5.212
[5,  4000] loss: 5.114
[5,  6000] loss: 5.140
</code></pre>
<p>Thank you in advance for any help!</p>
","2024-01-31 22:07:02","0","Question"
"77912013","77908932","","<p>It seems that PyTorch does the <code>shared_axis</code> operation as default. We can check with the following code:
TensorFlow:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
x = tf.keras.layers.PReLU(shared_axes=(1,2))
x.build((None, 10, 10, 3))  # initialize the weights to an image-like input shape
print(x.weights[0].shape)  # will print 'TensorShape([1, 1, 3])'

# if we omit the shared_axes parameter we get:
x = tf.keras.layers.PReLU()
x.build((None, 10, 10, 3))  # initialize the weights to an image-like input shape
print(x.weights[0].shape)  # will print 'TensorShape([10, 10, 3])'
</code></pre>
<p>PyTorch:</p>
<pre class=""lang-py prettyprint-override""><code>from torch import nn
x = nn.modules.activation.PReLU()
print(x.weight.shape)  # will print 'torch.Size([1])'

# to get one parameter per filter we have to set it
x = nn.modules.activation.PReLU(3)
print(x.weight.shape)  # will print 'torch.Size([3])'
</code></pre>
<p>Hope that helps to understand the differences. You can also initialize the torch version with a list to get the second version of the TF code.<br />
One additional difference is that TensorFlow initializes with <code>0.0</code>, while PyTorch initializes with <code>0.25</code>. To get the exact same initialization as TensorFlow, do:</p>
<pre class=""lang-py prettyprint-override""><code>f = #number of filters of the previous layer
x = nn.modules.activation.PReLU(f, init=0.0)
</code></pre>
","2024-01-31 09:03:16","1","Answer"
"77908932","","TensorFlow to PyTorch: x=tf.keras.layers.PReLU(shared_axes=[1,2])(x)","<p>How to write this line on PyTorch?
tf.keras.layers.PReLU(shared_axes=[1,2])(x)</p>
<p>It is important to have shared_axes=[1,2]</p>
<p>I found this solution somewhere, but Imnot sure if it is correct:
nn.PReLU(num_parameters=1)</p>
<p>Thanks in advance everyone!</p>
","2024-01-30 19:25:18","0","Question"
"77908430","77908339","","<p>You could do this either by creating a layer specifically for it, something like</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

class Conditional_Layer(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Conditional_Layer, self).__init__(**kwargs)

    def call(self, inputs, labels):
        # if y is 1, else pass zeros
        return tf.where(tf.equal(labels, 1), inputs, tf.zeros_like(inputs))

# going through your model
in_features = tf.keras.layers.Input(shape=(feature_shape,)) # where feature_shape is the dimensions of the data
in_labels = tf.keras.layers.Input(shape=(1,))

conditional_layer = Conditional_Layer()([in_features, in_labels])
</code></pre>
<p>Or by using a mask</p>
<pre class=""lang-py prettyprint-override""><code>mask = tf.cast(tf.equal(y_train, 1), dtype=tf.float32) # anywhere y==1, else set to 0
masked_input = x_train * mask
out = model(masked_input) # send through the rest of the model
</code></pre>
<p>The layer could be slotted into a network easily, while the mask may be better for intermediate results. Be cautious when doing this, however, especially when training, as this masking will largely affect the flow of your gradient during backprop.</p>
","2024-01-30 17:50:14","0","Answer"
"77908339","","How to send only certain inputs to the next layer based on label value","<p>Label y can take 0 or 1 value. I want to pass the input features to the next layer only if the corresponding data point has y value equal to 1. How would I implement this in tensorflow?</p>
<p>If I were to add a custom activation function, how would I take the y value(label) as an input to it? Another option was to use masks but I'm not too familiar with the syntax can someone please guide</p>
","2024-01-30 17:35:10","0","Question"
"77902862","77902803","","<blockquote>
<p>Can I control the input that being fed into each neuron?</p>
</blockquote>
<p>Yes.</p>
<p>You are describing the architecture of a neural net,
how it is wired up.</p>
<p>Rather than a &quot;fully connected&quot; layer,
you want neuron1 to be only connected to odd input features,
and neuron2 to be only connected to even ones.
You build the NN, so yes, of course you can construct it in that way.</p>
<p>Equivalently, you might choose to use a fully connected layer
which forces Weights to be <code>0</code> for even inputs to neuron1,
and similarly for odd inputs to neuron2.</p>
<p>Since the two neurons do not share weights,
this would be different from a Siamese architecture.</p>
","2024-01-29 22:01:03","1","Answer"
"77902803","","masking input for each neuron, is it possible?","<p>let's say I have an input dataframe, rows are number of data, columns are 5 features: ft1, ft2,.....,ft5.</p>
<p>Then I have a simple binary classification neural network which the hidden layer has 2 neurons. something like this:
<a href=""https://i.sstatic.net/YomX7.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/YomX7.png"" alt=""simple representation"" /></a></p>
<p>Can I control the input that being fed into each neuron? like only ft1, 3, 5 to neuron 1 and only ft2, 4 to neuron 2?</p>
<p>The first thing I can think of is masking, but it seems not work like that, maybe I can tweak the weight? Any suggestions?</p>
","2024-01-29 21:49:05","0","Question"
"77891352","77885918","","<p>You have to re-initialize the optimizer with the new model -- the model_finetune object. Currently, as I see it in your code, it seems to still use the optimizer which is initialized with your old model weights -- model.parameters().</p>
","2024-01-27 13:22:35","1","Answer"
"77885918","","Why finetuning MLP model on a small dataset, still keeps the test accuracy same as pre-trained weights?","<p>I have designed a simple MLP model trained on 6k data samples.</p>
<pre><code>class MLP(nn.Module):
    def __init__(self,input_dim=92, hidden_dim = 150, num_classes=2):
        super().__init__()
        self.input_dim = input_dim
        self.num_classes = num_classes
        self.hidden_dim = hidden_dim
        #self.softmax = nn.Softmax(dim=1)

        self.layers = nn.Sequential(
            nn.Linear(self.input_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Linear(self.hidden_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Linear(self.hidden_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Linear(self.hidden_dim, self.num_classes),

        )

    def forward(self, x):
        x = self.layers(x)
        return x
</code></pre>
<p>and the model has been instantiated</p>
<pre><code>model = MLP(input_dim=input_dim, hidden_dim=hidden_dim, num_classes=num_classes).to(device)

optimizer = Optimizer.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)
criterion = nn.CrossEntropyLoss()
</code></pre>
<p>and the hyperparameters:</p>
<pre><code>num_epoch = 300   # 200e3//len(train_loader)
learning_rate = 1e-3
batch_size = 64
device = torch.device(&quot;cuda&quot;)
SEED = 42
torch.manual_seed(42)
</code></pre>
<p>My implementation mostly follows <a href=""https://stackoverflow.com/questions/71199036/pytorch-nn-not-as-good-as-sklearn-mlp"">this question</a>. I save the model as pre-trained weights <code>model_weights.pth</code>.</p>
<p>The accuracy of <code>model</code> on the test dataset is <code>96.80%</code>.</p>
<p>Then, I have another 50 samples (in <code>finetune_loader</code>) that I am trying to fine-tune the model on these 50 samples:</p>
<pre><code>model_finetune = MLP()
model_finetune.load_state_dict(torch.load('model_weights.pth'))
model_finetune.to(device)
model_finetune.train()
# train the network
for t in tqdm(range(num_epoch)):
  for i, data in enumerate(finetune_loader, 0):
    #def closure():
      # Get and prepare inputs
      inputs, targets = data
      inputs, targets = inputs.float(), targets.long()
      inputs, targets = inputs.to(device), targets.to(device)
      
      # Zero the gradients
      optimizer.zero_grad()
      # Perform forward pass
      outputs = model_finetune(inputs)
      # Compute loss
      loss = criterion(outputs, targets)
      # Perform backward pass
      loss.backward()
      #return loss
      optimizer.step()     # a

model_finetune.eval()
with torch.no_grad():
    outputs2 = model_finetune(test_data)
    #predicted_labels = outputs.squeeze().tolist()

    _, preds = torch.max(outputs2, 1)
    prediction_test = np.array(preds.cpu())
    accuracy_test_finetune = accuracy_score(y_test, prediction_test)
    accuracy_test_finetune
    
    Output: 0.9680851063829787
</code></pre>
<p>The accuracy remains the same as before fine-tuning the model to 50 samples, I checked, and the output probabilities are also the same.</p>
<p>What could be the reason? Am I making some mistakes in the code for fine-tuning?</p>
","2024-01-26 11:32:05","-1","Question"
"77873610","77869946","","<p>Here is one way to rearrange the flattened tensor back into the original shape while keeping the order:</p>
<pre class=""lang-py prettyprint-override""><code>import torch

flattened = torch.tensor([0,0,0,4,0,0,0,8]) # flattened tensor
kernel_size = 2
input_h = 2  
input_w = 4

unflatten = []
for i in range(0, len(flattened), input_w):
    unflatten.append(flattened[i:i+input_w])

result = torch.stack(unflatten)
print(result)
</code></pre>
<p>The key ideas:</p>
<ul>
<li>Iterate over the flattened tensor in chunks of size <code>input_w</code> (the original input width)</li>
<li>Append those chunks as separate tensors to create a list</li>
<li>Stack that list back into a 2D tensor</li>
</ul>
<p>This takes advantage of slicing the flattened tensor and stitching together the pieces.</p>
<p>The output with the example data is:</p>
<pre><code>tensor([[0, 0, 0, 4],
        [0, 0, 0, 8]])
</code></pre>
","2024-01-24 13:54:43","0","Answer"
"77870576","77835888","","<p>The model fits on the training set. No validation set is needed. If you have a validation set than at the end of an epoch the validation images are fed into the trained model and a prediction is made. The prediction is than compared to the true value of the image file to determine the validation accuracy.</p>
","2024-01-24 04:26:53","1","Answer"
"77869946","","How to transmute a flattened tensor/array back to original size while keeping specific order","<p>I have a flattened pytorch tensor that represents the indices for reverting a MaxPool2d operation, after getting the gradients for the backwards pass. The issue is that the size changes based on the kernel_size and the original input height/width before the MaxPool forward pass.
For example, lets say I have an input of size 2x4 with a kernel_size of 2x2 (kernel always square, and stride always same as kernel):</p>
<p><code>input1 = tensor([[1,2,5,6], [3,4,7,8]])</code>
For input1, after the forward pass, the indices will be [3,3](indexing from 0).
In the backwards pass, I then, after flattening and adding the gradient, end up with a tensor like this:
tensor([0,0,0,(gradient of 4),0,0,0,(gradient of 8)])</p>
<p>The issue is that I now need to transform the tensor back into the original shape while keeping the number order. Using something simple like tensor.view(input_height,input_width) doesn't work because the order of the numbers is messed up:
<code>input1.view(2,4) = tensor([[1,2,3,4],  [5,6,7,8]])</code></p>
<p>I've tried things like chunking it into groups of input_height/input_width but then I have issues making it work for different sizes. I think there is an easy solution and I just lack the pytorch or numpy skills to figure it out :(</p>
<p>Edit:
Ok so I've tried <code>input1.view(2,4)</code> which as I've explained doesn't have the right order. And getting the right order isn't possible through permute or similar functions. I've tried chunking this way:
<code>input1.view(-1, 2)</code> which splits the tensor into chunks of 2, but then I can't stack them back up properly into multiple columns. I've searched everywhere and I don't know how to progress. I've even (to no avail) asked chatGPT lol.</p>
","2024-01-24 00:20:11","0","Question"
"77861642","77861305","","<p>Just use <code>.data</code> attribute</p>
<pre><code>print(&quot;Weight:&quot;, net.fc1.weight[0].data)
</code></pre>
","2024-01-22 17:28:32","1","Answer"
"77861374","77861305","","<pre><code>weight_without_grad = net.fc1.weight[0].clone().requires_grad_(False)
print(&quot;Weight:&quot;, weight_without_grad)
</code></pre>
<p>This clones the tensor and print it. another way is using <code>detach()</code> but I wont suggest because as the name suggests it detaches the tensor</p>
","2024-01-22 16:36:35","1","Answer"
"77861305","","How to remove grad_fn when printing neural network weights","<p>I have a neural net that uses nn.Linear connections between layers. When printing the weights between input and hidden layers with the code below:</p>
<pre><code>print(&quot;Weight:&quot;, net.fc1.weight[0])
</code></pre>
<p>The print out looks like this:</p>
<pre><code>Weight: tensor([ 0.0375,  0.1901,  0.0787,  0.2476,  0.0740,  0.2848, -0.2852, -0.0864,
     0.1827,  0.1384], grad_fn=&lt;SelectBackward0&gt;)
</code></pre>
<p>Is there a way to stop printing out the <code>grad_fn=&lt;SelectBackward0&gt;</code> and just print the weights out like this:</p>
<pre><code>Weight: tensor([ 0.0375,  0.1901,  0.0787,  0.2476,  0.0740,  0.2848, -0.2852, -0.0864,
 0.1827,  0.1384])
</code></pre>
","2024-01-22 16:23:32","0","Question"
"77852623","77852159","","<p>The total feature size output from the conv layers depends on the input size. It's not immediately clear from the model itself, but the code you posted works with an input size of <code>(bs, 3, 32, 32)</code>.</p>
<p>The model would not work with any other input size. This is why using <code>AdaptiveMaxPool2d</code> is generally preferred over fixed size pooling.</p>
","2024-01-20 20:28:09","0","Answer"
"77852159","","How I Know the Output Image Shape before putting it into Linear Layer in PyTorch?","<pre><code>class Net(nn.Module):
    def __init__(self, l1=120, l2=84):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, l1) 
        self.fc2 = nn.Linear(l1, l2)
        self.fc3 = nn.Linear(l2, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
</code></pre>
<p>16 is the number of Activation Map After convolution .
I don't understand in  self.fc1 = nn.Linear(16 * 5 * 5, l1) How 5 came ?
Does any formula for calculate this?</p>
","2024-01-20 18:13:07","0","Question"
"77850649","77850282","","<p>Firstly, define x, y inside of the loop.</p>
<pre><code>for data in trainset:
    x, y = data[0][0], data[1][0]
    break
</code></pre>
<p>Then use .reshape() to change from (1, 28, 28) to (28, 28)</p>
<pre><code>x = x.reshape([28, 28])
</code></pre>
<p>Convert to a numpy array (better for matplotlib) and plot</p>
<pre><code>x = x.numpy()
plt.imshow(x, cmap=&quot;Greys_r&quot;)
plt.show()
</code></pre>
<p>Below is the output</p>
<p><a href=""https://i.sstatic.net/LZs91.png"" rel=""nofollow noreferrer"">Output</a></p>
","2024-01-20 10:34:44","1","Answer"
"77850282","","Training set not showing in graph","<p>For some reason my training set is not showing as a matplotlib graph, I am using the torchvision dataset MNIST.</p>
<p>The code is running without any errors however the graph of data won't be shown. I tried doing the .view() to reshape the data shape from a (1, 28, 28) to a (28, 28) that will be allowed, however the data won't be shown. Here is my code:</p>
<pre><code>import torch
import torchvision
import matplotlib.pyplot as plt
from torchvision import transforms, datasets

train = datasets.MNIST(&quot;&quot;, train=True, download=True,
                       transform= transforms.Compose([transforms.ToTensor()]))

test = datasets.MNIST(&quot;&quot;, train=False, download=True,
                       transform= transforms.Compose([transforms.ToTensor()]))

trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)
testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)


for data in trainset:
    print(data)
    break

x, y = data[0][0], data[1][0]


print(y)


plt.imshow(data[0][0].view(28,28))
plt.show()
</code></pre>
","2024-01-20 08:25:05","0","Question"
"77848840","77843222","","<p>I solved the problem that the result was not reproduced between my laptop and desktop.</p>
<p>But I don't know exactly how this work.</p>
<p>I fixed the code in this way.</p>
<p><strong>Original One</strong></p>
<pre><code>reset_seeds(42)
model = Sequential()
model.add(Dense(64, input_shape = (train_X_arr.shape[1], ), activation = 'sigmoid'))
model.add(Dense(16, activation = 'tanh'))
model.add(Dense(1, activation = 'sigmoid'))
model.compile(loss = 'mae')
</code></pre>
<p><strong>New One</strong></p>
<pre><code>reset_seeds(42)
model = Sequential()
model.add(Dense(64, input_shape = (train_X_arr.shape[1], ), activation = 'sigmoid'))
model.add(Dense(16, activation = 'tanh'))
model.add(Dense(1, activation = 'sigmoid'))
model.compile(optimizer = 'adam', loss = 'mae') # Only this line changed
</code></pre>
<p>I think that this phenomenon is peculiar because the reproducibility was affected by its <code>optimizer</code> even if I set the seed to 42.</p>
<p>To my knowledge, I know that the default optimizer was <code>rmsprop</code>.</p>
<p>I will leave more comments if I precisely find out what was the problem.</p>
<p>Any comment will be helpful also.</p>
","2024-01-19 21:14:19","0","Answer"
"77843222","","Same seed number & package versions & python version but different neural net result from laptop and desktop","<p>I'm using a simple vanilla neural network like this,</p>
<pre><code>reset_seeds(42)
model = Sequential()
model.add(Dense(64, input_shape = (train_X_arr.shape[1], ), activation = 'sigmoid'))
model.add(Dense(16, activation = 'tanh'))
model.add(Dense(1, activation = 'sigmoid'))
model.compile(loss = 'mae')
</code></pre>
<p>The function named <code>reset_seeds</code> is defined below.</p>
<pre><code>def reset_seeds(seed):
    import random
    import os
    import tensorflow as tf

    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    random.seed(seed)
    tf.random.set_seed(seed)
</code></pre>
<p>Then I check the initial weights of the model in my laptop and the desktop</p>
<p><strong>Laptop's sum of initial weights (Before training)</strong></p>
<blockquote>
<p>[-9.959677, 0.0, -5.590966, 0.0, -1.1521256, 0.0]</p>
</blockquote>
<p><strong>Desktop's sum of initial weight (Before training)</strong></p>
<blockquote>
<p>[-9.959677, 0.0, -5.590966, 0.0, -1.1521256, 0.0]</p>
</blockquote>
<p>However, after I run the model defined above with one epoch, the sum of initial weights is different between my laptop and desktop.</p>
<pre><code>hist = model.fit(x = train_X_arr, y = train_y_arr, batch_size = 1, epochs = 1, verbose = 2, shuffle = False)
</code></pre>
<p><strong>Laptop's sum of initial weights (After training)</strong></p>
<blockquote>
<p>[-168.1607, -6.258976, 50.797672, 0.42788112, 0.15801406, -0.26924044]</p>
</blockquote>
<p><strong>Desktop's sum of initial weight (After training)</strong></p>
<blockquote>
<p>[-159.85245, -5.7658424, 57.23868, 0.47032726, 0.13733912, -0.25829855]</p>
</blockquote>
<p>I expected that the sum of the initial weight would be the <strong>same</strong> after the training because I set the random seed before compiling and training the model.</p>
<p>However, the result seems quite different.</p>
<p>I tried to figure out this for a whole week but I failed. Any help will be appreciated.</p>
","2024-01-19 01:13:44","0","Question"
"77835888","","What is the befault behaviour for Tensorflow.js fitDataset() if no validation dataset is specified?","<p>How does Tensorflow <strong>compute the fitting loss</strong> and <strong>what does it compute it against</strong> if no <code>validationData</code> is specified? It is an <strong>optional parameter</strong> and fitting runs even if you don't specify it, which is what I'm doing in my code right now. How is it different from specifying an explicit validation dataset?</p>
<pre><code>    model.fitDataset(dataset, {
        epochs: 30,
        validationData: validationDataset, // &lt;--- What is the behaviour if this optional parameter is not set?
    });
</code></pre>
<p>I didn't find any info in the documentation on it yet.</p>
","2024-01-17 22:27:09","0","Question"
"77824716","77791735","","<p>L4CasADi supports PyTorch Models exceeding linear layers (such as convolutions). L4CasADi supports all PyTorch Models, which are jit traceable/scriptable.</p>
<p>L4CasADi Example with Convolution:</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>import torch
import numpy as np
import l4casadi as l4c
import casadi as cs


# Create a model with convolutional layers
class ConvModel(torch.nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = torch.nn.Conv2d(1, 32, 3, padding=1)
        self.conv2 = torch.nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = torch.nn.Conv2d(64, 64, 3, padding=1)
        self.fc1 = torch.nn.Linear(64 * 7 * 7, 128)
        self.fc2 = torch.nn.Linear(128, 1)

    def forward(self, x):
        x = x.reshape(-1, 1, 7, 7)
        x = torch.nn.functional.relu(self.conv1(x))
        x = torch.nn.functional.relu(self.conv2(x))
        x = torch.nn.functional.relu(self.conv3(x))
        x = x.view(-1, 64 * 7 * 7)
        x = torch.nn.functional.relu(self.fc1(x))
        x = self.fc2(x)
        return x


x = np.random.randn(49).astype(np.float32)
model = ConvModel()
y = model(torch.tensor(x)[None])
print(f'Torch output: {y}')

l4c_model = l4c.L4CasADi(model, model_expects_batch_dim=True)

x_sym = cs.MX.sym('x', 49)
y_sym = l4c_model(x_sym)

f = cs.Function('y', [x_sym], [y_sym])
y = f(x)

print(f'L4CasADi Output: {y}')</code></pre>
</div>
</div>
</p>
","2024-01-16 09:34:31","0","Answer"
"77823532","77823498","","<p>Declaring and calling member function pointers have a different syntax than for normal pointers. The syntax is as shown below:</p>
<pre><code>struct previous_neuron_struct {
    double weight;
    double (neuron::*funcPtr)();  //syntax for declaring member function pointer 
};
int main() {
    //other code as before
    temp-&gt;funcPtr = &amp;neuron::Return_Value; //works now
    std::invoke( temp-&gt;funcPtr, neuron1);  //call

    (neuron1.*(temp-&gt;funcPtr))();//another way of calling
}
</code></pre>
<p><a href=""https://godbolt.org/z/bd8G7oP6c"" rel=""nofollow noreferrer"">Working demo</a></p>
","2024-01-16 04:56:11","1","Answer"
"77823498","","How can I have a struct with a variable with a pointer to a non-static member function?","<p>I am creating a project related to Neural Networks. When getting the output, I want to have a neuron call the &quot;ReturnValue&quot; function of all the previous neurons. I've created a neuron class with said function. I want to be able to store these function pointers in a struct (to pair it with some other applicable data values), then store this struct in a vector. InTo summarize there will be one entry in the vector for every neuron in the previous layer. Each entry will be a struct containing a function pointer and a few other things. My problem is that I can't get the pointer to the function in the first place. Below is some code to illustrate.</p>
<pre><code>#include &lt;iostream&gt;
#include &lt;vector&gt;

struct previous_neuron_struct {
    double weight;
    double (*funcPtr)(); //I think that this is correct
};

class neuron {
public:
    double value;
    std::vector&lt;previous_neuron_struct&gt; previous_neurons_vector;

    double Return_Value() {
        return value;
    }
};

int main() {
    neuron neuron1;
    neuron neuron2;
    //I know that it would be easier to avoid pointers, but this better illustrates the environment of the actual use case.
    previous_neuron_struct* temp = new previous_neuron_struct;
    temp-&gt;weight = 0.5;
    temp-&gt;funcPtr = neuron2.Return_Value; //&lt;- Problem is here

//Rest of code
}

</code></pre>
<p>Line 25 is the problematic line. No combination of asterisks or ampersands that I have come across will allow me to put the address (not the return value) of neuron2.Return_Value() into temp-&gt;funcPtr. This sample code right now will give me Visual Studio error code 0300: <code>a pointer to a bound function may only be used to call the function</code>. But with a slightly different combination that I have seen on some tutorial websites, <code>neuron2.*Return_Value;</code> I get <code>Identifier &quot;Return_Value&quot; is undefined</code>. Thanks</p>
","2024-01-16 04:38:34","1","Question"
"77821914","77821670","","<p>Yes, I understand your question.
<strong>The output layer should be equal to the number of  target classes.</strong> For Example in your case take output neuron as <code>y_train.nunique() is 10</code> then the final layer output and label should be in <strong>the range of 0 - 9.</strong> The Label value 10 will be not included in that specific range. <strong>So It throw error Received a label value of 10 which is outside the valid range becasuse the label 10 will not include in the final softmax neuron number of 10</strong></p>
<p><a href=""https://i.sstatic.net/dLuQa.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/dLuQa.png"" alt=""enter image description here"" /></a></p>
<p><strong>The Above image will represent the softmax layer with the classes of 3. [0.9% is class 0, 0.1% is class 1, 0.0% is class 2]</strong> If Number of class 10 Only 10 class probability in softmax will be created. <strong>In your case the number of classes will be 11.</strong></p>
<p>If <code>y_train.nunique() + 1 is 10</code> then the final layer output and label should be <strong>in the range of 0 - 10 here for the 10th class the probability softmax will be created.</strong> So the code works fine.</p>
<p><strong>Sum of all classes probability will be result in 1. The missing 9 is also will be consider as one class</strong></p>
","2024-01-15 19:20:17","1","Answer"
"77821670","","Neural networks - unable to understand the behaviour of the output layer","<p>I'd like to know why this works (look for the comment &quot;<em># This is the output layer and this is what I am talking about</em>&quot;):</p>
<pre><code>model = Sequential() # Not talking about this
model.add(Dense(32, activation='relu', input_dim = X_train.shape[1])) # Not talking about this
model.add(Dense(16, activation='relu')) # Not talking about this
model.add(Dropout(0.2)) # Not talking about this
model.add(Dense(16, activation='relu')) # Not talking about this
model.add(Dense(y_train.nunique()+1, activation='softmax')) # This is the output layer and this is what I am talking about
          
model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate = 0.01), metrics=['accuracy']) # Not talking about this
model.summary() # Not talking about this
</code></pre>
<p>and not this (look for the comment &quot;<em># This is the output layer and this is what I am talking about</em>&quot;)::</p>
<pre><code>model = Sequential() # Same as above
model.add(Dense(32, activation='relu', input_dim = X_train.shape[1])) # Same as above
model.add(Dense(16, activation='relu')) # Same as above
model.add(Dropout(0.2)) # Same as above
model.add(Dense(16, activation='relu')) # Same as above
model.add(Dense(y_train.nunique(), activation='softmax')) # This is the output layer and this is what I am talking about
          
model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate = 0.01), metrics=['accuracy']) # Same as above
model.summary() # Same as above
</code></pre>
<p>So what's going on here is that I have this very basic NN that I am using to predict a multiclass dataset. There are 10 classes in the target, starting from 0 and going all the way to 10 (with the exception of 9; 9 isn't there). At where I've commented &quot;<em># This is the output layer and this is what I am talking about</em>&quot;, when I give the unit of output neurons as the number of unique values of target (<code>y_train.nunique()</code>), it throws an error like this:</p>
<pre><code>Detected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):
  File &quot;&lt;frozen runpy&gt;&quot;, line 198, in _run_module_as_main
...

  File &quot;c:\&lt;redacted&gt;\Projects\&lt;redacted&gt;\Lib\site-packages\keras\src\backend.py&quot;, line 5775, in sparse_categorical_crossentropy

Received a label value of 10 which is outside the valid range of [0, 10).  Label values: 5 0 3 3 1 8 10 4 3 1 0 0 1 3 5 6 10 6 10 8 4 6 6 6 1 2 7 10 8 0 4 8
     [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_737445]
</code></pre>
<p>On the other hand, when I give the number of units as anything more than that, like in the above example it is <code>y_train.nunique()+1</code>, it goes through all 200 epochs. I don't understand what's going on.</p>
<p>Also,</p>
<ol>
<li>Is the output layer correct (for the number of classes in question)?</li>
<li>Is my understanding of the output layer correct (which is - for this specific problem - the number of neurons in the output must be equal to the number of unique values of the target (which are also the classes the data falls into))?</li>
</ol>
","2024-01-15 18:20:56","-1","Question"
"77810249","77808939","","<h2>Cause of the <code>ValueError</code></h2>
<p>The <code>Embedding</code> layer returns a tensor of shape <code>(batch_size, input_length, output_dim)</code> as mentioned in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"" rel=""nofollow noreferrer"">docs</a>.</p>
<p>In your case, the output of the <code>Embedding</code> layer goes to the <code>Dense</code> layers (and <code>Dropout</code> layers also) which would simply take in inputs of shape <code>( batch_size , input_length , embedding_dim )</code> and return a tensor of shape <code>( batch_size , input_length , dense_dims )</code>.</p>
<p>In the last <code>Dense</code> layer, the <code>units</code> parameter is set to <code>3</code> and hence the output of the NN is <code>( batch_size , input_length , 3 )</code>
, whereas the size of the labels is <code>( batch_size , 3 )</code> which <strong>do not match, hence resulting in a shape mismatch</strong>.</p>
<h2>Solution</h2>
<p>The outputs of the <code>Embedding</code> layer must be converted to a 2D tensor. This can be accomplished by:</p>
<ol>
<li><p>Passing the outputs of an <code>Embedding</code> layer to any recurrent layers (<code>LSTM</code>, <code>GRU</code> or <code>RNN</code>). See the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"" rel=""nofollow noreferrer"">docs on <code>LSTM</code></a>, specifically check the <code>return_sequences</code> argument as well.</p>
</li>
<li><p>Use global pooling layers, <code>GlobalMaxPooling1D</code> or <code>GlobalAveragePooling1D</code>.</p>
</li>
</ol>
","2024-01-13 03:51:38","1","Answer"
"77808939","","Shapes (None, 16, 3) and (None,) are incompatible - Model not fitting","<p>So i have my X_train which is a numpy array of shape (13878, 16) containing vectorized comments, and their corresponding labels in Y_train with shape (13878,) containing an int from 0 to 2 stating if it is hate speech, inappropiate language or neither respectively.
however, when i try to fit my model, i get the error: Shapes (None, 16, 3) and (None,) are incompatible.</p>
<p>I already tried one-hot encoding the labels and therefore changing the loss function but it gave me a similar error and I unfortunately can´t think of what could be that I am doing wrong.</p>
<p>My vectorization and other relevant code is below:</p>
<pre><code>max_features = 10000 #vocabulary size approx
sequence_length = 16 #comment length cap

vectorize_layer = layers.TextVectorization(
    max_tokens=max_features,
    output_mode='int',
    output_sequence_length=sequence_length)

vectorize_layer.adapt(X.values) #adapt vectorizer for our vocabulary
vectorized_comments=vectorize_layer(X.values)
</code></pre>
<pre><code>vectorized_comments_np = np.array(vectorized_comments) #from tensro to array to split

# First, split into training and the rest
X_train, X_temp, Y_train, Y_temp = train_test_split(vectorized_comments_np, Y, test_size=0.3, random_state=42, stratify=Y)

# Now, split the rest into validation and test
X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.33, random_state=42, stratify=Y_temp)
</code></pre>
<p>#create model</p>
<pre><code>model = tf.keras.Sequential([
  #layers.Flatten(input_shape=(16,)),
  layers.Embedding(max_features, 32),
  layers.Dense(128,activation=&quot;relu&quot;),
  layers.Dropout(0.2),
  layers.Dense(256,activation=&quot;relu&quot;),
  layers.Dropout(0.2),
  layers.Dense(128,activation=&quot;relu&quot;),
  layers.Dropout(0.2),
  layers.Dense(64,activation=&quot;relu&quot;),
  layers.Dense(3, activation=&quot;softmax&quot;)])

model.summary()
</code></pre>
<pre><code>model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam',
              metrics=[tf.metrics.Precision(),tf.metrics.F1Score(average=&quot;weighted&quot;)])
</code></pre>
<p>#fit</p>
<pre><code>model.fit(X_train,Y_train,epochs=5,verbose=1,validation_data=(X_val,Y_val),batch_size=64)
</code></pre>
<p>Error i get:   ValueError: Shapes (None, 16, 3) and (None,) are incompatible</p>
<p>I also tried expanding the dimension of Y but it didnt help, the error i got was  ValueError: Shapes (None, 16, 3) and (None, 1) are incompatible</p>
","2024-01-12 19:38:00","0","Question"
"77793137","77788290","","<p>Altough fun, combining genetic algorithms with neural networks is just very slow. Genetic algorithms work nicely when the individuals of the population can be tested/validated within a ms. Whenever training a network is involved things get much slower than that.</p>
<p>Where in the steps do you backpropogate the loss to the neural networks? If done at every step, it will speed things up if you do it every x steps.</p>
<p>I am not sure about any resources for these situations. Keeping the models simple, running them on GPU and propogating loss at every x steps will improve things but I am not expecting miracles.</p>
","2024-01-10 11:49:13","1","Answer"
"77791735","","Is there any solutions that help casadi MX variable to be used in pytorch nn.conv1d(convolution)?","<p>I now have a Sequential Neural Network which is used for predict robot states. But I have a problem when implementing the NN into Casadi to solve an MPC problem. The error keeps warning me that I can not use Casadi MX variable in a Sequential NN which requires convolution process.</p>
<p>I have seen the repo <a href=""https://github.com/Tim-Salzmann/l4casadi"" rel=""nofollow noreferrer"">l4casadi</a> but it seems only supporting nn.linear but not nn.conv1d. Hopes to find a solution here and thanks for answering.</p>
","2024-01-10 08:05:46","0","Question"
"77788290","","Suggestions about optimal way to run neural networks in parallel","<p>I started in the last days of 2023 a personal project just for fun - I recreated the classical &quot;Snake Game&quot; (from old Nokia mobiles) in Python and I wanted to integrate it with some Machine Learning methods so the ML algorithm would learn how to play and excel at it.</p>
<p>My expectation was do to something like a genetic algorithm + neural network, where I instantiate many games in &quot;parallel&quot;, let them play until all games are over, and finally pick the best ones and try to evolve them (applying some random mutations and crossing-over eventually).</p>
<p>In terms of implementation, it was an easy deal, but in terms of performance, it started to get terribly slow once I integrated Keras to the project - but probably it was my fault, maybe there's some other optimal way to do it.</p>
<p>Basically, I did the following:</p>
<ul>
<li>Created &quot;N&quot; instances of the snake game</li>
<li>Created &quot;N&quot; instances of a simple Keras sequential model <strong>(this step strongly hurts performance)</strong></li>
<li>Created a for loop to recalculate the &quot;next move&quot; for all the &quot;N&quot; games, where the next move for the &quot;Nth&quot; game is based on its current state being provided as an input for the &quot;Nth&quot; neural network, which provides the optimal &quot;next move&quot; as its output;</li>
<li>Updated the game screen containing all the snake games (just for visual feedback / fun, using pygame)</li>
<li>Repeated these steps until all games are over, then evolved all the neural networks based on mutations the best one(s), and restarted the game loop (started a &quot;new generation&quot;).</li>
</ul>
<p>The fact is that using all these &quot;N&quot; Keras instances seems to be a terrible choice in terms of performance, although the topology of the models is very simple.</p>
<p>I was thinking about implementing an ANN model manually, doing all the matrix multiplication, so it would become much lighter, but before doing it I wanted to ask here in SO - is there any other Python resource available that would fit my need?</p>
","2024-01-09 16:28:05","-1","Question"
"77779623","77779141","","<p>There are couple of issue. <strong>First</strong>, because of supervision training, you need to make sure that the length of the training paris (<code>X</code> and corresponding <code>Y</code>) are same. <strong>Next</strong>, as you want to build a model that would take <code>1</code> and <code>2</code> and predict <code>3</code>, that's why you also need to prepare your dataloader accordingly such that, it produces two values as <code>X</code> and a target value as <code>Y</code>; for example, for first instance, it might be as follows: <code>X[0]: [[1], [2]]</code> and <code>Y[0]: [3]</code>. <strong>Lastly</strong>, in your last layer, you used activation <code>softmax</code> which is incorrect to use here, instead it should be linear activaiton. Below is the full working code.</p>
<p><strong>Data Generator</strong></p>
<pre class=""lang-py prettyprint-override""><code>data = np.array([1, 2, 3, 4, 5, 6, 7])
sequences_length = 2

def dataloader(data, sequences_length):
    X, Y = [], []
    for i in range(len(data) - sequences_length):
        X.append(data[i:i+sequences_length])
        Y.append(data[i+sequences_length])
    return np.array(X), np.array(Y)

X, Y = dataloader(data, sequences_length)
X = np.reshape(X, (X.shape[0], sequences_length , 1))

# check
for i in range(X.shape[0]):
    print(X[i].reshape(-1), Y[i])
[1 2] 3
[2 3] 4
[3 4] 5
[4 5] 6
[5 6] 7
</code></pre>
<p><strong>Model</strong></p>
<pre class=""lang-py prettyprint-override""><code>model = keras.Sequential([
    layers.LSTM(64, input_shape=(sequences_length, 1)),
    layers.Dense(1)
])
model.compile(optimizer=&quot;adam&quot;, loss=&quot;mse&quot;)
model.fit(X, Y, epochs=1000, batch_size=1)
</code></pre>
<p><strong>Prediction</strong></p>
<pre class=""lang-py prettyprint-override""><code>inference_data = np.array([[8, 9]]).reshape(
    1, sequences_length, 1
)
model.predict(inference_data)
1/1 [==============================] - 0s 25ms/step
array([[9.420095]], dtype=float32)
</code></pre>
","2024-01-08 11:40:24","1","Answer"
"77779141","","Data cardinality is ambiguous in shape of input to LSTM layer","<p>Suppose I have these 7 time-series samples:</p>
<pre><code>1,2,3,4,5,6,7
</code></pre>
<p>I know there is a relation between each sample and its two earlier ones. It means when you know two earlier samples are <code>1,2</code> then you can predict the next one must be <code>3</code> and for <code>2,3</code> the next one is <code>4</code> and so on.</p>
<p>Now I want to train a <code>RNN</code> with a <code>LSTM</code> layer for above samples. What I did is:</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

X = np.array([[[1]],[[2]],[[3]],[[4]],[[5]],[[6]],[[7]]])
Y = np.array([[3],[4],[5],[6],[7]])

model = keras.Sequential([
    layers.LSTM(16, input_shape=(2, 1)),
    layers.Dense(1, activation=&quot;softmax&quot;)
])

model.compile(optimizer=&quot;rmsprop&quot;,
loss=&quot;mse&quot;,
metrics=[&quot;accuracy&quot;])

model.fit(X, Y, epochs=1, batch_size=1)
</code></pre>
<p>But I have encounter with this error:</p>
<pre><code>ValueError: Data cardinality is ambiguous:
  x sizes: 7
  y sizes: 5
Make sure all arrays contain the same number of samples.
</code></pre>
<p>I do not know how I have to change the shape of <code>X</code> and <code>Y</code> to solve the problem?</p>
","2024-01-08 10:59:28","1","Question"
"77774685","77774314","","<p>I have put together a small code example that shows how you can train on partial sets so that they don't all need to be loaded into memory at once.</p>
<ol>
<li>Choose a batch size that meets your system limitations</li>
<li>Identify the data and collect it all with labels and shuffle it up</li>
<li>Determine how many batches to use based on total size and batch size</li>
<li>Iterate epochs time (to maintain multi-epoch training that normally keras offers out of the box)</li>
<li>Iterate through each batch, loading the images as necessary, and fitting the model to it</li>
</ol>
<p>I copied the basic setup for a neural network classifier from tensorflow's website. In your case, you will not use <code>N</code> and you will list the training data using the code in the comment, which is based on your example above. I just downloaded a random cat and dog image to verify that the code worked. You may also need to edit the line in the loop that loads the data to work with your files.</p>
<pre><code>import numpy as np
from PIL import Image
import tensorflow as tf
import random

N = 90
batch_size = 10
rng = np.random.default_rng(seed=42)
epochs = 5

cat_file_set = [(0, 'cat.jpg')] * N  # (0, x) for x in list(os.listdir(&quot;E:\\ ... Cats1\\&quot;))
dog_file_set = [(1, 'dog.jpg')] * N  # (1, x) for x in list(os.listdir(E:\\ ... Dogs1\\&quot;))
file_set = cat_file_set + dog_file_set
random.shuffle(file_set)
total_batches = int(np.ceil(len(file_set) / batch_size))

# https://www.tensorflow.org/tutorials/quickstart/beginner
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(224, 224, 3)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])

for epochnum in range(epochs):
    for batchnum in range(total_batches):
        bslice = file_set[batchnum * batch_size: (batchnum + 1) * batch_size]
        train_data = np.array([np.array(Image.open(x[1])) for x in bslice])
        train_labels = np.array([x[0] for x in bslice])
        model.fit(train_data, train_labels, epochs=1)
# model.evaluate(train_data, train_labels, verbose=2)
</code></pre>
<p>Let me know if you have any questions.</p>
","2024-01-07 20:15:49","0","Answer"
"77774314","","ArrayMemoryError with .concatenate() in NumPy","<p>I am learning how to create neural networks, and I have made a neural network for training that distinguishes cats from dogs. The neural network had low accuracy (0.50) when I trained it on 100 photos of cats and dogs. Now I have downloaded a Google dataset for 10,000 photos of cats, and the same number of dogs. I normalized the files, converted them to .npy and started training the neural network. As a result, these warnings appeared in the first 20 seconds of operation:</p>
<pre><code>2024-01-07 15:09:51.166129: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING:tensorflow:From C:\Users\artyo\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.
</code></pre>
<p>But it seems to me that this is not particularly important, these warnings have been before, they do not affect the work. But after about 15-20 minutes of work (nothing happens all this time, only the Python process takes about 13 gigs of RAM), the neural network outputs the following:</p>
<pre><code>Traceback (most recent call last):
  File &quot;e:\Unity\!!neuro\projects\catsAndDogs100\main.py&quot;, line 15, in &lt;module&gt;
    train_data = np.concatenate((cats_train_data, dogs_train_data), axis=0)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 10.1 GiB for an array with shape (9000, 224, 224, 3) and data type float64
</code></pre>
<p>As I understand it, this is something related to a lack of some kind of memory, and this error occurs even before training, at the moment of combining arrays with cats and dogs. At the time of launching the program, 200 gigabytes are available on the disk on which the neural network files are located, 150 gigabytes on the system disk, and about 14 gigs of RAM are free at the time of launch. I have already tried to reduce the number of images in the dataset from 12,500 to 9900, as a result, only the number of &quot;inaccessible&quot; gigabytes in the error text decreased.
Code with concatenation:</p>
<pre><code># Загрузка данных кошек для обучения
cats_train_data = [np.load(&quot;E:\\Unity\\!!neuro\\datasets\\catsAndDogs100\\finishedCats1\\&quot; + filename) for filename in os.listdir(&quot;E:\\Unity\\!!neuro\\datasets\\catsAndDogs100\\finishedCats1\\&quot;)]
cats_train_labels = np.zeros(len(cats_train_data))  # Метки для кошек

# Загрузка данных собак для обучения
dogs_train_data = [np.load(&quot;E:\\Unity\\!!neuro\\datasets\\catsAndDogs100\\finishedDogs1\\&quot; + filename) for filename in os.listdir(&quot;E:\\Unity\\!!neuro\\datasets\\catsAndDogs100\\finishedDogs1\\&quot;)]
dogs_train_labels = np.ones(len(dogs_train_data))   # Метки для собак

# Объединение данных и меток для обучения
train_data = np.concatenate((cats_train_data, dogs_train_data), axis=0)
train_labels = np.concatenate((cats_train_labels, dogs_train_labels), axis=0)
</code></pre>
<p>I tried to reduce the amount of data in the dataset, and I also tried to give the process python.exe high priority and ask this question on the Russian version of Stackoverflow, but no one there has answered me.</p>
","2024-01-07 18:26:31","0","Question"
"77754542","77752683","","<p>Some clarifying questions.</p>
<p>How many GPUs do you have access to?</p>
<p>Are the local models pre-trained or trained in-line? If they are pre-trained, is it necessary to backprop through them?</p>
<p>GPUs really do not like parallel processing within a single card. If you have access to multiple cards, you can look into parallelizing the local models across multiple cards. If you don't have enough GPUs for this, you're better off running the local models in series. Multi-model parallel processing with card sharing will be a huge pain and most likely be slower than running in series.</p>
<p>If the local models are pre-trained and you don't need to backprop through them, you can consider building a feature extraction pipeline that computes local model outputs prior to training.</p>
","2024-01-03 20:37:09","0","Answer"
"77753218","77752683","","<p>To run multiple modules in parallel, you often want multiple processes (and multiple GPUs). Python isn't very good at multithreading (due to the GIL).</p>
<p>Even without Python, GPU programming is highly optimized for parallelizing large individual operations performed over a tensor, not for performing multiple separate operations in parallel. To perform separate operations in parallel on a single GPU, you'd need to send them to different GPU executors (&quot;streams&quot;).</p>
<p>You didn't link to the paper, but it's also sometimes the case that splitting an operation into multiple parallel modules is done just to better utilize multiple GPUs.</p>
","2024-01-03 16:17:23","0","Answer"
"77752683","","How to run multiple modules within a module in parallel?","<p>I've been reading a paper which contained the following machine learning model which I would like to replicate in PyTorch</p>
<p><a href=""https://i.sstatic.net/Y8Frs.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Y8Frs.png"" alt=""enter image description here"" /></a></p>
<p>Essentially the input gets split into n equally sized vectors and each of them gets passed to a separate local model. All outputs of local models are then concatenated and run through the next layer. (x is not relevant to my question here, so let's ignore it)</p>
<p>So far I've come up with this:</p>
<pre><code>class GlobalModel(torch.nn.Module):
    def __init__(self, n_local_models):
        super(GlobalModel, self).__init__()

        self.local_models = [LocalModel() for _ in range(n_local_models)]
        self.linear = torch.nn.Linear(100, 100)  
        self.activation = torch.nn.ReLU()
</code></pre>
<p>with LocalModel being some other torch.nn.Module. The linear Layer size is just a dummy, I will make it change dynamically with the local models later.</p>
<p>My question is, how can I best write a forward() function that runs all local models in parallel, before concatenating them and passing them on to the linear layer and activation function. Because the only way of implementing this that I can think of, is iterating through the list of local models and executing each of them in sequence. But this seems rather slow and I feel like there should be a more elegant solution.</p>
","2024-01-03 14:49:10","1","Question"
"77747266","77746953","","<p>I suggest you:</p>
<ol>
<li><p>If you are trying to perform classification, makes no sense to use timestamps as a feature. Timestamps are usually unique values and they may cause confussion to the model. Remove that feature. You could use month on quarter as a seasonal information feature, instead of microseconds information.</p>
</li>
<li><p>Try a Tree Regression method (Random Forest) to get a quick and specific information about feature relevance. It will point you where to focus for feature engineering.</p>
</li>
<li><p>Identify relevant features on the EDA. There is an interesting material here to visit on your dataset kaggle page: <a href=""https://www.kaggle.com/code/xokent/e-commerce-website-logs-visualization"" rel=""nofollow noreferrer"">https://www.kaggle.com/code/xokent/e-commerce-website-logs-visualization</a></p>
</li>
</ol>
","2024-01-02 16:13:02","1","Answer"
"77747080","77746953","","<p>From your code there isn't any obvious mistake made. I would suggest you do to do a few things here:</p>
<ul>
<li>study the <a href=""https://www.kaggle.com/code/bhushanshelke69/ecommerce-logs-eda"" rel=""nofollow noreferrer"">EDA</a> section</li>
<li>try to fit linear regression to a promising feature identified in the EDA, such as membership status, and improve your classifier by adding more features you identified as useful</li>
</ul>
<p>Neural networks are generally used only when you have exhausted traditional statistical methods because the amount of data is very large. However, you will need to have an underlying correlation between the input and output features you want to predict.</p>
<p>In your case, you handle time series data and a diverse set of other inputs (such as bytes compressed), and it could be possible that there isn't any useful correlation that the network could learn in these combined features.</p>
","2024-01-02 15:41:27","2","Answer"
"77746953","","Keras binary classificator always predict the same class","<p>I ran into a problem while building a NN with Keras, basically the network learns to predict always the class with more instances in the training set.</p>
<p>I've divided my code in sections:</p>
<p><strong>Data preparation</strong></p>
<pre><code>data = purchase_data.copy()
labelencoder = LabelEncoder()
target_sum = 120
data.loc[data['sales'] &lt;= target_sum, 'sales'] = False
data.loc[data['sales'] &gt; target_sum, 'sales'] = True

print(&quot;\n\nColumn Names &amp; formatting:\n&quot;)
for col in data.columns.values.tolist():
    if data[col].dtype == &quot;object&quot; or data[col].dtype == &quot;bool&quot;:
        print(&quot;{:&lt;30}&quot;.format(col), &quot;:&quot;, &quot;{:&lt;30}&quot;.format(str(data[col].dtype)) , &quot;Formatting to LabelEncoding&quot;)
        data[col] = labelencoder.fit_transform(data[col])
    else:
        print(&quot;{:&lt;30}&quot;.format(col), &quot;:&quot;, &quot;{:&lt;30}&quot;.format(str(data[col].dtype)) , &quot;No formatting required.&quot;)

# Converting datetime to float
data['accessed_date'] = data['accessed_date'].apply(lambda x: x.timestamp())

array = data.values 
class_column = 'sales' # The column I want to predict

X = np.delete(array, data.columns.get_loc(class_column), axis=1) # Removing class_column column
Y = array[:,data.columns.get_loc(class_column)] # Selecting class_column column
Y = Y[:, np.newaxis] # Resetting the shape value

# Normalizing the input values (excluding the class value)
scaler = preprocessing.Normalizer().fit(X)
X = scaler.transform(X)
</code></pre>
<p><strong>Splitting the dataset</strong></p>
<pre><code>seed = 1
X_train, X_test, Y_train, Y_test  = train_test_split(X, Y, test_size=0.33, random_state=seed, shuffle = True, stratify=(Y))
</code></pre>
<p><strong>Neural Network</strong></p>
<pre><code>tf.random.set_seed(seed)


# Building the neural network
modeldl = Sequential()

modeldl.add(Dense(64, input_dim=X.shape[1], activation='relu', kernel_initializer=he_normal()))
modeldl.add(Dropout(0.2))

modeldl.add(Dense(32, activation='relu', kernel_initializer=he_normal()))
modeldl.add(Dropout(0.2))

modeldl.add(Dense(1, activation='sigmoid', kernel_initializer=he_normal()))


# Compile model
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-04)
modeldl.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])

results = modeldl.fit(X_train, Y_train, epochs=80, batch_size=1000, verbose=1)
</code></pre>
<p><strong>Confusion matrix</strong>
At the end of the training we get this confusion matrix:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th></th>
<th>Positive</th>
<th>Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Positive</td>
<td>0 (TP)</td>
<td>21719 (FN)</td>
</tr>
<tr>
<td>Negative</td>
<td>0 (FP)</td>
<td>22620 (TN)</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Questions</strong>
How can I solve this issue?</p>
<p>I've tried:</p>
<ul>
<li>to play with hyperparameters</li>
<li>to predict another column instead of 'sales'</li>
<li>to resize the network</li>
<li>to fix a certain learning rate</li>
<li>to change the activation function</li>
<li>to add/remove dropout layers</li>
</ul>
<p><strong>Other info</strong>
The dataset contains more or less 50% of the class '0' and 50% of the class '1'. I'm using <a href=""https://www.kaggle.com/datasets/kzmontage/e-commerce-website-logs"" rel=""nofollow noreferrer"">this dataset</a> but I've removed the column and the rows related to returns.</p>
","2024-01-02 15:19:47","0","Question"
"77746860","77746352","","<p>You've mostly got the right idea. Small steps for implementing the second task:</p>
<ol>
<li>Load the pretrained VGG-19 model.</li>
<li>Freeze the weights of all layers except for the last two fully connected layers (FC1 and FC2). If you are defining a new Sequential, you won't have the pretrained weights since pretrained weights are not available, so the approach would involve training the layers from scratch rather than fine-tuning existing weights</li>
<li>Optionally, modify the last layer to fit the number of classes in your dataset.</li>
</ol>
<p>As you said above, the structure of the VGG-19's classifier section is:</p>
<pre><code>     (classifier): Sequential(
        (0): Linear(in_features=25088, out_features=4096, bias=True) # FC1
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4096, out_features=4096, bias=True) # FC2
        (4): ReLU(inplace=True)
        (5): Dropout(p=0.5, inplace=False)
        (6): Linear(in_features=4096, out_features=1000, bias=True) # Original output layer
      )
</code></pre>
<p>The code for updating only FC1 and FC2 (and the final classifier layer if you choose to modify it) will be updated during training, while the rest of the network remains unchanged:</p>
<pre><code>    import torch.nn as nn
    from torchvision import models
    from torchvision.models import VGG19_Weights
    
    # Load the pretrained model
    vgg19_model = models.vgg19(weights=VGG19_Weights.IMAGENET1K_V1) # since 0.13, the argument 'pretrained' has been deprecated and may be deleted in the future
    
    # Freeze all layers' weights in the model
    for param in vgg19_model.parameters():  # get all the parameters of the model
        param.requires_grad = False  # these layers won't be update during training
    
    # Unfreeze weights of last two fully connected layers (FC1 and FC2)
    for param in vgg19_model.classifier[0].parameters():
        param.requires_grad = True  # will be updated during training
    for param in vgg19_model.classifier[3].parameters():
        param.requires_grad = True  # will be updated during training
    
    # (Recommended) Modify the last layer for your number of classes
    class_to_idx = TODO
    num_classes = len(class_to_idx)
    model.classifier[6] = nn.Linear(4096, num_classes)
</code></pre>
<p>The last fully connected layer (initially with 1000 output features for ImageNet) is replaced with the number of features equal to the number of classes in your dataset, and this is the recommended (if not essential) approach. If your task requires a different number of classes, you must adapt the model to output the correct number of possibilities. Another thing to consider is that, while your task may have the same number of classes as ImageNet, the classes themselves are likely to be different. Retraining the output layer helps the model to better discriminate between the classes specific to your task.</p>
","2024-01-02 15:01:22","0","Answer"
"77746352","","How to fine tune FC1 and FC2 in VGG-19 PyTorch?","<p>I need to fine tune pretrained <a href=""https://i.sstatic.net/9SxXe.png"" rel=""nofollow noreferrer"">VGG-19</a> with pytorch. I have these specific tasks:</p>
<ol>
<li>Finetune the weights of all layers in the VGG-19 network.</li>
<li>Finetune the weights of only two last fully connected (FC1 and FC2) layers
in the VGG-19 network. And this is the only information given to me.</li>
</ol>
<p>VGG-19 structure is like below:</p>
<pre class=""lang-py prettyprint-override""><code>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (26): ReLU(inplace=True)
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): ReLU(inplace=True)
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
</code></pre>
<p>I tried to do first task like this and i think it is correct:</p>
<pre><code>model = models.vgg19(pretrained=True)

for param in model.parameters():
    param.requires_grad = True

model.classifier[6] = nn.Linear(4096, len(class_to_idx))
</code></pre>
<p>But i couldn't figure out second task, i tried this and i am not sure:</p>
<pre><code>model2 = models.vgg19(pretrained=True)

for param in model2.parameters():
    param.requires_grad = False

# Set requires_grad to True for FC1 and FC2
for param in model2.classifier[0].parameters():
    param.requires_grad = True

for param in model2.classifier[3].parameters():
    param.requires_grad = True

# Modify the last fully connected layers for the number of classes in your dataset
model2.classifier[6] = nn.Linear(4096, len(class_to_idx))
</code></pre>
<p>How to do second part? Should i keep the <code>model2.classifier[6]</code> or define a new Sequential structure?</p>
","2024-01-02 13:22:34","0","Question"