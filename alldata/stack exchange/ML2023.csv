Post Id,Parent Id,Title,Body,CreationDate,Score,PostType
"79661564","76319374","","<p>@<a href=""https://stackoverflow.com/users/16289309/rajdeeppal"">RajdeepPal</a> You can use python <code>uroman</code> package (<a href=""https://github.com/isi-nlp/uroman"" rel=""nofollow noreferrer""><code>github</code></a>).</p>
<pre class=""lang-py prettyprint-override""><code>
import uroman as ur
uroman = ur.Uroman()  
print(uroman.romanize_string('अंतिम लक्ष्य क्या है'))


output: amtim lakssya kyaa hai
</code></pre>
","2025-06-11 07:30:41","0","Answer"
"79627940","75664004","","<p>If you're using the Postgres app on macOS, download and install PostgreSQL 17. It already includes pgvector. Once installed, set the database on your app to the port where PostgreSQL 17 lives.</p>
<p>Solved the problem for me.</p>
","2025-05-19 00:15:02","0","Answer"
"79614784","76598217","","<p>Just to add to the other excellent answers here.   You seem to be misled by the term dimensions.   The image is an entanglement of two spaces a physical space where the pixels reside.  This space is represented by coordinates X and Y in the image.  The second space is the color space.  Each pixel is a combination of value R,G,B which are coordinates in 3D space where the axes are RED, GREEN and BLUE.   For example color white is represented by 1,1,1.   If it is slightly tinted yellow it will become 1,1,.9.  Most people would just call it white with a light tint of yellow.</p>
<p>So,  the code you put in the question reduces the image in the color space,  so it will use less precision for the color values.  These results in slightly less nuanced colors,  but also could result in much smaller file size.   To actually reduce the file size you will need to use an efficient encoding scheme.   This is why JPEG and GIF images are smaller than raw pixel dumps.    JPEG and GIF encoders do not use PCA  method to reduce the color space dimension,  but do work on the same principle.</p>
<p>If you want to reduce image size in X and Y dimensions the term you are looking for is downsampling.</p>
","2025-05-09 19:53:37","0","Answer"
"79597584","76535146","","<p>Yes, it's possible. Their documentation is very complicated, but I managed to create an empty dataset.</p>
<p>You have two options to create the dataset <a href=""https://cloud.google.com/document-ai/docs/create-dataset"" rel=""nofollow noreferrer"">details</a>:</p>
<ol>
<li><p>Provided bucket</p>
</li>
<li><p>Google managed</p>
</li>
</ol>
<p>I chose the second option.</p>
<pre><code>from google.cloud import documentai_v1beta3 as documentai
from google.api_core.client_options import ClientOptions

# Your settings
PROJECT_ID = &quot;PROJECT_ID&quot;
LOCATION = &quot;LOCATION&quot;
PROCESSOR_ID = &quot;PROCESSOR_ID&quot;
gcs_uri_prefix = &quot;GCS_URI&quot;

# Setup the endpoint correctly
client_options = ClientOptions(api_endpoint=f&quot;{LOCATION}-documentai.googleapis.com&quot;)

# Initialize the Document AI client
client = documentai.DocumentServiceAsyncClient(client_options=client_options)

# Build the full dataset resource name
dataset_name = f&quot;projects/{PROJECT_ID}/locations/{LOCATION}/processors/{PROCESSOR_ID}/dataset&quot;

# Prepare the dataset configuration
dataset = documentai.Dataset(
    name=dataset_name,
    gcs_managed_config=documentai.Dataset.GCSManagedConfig(
        gcs_prefix=documentai.GcsPrefix(
            gcs_uri_prefix=gcs_uri_prefix
        )
    ),
    spanner_indexing_config=documentai.Dataset.SpannerIndexingConfig()
)

# Prepare the update request
update_request = documentai.UpdateDatasetRequest(
    dataset=dataset
)

# Call the update_dataset API
operation = client.update_dataset(request=update_request)

response = (await operation).result()

</code></pre>
","2025-04-29 04:01:03","0","Answer"
"79595685","75472472","","<p>The answer is not so straight forward. From a mathematical perspective, if the importance is derived from tree based models, then yes, because the sum of importances adds up to 100 as explained by @Mattravel.</p>
<p>However, random forests tend to give more importance to features with higher cardinality, and hence binary features, like those coming from OHE will inherently show lower importance.</p>
<p>So, while it is true that we can add importance, to truly assess the importance of a categorical variable we might want to use additional methods, like using a different encoding, or a different feature selection process that can take up categorical variables as inputs.</p>
<p>For a list of feature selection process that support categorical variables check out <a href=""https://feature-engine.trainindata.com/en/latest/user_guide/selection/index.html"" rel=""nofollow noreferrer"">feature-engine's documentation</a>.</p>
<p><strong>Disclaimer</strong>: The links correspond to the docs of an open-source Python library, and I am the maintainer of that library.</p>
","2025-04-28 01:45:27","0","Answer"
"79583657","77131746","","<pre><code>import nltk
from nltk.tokenize import word_tokenize

nltk.download('punkt_tab')
sample_text = &quot;This is random text&quot;
tokens = word_tokenize(sample_text)

print(tokens)
</code></pre>
","2025-04-20 18:54:37","0","Answer"
"79581088","77298910","","<p>In your case the root cause is that you’re on Python 3.6.8, and as of W&amp;B 0.15 the library no longer fully supports Python 3.6—so the <code>wandb</code> you installed is incomplete.</p>
<p>Either upgrade Python to 3.7+:</p>
<pre><code># outside your old venv
python3.9 -m venv ~/venvs/psla39
source ~/venvs/psla39/bin/activate
pip install --upgrade pip
pip install wandb
</code></pre>
<p>or pin WandB to a Python 3.6-compatible version:</p>
<pre><code>pip uninstall wandb
pip install &quot;wandb&lt;0.15.0&quot;
</code></pre>
","2025-04-18 13:06:03","0","Answer"
"79558267","75089762","","<p>`coef` shows the coefficients for the rules and linear terms. In a binary classification problem, they are logistic regression coefficients. That is, the increase in log-odds of belonging to the target class, if the conditions of the rule apply. Rules with a negative coefficient decrease the probability of belonging to the target class if their conditions apply, rules with a positive coefficient increase the probability of belonging to the target class if their conditions apply. The larger the value of the coefficient, the larger the in- or decrease.</p>
","2025-04-06 13:31:24","0","Answer"
"79549093","76248184","","<p>You can achieve this by defining a custom metric as follows.</p>
<p>(Formula: (1-e^(num_params/max_params)) * weight)</p>
<pre class=""lang-py prettyprint-override""><code>class ModelComplexity(keras.metrics.Metric):
  def __init__(self, model: keras.Model, name='model_complexity', max_params=500000, weight=1.0, **kwargs):
    &quot;&quot;&quot;
    Custom Keras metric for tracking model complexity using the total number of parameters (trainable and not trainable).
    The metric is small for low complexity and large for high complexity.
    
    Arguments:
      model: the keras.Model 
      name: the metric name (default: 'model_complexity')
      max_params: point at which metric is euqal to 1-e^-1 (~0.63)
      weight: weight to multiply metric by
    &quot;&quot;&quot;
    super().__init__(name=name, **kwargs)
    self.num_params = model.count_params()
    self.max_params = max_params
    self.weight = weight

  def update_state(self, y_true, y_pred, sample_weight=None):
    pass

  def result(self):
    return (1 - np.exp( - self.num_params / self.max_params)) * self.weight

  def reset_state(self):
    self.complexity = 0
</code></pre>
<p>You can then use both accuracy metric and complexity metric when compiling the model.</p>
<pre class=""lang-py prettyprint-override""><code>model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
        loss='mean_absolute_error',
        metrics=['accuracy', ModelComplexity(model)]
    )
</code></pre>
<p>Finally, you can define multiple objectives when defining the tuner.</p>
<pre class=""lang-py prettyprint-override""><code>tuner = kt.Hyperband(model_builder,
                     objective=[kt.Objective(&quot;val_accuracy&quot;, direction=&quot;max&quot;),
                                kt.Objective(&quot;model_complexity&quot;, direction=&quot;min&quot;)],
                     max_epochs=10,
                     overwrite=True,
                     directory='my_dir30',
                     project_name='intro_to_kt30')
</code></pre>
<p>Note: model.count_params() only works on models that have been built, meaning when specifying your model, you need to add an input layer.</p>
<pre class=""lang-py prettyprint-override""><code>model = keras.Sequential([
    keras.Input(shape=(28,28,), name=&quot;input&quot;)
    # ... Your Layers
])
</code></pre>
<p>Note: I tested this by subclassing the kt.Hypermodel class but it should work with the build_model function aswell.</p>
","2025-04-01 20:08:32","0","Answer"
"79544725","77479005","","<p>if you don't require CUDA, then you can install mmcv lite:<br />
<code>pip install mmcv-lite</code></p>
<blockquote>
<ul>
<li><strong>mmcv-lite</strong>: lite, without CUDA ops but all other features, similar to mmcv&lt;1.0.0. It is useful when you do not need those CUDA ops.</li>
</ul>
<p><strong>Note</strong>: Do not install both(mmcv and mmcv-lite) versions in the same environment, otherwise you may encounter errors like <code>ModuleNotFound</code>. You need to uninstall one before installing the other. <code>Installing the full version is highly recommended if CUDA is available</code>.</p>
</blockquote>
","2025-03-30 14:27:41","0","Answer"
"79538357","77469097","","<p>Since March 18, 2025 (<a href=""https://x.com/OpenAIDevs/status/1902114937624830106"" rel=""nofollow noreferrer"">announcement here</a>), it is possible to provide PDF files directly, and even enforce a structured output. No need for OCR or converting to images.</p>
<p>The guide is <a href=""https://platform.openai.com/docs/guides/pdf-files?api-mode=chat"" rel=""nofollow noreferrer"">here</a>.</p>
<p>Here is a full example of parsing input PDFs with the API using <code>gpt-4o-mini</code> and outputting a structured JSON response, e.g. to parse PDFs containing bloodwork:</p>
<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/env python3
# /// script
# requires-python = &quot;&gt;=3.11&quot;
# dependencies = [
#     &quot;openai&quot;,
#     &quot;python-dotenv&quot;,
# ]
# ///
#

import json
import os
import base64
import argparse
from pathlib import Path
import openai
from dotenv import load_dotenv

load_dotenv()

openai.api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)

BLOODWORK_SCHEMA = {
    &quot;$schema&quot;: &quot;http://json-schema.org/draft-07/schema#&quot;,
    &quot;type&quot;: &quot;object&quot;,
    &quot;properties&quot;: {
        &quot;tests&quot;: {
            &quot;type&quot;: &quot;array&quot;,
            &quot;items&quot;: {
                &quot;type&quot;: &quot;object&quot;,
                &quot;properties&quot;: {
                    &quot;name&quot;: {
                        &quot;type&quot;: &quot;string&quot;,
                        &quot;description&quot;: &quot;Name of the test (e.g., 'Glucose', 'Hemoglobin A1c').&quot;,
                    },
                    &quot;result&quot;: {
                        &quot;type&quot;: &quot;number&quot;,
                        &quot;description&quot;: &quot;Numeric result of the test.&quot;,
                    },
                    &quot;unit&quot;: {
                        &quot;type&quot;: &quot;string&quot;,
                        &quot;description&quot;: &quot;Unit of measurement (e.g., 'mg/dL', '%').&quot;,
                    },
                },
                &quot;required&quot;: [&quot;name&quot;, &quot;result&quot;, &quot;unit&quot;],
                &quot;additionalProperties&quot;: False,
            },
        },
    },
    &quot;required&quot;: [&quot;tests&quot;],
    &quot;additionalProperties&quot;: False,
}


def parse_input(input_path: str) -&gt; str:
    &quot;&quot;&quot;
    Parse an input PDF file with the OpenAI API to extract bloodwork results.

    Args:
        input_path: Path to the PDF file to analyze

    Returns:
        str: Extracted bloodwork data in the specified JSON format
    &quot;&quot;&quot;
    # read and encode the PDF file
    with open(input_path, &quot;rb&quot;) as file:
        base64_pdf = base64.b64encode(file.read()).decode(&quot;utf-8&quot;)

    # prepare the messages for the API
    messages = [
        {
            &quot;role&quot;: &quot;system&quot;,
            &quot;content&quot;: &quot;You are a medical data extraction assistant. Extract bloodwork data from the provided PDF into the specified JSON schema format. Be precise and thorough.&quot;,
        },
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {
                    &quot;type&quot;: &quot;file&quot;,
                    &quot;file&quot;: {
                        &quot;filename&quot;: Path(input_path).name,
                        &quot;file_data&quot;: f&quot;data:application/pdf;base64,{base64_pdf}&quot;,
                    },
                },
                {
                    &quot;type&quot;: &quot;text&quot;,
                    &quot;text&quot;: &quot;Please extract all bloodwork data from this PDF into a structured format. Use the provided JSON schema for the output structure.&quot;,
                },
            ],
        },
    ]

    # call the OpenAI API with structured output
    print(&quot;Calling OpenAI API...&quot;)

    response = openai.chat.completions.create(
        model=&quot;gpt-4o-mini&quot;,
        messages=messages,
        max_tokens=8192,
        temperature=0,
        response_format={
            &quot;type&quot;: &quot;json_schema&quot;,
            &quot;json_schema&quot;: {
                &quot;name&quot;: &quot;bloodwork&quot;,
                &quot;schema&quot;: BLOODWORK_SCHEMA,
                &quot;strict&quot;: True,
            },
        },
    )

    print(&quot;OpenAI API call completed.&quot;)

    return response.choices[0].message.content


def main():
    parser = argparse.ArgumentParser(
        description=&quot;Extract bloodwork data from PDF files using OpenAI API&quot;
    )
    parser.add_argument(
        &quot;input&quot;, type=str, nargs=&quot;+&quot;, help=&quot;Input PDF file(s) to process&quot;
    )

    args = parser.parse_args()

    for input_file in args.input:
        if not input_file.lower().endswith(&quot;.pdf&quot;):
            print(f&quot;Skipping {input_file} - not a PDF file&quot;)
            continue

        try:
            # parse the input PDF
            data = parse_input(input_file)
            try:
                data = json.loads(data)
            except json.JSONDecodeError as e:
                print(f&quot;Error parsing JSON: {e}&quot;)
                print(f&quot;Raw data: {data}&quot;)
                raise e

            # create output filename
            output_file = str(Path(input_file).with_suffix(&quot;.json&quot;))

            # save the extracted data
            with open(output_file, &quot;w&quot;) as f:
                json.dump(data, f, indent=2)

            print(f&quot;Successfully processed {input_file} -&gt; {output_file}&quot;)

        except Exception as e:
            print(f&quot;Error processing {input_file}: {str(e)}&quot;)


if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<p>Create a <code>.env</code> file containing <code>OPENAI_API_KEY=sk-abcdefg</code> with your secret key, then run it with, e.g. <a href=""https://docs.astral.sh/uv/"" rel=""nofollow noreferrer""><code>uv</code></a>:</p>
<pre class=""lang-bash prettyprint-override""><code>uv run analyze-bloodwork.py /path/to/input.pdf
</code></pre>
","2025-03-27 09:15:44","2","Answer"
"79484008","75664004","","<p>In 2025 only the newer postgresql versions seem to work with pgvector. Make sure that no other postgresql services are running.</p>
<p>Install newer version of postgresql:</p>
<pre><code>brew install postgresql@17
brew link --overwrite postgresql@17
brew install pgvector
brew services start postgresql@17 &amp;&amp; sleep 1
</code></pre>
<p>Check if postgresql is running smoothly: 'brew services info postgresql@17'</p>
<p>Activate pgvector:</p>
<pre><code>psql -d postgres -c 'CREATE EXTENSION vector'
</code></pre>
","2025-03-04 14:39:03","0","Answer"
"79475336","77479005","","<p>I had this error due to an <strong>incompatibilty</strong> with the <strong>torch version</strong> I was using. I was trying to use it on kaggle which uses default: torch 2.5.1+cu121.</p>
<p>My solution:</p>
<ol>
<li><p>Install a compatible version of PyTorch. In my case, I downgraded to PyTorch 2.0.0 with CUDA 11.7:</p>
<pre><code>!pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.1 --extra-index-url https://download.pytorch.org/whl/cu117
</code></pre>
</li>
<li><p>Specify the torch and cuda version during mmcv-full package installation too:</p>
<pre><code>pip install mmcv-full==1.7.2 -f https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html
</code></pre>
</li>
</ol>
","2025-02-28 11:12:09","1","Answer"
"79454648","76248695","","<p>If any of the above solutions didn't solve the issue. You could try doing the following to help get rid of the error of being unable to install d2l package on Windows.</p>
<ol>
<li><p>Download the Python version &gt;3.10 &amp; &lt; 3.11</p>
</li>
<li><p>update the torch and torchvision versions to 2.3 and 0.18 with the command.</p>
<p>pip install torch==2.3 torchvision==0.18</p>
</li>
<li><p>Download the d2l-en package using the command.</p>
<p>git clone <a href=""https://github.com/d2l-ai/d2l-en.git"" rel=""nofollow noreferrer"">https://github.com/d2l-ai/d2l-en.git</a>
cd ./d2l-en</p>
</li>
<li><p>Upgrade the version of numpy from from 1.23.5 to 1.26.4 in the setup.py file</p>
</li>
<li><p>Update the setup tools</p>
<p>pip install -U setuptools</p>
</li>
<li><p>Install wheel and bdist_wheel as version pip does auto download those packages</p>
<p>pip install wheel
python setup.py bdist_wheel</p>
</li>
<li><p>Run the following commands to finally download the d2l package.</p>
<p>python ./setup.py bdist_wheel
pip install -U ./dist/d2l-1.0.3-py3-none-any.whl
pip install d2l==1.0.3</p>
</li>
</ol>
<p>These steps helped me get rid of the issue and it works like a charm.</p>
<p>Thanks.</p>
","2025-02-20 13:20:11","0","Answer"
"79445871","76020437","","<p>Not a specific answer, but I can't comment and thought this may be helpful enough to share.</p>
<p>I struggled with this exact issue for a week before finally figuring out that the file I wanted to apply inverse.transform to MUST match the original 'scaled' file regarding the number of columns.  In your case above, (26768,29) (31,) (26768,29) is telling you that they aren't the same.  In this case, it looks like one file is 29 columns wide while the other is '' wide.  Fix that (I dropped a column that had been added between the two events) and you should be good to go.</p>
","2025-02-17 15:29:09","0","Answer"
"79371321","77469097","","<p>I use a combo of claude and openai. You can upload PDFs directly to Claude api and it will extract desired info, but it can't do structured outputs. So I tell Claude to give json about the contents of the pdf (the best it can), then i pass the response to openai to convert Claude's response into actual json. Takes two api calls instead of one, but the upside is no first converting PDFs to images (no quick and easy way to do this in Python or nodejs), no extracting only text or only image (Claude can interpret both), and it's fast enough to run in a serverless lambda without the need for lambda layers or special binaries, just first upload the file to s3, then convert to base64 before passing to Claude. Works wonders</p>
","2025-01-20 12:28:01","0","Answer"
"79362374","74979359","","<p>I had the same confusion because I was comparing the <strong>position-wise feedforward</strong> and the <strong>output projection linear</strong> (at the end of the attention block) which appeared the exact same for me. I even thought the implementation should be a &quot;time-distributed-like&quot; layer or some explicit distinction for the position-wise linear based on its naming.</p>
<p>However, I found out that it's just the <strong>conceptual way of thinking about what the vectors represent</strong> not the computation itself.</p>
<p>In <strong>output projection linear</strong> the input tensor would be of shape <code>(batch, seq, num_head * head_dim)</code>, so each vector along the last dimension here represents the <strong>mixed information from different attention heads</strong>, so the linear layer here tries to combine the different heads perspectives into a single perspective for this token/position.</p>
<p>In <strong>position-wise feedforward</strong> layer the input tensor would be of shape <code>(batch, seq, hidden_dim)</code>, each vector along the last dimension <strong>represents a single token features</strong>, so the linear layer operation here appear to treat each vector independently.</p>
<p>So even though in most cases the <code>num_head * head_dim</code> would equal <code>hidden_dim</code>, it's just about what is represented by the vectors and what is the purpose of the linear layer at this stage.</p>
","2025-01-16 16:25:48","0","Answer"
"79353314","77061898","","<p>A token is not a word but a word part. On average you can count 4 letters per token.</p>
<p>Your try to set max_new_tokens = 300 will limit your output to round about 4 x 300 = 1200 letters.</p>
<p>Increase your max_new_tokens setting to a higher value.</p>
","2025-01-13 19:59:55","0","Answer"
"79345378","75649038","","<p>It was my mistake. I thought the output in both APIs would be the same but it doesn't seem like that. I just removed the np.argmax() line when predicting with Sklearn API. It seems this API already predict directly the class. Don't remove the question in case someone else is dealing with similar issues.</p>
","2025-01-10 10:29:45","0","Answer"
"79328232","75633185","","<p>The same problem happened to me. It is due to incompatibility of python packages. missingpy is incompatible with the last version of python package.</p>
<p>Precisely the private function _check_weights does not exist anymore in <code>neighbors._base.py</code> in the last version of scikit-learn.</p>
<p>Furthemore, if you have a virtual environment, open the directory <code>&quot;.venv/lib/python3.13/site-packages/missingpy/knnimpute.py&quot;</code>, you can see that _check_weights is imported from <code>sklearn.neighbors.base</code> and not from <code>sklearn.neighbors._base</code>.</p>
<p>This means that missingpy is not maintain anymore.</p>
<p>If you want to use it, you need to uninstall the newest version of scikit-learn :</p>
<p><code>pip uninstall scikit-learn</code></p>
<p>And install one of the latest version of scilit-learn which is compatible with missingpy. For example you can install a version &lt;= 1.1. For example :</p>
<p><code>pip install scikit-learn==1.1</code></p>
<p>Finally use the following commands.</p>
<pre class=""lang-py prettyprint-override""><code>import sklearn.neighbors._base
sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base  
from missingpy import MissForest
</code></pre>
<p>The package below allows you to carry out miss forest imputation and it is maintained :</p>
<p>pip install MissForest</p>
<p>References :</p>
<p><a href=""https://pypi.org/project/MissForest/"" rel=""nofollow noreferrer"">https://pypi.org/project/MissForest/</a></p>
","2025-01-04 04:20:05","0","Answer"
"79289270","77131746","","<p>The above interactive solutions didn't work for me.  Instead, I made a virtual environment (<code>venv</code>) for my workspace (activated), then followed the command line installation from here: <a href=""https://www.nltk.org/data.html"" rel=""nofollow noreferrer"">https://www.nltk.org/data.html</a></p>
<p><code>python -m nltk.downloader all</code></p>
<p>I imagine I could have simply downloaded <code>tokenizers</code>.</p>
","2024-12-17 20:19:43","0","Answer"
"79279420","75085236","","<p>So I encountered this exact problem and my issue was not correctly unpacking the train_test_split method to my data. I used:</p>
<pre><code>X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
</code></pre>
<p>instead of</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
</code></pre>
<p>so I know in your case this might not apply but this is for anyone who encounters this problem.</p>
<p>Just look at your code again.</p>
","2024-12-13 19:39:46","0","Answer"
"79245816","76204705","","<p>There are a few <code>R</code> Packages that also enable relatively transparent bootstrap LASSO analysis!</p>
<p>Check out:</p>
<ul>
<li><a href=""https://github.com/jameshorine/fastFeatures"" rel=""nofollow noreferrer"">https://github.com/jameshorine/fastFeatures</a></li>
<li><a href=""https://www.dmolitor.com/bolasso/index.html"" rel=""nofollow noreferrer"">https://www.dmolitor.com/bolasso/index.html</a></li>
</ul>
<p>You dont have to explicitly use the <code>boot</code> package - you may simply loop through the lasso procedure and save off the coefficients.</p>
<p>Saving off the individually &quot;resampled&quot; data sets is going to get memory-expensive really fast - I would suggest to simply save off the sampling scheme per iteration: i.e. the columns and rows that were sampled.</p>
<p>Your particular ask was something that I had not thought of with <code>fastFeatures</code>, and is a great idea to keep as an option for further analysis.</p>
","2024-12-02 22:51:58","1","Answer"
"79179736","76463707","","<p>Do:</p>
<p><code>pip install cython</code></p>
<p>Then try whatever you want.</p>
","2024-11-12 03:54:47","0","Answer"
"79175345","76901604","","<p>Use the <code>gr.HTML()</code> component:</p>
<pre><code>with gr.Blocks() as demo:
    title = gr.HTML(&quot;&lt;h1&gt;Dataset Explorer&lt;/h1&gt;&quot;)
    ...
</code></pre>
","2024-11-10 17:07:13","1","Answer"
"79108269","75886125","","<p>Speedup improvements will depend on several factors, including your model and hardware as mentioned by other answers.</p>
<p>Just noting here that in some cases I've seen further speedups by compiling the entire training loop instead of just the model, as explained by <a href=""https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html#demonstrating-speedups"" rel=""nofollow noreferrer"">this pytorch tutorial</a>.</p>
<p>Here's a simplified example from the tutorial:</p>
<pre><code>opt = torch.optim.Adam(model.parameters())

def train(mod, data):
    opt.zero_grad(True)
    pred = mod(data[0])
    loss = torch.nn.CrossEntropyLoss()(pred, data[1])
    loss.backward()
    opt.step()


model = init_model()
train_opt = torch.compile(train, mode=&quot;reduce-overhead&quot;)

for i in range(N_ITERS):
    inp = generate_data(16)
    train_opt(model, inp)
</code></pre>
<p>Here again the speedups depend on the detail and implementation of your training loop.</p>
","2024-10-21 00:03:55","0","Answer"
"79108114","77068899","","<p>Another option is <a href=""https://github.com/Yunuuuu/ggalign"" rel=""nofollow noreferrer"">ggalign</a>, you can</p>
<pre class=""lang-r prettyprint-override""><code># randomly generated phenograph data
set.seed(1)
TotalPercentage &lt;- data.frame(
    `Participant ID` = c(&quot;123&quot;, &quot;456&quot;, &quot;789&quot;),
    `1` = 125 * runif(72),
    `2` = 75 * runif(72),
    `3` = 175 * runif(72),
    `4` = 10 * runif(72),
    `5` = 100 * runif(72),
    `6` = 150 * runif(72),
    `7` = 200 * runif(72),
    check.names = FALSE
)
library(ggalign)
#&gt; Loading required package: ggplot2
</code></pre>
<pre class=""lang-r prettyprint-override""><code>ggstack(TotalPercentage) +
    # add color bar plot
    # we transform the input data frame into a long format data frame
    ggalign(action = plot_action(
        data = function(x) {
            ans &lt;- tidyr::pivot_longer(x,
                cols = as.character(1:7),
                names_to = &quot;group&quot;
            )
            dplyr::summarise(
                ans,
                value = sum(value), .by = c(`Participant ID`, group, .y)
            )
        }
    )) +
    geom_col(aes(value, .y, fill = group),
        orientation = &quot;y&quot;,
        position = position_fill()
    ) +
    scale_fill_brewer(palette = &quot;Dark2&quot;) +
    # add dendrogram
    align_dendro(data = ~ .x[-1L]) &amp;
    scale_x_continuous(expand = expansion()) &amp;
    theme(plot.margin = margin(l = 5, r = 10))
</code></pre>
<p><a href=""https://i.sstatic.net/bv1EJTUr.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bv1EJTUr.png"" alt=""enter image description here"" /></a>
</p>
<p><sup>Created on 2024-10-21 with <a href=""https://reprex.tidyverse.org"" rel=""nofollow noreferrer"">reprex v2.1.0</a></sup>
~</p>
","2024-10-20 21:47:28","1","Answer"
"79108029","77029483","","<p>The problem arises when the whole dataset is loaded by the GPU (instead of loading it with the CPU and only sending batches to the GPU).</p>
<p>I managed to fix this type of issue by adding <code>with tf.device('cpu'):</code> to the data loading process (just that, the remaining training should be done with the GPU).</p>
<p>Applied to your example code, something along the lines of:</p>
<pre class=""lang-py prettyprint-override""><code>model = build_model(
    filters=50,
    filter_step=1,
    stages=5,
    stage_steps=1,
    initial_convolutions=0,
    stacks=1,
)

print(model.summary()) 

with tf.device('cpu'):
    dataset = tf.data.Dataset.from_tensor_slices((X, y))
    dataset = dataset.batch(1)

model.fit(
    dataset,
    epochs=2**7,
    callbacks=[
        EarlyStopping(monitor=&quot;loss&quot;, patience=5, min_delta=1e-7, start_from_epoch=10),
        LearningRateScheduler(step_decay)
    ],
)
</code></pre>
<p><em>Thanks to @mrk's <a href=""https://stackoverflow.com/a/77175057/6135182"">answer</a> for pointing me in the right direction of the issue at hand. See also <a href=""https://stackoverflow.com/q/73610400/6135182"">this question</a> and the <a href=""https://github.com/keras-team/tf-keras/issues/435#issue-1909335832"" rel=""nofollow noreferrer"">linked GitHub issue</a>.</em></p>
","2024-10-20 20:44:12","0","Answer"
"79051980","77737016","","<p>You can create a second view of the tensor that doesn't allow gradients via detach. Apply the anti mask to that and then sum it. So basically:</p>
<pre><code>return (self.subdiagonal_block * mask) +   
  (self.subdiagonal_block.detach() * ~mask)
</code></pre>
","2024-10-03 19:45:58","0","Answer"
"79043989","77490008","","<p>I faced a similar problem for the last couple of days and tried almost all the solutions available.
Finally what worked was simply upgrading <strong>typing_extensions</strong></p>
<pre><code>pip install typing_extensions&gt;=4.5 --upgrade
</code></pre>
","2024-10-01 16:26:07","0","Answer"
"79005663","75730103","","<p>I guess you can by just modifying the data files or by providing a new path that contain YOLOv8 format. Below you can find an example:</p>
<pre><code>!yolo task=detect mode=train resume model=/content/drive/MyDrive/yolov8/training_results/helmets5/weights/last.pt data=/content/drive/MyDrive/yolov8/dataset.yaml epochs=100 imgsz=640 batch=8 project=/content/drive/MyDrive/yolov8/training_results name=helmets
</code></pre>
<p>Modify the original command like this. Just change the model from yolov8.pt to last.pt and it will resume training from last stopped epoch</p>
<p>the code above is copied from a github discussion in yolov8 profile</p>
","2024-09-20 07:15:54","0","Answer"
"78987649","77444565","","<p>Try running your models again but <strong>without applying SMOTE</strong> to your train dataset: it ruins it by adding synthetic data/noise.</p>
<p>Here is a list of sources and social media related to it:</p>
<ul>
<li>CrossValidated:
<a href=""https://stats.stackexchange.com/questions/357466/are-unbalanced-datasets-problematic-and-how-does-oversampling-purport-to-he"">https://stats.stackexchange.com/questions/357466/are-unbalanced-datasets-problematic-and-how-does-oversampling-purport-to-he</a></li>
<li>Frank Harrell:
<a href=""https://twitter.com/f2harrell/status/1062424969366462473"" rel=""nofollow noreferrer"">https://twitter.com/f2harrell/status/1062424969366462473</a></li>
<li>Abishek: <a href=""https://twitter.com/abhi1thakur/status/1480525555527258122?t=guznAsPg_LbF_H-Qh1tOpg&amp;s=08"" rel=""nofollow noreferrer"">https://twitter.com/abhi1thakur/status/1480525555527258122?t=guznAsPg_LbF_H-Qh1tOpg&amp;s=08</a></li>
<li>Carlos Mougan: <a href=""https://twitter.com/CarlosMougan/status/1475756319999205377"" rel=""nofollow noreferrer"">https://twitter.com/CarlosMougan/status/1475756319999205377</a></li>
<li>JFPuget:
<a href=""https://twitter.com/JFPuget/status/1475769513480179717"" rel=""nofollow noreferrer"">https://twitter.com/JFPuget/status/1475769513480179717</a></li>
</ul>
<p>Paper &quot;To SMOTE or not to SMOTE&quot; that designed this problem:
<a href=""https://arxiv.org/abs/2201.08528"" rel=""nofollow noreferrer"">https://arxiv.org/abs/2201.08528</a></p>
","2024-09-15 14:51:40","0","Answer"
"78969357","77469097","","<p>You can <strong>convert PDF to TEXT</strong>, since I face the same issue, I used <strong>PyPDF2</strong>.</p>
<pre><code>import PyPDF2

def pdf_to_text(pdf_path):

# Open the PDF file in read-binary mode
with open(pdf_path, 'rb') as pdf_file:
    # Create a PdfReader object instead of PdfFileReader
    pdf_reader = PyPDF2.PdfReader(pdf_file)

    # Initialize an empty string to store the text
    text = ''

    for page_num in range(len(pdf_reader.pages)):
        page = pdf_reader.pages[page_num]
        text += page.extract_text()


return text
</code></pre>
<p>Finally feed the text  in the context of the prompt.</p>
","2024-09-10 11:54:30","-1","Answer"
"78959569","77131746","","<p>I tried different ways but the issue is resolved by simply running these commands:</p>
<pre><code>import nltk
nltk.download('punkt_tab') 
</code></pre>
","2024-09-07 07:08:34","0","Answer"
"78934568","75902400","","<p>Overfitting
Underfitting
lack of sufficient data</p>
","2024-08-31 07:31:02","-1","Answer"
"78924474","77469097","","<p>May 2025 edit: according to the <a href=""https://platform.openai.com/docs/guides/pdf-files?api-mode=responses&amp;lang=python"" rel=""nofollow noreferrer"">official guide</a>, using OpenAI GPT-4.1 allows to extract content of (or answer questions on) an input pdf file <code>foobar.pdf</code> stored locally, with a solution along the lines of</p>
<pre class=""lang-py prettyprint-override""><code>from openai import OpenAI
import os

filename = &quot;foobar.pdf&quot;
prompt = &quot;&quot;&quot;Extract the content from the file provided without altering it.
            Just output its exact content and nothing else.&quot;&quot;&quot;

client = OpenAI(api_key=os.environ.get(&quot;MY_OPENAI_KEY&quot;))

file = client.files.create(
    file=open(filename, &quot;rb&quot;),
    purpose=&quot;user_data&quot;
)

response = client.responses.create(
    model=&quot;gpt-4.1&quot;,
    input=[
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {
                    &quot;type&quot;: &quot;input_file&quot;,
                    &quot;file_id&quot;: file.id,
                },
                {
                    &quot;type&quot;: &quot;input_text&quot;,
                    &quot;text&quot;: prompt,
                },
            ]
        }
    ]
)
</code></pre>
<p>The <code>prompt</code> can of course be replaced with the desired user request and I assume that the openai key is stored in a env var named <code>MY_OPENAI_KEY</code>.</p>
<p>P.S. I have edited the answer as this approach is much more streamlined w.r.t to the assistants-based 2024 solution that you can see in the edit history, heavily inspired by <a href=""https://medium.com/@erik-kokalj/effectively-analyze-pdfs-with-gpt-4o-api-378bd0f6be03"" rel=""nofollow noreferrer"">https://medium.com/@erik-kokalj/effectively-analyze-pdfs-with-gpt-4o-api-378bd0f6be03</a></p>
","2024-08-28 16:58:14","21","Answer"
"78893697","75918536","","<p>My intuition is that combining loocv and rmse can be misleading, because you will have one curve computed using rmse (training) and the other with MAE (validation). So, you lose interpretability between the two curves.</p>
<p>This would not happen if you use mean squared error instead of root mean squared error.</p>
","2024-08-20 17:19:29","0","Answer"
"78884106","76034630","","<p>By default the TransformerEncoderLayer is expecting the sequence as first dimension of the input:</p>
<p>Updating you code as follows may solve your issue :</p>
<pre><code>transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads), num_layers=num_layers,batch_first=True)
</code></pre>
","2024-08-18 08:38:09","0","Answer"
"78869797","77450322","","<p>Restarting the runtime works even if you are using Databricks clusters. I faced the same issue and restarting the runtime worked.</p>
","2024-08-14 08:10:21","1","Answer"
"78834736","76463707","","<p>As lib lap has not been updated since 2018, it is believed that it has been discontinued. I solved this problem by installing a lib that has the same functions as the current one:</p>
<pre><code>pip install lapx
</code></pre>
","2024-08-05 13:43:01","0","Answer"
"78817208","77126001","","<p>Some more explanatory code:</p>
<pre class=""lang-py prettyprint-override""><code>import json
import numpy as np
import shap
import xgboost as xgb
from scipy.special import expit, logit

print('shap.__version__:',shap.__version__)
print('xgb.__version__:',xgb.__version__)
print()

X, y = shap.datasets.adult()

estimator = xgb.XGBClassifier(
    objective='binary:logistic',
    n_estimators=200)

estimator.fit(X,y)

explainer = shap.TreeExplainer(
    model=estimator,
    feature_perturbation='tree_path_dependent',
    model_output='raw')

print(&quot;estimator.get_params()['n_estimators']:&quot;,estimator.get_params()['n_estimators'])
print('explainer.model.tree_limit:',explainer.model.tree_limit)
print()

print(&quot;float(json.loads(estimator.get_booster().save_config())['learner']['learner_model_param']['base_score']):&quot;,float(json.loads(estimator.get_booster().save_config())['learner']['learner_model_param']['base_score']))
print('expit(explainer.model.base_offset):',expit(explainer.model.base_offset))
print('expit(explainer.expected_value):',expit(explainer.expected_value))
print()

shap_values = explainer(X)

# phi is taken from shap.explainers._tree.TreeExplainer.shap_value
# Also see https://xgboost.readthedocs.io/en/stable/prediction.html
phi = explainer.model.original_model.predict(
    xgb.DMatrix(X),
    #iteration_range=(0, explainer.model.tree_limit),
    pred_contribs=True,
    approx_contribs=False,
    validate_features=False)

print('expit(estimator.get_booster().predict(xgb.DMatrix(X),pred_contribs=True))[0,-1]:',expit(estimator.get_booster().predict(xgb.DMatrix(X),pred_contribs=True))[0,-1])
print('expit(phi[0, -1]):',expit(phi[0, -1]))
print('expit(explainer.expected_value):',expit(explainer.expected_value))
print()

print('expit(phi[0].sum()):',expit(phi[0].sum()))
print('estimator.predict_proba(X.loc[[0]])[0,1]:',estimator.predict_proba(X.loc[[0]])[0,1])
print()

# https://xgboost.readthedocs.io/en/latest/tutorials/intercept.html
print('X.shape:',X.shape)
print('phi.shape:',phi.shape,'(extra column for expected value aka intercept)')
print('np.all(phi[:,-1] == explainer.expected_value):',np.all(phi[:,-1] == explainer.expected_value),'(the expected value is the same for all predictions)')
</code></pre>
<p>(<a href=""https://stackoverflow.com/questions/78818308/how-does-xgboost-calculate-base-score"">I don't know how XGBoost calculates <code>base_score</code>.</a>)</p>
<p>Output:</p>
<pre class=""lang-py prettyprint-override""><code>shap.__version__: 0.46.0
xgb.__version__: 2.1.0

estimator.get_params()['n_estimators']: 200
explainer.model.tree_limit: 200

float(json.loads(estimator.get_booster().save_config())['learner']['learner_model_param']['base_score']): 0.26177529
expit(explainer.model.base_offset): [0.26177529]
expit(explainer.expected_value): [0.26177529]

expit(estimator.get_booster().predict(xgb.DMatrix(X),pred_contribs=True))[0,-1]: 0.21074083
expit(phi[0, -1]): 0.21074083
expit(explainer.expected_value): 0.21074083

expit(phi[0].sum()): 0.000256332
estimator.predict_proba(X.loc[[0]])[0,1]: 0.00025633152

X.shape: (32561, 12)
phi.shape: (32561, 13) (extra column for expected value aka intercept)
np.all(phi[:,-1] == explainer.expected_value): True (the expected value is the same for all predictions)
</code></pre>
","2024-07-31 15:35:06","0","Answer"
"78789068","76537113","","<p>The issue is that accuracy is not well defined for 1 sample in the test sample which is what leave one out does . The solution is to store all trues and predictions from every fold into arrays and calculate the desired score based on the stored arrays/list (Like what was done in Parneeth's solution).
Hope this helps someone.</p>
","2024-07-24 14:46:59","0","Answer"
"78788900","77541978","","<p>TLDR; scikit-learn uses <code>idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1</code> to prevent zero divisions. instead of <code>idf(t) = n/df(t) + 1</code>. You've seemed to miss the <code>log</code> and additional <code>+1</code>'s.</p>
<p>The implementation details are briefly descibed in the docs, as it says</p>
<blockquote>
<p>Equivalent to <code>CountVectorizer</code> followed by <code>TfidfTransformer</code>.
<a href=""https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"" rel=""nofollow noreferrer"">scikit-learn#TfidfVectorizer</a></p>
</blockquote>
<p>When looking at the docs of <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"" rel=""nofollow noreferrer"">scikit-learn#TfidfTransformer</a></p>
<blockquote>
<p>The formula that is used to compute the tf-idf for a term <code>t</code> of a document d in a document set is <code>tf-idf(t, d) = tf(t, d) * idf(t)</code>, and the <code>idf</code> is computed as <code>idf(t) = log [ n / df(t) ] + 1</code> (if smooth_idf=False), where <code>n</code> is the total number of documents in the document set and <code>df(t)</code> is the document frequency of <code>t</code>; the document frequency is the number of documents in the document set that contain the term <code>t</code>. The effect of adding “1” to the <code>idf</code> in the equation above is that terms with zero <code>idf</code>, i.e., terms that occur in all documents in a training set, will not be entirely ignored. (Note that the <code>idf</code> formula above differs from the standard textbook notation that defines the <code>idf</code> as <code>idf(t) = log [ n / (df(t) + 1) ]</code>).</p>
<p>If <code>smooth_idf=True</code> (the default), the constant “1” is added to the numerator and denominator of the <code>idf</code> as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: <code>idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1</code>.</p>
</blockquote>
<p>Providing a full explanation of their implementation choices</p>
","2024-07-24 14:11:12","0","Answer"
"78787652","77541978","","<p>This different comes from IDF calculations,</p>
<p>IDF calculation for manuel TF-IDF (non-standard IDF formula),</p>
<p>IDF(t)=log(N/DF(t)),
where  N is the total number of documents, and DF(t) is the number of documents containing the term.</p>
<p>IDF calculation for scikit-learn (the standard IDF formula):</p>
<p>IDF(t)=log((1+N)/(1+DF(t)))+1</p>
<p>scikit-learn added 1 to make sure that terms in all documents don't end up with an zero IDF and also prevent division by zero.</p>
","2024-07-24 10:05:22","0","Answer"
"78770973","77216743","","<p>After running</p>
<pre><code>pip install keras==2.10.0 
pip install tensorflow==2.10.0 
pip install tensorflow-probability==0.18.0
</code></pre>
<p>like Malu suggested, the model does in fact run but without a GPU. Right after DDSP install and data extraction but before it starts training, I get an error message that some dll file is missing so a GPU cannot be used. From what I can tell, this is because a certain version of CUDA toolkit and CUDANN is already installed for colab and I don't think it will let you downgrade to the needed versions for tensorflow==2.10.0. I hope some more people can take a look at thus because I really don't want to wait 4 days for my model...</p>
","2024-07-19 19:37:22","0","Answer"
"78683787","77248571","","<p>You can't save float data in a PNG, since it is only capable of storing up to 16 bits/sample integers.</p>
<p>Your options are:</p>
<ul>
<li>save your <code>float</code> data as a TIFF, PFM, or EXR format file</li>
<li>scale your data to <code>uint8</code> or <code>uint16</code> and save as PNG</li>
</ul>
<p>So, for a <code>uint16</code> PNG, you can do:</p>
<pre><code>imsave(&quot;result.png&quot;, (65535 * processed_img).astype(np.uint16))
</code></pre>
","2024-06-28 17:32:30","0","Answer"
"78683693","77248571","","<p>I had this problem some time ago. The problem comes from the fact that the image I was trying to save was of type <strong>float</strong>. It seems to me that this is your problem.</p>
<p>Changing the type to uint8 : <strong>.astype(np.uint8)</strong> shall do the job. Still if image values are in interval [0,1], you shall multiply it by 255 before converting to 'uint8'.</p>
<pre><code>imsave(&quot;BW/leaf.png&quot;, (255 * processed_img).astype(np.uint8))
</code></pre>
","2024-06-28 17:08:04","0","Answer"
"78675322","74979359","","<p>position-wise is a logical concept, which means that each vector in the output matrix is only related to one vector of a token in the input, but the actual implementation still uses the ordinary matmul. This is no different from the calculation of attention. It's just that when calculating Q*K^T in attention, you can see that each vector in attention is related to all vectors of all tokens.</p>
","2024-06-27 02:25:42","0","Answer"
"78634289","77101192","","<p>If you'd like to use a newer version of the diffusers package, you can access randn_tensor without downgrading the package:</p>
<pre><code>from diffusers.utils.torch_utils import randn_tensor
</code></pre>
","2024-06-17 19:06:30","3","Answer"
"78616007","77541935","","<p>I trained 8,000 640x640 photos with YOLOv8 for 200 epochs and with a batch size of 32. I converted this model to coreml using the method above:</p>
<pre><code>from ultralytics import YOLO
model_path=&quot;{best.pt model}&quot;
model=YOLO(model_path)
model.export(format='coreml', nms=True, imgsz=[720,1280])
</code></pre>
<p>In the CoreML preview section, it works very successfully when I add a photo, but when I take a photo from an iPhone and use this CoreML in the application, I get very poor results. My goal is to create an iOS application that detects objects in the photo taken by the user and displays them on the screen. I am sharing my codes below. Thank you in advance for your help</p>
<pre><code>extension CameraVC : AVCapturePhotoCaptureDelegate {

func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: (any Error)?) {
    
    guard let data = photo.fileDataRepresentation() else {
        return
    }
    
    guard let image = UIImage(data: data) else {
        return
    }
    
    let imageView = UIImageView(image: image)
    imageView.contentMode = .scaleAspectFit
    imageView.frame = view.bounds
    view.addSubview(imageView)
    session?.stopRunning()
    
    if(layerFlag){
        guard let cgImage = image.cgImage else {
            fatalError(&quot;Unable to create CIImage&quot;)
        }
        let handler = VNImageRequestHandler(cgImage: cgImage,orientation: CGImagePropertyOrientation(image.imageOrientation))
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([self.viewModel.detectionRequest])
            } catch {
                fatalError(&quot;Failed to perform detection: \(error)&quot;)
            }
        }

    }
</code></pre>
<p>CoreML Model:</p>
<pre><code>lazy var detectionRequest: VNCoreMLRequest = {
    do {
        let model = try VNCoreMLModel(for: bestv720().model)
        let request = VNCoreMLRequest(model: model) { [weak self] request, error in
            self?.processDetections(for: request, error: error)
        }
       request.imageCropAndScaleOption = .centerCrop
        return request
    } catch {
        fatalError(&quot;Failed to load Vision ML model: \(error)&quot;)}}()
</code></pre>
<p>to see labels:</p>
<pre><code>func processDetections(for request: VNRequest, error: Error?) {
    DispatchQueue.main.async {
        guard let results = request.results as? [VNRecognizedObjectObservation] else {
            return
        }
        var label = &quot;&quot;
        var all_results = []
        var all_confidence = []
        var true_results = []
        var true_confidence = []
        for result in results {
            for i in 0...results.count{
                all_results.append(result.labels[i].identifier)
                all_confidence.append(result.labels[i].confidence)
                for confidence in all_confidence {
                    if confidence as! Float &gt; 0.7 {
                        true_results.append(result.labels[i].identifier)
                        true_confidence.append(confidence)
                    }
                }
            }
            label = result.labels[0].identifier
        }
        print(&quot;True Results &quot; , true_results)
        print(&quot;True Confidence &quot;, true_confidence)
        self.output?.updateView(label:label)
    }
</code></pre>
","2024-06-13 05:44:23","0","Answer"
"78594602","77149319","","<p>I ran into the same warning from some code that chatGPT created for me.  This is in python.  I was able to resolve it and I thought I'd add this in case anyone else may have received this.</p>
<pre><code>class Chatbot:
 def __init__(self):
     self.classifier = None
     self.vectorizer = CountVectorizer(tokenizer=self.tokenize)
     self.stop_words = set(stopwords.words('english'))
</code></pre>
<p>Changed the vectorizer line to:</p>
<pre><code>self.vectorizer = CountVectorizer(tokenizer=self.tokenize,token_pattern=None)
</code></pre>
","2024-06-08 02:50:54","0","Answer"
"78578559","77615883","","<p>This is fixed in version 1.5.0, worth upgrading your scikit-learn version.</p>
","2024-06-05 02:52:32","0","Answer"
"78578054","77444565","","<p>For fraud detection where the imbalanced data is super common, <strong>PR curve</strong> is commonly used, especially with the consideration in optimizing user experience where the false positive rate should be minimized while maximizing the true positive rate.</p>
<p>For any prediction model, feature engineering's variables are always important for a precise prediction. If the model gives a wrong answer, given the same variables' values, then your model is obviously missing one or more predictive variables needed to be engineered/added.</p>
<p>For <strong>feature engineering</strong>, please see Dr. Hsu's KDD conference talk, &quot;Real-time risk control system for CNP (card not present), 2011&quot;. A video of his presentation is available online by ACM.</p>
<p>For <strong>feature selection</strong> (via supervised learning), the decision tree tool, C5.0, can be useful to you.</p>
<p>For <strong>unsupervised learning</strong>, please see Dr. Hsu's GTC-2018's poster, &quot;Unsupervised Deep Learning for Anti-Fraud of Financial Transactions&quot;.</p>
<p>Best luck!</p>
","2024-06-04 22:40:47","0","Answer"
"78544428","75775979","","<pre><code>mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)
</code></pre>
<p>This should work!</p>
","2024-05-28 13:26:39","0","Answer"
"78533133","77030715","","<p>This error might be due to <code>timm</code> package version you have installed; as mentioned in the paper's <a href=""https://github.com/isl-org/ZoeDepth/issues/72"" rel=""nofollow noreferrer"">github issues</a>.</p>
<p>So I suggest change your first cell to:</p>
<pre class=""lang-py prettyprint-override""><code>!pip install torch
!pip install timm==0.6.7
</code></pre>
","2024-05-25 16:54:48","0","Answer"
"78528968","75908800","","<p>I am not really sure what you mean, but for rotation of the hand while it is parallel to the screen, comparing the y coordinates of the fifth and the seventeenth landmarks could help.</p>
<pre><code>distance_rotation = landmarks[5].y - landmarks[17].y
</code></pre>
","2024-05-24 13:45:17","0","Answer"
"78507460","77351990","","<p>I faced the same problem and I opted to use mapping.</p>
<pre><code>city_mapping = {'Kampala': 0, 'Nairobi': 1,
                'Lagos': 2, 'Bujumbura':3,
               'Kisumu':4, 'Gulu':5,
                'Accra':6, 'Yaoundé':7
} 
country_mapping = {
    'Uganda':0, 'Burundi':1, 
    'Kenya':2, 'Nigeria':3,
    'Cameroon':4, 'Ghana':5
}

#Encoding the city variable 
train_df['city'] = train_df['city'].replace(city_mapping)
test_df['city'] = test_df['city'].replace(city_mapping)

#Encoding the country variable
train_df['country'] = train_df['country'].replace(country_mapping)
test_df['country'] = test_df['country'].replace(country_mapping)
</code></pre>
","2024-05-20 15:26:26","0","Answer"
"78355155","75793658","","<p>@fmw42 solution <strong>works excellent</strong> for me.</p>
<p>However, what was not answered is <strong>how to get atomatically a nice mask for the lips</strong>.
Let me share a complete solution with obtaining a proper lips mask and afterwards recolor it.</p>
<h2>1. Imports and face detection via mediapipe</h2>
<pre><code>import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import cv2
import numpy as np
import skimage.exposure
</code></pre>
<p>Run face parts landmark detection, <a href=""https://developers.google.com/mediapipe/solutions/vision/face_landmarker/python"" rel=""nofollow noreferrer"">how to run official documentation</a></p>
<pre><code>base_options = python.BaseOptions(model_asset_path='models/face_landmarker.task')
options = vision.FaceLandmarkerOptions(base_options=base_options,
                                       output_face_blendshapes=True,
                                       output_facial_transformation_matrixes=True,
                                       num_faces=1)
detector = vision.FaceLandmarker.create_from_options(options)

# read in image of the lady and detect face parts landmarks
image_data = cv2.imread('lady.jpg')
mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_data)

# Detect face landmarks from the input image.
detection_result = detector.detect(mp_image)

image_height, image_width, channels = image_data.shape
face_landmarks = detection_result.face_landmarks[0]
</code></pre>
<h2>2. Get crude lips mask from mediapipe</h2>
<p>Landmark indexes of upper and bottom lips. <a href=""https://storage.googleapis.com/mediapipe-assets/documentation/mediapipe_face_landmark_fullsize.png"" rel=""nofollow noreferrer"">Full mapping of face indexes.</a></p>
<pre><code># Upper lip indexes
upper_lip_indexes = [61,185,40,39,37,0,267,269,270,409,291,308,415,310,311,312,13,82,81,80,191,78]
# Bottom lip indexes
bottom_lip_indexes = [78,95,88,178,87,14,317,402,318,324,308,291,375,321,405,314,17,84,181,91,146,61]
</code></pre>
<p>Define a function gets x,y coords for each indexes, creates polygon and fills the polygon to make a segmentation mask.</p>
<pre><code># Create segmented mask from polygon function
def create_segmented_mask(indexes_list):
    # Initialize a list to store the landmarks of the face part.
    landmarks = []
    
    # Iterate over the indexes of the landmarks of the face part. 
    for index in indexes_list:
        
        # Append the landmark into the list.
        landmarks.append([int(face_landmarks[index].x * image_width),
                               int(face_landmarks[index].y * image_height)])
    shape = (image_height, image_width)
    mask = np.zeros(shape)

    polygon = [np.array(landmarks).astype(int)]
    segmented_mask = cv2.fillPoly(mask, polygon, 1)
    return segmented_mask

</code></pre>
<p>Run function and obtain segmentation masks for lips</p>
<pre><code>segmented_mask_top_lip = create_segmented_mask(upper_lip_indexes)
plt.imshow(segmented_mask_top_lip)
</code></pre>
<p><a href=""https://i.sstatic.net/9xjbt.jpg"" rel=""nofollow noreferrer"">upper lip segmentation mask</a></p>
<pre><code>segmented_mask_bottom_lip = create_segmented_mask(bottom_lip_indexes)
plt.imshow(segmented_mask_bottom_lip )
</code></pre>
<p><a href=""https://i.sstatic.net/NtEh5.jpg"" rel=""nofollow noreferrer"">bottom lip segmentation mask</a></p>
<p>Combine both upper and bottom lips masks</p>
<pre><code># Combine both upper and bottom lip masks into one via addition
segmented_mask_lips_full = cv2.add(segmented_mask_top_lip, segmented_mask_bottom_lip)
# change anything that is higher than 0 to 255
segmented_mask_lips_full[segmented_mask_lips_full&gt;0]=255
segmented_mask_lips_full=segmented_mask_lips_full.astype('uint8')
plt.imshow(segmented_mask_lips_full)
</code></pre>
<p>You can see the segmentation mask is very crude:
<a href=""https://i.sstatic.net/wYJio.png"" rel=""nofollow noreferrer"">full lips segmentation mask</a></p>
<h2>3. Get improved mask based on the previous one.</h2>
<p>We will use this crude mask to crop lips from the original image, and then based on the extracted color range we can build a better softer mask.</p>
<pre><code># Crop lips from the face using mediapipe mask
image_data_me_lips = image_data_me.copy()
image_full_lips_cropped = cv2.bitwise_and(image_data_me_lips, image_data_me_lips, mask=segmented_mask_lips_full)
</code></pre>
<p><a href=""https://i.sstatic.net/cqyFo.jpg"" rel=""nofollow noreferrer"">lips cropped</a></p>
<p>Get better mask for lips: extract min and max color values from cropped lips to create lower and upper color threshold range.</p>
<pre><code># The min_threshold is to filter any way too dark colors
min_threshold = 10
min_Red = int(resultant_image_full_lips_rgb[:,:,0][resultant_image_full_lips_rgb[:,:,0]&gt;min_threshold].min())
print(min_Red)
min_Ggreen = int(resultant_image_full_lips_rgb[:,:,1][resultant_image_full_lips_rgb[:,:,1]&gt;min_threshold].min())
print(min_Ggreen)
min_Blue = int(resultant_image_full_lips_rgb[:,:,2][resultant_image_full_lips_rgb[:,:,2]&gt;min_threshold].min())
print(min_Blue)

# light_colors_substraction is to filter out any way too bright colors
light_colors_substraction = 10
max_Red = int(resultant_image_full_lips_rgb[:,:,0].max())
print(max_Red)
max_Ggreen = int(resultant_image_full_lips_rgb[:,:,1].max() - light_colors_substraction)
print(max_Ggreen)
max_Blue = int(resultant_image_full_lips_rgb[:,:,2].max() - light_colors_substraction)
print(max_Blue)

# threshold on lip color, the order is BGR
lower = (min_Blue,min_Ggreen,min_Red)
upper = (max_Blue,max_Ggreen,max_Red)
</code></pre>
<p>Create new mask from cropped lips for given color range and apply morphology and antialiasing</p>
<pre><code>#mask for given range
mask = cv2.inRange(image_full_lips_cropped, lower, upper)

# apply morphology open and close
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

# antialias mask, convert to float in range 0 to 1
mask = cv2.GaussianBlur(mask, (0,0), sigmaX=3, sigmaY=3, borderType = cv2.BORDER_DEFAULT)
mask = skimage.exposure.rescale_intensity(mask, in_range=(128,255), out_range=(0,1)).astype(np.float32)
mask_255 = (255*mask).clip(0,255).astype(np.uint8)
cv2.imwrite('lady_mask_full_lips_improved.png', mask_255)
</code></pre>
<p><a href=""https://i.sstatic.net/T9Q5e.png"" rel=""nofollow noreferrer"">improved lips mask</a></p>
<h2>4. Apply color to lips</h2>
<p>Apply smart lips colorization provided by @fmw42</p>
<p>Notice shift color options, <code>sfact=1.2</code> and <code>vfact=0.7</code> seems to produce best results (tested on various pictures).</p>
<pre><code># specify desired bgr color for lips and make into array
desired_color = (170,130,255)    # pink
#desired_color = (255,0,0)        # blue
#desired_color = (0,255,0)         # green

# shift input image color, experiment yourself
sfact=1.2 # 1-1.5
vfact=0.7 # 0.7-0.9 seem good

print(desired_color)

# create swatch
swatch = np.full((200,200,3), desired_color, dtype=np.uint8)

# read image
#img = cv2.imread(&quot;media/me2.jpg&quot;)
img = image_data_me.copy()

# read mask
#mask = cv2.imread(&quot;media/me_new_lips_mask.png&quot;, cv2.IMREAD_GRAYSCALE)
mask = mask_255


# convert input to HSV and separate channels
hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
h, s, v = cv2.split(hsv_img)

# dilate mask to make it better fit the lips
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))
mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)

# get average bgr color of lips as array
ave_color = cv2.mean(img, mask=mask)[:3]
print(ave_color)

# create 1 pixel image of average color
ave_color_img = np.full((1,1,3), ave_color, dtype=np.float32)
print(ave_color_img)

# create 1 pixel image of desired color
desired_color_img = np.full((1,1,3), desired_color, dtype=np.float32)
print(desired_color_img)

# convert desired color image to HSV
desired_hsv = cv2.cvtColor(desired_color_img, cv2.COLOR_BGR2HSV)

# convert average color image to HSV
ave_hsv = cv2.cvtColor(ave_color_img, cv2.COLOR_BGR2HSV)

# compute difference in HSV color arrays and separate channel values
diff_hsv = desired_hsv - ave_hsv
diff_h, diff_s, diff_v = cv2.split(diff_hsv)
print(diff_hsv)

# shift input image color
hnew = np.mod(h + diff_h/2, 180).astype(np.uint8)
snew = (sfact*(s + diff_s)).clip(0,255).astype(np.uint8)
vnew = (vfact*(v + diff_v)).clip(0,255).astype(np.uint8)

# merge channels back to HSV image
hsv_new = cv2.merge([hnew,snew,vnew])

# convert new HSV image to BGR
new_img = cv2.cvtColor(hsv_new, cv2.COLOR_HSV2BGR)

# antialias mask, convert to float in range 0 to 1 and make 3-channels
mask = cv2.GaussianBlur(mask, (0,0), sigmaX=5, sigmaY=5, borderType = cv2.BORDER_DEFAULT)
mask = skimage.exposure.rescale_intensity(mask, in_range=(128,255), out_range=(0,1)).astype(np.float32)
mask = cv2.merge([mask,mask,mask])

# combine img and new_img using mask 
result = (img * (1 - mask) + new_img * mask)
result = result.clip(0,255).astype(np.uint8)

# save result
cv2.imwrite('lady_recolor.jpg', result)

plt.figure(figsize=[15,15])
plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
</code></pre>
<p><a href=""https://i.sstatic.net/Cja9T.jpg"" rel=""nofollow noreferrer"">result pink lips</a></p>
","2024-04-19 16:41:21","0","Answer"
"78339046","75664004","","<h3>Step 0: Prepare PostgreSQL</h3>
<p>First, ensure that PostgreSQL is installed and running on your machine. You can use Homebrew to install PostgreSQL if it is not already installed:</p>
<pre class=""lang-bash prettyprint-override""><code>brew install postgresql
brew services start postgresql
psql postgres
</code></pre>
<h3>Step 1: Compile and Install the Extension</h3>
<p>The 'pgvector' extension supports PostgreSQL versions 12 and above. Follow these steps to compile and install the extension:</p>
<pre class=""lang-bash prettyprint-override""><code># Navigate to a temporary directory and clone the pgvector repository
cd /tmp
git clone --branch v0.6.2 https://github.com/pgvector/pgvector.git

# Change to the pgvector directory
cd pgvector

# Compile and install the extension
make
make install  # You may need to use 'sudo' if you encounter permission issues
</code></pre>
<h3>Step 2: Getting Started with 'pgvector'</h3>
<p>Once the extension is installed, you can create it within your PostgreSQL database and begin using it:</p>
<pre class=""lang-sql prettyprint-override""><code>-- Create the pgvector extension
CREATE EXTENSION vector;

-- Create a table that uses the vector data type
CREATE TABLE items (
    id bigserial PRIMARY KEY,
    embedding vector(3)
);
</code></pre>
<p><strong>Reference:</strong></p>
<ul>
<li>For more details and updates on the 'pgvector' extension, visit the <a href=""https://github.com/pgvector/pgvector"" rel=""nofollow noreferrer"">pgvector GitHub repository</a>.</li>
</ul>
<hr />
","2024-04-17 07:18:44","1","Answer"
"78326190","75309099","","<p>You can reset the index for all of your inputs. Modify your codes based on y_train = y_train.reset_index(drop=True)</p>
","2024-04-15 05:06:28","0","Answer"
"78326081","77061898","","<p>Do several iterations and make some sort of a pattern matching between number of tokens in the input prompt and max token parameter to get a complete output (as a percentage of input token length)</p>
","2024-04-15 04:18:36","0","Answer"
"78312905","76247802","","<p>Add <code>use_safetensors=True</code> to <code>from_pretrained</code>. Also make sure to grab the index.json file from the model repo and add it to your local model dir manually. These often get dropped on download from Huggingface and without it the model will not work.</p>
","2024-04-11 20:30:36","1","Answer"
"78310568","77694839","","<p>Working with <strong>transformers</strong> from Huggig Face and with <strong>Pytorch</strong> I use the snippets that you can see here:</p>
<pre class=""lang-py prettyprint-override""><code>num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    &quot;linear&quot;,
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
print(num_training_steps)
</code></pre>
<pre class=""lang-py prettyprint-override""><code>import torch

device = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device(&quot;cpu&quot;)
model.to(device)
device
</code></pre>
<pre class=""lang-py prettyprint-override""><code>from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
</code></pre>
","2024-04-11 13:11:08","0","Answer"
"78282196","75026592","","<p>The easiest way would be to inherit <code>get_feature_names_out</code> from <code>OneToOneFeatureMixin</code>. According to the docstrings:</p>
<p><code>OneToOneFeatureMixin</code> provides <code>get_feature_names_out</code> for simple transformers.</p>
<p>This mixin assumes there's a 1-to-1 correspondence between input features and output features, such as <code>~sklearn.preprocessing.StandardScaler</code>.</p>
<pre><code>Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.base import OneToOneFeatureMixin
&gt;&gt;&gt; class MyEstimator(OneToOneFeatureMixin):
...     def fit(self, X, y=None):
...         self.n_features_in_ = X.shape[1]
...         return self
&gt;&gt;&gt; X = np.array([[1, 2], [3, 4]])
&gt;&gt;&gt; MyEstimator().fit(X).get_feature_names_out()
array(['x0', 'x1'], dtype=object)
</code></pre>
","2024-04-05 20:23:44","1","Answer"
"78267483","77642444","","<p>When you create Chroma with Langchain (<code>langchain_chroma</code>) you need to pass the embedding function (wrapper-class) for OpenAI from LangChain instead of ChromaDB.</p>
<p>I assume this because you pass it as <code>openai_ef</code> which is the same name of the variable in the <a href=""https://docs.trychroma.com/embeddings/openai"" rel=""nofollow noreferrer"">ChromaDB tutorial on their website</a>. This looked probably like this:</p>
<pre class=""lang-py prettyprint-override""><code>import chromadb.utils.embedding_functions as embedding_functions

openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=OPEN_API_KEY)
</code></pre>
<p>Instead you need the function from the LangChain package and pass it when you create the <code>langchain_chroma</code> object. It should look like this:</p>
<pre class=""lang-py prettyprint-override""><code>from langchain_openai.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(openai_api_key=OPEN_API_KEY)
</code></pre>
<p>I did not dig deep into why this is the case, but for me at leat this was the solution. Upgrading the packages did not solve this <code>has no attribute 'embed_query'</code> - error.</p>
","2024-04-03 11:59:52","0","Answer"
"78260008","75791020","","<p>By default, ModelCheckpoint monitors after each epoch, which is after the training steps and validation steps. But when using the &quot;every_n_train_steps=100&quot; argument in the ModelCheckpoint, it tries to monitor val_loss during training - before you have calculated a val_loss. That's why it cannot find it. If you wait until second epoch, it should be able to find the val_loss from previous epoch.</p>
<p>But in that case, is val_loss a reliable measure? It would likely save the model for every step of the epoch 2 training because it thinks that the last model in the previous epoch 1 has the best val_loss so far. Calculating the val_loss for every step seems excessive.</p>
<p>Instead you have to carefully consider when to do what. If you want to save models during training, you should monitor train_loss. Introducing the scheduler can complicate things - be careful of when the scheduler monitors.</p>
","2024-04-02 08:40:33","1","Answer"
"78216092","75259774","","<p>To get the best performance, make sure to create your numpy arrays with dtype float32 from the start.</p>
<p>If that is not possible, change:</p>
<pre><code>x = torch.from_numpy(x)
y = torch.from_numpy(y)
</code></pre>
<p>to:</p>
<pre><code>x = torch.from_numpy(x).float()
y = torch.from_numpy(y).float()
</code></pre>
","2024-03-24 21:00:25","0","Answer"
"78215051","76396140","","<p>first uninstall pip uninstall opencv-contrib-python
then reinstall pip install opencv-contrib python
and regarding this &quot;clf=cv2.face.LBPHFaceRecognizer_create()&quot;
write,
&quot;clf=cv2.face.LBPHFaceRecognizer.create()&quot;
and see if it works</p>
","2024-03-24 15:18:24","0","Answer"
"78198547","77708996","","<p>You will get <code>.safetensors</code> format model if you save model by below code:</p>
<pre class=""lang-py prettyprint-override""><code>model.save_pretrained('folder/')
</code></pre>
<p>And you will get <code>.bin</code> format model if you save model by below code:</p>
<pre class=""lang-py prettyprint-override""><code>torch.save(model.state_dict(), 'folder/pytorch_model.bin'.format(epoch))
</code></pre>
","2024-03-21 08:48:22","3","Answer"
"78159892","77038120","","<p>Operation that you want is called Cartesian Product. Using torch you can achieve similar results to yours using torch.cartesian_prodd</p>
<pre><code>torch.cartesian_prod(torch.arange(0, 1, 0.2), torch.arange(0, 1, 0.2))
</code></pre>
<p>it produces</p>
<pre><code>tensor([[0.0000, 0.0000],
    [0.0000, 0.2000],
    [0.0000, 0.4000],
    [0.0000, 0.6000],
    [0.0000, 0.8000],
    [0.2000, 0.0000],
    [0.2000, 0.2000],
    [0.2000, 0.4000],
    [0.2000, 0.6000],
    [0.2000, 0.8000],
    [0.4000, 0.0000],
    [0.4000, 0.2000],
    [0.4000, 0.4000],
    [0.4000, 0.6000],
    [0.4000, 0.8000],
    [0.6000, 0.0000],
    [0.6000, 0.2000],
    [0.6000, 0.4000],
    [0.6000, 0.6000],
    [0.6000, 0.8000],
    [0.8000, 0.0000],
    [0.8000, 0.2000],
    [0.8000, 0.4000],
    [0.8000, 0.6000],
    [0.8000, 0.8000]])
</code></pre>
<p>Hope it helps</p>
","2024-03-14 10:45:19","3","Answer"
"78138515","75102134","","<p>Convert tensor array object into float32 if it float64</p>
<p>Before:</p>
<pre><code>model(X_train) # float64
</code></pre>
<p>After:</p>
<pre><code>model(X_train.to(torch.float32)) # float32
</code></pre>
","2024-03-11 05:11:58","2","Answer"
"78132968","76521642","","<p>And also make this change:</p>
<pre><code>layer.trainable = True
</code></pre>
<p>Setting it to false will not train the parameters hence fine tuning will not happen.</p>
","2024-03-09 15:59:57","0","Answer"
"78111234","77094149","","<p>Beside the answer from Sayan Banerjee, please also remember to change the saving code: from</p>
<pre><code>model.save_pretrained(savedModelPath)
</code></pre>
<p>to</p>
<pre><code>model.module.save_pretrained(savedModelPath)
</code></pre>
<p>or you may lose your trained model :(</p>
","2024-03-06 00:37:45","1","Answer"
"78105119","75908800","","<p>first you can use cv2 for process image use while loop and get frame step by step then use person detection pose detection may enought then find the cordinate of sholder and elbow then change it numpy array then find direction vector by subtracting sholder from elbow then you get direction vector compare you can use it by negetive postive value to find specfic rotation like hands up and hands down if you want more then we could discuss more</p>
","2024-03-05 03:04:06","0","Answer"
"78098929","77100654","","<p>Try doing this <code>pip install --pre -U triton</code></p>
","2024-03-04 04:12:12","0","Answer"
"78098446","77223737","","<p>This is the code I ended up using when I had to figure something similar out.</p>
<p><img src=""https://i.sstatic.net/SuHDz.png"" alt=""Photo of Tool"" /></p>
<p>The above image shows that the .HTML table it generates upon hovering show sthe frequency and color name / hex value of the color. Also, if you click the color block it'll copy that hex value.</p>
<pre><code>[import cv2
import numpy as np
from PIL import Image
from sklearn.cluster import KMeans
from webcolors import CSS3_HEX_TO_NAMES, hex_to_rgb

# Specify the path to the image file
image_path = &quot;Picture.png&quot;

def get_dominant_colors(image_path, num_colors=10, num_clusters=5):
    &quot;&quot;&quot;
    Utilizes KMeans clustering to identify dominant colors in an image.
    &quot;&quot;&quot;
    image = Image.open(image_path)
    image = image.resize((200, 200))
    image = image.convert('RGB')

    img_array = np.array(image)
    pixels = img_array.reshape(-1, 3)
    kmeans = KMeans(n_clusters=num_clusters, random_state=0)
    labels = kmeans.fit_predict(pixels)
    centers = kmeans.cluster_centers_
    color_counts = {}
    for label in np.unique(labels):
        color = tuple(centers\[label\].astype(int))
        color_counts\[color\] = np.count_nonzero(labels == label)
    sorted_colors = sorted(color_counts.items(), key=lambda x: x\[1\], reverse=True)
    dominant_colors = \[color for color, count in sorted_colors\[:num_colors\]\]
    color_occurrences = \[count for color, count in sorted_colors\[:num_colors\]\]
    dominant_colors_hex = \['#%02x%02x%02x' % color for color in dominant_colors\]
    return dominant_colors_hex, color_occurrences

def closest_color(hex):
    &quot;&quot;&quot;
    Finds the closest matching color name from CSS3 colors.
    &quot;&quot;&quot;
    colors = {}
    for key, name in CSS3_HEX_TO_NAMES.items():
        r_c, g_c, b_c = hex_to_rgb(key)
        rd = (int(hex\[1:3\], 16) - r_c) ** 2
        gd = (int(hex\[3:5\], 16) - g_c) ** 2
        bd = (int(hex\[5:7\], 16) - b_c) ** 2
        colors\[(rd + gd + bd)\] = name
    return colors\[min(colors.keys())\]

def rgb_to_hex(rgb):
    &quot;&quot;&quot;
    Converts RGB tuple to hexadecimal color representation.
    &quot;&quot;&quot;
    return '#{:02x}{:02x}{:02x}'.format(rgb\[0\], rgb\[1\], rgb\[2\])

def get_colors(image_path):
    &quot;&quot;&quot;
    Retrieves all distinct colors present in the image.
    &quot;&quot;&quot;
    image = Image.open(image_path)
    image = image.resize((200, 200))
    image = image.convert('RGB')

    # Fetch pixel colors
    pixels = list(image.getdata())

    # Identify unique colors
    unique_colors = list(set(pixels))

    return unique_colors

# Obtain dominant colors
dominant_colors_hex, color_occurrences = get_dominant_colors(image_path)

# Display extracted color names
print(&quot;Extracted Colors:&quot;)
for col_hex in dominant_colors_hex:
    col_name = closest_color(col_hex)
    print(col_name)

# Write distinct colors and their counts to a text file
with open(image_path.split('.')\[0\] + &quot;_Color_List.txt&quot;, 'w') as f:
    for col_hex, col_occ in zip(dominant_colors_hex, color_occurrences):
        col_name = closest_color(col_hex)
        print(f&quot;{col_name} \[{col_occ}\]&quot;, file=f)

# Convert colors to hexadecimal representation
distinct_colors = get_colors(image_path)
distinct_colors_hex = \[rgb_to_hex(color) for color in distinct_colors\]

# Generate HTML color table
html_content = &quot;&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;style&gt;\ntable {\nborder-collapse: collapse;\n}\ntd {\nborder: 1px solid black;\nwidth: 15px;\nheight: 15px;\n}\n&lt;/style&gt;\n&lt;script&gt;\nfunction copyColor(hex) {\n  var dummy = document.createElement('textarea');\n  document.body.appendChild(dummy);\n  dummy.value = hex;\n  dummy.select();\n  document.execCommand('copy');\n  document.body.removeChild(dummy);\n}\n&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;table&gt;&quot;
html_content += &quot;\n&lt;tr&gt;&quot;
for color, count, hex_code in zip(dominant_colors_hex, color_occurrences, distinct_colors_hex):
    color_name = closest_color(color)
    html_content += f&quot;\n&lt;td title='{color_name} ({hex_code}), {count} times' style='background-color:{color}' onclick='copyColor(\&quot;{color}\&quot;)'&gt;&lt;/td&gt;&quot;
html_content += &quot;\n&lt;/tr&gt;\n&lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;&quot;

# Write HTML content to file
with open(image_path.split('.')\[0\] + &quot;_Color_Table.html&quot;, 'w') as f:
    f.write(html_content)][1]
</code></pre>
","2024-03-04 00:39:52","0","Answer"
"78046786","75746687","","<p>Adding     <code>evaluation_strategy = 'steps',</code> to the training arguments fixed it for me</p>
","2024-02-23 10:41:17","0","Answer"
"78042069","75158273","","<p><code>pip uninstall umap</code></p>
<p><code>pip unstall umap-learn</code></p>
<p>Wipe out all folders of <code>umap</code> and <code>umap-learn</code> in your <code>/home/user/.pyenv/versions/3.11.7/lib/python3.11/site-packages</code> folder</p>
<p>Shutdown your jupyter kernel (if applicable) and re-run your code.</p>
","2024-02-22 15:14:22","1","Answer"
"78010860","76321820","","<p>`</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

param_space = {
    'n_estimators': [100, 200, 300, 400, 500],
    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5],
    'max_depth': [3, 5, 7, 9, 11],
    'reg_alpha': [0.1, 0.3, 0.5],
    'reg_lambda': [0.1, 0.3, 0.5]
}
# Create the XGBoost model
model = XGBClassifier()

bayes_search = BayesSearchCV(
    estimator=model,
    search_spaces=param_space,
    scoring='f1_macro',
    cv=3,
    n_jobs=-1,
    n_iter=50,  
    random_state=42
)
# added this line to my code
np.int = int

bayes_search.fit(X_train, y_train)
</code></pre>
<p>` JUST ADD THE ABOVE LINE TO THE CODE IT WORKS</p>
","2024-02-17 03:28:44","0","Answer"
"78004362","75011843","","<p>The solution from @joao-pedro-macalos is almost complete, I just needed to add <code>show=False</code> to <code>beeswarm</code>.
Anyway I try to provide a complete solution here (tested on shap==0.44.1).</p>
<pre><code>import shap
import xgboost as xgb
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Create a mock dataset
X, y = shap.datasets.adult()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a model
model = xgb.XGBClassifier()
model.fit(X_train, y_train)

# Compute SHAP
explainer = shap.Explainer(model, X_train)
shap_values_test = explainer(X_test[:500])
shap_values_train = explainer(X_train[:500])

# Plot
# (credit to @joao-pedro-macalos )
plt.figure()
plt.subplot(1,2,1)
shap.plots.beeswarm(
    shap_values_test, max_display=10, show=False)
plt.subplot(1,2,2)
shap.plots.beeswarm(
    shap_values_train, max_display=10, show=False)

# Optional for adjusting the margins:
plt.subplots_adjust(
    left=1,
    bottom=0.1, 
    right=3, 
    top=0.9
</code></pre>
","2024-02-15 22:54:27","2","Answer"
"77978016","76471584","","<p>Today, when talking about contextualized embeddings it is usually used to describe embeddings that dynamically change depending on the given context (for example the sentence for which the &quot;word&quot; appears in) and not generated once as a pre-training procedure and used as a dictionary with no dependence on the current context, like in w2v.</p>
<p>While both w2v and contextualized embeddings are usually generated based on the <strong>context</strong> that the &quot;words&quot; appear in, w2v is trained only once while using all of the contexts the &quot;word&quot; appears in as a pre-training procedure. On the other hand, contextualized embeddings are generated dynamically given &quot;word&quot; and the context it appears in.</p>
<p>An example that clearly shows the difference is the word &quot;mouse&quot;. This word can be used to describe an animal, or a mechanical tool used to move the cursor on a computer screen. In w2v, the embedding of &quot;mouse&quot; will be static and will hold information about both an &quot;animal-mouse&quot; and &quot;computer-mouse&quot;. In contextual embedding you will need to provide the current context the word appears in and therefore there will be a different embedding to the &quot;mouse&quot; in a sentece talking about animals and &quot;mouse&quot; in a sentence talking about computers.</p>
<p>Note that contextualized-embedding are talked about in the context of Large-Language-Models which can dynamically output text embeddings on the fly based on context context.</p>
","2024-02-11 18:51:23","0","Answer"
"77961644","77716307","","<p>I am currently reading this book and running the provided code. I got the same  error and what works for is to save the model using the legacy <em>.h5</em> extension instead of <em>.keras</em></p>
<pre><code>callbacks = [
keras.callbacks.ModelCheckpoint(
    filepath=&quot;features_extraction_with_data_augmentation.h5&quot;,
    save_best_only=True,
    monitor=&quot;val_loss&quot;
)]
</code></pre>
","2024-02-08 12:27:08","2","Answer"
"77951524","75158273","","<p>Worked through this today, so posting here in case its of use to anyone. Following the advice here: <a href=""https://github.com/MaartenGr/BERTopic/issues/1209"" rel=""nofollow noreferrer"">https://github.com/MaartenGr/BERTopic/issues/1209</a></p>
<p>Take the following steps:</p>
<ol>
<li>Delete your current virtual environment</li>
<li>Create a fresh environment</li>
<li>Run <code>pip install bertopic</code> from within that new environment</li>
</ol>
<p>If you now run pip install umap-learn you will be told that all the requirements are already satisfied. Now you can just import as you like using:</p>
<pre><code>import umap.umap_ as UMAP 
</code></pre>
<p>All calls to UMAP now need to follow this structure: <code>UMAP.UMAP</code></p>
","2024-02-07 00:02:28","0","Answer"
"77945713","76788751","","<pre><code>import numpy as np
import albumentations as A

category_id = [0, 1, 2] 
bbox = [[1,2,3,4], [4,5,6,7], [8,9,10,11]]

trans = A.Compose([
    A.HorizontalFlip(p=0.5), 
], bbox_params=A.BboxParams(format='coco', label_fields=['any_name']))

augmented = trans(image=np.array(image), bboxes=bbox, any_name=category_id)
</code></pre>
<p>It took me a while to realize the issue is that the label_fields parameter in bbox_params needs to match the key used. &quot;noted by &quot;any_name&quot; &quot;</p>
<p>Just wanted to document this in case others run into the same confusion with these parameters.</p>
","2024-02-06 06:48:06","0","Answer"
"77937139","76463707","","<p>I had the same issue installing lap=0.4 on Python=3.11.5
Solved by installing python=3.9 via conda install python=3.9</p>
","2024-02-04 18:46:31","0","Answer"
"77922644","76603178","","<p>I'm using Chroma for my vectorstore and faced similar problems. This was how I solved it. Note: I named my vectorstore as <code>db</code>.</p>
<pre class=""lang-py prettyprint-override""><code>persist_directory = 'db'

# Only run these 2 lines for the first run. Comment them out after running it for the first time.
db = Chroma.from_documents(doc, OpenAIEmbeddings(), persist_directory=persist_directory)
db.persist()

# Subsequent runs should give the specified number of documents
db = Chroma(persist_directory=persist_directory, embedding_function=OpenAIEmbeddings())

document_content_description = &quot;Your document description&quot;
retriever = SelfQueryRetriever.from_llm(
    llm,
    db,
    document_content_description,
    metadata_field_info,
    verbose=True,
    enable_limit=True
)

docs = retriever.get_relevant_documents(&quot;I am looking for 7 documents regarding...&quot;) # Should return 7 documents
print(len(docs)) # Should be 7
</code></pre>
<p>Hope this helps.</p>
","2024-02-01 18:44:59","1","Answer"
"77902691","76603178","","<p>One option is to change the retriever method to &quot;similarity_score_threshold&quot; as described on the <a href=""https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore#similarity-score-threshold-retrieval"" rel=""nofollow noreferrer"">Langchain site</a>, e.g.:</p>
<pre><code>retriever = db.as_retriever(search_type=&quot;similarity_score_threshold&quot;, search_kwargs={&quot;score_threshold&quot;: 0.5})
</code></pre>
<p>You still need to adjust the &quot;k&quot; argument if you do this. Otherwise, I found that it still defaults to k=4 max documents returned. As a workaround, I set &quot;k&quot; to the length of the full set of documents so that it returns every document above the &quot;score_threshold&quot;, e.g.:</p>
<pre><code>retriever = db.as_retriever(search_type=&quot;similarity_score_threshold&quot;, search_kwargs={&quot;score_threshold&quot;: 0.7, &quot;k&quot;: len(docs)})
</code></pre>
<p>The downside is that this requires experimenting with score thresholds, which is an inexact science.</p>
","2024-01-29 21:20:56","1","Answer"
"77877705","77214404","","<p>Although your requirement is quite vague, you can still look at this.</p>
<pre><code>import pandas as pd
import numpy as np


df = pd.DataFrame({'MovieA': [0, 1.166667, 1.166667, 0, np.nan],
                   'MovieB': [np.nan, -0.333333, -0.333333, -1.5, 0.25],
                   'MovieC': [-0.5, -0.833333, np.nan, np.nan, np.nan],
                   'MovieD': [0.5, np.nan, -0.833333, np.nan, -0.25],
                   'MovieE': [np.nan, np.nan, np.nan, 1.5, np.nan]},
                  index=['Angee', 'Anirvesh', 'Jay', 'Karthik', 'Naman'])
&quot;&quot;&quot;
print(df)
            MovieA    MovieB    MovieC    MovieD  MovieE
Angee     0.000000       NaN -0.500000  0.500000     NaN
Anirvesh  1.166667 -0.333333 -0.833333       NaN     NaN
Jay       1.166667 -0.333333       NaN -0.833333     NaN
Karthik   0.000000 -1.500000       NaN       NaN     1.5
Naman          NaN  0.250000       NaN -0.250000     NaN
&quot;&quot;&quot;

# Calculate correlations with Pearson's method
corr_matrix = df.T.corr(method='pearson')
&quot;&quot;&quot;print(corr_matrix)
          Angee  Anirvesh  Jay  Karthik  Naman
Angee       1.0       1.0 -1.0      NaN    NaN
Anirvesh    1.0       1.0  1.0      1.0    NaN
Jay        -1.0       1.0  1.0      1.0    1.0
Karthik     NaN       1.0  1.0      1.0    NaN
Naman       NaN       NaN  1.0      NaN    1.0
&quot;&quot;&quot;
# Fill diagonal with let's say 999.Just for understanding.
np.fill_diagonal(corr_matrix.values, 999)

&quot;&quot;&quot;
print(corr_matrix)
          Angee  Anirvesh    Jay  Karthik  Naman
Angee     999.0       1.0   -1.0      NaN    NaN
Anirvesh    1.0     999.0    1.0      1.0    NaN
Jay        -1.0       1.0  999.0      1.0    1.0
Karthik     NaN       1.0    1.0    999.0    NaN
Naman       NaN       NaN    1.0      NaN  999.0&quot;&quot;&quot;


# Concise Filling diagonal with let's say 888.Just for understanding.Also adding fillna(0)
corr_matrix = df.T.corr(method='pearson').where(~np.eye(len(df), dtype=bool), 888).fillna(0)
&quot;&quot;&quot;print(corr_matrix)

          Angee  Anirvesh    Jay  Karthik  Naman
Angee     888.0       1.0   -1.0      0.0    0.0
Anirvesh    1.0     888.0    1.0      1.0    0.0
Jay        -1.0       1.0  888.0      1.0    1.0
Karthik     0.0       1.0    1.0    888.0    0.0
Naman       0.0       0.0    1.0      0.0  888.0
&quot;&quot;&quot;
</code></pre>
","2024-01-25 05:28:34","1","Answer"
"77874018","76463707","","<p>If it does not help -  try  <strong>pip install wheel</strong> and then  <strong>pip install lap</strong></p>
","2024-01-24 14:55:14","0","Answer"
"77855091","77450322","","<p>If your are on colab just restart your runtime and then run the code line again.
Note: When ever you install gradio restart your runtime. <br>Install gradio as:</p>
<p><code>%pip install jiwer gradio typing-extensions</code></p>
","2024-01-21 13:52:14","4","Answer"
"77849608","76502318","","<p>Quick note on XGBoost with 'hist' tree_method: it swaps DMatrix for QuantileDMatrix internally to save memory. Just be cautious – if your input data (like a NumPy array) is on the CPU while training uses CUDA, there's a performance hit. Data first hits the CPU, then heads to the GPU.</p>
<p>What you can do:</p>
<ol>
<li>Transform the X,y before feeding to XGBClassifier to Cuda Dataframe
see <a href=""https://pypi.org/project/cudf-cu12/"" rel=""nofollow noreferrer"">cudf</a>.</li>
<li>Transform the X,y before feeding to XGBClassifier to
Cupy numpy, see <a href=""https://docs.cupy.dev/en/stable/install.html"" rel=""nofollow noreferrer"">cupy</a>.</li>
<li>Overwrite the _create_dmatrix function of
the XGBModel Class as follows, see comparisons below.</li>
</ol>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>X, y = make_classification(n_samples=500_0000, n_features=20,
                           n_informative=10, n_redundant=10, random_state=42)

# scikit-learn
t = time.time()
model = XGBClassifier(tree_method=""gpu_hist"", gpu_id=0,
                      predictor=""gpu_predictor"", max_bin=256)
model.fit(X, y)
print(""scikit-learn interface: "", time.time() - t)

# scikit-learn again
t = time.time()
model.fit(X, y)
print(""scikit-learn (2nd) interface: "", time.time() - t)

print()

#CUPY
t = time.time()
model = XGBClassifier(tree_method=""gpu_hist"", gpu_id=0,
                      predictor=""gpu_predictor"", max_bin=256)

model.fit(cp.array(X), cp.array(y))
print(""CUPY-scikit-learn interface: "", time.time() - t)

t = time.time()
model.fit(cp.array(X), cp.array(y))
print(""CUPY-scikit-learn (2nd) interface: "", time.time() - t)

print()

#CUDF
t = time.time()
model = XGBClassifier(tree_method=""gpu_hist"", gpu_id=0,
                      predictor=""gpu_predictor"", max_bin=256)
model.fit(cudf.DataFrame(X), cudf.DataFrame(y))
print(""CUDF-scikit-learn interface: "", time.time() - t)

t = time.time()
model.fit(cudf.DataFrame(X), cudf.DataFrame(y))
print(""CUDF-scikit-learn (2nd) interface: "", time.time() - t)

print()

#OVERWRITE _create_dmatrix
class MyXGB(XGBClassifier):
    def __init__(self, **kwargs):  # pylint: disable=useless-parent-delegation
        """"""Initalize Trainer.""""""
        super().__init__(**kwargs)

    def _create_dmatrix(self, ref: Optional[DMatrix], **kwargs: Any) -&gt; DMatrix:
        return DMatrix(**kwargs, nthread=self.n_jobs)

t = time.time()
model = MyXGB(tree_method=""gpu_hist"", gpu_id=0,
                      predictor=""gpu_predictor"", max_bin=256)
model.fit(X, y)
print(""OVERWRITE-scikit-learn interface: "", time.time() - t)

t = time.time()
model.fit(cp.array(X), cp.array(y))
print(""OVERWRITE-scikit-learn (2nd) interface: "", time.time() - t)

print()

# DMatrix
dtrain = xgb.DMatrix(data=X, label=y)
t = time.time()
model = xgb.train({""tree_method"": ""gpu_hist"", ""gpu_id"": 0,
                  ""predictor"": ""gpu_predictor""}, dtrain)
print(""native interface: "", time.time() - t)

# DMatrix again
t = time.time()
model = xgb.train({""tree_method"": ""gpu_hist"", ""gpu_id"": 0,
                  ""predictor"": ""gpu_predictor""}, dtrain)
print(""native (2nd) interface:: "", time.time() - t)</code></pre>
</div>
</div>
</p>
<p>OUTPUT:</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>scikit-learn interface:  21.925138473510742
scikit-learn (2nd) interface:  20.68904447555542

CUPY-scikit-learn interface:  5.335642099380493
CUPY-scikit-learn (2nd) interface:  5.236214876174927

CUDF-scikit-learn interface:  5.496228933334351
CUDF-scikit-learn (2nd) interface:  5.3957905769348145

OVERWRITE-scikit-learn interface:  7.505085468292236
OVERWRITE-scikit-learn (2nd) interface:  5.462920427322388

native interface:  1.2605454921722412
native (2nd) interface::  0.5620841979980469</code></pre>
</div>
</div>
</p>
<p>Not perfect but better.</p>
","2024-01-20 02:00:48","1","Answer"
"77839117","76776695","","<pre><code># Here is the solution which worked for me:
from langchain.chains import LLMChain
from langchain.chains import ConversationChain
from langchain.memory import (
    ConversationBufferMemory
)
from langchain_openai import OpenAI

template = &quot;&quot;&quot;
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. 
If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the &quot;Relevant Information&quot; section and does not hallucinate.

Relevant Information:
{chat_history}

Conversation:
Human: {input}
AI:&quot;&quot;&quot;
prompt = PromptTemplate(input_variables=[&quot;chat_history&quot;, &quot;input&quot;], template=template)

# Assuming settings.LLM_MODEL_NAME and memory are defined elsewhere
llm = OpenAI(temperature=0.9, streaming=True)

memory = ConversationBufferMemory(memory_key=&quot;chat_history&quot;, return_messages=True)
memory.chat_memory.add_user_message(&quot;hi, my name is Abbas!&quot;)
memory.chat_memory.add_ai_message(&quot;what's up?&quot;)
memory.load_memory_variables({})

## ConversationChain or LLMChain
conversation = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True,
    memory=memory)
conversation.invoke(&quot;Translate this sentence from English to French: I love programming.&quot;)

# Hope it will be clear, let me know if I can help you, thanks
</code></pre>
","2024-01-18 11:43:37","0","Answer"
"77784909","77433100","","<p>FYI</p>
<pre><code># Calculate log softmax to get log probabilities
log_probs = torch.nn.functional.log_softmax(logits, dim=-1)

# Initialize perplexity list
token_ppls = []


# Traverse each token, calculate its perplexity
for i in range(1, input_ids.size(1)):
    # Get the actual log probability of the next token
    target_id = input_ids[0, i]
    target_log_prob = log_probs[0, i-1, target_id].item()

    # Calculate the token's perplexity and add it to the list
    token_ppl = torch.exp(-torch.tensor(target_log_prob)).item()
    token_ppls.append(token_ppl)

   
</code></pre>
","2024-01-09 07:12:51","1","Answer"
"77781616","77716307","","<p>You can simply wrap the function <code>keras.applications.vgg16.preprocess_input</code> in <code>keras.layers.Lambda</code> as follows:</p>
<pre class=""lang-py prettyprint-override""><code>...
x = data_augmentation(inputs)
x = keras.layers.Lambda(
     lambda x: keras.applications.vgg16.preprocess_input(x))(x)
x = conv_base(x)
...
</code></pre>
<p><code>ModelCheckPoint</code> then should be able to save the model.
You would need to set <code>safe_mode=False</code> when you load the model with Lambda layer.</p>
<p>Hope this helps.</p>
","2024-01-08 15:32:47","5","Answer"
"77773637","76509562","","<p>set</p>
<pre><code>tokenized_dataset = tokenized_dataset.map(
    group_texts,
    batched=True,
    batch_size=8)

</code></pre>
","2024-01-07 15:17:56","-1","Answer"
"77773598","75982832","","<p>my keras version is 2.15.0
change --&gt; <strong>from keras.src.utils.layer_utils import CallFunctionSpec</strong>
it work for me</p>
","2024-01-07 15:06:41","0","Answer"
"77772763","75282840","","<p>Just add one comment to @mohammad-joshaghani’s solution, when using search_space and GridSampler to define custom values for hyper-parameters, one has to provide custom values for all the hyper-parameters that need to be tuned and define in objective() function. Otherwise, any attempts to run the optimisation for ML models would be terminated with complained error info from <em>optuna/samplers/_grid.py, line 186, in sample_independent
raise ValueError(message)</em> as follows:</p>
<p>“<em>ValueError: The parameter name, learning_rate, is not found in the given grid.</em>”</p>
<p>On the other hand, if someone prefers to provide user-specified values for only a subset of hyper-parameters, @youjun-hu’s solution is recommended.</p>
","2024-01-07 10:47:59","0","Answer"
"77770269","74979359","","<p>I will answer intuitively why it is position-wise.
According to the code definition in the question if you have batched input of dimensions (batch, sequence length, d_model)
Note that the input dimension of the FF layer is d_model, this means that the same network is applied at the same time to every token on the features dimension which is d_model.
The example in @amiola's answer above explains the concept numerically.</p>
","2024-01-06 17:07:15","1","Answer"
"77770031","77737679","","<p>Instead of using predefined patterns, you'll probably get way better performance implementing a language model for your chatbot.</p>
<p>You can simply use models that are pre-trained on french? I know XLM-Roberta is trained on hundred languages so it will support your task, as the tokenizer will tokenize the sentence and the model will understand its french based on the input_ids.</p>
","2024-01-06 15:51:04","0","Answer"
"77759913","77708996","","<p>Probably you figured it out already but updating the transformer library now to the newest version resolves the issue.</p>
<pre><code>pip install -U transformers
</code></pre>
<p>U don't need to transform the model anymore you can load the load the model.safetensor with SentenceTransformer(&quot;Modelpath&quot;)</p>
","2024-01-04 16:51:24","5","Answer"
"77757722","77380210","","<p>In case this helps anyone else, I received a similar error <code>numba.cuda.cudadrv.error.CudaSupportError: Error at driver init: Call to cuInit results in CUDA_ERROR_OUT_OF_MEMORY (2)</code> with the following system configuration:</p>
<ul>
<li>Host OS Microsoft Windows 11 Pro Version 10.0.22621 Build 22621</li>
<li>Running latest NVIDIA drivers (546.33) on host</li>
<li>WSL2 with fresh install of Ubuntu 22.04.3 LTS</li>
<li>Installed Miniconda3-py310_23.11.0-2-Linux-x86_64.sh</li>
<li>Installed RAPIDS via WSL2 Conda Install (Preferred Method)</li>
<li>Specific command executed in WSL2 <code>conda create --solver=libmamba -n rapids-23.12 -c rapidsai -c conda-forge -c nvidia  rapids=23.12 python=3.10 cuda-version=12.0</code></li>
<li>Activated the newly created rapids-23.12 Conda environment</li>
</ul>
<p>In my case, because I have 4 discrete GPUs, this was confusing things inside WSL.</p>
<p>My bug is limited to those folks using WSL2 and have more than one GPU present in their set-up. I recall reading that WSL2 only supports 1 GPU (<a href=""https://docs.rapids.ai/install#wsl2-conda"" rel=""nofollow noreferrer"">https://docs.rapids.ai/install#wsl2-conda</a> : &quot;Only single GPU is supported&quot; and &quot;GPU Direct Storage is not supported&quot;). But it is not well documented that you need to help Python target the specific GPU that is supported.</p>
<p>To overcome this bug it is necessary to stipulate explicitly the CUDA_VISIBLE_DEVICES env variable and I would recommend doing so as an env variable in ~/.bashrc by adding the line :
export CUDA_VISIBLE_DEVICES=0</p>
<p>Note this is zero indexed and is the ID of the GPU.</p>
<p>However, after some experimenting, I found that RAPIDS installation on WSL2 via Conda does support multiple GPUs, but in my case GPU ID 2 is what is causing the error, probably because it is fully used by the host OS or something like this. Given I have 4 GPUs, if I export CUDA_VISIBLE_DEVICES=0,1,2,3 and try to <code>import cudf</code> in Python, I error out as per above. But if I do export CUDA_VISIBLE_DEVICES=0,1,3 everything works normally.</p>
<p>In fact, running <code>numba -s</code> it recognised all 3 GPUs as 0, 1, 2 and therefore seems to reset it's index based on the GPUs the environment variable exposes. Further, when using XGBoost I can target all 3 GPUs exposed via the environment variable using IDs 0, 1, 2 respectively.</p>
","2024-01-04 10:53:16","1","Answer"
"77747934","77716307","","<p>I believe functional model (unlike sequential) fails to save <code>keras.applications.vgg16.preprocess_input</code> part of the model (looks like a bug to me). The save attempts happens in the <code>ModelCheckpoint</code> callback.</p>
<p>For me (Apple Silicon, MacOS Sonoma 14.2.1, TF 2.15 with tensorflow-metal 1.1.0) using custom implementation for VGG16 preprocessing step works:</p>
<pre><code>def preprocess_input(imgs):
    return tf.reverse(imgs, axis=[-1]) - tf.constant([103.939, 116.779, 123.68], dtype=tf.float32)
</code></pre>
<p>This can be used instead of <code>keras.applications.vgg16.preprocess_input</code>, it does the same transform but can be serialized successfully.</p>
","2024-01-02 18:31:58","1","Answer"
"77737690","77737679","","<p>Most LLMs don't particularly care which language you ask the question in. It will respond in the language in which you ask the question. You can also add it to the prompt instructions by setting the system message (or adding to it).</p>
<p>&quot;You are a helpful IT assistant and will respond in French at all times&quot;. Something like that. You can try it out.</p>
<p>Note that this is for the LLM input and output, you will still need to take care of the French UI of your bot.</p>
","2023-12-30 23:10:05","0","Answer"
"77737679","","Create a multilingual chatbot","<p>I created a chatbot using PyTorch an I want to make it support the French language. Note that I want to train the chatbot so that it can respond to technical questions.</p>
<p>One of the things that came to my mind is to use translation APIs but since the chatbot is expected to respond to technical questions translation APIs might provide inaccurate information</p>
","2023-12-30 23:05:27","0","Question"
"77737664","77737016","","<p>You can mask the zero values during the forward pass and that will block the gradient.</p>
<p>Here's an example assuming the sub-diagonal block is in the upper right corner of the matrix</p>
<pre class=""lang-py prettyprint-override""><code>import torch
import torch.nn as nn

vertical_dim = 2
horizontal_dim = 2
total_dim = vertical_dim + horizontal_dim

# create mask for non-block values
mask = torch.ones(total_dim, total_dim)
mask[vertical_dim:] = 0
mask[:, horizontal_dim:] = 0

# create params using the mask to zero non-block values
params = nn.Parameter(torch.rand(total_dim, total_dim) * mask)

# dummy loss example, applying the mask to params during the forward pass
loss = (params * mask).mean()

loss.backward()

# inspect the grad tensor and see that only the sub-diagonal block values have gradient values
params.grad
</code></pre>
","2023-12-30 22:58:53","1","Answer"
"77737087","77737016","","<p>I think you can make a boolean mask tensor that's a diagonal of 1's and 0's with 1's (or <code>True</code>s) for the values you want to keep/train, then do something like <code>x = torch.where(mask, x, zeros)</code></p>
<p>Or, if you have values you don't want to modify for the non-training parts, put them in a separate constant non-parameter tensor and <code>x = torch.where(mask, x, constant_values)</code></p>
<p>as long as <code>zeros</code> or <code>constant_values</code> are non-parameters, it'll backprop through torch.where into x but shouldn't modify the non-parameter part.</p>
","2023-12-30 18:58:11","2","Answer"
"77737016","","How to define PyTorch tensor that is only partially trainable","<p>I am trying to build a custom model to train in PyTorch, and long story short I need to build a tensor with all the elements set to zero except for a rectangular sub-diagonal block, crucially the optimization process should touch only the elements of this sub-diagonal block, leaving all the zeroes untouched. To do this I defined a custom pytorch network and defined my rectangual block with <code>nn.Parameter</code></p>
<pre><code>class My_Network(nn.Module):
    def __init__(self , vertical_dim , horizontal_dim):
        super().__init__()
        self.total_dim = vertical_dim + horizontal_dim
        self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , horizontal_dim))

</code></pre>
<p>In this way, correct me if I am wrong, PyTorch should initialize the values of this tensor with random values, and should register them as parameters of the model to be optimized during training. But now I am stuck, I want to tell PyTorch to build a square matrix tensor, with dimension equal to <code>self.total_dim</code>, that is all zeroes except for the sub-diagonal block, and as I was saying in the computation that I will define in the forward method pytorch should train only the sub-diagonal block.</p>
<p>I can add a zeros tensor as I want it, without setting it as a model parameter, like so (if I am not mistaken):</p>
<pre><code>class My_Network(nn.Module):
    def __init__(self , vertical_dim , horizontal_dim):
        super().__init__()
        self.total_dim = vertical_dim + horizontal_dim
        self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , horizontal_dim))
        self.total_zero_tensor = torch.zeros(self.total_dim, self.total_dim)

</code></pre>
<p>But now how can I tell PyTorch to plug my subdiagonal block in the down left corner of this matrix of zeroes? I need to define this matrix for my computations to follow (I will need to perform matrix multiplications), but it is crucial than only the little subdiagonal block be considered as a set of parameters to be trained.</p>
","2023-12-30 18:32:49","1","Question"
"77732751","77728334","","<p>Seeing logs about CUDA in the original posts suggests to me that you're trying to use CUDA-enabled LightGBM. It's important to clarify that, as LightGBM supports two different GPU-accelerated builds:</p>
<ul>
<li><code>-DUSE_GPU=1</code> (<code>&quot;device&quot;: &quot;gpu&quot;</code>) = OpenCL-based build targeting a wide range of GPUs</li>
<li><code>-DUSE_CUDA=1</code> (<code>&quot;device&quot;: &quot;cuda&quot;</code>) = CUDA kernels targeting NVIDIA GPUs</li>
</ul>
<p>As described in the project's docs (<a href=""https://github.com/microsoft/LightGBM/blob/v4.2.0/python-package/README.rst"" rel=""noreferrer"">link</a>), as of <code>v4.0.0</code> building the <code>lightgbm</code> Python package from sources in its <code>git</code> repos requires use of a shell script in that repo.</p>
<p>Run the following to build and install a CUDA-enabled version of the library from the source code on GitHub.</p>
<pre class=""lang-bash prettyprint-override""><code>git clone --recursive https://github.com/microsoft/LightGBM
cd LightGBM/
sh build-python.sh install --cuda
</code></pre>
<p>If you'd prefer to install from a release on PyPI without having to clone the repo, run the following.</p>
<pre class=""lang-bash prettyprint-override""><code>pip install \
  --no-binary lightgbm \
  --config-settings=cmake.define.USE_CUDA=ON \
  'lightgbm&gt;=4.0.0'
</code></pre>
<p>With CUDA-enabled LightGBM installed that way, you can then use GPU-accelerated training by passing <code>&quot;device&quot;: &quot;cuda&quot;</code> through parameters, like this:</p>
<pre class=""lang-py prettyprint-override""><code>import lightgbm as lgb
from sklearn.datasets import make_regression

X, y = make_regression(n_samples=10_000)
dtrain = lgb.Dataset(X, label=y)
bst = lgb.train(
    params={
        &quot;objective&quot;: &quot;regression&quot;,
        &quot;device&quot;: &quot;cuda&quot;,
        &quot;verbose&quot;: 1
    },
    train_set=dtrain,
    num_boost_round=5
)
</code></pre>
","2023-12-29 15:33:57","5","Answer"
"77731267","77730719","","<p>I tried another way to speed the process.
Firstly, I run the following code to find the best parameter of num_workers.</p>
<pre><code>from time import time
import multiprocessing as mp
import torch
import torchvision
from torchvision import transforms
 
 
transform = transforms.Compose([
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize((0.1307,), (0.3081,))
])
 
trainset = torchvision.datasets.MNIST(
    root='dataset/',
    train=True,  #如果为True，从 training.pt 创建数据，否则从 test.pt 创建数据。
    download=True, #如果为true，则从 Internet 下载数据集并将其放在根目录中。 如果已下载数据集，则不会再次下载。
    transform=transform
)
 
print(f&quot;num of CPU: {mp.cpu_count()}&quot;)
for num_workers in range(2, mp.cpu_count(), 2):  
    train_loader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=num_workers, batch_size=64, pin_memory=True)
    start = time()
    for epoch in range(1, 3):
        for i, data in enumerate(train_loader, 0):
            pass
    end = time()
    print(&quot;Finish with:{} second, num_workers={}&quot;.format(end - start, num_workers))
</code></pre>
<p>here are the output:</p>
<pre><code>num of CPU: 32
Finish with:8.80056643486023 second, num_workers=2
Finish with:6.9174275398254395 second, num_workers=4
Finish with:6.977447032928467 second, num_workers=6
Finish with:6.9256751537323 second, num_workers=8
Finish with:7.585498094558716 second, num_workers=10
Finish with:8.303900718688965 second, num_workers=12
Finish with:9.681997299194336 second, num_workers=14
Finish with:10.215168476104736 second, num_workers=16
Finish with:10.819851875305176 second, num_workers=18
Finish with:11.382972717285156 second, num_workers=20
Finish with:12.100224256515503 second, num_workers=22
Finish with:12.827118635177612 second, num_workers=24
Finish with:13.584873914718628 second, num_workers=26
Finish with:14.99898624420166 second, num_workers=28
Finish with:15.615322828292847 second, num_workers=30
</code></pre>
<p>the previous value of num_workers is 2 and I changed it to 8. After that, I surprisely found that did work! It ran much more faster.Here is what I changed:</p>
<pre><code>trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=8)
</code></pre>
<p>Although the superficial problems is solved, but I am still confused that why the same program run normally on my old pc and pycharm but don't work on my new pc's jupyter notebook. I suppose that is a problem about cpu schedule, it's just a guess cause I'm not expert on this. Someone who know this can tell me about that?</p>
","2023-12-29 09:50:44","0","Answer"
"77730838","77730719","","<p>I think the issue you're experiencing could be related to the configuration of Jupyter Notebook and how it utilizes resources. You can do following suggestions to potentially improve the performance.</p>
<ol>
<li>Check Jupyter Notebook Configuration</li>
</ol>
<p>Ensure that Jupyter Notebook is using the correct Python kernel. Sometimes, Jupyter Notebook may use a different Python environment than the one you intend to use.</p>
<ol start=""2"">
<li>Check Resource Allocation</li>
</ol>
<p>Check the resource allocation for Jupyter Notebook by running the following commands in a Jupyter Notebook cell. Ensure that Jupyter is using all available CPU cores. If not you can adjust.</p>
<pre><code>import os
os.cpu_count()
</code></pre>
<ol start=""3"">
<li>Update Jupyter and Dependencies</li>
</ol>
<p>You can update them using the following commands.</p>
<pre><code>!pip install --upgrade jupyter
!pip install --upgrade numpy tensorflow
</code></pre>
<ol start=""4"">
<li>Use Jupyter Extensions</li>
</ol>
<p>You can install Jupyter Extenstions like</p>
<ul>
<li>jupyter_contrib_nbextensions</li>
<li>nbresuse</li>
</ul>
<p>to monitor resource usage and manage the notebook environment.</p>
","2023-12-29 07:56:42","0","Answer"
"77730719","","low cpu usage when I run a simple cnn model on jupyter notebook","<p>I run a very simple CNN model on the Jupyter notebook, but the process is very slow. I run the same program on my old laptop(core i7U 10gen). and it just took one and half minutes, but on my new laptop(core i9 13900hx and rtx4060) it took 30 minutes!!! They are both ran on CPU, but on my old PC, the CPU usage is 100%, on my new PC, it is about 20%. And then, I run the same program in the PyCharm, it's normal! This confused me very much, I have tried many ways but don't work. I wanna wonder where the real problem is? My Jupyter notebook or other thing?</p>
<p>I tried run the same program on different PC, on different IDE platform. I wanna wonder where the real problem is.</p>
","2023-12-29 07:23:45","-1","Question"
"77729468","77704108","","<p>The problem is given was given by the fact that I was importing the images, and then converting them to tensors with <code>transforms.ToTensor()</code>, which rescales the pixel values in the range [0,1]. While the CNN was actually meant to work with [0,255].
Having so small pixel values, a small standard deviation with the normal initialization is almost equivalent to a null initialization.
So in order to fix this kind of problem you have to be sure that the pixel values are in the range [0,255].
Also the <code>softmax</code> at the end of the network worsens the problem, as already pointed out.</p>
","2023-12-28 22:39:15","0","Answer"
"77728995","77728334","","<p>You can install already builded package:</p>
<p>here's notation from official github lightgbm repository:</p>
<blockquote>
<p>Build GPU Version</p>
<pre><code>pip install lightgbm --config-settings=cmake.define.USE_GPU=ON
</code></pre>
<p>All requirements from Build from Sources section apply for this
installation option as well.</p>
<p>For Windows users, CMake (version 3.8 or higher) is strongly required.</p>
<p>Boost and OpenCL are needed: details for installation can be found in
Installation Guide. Almost always you also need to pass
OpenCL_INCLUDE_DIR, OpenCL_LIBRARY options for Linux and BOOST_ROOT,
BOOST_LIBRARYDIR options for Windows to CMake via pip options, like</p>
<pre><code>pip install lightgbm \
  --config-settings=cmake.define.USE_GPU=ON \
  --config-settings=cmake.define.OpenCL_INCLUDE_DIR=&quot;/usr/local/cuda/include/&quot;
</code></pre>
<p><br />
--config-settings=cmake.define.OpenCL_LIBRARY=&quot;/usr/local/cuda/lib64/libOpenCL.so&quot;</p>
<p>All available options that can be passed via cmake.define.{option}.</p>
<ul>
<li>Boost_ROOT</li>
<li>Boost_DIR</li>
<li>Boost_INCLUDE_DIR</li>
<li>BOOST_LIBRARYDIR</li>
<li>OpenCL_INCLUDE_DIR</li>
<li>OpenCL_LIBRARY</li>
</ul>
<p>For more details see FindBoost and FindOpenCL.</p>
<p>Build CUDA Version</p>
<pre><code>pip install lightgbm --config-settings=cmake.define.USE_CUDA=ON
</code></pre>
<p>All requirements from Build from Sources section apply for this
installation option as well, and CMake (version 3.16 or higher) is
strongly required.</p>
<p>CUDA library (version 10.0 or higher) is needed: details for
installation can be found in Installation Guide.</p>
<p>To use the CUDA version within Python, pass {&quot;device&quot;: &quot;cuda&quot;}
respectively in parameters.</p>
</blockquote>
<p>In short how to build:</p>
<ol>
<li><p>Install Dependencies:
Make sure you have all the necessary dependencies installed on your system. For CUDA support, you need to have CUDA Toolkit and cuDNN installed. Make sure your CUDA Toolkit and cuDNN versions are compatible with the version of LightGBM you are trying to install.</p>
</li>
<li><p>Update CMake Command:
Modify your cmake command to explicitly enable CUDA. Update the command as follows:</p>
</li>
</ol>
<pre><code>cmake -DUSE_GPU=1 -DUSE_CUDA=1 ..
</code></pre>
<ol start=""3"">
<li>build</li>
</ol>
<pre><code>make -j$(nproc)
</code></pre>
<ol start=""4"">
<li>install package in pip</li>
</ol>
<pre><code>cd ../python-package
pip install .
</code></pre>
","2023-12-28 20:18:04","-1","Answer"
"77728508","77094149","","<p>Using multiple GPUs is specific to machine learning libraries. I stumbled upon the same problem while doing image segmentation in Pytorch. The solution is to use the module <a href=""https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html"" rel=""noreferrer"">torch.nn.DataParallel()</a> with the model. The given code can be changed as follows:</p>
<pre><code>device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)
</code></pre>
<p>here, the <code>device_ids</code> is the index of GPUs. Suppose if you have 4 GPUs then it would be <code>device_ids = [0,1,2,3]</code> or whatever the index it maybe.</p>
<p>And the result of
<a href=""https://i.sstatic.net/pc8GW.png"" rel=""noreferrer"">using both GPUs</a> is here!.</p>
<p>PS: This is my first post in the prestigious stack overflow, please do share your comments and views.</p>
","2023-12-28 18:19:04","7","Answer"
"77728334","","install lightgbm GPU in a WSL conda env","<p>-------------------- original question ---------------------------------</p>
<p>How to install LightGBM??
I have checked multiple sources but staill failed to install.</p>
<p>I tried pip and conda but both return the error:</p>
<pre><code>[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.
[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.
Please recompile with CMake option -DUSE_CUDA=1
</code></pre>
<p>What i have tried is following:</p>
<pre><code>git clone --recursive https://github.com/microsoft/LightGBM
cd LightGBM/
mkdir -p build
cd build
cmake -DUSE_GPU=1 ..
make -j$(nproc)
cd ../python-package
pip install .
</code></pre>
<p>-------------------- My solution below (cuda) ---------------------------------</p>
<p>Thanks for the replies guys. I tried some ways and finally it works as below:
First, make sure cmake is installed (under the wsl):</p>
<pre><code>sudo apt-get update
sudo apt-get install cmake
sudo apt-get install g++
</code></pre>
<p>Then,</p>
<pre><code>git clone --recursive https://github.com/microsoft/LightGBM
cd LightGBM
mkdir build
cd build
cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..
make -j4
</code></pre>
<p>Currently, the install is not linked to any conda env yet. So to do this, under the vscode terminal (or still wsl), conda activate an env and then create a jupyter notebook for testing:
Make sure that <code>lib_lightgbm.so</code> is under the <code>LightGBM/python-package</code>, if not, copy into that folder.
Then in the jupyter notebook:</p>
<pre><code>import sys
import numpy as np
sys.path.append('/mnt/d/lgm-test2/LightGBM/python-package')
import lightgbm as lgb
</code></pre>
<p>The final bit is you can refer Jame's reply that device needs to be set to 'cuda' instead of 'gpu'.</p>
","2023-12-28 17:34:48","4","Question"
"77716307","","TypeError: Cannot serialize object Ellipsis of type <class 'ellipsis'>","<p>I am learning Tensorflow / Keras with the book &quot;Deep Learning with Python&quot;. In chapter 8 it explains how to use a pretrained model. However, the provided code doesn't run and I get an error message when executing <code>model.fit</code>:</p>
<pre><code>TypeError: Cannot serialize object Ellipsis of type &lt;class 'ellipsis'&gt;. 
To be serializable, a class must implement the 'get_config()' method.
</code></pre>
<p>I am using Tensorflow version 2.15.0</p>
<p>The program uses the dogs-vs-cats dataset from kaggle. It creates a smaller subset and creates a training, validation and test dataset. This all works as it is used for some other examples in the book. It then uses the pretrained VGG16 model and trains a dense layer connected to it</p>
<p>Here is my code:</p>
<pre><code>import tensorflow as tf
from tensorflow import keras

#upload kaggle.json file with the kaggle API Token 
from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq dogs-vs-cats.zip
!unzip -qq train.zip

import os, shutil, pathlib
original_dir = pathlib.Path(&quot;train&quot;)
new_base_dir = pathlib.Path(&quot;dogs-vs-cats_small&quot;)

def make_subset(subset_name, start_index, end_index):
    for category in (&quot;cat&quot;, &quot;dog&quot;):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f&quot;{category}.{i}.jpg&quot; for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(&quot;train&quot;, start_index=0, end_index=1000)
make_subset(&quot;validation&quot;, start_index=1000, end_index=1500)
make_subset(&quot;test&quot;, start_index=1500, end_index=2500)

import pathlib

base_dir = pathlib.Path(&quot;dogs-vs-cats_small&quot;)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir / &quot;train&quot;,
    image_size=(180, 180),
    batch_size=32
)

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir / &quot;validation&quot;,
    image_size=(180, 180),
    batch_size=32
)

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir / &quot;test&quot;,
    image_size=(180, 180),
    batch_size=32
)

#create neural network
conv_base = keras.applications.vgg16.VGG16(
  weights=&quot;imagenet&quot;,
  include_top=False
)
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(&quot;horizontal&quot;),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
)

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = keras.applications.vgg16.preprocess_input(x)
x = conv_base(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
outputs = keras.layers.Dense(1, activation=&quot;sigmoid&quot;)(x)

model = keras.Model(inputs, outputs)

model.compile(
    loss=&quot;binary_crossentropy&quot;,
    optimizer=&quot;rmsprop&quot;,
    metrics=[&quot;accuracy&quot;]
)

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath=&quot;features_extraction_with_data_augmentation.keras&quot;,
        save_best_only=True,
        monitor=&quot;val_loss&quot;
    )
]

history = model.fit(  # error thrown here
    train_dataset,
    epochs=50,
    validation_data=validation_dataset,
    callbacks=callbacks
)
</code></pre>
","2023-12-26 08:20:52","3","Question"
"77708996","","How to convert model.safetensor to pytorch_model.bin?","<p>I'm fine tuning a pre-trained bert model and i have a weird problem:
When i'm fine tuning using the CPU, the code saves the model like this:</p>
<p><a href=""https://i.sstatic.net/ve8EQ.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/ve8EQ.png"" alt=""model fine tuned with cpu"" /></a></p>
<p>With the &quot;pytorch_model.bin&quot;. But when i use CUDA (that i have to), the model is saved like this:</p>
<p><a href=""https://i.sstatic.net/vOfy1.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/vOfy1.png"" alt=""model fine tuned with gpu"" /></a></p>
<p>When i try to load this &quot;model.safetensors&quot; in the future, it raises an error &quot;pytorch_model.bin&quot; not found. I'm using two differents venvs to test using the CPU and CUDA.</p>
<p>How to solve this? is some version problem?</p>
<p>I'm using sentence_transformers framework to fine-tune the model.</p>
<p>Here's my training code:</p>
<pre class=""lang-py prettyprint-override""><code>checkpoint = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'

word_embedding_model = models.Transformer(checkpoint, cache_dir=f'model/{checkpoint}')
pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode='mean')
model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda')


train_loss = losses.CosineSimilarityLoss(model)

evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(val_examples, name='sbert')

model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=5, evaluator=evaluator, show_progress_bar=True, output_path=f'model_FT/{checkpoint}', save_best_model=True)
</code></pre>
<p>I did try the tests in two differentes venvs, and i'm expecting the code to save a &quot;pytorch_model.bin&quot; not a &quot;model.safetensors&quot;.</p>
<p>EDIT: i really don't know yet, but it seems that is the newer versions of transformers library that causes this problem. I saw that with hugging-face is possible to load the safetensors, but with Sentence-transformers (that i need to use) it's not.</p>
","2023-12-23 20:43:20","7","Question"
"77706936","77704426","","<p>The <code>7x7</code> conv at the start of the model was popular for resnet-era CNN models. The thinking was a larger conv at the start would 1) grab larger bits of the full resolution input and 2) increase the receptive field for subsequent layers.</p>
<p>More modern CNNs have moved away from larger convolution kernels in general, preferring to add more layers of <code>3x3</code> convs instead of larger kernel layers.</p>
","2023-12-23 07:27:35","1","Answer"
"77706508","77231544","","<p>The problem is by default, when you use <code>make_future_dataframe</code> using model object, the model will only predict <code>n_forecasts</code> ahead. In this case, the default value for <code>n_forecasts</code> is 1. Hence, you will only see 1 step future prediction. If you want the model to predict 7 days ahead, you have to train the model with <code>n_forecasts=7</code>.</p>
<p>If you want to know your model's hyperparam values, use <code>model.model.n_forecasts</code> to check the value.</p>
","2023-12-23 03:08:51","1","Answer"
"77706184","77704426","","<p>It depends on your datasets. The input size of CIFAR-10 is 32x32. A 3x3 filter may lead to too small feature maps in the following layers and thus hurt the performance of the downstream applications (e.g., style transfer or transfer learning), while ResNet is originally proposed for ImageNet of size 224x224. To this end, some people modify the architecture to better suit their applications.</p>
<p>However, both 7x7 and 3x3 should be fine as long as you specify the architecture clearly (if you are writing a paper or document).</p>
","2023-12-22 23:22:49","1","Answer"
"77705970","77704108","","<p>I was able to use your model to attain about 90% validation accuracy on an MNIST dataset (1500 samples, 10 classes). I used the same network you defined, but modified the layer sizes for my image dimensions and output classes (28x28 grayscale input, 10-class output).</p>
<p>Main things I did:</p>
<ul>
<li>Normalised the input images</li>
<li>Used the default layer initialisations</li>
<li>Used an Adam optimizer rather than SGD</li>
<li><strong>Update:</strong> Don't return <code>softmax</code> because the loss function needs the raw logits</li>
</ul>
<p><a href=""https://i.sstatic.net/9zLmF.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/9zLmF.png"" alt=""enter image description here"" /></a></p>
<p><a href=""https://i.sstatic.net/G3J8t.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/G3J8t.png"" alt=""enter image description here"" /></a></p>
<pre><code>import torch
from torch import nn, optim
from torch.utils.data import DataLoader

import torchvision

from datetime import datetime
import numpy as np

np.random.seed(0)
torch.manual_seed(0)

#Load data
mnist = torchvision.datasets.MNIST('./torch_mnist', train=True, download=True)

#Get tensors, and to appropriate dtypes
X = mnist.data.float()
y = mnist.targets.long()

#Normalise X
means = X.mean(dim=0)
stds = X.std(dim=0)
X = torchvision.transforms.Normalize(means, stds + 1e-10)(X)
X = torch.unsqueeze(X, dim=1)

#Shuffle. Stratified sampling of 1500 samples.
from sklearn.model_selection import train_test_split
X, _, y, _ = train_test_split(X, y, stratify=y, train_size=1500, shuffle=True, random_state=0)

class simpleCNN(nn.Module):
  def __init__(self):
    super().__init__()

    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1)
    self.relu1 = nn.ReLU()
    self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)

    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1)
    self.relu2 = nn.ReLU()
    self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)

    self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1)
    self.relu3 = nn.ReLU()

    # self.fc1 = nn.Linear(32 * 12 * 12, 15)
    self.fc1 = nn.Linear(32 * 3 * 3, 10)
    self.softmax = nn.Softmax(dim=1)

  def forward(self,x):
    x = self.conv1(x)
    x = self.relu1(x)
    x = self.maxpool1(x)

    x = self.conv2(x)
    x = self.relu2(x)
    x = self.maxpool2(x)

    x = self.conv3(x)
    x = self.relu3(x)

    # x = x.view(-1, 32 * 12 * 12)
    x = x.view(-1, 32 * 3 * 3)

    x = self.fc1(x) #return raw logits to CE loss function
    #x = self.softmax(x)

    return x

def init_weights(m):
  if isinstance(m,nn.Conv2d) or isinstance(m,nn.Linear):
    nn.init.normal_(m.weight,0,0.01)
    nn.init.zeros_(m.bias)

model = simpleCNN()
# model.apply(init_weights)

loss_function = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
optimizer = optim.Adam(model.parameters())

validation_size = 250
train_loader = DataLoader(list(zip(X[:-validation_size], y[:-validation_size])), shuffle=True, batch_size=32)
validation_loader = DataLoader(list(zip(X[-validation_size:], y[-validation_size:])), batch_size=validation_size)

def train_one_epoch(epoch_index, loader):
  running_loss = 0

  for i, data in enumerate(loader):

    inputs, labels = data #get the minibatch
    outputs = model(inputs) #forward pass

    loss = loss_function(outputs, labels) #compute loss
    running_loss += loss.item() #sum up the loss for the minibatches processed so far

    optimizer.zero_grad() #reset gradients
    loss.backward() #compute gradient
    optimizer.step() #update weights

  return running_loss / (i + 1) # average loss per minibatch

EPOCHS = 16

best_validation_loss = np.inf

train_losses = []
validation_losses = []
validation_accuracies = []

for epoch in range(EPOCHS):
    print('EPOCH{:&gt;2d}'.format(epoch + 1), end='    ')

    model.train()
    train_loss = train_one_epoch(epoch, train_loader)
    
    running_validation_loss = 0.0

    model.eval()

    with torch.no_grad():
        total_correct = 0
        for i, vdata in enumerate(validation_loader):
            vinputs, vlabels = vdata
            voutputs = model(vinputs)
            vloss = loss_function(voutputs, vlabels)
            running_validation_loss += vloss.item()
            
            total_correct += (voutputs.argmax(dim=1) == vlabels).sum()
    validation_loss = running_validation_loss / (i + 1)
    validation_acc = total_correct / len(validation_loader.dataset) * 100
    print('LOSS train: {:1.3f} validation: {:1.3f} | ACC val: {:&gt;5.1f}%'.format(
        train_loss, validation_loss, validation_acc
    ))
  
    if validation_loss &lt; best_validation_loss: #save the model if it's the best so far
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        best_validation_loss = validation_loss
        model_path = 'model_{}_{}'.format(timestamp, epoch)
        torch.save(model.state_dict(), model_path)
    
    train_losses.append(train_loss)
    validation_losses.append(validation_loss)
    validation_accuracies.append(validation_acc)

import matplotlib.pyplot as plt
plt.plot(train_losses, color='tab:red', linewidth=3, label='train loss')
plt.plot(validation_losses, color='tab:green', linewidth=3, label='validation loss')
plt.xlabel('Epoch')
plt.ylabel('CE loss')

ax_right = plt.gca().twinx()
ax_right.plot(validation_accuracies, color='tab:green', linestyle='--', label='validation accuracy')
ax_right.set_ylabel('accuracy (%)')

plt.gcf().legend(ncol=3)
plt.gcf().set_size_inches(6, 3)
</code></pre>
","2023-12-22 21:58:25","1","Answer"
"77704426","","Resnet34 first layer 7x7 or 3x3","<p>I've been trying to implement Resnet34 using pytorch but while looking at other's implementations, I see that some of them have 3x3 convlution layers + bn + relu as the first layer. However, on the architecture graph it is written 7x7/2 convolution layer. I am really confused about which one is the right one. By the way, I am training on CIFAR10 and am currently getting 0.9 accuracy after 100 epoches using the 7x7 convolution layers.</p>
<p>Thank you!</p>
<p><a href=""https://i.sstatic.net/4kypF.png"" rel=""nofollow noreferrer"">architecture graph</a></p>
<pre><code>self.input_layer = nn.Sequential(             
nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False),             
nn.BatchNorm2d(64),             
nn.ReLU(),             
nn.MaxPool2d(3, stride=2,padding=1)         
)
</code></pre>
<p>Here is the code for my first convolution layer.</p>
","2023-12-22 15:14:50","1","Question"
"77704108","","Convolutional Neural Network not learning","<p>I'm trying to train a Convolutional Neural Network for image recognition on a training set 1500 images with 15 categories. I've been told that, with this architecture and initial weights drawn from a Gaussian distribution with a mean of 0 and a standard deviation of 0.01 and the initial bias values to 0, with the proper learning rate it should achieve an accuracy of around 30%.</p>
<p>However, it doesn't learn anything at all: the accuracy is similar to the one of a random classifier and the weights after training still follow a normal distribution. What am I doing wrong?</p>
<p>This is the NN</p>
<pre><code>class simpleCNN(nn.Module):
  def __init__(self):
    super(simpleCNN,self).__init__() #initialize the model

    self.conv1=nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=1) #Output image size is (size+2*padding-kernel)/stride --&gt;62*62
    self.relu1=nn.ReLU()
    self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2) #outtput image 62/2--&gt;31*31

    self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=1) #output image is 29*29
    self.relu2=nn.ReLU()
    self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2) #output image is 29/2--&gt;14*14  (MaxPool2d approximates size with floor)

    self.conv3=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1) #output image is 12*12
    self.relu3=nn.ReLU()

    self.fc1=nn.Linear(32*12*12,15) #16 channels * 16*16 image (64*64 with 2 maxpooling of stride 2), 15 output features=15 classes
    self.softmax = nn.Softmax(dim=1)

  def forward(self,x):
    x=self.conv1(x)
    x=self.relu1(x)
    x=self.maxpool1(x)

    x=self.conv2(x)
    x=self.relu2(x)
    x=self.maxpool2(x)

    x=self.conv3(x)
    x=self.relu3(x)

    x=x.view(-1,32*12*12)

    x=self.fc1(x)
    x=self.softmax(x)

    return x
</code></pre>
<p>The inizialization:</p>
<pre><code>def init_weights(m):
  if isinstance(m,nn.Conv2d) or isinstance(m,nn.Linear):
    nn.init.normal_(m.weight,0,0.01)
    nn.init.zeros_(m.bias)

model = simpleCNN()
model.apply(init_weights)
</code></pre>
<p>The training function:</p>
<pre><code>loss_function=nn.CrossEntropyLoss()
optimizer=optim.SGD(model.parameters(),lr=0.1,momentum=0.9)

def train_one_epoch(epoch_index,loader):
  running_loss=0

  for i, data in enumerate(loader):

    inputs,labels=data #get the minibatch
    outputs=model(inputs) #forward pass

    loss=loss_function(outputs,labels) #compute loss
    running_loss+=loss.item() #sum up the loss for the minibatches processed so far

    optimizer.zero_grad() #reset gradients
    loss.backward() #compute gradient
    optimizer.step() #update weights

  return running_loss/(i+1) # average loss per minibatch

</code></pre>
<p>The training:</p>
<pre><code>EPOCHS=20

best_validation_loss=np.inf

for epoch in range(EPOCHS):
  print('EPOCH{}:'.format(epoch+1))

  model.train(True)
  train_loss=train_one_epoch(epoch,train_loader)

  running_validation_loss=0.0

  model.eval()

  with torch.no_grad(): # Disable gradient computation and reduce memory consumption
    for i,vdata in enumerate(validation_loader):
      vinputs,vlabels=vdata
      voutputs=model(vinputs)
      vloss=loss_function(voutputs,vlabels)
      running_validation_loss+=vloss.item()
  validation_loss=running_validation_loss/(i+1)
  print('LOSS train: {} validation: {}'.format(train_loss,validation_loss))

  if validation_loss&lt;best_validation_loss: #save the model if it's the best so far
    timestamp=datetime.now().strftime('%Y%m%d_%H%M%S')
    best_validation_loss=validation_loss
    model_path='model_{}_{}'.format(timestamp,epoch)
    torch.save(model.state_dict(),model_path)

</code></pre>
<p>With the default initializion it works a little better, but i'm supposed to reach 30% with the gaussian.
Could you spot some issue that might be causing it not to learn? I have already tries different learning rates and momentum.</p>
","2023-12-22 14:06:23","2","Question"
"77696103","77694839","","<p>To run on multiple GPU:s you must adopt the training to run distributed training.
Pytorch has documentation regarding the area here:</p>
<p><a href=""https://pytorch.org/tutorials/distributed/home.html"" rel=""nofollow noreferrer"">https://pytorch.org/tutorials/distributed/home.html</a></p>
<p>From there you can find what case fits you the best.</p>
<p>I also found another source which goes into the distributed training area:
<a href=""https://saturncloud.io/blog/how-to-use-multiple-gpus-in-pytorch/"" rel=""nofollow noreferrer"">https://saturncloud.io/blog/how-to-use-multiple-gpus-in-pytorch/</a></p>
<p>There they talk about three different methods, where the first (Data parallelism) is the most common for simpler and smaller models, as it is the easiest to adapt to.</p>
","2023-12-21 06:22:26","1","Answer"
"77694839","","How can I use Multiple GPU's During Model training on Kaggle","<p>On Kaggle I have 2 GPU T4, but I don't understand how I can use them in Pytorch or adapt the code to train on 2 gpu's</p>
<p><a href=""https://i.sstatic.net/YI7oO.png"" rel=""nofollow noreferrer"">pic of 2 gpu's</a></p>
<p>My training code:</p>
<pre><code>for epoch in range(2):

    running_loss = 0.0
    for data in tqdm(dataset):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
</code></pre>
","2023-12-20 22:41:19","4","Question"
"77666876","77298910","","<p>Downgrade the wandb version to wandb==0.15.11</p>
","2023-12-15 14:19:01","0","Answer"
"77663898","77657071","","<p>What crabdog says is good, reading should be fast and avoid minimal resource consumption.</p>
<p>I don't know exactly how your project is structured, but remember that you can use data cachers, queues and other techniques to mi</p>
","2023-12-15 01:51:13","0","Answer"
"77663625","77657071","","<p>If these are all tensor fields (used during vector search) here are some things to be aware of.</p>
<ul>
<li>The single k-v pair will only work if the value is a string. List of strings are only supported as non-tensor fields used for filtering. So this would work: <strong><code>Tags: &quot;blue, patterned, cotton, elegant&quot;</code></strong></li>
<li>Because there is only one k-v pair, only a single tensor field is generated. Because the string is short, you will likely only get a single vector for this tensor field</li>
<li>For the multiple k-v pair case, each k-v pair will generate a tensor field (and 1 vector per tensor field).</li>
<li>The extra vectors will require greater RAM usage, and perhaps, depending on the scale of your index, a slightly slower search speed</li>
</ul>
<p>Vector search performs better when the model that is creating the embedding has some context. So an embedding generated from the string <strong><code>&quot;blue, patterned, cotton, elegant&quot;</code></strong> will likely have better recall performance than 4 separate embeddings that are each generated from a single word. So for recall, speed and resource performance the first option will work better in most cases.</p>
","2023-12-14 23:50:54","0","Answer"
"77663602","75371176","","<p><code>MachAr</code> was deprecated in the <a href=""https://numpy.org/doc/stable/release/1.22.0-notes.html#the-np-machar-class-has-been-deprecated"" rel=""noreferrer"">numpy v1.22</a> release notes.<br />
Rather than holding back numpy to an older version, you could also use statsmodels v0.13.1 or newer.  That was the version that fixed this issue.</p>
","2023-12-14 23:41:13","6","Answer"
"77657071","","Single or multiple key-value pair data structure for vector search with Marqo?","<p>I'm implementing vector search for a work project using Marqo Cloud. I have some data for my documents (products) that can either be structured as:</p>
<p>A single key-value pair, for example: Tags: red, spotty, nylon, casual</p>
<p>Or multiple key-value pairs with each tag title, for example:
Color: red
Design: spotty
Material: nylon
Style: casual</p>
<p>Will one of these data structures perform better than the other in vector search? Or is the difference likely to be negligible?</p>
","2023-12-13 23:34:17","0","Question"
"77652476","77642444","","<p>I get the same error with chromadb and ollama:</p>
<pre><code>AttributeError: 'SentenceTransformerEmbeddingFunction' object has no attribute 'embed_query'
</code></pre>
<p>My code:</p>
<pre><code>embeddingfn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=&quot;all-MiniLM-L6-v2&quot;)

client = chromadb.PersistentClient(path=&quot;/Users/massa/AI/chromadb/&quot;)
collection = client.get_or_create_collection(name=&quot;asstr.org&quot;, embedding_function=embeddingfn)

ollama = Ollama(base_url='http://localhost:11434', model=&quot;llama2-uncensored&quot;)
langchain_chroma = Chroma(
    client=client,
    collection_name=&quot;asstr.org&quot;,
    embedding_function=embeddingfn)

qachain=RetrievalQA.from_chain_type(ollama, retriever=langchain_chroma.as_retriever())
d = qachain({&quot;query&quot;: sys.argv[1] })
</code></pre>
<p>I have updated all versions just now. All on python3.11.
Name: chromadb
Version: 0.4.19
Name: openai
Version: 1.3.9
Name: langchain
Version: 0.0.350</p>
<p>THANKS!!</p>
","2023-12-13 09:41:41","2","Answer"
"77652325","77635064","","<p>I found a solution --- the batch normalization layer before the last layer (Conv2DTranspose)</p>
<pre><code>x = keras.layers.BatchNormalization()(x)
</code></pre>
","2023-12-13 09:21:24","0","Answer"
"77646746","77610686","","<p>My guess is that different random seeds are the reason for your different results.</p>
<p>If you provide the integer class representation to <code>autokeras</code>, it will be converted to the one-hot representation automatically. You can check this by running</p>
<pre><code>[p.preprocessor for p in clf.outputs[0].in_blocks[0].get_hyper_preprocessors()]
</code></pre>
<p>at the end of your notebook using the integer class representation which should show the <code>OneHotEncoder</code> object at the end of the list. So in both of your notebooks the loss function should be <code>CategoricalCrossentropy</code> which you can check by running <code>clf.outputs[0].in_blocks[0].loss</code> at the end of your notebooks.</p>
<p>To fix the random seed issue, the <code>StructuredDataClassifier</code> constructor provides a <code>seed</code> parameter, but in my experience it is not enough (after setting this I still got different results on a toy problem). So do this instead:</p>
<pre><code>import keras  # you can do this at the top of your notebook
random_seed = 17  # choose your favorite

keras.utils.set_random_seed(random_seed)
clf = ak.StructuredDataClassifier(overwrite=True, max_trials=10, seed=random_seed)
</code></pre>
<p>I also added the <code>overwrite=True</code> parameter to ensure no previous results are loaded (depending on how you ran your notebooks this could also contribute to the differences).</p>
<p>If I am correct, you might want to increase the <code>max_trials</code> parameter later to stabilize the results (that is to see comparable evaluation results for different random seeds). As I see in the <code>autokeras</code> code, the default setting is 100.</p>
","2023-12-12 14:12:40","1","Answer"
"77644613","77380874","","<p>You can apply the idea of Gradient Reversal layer to train the weight of losses, but in general I think you should rescale the loss and apply some constraints to the weights (sigmoid, softmax, ...)</p>
","2023-12-12 08:27:32","0","Answer"
"77643384","77642444","","<p>Can you check python version, langchain version and openai version again? I run sucessfully with my versions:</p>
<pre><code>python==3.11
langchain==0.0.339
openai==1.3.4
chromadb==0.4.17
</code></pre>
","2023-12-12 02:37:18","2","Answer"
"77642444","","How can you use an already created chromadb collection with a LLM using openai and langchain?","<p>I already have a chromadb collection created with its documents and metadata.</p>
<p>The problem is when I want to use langchain to create a llm and pass this chromadb collection to use as a knowledge base.</p>
<pre><code>langchain_chroma = Chroma(
client=persistent_client,
collection_name=collection.name,
embedding_function=openai_ef,
)

llm_model = &quot;gtp35turbo-latest&quot;

llm = AzureChatOpenAI(
   api_key=openai_api_key,
   api_version=openai_api_version,
   azure_endpoint=openai_api_base,
   model=llm_model)

qa_chain = RetrievalQA.from_chain_type(
   llm,
   retriever=langchain_chroma.as_retriever(),
   chain_type=&quot;refine&quot;
)
</code></pre>
<p>When I want to run:</p>
<pre><code>qa_chain.run(&quot;How many datascientist do I need for a Object detection problem&quot;)
</code></pre>
<p>I got this error:</p>
<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-81-3cdb65aeb43e&gt; in &lt;cell line: 1&gt;()
----&gt; 1 qa.run(&quot;How many datascientist do I need for a Object detection problem&quot;)

9 frames
/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py in similarity_search_with_score(self, query, k, filter, where_document, **kwargs)
    430             )
    431         else:
--&gt; 432             query_embedding = self._embedding_function.embed_query(query)
    433             results = self.__query_collection(
    434                 query_embeddings=[query_embedding],

AttributeError: 'OpenAIEmbeddingFunction' object has no attribute 'embed_query'
</code></pre>
<p>How to solve it?</p>
","2023-12-11 21:17:23","1","Question"
"77640235","77438653","","<p>The approach NLP from scratch described is correct, but there are other ways.</p>
<p><strong>Current LLMS such as chatgpt are sometimes able to perform this kind of task without any additional training.</strong></p>
<p>For example, I used this prompt</p>
<blockquote>
<p>Based on the following text, which species or genus are unicelular, and which filamentous?
Please answer in the format &quot;Genus: unicelular&quot;
Nannochloropsis gaditana is in the genus of Nannochloropsis comprising six known species all of which are unicelular. Unlike these species all species in the genus Arthrospira are filamentous such as Arthrospira platensis.</p>
</blockquote>
<p>And h2oGPT [Model: mistralai/Mixtral-8x7B-Instruct-v0.1] on extract mode <a href=""https://gpt.h2o.ai/?_gl=1*1ebu9dd*_ga*NDgwMTA3NDE3LjE3MDIzMDM1NDU.*_ga_7C4SBBBJ5L*MTcwMjMwMzU0NS4xLjEuMTcwMjMwMzU1OC40Ny4wLjA."" rel=""nofollow noreferrer"">accesible here</a> gave me this answer</p>
<blockquote>
<p>Sure, here's the answer based on the given text:<br><br>*
Nannochloropsis: unicellular<br>* Arthrospira: filamentous</p>
</blockquote>
<p><strong>The prompt could be seriously improved to better fit the results you desire and the model you decide to use, and you should play around with it and try to optimize it.</strong></p>
<p>That said, this approach could also definitely work to achieve what you desire without training. Good luck!</p>
","2023-12-11 14:20:38","3","Answer"
"77637990","77635064","","<p>It may be difficult to answer as you do not use any activation of you output.</p>
<p>If you have 1 class and you want to predict if the sample belongs to that class you should have a sigmoid activation on your output, and then threshold the prediction as the sigmoid activation will give you the probability of the predicted class. This is defined as binary classification.</p>
<p>I would keep the <code>OUTPUT_CLASSES=1</code> as that will give you the possibility of the binary classification if you use the sigmoid activation on the final layer:</p>
<pre><code># This is the last layer of the model
last = layers.Conv2DTranspose(
    filters=output_channels, kernel_size=3, strides=2,
    padding='same', activation=&quot;sigmoid&quot;)  #64x64 -&gt; 128x128

x = last(x)
</code></pre>
","2023-12-11 07:23:07","1","Answer"
"77635064","","Adjust Image Segmentaion model (from TF tutorial) for binary masking","<p>I need an Image Segmentation model for Tensorflow. Input is Image and Mask(binary, masked or non-masked), and output is image mask with 0 and 1.</p>
<p>I followed the Image segmentation tutorial from <a href=""https://www.tensorflow.org/tutorials/images/segmentation"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/images/segmentation</a></p>
<p>But now I want to run it for binary mask (without border class) on my dataset
The new dataset is prepared and inputted to the model.fit. It must be fine.</p>
<p>How do I change this model to only 2 classes (non-masked and masked)?</p>
<pre><code>base_model: keras.Model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)

# Use the activations of these layers
layer_names = [
    'block_1_expand_relu',   # 64x64
    'block_3_expand_relu',   # 32x32
    'block_6_expand_relu',   # 16x16
    'block_13_expand_relu',  # 8x8
    'block_16_project',      # 4x4
]
base_model_outputs = [base_model.get_layer(name).output for name in layer_names]

# Create the feature extraction model
down_stack = Model(inputs=base_model.input, outputs=base_model_outputs)

down_stack.trainable = False

up_stack = [
    pix2pix.upsample(512, 3),  # 4x4 -&gt; 8x8
    pix2pix.upsample(256, 3),  # 8x8 -&gt; 16x16
    pix2pix.upsample(128, 3),  # 16x16 -&gt; 32x32
    pix2pix.upsample(64, 3),   # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
  inputs = layers.Input(shape=[128, 128, 3])

  # Downsampling through the model
  skips = down_stack(inputs)
  x = skips[-1]
  skips = reversed(skips[:-1])

  # Upsampling and establishing the skip connections
  for up, skip in zip(up_stack, skips):
    x = up(x)
    concat = layers.Concatenate()
    x = concat([x, skip])

  # This is the last layer of the model
  last = layers.Conv2DTranspose(
      filters=output_channels, kernel_size=3, strides=2,
      padding='same')  #64x64 -&gt; 128x128

  x = last(x)

  return Model(inputs=inputs, outputs=x)

OUTPUT_CLASSES = 3

model = unet_model(output_channels=OUTPUT_CLASSES)

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
</code></pre>
<p>When I change OUTPUT_CLASSES  to 2 it gives me an error:</p>
<pre><code>W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.
</code></pre>
<p>When <code>OUTPUT_CLASSES</code> is 1 the predicted mask is empty.</p>
<p>Maybe something else must be changed? I'm not into NN architecture yet, so I may not see something obvious.</p>
<p><strong>EDIT:</strong></p>
<p>I have added activation='sigmoid' to the output layer</p>
<pre><code>  last = tf.keras.layers.Conv2DTranspose(
      filters=output_channels, kernel_size=3, strides=2,
      padding='same', activation='sigmoid')  #64x64 -&gt; 128x128

  x = last(x)
</code></pre>
<p>and <code>OUTPUT_CLASSES = 1</code></p>
<p>the weird behavior is the next:
expected mask is when I train it on a very small dataset (picture and mask from testing included in this dataset, just for testing how it detects seen image), I'm getting something on the first epoch. But the more epoch the worse result. However, the accuracy is ~0.99.</p>
<p>expected mask:<br />
<a href=""https://i.sstatic.net/u8dsX.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/u8dsX.png"" alt=""expected mask"" /></a></p>
<p>predicted mask epoch 0:<br />
<a href=""https://i.sstatic.net/c43Cz.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/c43Cz.png"" alt=""predicted mask epoch 0:"" /></a></p>
<p>If you open the image you may see a slight shadow on the expected mask part.</p>
<p>predicted mask epoch 1:<br />
<a href=""https://i.sstatic.net/MYN6R.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/MYN6R.png"" alt=""enter image description here"" /></a><br />
...</p>
<p>epoch 4:<br />
<a href=""https://i.sstatic.net/9uYaJ.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/9uYaJ.png"" alt=""enter image description here"" /></a></p>
<p>so it's getting worse with each iteration.</p>
<p>The dataset includes images that should show no mask. Maybe that's the issue? (Edit: excluded data without masks from dataset -- did not help)</p>
<p>EDIT 2:</p>
<pre><code>x = tf.keras.layers.BatchNormalization()(x) 
</code></pre>
<p>helped, not perfect but something</p>
","2023-12-10 13:55:04","1","Question"
"77634237","77061898","","<p>As far as I know when working with basic model like the one you mentioned there are chances that the model won't be able to give quite good results. You can switch to working with models like GPT-3 and llama if that's feasible.</p>
","2023-12-10 09:08:41","-2","Answer"
"77632228","77610686","","<p><strong>Assumption 1:</strong>
OHE preprocessing, results in 3 classes, based on the <a href=""https://autokeras.com/structured_data_classifier/"" rel=""nofollow noreferrer"">Structured data classifier documentation</a> - <code>autokeras</code> will pick <code>categorical_crossentropy</code>.</p>
<p><strong>Assumption 2:</strong>
Without_OHE, it will result in 1 class (with possible integer values 1, 2, or 3). Again, based on the documentation mentioned above - <code>autokeras</code> will now pick  <code>binary_crossentropy</code> (I guess).</p>
<p>So without the full data (or at least a MVDataset) we have a hard time helping. I would recommend to debug as follows:</p>
<ul>
<li>a) Specifiy the loss you want to use in your both scripts explicitly. At least we will know which loss you are using and how the results will look like.</li>
<li>b) As the second thing you are trying shouts regression problem to me, you should be using the <code>autokeras'</code> <a href=""https://autokeras.com/structured_data_regressor/"" rel=""nofollow noreferrer"">Structured data regressor</a>.</li>
</ul>
<p><em>Note: From my experience (but who am I to judge) I would expect the classification problem to be better performing. As this is an easier task to begin with. So I would not trust your current regression performance, and you did right showing up here.</em></p>
","2023-12-09 17:36:07","0","Answer"
"77627025","77625369","","<p>I think it helps to start with a simple baseline. In your case there's additional complexity of wrapping the model in a class. Here's a simpler approach that is useful for checking things are working, and running some simple tests:</p>
<p><a href=""https://i.sstatic.net/B728j.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/B728j.png"" alt=""enter image description here"" /></a></p>
<pre><code>import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#Read in data
df = pd.read_csv(&quot;diabetes.csv&quot;)
features = df.drop(columns=&quot;Outcome&quot;)
y = df[&quot;Outcome&quot;]

#Start off without CV to confirm basics, like model can learn
features_train, features_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=0)

#Preprocess the features
scaler = StandardScaler().fit(features_train)
X_train = scaler.transform(features_train)
X_test = scaler.transform(features_test)

#Fit default model
model = LogisticRegression().fit(X_train, y_train)

#Print scores
print('Accuracy scores')
train_pred = model.predict(X_train)
test_pred = model.predict(X_test)
print(' Train:', accuracy_score(y_train, train_pred).round(3))
print(' Test: ', accuracy_score(y_test, test_pred).round(3))
</code></pre>
<p>We start off without using CV, just to ensure the model is fitting and we're getting reasonable results. The 0 predictions look good, but the 1 predictions are quite spread out. A histogram of the data identifies potential issues:</p>
<p><a href=""https://i.sstatic.net/4ZJIc.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4ZJIc.png"" alt=""enter image description here"" /></a></p>
<pre><code>features_train.hist(bins=50, grid=False)
plt.tight_layout()
plt.show()
</code></pre>
<p>Some features have a value of 0. Whilst this makes sense for some features like Pregnancies, it's not a valid value for Age, BMI, and other measurements. There are ways to deal with this, including replacing those invalid zeros with the mean. Running <code>.hist()</code> on <code>y_train</code> shows that the dataset is imbalanced - using <code>class_weight=&quot;balanced&quot;</code> will help <code>LogisticRegression</code> manage the imbalance.</p>
","2023-12-08 13:48:17","2","Answer"
"77626020","77625369","","<p>In this case, I don't think the issue is with the dataset, as it has a 10.0 usability rating on Kaggle. The only thing that stands out to me in your code is the 2000 iterations that you train the model for, it could be a bit too much and cause the model to overfit.</p>
<p>If you don't want to mess with hyperparameter tuning yet, try lowering the number of iterations yourself by different intervals, and see how the model behavior changes with different values of <code>max_iter</code>.</p>
<p>If you want to find the optimal number of iterations, try using <code>GridSearchCV</code> from sklearn (<a href=""https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"" rel=""nofollow noreferrer"">docs</a>) on the <code>max_iter</code> hyperparameter in order to find the best number of iterations to train the model for.</p>
","2023-12-08 10:47:18","0","Answer"
"77625369","","Why is my Logistic Regression Model predicting the same thing repetitively?","<p><a href=""https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset</a></p>
<p>I used this kaggle dataset for my diabetes dataset and am trying to create a LogisticRegression model to predict outcomes.</p>
<p>I created the following class:</p>
<pre><code>import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import KFold
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

class diabetesLogReg:
    df = pd.read_csv(&quot;/Users/aahan_bagga/Desktop/diabetes_data.csv&quot;)
    X=df.drop([&quot;Outcome&quot;], axis=1)
    Y=df[&quot;Outcome&quot;]
    preg = 0
    glucose = 0
    BP = 0
    skinThickness = 0
    insulin = 0
    bmi = 0
    diabetesPedigreeFunction = 0
    age = 0
    def __init__(self, p, g, BP, ST, I, BMI, DPF, age):
        self.preg = p
        self.glucose = g
        self.BP = BP
        self.skinThickness = ST
        self.insulin = I
        self.bmi = BMI
        self.diabetesPedigreeFunction = DPF
        self.age = age

    def preprocessing(self):
        global Y_train
        global Y_test
        #K-fold cross validation
        kf = KFold(n_splits = 9, shuffle = True, random_state = 19)

        global X_train, X_test, Y_train, Y_test
        for training_index, testing_index in kf.split(self.X):
            X_train, X_test = self.X.iloc[training_index], self.X.iloc[testing_index]
            Y_train, Y_test = self.Y.iloc[training_index], self.Y.iloc[testing_index]


        #Noramlization marginally better than Standardization
        scaler = MinMaxScaler()
        global x_train_s, x_test_s
        x_train_s = scaler.fit_transform(X_train)
        x_test_s = scaler.transform(X_test)

    def train(self):
        global model
        model = LogisticRegression(max_iter = 2000)
        model.fit(x_train_s,Y_train)
        y_pred = model.predict(x_test_s)
        return f&quot;{accuracy_score(Y_test, y_pred) * 100}%&quot;
    
        # TUNE HYPERPARAMETERS HERE
    
    def diabetes_pred(self):
        prob = model.predict_proba([[self.preg, self.glucose, self.BP, self.skinThickness, self.insulin, self.bmi, self.diabetesPedigreeFunction, self.age]])
        print(prob)
        if prob[0,1] &gt; 0.5:
            return &quot;Diabetes&quot;
        else:
            return &quot;No Diabetes&quot;
    
    #def decision_boundary_graph():
        #
    


d = diabetesLogReg(2,126,45,23,340,30,0.12,29)

d.preprocessing()
print(d.train())
print(d.diabetes_pred())
</code></pre>
<p>It is repetitively outputting:</p>
<pre><code>80.0%
[[0. 1.]]
Diabetes
</code></pre>
<p>It has been outputting the &quot;Diabetes&quot; outcome for all the predictions it has made. I'm new to machine learning but I know that I haven't tuned my hyperparameters. Does it have to do with the length of the dataset, is it too short? Or maybe something to do with my k fold cross validation?</p>
","2023-12-08 08:47:22","0","Question"
"77617073","77615883","","<p>There seems to be a <a href=""https://github.com/scikit-learn/scikit-learn/issues/26768"" rel=""nofollow noreferrer"">bug report</a> for this in Scikit-learn <code>1.3.0</code> (although it seems to have been <a href=""https://github.com/scikit-learn/scikit-learn/pull/26772"" rel=""nofollow noreferrer"">fixed</a> in the nightly builds). Try downgrading to version <code>1.2.2</code>:</p>
<pre><code>pip uninstall scikit-learn
pip install scikit-learn==1.2.2
</code></pre>
","2023-12-07 00:44:58","2","Answer"
"77616998","76321820","","<p>I managed to resolve this by simply adding this line before calling .fit()</p>
<pre><code>opt = BayesSearchCV(...)

np.int = int
opt.fit(...)
</code></pre>
<p>Hope this helps.</p>
","2023-12-07 00:12:39","12","Answer"
"77615883","","AttributeError: 'Flags' object has no attribute 'c_contiguous'","<p>I am following Hands On Machine Learning Book by Aurélien Géron and running in to the following error.</p>
<p>Code:</p>
<pre><code>y_train_large = (y_train.astype(&quot;int&quot;) &gt;= 7)
y_train_odd = (y_train.astype(&quot;int&quot;) % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]

#model
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)

y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)
</code></pre>
<p>The last line produces the following error:</p>
<pre><code>{
AttributeError: 'Flags' object has no attribute 'c_contiguous'&quot;
}
</code></pre>
<p>Since I am following the book, I expected this code to work. I have tried solutions from Google Bard and Claude AI chatbots but with no success.</p>
","2023-12-06 19:42:47","2","Question"
"77614126","77100654","","<p>I have this exact problem, but with a slightly different error message. However, I only got this message because I am using tensorflow 2.15 with cuDNN 8.9.4.</p>
<p>According to the Windows-native tab of the step-by-step pip-based <a href=""https://www.tensorflow.org/install/pip?authuser=2#windows-native_1"" rel=""nofollow noreferrer"">installation guide</a> on the tensorflow website, only <code>cudatoolkit=11.2</code> and <code>cudnn=8.1.0</code> are required for up to tensorflow 2.11. I have been running tensorflow 2.10 on Windows and 2.11 on Linux with these cuda and cuDNN versions without any problems for some time now. I've been having these PTX-related problems only with the recent versions of tensorflow demanding recent versions of cuda and cudnn. Maybe you can give it a try.</p>
","2023-12-06 14:51:28","0","Answer"
"77610686","","Why does the one-hot-encoding give worse accuracy in this case?","<p>I have two directories, <code>train_data_npy</code> and <code>valid_data_npy</code> where there are 3013 and 1506 <code>*.npy</code> files, respectively.</p>
<p>Each <code>*.npy</code> file has 11 columns of float types, of which the first eight columns are features and the last three columns are one-hot-encoded labels (characters) of three classes.</p>
<pre><code>----------------------------------------------------------------------
f1      f2      f3      f4   f5   f6   f7   f8          ---classes---
----------------------------------------------------------------------
0.0     0.0     0.0     1.0  1.0  1.0  1.0  1.0         0.0  0.0  1.0
6.559   9.22    0.0     1.0  1.0  1.0  1.0  1.0         0.0  0.0  1.0
5.512   6.891   10.589  0.0  0.0  0.0  0.0  1.0         0.0  0.0  1.0
7.082   8.71    7.227   0.0  0.0  0.0  0.0  0.0         0.0  0.0  1.0
6.352   9.883   12.492  0.0  0.0  0.0  0.0  0.0         0.0  0.0  1.0
6.711   10.422  13.44   0.0  0.0  0.0  0.0  1.0         0.0  0.0  1.0
7.12    9.283   12.723  0.0  0.0  0.0  0.0  0.0         0.0  0.0  1.0
6.408   9.277   12.542  0.0  0.0  0.0  0.0  0.0         0.0  0.0  1.0
6.608   9.686   12.793  0.0  0.0  0.0  0.0  0.0         0.0  0.0  1.0
6.723   8.602   12.168  0.0  0.0  0.0  0.0  0.0         0.0  0.0  1.0
... ... ... ... ...
</code></pre>
<p>Given the format of the data, I have written two scripts.</p>
<p><code>cnn_autokeras_by_chunk_with_ohe.py</code> uses OHE labels as they are, and <code>cnn_autokeras_by_chunk_without_ohe.py</code> converts OHE data into integers.</p>
<p>The first one achieves an accuracy of <code>0.40</code>, and the second one achieves an accuracy of <code>0.97</code>.</p>
<p><strong>Why does the one-hot-encoding give worse accuracy in this case?</strong></p>
<hr />
<p>The Python script's task is to load those <code>*.npy</code> files in chunks so that the memory is not overflowed while searching for the best model.</p>
<hr />
<pre><code># File: cnn_autokeras_by_chunk_with_ohe.py
import numpy as np
import tensorflow as tf
import autokeras as ak
import os

# Update these values to match your actual data
N_FEATURES = 8
N_CLASSES = 3  # Number of classes
BATCH_SIZE = 100

def get_data_generator(folder_path, batch_size, n_features, n_classes):
    &quot;&quot;&quot;Get a generator returning batches of data from .npy files in the specified folder.
    The shape of the features is (batch_size, n_features).
    The shape of the labels is (batch_size, n_classes).
    &quot;&quot;&quot;
    def data_generator():
        files = os.listdir(folder_path)
        npy_files = [f for f in files if f.endswith('.npy')]

        for npy_file in npy_files:
            data = np.load(os.path.join(folder_path, npy_file))
            x = data[:, :n_features]
            y = data[:, n_features:]

            for i in range(0, len(x), batch_size):
                yield x[i:i+batch_size], y[i:i+batch_size]

    return data_generator

train_data_folder = '/home/my_user_name/original_data/train_data_npy'
validation_data_folder = '/home/my_user_name/original_data/valid_data_npy'

train_dataset = tf.data.Dataset.from_generator(
    get_data_generator(train_data_folder, BATCH_SIZE, N_FEATURES, N_CLASSES),
    output_signature=(
        tf.TensorSpec(shape=(None, N_FEATURES), dtype=tf.float32),
        tf.TensorSpec(shape=(None, N_CLASSES), dtype=tf.float32)  # Labels are now 2D with one-hot encoding
    )
)

validation_dataset = tf.data.Dataset.from_generator(
    get_data_generator(validation_data_folder, BATCH_SIZE, N_FEATURES, N_CLASSES),
    output_signature=(
        tf.TensorSpec(shape=(None, N_FEATURES), dtype=tf.float32),
        tf.TensorSpec(shape=(None, N_CLASSES), dtype=tf.float32)  # Labels are now 2D with one-hot encoding
    )
)

# Initialize the structured data classifier.
clf = ak.StructuredDataClassifier(max_trials=10) # Set max_trials to any value you desire.

# Feed the tensorflow Dataset to the classifier.
clf.fit(train_dataset, epochs=100)

# Get the best hyperparameters
best_hps = clf.tuner.get_best_hyperparameters()[0]

# Print the best hyperparameters
print(best_hps)

# Export the best model
model = clf.export_model()

# Save the model in tf format
model.save(&quot;heca_v2_model_with_ohe&quot;, save_format='tf')  # Note the lack of .h5 extension

# Evaluate the best model with testing data.
print(clf.evaluate(validation_dataset))
</code></pre>
<pre><code># File: cnn_autokeras_by_chunk_without_ohe.py
import numpy as np
import tensorflow as tf
import os
import autokeras as ak

N_FEATURES = 8
N_CLASSES = 3  # Number of classes
BATCH_SIZE = 100

def get_data_generator(folder_path, batch_size, n_features):
    &quot;&quot;&quot;Get a generator returning batches of data from .npy files in the specified folder.

    The shape of the features is (batch_size, n_features).
    &quot;&quot;&quot;
    def data_generator():
        files = os.listdir(folder_path)
        npy_files = [f for f in files if f.endswith('.npy')]

        for npy_file in npy_files:
            data = np.load(os.path.join(folder_path, npy_file))
            x = data[:, :n_features]
            y = data[:, n_features:]
            y = np.argmax(y, axis=1)  # Convert one-hot-encoded labels back to integers

            for i in range(0, len(x), batch_size):
                yield x[i:i+batch_size], y[i:i+batch_size]

    return data_generator

train_data_folder = '/home/my_user_name/original_data/train_data_npy'
validation_data_folder = '/home/my_user_name/original_data/valid_data_npy'

train_dataset = tf.data.Dataset.from_generator(
    get_data_generator(train_data_folder, BATCH_SIZE, N_FEATURES),
    output_signature=(
        tf.TensorSpec(shape=(None, N_FEATURES), dtype=tf.float32),
        tf.TensorSpec(shape=(None,), dtype=tf.int32)  # Labels are now 1D integers
    )
)

validation_dataset = tf.data.Dataset.from_generator(
    get_data_generator(validation_data_folder, BATCH_SIZE, N_FEATURES),
    output_signature=(
        tf.TensorSpec(shape=(None, N_FEATURES), dtype=tf.float32),
        tf.TensorSpec(shape=(None,), dtype=tf.int32)  # Labels are now 1D integers
    )
)

# Initialize the structured data classifier.
clf = ak.StructuredDataClassifier(max_trials=10) # Set max_trials to any value you desire.

# Feed the tensorflow Dataset to the classifier.
clf.fit(train_dataset, epochs=100)

# Get the best hyperparameters
best_hps = clf.tuner.get_best_hyperparameters()[0]

# Print the best hyperparameters
print(best_hps)

# Export the best model
model = clf.export_model()

# Save the model in tf format
model.save(&quot;heca_v2_model_without_ohe&quot;, save_format='tf')  # Note the lack of .h5 extension

# Evaluate the best model with testing data.
print(clf.evaluate(validation_dataset))
</code></pre>
<hr />
<p><strong>EDIT:</strong></p>
<pre><code>    0 MSE C  0.000   0.000  0.000 1 1 1 1  1  0
    1 ASN C  7.042   9.118  0.000 1 1 1 1  1  0
    2 LEU H  5.781   5.488  7.470 0 0 0 0  1  0
    3 THR H  5.399   5.166  6.452 0 0 0 0  0  0
    4 GLU H  5.373   4.852  6.069 0 0 0 0  1  0
    5 LEU H  5.423   5.164  6.197 0 0 0 0  2  0
</code></pre>
<p>(1) - residue number for debug purpose only (NOT A FEATURE)<br />
(2) - residue type for debug purpose only (NOT A FEATURE)<br />
(3) - secondary structure (TRUE LABEL)<br />
(4) - r13<br />
(5) - r14<br />
(6) - r15<br />
(7) - neighbor count with 4A<br />
(8) - neighbor count with 4.5A<br />
(9) - neighbor count with 5A<br />
(10) - neighbor count with 6A<br />
(11) - neighbor count with 8A<br />
(12) - hydrogen bonds count</p>
","2023-12-06 05:12:08","1","Question"
"77605885","75814047","","<p>The Trainer class can auto detect if there are multiple GPUs. You just need to copy your code to Kaggle, and enable the accelerator(multiple GPUs or single GPU) from the <code>Notebook options</code>. And check if the training process can work well normally. Here is an example of mine, I have been tested Trainer with Multiple GPUs or Single GPU. The training process works well as normal. But the training time is not less than single GPU. Here is the notebook <a href=""https://www.kaggle.com/code/aisuko/text-classification-with-transformers/notebook?scriptVersionId=153710473"" rel=""nofollow noreferrer"">https://www.kaggle.com/code/aisuko/text-classification-with-transformers/notebook?scriptVersionId=153710473</a></p>
<p>If you are using native PyTorch with your customise training loop. Here is the document for distributed training <a href=""https://huggingface.co/docs/transformers/accelerate#distributed-training-with--accelerate"" rel=""nofollow noreferrer"">https://huggingface.co/docs/transformers/accelerate#distributed-training-with--accelerate</a></p>
","2023-12-05 11:38:29","0","Answer"
"77593565","75979420","","<p>Your custom LLM class is already a good start. To use MPS, you can try:</p>
<pre><code>pipeline.to(&quot;mps&quot;)
</code></pre>
<p>The declaration of pipeline would stay the same without the <code>device=0</code> parameter.</p>
","2023-12-03 08:43:51","0","Answer"
"77592472","77216743","","<p>I got the same error and looks like I managed to solve it.</p>
<p>Try running these:</p>
<pre><code>pip install keras==2.10.0
pip install tensorflow==2.10.0
pip install tensorflow-probability==0.18.0
</code></pre>
","2023-12-02 22:51:41","1","Answer"
"77575685","75664004","","<p>According to the <a href=""https://ERROR:%20%20could%20not%20open%20extension%20control%20file"" rel=""nofollow noreferrer"">pgvector docs</a> you can do install pgvector with Homebrew.</p>
<pre><code>brew install pgvector
</code></pre>
<p>Then connect to your postgres server:</p>
<pre><code>psql postgres
</code></pre>
<p>And create the extension:</p>
<pre><code>create extension vector;
</code></pre>
","2023-11-30 03:20:27","-1","Answer"
"77556207","77469134","","<p>You can programmatically do what you describe but I am not sure what would be the gain over using a simple Random Forest that internally does all this (feature subselection and fitting etc).</p>
<p>Here is an implementation of what you have described. I have used exactly the same base and stacking model as the ones you mentioned:</p>
<pre><code>import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from sklearn.base import clone
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer

def select_columns(X, columns):
    return X[columns]


X, y = make_classification(n_samples=1000, n_features=10, n_classes=3, n_informative=3)
df = pd.DataFrame(X, columns=list('ABCDEFGHIJ'))
X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=42)


feature_subsets = {
    0: ['A', 'B', 'C'],
    1: ['D', 'E', 'F', 'G'],
    2: ['G', 'H', 'I', 'J']
}

# Base model
base_dt_model = DecisionTreeClassifier(random_state=42)

#One-vs-Rest classifiers with feature subsets
classifiers = []
for class_label, features in feature_subsets.items():

    model = clone(base_dt_model)
    
    # select features, then apply the unique model
    pipeline = Pipeline([
        ('feature_selection', FunctionTransformer(select_columns, kw_args={'columns': features})),
        ('classifier', model)
    ])
    
    classifiers.append(('dt_class_' + str(class_label), pipeline))

# Logistic Regression as the metaclassifier
stack = StackingClassifier(estimators=classifiers, final_estimator=LogisticRegression())

stack.fit(X_train, y_train)

y_pred = stack.predict(X_test)
</code></pre>
","2023-11-27 10:34:49","-1","Answer"
"77555755","77469134","","<p>You need to use <code>make_pipeline</code> and <code>FunctionTransformer</code> (<a href=""https://stackoverflow.com/a/59743367/3304969"">check this answer</a>) on top of custom functions to filter the data by the respective columns and to manipulate the target values.</p>
<p>Here's a demo code</p>
<pre><code>from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelBinarizer
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import StackingClassifier
X, y = load_iris(return_X_y=True)

# Functions to filter the X on the important features
def select_dim1(X):
    red_X1 = X[:,:2]
    return red_X1

def select_dim2(X):
    red_X2 = X[:,2:]
    return red_X2

def select_dim3(X):
    red_X3 = X[:,3:]
    return red_X3

# functions to label binarise separate classes in y
def y_0(y):
    y[y == 0] = 1
    return y
def y_1(y):
    y[(y == 0)|(y == 2)] = 0
    return y
def y_2(y):
    y[y &lt; 2] = 0
    return y

# converting them to function transformer
from sklearn.preprocessing import FunctionTransformer
select_dim1_tr = FunctionTransformer(select_dim1)
select_dim2_tr = FunctionTransformer(select_dim2)
select_dim3_tr = FunctionTransformer(select_dim3)

select_y_0_tr = FunctionTransformer(y_0)
select_y_1_tr = FunctionTransformer(y_1)
select_y_2_tr = FunctionTransformer(y_2)

estimators = [
    ('dt1', make_pipeline(select_y_0_tr,select_dim1_tr, DecisionTreeClassifier(random_state=42))),
    ('dt2', make_pipeline(select_y_1_tr,select_dim2_tr, DecisionTreeClassifier(random_state=42))),
    ('dt3', make_pipeline(select_y_2_tr,select_dim3_tr, DecisionTreeClassifier(random_state=42)))
]

clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)

clf.fit(X_train, y_train).score(X_test, y_test)
</code></pre>
","2023-11-27 09:22:09","-2","Answer"
"77548712","77538082","","<p>Frankly, you have to think about internals of any pseudo RNG and compare them with what you want. RNG is pretty simple construct.</p>
<p>There is N-bit state as well as three functions:</p>
<ul>
<li>state seed2state(seed) # this converts seed to appropriate state</li>
<li>state nextstate(state) # advance state by one step</li>
<li>uint64 state2output(state) # extract &quot;randomness&quot; from state and use it for say [0...1) U01 rv.</li>
</ul>
<p>That is it, nothing more, nothing less. Everything else are helpful add-ons.</p>
<p>You are using PCG64 (XLS RR varian), which has 128bit state, and generate 64bit output.</p>
<p>First problem is how you populate state from seed. Potential problem here is that you use small value integer, and not enough bit chopping/mixing happens right away after one call to nextstate() and then to state2output(). Basically small integer seed will leave state of mostly zeros, which could affect you simulation.</p>
<p>Solution - run some 1K-10K calls to mixup your RNG. And then save PCG state as dictionary/JSON and start for here, you have your state well mixed. This is actually best approach - simulation code shall get state, not seed, as input. You control state outside of the simulation code.</p>
<pre><code>seed = np.uint64(13579754321)

pcg = np.random.PCG64(seed)
rng = np.random.Generator(pcg)

rng.bytes(64*10000) # mixing/warm-up

state = pcg.state # save/restore state
pcg.state = state
</code></pre>
<p>Second issue is to ensure independent sampling sequences for different simulations, such that there is no overlap, and no correlations.</p>
<p>Advice to make seeds large such there is no overlap works ONLY BY CHANCE. Why
leave to change things which could be perfectly controlled?</p>
<p>PCG64 has two feature which could greatly help - advance and jumps. Advance will move state like there are distance number of calls made. Internally it is pretty fast and works in log(distance) time.</p>
<p>You have to calculate or check once how many RNG calls you need for single simulation, make some reservations and just use it.</p>
<p>Some pseudocode</p>
<pre><code>def simulation(some parameters, state) -&gt; value:
    pcg = np.random.PCG64(1)
    pcg.state = state
    
    rng = np.random.Generator(pcg)
    ...
    return value
</code></pre>
<p>main function</p>
<pre><code>def main():

    nof_PCG_calls_per_simulation = 100000000

    pcg = np.random.PCG64(135797531)
    rng = np.random.Generator(pcg)

    rng.bytes(64*10000) # mixing/warm-up

    state = pcg.state

    N = 1000 # number of simulations to run

    s = 0.0
    for k in range(0, N):
        pcg = np.random.PCG64(1)
        pcg.state = state

        simstate = pcg.advance(N*nof_PCG_calls_per_simulation).state

        v = simulation(whatever, simstate)
        s += v

    return (s/N, N)
</code></pre>
<p>There is also good PCG method to consider - jumps. It is semantically very close to advance, it returns new PCG and states are different as if 2<sup>127</sup> numbers are generated.</p>
<p>This way you would be sure to have well-mixed PCG state as well as that different streams used in different simulation are REALLY not overlapping.</p>
","2023-11-25 16:44:46","1","Answer"
"77543096","77541935","","<p>After digging more into documentation and some R&amp;D on export from <a href=""https://docs.ultralytics.com/modes/export/#arguments"" rel=""nofollow noreferrer"">Ultralytics</a>, this is what I found:</p>
<p>The images in dataset for training model were in W:1280 H:720 size.
So during the train, I saw some warnings from Ultralytics</p>
<pre><code>WARNING ⚠️ updating to 'imgsz=1280'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'
</code></pre>
<p>To export for CoreML it's better to define the exact image sizes based on the ratio you are going to use for predictions. So I used this command on my Jupyter notebook running locally on my Macbook Pro M1:</p>
<pre><code>from ultralytics import YOLO

model_path=&quot;{Path to your .pt model}&quot;
model=YOLO(model_path)

model.export(format='coreml', nms=True, imgsz=[720,1280])
</code></pre>
<p><strong>And now the predictions are even faster and more precise even on iOS devices. (tested on iPhone 14 Pro max)</strong></p>
<p>Source images are in 4K resolution, so I used these settings to create the right <code>CVPixelBuffer</code> for passing to the <code>VNImageRequestHandler</code> for developing object detection applications in swift.</p>
<pre><code>let outputSettings: [String: Any] = [
         kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
         kCVPixelBufferWidthKey as String: 1280,
         kCVPixelBufferHeightKey as String: 720]
</code></pre>
","2023-11-24 12:20:59","0","Answer"
"77541978","","I do not understand the working of tfidfvectorizer of sckit-learn","<p>The formula I know to calculate tf-idf is TF * IDF where TF is the number of times the word occurs in a document D and IDF is Number Of Documents/ Number Of Documents which contains the word + 1.</p>
<p>This is my dataset.
<code>corpus = [ 'This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?', ]</code>
Now I calculated td-idf of the word 'document' in document 1, the output was 0.22.
But when I used sckit's tfidf vectorizer, the output was:
1.22314355
The vectorizer I used had the following parameters:
<code>vectorizer = TfidfVectorizer(norm=None) </code>
Please explain me why is the answer different.</p>
","2023-11-24 09:16:18","0","Question"
"77541935","","Inconsistent Object Detection Performance Between YOLOv8n PyTorch and Converted CoreML Model","<p>I'm experiencing a significant performance discrepancy between my YOLOv8n object detection model in its original PyTorch format (.pt) and after converting it to CoreML format for deployment on iOS devices. The original model, trained on a custom dataset, detects objects successfully in a given image. However, the converted CoreML model fails to detect any objects in the same image.
I tested in some other images. Although it detects objects in iOS and Mac devices, it does not perform the same as the original .pt detection.</p>
<p><strong>Details:</strong></p>
<p>Original Model: YOLOv8n, trained on a custom dataset using Ultralytics' implementation. in CoLap by using A100.</p>
<p>Conversion Tool:</p>
<pre><code>!pip install coremltools
</code></pre>
<pre><code>from ultralytics import YOLO
model_path=f&quot;{HOME}/runs/detect/train/weights/best.pt&quot;
model=YOLO(model_path)
model.export(format='coreml', nms=True)
</code></pre>
<p><strong>Questions:</strong></p>
<ol>
<li><p>Are there specific layers or operations in YOLOv8n that are known to have compatibility issues with CoreML?</p>
</li>
<li><p>What are the recommended steps for debugging such a discrepancy in object detection performance between the original and converted models?</p>
</li>
</ol>
<p>Any insights or suggestions for further troubleshooting?</p>
<p><a href=""https://i.sstatic.net/drwfV.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/drwfV.jpg"" alt=""enter image description here"" /></a>
<a href=""https://i.sstatic.net/EhU1M.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/EhU1M.jpg"" alt=""enter image description here"" /></a></p>
","2023-11-24 09:09:33","0","Question"
"77538119","77538082","","<p>The justification is in the <a href=""https://numpy.org/doc/stable/reference/random/index.html#random-quick-start"" rel=""nofollow noreferrer"">quick start page</a> which you linked:</p>
<blockquote>
<p>We recommend using very large, unique numbers to ensure that your seed is different from anyone else’s. This is good practice to ensure that your results are statistically independent from theirs unless you are intentionally trying to reproduce their result.</p>
</blockquote>
<p>In short, this is to avoid reproducing someone else's bias (if any) by generating the exact same dataset, since humans are more likely to pick short numbers by default (<code>0</code>, <code>11</code>, <code>42</code>) rather than very large ones.</p>
<p>In your use case this is probably not important.</p>
","2023-11-23 15:41:53","2","Answer"
"77538082","","Correctly seeding numpy random generator","<p>For my scientific experiments, I usually seed using:</p>
<p><code>rng = np.random.Generator(np.random.PCG64(seed))</code></p>
<p>which for the current numpy version is equivalent to</p>
<p><code>rng = np.random.Generator(np.random.default_rng(seed))</code></p>
<p>As I repeat my experiments <code>n</code> times and average their results, I usually set the <code>seed</code> to all the numbers between <code>0</code> and <code>n</code>.</p>
<p>However, reading the documentations <a href=""https://numpy.org/doc/stable/reference/random/index.html#random-quick-start"" rel=""nofollow noreferrer"">here</a> and <a href=""https://numpy.org/doc/stable/reference/random/bit_generators/index.html#seeding-and-entropy"" rel=""nofollow noreferrer"">here</a> it states that</p>
<blockquote>
<p>Seeds should be large positive integers.</p>
</blockquote>
<p>or</p>
<blockquote>
<p>We default to using a 128-bit integer using entropy gathered from the OS. This is a good amount of entropy to initialize all of the generators that we have in numpy. We do not recommend using small seeds below 32 bits for general use.</p>
</blockquote>
<p>However, in the second reference, it also states</p>
<blockquote>
<p>There will not be anything wrong with the results, per se; even a seed of 0 is perfectly fine thanks to the processing that SeedSequence does.</p>
</blockquote>
<p>This feels contradictory and I wonder, if small seeds are now totally fine to use, or one should move towards higher seeds. Especially, I wonder, (i) at which point (if any) would a large seed make a difference to a low seed and (ii) if one does scientific experiments (e.g. machine learning / algorithmic research) should one prefer higher to lower seeds or should it not make a difference?</p>
<p>PS: This question is highly related to <a href=""https://stackoverflow.com/questions/41336548/random-number-seed-in-numpy"">Random number seed in numpy</a> but concerns the now recommended Generator. Furthermore, the answer seems not in-depth enough as it does not include a discussion about high and low seeds.</p>
","2023-11-23 15:36:08","3","Question"
"77531795","77479005","","<p>This error happens when you may not have a pre-built package corresponding to CUDA or Pytorch or MMCV version.</p>
<p>In this situation, you can build <code>MMCV</code> from source by following the <a href=""https://mmcv.readthedocs.io/en/latest/get_started/build.html"" rel=""nofollow noreferrer"">MMCV build official guide</a>.</p>
","2023-11-22 16:49:12","0","Answer"
"77523318","77520936","","<p>Specifically for <code>tfds</code> datasets, you can get the number of total observations with <code>with_info=True</code> like you did.</p>
<pre><code>import tensorflow_datasets as tfds
import tensorflow as tf

(train, test), info = tfds.load(
    'mnist',
    split=['train', 'test'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True,
)

num_total_train_records = info.splits['train'].num_examples
num_total_test_records = info.splits['test'].num_examples
</code></pre>
<p>Then, to create the correct <code>steps_per_epoch</code>, you can use the floor division operator to get the correct number of batches:</p>
<pre><code>num_x_batches_per_epoch = num_total_train_records // batch_size
num_v_batches_per_epoch = num_total_test_records // batch_size 
</code></pre>
<p>Complete example:</p>
<pre><code>import tensorflow_datasets as tfds
import tensorflow as tf
(train, test), info = tfds.load(
    'mnist',
    split=['train', 'test'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True,
)
num_total_train_records = info.splits['train'].num_examples
num_total_test_records = info.splits['test'].num_examples

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10)
])
model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
)

num_epochs = 2
batch_size = 8

num_x_batches_per_epoch = num_total_train_records // batch_size
num_v_batches_per_epoch = num_total_test_records // batch_size 
x_generator = train.batch(batch_size).as_numpy_iterator()
v_generator = test.batch(batch_size).as_numpy_iterator()
model.fit(
    x=x_generator ,
    epochs=num_epochs,
    batch_size=batch_size,
    steps_per_epoch=num_x_batches_per_epoch,
    validation_data=v_generator,
    validation_steps=num_v_batches_per_epoch,
    validation_batch_size=batch_size
)
</code></pre>
","2023-11-21 13:44:53","0","Answer"
"77522033","77520936","","<p>First of all you are computing the steps wrong, you don't divide by the number of epochs at all just the data size to the batch size, because the steps are the number of fetched batches per each epoch:</p>
<pre><code>num_x_batches_per_epoch = int(np.floor(num_total_train_records / batch_size))
num_v_batches_per_epoch = int(np.floor(num_total_test_records / batch_size))
</code></pre>
<p>Second you are using a Tensorflow dataset objects</p>
<pre><code>(train, test), info = tfds.load 
</code></pre>
<p>so not a custom generator, so you don't specify the steps for training or validation.</p>
<p>Check this tutorial:
<a href=""https://www.tensorflow.org/datasets/keras_example"" rel=""nofollow noreferrer"">https://www.tensorflow.org/datasets/keras_example</a></p>
","2023-11-21 10:22:35","0","Answer"
"77520936","","tensorflow - tf.keras.Model.fit causes run out of data for validation data with validation_steps being set","<p>Trying to understand the <code>validation_steps</code> parameter of <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">tf.keras.Model.fit</a>.</p>
<blockquote>
<p>Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.</p>
</blockquote>
<p>For instance, <a href=""https://www.tensorflow.org/datasets/catalog/mnist"" rel=""nofollow noreferrer"">TFDS MNIST</a> dataset has <code>60,000</code> train and <code>10,000</code> test data records. Trying to consume all the records during <code>num_epochs=2</code> epochs with <code>batch_size=8</code> using generators as the data sources to the model.</p>
<pre><code>(train, test), info = tfds.load(
    'mnist',
    split=['train', 'test'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True,
)

x_generator = train.batch(batch_size).as_numpy_iterator()
v_generator = test.batch(batch_size).as_numpy_iterator()   # using 'test' for validation here
</code></pre>
<p>The training data can afford <code>3750=(60000 / batch_size=8 / epochs=2)</code> batches, and the test data can afford <code>625=(10000 / batch_size=8 / epochs=2)</code> batches.</p>
<pre><code>def f(image, label):
    return 1

num_total_train_records = len(list(        # 60000
    train.map(f)
))
num_total_test_records = len(list(         # 10000
    test.map(f)
))
print(num_total_train_records, num_total_test_records)
-----
60000 10000
</code></pre>
<pre><code>num_epochs = 2
batch_size = 8

num_x_batches_per_epoch = int(np.floor(num_total_train_records / batch_size / num_epochs))
num_v_batches_per_epoch = int(np.floor(num_total_test_records / batch_size / num_epochs)) 
print(num_x_batches_per_epoch, num_v_batches_per_epoch)
# ---
# show 3750 625
</code></pre>
<p>However, setting <code>tf.keras.Model.fit(validation_steps=625)</code> causes the error <code>Your input ran out of data... Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 625 batches)</code>.</p>
<pre><code>model.fit(
    x=x_generator ,
    epochs=num_epochs,
    batch_size=batch_size,    # not using batch_size arg makes no difference
    steps_per_epoch=num_x_batches_per_epoch,
    validation_data=v_generator,
    validation_steps=num_v_batches_per_epoch,
    validation_batch_size=batch_size
)
</code></pre>
<pre><code>Your input ran out of data; interrupting training. 
Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches 
(in this case, 625 batches). You may need to use the repeat() function when building your dataset.

2023-11-21 17:39:33.226528: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 17391114698345974101
2023-11-21 17:39:33.226580: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8226056677969075330
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 625 batches). You may need to use the repeat() function when building your dataset.
</code></pre>
<h2>Code</h2>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow import keras
import tensorflow_datasets as tfds


(train, test), info = tfds.load(
    'mnist',
    split=['train', 'test'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True,
)


def f(image, label):
    return 1

num_total_train_records = len(list(
    train.map(f)
))
num_total_test_records = len(list(
    test.map(f)
))
print(num_total_train_records, num_total_test_records)

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10)
])
model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
)

num_epochs = 2
batch_size = 8

num_x_batches_per_epoch = int(np.floor(num_total_train_records / batch_size / num_epochs))
num_v_batches_per_epoch = int(np.floor(num_total_test_records / batch_size / num_epochs)) 
print(num_x_batches_per_epoch, num_v_batches_per_epoch)
# ---
# will show 3750 625


x_generator = train.batch(batch_size).as_numpy_iterator()
v_generator = test.batch(batch_size).as_numpy_iterator()

model.fit(
    x=x_generator ,
    epochs=num_epochs,
    batch_size=batch_size,
    steps_per_epoch=num_x_batches_per_epoch,
    validation_data=v_generator,
    validation_steps=num_v_batches_per_epoch,
    validation_batch_size=batch_size
)
</code></pre>
<p>By minus 1, it works.</p>
<pre><code>num_v_batches_per_epoch = int(np.floor(num_total_test_records / batch_size / num_epochs)) -1  # Cuase ran out of data without -1
</code></pre>
<p>Please help understand this behavior. Also the document says <code>Only relevant if validation_data is provided and is a tf.data dataset.</code> but obviously it is not only for <code>tf.data.Dataset</code>.</p>
<h2>Environment</h2>
<pre><code>tensorflow 2.14.1
Python 3.10.12
Ubuntu 22.04 LTS
</code></pre>
","2023-11-21 07:14:37","0","Question"
"77511838","77467530","","<p>It looks like the <code>classifier_model.pkl</code> file does not exist in the <strong>current git branch</strong> from where your streamlit app <code>SpecLines_App</code> is being run.
Hence, you are getting the <code>FileNotFoundError</code>.</p>
<p>To solve this, there are at least two solutions. Choose which one works better for your needs:</p>
<ol>
<li><p>Include the <code>classifier_model.pkl</code> file in your <strong>current</strong> git branch.
Then <code>model = pd.read_pickle('classifier_model.pkl')</code> should work.</p>
</li>
<li><p>Download the <code>classifier_model.pkl</code> file at runtime <strong>if it does not exist</strong> (example code bellow):</p>
</li>
</ol>
<pre class=""lang-py prettyprint-override""><code>...
import requests
from pathlib import Path

def download_model():
    url = 'https://github.com/mblk3/MLM_Atomic_Spec_Lines/raw/02f6a04db06b459169ea0d19c347146ea1ad17d8/classifier_model.pkl'
    local_filename = url.split('/')[-1]
    response = requests.get(url)
    open(local_filename, 'wb').write(response.content)

def is_model_found(file):
    model_path = Path(file)
    found = model_path.is_file()
    if not found:
        st.write(f&quot;DEBUG: File `{model_path.absolute()}` not found. Let's download it! :arrow_down:&quot;)
        download_model()
    else:
        st.write(f&quot;DEBUG: File `{model_path.absolute()}` found! :sunglasses:&quot;)
...

model_filename = &quot;classifier_model.pkl&quot;
is_model_found(model_filename)
model = pd.read_pickle(model_filename)
</code></pre>
","2023-11-19 17:49:48","0","Answer"
"77506590","77490008","","<p>Today I faced the same issue while connecting MySQL with Python.(cannot import name 'TypeAlias' from 'typing_extensions' (/usr/lib/python3/dist-packages/typing_extensions.py))</p>
<p><strong>I solved this using:</strong></p>
<pre><code>pip install typing-extensions --upgrade
</code></pre>
<p>Give it a try!</p>
","2023-11-18 10:59:04","9","Answer"
"77506314","76866418","","<p>According to <a href=""https://stackoverflow.com/a/20101940/14872121"">this</a>:
You can solve the issue by running:</p>
<pre><code>pip uninstall tflearn
pip install git+https://github.com/MihaMarkic/tflearn.git@fix/is_sequence_missing
</code></pre>
","2023-11-18 09:26:51","3","Answer"
"77501953","77469097","","<p>One solution: <strong>Convert the pdf to images and feed it to the vision model</strong> as multi image inputs <a href=""https://platform.openai.com/docs/guides/vision"" rel=""noreferrer"">https://platform.openai.com/docs/guides/vision</a>.</p>
<blockquote>
<p>GPT-4 with vision is not a different model that does worse at text tasks because it has vision, it is simply GPT-4 with vision added</p>
</blockquote>
<p>Since its the same model with vision capabilities, this should be sufficient to do both text and image analysis.</p>
<p>You could also choose to extract images from pdf and feed those separately making a multi-model architecture. I have a preference for the first. Ideally experiments should be run to see what produces better results.</p>
<p><em>Text only + images only</em>   <strong>VS</strong>   <em>Images (containing both)</em></p>
<p>Pdf to image can be done in python locally as can separating img from pdf. It isn't a difficult task requiring support from someone like openAI.</p>
","2023-11-17 13:16:20","5","Answer"
"77490008","","cannot import name 'TypeAliasType' from 'typing_extensions' (/usr/local/lib/python3.10/dist-packages/typing_extensions.py)","<p>I using elevenlab api for voice cloning in google colab. Here is my code</p>
<pre><code>import elevenlabs

from elevenlabs import set_api_key

set_api_key(&quot;*****************&quot;)
</code></pre>
<p>It gives me this error:</p>
<blockquote>
<p>ImportError: cannot import name 'TypeAliasType' from 'typing_extensions' (/usr/local/lib/python3.10/dist-packages/typing_extensions.py</p>
</blockquote>
<p>I have changed the version of typing_extensions but it does not work for me.</p>
<p>I have changed the version of typing_extension as gpt suggest me to change the version of it. But it was still not working. when I install the new version of typing_extention. Then it gives me this error:</p>
<blockquote>
<p>ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
tensorflow-probability 0.22.0 requires typing-extensions&lt;4.6.0, but you have typing-extensions 4.8.0 which is incompatible.</p>
</blockquote>
<p>along with installation</p>
","2023-11-15 18:08:34","3","Question"
"77479005","","Not able to download mmcv 1.3.0 and build wheels","<p>When I try to install <code>mmcv-full==1.3.0</code>, it couldn't be downloaded and build the wheel (where I have updated to wheel already)</p>
<p><a href=""https://i.sstatic.net/dGOBV.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/dGOBV.png"" alt=""enter image description here"" /></a></p>
<p>error Could not build wheels for mmcv-full, which is required to install pyproject.toml-based projects
<a href=""https://i.sstatic.net/Z0bRh.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Z0bRh.png"" alt=""enter image description here"" /></a></p>
<p>But then when I try to use
<code>mim install mmcv-full</code></p>
<p>error message:</p>
<pre><code>RROR: Failed building wheel for mmcv-full
  Running setup.py clean for mmcv-full
Failed to build mmcv-full
ERROR: Could not build wheels for mmcv-full, which is required to install pyproject.toml-based projects
</code></pre>
<p>The latest version of <code>mmcv-full</code> could be downloaded, but as the repo I am trying to clone needs to use <code>mmcv version 1.3.0</code>.
I am using <code>Windows 11</code> and would like to know how should I download the version.</p>
","2023-11-14 08:00:38","1","Question"
"77477351","77217287","","<p>You can also run your documents through an OCR Processor, get the document objects from said processor and then edit the document objects as a Json. For example, for labeling a splitter processor values, I edited the <code>entities</code> key in the document object Json with the following values:</p>
<pre><code>{
    &quot;entities&quot;: []
        [{
            &quot;confidence&quot;: 1, 
            &quot;pageAnchor&quot;: {
                &quot;pageRefs&quot;: [{}]}, 
            &quot;type&quot;: &quot;&lt;document_type&gt;&quot;
        }, {
            &quot;confidence&quot;: 1, 
            &quot;pageAnchor&quot;: {
                &quot;pageRefs&quot;: [
                    {&quot;page&quot;: &quot;1&quot;}, 
                    {&quot;page&quot;: &quot;2&quot;}
                ]
            }, 
            &quot;type&quot;: &quot;&lt;document_type&gt;&quot;},
        {
            &quot;confidence&quot;: 1, 
            &quot;pageAnchor&quot;: {
                &quot;pageRefs&quot;: [{}]}, 
            &quot;type&quot;: &quot;&lt;document_type&gt;&quot;
        }, {
            &quot;confidence&quot;: 1, 
            &quot;pageAnchor&quot;: {
                &quot;pageRefs&quot;: [
                    {&quot;page&quot;: &quot;1&quot;}, 
                    {&quot;page&quot;: &quot;2&quot;}
                ]
            }, 
            &quot;type&quot;: &quot;&lt;document_type&gt;&quot;}], 
    &quot;pages&quot;: [...]
}
</code></pre>
","2023-11-13 23:11:49","0","Answer"
"77471059","75800779","","<p>Got similar issue for a regression problem using CNN. It works in Keras, but not in Torch. Followed other suggestions such as learning rate, batch size, normalization etc.</p>
<p>Turns out Torch is using Lecun initialization by default.
For relu, it is best to use Kaiming He initialization and it solved the problem for me.</p>
<pre><code>self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)
nn.init.kaiming_normal_(self.conv1.weight)
</code></pre>
<p>Also refer to this:
<a href=""https://adityassrana.github.io/blog/theory/2020/08/26/Weight-Init.html"" rel=""nofollow noreferrer"">https://adityassrana.github.io/blog/theory/2020/08/26/Weight-Init.html</a></p>
","2023-11-12 23:20:12","0","Answer"
"77469555","76661319","","<p><strong>This is an example of using LLM (In this example: codellama-13b-instruct.gguf) from local directory in SQL Chain in Langchain Library</strong></p>
<p>Reference Link : <a href=""https://python.langchain.com/docs/use_cases/qa_structured/sql"" rel=""nofollow noreferrer"">https://python.langchain.com/docs/use_cases/qa_structured/sql</a></p>
<pre><code># @author: prgarg007

from langchain.llms import LlamaCpp
from langchain.utilities import SQLDatabase
from langchain.chains import create_sql_query_chain
from langchain.callbacks.manager import CallbackManager
from langchain_experimental.sql import SQLDatabaseChain
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])
llm = LlamaCpp(
    model_path = &quot;codellama-13b-instruct.gguf&quot;,
    temperature = 0.0,
    n_ctx=10000,
    n_gpu_layers= 15, # Change this until this crash (This is for offloading to GPU)
    n_threads = 3,
    n_batch=512,
    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls
    callback_manager=callback_manager,
    verbose=True,
    repeat_penalty=1.8
)

db = SQLDatabase.from_uri(&quot;sqlite:///Chinook.db&quot;)

chain = create_sql_query_chain(llm, db)

response = chain.invoke({&quot;question&quot;: &quot;How many employees are there&quot;})
print(response)
       
db.run(response)

# Db Chain method

db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)
db_chain.run(&quot;How many employees are there?&quot;)
</code></pre>
","2023-11-12 15:34:14","0","Answer"
"77469134","","StackingClassifier with base-models trained on feature subsets","<p>I can best describe my goal using a synthetic dataset. Suppose I have the following:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression

X, y = make_classification(n_samples=1000, n_features=10, n_classes=3,
                             n_informative=3)

df = pd.DataFrame(X, columns=list('ABCDEFGHIJ'))

X_train, X_test, y_train, y_test = train_test_split(
    df, y, test_size=0.3, random_state=42)

X_train.head()
         A       B           C        D         E       F          G         H       I        J
541 -0.277848 1.022357 -0.950125 -2.100213  0.883638 0.821387  1.154613  0.075376  1.176242 -0.470087
440  1.089665 0.841446 -1.701004 -1.036256 -1.229357 0.345068  1.876470 -0.750067  0.080685 -1.318271
482  0.016010 0.025488 -1.189296 -1.052935 -0.623029 0.669521  1.518927  0.690019 -0.045486 -0.494186
422 -0.133358 -2.16219  1.170989 -0.942150  1.933444 -0.55118 -0.059908 -0.938672 -0.924097 -0.796185
778  0.901954 1.479360 -2.639176 -2.588845 -0.753915 -1.650621 2.727146  0.075260  1.330432 -0.941594
</code></pre>
<p>After conducting a feature importance analysis, the discovered that each of the 3-classes in the dataset can best be predicted using feature subset, as oppose to the whole. For example:</p>
<pre><code>class  | optimal predictors
-------+-------------------
   0   |  A, B, C
   1   |  D, E, F, G
   2   |  G, H, I, J
-------+-------------------
</code></pre>
<p>At this point, I would like to use 3 <code>one-ve-rest</code> classifiers to train sub-models, one for each class and using the class's best predictors (as the base models). And then a <code>StackingClassifier</code> for final prediction.</p>
<p>I have high-level understanding of the <code>StackingClassifier</code>, where different base models can be trained (e.g. <code>DT, SVC, KNN</code> etc) and a meta classifier using another model e.g. <code>Logistice Regression</code>.</p>
<p>In this case however, the base model is one <code>DT</code> classifier, only that each is to be trained using feature subset best for the class, as above.</p>
<p>Then finally make predictions on the <code>X_test</code>.</p>
<p>But I am not sure how this can be done. So I give the description of my work using pseudo data as above.</p>
<p>How to design this to train the base models, and a final prediction?</p>
","2023-11-12 13:36:50","1","Question"
"77469097","","How can I process a pdf using OpenAI's APIs (GPTs)?","<p>The web interface for ChatGPT has an easy pdf upload. <strong>Is there an API from openAI that can receive pdfs?</strong></p>
<p>I know there are 3rd party libraries that can read pdf but given there are images and other important information in a pdf, it might be better if a model like GPT 4 Turbo was fed the actual pdf directly.</p>
<p>I'll state my use case to add more context. I intent to do RAG. In the code below I handle the PDF and a prompt. Normally I'd append the text at the end of the prompt. I could still do that with a pdf if I extract its contents manually.</p>
<p>The following code is taken from here <a href=""https://platform.openai.com/docs/assistants/tools/code-interpreter"" rel=""noreferrer"">https://platform.openai.com/docs/assistants/tools/code-interpreter</a>. Is this how I'm supposed to do it?</p>
<pre class=""lang-py prettyprint-override""><code># Upload a file with an &quot;assistants&quot; purpose
file = client.files.create(
  file=open(&quot;example.pdf&quot;, &quot;rb&quot;),
  purpose='assistants'
)

# Create an assistant using the file ID
assistant = client.beta.assistants.create(
  instructions=&quot;You are a personal math tutor. When asked a math question, write and run code to answer the question.&quot;,
  model=&quot;gpt-4-1106-preview&quot;,
  tools=[{&quot;type&quot;: &quot;code_interpreter&quot;}],
  file_ids=[file.id]
)
</code></pre>
<p>There is an upload endpoint as well, but it seems the intent of those endpoints are for fine-tuning and assistants. I think the RAG use case is a normal one and not necessarily related to assistants.</p>
","2023-11-12 13:25:44","33","Question"
"77467603","77467530","","<p>You are attempting to open a relative pathname, so
<a href=""https://en.wikipedia.org/wiki/Working_directory"" rel=""nofollow noreferrer"">CWD</a>
will matter. You can learn what it is using:</p>
<pre><code>import os

print(os.getcwd())
</code></pre>
<p>Consider doing a <code>cd</code> to a new directory before running this program.</p>
<hr />
<p>Opening an absolute pathname may be preferrable.</p>
<p>This should obtain the location of your git repository:</p>
<pre><code>from pathlib import Path
...
repo_top = Path(__file__ + &quot;/..&quot;).resolve()
print(repo_top)
model = pd.read_pickle(repo_top / 'classifier_model.pkl')
</code></pre>
","2023-11-12 03:09:24","1","Answer"
"77467530","","How do I to read a github file with python in the same repository?","<p>I keep getting a FileNotFoundError when I try to open a file in the same repository with my code. I want to use 'classifier_model.pkl' in 'SpecLines_App'</p>
<pre><code>import streamlit as st
import numpy as np
import pickle
import pandas as pd

#https://github.com/mblk3/MLM_Atomic_Spec_Lines/blob/02f6a04db06b459169ea0d19c347146ea1ad17d8/classifier_model.pkl
#joblibFile = open('code_/classifier_model.pkl', 'rb')
#joblibFile = open(url, 'rb')
#model = pickle.load(joblibFile)

model = pd.read_pickle(r'classifier_model.pkl')
</code></pre>
<p>^This is what I've tried, and I'm not sure why it doesn't work.</p>
<p>How could I open this?</p>
<p>streamlit: classify-atomic-spec-lines.streamlit.app</p>
<p>github: github.com/mblk3/MLM_Atomic_Spec_Lines</p>
","2023-11-12 02:17:40","1","Question"
"77463286","77440001","","<p>@lahbton and @Leftyx,</p>
<p>I've managed to get your example to work, but I've just turned it into a console.
The problem came from the version that the &quot;libtorch-cpu-win-x64&quot; or whatever you were using. Microsoft.ML 3.0.0-preview.23511.1 and Microsoft.ML.TorchSharp 0.21.0-preview.23511.1 use the version &quot;libtorch-cpu-win-x64&quot; or other 1.13.0.1.</p>
<p>test/Microsoft.ML.Tests/Microsoft.ML.Tests.csproj</p>
<pre><code>  &lt;ItemGroup Condition=&quot;'$(TargetArchitecture)' == 'x64'&quot;&gt;
    &lt;PackageReference Include=&quot;libtorch-cpu-win-x64&quot; Version=&quot;$(LibTorchVersion)&quot; Condition=&quot;$([MSBuild]::IsOSPlatform('Windows')) AND '$(TargetArchitecture)' == 'x64'&quot; /&gt;
      &lt;!-- &lt;PackageReference Include=&quot;TorchSharp-cuda-windows&quot; Version=&quot;0.99.5&quot; Condition=&quot;$([MSBuild]::IsOSPlatform('Windows'))&quot; /&gt;   --&gt;
    &lt;PackageReference Include=&quot;libtorch-cpu-linux-x64&quot; Version=&quot;$(LibTorchVersion)&quot; Condition=&quot;$([MSBuild]::IsOSPlatform('Linux')) AND '$(TargetArchitecture)' == 'x64'&quot; /&gt;
    &lt;PackageReference Include=&quot;libtorch-cpu-osx-x64&quot; Version=&quot;$(LibTorchVersion)&quot; Condition=&quot;$([MSBuild]::IsOSPlatform('OSX')) AND '$(TargetArchitecture)' == 'x64'&quot; /&gt;
  &lt;/ItemGroup&gt;
</code></pre>
<p>eng/Versions.props</p>
<pre><code>&lt;LibTorchVersion&gt;1.13.0.1&lt;/LibTorchVersion&gt;
</code></pre>
<p>Here is my code :
Program.cs</p>
<pre><code>using Microsoft.ML;
using Microsoft.ML.Data;
using Microsoft.ML.TorchSharp;

public class Program
{
    // Main method
    public static void Main(string[] args)
    {
        try
        {
            var context = new MLContext();
            context.FallbackToCpu = true;
            context.GpuDeviceId = null;

            var labels = context.Data.LoadFromEnumerable(
            new[] {
                new Label { Key = &quot;PERSON&quot; },
                new Label { Key = &quot;CITY&quot; },
                new Label { Key = &quot;COUNTRY&quot;  }
            });

            var dataView = context.Data.LoadFromEnumerable(
                new List&lt;TestSingleSentenceData&gt;(new TestSingleSentenceData[] {
                    new TestSingleSentenceData()
                    {   // Testing longer than 512 words.
                        Sentence = &quot;Alice and Bob live in the USA&quot;,
                        Label = new string[]{&quot;PERSON&quot;, &quot;0&quot;, &quot;PERSON&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;COUNTRY&quot;}
                    },
                     new TestSingleSentenceData()
                     {
                        Sentence = &quot;Alice and Bob live in the USA&quot;,
                        Label = new string[]{&quot;PERSON&quot;, &quot;0&quot;, &quot;PERSON&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;COUNTRY&quot;}
                     },
                }));
            var chain = new EstimatorChain&lt;ITransformer&gt;();
            var estimator = chain.Append(context.Transforms.Conversion.MapValueToKey(&quot;Label&quot;, keyData: labels))
               .Append(context.MulticlassClassification.Trainers.NameEntityRecognition(outputColumnName: &quot;outputColumn&quot;))
               .Append(context.Transforms.Conversion.MapKeyToValue(&quot;outputColumn&quot;));

            var transformer = estimator.Fit(dataView);
            transformer.Dispose();

            Console.WriteLine(&quot;Success!&quot;);
        }
        catch (Exception ex)
        {
            Console.WriteLine($&quot;Error: {ex.Message}&quot;);
        }
    }

    private class Label
    {
        public string Key { get; set; }
    }

    private class TestSingleSentenceData
    {
        public string Sentence;
        public string[] Label;
    }
}
</code></pre>
<p>ConsoleApp1.csproj</p>
<pre><code>&lt;Project Sdk=&quot;Microsoft.NET.Sdk&quot;&gt;

  &lt;PropertyGroup&gt;
    &lt;OutputType&gt;Exe&lt;/OutputType&gt;
    &lt;TargetFramework&gt;net7.0&lt;/TargetFramework&gt;
    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;
    &lt;Nullable&gt;enable&lt;/Nullable&gt;
  &lt;/PropertyGroup&gt;

  &lt;ItemGroup&gt;
      &lt;PackageReference Include=&quot;libtorch-cpu-win-x64&quot; Version=&quot;1.13.0.1&quot; /&gt;
      &lt;PackageReference Include=&quot;Microsoft.ML&quot; Version=&quot;3.0.0-preview.23511.1&quot; /&gt;
      &lt;PackageReference Include=&quot;Microsoft.ML.TorchSharp&quot; Version=&quot;0.21.0-preview.23511.1&quot; /&gt;
  &lt;/ItemGroup&gt;

&lt;/Project&gt;

</code></pre>
<p><a href=""https://github.com/dotnet/machinelearning/issues/630#issuecomment-1806550435"" rel=""nofollow noreferrer"">https://github.com/dotnet/machinelearning/issues/630#issuecomment-1806550435</a></p>
","2023-11-10 23:18:35","1","Answer"
"77462619","77440001","","<p>You will only need to reference 2 packages for that experiment</p>
<pre><code>&lt;ItemGroup&gt;
   &lt;PackageReference Include=&quot;Microsoft.ML.TorchSharp&quot; Version=&quot;0.21.0-preview.23511.1&quot; /&gt;
   &lt;PackageReference Include=&quot;libtorch-cpu-&lt;your-platform&gt;&quot; Version=&quot;2.1.0.1&quot; /&gt;
&lt;/ItemGroup&gt;
</code></pre>
<p>As <code>Microsoft.ML.TorchSharp</code> contains all the references you will need:</p>
<p><a href=""https://i.sstatic.net/SONMT.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/SONMT.png"" alt=""dependencies"" /></a></p>
<p>Now the bad news.<br />
At runtime you will get a bunch of errors related to missing files or dlls. I spent a good amount of time trying to figure out what I was missing but, I guess, it is just related to the versions of some libraries.</p>
<p>At the end I cloned the whole <a href=""https://github.com/dotnet/machinelearning"" rel=""nofollow noreferrer"">repo</a> and compiled for my platform (Win-x64) and tried to find the files with different sizes (some don't have a version so I the size was the oonly option) and it boils down to 7 libs:</p>
<p><a href=""https://i.sstatic.net/zigQr.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/zigQr.png"" alt=""enter image description here"" /></a></p>
<p>Those brought in by the compilation are all there ... just not the ones the ML.NET expects:</p>
<p><a href=""https://i.sstatic.net/KXkWZ.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/KXkWZ.png"" alt=""library brought in by the compiler"" /></a></p>
<p>I replaced the dlls with the ones from the ML.NET repo, copied them in the folder <code>\bin\Debug\net7.0\runtimes\win-x64\native</code> and everything works fine:</p>
<p><a href=""https://i.sstatic.net/z7BUW.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/z7BUW.png"" alt=""enter image description here"" /></a></p>
<p><strike>Maybe there is a smarter solution but I couldn't find any.</strike></p>
<p><strong>UPDATE:</strong></p>
<p>As <a href=""https://github.com/anrouxel"" rel=""nofollow noreferrer"">anrouxel</a> suggested on <a href=""https://github.com/dotnet/machinelearning/issues/630#issuecomment-1806602937"" rel=""nofollow noreferrer"">Github</a> the best way is to use <code>libtorch-cpu</code> version <code>1.13.0.1</code>:</p>
<p><a href=""https://i.sstatic.net/KkuFI.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/KkuFI.png"" alt=""enter image description here"" /></a></p>
","2023-11-10 20:07:28","1","Answer"
"77460848","77444565","","<p><code>LogisticRegression</code> would be more suited to this classification problem than <code>LinearRegression</code>, so it's worth a try if you haven't already.</p>
<p>The ROC metric summarises both recall and false positives. An ideal ROC metric of 1.0 would correspond to a scenario where you achieve both perfect recall and no false positives. <code>sklearn</code> has some weighted variants of the <a href=""https://scikit-learn.org/stable/modules/model_evaluation.html"" rel=""nofollow noreferrer"">ROC metric</a>. This provides a way of <em>scoring</em> a model after it has been trained.</p>
<p>Note that you can't use this type of metric to directly <em>optimise</em> the model in <code>sklearn</code> - you'd need to switch to PyTorch or similar and use a custom loss function.</p>
","2023-11-10 14:47:43","0","Answer"
"77450322","","I cannot import name 'TypeAliasType' from 'typing_extensions'","<p>I am new to Python and found the following error like that. I would really appreciate your comments. Thanks
<a href=""https://i.sstatic.net/Kx9Fk.png"" rel=""noreferrer"">I try to import Gradio library as gr</a></p>
<p>I've tried several existing suggestions, but the results are in vain. I don't know what to do</p>
","2023-11-09 03:38:10","5","Question"
"77444872","77440929","","<p>You can run Python code from a Java application using the subprocess module
refer this <a href=""https://towardsdev.com/executing-a-python-script-from-a-java-file-and-vise-versa-ea73dda0026e"" rel=""nofollow noreferrer"">blog about python and java usage</a></p>
","2023-11-08 10:48:53","0","Answer"
"77444565","","Optimize metrics for Fraud Detection Imbalanced Data","<p>I would need your help to improve my model performance. As mostly happens for fraud detection, I have an imbalanced dataset (0.1/0.9). I would like to optimize the recall for my target 1 and 0, because in one case I want to avoid fraud detection, on the other hand I want to limit the cost of targeting non-fraudulent clients as fraudulent because the 5% of the incorrect classified would decrease my revenue by €3K each (while targeting correct fraudulent would make me save 1k of loss for each customer detected).</p>
<p>First question I have is: what metrics would you consider based on this problem? I am more focused on recall, but I would read your opinions.</p>
<p>Second question: How can I improve my model performance?</p>
<p>So far, the best results I got without lowering the treshold is:</p>
<p>Accuracy: 0.89
Confusion Matrix:
[[3153  279]
[ 145  297]]</p>
<p>Classification Report:
precision    recall  f1-score   support</p>
<pre><code>       0       0.96      0.92      0.94      3432
       1       0.52      0.67      0.58       442

accuracy                           0.89      3874
</code></pre>
<p>while if I lower the treshold to increase the recall of target 1:</p>
<p>Accuracy: 0.61
Confusion Matrix:
[[1959 1473]
[  42  400]]</p>
<p>Classification Report:
precision    recall  f1-score   support</p>
<pre><code>       0       0.98      0.57      0.72      3432
       1       0.21      0.90      0.35       442

accuracy                           0.61      3874
</code></pre>
<p>I tried several models:
Linear Regression, XGBoost, Random forest and SVM</p>
<p>Moreover, even over/undesampling techniques (only on the train set)
RandomOverSampling, RandomUnderSampling, SMOTE</p>
<p>Do you have any other advice?</p>
","2023-11-08 10:08:43","0","Question"
"77442042","77413586","","<p>I just needed to install tensorflow to my environment.</p>
","2023-11-07 23:30:07","0","Answer"
"77441746","77440929","","<p>you can convert model to ONNX runtime format  and then run it through Apache OpenNLP, you can read <a href=""https://blogsarchive.apache.org/opennlp/entry/accelerate-hugging-face-transformer-models"" rel=""nofollow noreferrer"">this tutorial</a> and this <a href=""https://opennlp.apache.org/docs/2.3.0/manual/opennlp.html#intro.models.onnx"" rel=""nofollow noreferrer"">documentation</a></p>
<p>the class <code>SentenceFeatureGeneratorFactory</code> might be helpful</p>
","2023-11-07 22:04:18","3","Answer"
"77440929","","Any alternative of Python Transfomer Package in java?","<p>I am loading a Python model from Hugging Face.</p>
<p>A pretrained model used to generate answers of questions from a given context.</p>
<p>Model Description:
<a href=""https://huggingface.co/deepset/roberta-base-squad2"" rel=""nofollow noreferrer"">model link page</a></p>
<p><strong>Model loading sample:</strong></p>
<pre><code>from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline

model_name = &quot;deepset/roberta-base-squad2&quot;

# a) Get predictions
nlp = pipeline('question-answering, model=model_name, tokenizer=model_name)
   QA_input = {
      'question': 'Why is model conversion important?',
      'context': 'The option to convert models between FARM and transformers'
}
 res = nlp(QA_input)
</code></pre>
<p>It is using a Python transformer package to load it. Now I can create its API in Python easily, but I want to create an API of this model in Java, where its parameters ('Question' &amp; 'Context') will be given by the user itself.</p>
<p>Now I want to know, how will I load this model in Java? Is there any transformer dependency in Java?</p>
","2023-11-07 19:24:39","1","Question"
"77440333","76247802","","<p>You <em>should</em> be using safetensors when relevant - they're more secure and efficient than the alternatives (pt and bin). First confirm you have <code>safetensors</code> installed:</p>
<pre class=""lang-py prettyprint-override""><code>import importlib.util
print(importlib.util.find_spec(&quot;safetensors&quot;) is not None)
</code></pre>
<p>Otherwise install it:</p>
<pre class=""lang-bash prettyprint-override""><code>!pip install safetensors
</code></pre>
<p>If errors persist, try:</p>
<pre class=""lang-py prettyprint-override""><code>!pip install 'transformers[torch]'
</code></pre>
<p>Things should work after resolving any dependency issues and restarting your kernel to reload modules. For reference, I was able to load a fine-tuned <code>distilroberta-base</code> and its corresponding <code>model.safetensors</code> file with the following:</p>
<pre class=""lang-bash prettyprint-override""><code>!pip install accelerate==0.24.1
!pip install huggingface-hub==0.17.3 
!pip install safetensors==0.4.0 
!pip install tokenizers==0.14.1 
!pip install transformers==4.35.0
</code></pre>
<pre class=""lang-py prettyprint-override""><code>model = AutoModelForMaskedLM.from_pretrained(&lt;model_path&gt;)
tokenizer = AutoTokenizer.from_pretrained(&lt;tokenizer_path&gt;)
</code></pre>
","2023-11-07 17:38:12","1","Answer"
"77440001","","CUDA issue with NER (Named Entity Recognition) for ML predictions","<p>I'm attempting to use <strong>NamedEntityRecognition (NER)</strong>(<a href=""https://github.com/dotnet/machinelearning/issues/630"" rel=""nofollow noreferrer"">https://github.com/dotnet/machinelearning/issues/630</a>) to predict categories for words/phrases within a large body of text.</p>
<p>Currently using 3 Nuget packages to try get this working:</p>
<p><em>Microsoft.ML (3.0.0-preview.23511.1)</em></p>
<p><em>Microsoft.ML.TorchSharp (0.21.0-preview.23511.1)</em></p>
<p><em>Torchsharp-cpu (0.101.1)</em></p>
<p>At the point of training the model [estimator.Fit(dataView)], I get the following error:</p>
<p><strong>Field not found: 'TorchSharp.torch.CUDA'.</strong></p>
<p>I may have misunderstood something here, but I should be processing with CPU from the Torchsharp-cpu package and I'm not sure where the CUDA reference is coming from. This also appears to be a package reference rather than a field?</p>
<pre><code>using Microsoft.ML;
using Microsoft.ML.Data;
using Microsoft.ML.TorchSharp;
using System;
using System.Collections.Generic;
using System.Windows.Forms;

namespace NerTester
{
    public partial class Form1 : Form
    {
        public Form1()
        {
            InitializeComponent();
        }

    private class TestSingleSentenceData
    {
        public string Sentence;
        public string[] Label;
    }

    private class Label
    {
        public string Key { get; set; }
    }

    private void startButton_Click(object sender, EventArgs e)
        {
        try
        {
                var context = new MLContext();
                context.FallbackToCpu = true;
                context.GpuDeviceId = null;

                var labels = context.Data.LoadFromEnumerable(
                new[] {
                new Label { Key = &quot;PERSON&quot; },
                new Label { Key = &quot;CITY&quot; },
                new Label { Key = &quot;COUNTRY&quot;  }
                });

                var dataView = context.Data.LoadFromEnumerable(
                    new List&lt;TestSingleSentenceData&gt;(new TestSingleSentenceData[] {
                    new TestSingleSentenceData()
                    {   // Testing longer than 512 words.
                        Sentence = &quot;Alice and Bob live in the USA&quot;,
                        Label = new string[]{&quot;PERSON&quot;, &quot;0&quot;, &quot;PERSON&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;COUNTRY&quot;}
                    },
                     new TestSingleSentenceData()
                     {
                        Sentence = &quot;Alice and Bob live in the USA&quot;,
                        Label = new string[]{&quot;PERSON&quot;, &quot;0&quot;, &quot;PERSON&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;COUNTRY&quot;}
                     },
                    }));
                var chain = new EstimatorChain&lt;ITransformer&gt;();
                var estimator = chain.Append(context.Transforms.Conversion.MapValueToKey(&quot;Label&quot;, keyData: labels))
                   .Append(context.MulticlassClassification.Trainers.NameEntityRecognition(outputColumnName: &quot;outputColumn&quot;))
                   .Append(context.Transforms.Conversion.MapKeyToValue(&quot;outputColumn&quot;));

                var transformer = estimator.Fit(dataView);
                transformer.Dispose();
                
                MessageBox.Show(&quot;Success!&quot;);
            }
        catch (Exception ex)
            {
        MessageBox.Show($&quot;Error: {ex.Message}&quot;);
            }
    }
    }
}
</code></pre>
<p>Application is running on x64 and the documentation for NER appears to be limited.</p>
<p>Any help would be greatly appreciated.</p>
<p>Tried changing the Nuget packages I'm referencing, including the use if libtorch packages.</p>
<p>Attempted running the application in x86 and x64 configuration.</p>
<p>Added code to try force CPU usage rather than GPU (CUDA).</p>
","2023-11-07 16:42:42","1","Question"
"77438998","77438653","","<p>The problem you are looking into is called <a href=""https://en.wikipedia.org/wiki/Named-entity_recognition"" rel=""nofollow noreferrer"">named entity recognition</a> and there are both traditional NLP models and LLMs trained for this type of task.</p>
<p>For example, for the former this is commonly done in <a href=""https://spacy.io/"" rel=""nofollow noreferrer"">spaCy</a>:</p>
<pre class=""lang-py prettyprint-override""><code>text = '''
Peter lives in a house he build himself, he is a great carpenter. 
Linda likes to run marathons when she is not busy running her own business. 
John is 40 and lives from fishing
'''

import spacy

nlp = spacy.load(&quot;en_core_web_sm&quot;)
ner = nlp(text)

for word in ner.ents:
    print(word.text,word.label_)
</code></pre>
<pre><code>Peter PERSON
Linda PERSON
John PERSON
40 DATE
</code></pre>
<p>However, as you can see, these models are not perfect, and also have a specific sets of entity types they are trained to recognize by default. If you want to recognize your own custom entity types, you would need to find the right pre-trained model for this use case or <a href=""https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7"" rel=""nofollow noreferrer"">train your own</a>.</p>
","2023-11-07 14:23:37","2","Answer"
"77438653","","extracting names and associated labels from text with language model","<p>I am trying to extract information from scientific literature on microalgae and i need to be able to scan a text for various names and find their corresponding category.</p>
<p>As an simple example, say I have 3 names (Peter, John, Linda) and I want to find their job title from this list of titles (Carpenter, Fisherman, Ninja) and this is the text:
&quot;Peter lives in a house he build himself, he is a great carpenter. Linda likes to run marathons when she is not busy running her own business. John is 40 and lives from fishing&quot;</p>
<p>I would like a response like so (Peter = carpenter, John = Fisherman, Linda = NA).
Currently I am trying bert but can only find a way to extract a single label from a text and I cannot find a way to contextualise it to the person in question.</p>
<p>Does anyone have suggestion on how to go about this?</p>
<p>(UPDATE) A more specific example would be using this text:
&quot;Nannochloropsis gaditana is in the genus of Nannochloropsis comprising six known species all of which are unicellur. Unlike these species all species in the genus Arthrospira are filamentous such as Arthrospira platensis.&quot;</p>
<p>Here i need to extract:  Nannochlorpsis gaditana = unicellur, Arthrospira platensis = filamentous.</p>
","2023-11-07 13:34:55","1","Question"
"77433933","77433100","","<p>this is happening because in the second code snippet, you loop over the input sequence by adding a new token at each iteration:</p>
<pre><code>i=0: input_ids[:, :i+1] := tensor([[25082]], device='cuda:0')
i=1: input_ids[:, :i+1] := tensor([[25082, 33511]], device='cuda:0')
i=2: input_ids[:, :i+1] := tensor([[25082, 33511,     0]], device='cuda:0')
</code></pre>
<p>Then, the computation of the perplexity in the last iteration of the loop is essentially identical to doing this:</p>
<pre><code>outputs = model(input_ids.to(device), labels=target_ids)
ppl = torch.exp(outputs.loss)
</code></pre>
<p>Here's how you can compute the perplexity and per-token perplexity (see <a href=""https://github.com/huggingface/transformers/blob/v4.35.0/src/transformers/models/gpt2/modeling_gpt2.py#L1103"" rel=""nofollow noreferrer"">https://github.com/huggingface/transformers/blob/v4.35.0/src/transformers/models/gpt2/modeling_gpt2.py#L1103</a>):</p>
<pre><code>import torch.nn.functional as F
[...]
sent = 'Happy Birthday!'
input_ids = tokenizer(sent, return_tensors='pt')['input_ids'].to(device)
labels = input_ids.clone()

output = model(input_ids, labels=labels)
logits = output.logits
shift_logits = logits[..., :-1, :].contiguous()
shift_labels = labels[..., 1:].contiguous()
loss = F.cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1), reduction='none')
per_token_perplexity = torch.exp(loss)
average_perplexity = torch.exp(torch.mean(loss))
print(per_token_perplexity)
print(average_perplexity)
</code></pre>
<p>The output:</p>
<pre><code>tensor([5.4192e+04, 4.1502e+01], device='cuda:0', grad_fn=&lt;ExpBackward0&gt;)
tensor(1499.6934, device='cuda:0', grad_fn=&lt;ExpBackward0&gt;)
</code></pre>
","2023-11-06 19:59:29","2","Answer"
"77433100","","How to get perplexity per token rather than average perplexity?","<p>I can get the perplexity of a whole sentence from <a href=""https://huggingface.co/docs/transformers/perplexity"" rel=""nofollow noreferrer"">here</a>:</p>
<pre><code>device = &quot;cuda&quot;
from transformers import GPT2LMHeadModel, GPT2TokenizerFast

device = &quot;cuda&quot;
model_id = &quot;gpt2&quot;
model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
tokenizer = GPT2TokenizerFast.from_pretrained(model_id)
sent = 'Happy Birthday!'
input_ids = tokenizer(sent, return_tensors='pt')['input_ids']
target_ids = input_ids.clone()
outputs = model(input_ids.to(device), labels=target_ids)
ppl = torch.exp(outputs.loss)
print(ppl)
&gt;&gt;&gt;tensor(1499.6934, device='cuda:0', grad_fn=&lt;ExpBackward0&gt;)
</code></pre>
<p>But how can I get the perplexity value for each token, instead of of the average perplexity of the entire sequence of tokens? The input sentence in this example, <code>'Happy Birthday!'</code> is composed of 3 tokens. Based on the formula for perplexity:
<a href=""https://i.sstatic.net/pCsqc.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/pCsqc.png"" alt=""enter image description here"" /></a></p>
<p>This should result in 3 values: log probability of the first token, log probability of the second token given the first, and the log probability of the third token given the first 2. Each should be exponentiated to get the perplexity value of each token.</p>
<p>I currently have the following:</p>
<pre><code>import torch
from transformers import GPT2LMHeadModel, GPT2TokenizerFast

device = &quot;cuda&quot;
model_id = &quot;gpt2&quot;
model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
tokenizer = GPT2TokenizerFast.from_pretrained(model_id)

sent = 'Happy Birthday!'
input_ids = tokenizer(sent, return_tensors='pt')['input_ids'].to(device)
target_ids = input_ids.clone()

# Initialize an empty list to store perplexities for each token
perplexities = []

# Calculate perplexity for each token
for i in range(input_ids.shape[1]):
    output = model(input_ids[:, :i+1], labels=target_ids[:, :i+1])
    log_prob = output.loss.item()
    perplexity = torch.exp(torch.tensor(log_prob))
    perplexities.append(perplexity.item())

# Perplexities is now a list containing the perplexity values for each token
for i, token in enumerate([tokenizer.decode(i) for i in input_ids[0]]):
    print(f&quot;Token: {token}, Perplexity: {perplexities[i]}&quot;)
    &gt;&gt;&gt; Token: Happy, Perplexity: nan
Token:  Birthday, Perplexity: 54192.46484375
Token: !, Perplexity: 1499.693359375
</code></pre>
<p>But I'm not sure what I'm doing wrong, as the last token seem to have the same perplexity as the entire sentence.</p>
","2023-11-06 17:30:20","2","Question"
"77427643","75011843","","<p>Here's how to do it:</p>
<pre class=""lang-py prettyprint-override""><code>from matplotlib import pyplot as plt
import shap

plt.figure()
plt.subplot(1,2,1)
shap.plots.beeswarm(explainer_a(X_test_a), max_display=10)
plt.subplot(1,2,2)
shap.plots.beeswarm(explainer_a(X_test_b), max_display=10)

# Optional for adjusting the margins:
plt.subplots_adjust(
    left=1,
    bottom=0.1, 
    right=3, 
    top=0.9
)
</code></pre>
","2023-11-05 20:54:59","1","Answer"
"77416398","77360745","","<p>Try this code, A neural network with an input layer, two hidden layers, and an output layer. The network is trained on the XOR problem dataset, and you can test it by passing different inputs to the <strong>forward_pass</strong> method</p>
<pre><code>import numpy as np

class Neuron:
    def __init__(self, weights, bias):
        self.weights = weights
        self.bias = bias

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def compute(self, inputs):
        weighted_sum = np.dot(inputs, self.weights) + self.bias
        return self.sigmoid(weighted_sum)

class Layer:
    def __init__(self, num_neurons, num_inputs):
        self.neurons = []
        self.outputs = []
        self.num_neurons = num_neurons
        self.num_inputs = num_inputs
        self.initialize_weights_and_biases()

        for _ in range(num_neurons):
            self.neurons.append(Neuron(self.weights, self.biases))

    def initialize_weights_and_biases(self):
        self.weights = 2 * np.random.random((self.num_inputs, self.num_neurons)) - 1
        self.biases = 2 * np.random.random((1, self.num_neurons)) - 1

    def forward(self, inputs):
        self.outputs = np.array([])
        for neuron in self.neurons:
            self.outputs = np.append(self.outputs, neuron.compute(inputs))

class NeuralNetwork:
    def __init__(self, layers):
        self.layers = layers

    def forward_pass(self, inputs):
        for layer in self.layers:
            layer.forward(inputs)
            inputs = layer.outputs
        return inputs

    def calculate_error(self, predicted_outputs, true_outputs):
        error = (true_outputs - predicted_outputs) * predicted_outputs * (1 - predicted_outputs)
        return error

    def train_network(self, training_data_inputs, training_data_outputs, num_iterations):
        for _ in range(num_iterations):
            for i, layer in enumerate(self.layers):
                if i == 0:
                    layer.forward(training_data_inputs)
                else:
                    layer.forward(self.layers[i - 1].outputs)

            predicted_outputs = self.layers[-1].outputs
            error = self.calculate_error(predicted_outputs, training_data_outputs)

            for i, layer in enumerate(reversed(self.layers)):
                prev_outputs = (
                    self.layers[-i - 2].outputs if i &lt; len(self.layers) - 1 else training_data_inputs
                )
                layer_back = layer.neurons if i == 0 else layer_back

                for j, neuron in enumerate(layer.neurons):
                    neuron.weights += np.dot(prev_outputs.T, error[:, j])
                    neuron.bias += np.sum(error[:, j])

                error = np.dot(error, layer.weights.T)

def main():
    # XOR problem dataset
    input_training_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    output_training_data = np.array([[0, 1, 1, 0]]).T

    input_layer = Layer(2, 2)
    hidden_layer1 = Layer(3, 2)
    hidden_layer2 = Layer(3, 3)
    output_layer = Layer(1, 3)

    layers = [input_layer, hidden_layer1, hidden_layer2, output_layer]

    network = NeuralNetwork(layers)

    network.train_network(input_training_data, output_training_data, num_iterations=10000)

    test_input = np.array([[0, 1, 1]])
    predicted_output = network.forward_pass(test_input)
    print(&quot;Predicted output for [0, 1, 1]:&quot;, predicted_output)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
","2023-11-03 11:42:19","0","Answer"
"77413848","77413586","","<p>Make sure you have Rust and Cargo installed. If installed, check your PATH environment variables to ensure it includes path to Rust and Cargo</p>
","2023-11-03 02:21:58","0","Answer"
"77413821","77413586","","<p>You can <a href=""https://github.com/huggingface/transformers#with-pip"" rel=""nofollow noreferrer"">read document</a> about how to install this package.</p>
<p>You will need to install at least one of <strong>Flax</strong>, <strong>PyTorch</strong>, or <strong>TensorFlow</strong>.</p>
<p>When one of those backends has been installed, Transformers can be installed using pip as follows:</p>
<pre><code>pip install transformers
</code></pre>
","2023-11-03 02:15:15","0","Answer"
"77413586","","Issue installing transformers","<p>I'm doing a NLP project on vscode &quot; amazon reviews sentiment analyzer&quot; every thing is going ok until I reached the part for importing transformers</p>
<p>when I'm installing transformers from pip Im getting this error :</p>
<pre><code>error: subprocess-exited-with-error

  × Preparing metadata (pyproject.toml) did not run successfully.
</code></pre>
<p>I tried downloading rust and cargo and it didn't work
I'm sure its in the environment variable It the first time I do NLTK project .</p>
","2023-11-03 00:29:42","-3","Question"
"77409042","77406906","","<p>Another idea for you:</p>
<pre><code># calculate IQR for column Height
Q1 = df_all['Sales'].quantile(0.10)
Q3 = df_all['Sales'].quantile(0.90)
IQR = Q3 - Q1

# identify outliers
threshold = 1.5
outliers = df_all[(df_all['Sales'] &lt; Q1 - threshold * IQR) |
                  (df_all['Sales'] &gt; Q3 + threshold * IQR)]
</code></pre>
<p>You can change quantile size for determine threshhold.</p>
","2023-11-02 11:00:41","0","Answer"
"77407184","77406906","","<p>Try this:</p>
<pre><code>df_all['z'] = np.abs(stats.zscore(df_all['Sales']))
threshold = df_all[df_all.Sales == 20].z.mean()
outliers = df_all[df_all['z']&gt; threshold]
print(outliers)
</code></pre>
","2023-11-02 05:44:05","0","Answer"
"77406906","","Identify the extreme end outliers python","<p>I have many data frames below are the samples but in actuality, they are huge in size -</p>
<p>one sample - df_all</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th style=""text-align: left;"">Seller</th>
<th style=""text-align: center;"">Date</th>
<th style=""text-align: right;"">Sales</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">2-Aug-2023</td>
<td style=""text-align: right;"">26</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">3-Aug-2023</td>
<td style=""text-align: right;"">27</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">4-Aug-2023</td>
<td style=""text-align: right;"">40</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">5-Aug-2023</td>
<td style=""text-align: right;"">50</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">6-Aug-2023</td>
<td style=""text-align: right;"">60</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">7-Aug-2023</td>
<td style=""text-align: right;"">76</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">8-Aug-2023</td>
<td style=""text-align: right;"">106</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">9-Aug-2023</td>
<td style=""text-align: right;"">126</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">12-Aug-2023</td>
<td style=""text-align: right;"">1212126</td>
</tr>
<tr>
<td style=""text-align: left;"">EWC</td>
<td style=""text-align: center;"">13-Aug-2023</td>
<td style=""text-align: right;"">626</td>
</tr>
</tbody>
</table>
</div>
<p>Another sample - df_all</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th style=""text-align: left;"">Seller</th>
<th style=""text-align: center;"">Date</th>
<th style=""text-align: right;"">Sales</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">2-Aug-2023</td>
<td style=""text-align: right;"">1</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">3-Aug-2023</td>
<td style=""text-align: right;"">1</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">4-Aug-2023</td>
<td style=""text-align: right;"">1</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">5-Aug-2023</td>
<td style=""text-align: right;"">1</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">6-Aug-2023</td>
<td style=""text-align: right;"">2</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">7-Aug-2023</td>
<td style=""text-align: right;"">2</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">8-Aug-2023</td>
<td style=""text-align: right;"">2</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">9-Aug-2023</td>
<td style=""text-align: right;"">2</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">12-Aug-2023</td>
<td style=""text-align: right;"">15</td>
</tr>
<tr>
<td style=""text-align: left;"">BMW</td>
<td style=""text-align: center;"">13-Aug-2023</td>
<td style=""text-align: right;"">20</td>
</tr>
</tbody>
</table>
</div>
<p>Here I have 2 seller examples.
EWC on 12th Aug its sales value is 1212126 which is an extreme outlier.
BMW On 12th and 13th Aug its value is 15 and 20 which is not an extreme outlier.</p>
<p>I am using the below code but it is also showing BMW 15 and 20 values as outliers, which is not required. I only need to identify the extreme outliers.</p>
<pre><code>        z = np.abs(stats.zscore(df_all['Sales']))
        threshold = 3
        outliers = df_temp[z &gt; threshold]
        print(outliers)
</code></pre>
","2023-11-02 04:16:50","1","Question"
"77387324","77360745","","<p>You're almost there. I have done exactly this as an assignment. You need a list in Layer to store error for every layer.
Starting with the last layer, the error will get backpropagated till the first layer.</p>
<pre><code>def trainNetwork(self, trainingDataInputs, trainingDataOutputs, numberOfIterations):
    #initialise the best weights with random values
    for y in range(0, numberOfIterations):
        predictedOutputs = self.forwardPass(trainingDataInputs)
        error = self.calculateError(predictedOutputs, trainingDataOutputs)
        for i in layers[0].neurons:             
            i.weights += np.dot(trainingDataInputs.T, error.T)

        N = predictedOutputs.len()
        next_layer = layers[-1]
        next_layer.error = error

        for i in range(len(layers) - 2, -1):
            next_layer = layers[i+1]
            current_layer = layers[i]
            current_layer.error = np.dot(next_layer.error, next_layer.weights.T) * current_layer.output * (1-current_layer.output)
            for i in next_layer.neurons:
                i.weights += np.dot(current_layer.output.T, next_layer.error)/N

        # for the first layer, updating weights needs to be done against the inputs
        for i in current_layer.neurons:
            i.weights += np.dot(trainingDataInputs.T, current_layer.error)/N
</code></pre>
<p>*PS: Correct me if I am wrong but weight updation formula is np.dot(trainingDataInputs.T, error.T) for your code
You can also add learning rate to your code
*</p>
","2023-10-30 09:02:20","1","Answer"
"77382997","77380210","","<p>The problem has been solved. Do the following to register in the nano .bashrc
Under the wsl instance:</p>
<pre><code>sudo nano .bashrc
</code></pre>
<p>Insert the followings:</p>
<pre><code>export LD_LIBRARY_PATH=&quot;/usr/lib/wsl/lib/&quot;  
export NUMBA_CUDA_DRIVER=&quot;/usr/lib/wsl/lib/libcuda.so.1&quot;
</code></pre>
<p>And then:</p>
<pre><code>source .bashrc
</code></pre>
","2023-10-29 11:01:43","2","Answer"
"77381455","77380874","","<p>You can't have loss weights be learned within the same process. The weights will go to zero (or even negative). Loss weights are hyperparameters that must be set externally.</p>
<p>If you want a learning process to set the loss weights, it has to be an outer loop around your model training process.</p>
<p>You can research loss weighting in multitask learning to learn more.</p>
","2023-10-28 22:34:15","1","Answer"
"77380874","","How to have trainable weights for multiple losses?","<p>I have a weighted loss consisting multiple losses for training my model.</p>
<pre><code>loss = w1 * loss1 + w2 * loss2 + w3 * loss3
loss.backward()
</code></pre>
<p>Is there any possible way to make w1, w2 and w3 learnable parameters? I tried making initializing them using <code>self.w1 = nn.Parameter(torch.tensor(0.33), requires_grad=True)</code> inside the model, but after one iteration it's value is becoming <code>nan</code>.</p>
<p>There are other issues to consider when we want to make the weights learnable such as, whats stopping them from going to zero or even going negative in order to make loss zero, how would we ensure that the weights don't concentrate on just one loss.</p>
<p>Is there a way to have these weights learnable rather than having hand-tuned weights?</p>
","2023-10-28 19:14:51","1","Question"
"77380210","","rapids cannot import cudf: Error at driver init: Call to cuInit results in CUDA_ERROR_NO_DEVICE (100)","<p>To install RAPIDS, i have already installed WSL2.</p>
<p>But i still got the following error when import cudf:</p>
<pre><code>/home/zy-wsl/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cudf/utils/_ptxcompiler.py:61: UserWarning: Error getting driver and runtime versions:

stdout:



stderr:

Traceback (most recent call last):
  File &quot;/home/zy-wsl/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py&quot;, line 258, in ensure_initialized
    self.cuInit(0)
  File &quot;/home/zy-wsl/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py&quot;, line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File &quot;/home/zy-wsl/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py&quot;, line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [100] Call to cuInit results in CUDA_ERROR_NO_DEVICE

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;&lt;string&gt;&quot;, line 4, in &lt;module&gt;
  File &quot;/home/zy-wsl/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py&quot;, line 296, in __getattr__
    self.ensure_initialized()
  File &quot;/home/zy-wsl/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/numba/cuda/cudadrv/driver.py&quot;, line 262, in ensure_initialized
    raise CudaSupportError(f&quot;Error at driver init: {description}&quot;)
...


Not patching Numba
  warnings.warn(msg, UserWarning)
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
---------------------------------------------------------------------------
CudaSupportError                          Traceback (most recent call last)
/mnt/d/learn-rapids/Untitled.ipynb Cell 4 line 1
----&gt; 1 import cudf

File ~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cudf/__init__.py:26
     20 from cudf.api.extensions import (
     21     register_dataframe_accessor,
     22     register_index_accessor,
     23     register_series_accessor,
     24 )
     25 from cudf.api.types import dtype
---&gt; 26 from cudf.core.algorithms import factorize
     27 from cudf.core.cut import cut
     28 from cudf.core.dataframe import DataFrame, from_dataframe, from_pandas, merge

File ~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cudf/core/algorithms.py:10
      8 from cudf.core.copy_types import BooleanMask
      9 from cudf.core.index import RangeIndex, as_index
---&gt; 10 from cudf.core.indexed_frame import IndexedFrame
     11 from cudf.core.scalar import Scalar
     12 from cudf.options import get_option

File ~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cudf/core/indexed_frame.py:59
     57 from cudf.core.dtypes import ListDtype
...
    302 if USE_NV_BINDING:
    303     return self._cuda_python_wrap_fn(fname)

CudaSupportError: Error at driver init: 
Call to cuInit results in CUDA_ERROR_NO_DEVICE (100):
</code></pre>
<p>Tried the latest install line below:</p>
<pre><code>conda create --solver=libmamba -n rapids-23.12 -c rapidsai-nightly -c conda-forge -c nvidia  \
    cudf=23.12 cuml=23.12 python=3.10 cuda-version=12.0 \
    jupyterlab
</code></pre>
<pre><code> NVIDIA-SMI 545.23.05              Driver Version: 545.84       CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA RTX A6000               On  | 00000000:01:00.0  On |                  Off |
| 30%   53C    P3              54W / 300W |   1783MiB / 49140MiB |     10%      Default |
|                                         |                      |                  N/A
</code></pre>
<p>Also that cudf has been in the conda env:</p>
<pre><code>cudf                      23.12.00a       cuda12_py310_231028_g2a923dfff8_124    rapidsai-nightly
cuml                      23.12.00a       cuda12_py310_231028_gff635fc25_31    rapidsai-nightly
</code></pre>
<p>I also tried using numba-s in the wsl env, and found the following:</p>
<pre><code>__CUDA Information__
CUDA Device Initialized                       : False
CUDA Driver Version                           : ?
CUDA Runtime Version                          : ?
CUDA NVIDIA Bindings Available                : ?
CUDA NVIDIA Bindings In Use                   : ?
CUDA Minor Version Compatibility Available    : ?
CUDA Minor Version Compatibility Needed       : ?
CUDA Minor Version Compatibility In Use       : ?
CUDA Detect Output:
None
CUDA Libraries Test Output:
None

__Warning log__
Warning (cuda): CUDA device initialisation problem. Message:Error at driver init: Call to cuInit results in CUDA_ERROR_NO_DEVICE (100)
Exception class: &lt;class 'numba.cuda.cudadrv.error.CudaSupportError'&gt;
Warning (no file): /sys/fs/cgroup/cpuacct/cpu.cfs_quota_us
Warning (no file): /sys/fs/cgroup/cpuacct/cpu.cfs_period_us
</code></pre>
<p>Seems like the CUDA is not initiated in wsl but when i run this command in windows prompt, it returns:</p>
<pre><code>__CUDA Information__
CUDA Device Initialized                       : True
CUDA Driver Version                           : ?
CUDA Runtime Version                          : ?
CUDA NVIDIA Bindings Available                : ?
CUDA NVIDIA Bindings In Use                   : ?
CUDA Minor Version Compatibility Available    : ?
CUDA Minor Version Compatibility Needed       : ?
CUDA Minor Version Compatibility In Use       : ?
CUDA Detect Output:
Found 1 CUDA devices
id 0     b'NVIDIA RTX A6000'                              [SUPPORTED]
                      Compute Capability: 8.6
                           PCI Device ID: 0
                              PCI Bus ID: 1
                                    UUID: GPU-17e7be94-251e-a2d9-3924-d167c0e59a56
                                Watchdog: Enabled
                            Compute Mode: WDDM
             FP32/FP64 Performance Ratio: 32
Summary:
        1/1 devices are supported

CUDA Libraries Test Output:
None
__Warning log__
Warning (cuda): Probing CUDA failed (device and driver present, runtime problem?)
(cuda) &lt;class 'FileNotFoundError'&gt;: Could not find module 'cudart.dll' (or one of its dependencies). Try using the full path with constructor syntax.
</code></pre>
","2023-10-28 16:02:14","-2","Question"
"77375628","76866418","","<p>I encountered the same issue! See, if you don't want to go back to old Tensorflow versions try these:</p>
<ol>
<li>Fork the Tflearn repo <a href=""https://github.com/tflearn/tflearn"" rel=""nofollow noreferrer"">https://github.com/tflearn/tflearn</a></li>
<li>See the updates in one the pull requests (<a href=""https://github.com/tflearn/tflearn/pull/1173"" rel=""nofollow noreferrer"">https://github.com/tflearn/tflearn/pull/1173</a>) of this repo</li>
<li>Make these changes in your forked repo</li>
<li>The uninstall Tflearn and then reinstall tflearn from your forked repo</li>
</ol>
<ul>
<li>Just do pip install <code>git+https://github.com/&lt;your_github_user_name&gt;/&lt;forked_repo_name&gt;.git </code></li>
</ul>
","2023-10-27 16:09:05","0","Answer"
"77360745","","How to train a network with two or more layers","<p>I am implementing a neural network from scratch using python. I have a Neuron class, layer class and network class.</p>
<p>I have managed to train and use a network with 1 layer, 1 Neuron and 3 inputs.</p>
<p>I now want to try using 2 or more layers, both with an arbitrary number of Neurons. My problem is, how would I now change the 'train' function to train a network like this?</p>
<p>At present, if the layer is 0 then it will input the network inputs into the neurons. If the layer is above 0, then it will input the outputs from the previous layer.</p>
<p>But what do I do next?</p>
<p>I have used the code below:</p>
<pre><code>
import numpy as np
from numpy import exp, random
import math

from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

np.random.seed(1)

class Neuron:

    def __init__(self, weights, bias):

        self.weights = weights
        self.bias = bias

    def sigmoid(self, x):

        output = 1/(1+exp(-x))

        return output

    def compute(self, inputs):

        self.output = self.sigmoid(np.dot(inputs, self.weights) + self.bias)

        return self.output

class Layer: 

    def __init__(self, numberOfNeurons, numberOfInputs):

        self.neurons = []
        self.outputs = []
        self.numberOfNeurons = numberOfNeurons
        self.numberOfInputs = numberOfInputs

        self.initialiseWeightsAndBiases()

        for i in range(0,numberOfNeurons):

            self.neurons.append(Neuron(self.weights, self.biases))

    def initialiseWeightsAndBiases(self):

        self.weights = 2 * random.random((self.numberOfInputs, self.numberOfNeurons)) - 1

        self.biases = 2 * random.random((1, self.numberOfNeurons)) - 1

    
    def forward(self, inputs):

        self.outputs = np.array([])

        for i in self.neurons:

            self.outputs = np.append(self.outputs, i.compute(inputs))

class NeuralNetwork:

    def __init__(self, layers):

        self.layers = layers

    def forwardPass(self, inputs):

        for i in range(0,len(layers)):

            if i == 0:

                layers[i].forward(inputs)   

            else:
                
                layers[i].forward(layers[i-1].outputs)

        return layers[-1].outputs

    def calculateError(self, predictedOutputs, trueOutputs):

        error = (trueOutputs - predictedOutputs) * predictedOutputs * (1 - predictedOutputs)

        return error

    def trainNetwork(self, trainingDataInputs, trainingDataOutputs, numberOfIterations):

        #initialise the best weights with random values

        for y in range(0, numberOfIterations):

            predictedOutputs = self.forwardPass(trainingDataInputs)

            error = self.calculateError(predictedOutputs, trainingDataOutputs)

            for i in layers[0].neurons:             

                i.weights += np.dot(trainingDataInputs.T, error.T)


    def visualiseNetwork(self):

        pass


#Layer(numberOfNeurons, numberOfInputs)

inputLayer = Layer( 1, 3)

layers = [inputLayer]

network1 = NeuralNetwork(layers)

inputTrainingData = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])
outputTrainingData = [[0, 1, 1, 0]]

network1.trainNetwork(inputTrainingData, outputTrainingData, 10000)

outputs = network1.forwardPass([[0,1,1]])

print(outputs)

</code></pre>
","2023-10-25 15:08:40","1","Question"
"77352048","77351990","","<p>You can use a common <a href=""https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html"" rel=""nofollow noreferrer""><code>CategoricalDtype</code></a>:</p>
<pre><code>df_train = pd.DataFrame({'City': ['London' , 'Bristol', 'Paris', 'Rome', 'London', 'Worcester']})
df_test = pd.DataFrame({'City': ['Paris', 'Rome','Rome','London', 'Gloucester']})

cat = pd.CategoricalDtype(pd.concat([df_train['City'], df_test['City']]).unique())

df_train['code'] = df_train['City'].astype(cat).cat.codes
df_test['code'] = df_test['City'].astype(cat).cat.codes
</code></pre>
<p>Output:</p>
<pre><code># df_train
        City  code
0     London     0
1    Bristol     1
2      Paris     2
3       Rome     3
4     London     0
5  Worcester     4

# df_test
         City  code
0       Paris     2
1        Rome     3
2        Rome     3
3      London     0
4  Gloucester     5
</code></pre>
<p>Or just convert the cities to Categorical:</p>
<pre><code>df_train['City'] = df_train['City'].astype(cat)
df_test['City'] = df_test['City'].astype(cat)
</code></pre>
","2023-10-24 12:27:56","1","Answer"
"77351990","","Test and Train Data have different cities, how to find and differences and encode using the same coding system on both columns from test & train data","<p>I have a test set and train set. They have a city columns one (train) has 290 unique and the test has 30. I am hoping there is overlap i.e. London, Bristol are in both sets, but Gloucester might be on one set and not the other.</p>
<p>I want to also encode these ,cities to a numerical value that correlates between both sets, so London should be encoded as 1 in test and train.</p>
<p>I have looked at LabelEncoder but cannot see how to get both sets to use the same numbering for cities they both share.</p>
<p>LabelEncoder works fine but no correlation between the two sets.</p>
<p>before:</p>
<pre><code>df_train['City']
'London' , 'Bristol', 'Paris', 'Rome', 'London', 'Worcester'

df_test['City']
'Paris', 'Rome','Rome','London', 'Gloucester'
</code></pre>
<p>output:</p>
<pre><code>df_train['City']
1 2 3 4 1 6

df_test['City']
3 4 4 1 7
</code></pre>
","2023-10-24 12:19:41","1","Question"
"77343238","75589764","","<p>I ended up using <a href=""https://spark.apache.org/docs/3.2.0/api/python/reference/api/pyspark.sql.GroupedData.applyInPandas.html"" rel=""nofollow noreferrer"">applyInPandas</a> which does a nice job parallelizing a task based on a group by of one or several columns the original dataframe.</p>
","2023-10-23 07:08:21","0","Answer"
"77341919","76633836","","<p><code>CharacterTextSpliiter</code> behaves differently from what you expected.</p>
<pre><code>text_splitter = CharacterTextSplitter(
    separator=&quot;\n&quot;,
    chunk_size=6,
)
</code></pre>
<p>It first looks for the first 6 characters and then splits the next chunk from the closest separator, not from the 7th character.</p>
<p>As stated in the docs default separator is &quot;\n&quot;.</p>
<blockquote>
<p>This is the simplest method. This splits based on characters (by
default &quot;\n\n&quot;) and measure chunk length by number of characters.</p>
</blockquote>
<p>you can test the behaviour with a sample code. first create a <code>test.txt</code> file with this</p>
<pre><code>1.Respect for Others: Treat others with kindness.
2.Honesty and Integrity: Be truthful and act with integrity in your interactions with others.
3.Fairness and Justice: Treat people equitably.
4.Respect for Property: Respect public and private property.
5.Good Citizenship: Contribute positively to your community by obeying laws, voting, volunteering, and supporting communal well-being.
</code></pre>
<p>then write this code:</p>
<pre><code>from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# it will first find first 20 character then it will make the next chunk at the closest separator
text_splitter = CharacterTextSplitter(
    separator=&quot;\n&quot;,
    chunk_size=20,
    chunk_overlap=0
)

loader = TextLoader(&quot;test.txt&quot;)
docs = loader.load_and_split(
    text_splitter=text_splitter
)

for doc in docs:
    print(doc.page_content)
    print(&quot;\n&quot;)
</code></pre>
<p>this is how it look like:</p>
<p><a href=""https://i.sstatic.net/sfLcm.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/sfLcm.png"" alt=""enter image description here"" /></a></p>
","2023-10-22 22:36:22","12","Answer"
"77339487","77337720","","<p>I'm assuming by the fully connected network you're referring to the Fully Connected (FC) / <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"" rel=""nofollow noreferrer"">Linear</a> layer.</p>
<pre><code>from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig, GPT2Config
configuration = GPT2Config()
model = GPT2LMHeadModel(configuration)
print(model) 
</code></pre>
<p>The above would show you the modules inside the model:</p>
<pre><code>GPT2LMHeadModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-11): 12 x GPT2Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=768, out_features=50257, bias=False)
)
</code></pre>
<p>You can now access and update the FC layer by:</p>
<pre><code>model.lm_head = nn.Sequential(
    nn.Linear(in_features = 768, out_features = 256),
    nn.ReLU(inplace = True),
    nn.Dropout1d(0.25),
    nn.Linear(in_features = 256, out_features = 128)
)
</code></pre>
<p>The above is just a sample, you can experiment with different combinations.</p>
","2023-10-22 10:06:05","1","Answer"
"77338135","77337720","","<p>To experiment with different hyperparameters, you can use the <strong>Autoclass</strong> provided by HG. This class allows you to create a custom architecture with a base class from one of the available models on the HG hub. For instance, if you want to experiment with the number of layers, you can pass a config parameter and change the layer number to the desired value. Like <code>&quot;n_layers&quot;: 6.</code> To learn more, please refer to the following link: <a href=""https://huggingface.co/docs/transformers/create_a_model"" rel=""nofollow noreferrer"">https://huggingface.co/docs/transformers/create_a_model</a>.</p>
","2023-10-21 23:21:34","-1","Answer"
"77337843","76776695","","<p>You can only pass two variables:
1-Context
2-Question
This is a limitation.</p>
<pre><code>qs=&quot;How are you?&quot;
PROMPT = PromptTemplate(input_variables=[&quot;context&quot;,&quot;question&quot;], template=template)
qa_with_sources = RetrievalQA.from_chain_type(llm=OpenAI(model_name=&quot;gpt-4&quot;,temperature=0.2), chain_type=&quot;stuff&quot;,chain_type_kwargs = {&quot;prompt&quot;: PROMPT}, retriever=docsearch.as_retriever(), return_source_documents=True)
llm_response = qa_with_sources({&quot;query&quot;: qs})

</code></pre>
<p>Use it like this and it will work!</p>
","2023-10-21 21:21:24","1","Answer"
"77337720","","How to change the fully connected network in a GPT model on Huggingface?","<p>I'm following <a href=""https://huggingface.co/learn/nlp-course/chapter7/6"" rel=""nofollow noreferrer"">this tutorial on training a causal language model from scratch</a>.</p>
<p>In the tutorial they load the standard GPT2 as follows:</p>
<pre><code>from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig

config = AutoConfig.from_pretrained(
    &quot;gpt2&quot;,
    vocab_size=len(tokenizer),
    n_ctx=context_length,
    bos_token_id=tokenizer.bos_token_id,
    eos_token_id=tokenizer.eos_token_id,
)
model = GPT2LMHeadModel(config)
</code></pre>
<p>How can I load the same model, but use my custom fully connected network instead of the standard one? Mainly want to experiment with variations such as more/less layers, different activation functions, etc.</p>
<p>I found the <a href=""https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py"" rel=""nofollow noreferrer"">source code here</a>, but it's very convoluted and I can't figure out how to replace the fully connected parts with a custom ones or what structure the custom one should have in the first place (e.g., input/output size).</p>
<p><strong>Update</strong>
For example, using a FC network as such:</p>
<pre><code>class FC_model(nn.Module):
    def __init__(self):
        super(FC_model, self).__init__()

        self.fc1 = nn.Linear(768,256)
        self.fc2 = nn.Linear(256,256)
        self.fc3 = nn.Linear(256,50000)

    def forward(self, x):
        x = torch.sin(self.fc1(x)) + torch.rand(1)
        x = torch.sin(self.fc2(x))
        x = self.fc3(x)
        return x
</code></pre>
","2023-10-21 20:40:53","-1","Question"
"77329185","77174989","","<p>The shape of your input images is (50, 50, 3) which indicates three color channels. However, your model's output layer is defined to have four units which shows that it expects a four-channel input.
Make sure the input shape of your model matches the shape of your input data to address this problem. Set the num_channels parameter in your model function to 3 because your images have three color channels.</p>
","2023-10-20 07:51:05","0","Answer"
"77324973","75589764","","<ol>
<li><p>Initialize a <strong>SparkContext</strong></p>
</li>
<li><p>Create individual dataframes corresponding to each of your DeviceID (use filter method) and create a list like
<strong>category_data_list = [category_A_data, category_B_data, category_C_data]</strong>.</p>
</li>
</ol>
<p>3)Define a function to train model on each of these categories of data</p>
<p>4)Use <strong>parallelize</strong> function and pass the category_data_list.</p>
<p>5)Repeat the above steps for predictions as well.</p>
","2023-10-19 15:05:08","0","Answer"
"77324819","75224346","","<p>BerTopic merely makes few calls to existing APIs, so I advise to <strong>repeat and adapt the few steps that BerTopic takes</strong> when generating the plot. We gain lots of flexibility with little code, plus educatation on how it works:</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.metrics.pairwise import cosine_similarity
from scipy.cluster import hierarchy as sch
from bertopic._utils import validate_distance_matrix
import plotly.figure_factory as ff


embeddings = topic_model.c_tf_idf_ # (N_TOPICS,N_WORDS)
distance_fn = lambda x: 1 - cosine_similarity(x)
distance_function_viz = lambda x: validate_distance_matrix(distance_fn(x), embeddings.shape[0])
fig = ff.create_dendrogram(embeddings,
                            orientation=orientation,
                            distfun=distance_function_viz,
                            linkagefun=linkage_function,
                            hovertext=annotations,
                            color_threshold=color_threshold)
axis= &quot;yaxis&quot;

def get_topic_label(idx):
    return str(idx)+&quot;_&quot;+&quot;_&quot;.join(k for (k,v) in topic_model.get_topic(int(idx))[:5])

fig.update_layout(
    height=200 + (15 * embeddings.shape[0]),
    width = 1200,
    yaxis=dict(tickmode=&quot;array&quot;,ticktext=list(map(get_topic_label, fig.layout[axis][&quot;ticktext&quot;])))
)
fig
</code></pre>
<p><a href=""https://i.sstatic.net/dXyLh.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/dXyLh.png"" alt=""enter image description here"" /></a></p>
","2023-10-19 14:48:55","0","Answer"
"77323460","75115715","","<p>There is a really good blog by Sentinel Hub on different normalization schemes that can be used to normalize satellite images <a href=""https://medium.com/sentinel-hub/how-to-normalize-satellite-images-for-deep-learning-d5b668c885af"" rel=""nofollow noreferrer"">https://medium.com/sentinel-hub/how-to-normalize-satellite-images-for-deep-learning-d5b668c885af</a></p>
<p>Main issue with these data is that they are heavy-tailed and therefore require special treatment to handle pixel values that lie in the tail end as they can greatly influence the normalization values. In the blog you can see that normalization based on min/max is the worst possible option and any scheme that are based on percentiles tend to perform well as they can handle outliers. In my personal experience, dynamic world method of using log normalization has given the best result because you perform normalization in the log space which converts the heavy-tailed distribution to a normal distribution.</p>
<p>Also, please note that even though the image is 16 bit, the almost all of the pixel values will be much smaller than 65535. This is because satellite images are reflectance values which are bounded away from 0. Majority of the objects on earth including vegetation don't have high reflectance.</p>
","2023-10-19 11:41:03","0","Answer"
"77320822","77319872","","<p>To improve tag-based matching with a large set of tags, you can use part-of-speech tagging (POS tagging) to identify essential keywords within tags. These keywords, like &quot;data science&quot; or &quot;Japanese food,&quot; serve as the focal points for matching. Convert these keywords into vector representations using techniques like Word2Vec or TF-IDF, which capture semantic meanings.</p>
<p>Next, compare the vectors of different tags to measure their similarity. Common similarity metrics like cosine similarity can quantify the relatedness of tags. Set a similarity threshold to determine which tags are considered relevant matches. Fine-tune this threshold to control the granularity of matches.</p>
<p>When users select tags, compare their chosen tags with others in your database. Present potential matches whose similarity scores exceed the threshold. Additionally, handle variations in tags using techniques like synonym mapping or stemming to ensure robust matching.</p>
<p>This approach allows for more nuanced and distant tag relations, resulting in a flexible and accurate matching system. While it may require computational resources, it greatly enhances the user experience by providing better tag-based recommendations.</p>
","2023-10-19 03:36:10","0","Answer"
"77320057","77319872","","<p>Your conjectures are reasonable, but: you have to test them in a real system, subject to your data, goals, and other choices.</p>
<p>The quality of your results could vary quite a bit on your choices of how to define 'entities', and other data prep/enhancement.</p>
<p>Ultimately you're asking a sort of classification or ranking question:</p>
<p>&quot;Given this [free-text-description-of-wants], how likely us another [free-text-description-of-offering] to make some user satisfied?&quot;</p>
<p>(It's classification if you're focusing on: would downstream evaluation consider it binary 'good-enough' or 'no-good'. It's ranking/scoring if you want to report some sense of relative-appropriateness.)</p>
<p>Something simple like various kinds of mere semantic-similarity between the 2 texts migth be valid way to go from nothing to something: bootstrap a little advantage.</p>
<p>But it's likely the true relationship to successful downstream matching/recommended is more complicated than mere textual-similarity. (For example, the best matches may conventionally be described with different sets of words than are used for free-form specifications, in a realtionship that people understand, and may be learnable, but isn't mere word-correlations.)</p>
<p>Thus you might want to enhance your texts with extra calculated features, and generically train a system to score candidate pairs of <code>(need-text-with-all-features), (offer-text-with-all-features)</code> as better or worse, based on your other (ad hoc or formally-acquired) 'gold standard' examples of what you want the system to do.</p>
<p>There are boundless ways to iteratively try &amp; improve such a system - what makes sense depends on your data, &amp; effective budgets of skills/attention/compute/etc.</p>
","2023-10-18 22:59:38","0","Answer"
"77319872","","Text to Tag similarity word2vec","<p>Our users will give a 2 to 3 sentence description about their profession.
Example user A (profile description): <code>I am a data scientist living in Berlin, I like Japanese food and I am also interested in arts.</code></p>
<p>Then they also give a description about what kind of person they are looking for.
Example user B (looking for description): <code>I am looking for a data scientist, sales guy and an architect for my new home</code>.</p>
<p>We want to match these on the basis that user A is a data scientist and user B is looking for a data scientist.</p>
<p>At first we required the user to hand select the tags they want to be matched on.
And example of the kind of tags we provided:</p>
<pre><code>Environmental Services
Events Services
Executive Office
Facilities Services
Human Resources
Information Services
Management Consulting
Outsourcing/Offshoring
Professional Training &amp; Coaching
Security &amp; Investigations
Staffing &amp; Recruiting
Supermarkets
Wholesale
Energy &amp; Mining
Mining &amp; Metals
Oil &amp; Energy
Utilities
Manufacturing
Automotive
Aviation &amp; Aerospace
Chemicals
Defense &amp; Space
Electrical &amp; Electronic Manufacturing
Food Production
Industrial Automation
Machinery
Japanese Food
...
</code></pre>
<p>This system kinda works but we have a lot of tags and want to create more 'distant' relations.</p>
<p>So we need:</p>
<ul>
<li>to know which parts are important, we could use POS-tagging for this, to extract the 'data science', 'japanese food' etc?</li>
<li>and then compare the vectors of each part; e.g. 'data science' with 'statistics' is a good match, and 'japanese food' and 'asian food' is a good match.</li>
<li>and set a threshold.</li>
<li>and this should result in a more convenient way of matching right?</li>
</ul>
","2023-10-18 22:04:40","0","Question"
"77312134","77266349","","<p>It is possible that you are running out of resources hence having an error when deploying your custom container. Kindly check your <a href=""https://cloud.google.com/vertex-ai/docs/quotas"" rel=""nofollow noreferrer"">quota and limits</a>, at the same time, take a look at the <a href=""https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements"" rel=""nofollow noreferrer"">custom container requirements</a>.</p>
<p>I found a similar <a href=""https://stackoverflow.com/questions/74637402/vertex-ai-custom-container-deployment"">question</a>, posted some months ago and I believe this will help you resolve the problem.</p>
","2023-10-17 20:38:37","0","Answer"
"77303713","77217287","","<p>The Document AI API does not currently support applying a label on import when using the <a href=""https://cloud.google.com/document-ai/docs/reference/rest/v1beta3/projects.locations.processors.dataset/importDocuments"" rel=""nofollow noreferrer""><code>importDocuments()</code></a> method. You need to use the Cloud Console to do bulk labeling.</p>
<p>I would recommend adding more details to the public issue tracker <a href=""https://stackoverflow.com/users/19378826/nestor-ceniza-jr"">nestor-ceniza-jr@</a> created so that this can be prioritized by the product development team.</p>
<p><a href=""https://issuetracker.google.com/303285767"" rel=""nofollow noreferrer"">https://issuetracker.google.com/303285767</a></p>
","2023-10-16 16:55:01","2","Answer"
"77299490","75883084","","<p>i had a same problem.
about my case, it because of version of keras and tensorflow.</p>
<p>check your keras version and tensorflow version.</p>
<pre><code>import tensorflow as tf
print(tf.__version__)
</code></pre>
<hr />
<pre><code>!pip uninstall tensorflow --yes
</code></pre>
<hr />
<pre><code>import keras
print(keras.__version__)
</code></pre>
<hr />
<pre><code>!pip install tensorflow==0.00.0
</code></pre>
<p>0.00.0 is the same number of keras version.</p>
","2023-10-16 05:03:57","0","Answer"
"77298910","","Module ‘wandb’ has no attribute ‘apis’","<p>I’m trying to use wandb in a project I’m running on a server via SSH. I created and configured the virtual environment, but with wandb, I’m encountering the error ‘module ‘wandb’ has no attribute ‘apis’’. The server is running Python 3.6.8 and has wandb-0.15.12 installed. However, when I use ‘wandb login’ or any other wandb command, it throws the error. Could anyone help me resolve this issue?</p>
<pre><code>Traceback (most recent call last):
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/bin/wandb&quot;, line 5, in &lt;module&gt;
    from wandb.cli.cli import cli
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/__init__.py&quot;, line 27, in &lt;module&gt;
    from wandb import sdk as wandb_sdk
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/sdk/__init__.py&quot;, line 4, in &lt;module&gt;
    from .artifacts.artifact import Artifact  # noqa: F401
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/sdk/artifacts/artifact.py&quot;, line 36, in &lt;module&gt;
    from wandb.apis.normalize import normalize_exceptions
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/apis/__init__.py&quot;, line 44, in &lt;module&gt;
    from .public import Api as PublicApi  # noqa
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/apis/public.py&quot;, line 51, in &lt;module&gt;
    from wandb.sdk.launch.errors import LaunchError
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/sdk/launch/__init__.py&quot;, line 1, in &lt;module&gt;
    from ._launch import launch
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/sdk/launch/_launch.py&quot;, line 12, in &lt;module&gt;
    from .agent import LaunchAgent
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/sdk/launch/agent/__init__.py&quot;, line 1, in &lt;module&gt;
    from .agent import LaunchAgent
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/sdk/launch/agent/agent.py&quot;, line 15, in &lt;module&gt;
    from wandb.sdk.launch._launch_add import launch_add
  File &quot;/home/tcouto/mestrado_andrey/psla/venv-psla/lib64/python3.6/site-packages/wandb/sdk/launch/_launch_add.py&quot;, line 5, in &lt;module&gt;
    import wandb.apis.public as public
AttributeError: module 'wandb' has no attribute 'apis'

</code></pre>
<p>I tried to reinstall and set it up in another virtual environment, but the same error keeps happening, and don't have any other file with that name inside the folder</p>
","2023-10-16 00:41:27","1","Question"
"77288659","77231544","","<p>So I have understood the problem: when you use <code>n_lags</code>, <code>n_forecast</code> is set as default to 1, so <code>model.predict(future)</code> doesn't predict 100 days off.</p>
<p>Note:
The final values of the dataframe &quot;forecast&quot; will be stored on the diagonal of the dataframe, if you want all the values in a single column <code>yhat1</code> I made this function:</p>
<pre><code>def exctract_yhat(forecasts, size):
  columns = forecasts.columns[3:]
  newframe = forecasts[['ds', 'yhat1']].iloc[-size:].copy()
  for col in columns:
      if 'yhat' in col:
         newframe['yhat1'] = newframe['yhat1'].fillna(forecasts[col])
  return newframe
</code></pre>
<p>#size is = n_forecasts parameters</p>
","2023-10-13 14:42:40","2","Answer"
"77285545","77266349","","<p>I'm always starting with an official base image from GCP like so:</p>
<pre><code>FROM gcr.io/deeplearning-platform-release/pytorch-gpu.2-0.py310:latest
</code></pre>
<p>This one is with GPU support but there are others:
<a href=""https://console.cloud.google.com/gcr/images/deeplearning-platform-release/GLOBAL"" rel=""nofollow noreferrer"">https://console.cloud.google.com/gcr/images/deeplearning-platform-release/GLOBAL</a></p>
<p>With those base images you don't need to care about GCP SDK and its dependencies.</p>
","2023-10-13 06:37:40","0","Answer"
"77270160","77269827","","<p>8e-2 is a pretty high learning rate. Try 1e-5, work your way up if that's stable.</p>
","2023-10-11 04:02:49","0","Answer"
"77269908","77269827","","<p>Try initializing the weight and bias as shown in the code below.</p>
<p>If the variance of the weight or bias matrix is too large, the loss will increase.</p>
<p><a href=""https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"" rel=""nofollow noreferrer"">This paper</a>(Xavier initialization), and <a href=""https://arxiv.org/abs/1502.01852"" rel=""nofollow noreferrer"">this paper</a>(He initialization) will help you understand why this is so.</p>
<pre><code>class classificador(nn.Module):
    def __init__(self):
        super().__init__()
        self.features, self.classifiers = [], []

        self.features += [nn.Conv2d(3, 64, 3), nn.ReLU(inplace=True), nn.BatchNorm2d(64), nn.MaxPool2d(2)]
        self.features += [nn.Conv2d(64, 64, 3), nn.ReLU(inplace=True), nn.BatchNorm2d(64), nn.MaxPool2d(2)]
     
        self.flatten = nn.Flatten()

        self.classifiers += [nn.Linear(14 * 64 * 64, 256), nn.ReLU(inplace=True)]
        self.classifiers += [nn.Linear(256, 128), nn.ReLU(inplace=True)]
        self.classifiers += [nn.Linear(128, 15)]

    for m in self.features:
         if isinstance(m, nn.Conv2d):
             nn.init.kaiming_normal_(m.weight, mode=&quot;fan_out&quot;, nonlinearity=&quot;relu&quot;)
             if m.bias is not None:
                 nn.init.constant_(m.bias, 0)
    
    for m in self.classifier:
        if isinstance(m, nn.Linear):
            nn.init.normal_(m.weight, 0, 0.01)
            nn.init.constant_(m.bias, 0)
    
    self.features = nn.Sequential(*self.features)
    self.classifier = nn.Sequential(*self.classifiers)

    def forward(self, X):
        X = self.features(X)
        X = self.flatten(X)
        X = self.classifiers(X)
        return X
</code></pre>
","2023-10-11 02:30:02","2","Answer"
"77269827","","Loss in validation with Pytorch result NaN or a high loss","<p>I'm trying to train a deep learning and when I put someone value, or show &quot;Perda NaN&quot; (Loss NaN) or Loss in validation so high. Learning hate to be 0.08 and momentum is 0.</p>
<pre><code>import torch
from torch import nn, optim
import torch.nn.functional as F
from torchvision import datasets, transforms
import os
import random
import shutil

# Defina as sementes para reproducibilidade
torch.manual_seed(123)

# Diretórios dos dados
data_dir_train = 'train'
data_dir_test = 'test'

# Transformações para treinamento e teste
transform_train = transforms.Compose(
    [
        transforms.Resize([64, 64]),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor()
    ]
)

transform_test = transforms.Compose(
    [
        transforms.Resize([64, 64]),
        transforms.ToTensor()
    ]
)

# Carregamento dos dados
train_dataset = datasets.ImageFolder(data_dir_train, transform=transform_train)
test_dataset = datasets.ImageFolder(data_dir_test, transform=transform_test)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)

# Classe do modelo
class classificador(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3))
        self.conv2 = nn.Conv2d(64, 64, (3, 3))
        self.activation = nn.ReLU()
        self.bnorm = nn.BatchNorm2d(num_features=64)
        self.pool = nn.MaxPool2d(kernel_size=(2, 2))
        self.flatten = nn.Flatten()
        self.linear1 = nn.Linear(in_features=14 * 14 * 64, out_features=256)
        self.linear2 = nn.Linear(256, 128)
        self.output = nn.Linear(128, 15)

    def forward(self, X):
        X = self.pool(self.bnorm(self.activation(self.conv1(X))))
        X = self.pool(self.bnorm(self.activation(self.conv2(X))))
        X = self.flatten(X)
        X = self.activation(self.linear1(X))
        X = self.activation(self.linear2(X))

        # Saída
        X = self.output(X)

        return X

# Instancie o modelo
net = classificador()

# Função de perda e otimizador
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.08, momentum=0.)

# Dispositivo para treinamento
device = torch.device('cpu')
device

net.to(device)

# Função de treinamento com as alterações necessárias
def training_loop(loader, epoch, model, optimizer, criterion, clip_value):
    running_loss = 0.
    running_accuracy = 0.

    model.train()  # Certifique-se de que o modelo está em modo de treinamento

    for i, data in enumerate(loader):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        ps = F.softmax(outputs, dim=1)
        top_p, top_class = ps.topk(k=1, dim=1)
        equals = top_class == labels.view(*top_class.shape)
        accuracy = torch.mean(equals.type(torch.float))
        running_accuracy += accuracy

        loss = criterion(outputs, labels)
        loss.backward()

        # Clip de gradientes
        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)

        optimizer.step()

        running_loss += loss.item()
        print('\rÉpoca {:3d} - Loop {:3d} de {:3d}: perda {:03.2f} - precisão {:03.2f}'.format(epoch + 1, i + 1, len(loader), loss, accuracy), end='\r')

    # Imprimindo os dados referentes a essa época
    print('\rÉPOCA {:3d} FINALIZADA: perda {:.5f} - precisão {:.5f}'.format(epoch + 1, running_loss / len(loader), running_accuracy / len(loader)))

# Número de épocas
epochs = 20
clip_value = 1.0  # Define o valor de clip dos gradientes

for epoch in range(epochs):
    # Treino
    print(&quot;Treinando&quot;)
    training_loop(train_loader, epoch, net, optimizer, criterion, clip_value)
    net.eval()
    # Teste
    print(&quot;Validando&quot;)
    training_loop(test_loader, epoch, net, optimizer, criterion, clip_value)
    net.train()

# Salvar o modelo treinado
net.eval()
torch.save(net.state_dict(), &quot;checkpoint.pth&quot;)

</code></pre>
<p>Return</p>
<pre><code>Treinando
ÉPOCA   1 FINALIZADA: perda 2.52318 - precisão 0.184744
Validando
ÉPOCA   1 FINALIZADA: perda 2.49540 - precisão 0.186060
Treinando
ÉPOCA   2 FINALIZADA: perda 2.42010 - precisão 0.203160
Validando
ÉPOCA   2 FINALIZADA: perda 2.39942 - precisão 0.220670
Treinando
ÉPOCA   3 FINALIZADA: perda 2.37517 - precisão 0.211457
Validando
ÉPOCA   3 FINALIZADA: perda 2.31256 - precisão 0.243990
Treinando
ÉPOCA   4 FINALIZADA: perda 2.33311 - precisão 0.234393
Validando
ÉPOCA   4 FINALIZADA: perda 2.28414 - precisão 0.244950
</code></pre>
<p>I need try to change my code or I should try to use &quot;Keras&quot;?</p>
","2023-10-11 01:53:33","0","Question"
"77266349","","how to deploy custom container in Vertex AI as endpoint","<p>i am trying to deploy custom container in vertex ai as endpoint ( REST URL or API) , i am able to build the docker image successfully , but not able to deploy the model as endpoint , from the logs also i am not able to understand whats the error.</p>
<p>below is my predict.py , dockerfile and deployment script</p>
<pre><code>import numpy as np

def predict(data):
  # Example prediction function
  print (data)
  #result = np.sum(data, axis=1)  # Example: Sum along axis 1
  results = [3,4,5,6]
  results_array = np.array(results)
  print ({&quot;predictions&quot;: results_array.tolist()})
  return ({&quot;predictions&quot;: results_array.tolist()})
  predict([3,4,6])
</code></pre>
<p>dockerfile</p>
<pre><code>FROM python:3.10
WORKDIR /code

COPY requirements.txt requirements.txt
COPY model.pkl model.pkl
RUN pip install --upgrade pip
RUN pip --version
RUN pip install -r requirements.txt
COPY . .
CMD [&quot;python3&quot;, &quot;predict.py&quot;]
</code></pre>
<p>Deployment script</p>
<pre><code>import os
import google.cloud.aiplatform as aiplatform

# Set your GCP project ID, location, and model name
project = &quot;project ID&quot;
location = &quot;us-central1&quot;
model_name = &quot;testing_3&quot;

# Initialize the API client
aiplatform.init(project=project, location=location)

# Define the container image URI
container_image_uri = &quot;image URI&quot;

# Create a custom container prediction model
model = aiplatform.Model.upload(
display_name=model_name,
serving_container_image_uri=container_image_uri,
 )

print (&quot;deploying the model now&quot;)
try:
  # Deploy the model
  endpoint = model.deploy(machine_type=&quot;n1-standard-4&quot;)
  print(endpoint)
except Exception as e:
  print(f&quot;Error deploying the model: {e}&quot;)
</code></pre>
<p>i have also try to run the deployed docker image and its running without any error , only i am not able to deploy the endpoint</p>
<p>Can anyone help me here?</p>
","2023-10-10 13:43:48","-2","Question"
"77263861","77259723","","<p>What you could do:</p>
<ol>
<li>If you need batch inference, you could use <a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html"" rel=""nofollow noreferrer"">SageMaker Training Heterogeneous clusters</a> for inference (instead of training).</li>
<li>Create a pipeline where you have preprocessing in EC2, then forward the result to a SageMaker endpoint.</li>
<li>There are many of ML GPU instance types available in SageMaker, pick one that has the right mix of CPU-GPU power (e.g., G5 series). And implement internal queuing inside the instance to buffer between the pre-processing and the GPU computation.</li>
</ol>
","2023-10-10 07:52:32","0","Answer"
"77259928","77259723","","<p>Today, the only way to have heterogeneous instance types on a single SageMaker endpoint is if you use different production variants. You would have to orchestrate which variant you send the request to yourself.</p>
<p><a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html#model-testing-target-variant"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html#model-testing-target-variant</a></p>
","2023-10-09 15:04:34","0","Answer"
"77259723","","Running pre-process and inference on different instances in AWS SageMaker","<p>I'm trying to figure out if there's a way to run a pre-process and inference on different instances in Sagemaker. Right now, I have an image model deployed that runs on a GPU instance, and my idea is to separate preprocessing from inference and have it on a cheaper CPU instance to (hopefully) save costs.</p>
<p>I tried following <a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/multi-container-endpoints.html"" rel=""nofollow noreferrer"">multiple models with different containers</a> tutorial, but it looks like both jobs are running on the same instance.</p>
<p>Does anyone know the way to run preprocess and inference within one endpoint, but on two different instances? Or perhaps knows a better way to do it.</p>
","2023-10-09 14:35:46","0","Question"
"77248571","","How to save a reconstructed binary image using skimage imsave","<p>I have been trying to preprocess an image for feature extraction using skimage library.But I can't save the image as it gives error saying &quot;cannot write mode F as PNG&quot;</p>
<p>the funtion for processing the image is given here</p>
<pre><code>def image_process(image):
    img = imread(image)
    rem_img = remove(img)
    rgb_img = rgba2rgb(rem_img)
    gray_img = rgb2gray(rgb_img)
    bin_img = gray_img &lt; threshold_otsu(gray_img)
    smooth_img = gaussian(bin_img)

    seed_px = np.copy(smooth_img)
    seed_px[1:-1 , 1:-1]=smooth_img.max()
    mask = smooth_img
    filled_img = reconstruction(seed_px , mask , method ='erosion')

    return filled_img
</code></pre>
<p>then just tried to save the image in directory BW uisng imsave</p>
<pre><code>leaf_img = &quot;neem.jpg&quot;
processed_img = image_process(leaf_img)
imsave(&quot;BW/leaf.png&quot;, processed_img)
</code></pre>
<p>It shows error</p>
<pre><code>KeyError                                  Traceback (most recent call last)
File C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1299, in _save(im, fp, filename, chunk, save_all)
   1298 try:
-&gt; 1299     rawmode, mode = _OUTMODES[mode]
   1300 except KeyError as e:

KeyError: 'F'

The above exception was the direct cause of the following exception:

OSError                                   Traceback (most recent call last)
Cell In[26], line 3
      1 leaf_img = &quot;neem.jpg&quot;
      2 processed_img = image_process(leaf_img)
----&gt; 3 imsave(&quot;BW/leaf.png&quot;, processed_img)

File C:\Python\lib\site-packages\skimage\io\_io.py:143, in imsave(fname, arr, plugin, check_contrast, **plugin_args)
    141 if check_contrast and is_low_contrast(arr):
    142     warn(f'{fname} is a low contrast image')
--&gt; 143 return call_plugin('imsave', fname, arr, plugin=plugin, **plugin_args)

File C:\Python\lib\site-packages\skimage\io\manage_plugins.py:205, in call_plugin(kind, *args, **kwargs)
    202     except IndexError:
    203         raise RuntimeError(f'Could not find the plugin &quot;{plugin}&quot; for {kind}.')
--&gt; 205 return func(*args, **kwargs)

File C:\Python\lib\site-packages\imageio\v3.py:139, in imwrite(uri, image, plugin, extension, format_hint, **kwargs)
    104 def imwrite(uri, image, *, plugin=None, extension=None, format_hint=None, **kwargs):
    105     &quot;&quot;&quot;Write an ndimage to the given URI.
    106 
    107     The exact behavior depends on the file type and plugin used. To learn about
   (...)
    136 
    137     &quot;&quot;&quot;
--&gt; 139     with imopen(
    140         uri,
    141         &quot;w&quot;,
    142         legacy_mode=False,
    143         plugin=plugin,
    144         format_hint=format_hint,
    145         extension=extension,
    146     ) as img_file:
    147         encoded = img_file.write(image, **kwargs)
    149     return encoded

File C:\Python\lib\site-packages\imageio\core\v3_plugin_api.py:367, in PluginV3.__exit__(self, type, value, traceback)
    366 def __exit__(self, type, value, traceback) -&gt; None:
--&gt; 367     self.close()

File C:\Python\lib\site-packages\imageio\plugins\pillow.py:123, in PillowPlugin.close(self)
    122 def close(self) -&gt; None:
--&gt; 123     self._flush_writer()
    125     if self._image:
    126         self._image.close()

File C:\Python\lib\site-packages\imageio\plugins\pillow.py:457, in PillowPlugin._flush_writer(self)
    454     self.save_args[&quot;save_all&quot;] = True
    455     self.save_args[&quot;append_images&quot;] = self.images_to_write
--&gt; 457 primary_image.save(self._request.get_file(), **self.save_args)
    458 self.images_to_write.clear()
    459 self.save_args.clear()

File C:\Python\lib\site-packages\PIL\Image.py:2431, in Image.save(self, fp, format, **params)
   2428         fp = builtins.open(filename, &quot;w+b&quot;)
   2430 try:
-&gt; 2431     save_handler(self, fp, filename)
   2432 except Exception:
   2433     if open_fp:

File C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1302, in _save(im, fp, filename, chunk, save_all)
   1300 except KeyError as e:
   1301     msg = f&quot;cannot write mode {mode} as PNG&quot;
-&gt; 1302     raise OSError(msg) from e
   1304 #
   1305 # write minimal PNG file
   1307 fp.write(_MAGIC)

OSError: cannot write mode F as PNG type here

</code></pre>
<p>Can someone please explain what is the problem here? and a solution will be really helpful..Thanks in advance</p>
","2023-10-07 06:06:06","1","Question"
"77244033","76173400","","<p>Similar to the env.reset(), in recent version of OpenAI gym, <code>env.step(action)</code> returns 5 elements instead of 4. replace:
<code>next_obs, reward, is_done, _= env.step(action)</code> with <code>next_obs, reward, is_done, _, _= env.step(action)</code></p>
","2023-10-06 11:21:28","0","Answer"
"77240760","77231544","","<p>I have basically the same problem, it's due to the new update 0.6.2, 0.5.1 worked fine, but basically the new version seems a bit broken. I have understood that the problem is because of the parameter n_lags, it basically tries to forecast &quot;backwards&quot;.</p>
<p>You can check this iusse:
<a href=""https://github.com/AlbertoAlmuinha/neuralprophet/issues/8"" rel=""nofollow noreferrer"">https://github.com/AlbertoAlmuinha/neuralprophet/issues/8</a></p>
<p>Basically you have to add rows for the number of n_lags at the dataframe, or alternatively going back to 0.5.1.</p>
","2023-10-05 21:44:56","0","Answer"
"77238697","76533527","","<p>Had the same problem.
In my case, where I used class, it worked when I stored the result from result_callback function (Mine is return_result) to a class variable.</p>
<pre><code>def return_result(self, result: mp.tasks.vision.HandLandmarkerResult, output_image: mp.Image, timestamp_ms: int):
        self.detection_result = result

def detect(self, image, ts=None):
    if self.input_type == 'LIVE_STREAM':
        self.detector.detect_async(image, ts)

    return self.detection_result


</code></pre>
<p>and later called the detect function to get the result.</p>
<pre><code>detectedResults = detector.detect(convertedFrame, frameNo)
</code></pre>
<p><strong>With your code, used a 'global' RESULT variable as below</strong></p>
<pre><code>import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import cv2
import time
import mediapipe as mp
import numpy as np
from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2
import numpy as np

MARGIN = 10  # pixels
FONT_SIZE = 1
FONT_THICKNESS = 1
HANDEDNESS_TEXT_COLOR = (88, 205, 54)  # vibrant green

BaseOptions = mp.tasks.BaseOptions
HandLandmarker = mp.tasks.vision.HandLandmarker
HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions
HandLandmarkerResult = mp.tasks.vision.HandLandmarkerResult
VisionRunningMode = mp.tasks.vision.RunningMode

RESULT = None


# Create a hand landmarker instance with the live stream mode:
def print_result(result: mp.tasks.vision.HandLandmarkerResult, output_image: mp.Image, timestamp_ms: int):
    # print(result)
    global RESULT
    RESULT = result


options = HandLandmarkerOptions(
    base_options=BaseOptions(model_asset_path='hand_landmarker.task'),
    running_mode=VisionRunningMode.LIVE_STREAM,
    result_callback=print_result)
with HandLandmarker.create_from_options(options) as landmarker:
    cap = cv2.VideoCapture(0)
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_np = np.array(frame)
        timestamp = int(round(time.time() * 1000))
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_np)
        frame = mp_image.numpy_view()
        landmarker.detect_async(mp_image, timestamp)
        if type(RESULT) is not type(None):
            hand_landmarks_list = RESULT.hand_landmarks
            for idx in range(len(hand_landmarks_list)):
                hand_landmarks = hand_landmarks_list[idx]

                # Draw the hand landmarks.
                hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
                hand_landmarks_proto.landmark.extend([
                    landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in
                    hand_landmarks
                ])
                solutions.drawing_utils.draw_landmarks(
                    frame,
                    hand_landmarks_proto,
                    solutions.hands.HAND_CONNECTIONS,
                    solutions.drawing_styles.get_default_hand_landmarks_style(),
                    solutions.drawing_styles.get_default_hand_connections_style())
        else:
            print('else')
        cv2.imshow('Frame', frame)
        if cv2.waitKey(1) &amp; 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()
</code></pre>
","2023-10-05 15:49:17","0","Answer"
"77231842","77223737","","<p>One of the possibilities is to use <a href=""https://pypi.org/project/webcolors/"" rel=""nofollow noreferrer"">webcolors</a> package. I modified your code to find the name of the closest matching color on the color palette:</p>
<pre><code>import cv2
import numpy as np
from PIL import Image
from sklearn.cluster import KMeans
import webcolors
from webcolors import CSS3_HEX_TO_NAMES, hex_to_rgb

image_path = &quot;Photo1.png&quot;
num_colors = 5
num_clusters = 5

def get_dominant_colors(image_path, num_colors=10, num_clusters=5):
    image = Image.open(image_path)
    image = image.resize((200, 200))
    image = image.convert('RGB')
    img_array = np.array(image)
    pixels = img_array.reshape(-1, 3)
    kmeans = KMeans(n_clusters=num_clusters, random_state=0)
    labels = kmeans.fit_predict(pixels)
    centers = kmeans.cluster_centers_
    color_counts = {}
    for label in np.unique(labels):
        color = tuple(centers[label].astype(int))
        color_counts[color] = np.count_nonzero(labels == label)
    sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)
    dominant_colors = [color for color, count in sorted_colors[:num_colors]]
    color_occurrences = [count for color, count in sorted_colors[:num_colors]]
    dominant_colors_hex = ['#%02x%02x%02x' % color for color in dominant_colors]
    return dominant_colors_hex, color_occurrences

dominant_colors, color_occurrences = get_dominant_colors(image_path, num_colors, num_clusters)

def closest_color(hex):
    colors = {}
    for key, name in CSS3_HEX_TO_NAMES.items():
        r_c, g_c, b_c = hex_to_rgb(key)
        rd = (int(hex[1:3], 16) - r_c) ** 2
        gd = (int(hex[3:5], 16) - g_c) ** 2
        bd = (int(hex[5:7], 16) - b_c) ** 2
        colors[(rd + gd + bd)] = name
    return colors[min(colors.keys())]
print(&quot;Dominant colors: &quot;)

for col in dominant_colors:
    col_name = closest_color(col)
    print(col_name)

palette_height = 100
palette_width = 100 * num_colors
palette = np.zeros((palette_height, palette_width, 3), dtype=np.uint8)

start_x = 0
for color_hex in dominant_colors:
    color_rgb = tuple(int(color_hex[i:i+2], 16) for i in (1, 3, 5))
    end_x = start_x + 100
    palette[:, start_x:end_x] = color_rgb
    start_x = end_x

palette_image = Image.fromarray(palette)
palette_bgr = cv2.cvtColor(np.array(palette_image), cv2.COLOR_RGB2BGR)

cv2.imshow(&quot;Palette&quot;, palette_bgr)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p>You can swap the color mapping from CSS3 to <a href=""https://www.webstandards.org/learn/reference/charts/color_names/index.html"" rel=""nofollow noreferrer"">HTML4</a>, for example. It includes names for the 16 base colors <a href=""https://webcolors.readthedocs.io/en/1.5/contents.html"" rel=""nofollow noreferrer"">Here you can find more.</a>
Just replace the line</p>
<pre><code>for key, name in CSS3_HEX_TO_NAMES.items():
</code></pre>
<p>with</p>
<pre><code>for key, name in HTML4_HEX_TO_NAMES.items():
</code></pre>
","2023-10-04 17:40:22","1","Answer"
"77231544","","Neural Prophet Not Predicting At All?","<p>I am trying to predict the number of customers entering a certain beach. As such, the numbers in the data tend to fluctuate, and wish to use Neural Prophet in order to predict future guests. However, with the current setup that I have for my Neural Prophet Model, the model is simply not predicting past the final date in the original data, even though for other parameters it does predict, just not accurately.</p>
<p>Here is what the predictions look like (Dashed line) vs. Original (Solid Line):
<a href=""https://i.sstatic.net/qP8SE.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>I specifically asked to forecast the next 100 days, but that's not showing at all.
Here is my set-up for the model:</p>
<pre><code> model = NeuralProphet(
        #growth=&quot;off&quot;,  # Determine trend types: 'linear', 'discontinuous', 'off'
        # changepoints=None, # list of dates that may include change points (None -&gt; automatic )
        n_changepoints=0,
        # changepoints_range=0,
        # trend_reg=0,
        # trend_reg_threshold=False,
        # # seasonality_reg=1,
        # # d_hidden = 0,
        n_lags=10,
        # # num_hidden_layers=0,     # Dimension of hidden layers of AR-Net
        # # ar_reg=None,  # Sparcity in the AR coefficients
        learning_rate=0.01,
        epochs=100,
        normalize=&quot;auto&quot;,  # Type of normalization ('minmax', 'standardize', 'soft', 'off')
        impute_missing=True,        
        yearly_seasonality=True,
        weekly_seasonality=False,
        daily_seasonality= False,
        seasonality_mode=&quot;multiplicative&quot;,
        loss_func=&quot;MSE&quot;,
    )

    # Fit the model to the training data
    model.fit(data,freq=&quot;D&quot;)  
    future = model.make_future_dataframe(data, periods=1000,n_historic_predictions=len(data))
    forecast = model.predict(future)
</code></pre>
","2023-10-04 16:52:25","2","Question"
"77225835","77184772","","<p>Consider that you are solving a regression problem. So you are working with a continuous, noncategorical variable, so calculating accuracy loses its meaning.</p>
<p>You have already used mse as a metric, alternatively you can use mean_absolute_error.</p>
<p>Replace your following code with the one below.</p>
<pre><code>plt.figure()
plt.plot(history.history['accuracy'],label='accuracy')
plt.plot(history.history['val_accuracy'],label='val_accuracy')
plt.title('accuracy')
plt.ylabel('accuracy_values')
plt.xlabel('epoch')
plt.legend()
plt.savefig(f'{path/itemName}_accuracy_plot.png')
</code></pre>
<pre><code>plt.figure()
plt.plot(history.history['mean_absolute_error'],label='mean_absolute_error')
plt.plot(history.history['val_mean_absolute_error'],label='val_mean_absolute_error')
plt.title('mean_absolute_error')
plt.ylabel('mean_absolute_value')
plt.xlabel('epoch')
plt.legend()
plt.savefig(f'{path/itemName}_mean_absolute_error_plot.png')
</code></pre>
","2023-10-03 22:33:39","0","Answer"
"77225340","77217287","","<p>The documentation did not explicitly state the support of labeling task through API requests,  but is missing listed the options on how to label your <a href=""https://cloud.google.com/document-ai/docs/workbench/label-documents#labeling_options"" rel=""nofollow noreferrer"">documents</a>:</p>
<blockquote>
<ul>
<li><p>Manual: manually label your documents in the Google Cloud console</p>
</li>
<li><p>Auto-labeling: use an existing processor version to generate labels</p>
</li>
<li><p>Document labeling tasks: lets you outsource document labeling to a team of labeling specialists</p>
</li>
<li><p>Import pre-labeled documents: save time if you already have labeled documents</p>
</li>
</ul>
</blockquote>
<p>It seems auto labeling is to be done by console's UI too, If applicable I would suggest apply labeling tasks to a labeling specialists option where you can add instructions and add pools for your specialists.</p>
<p>For the meantime I have created a feature request for this,for the visibility of other users too that may be searching for the same feature and gain traction (you may add details to the thread too): <a href=""https://issuetracker.google.com/303285767"" rel=""nofollow noreferrer"">https://issuetracker.google.com/303285767</a></p>
","2023-10-03 20:27:52","2","Answer"
"77223737","","How to extract the specific colors from an image","<p>I need some support in adding details to my code. In my code, I am just using 1 image (see attachment, called &quot;Photo1&quot;).</p>
<p>When I run the whole code, it will give me the following output:</p>
<pre><code>,&quot;Dominant Colors:
['#263f6c', '#4c5d85', '#d3d6d8', '#9db1c6', '#7388a7']&quot;
</code></pre>
<p>I don't want the output as codes, I want to know exactly which colors are the dominant colors (example: red, blue, black) and return it in a column called &quot;extracted colors&quot;</p>
<p>How can I add these details in my code?</p>
<pre><code>import cv2
import numpy as np
from PIL import Image
from sklearn.cluster import KMeans

image_path = &quot;Photo1.jpg&quot;
num_colors = 5
num_clusters = 5

def get_dominant_colors(image_path, num_colors=10, num_clusters=5):
    image = Image.open(image_path)
    image = image.resize((200, 200))
    image = image.convert('RGB')
    img_array = np.array(image)
    pixels = img_array.reshape(-1, 3)
    kmeans = KMeans(n_clusters=num_clusters, random_state=0)
    labels = kmeans.fit_predict(pixels)
    centers = kmeans.cluster_centers_
    color_counts = {}
    for label in np.unique(labels):
        color = tuple(centers[label].astype(int))
        color_counts[color] = np.count_nonzero(labels == label)
    sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)
    dominant_colors = [color for color, count in sorted_colors[:num_colors]]
    color_occurrences = [count for color, count in sorted_colors[:num_colors]]
    dominant_colors_hex = ['#%02x%02x%02x' % color for color in dominant_colors]
    return dominant_colors_hex, color_occurrences

dominant_colors, color_occurrences = get_dominant_colors(image_path, num_colors, num_clusters)

print(&quot;Dominant Colors:&quot;)
print(dominant_colors)

palette_height = 100
palette_width = 100 * num_colors
palette = np.zeros((palette_height, palette_width, 3), dtype=np.uint8)

start_x = 0
for color_hex in dominant_colors:
    color_rgb = tuple(int(color_hex[i:i+2], 16) for i in (1, 3, 5))
    end_x = start_x + 100
    palette[:, start_x:end_x] = color_rgb
    start_x = end_x

palette_image = Image.fromarray(palette)
palette_bgr = cv2.cvtColor(np.array(palette_image), cv2.COLOR_RGB2BGR)

cv2.imshow(&quot;Palette&quot;, palette_bgr)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p><img src=""https://i.sstatic.net/FjrQC.jpg"" alt=""enter image description here"" /></p>
","2023-10-03 15:47:35","0","Question"
"77217287","","In GCP's DocumentAI, when importing documents via API, is it possible to add a Document Type label?","<p>I am creating a Custom Document Classification Processor in GCP's DocumentAI platform, and am trying to understand whether it is possible to assign a Document Type label to documents when importing them to train the Processor.</p>
<p><a href=""https://stackoverflow.com/a/76535922/1940466"">This StackOverflow answer</a> notes that GCP's DocumentAI platform does expose an API to create a Dataset and upload documents to it. With that in mind, I know that it is possible to use the DocumentAI API to create a dataset, and then (as in the code below) to update that Dataset's schema with document types:</p>
<pre class=""lang-py prettyprint-override""><code>from google.cloud import documentai_v1beta3 as documentai

document_processor_service_client = documentai.DocumentProcessorServiceClient()

processor_name = 'projects/123456789/locations/us/processors/example123'

processor = document_processor_service_client.get_processor(documentai.GetProcessorRequest(name=processor_name))

dataset_schema = document_service_client.get_dataset_schema(documentai.GetDatasetSchemaRequest(name=f'{processor.name}/dataset/datasetSchema'))
dataset_schema

dataset_schema.document_schema.entity_types = [
    {
    &quot;name&quot;: &quot;test1&quot;,
    &quot;base_types&quot;: [&quot;document&quot;],
    &quot;entity_type_metadata&quot;: {
    },
    &quot;display_name&quot;: &quot;test1&quot;
  },
  {
    &quot;name&quot;: &quot;test2&quot;,
    &quot;base_types&quot;: [&quot;document&quot;],
    &quot;entity_type_metadata&quot;: {
    },
    &quot;display_name&quot;: &quot;test2
  },
    {
    &quot;name&quot;: &quot;test4&quot;,
    &quot;base_types&quot;: [&quot;document&quot;],
    &quot;entity_type_metadata&quot;: {
    },
    &quot;display_name&quot;: &quot;test4&quot;
  }
]

update_schema_request = document_service_client.update_dataset_schema(documentai.UpdateDatasetSchemaRequest(dataset_schema=dataset_schema))
</code></pre>
<p>I know that the API also allows importing one or more documents, as in this code:</p>
<pre class=""lang-py prettyprint-override""><code>import_documents_request = document_service_client.import_documents(
    documentai.ImportDocumentsRequest(
        dataset=f&quot;{processor.name}/dataset&quot;,
        batch_documents_import_configs=[
            documentai.ImportDocumentsRequest.BatchDocumentsImportConfig(
                auto_split_config=documentai.ImportDocumentsRequest.BatchDocumentsImportConfig.AutoSplitConfig(
                    training_split_ratio=0.7
                ),
                batch_input_config=documentai.BatchDocumentsInputConfig(
                    gcs_documents=documentai.GcsDocuments(
                        documents=[
                            documentai.GcsDocument(
                                gcs_uri=&quot;gs://path/to/document.pdf&quot;,
                                mime_type=&quot;application/pdf&quot;,
                            )
                        ]
                    )
                ),
            )
        ],
    ),
)
</code></pre>
<p>When manually uploading documents in Cloud Console, there is an option for applying a Document Type label to all imported documents:</p>
<p><a href=""https://i.sstatic.net/FHkK7.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/FHkK7.png"" alt=""Screenshot of &quot;Import documents&quot; interface in Cloud Console"" /></a></p>
<p><strong>I can't tell from the DocumentAI documentation: Is it possible to similarly assign a Document Type label to one or more Documents via the API? Whether during upload, or after?</strong> I have a lot of documents ready to use in a training set, and just need to give each an overall Document Type label (vs. annotating specific fields in each document), so I am looking for a way to do so programmatically, rather than manually.</p>
","2023-10-02 17:06:48","2","Question"
"77217140","77208231","","<p>@Yakov Dan answer is correct, here is another approach:</p>
<ul>
<li>Reshape the outputs of <code>ModelA</code> and <code>ModelB</code> to have the same number of frames,</li>
</ul>
<blockquote>
<p>ModelA  shape [batch size, num of features, num of frames] and<br />
ModelB has the shape [batch size, num of features, num of frames, height, width].</p>
</blockquote>
<ul>
<li>Reshape ModelB to have the same number of frames as ModelA.</li>
<li>Flatten the outputs of ModelA and ModelB along the height and width dimensions. This will convert the outputs from 5-dimensional tensors to 3-dimensional tensors, where each frame is represented as a single vector.</li>
<li>Concatenate the flattened outputs of ModelA and ModelB along the feature dimension. This will result in a tensor with the shape <code>[batch size, num of features_A + num of features_B, num of frames]</code>.</li>
</ul>
<pre class=""lang-py prettyprint-override""><code>output_modelA = torch.randn(batch_size, num_features_A, num_frames)
output_modelB = torch.randn(batch_size, num_features_B, num_frames, height, width)

# Reshape ModelB to have the same number of frames as ModelA
output_modelB = output_modelB.view(batch_size, num_features_B, num_frames, -1)

# Flatten the outputs of ModelA and ModelB
output_modelA = output_modelA.view(batch_size, num_features_A, -1)
output_modelB = output_modelB.view(batch_size, num_features_B, -1)

# Concatenate the flattened outputs along the feature dimension
concatenated_output = torch.cat((output_modelA, output_modelB), dim=1)

# Define the LSTM module

# Pass the concatenated tensor into the LSTM
</code></pre>
","2023-10-02 16:39:17","1","Answer"
"77216743","","How to solve (dependency) error on Google collab in official example for training own DDSP-VST model?","<p>I am completely new to Colab and I have been trying to get the following example to run in Colab:
<a href=""https://g.co/magenta/train-ddsp-vst"" rel=""nofollow noreferrer"">https://g.co/magenta/train-ddsp-vst</a></p>
<p>The execution (of the unchanged notebook from the link above) works until the point when DDSP is being imported and then fails with an error that looks like incompatible package versions of <code>tensorflow</code> and <code>keras</code>:</p>
<p><a href=""https://i.sstatic.net/47WKn.png"" rel=""nofollow noreferrer"">Screenshot of execution</a></p>
<p>The full error message:</p>
<pre><code>---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
/usr/local/lib/python3.10/dist-packages/ipyfilechooser/filechooser.py in _on_select_click(self, _b)
    315             if self._callback is not None:
    316                 try:
--&gt; 317                     self._callback(self)
    318                 except TypeError:
    319                     # Support previous behaviour of not passing self

12 frames
&lt;ipython-input-1-90823fe106f1&gt; in run_after_select(chooser)
    308     def run_after_select(chooser):
    309       drive_dir = chooser.selected_path
--&gt; 310       run_training(drive_dir=drive_dir)
    311 
    312     fc = FileChooser(initial_dir)

&lt;ipython-input-1-90823fe106f1&gt; in run_training(drive_dir)
    336   # Import DDSP
    337   # ------------------------------------------------------------------------------
--&gt; 338   from ddsp.colab import colab_utils
    339   globals()['colab_utils'] = colab_utils
    340 

/usr/local/lib/python3.10/dist-packages/ddsp/__init__.py in &lt;module&gt;
     17 # Module imports.
     18 from ddsp import core
---&gt; 19 from ddsp import dags
     20 from ddsp import effects
     21 from ddsp import losses

/usr/local/lib/python3.10/dist-packages/ddsp/dags.py in &lt;module&gt;
     28 import tensorflow.compat.v2 as tf
     29 
---&gt; 30 tfkl = tf.keras.layers
     31 
     32 # Define Types.

/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py in __getattr__(self, item)
     56 
     57   def __getattr__(self, item):
---&gt; 58     module = self._load()
     59     return getattr(module, item)
     60 

/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py in _load(self)
     39     &quot;&quot;&quot;Load the module and insert it into the parent's globals.&quot;&quot;&quot;
     40     # Import the target module and insert it into the parent's namespace
---&gt; 41     module = importlib.import_module(self.__name__)
     42     self._parent_module_globals[self._local_name] = module
     43 

/usr/lib/python3.10/importlib/__init__.py in import_module(name, package)
    124                 break
    125             level += 1
--&gt; 126     return _bootstrap._gcd_import(name[level:], package, level)
    127 
    128 

/usr/local/lib/python3.10/dist-packages/keras/api/__init__.py in &lt;module&gt;
      6 import sys as _sys
      7 
----&gt; 8 from keras.api import keras
      9 from tensorflow.python.util import module_wrapper as _module_wrapper
     10 

/usr/local/lib/python3.10/dist-packages/keras/api/keras/__init__.py in &lt;module&gt;
     11 
     12 from keras import __version__
---&gt; 13 from keras.api.keras import __internal__
     14 from keras.api.keras import activations
     15 from keras.api.keras import applications

/usr/local/lib/python3.10/dist-packages/keras/api/keras/__internal__/__init__.py in &lt;module&gt;
      6 import sys as _sys
      7 
----&gt; 8 from keras.api.keras.__internal__ import layers
      9 from keras.api.keras.__internal__ import legacy
     10 from tensorflow.python.util import module_wrapper as _module_wrapper

/usr/local/lib/python3.10/dist-packages/keras/api/keras/__internal__/layers/__init__.py in &lt;module&gt;
      6 import sys as _sys
      7 
----&gt; 8 from keras.engine.base_layer import BaseRandomLayer
      9 from keras.layers.preprocessing.image_preprocessing import BaseImageAugmentationLayer
     10 from tensorflow.python.util import module_wrapper as _module_wrapper

/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py in &lt;module&gt;
     34 from keras import regularizers
     35 from keras.dtensor import lazy_variable
---&gt; 36 from keras.engine import base_layer_utils
     37 from keras.engine import input_spec
     38 from keras.engine import keras_tensor

/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer_utils.py in &lt;module&gt;
     22 
     23 from keras import backend
---&gt; 24 from keras.dtensor import dtensor_api as dtensor
     25 from keras.utils import control_flow_util
     26 from keras.utils import tf_inspect

ImportError: cannot import name 'dtensor_api' from 'keras.dtensor' (/usr/local/lib/python3.10/dist-packages/keras/dtensor/__init__.py)
</code></pre>
<p>This error seems to be thrown somewhere down the line with the following import in <code>def run_training():</code></p>
<pre class=""lang-py prettyprint-override""><code>from ddsp.colab import colab_utils
</code></pre>
<p>As this happens with an official example without changes and another user posted very recently with about a <a href=""https://stackoverflow.com/questions/77176816/how-can-i-solve-this-error-on-google-colab-when-i-want-to-train-a-model-on-ddsp"">similar (the same?) issue</a>, I suspect some packages must have been updated very recently and this now causes the error.</p>
<p>To fix the error, I have tried to first uninstall and then re-install specific versions of tensorflow and/or keras but this causes further compatibility issues and pip throws an error.</p>
<p>Is there a way to fix such issues from within Colab or does this need to be fixed inside <code>ddsp.collab</code> by the maintainers?</p>
","2023-10-02 15:30:02","3","Question"
"77214493","77214404","","<p>The NaNs are correct, they are returned when you cannot compute the correlation because of NaNs. This happens when you don't have at least <strong>two</strong> common values.</p>
<p>Filling the NaNs <strong>before</strong> computation indeed doesn't make sense as this will add fake datapoints that will be used to compute the correlation.</p>
<p>What you could do is <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html"" rel=""nofollow noreferrer""><code>fillna</code></a> with <code>0</code> <strong>after</strong> the computation if you really don't want NaNs:</p>
<pre><code>out = df.T.corr().fillna(0)
</code></pre>
<p>Output:</p>
<pre><code>          Angee  Anirvesh  Jay  Karthik  Naman
Angee       1.0       1.0 -1.0      0.0    0.0
Anirvesh    1.0       1.0  1.0      1.0    0.0
Jay        -1.0       1.0  1.0      1.0    1.0
Karthik     0.0       1.0  1.0      1.0    0.0
Naman       0.0       0.0  1.0      0.0    1.0
</code></pre>
","2023-10-02 09:26:34","1","Answer"
"77214404","",".corr() method for dataframe not returning ideal values only returns either -1 or 1","<p>Ideally it should be returning values between -1 and 1 for every cell except for the cells that have the same column name and row name those need to have a 1 value</p>
<p>Tried replacing the NaN with 0 before doing corr() and it returns proper values but those values are inaccurate for the purpose of the program</p>
<pre><code># df
            MovieA    MovieB    MovieC    MovieD  MovieE
Angee     0.000000       NaN -0.500000  0.500000     NaN
Anirvesh  1.166667 -0.333333 -0.833333       NaN     NaN
Jay       1.166667 -0.333333       NaN -0.833333     NaN
Karthik   0.000000 -1.500000       NaN       NaN     1.5
Naman          NaN  0.250000       NaN -0.250000     NaN

# df.T.corr()
          Angee  Anirvesh  Jay  Karthik  Naman
Angee       1.0       1.0 -1.0      NaN    NaN
Anirvesh    1.0       1.0  1.0      1.0    NaN
Jay        -1.0       1.0  1.0      1.0    1.0
Karthik     NaN       1.0  1.0      1.0    NaN
Naman       NaN       NaN  1.0      NaN    1.0
</code></pre>
","2023-10-02 09:15:04","0","Question"
"77210898","76644713","","<p>I found this same piece of code in a YouTube tutorial and encountered the same error in the last line of code; <code>model.learn(total_timesteps=20000)</code></p>
<p>The solution that worked for me was very simple; instead of <code>gym</code> use the new <code>gymnasium</code> library. I assume the error was caused by some deprecated elements in the <code>gym</code> library, which are not properly working with the new <code>stable_baselines3</code>.</p>
<p>I have included my code below; note that this only includes the lines of code required to run the model learning. This worked for me without any errors or warnings.</p>
<pre><code>import os
import gymnasium
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv

env_name = 'CartPole-v1'
log_path = os.path.join('Training', 'Logs')

env = gymnasium.make(env_name)
env = DummyVecEnv([lambda: env])  # Wrapping the environment -&gt; vectorizing the environment
model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)  # Creating the PPO model

model.learn(total_timesteps=20000)
</code></pre>
<p>Also, remember to use <code>CartPole-v1</code> instead of <code>CartPole-v0</code>; the gymnasium library will still identify <code>CartPole-v0</code>, but better to update to the new version of the CartPole problem.</p>
<p>Moreover, once updated to <code>gymnasium</code>, the code for taking a step in the environment must be rewritten as follows.</p>
<pre><code>n_state, reward, terminated, truncated, info = env.step(action) 
done = terminated | truncated 
</code></pre>
","2023-10-01 14:25:28","0","Answer"
"77209702","77208231","","<p>You can reshape the second model's output vector such that the new number of features would be <code>num of features x height x width</code></p>
<p>Assuming that both vectors have the same batch size and the same number of frames:
First, you reorder both output vectors such that the order is <code>[batch size, num of frames, num of features, ...]</code></p>
<p>Then, you concatenate on the last dimension:</p>
<pre><code>output1 = torch.randn(10, 5, 20)
output2 = torch.randn(10, 7, 20, 100, 200)
output1 = output1.permute(0, 2, 1) 
output2 = output2.permute(0, 2, 1, 3, 4)
output = torch.concatenate([output1, output2], dim=2)

</code></pre>
<p>Now, the output tensor has all features from both output vectors together, per frame number per instance in batch which would generally make sense</p>
","2023-10-01 08:07:56","2","Answer"
"77209447","77184772","","<p>Looks like this is a forecasting problem. Because it's taking the data sequentially, the model responds to the impulsive spikes with a prediction, it's not learning to anticipate them. It looks like this was as close as your model got, and your plot is probably what your minimum loss looks like on this data.</p>
<p>Instead of accuracy, which in tensorflow/keras is a classification metric, you might try something like MSE, MAPE, etc, which would be a little closer to what I think you're looking for.</p>
","2023-10-01 06:21:51","0","Answer"
"77209166","77174989","","<p>A potential issue may arise due to a disparity between the initial input hidden layer architecture in the TensorFlow neural network model. Specifically, this layer consists of a fully connected component designed to accept input data with dimensions of (batch, num_features), whereas your input data possesses dimensions of (batch, height, width, channels). If you are not employing a Convolutional Neural Network (CNN) structure, it is advisable to consider a preprocessing step in which the input features are reshaped, effectively flattening them into the format (batch, height*width*channels).</p>
","2023-10-01 03:52:25","1","Answer"
"77208231","","How do I concatenate outputs of two different models if the shapes are completely different?","<p>I am having two pretrained models in pytorch which use different type of input data. Both of them I am using for feature extraction and want to concatenate their outputs at the end and put them into LSTM.</p>
<p>I am having the following outputs:</p>
<p>ModelA <code>[batch size, num of features, num of frames]</code></p>
<p>ModelB <code>[batch size, num of features, num of frames, height, width]</code></p>
<p>How can I concatenate them so that I can put concatenated vector into LSTM and train it. I am not sure how to do it in a way so that my concatenated vector still &quot;makes sense&quot; and does not lose any information.</p>
","2023-09-30 19:47:05","0","Question"
"77203000","76173400","","<p>In the recent versions of OpenAI gym, <code>env.reset()</code> returns a tuple of <code>(observation, info)</code> and not just <code>observation</code> like in the previous versions. So, replace <code>obs = env.reset()</code> with <code>obs, _ = env.reset()</code> and your code should start working.</p>
","2023-09-29 15:02:40","2","Answer"
"77199438","76842353","","<p>Use other parameters like copy_X, fit_intercept, n_jobs, positive and assign the values for copy_X = [True, False], fit_intercept = [True, False], n_jobs = [1,2,3] and positive = [True, False]. You will get final result of the function.</p>
<pre><code>
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor

def find_best_model_using_gridsearchcv(X,y):
    algos = {
        'linear_regression' : {
            'model': LinearRegression(),
            'params': {
                'copy_X' : [True, False],
                'fit_intercept' : [True, False],
                'n_jobs' : [1,2,3],
                'positive' : [True, False]
            }
        },
        'lasso': {
            'model': Lasso(),
            'params': {
                'alpha': [1,2],
                'selection': ['random', 'cyclic']
            }
        },
        'decision_tree': {
            'model': DecisionTreeRegressor(),
            'params': {
                'criterion' : ['mse','friedman_mse'],
                'splitter': ['best','random']
            }
        }
    }
    scores = []
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
    for algo_name, config in algos.items():
        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
        gs.fit(X,y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores,columns=['model','best_score','best_params'])

find_best_model_using_gridsearchcv(X,y)```
</code></pre>
","2023-09-29 04:21:25","0","Answer"
"77184772","","why is my predicted LSTM model shifted left as well as the accuracy 0","<p>I have seen some other posts with shifted LSTM models being shifted however looking into them I didn't find a solution.Is something wrong with how im slicing the data in the Sequential_Input function? Does anyone have any suggestions? As well as that its odd that the accuracy is a constant zero rather then some kind of more random convergence to 1.</p>
<p>Below is the code and images from the model.</p>
<pre><code>import pandas as pd
import utilities
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import sklearn as sk
import pathlib
from ItemIdEnum import item
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import TimeSeriesSplit
import seaborn as sns
from statsmodels.graphics.gofplots import qqplot
from scipy.stats import norm, uniform


def Sequential_Input_LSTM(df, input_sequence):
    df_np = df.to_numpy()
    X = []
    y = []
    
    for i in range(len(df_np) - input_sequence):
        row = [a for a in df_np[i:i + input_sequence]]
        X.append(row)
        label = df_np[i + input_sequence]
        y.append(label)
        
    return np.array(X), np.array(y)

def createLSTM(itemName: str, data: pd.DataFrame, n_input: int, n_features: int, epochs: int, batch_size: int, save: bool, savePlot: bool) -&gt; None:
    cwd = pathlib.Path().cwd()
    path = cwd.joinpath(&quot;LSTM_models/&quot;+itemName)
    try:
        path.mkdir(parents=True, exist_ok=False)
    except FileExistsError as e:
        print(e)
        pass
    
    early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 5)
    data = utilities.convertFromZuluTime(data)
    data = utilities.removeOutliers(data)

    data = data.drop(columns=['range','universe_id','http_last_modified'])
    data['issued'] = pd.to_datetime(data['issued'],origin='unix',unit='D')
    date_time = pd.to_datetime(data['issued'])
    data.set_index('issued',inplace=True)
    plt.figure()
    data['price'].hist()
    plt.savefig(f'{path/itemName}_predata_standarize_hist.png')
    plt.figure()
    data['price'].plot(ylabel='Price')
    plt.savefig(f'{path/itemName}_predata_standarize_plot.png')
    xFeat = data
   
    sc =MinMaxScaler()
    X_ft = sc.fit_transform(xFeat.values)
    X_ft = pd.DataFrame(X_ft, index=xFeat.index, columns=xFeat.columns)
    plt.figure()
    data['price'].hist()
    plt.savefig(f'{path/itemName}_postdata_standarize_hist.png')
    plt.figure()
    data['price'].plot()
    plt.savefig(f'{path/itemName}_postdata_standarize_plot.png')
    n_input = n_input  

    df_min_model_data = X_ft['price']

    X, y = Sequential_Input_LSTM(df_min_model_data, n_input)
    trainSplit = 0.8
    splitIDX = int(np.floor(len(X)*trainSplit))
    dateIndex = date_time
    XTrain, xTest = X[:splitIDX], X[splitIDX:]
    yTrain, yTest = y[:splitIDX], y[splitIDX:]
    XTrainDates, xTestDates = dateIndex[:splitIDX], dateIndex[splitIDX+10:]


    n_features = n_features

    lstm = tf.keras.models.Sequential()
    lstm.add(tf.keras.layers.InputLayer((n_input,n_features)))
    lstm.add(tf.keras.layers.LSTM(100,return_sequences=True,activation='relu'))
    lstm.add(tf.keras.layers.Dropout(0.5))
    lstm.add(tf.keras.layers.LSTM(100,return_sequences=True,activation='relu'))
    lstm.add(tf.keras.layers.LSTM(50))
    lstm.add(tf.keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal'))
    lstm.add(tf.keras.layers.Dense(1))
    lstm.compile(loss='mean_squared_error',optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError(),tf.keras.metrics.Accuracy()])
    lstm.summary()

    history = lstm.fit(XTrain,yTrain,epochs=epochs,batch_size=batch_size,shuffle=False,validation_data=(xTest,yTest), callbacks = [early_stop] )
    lstm.evaluate(xTest,yTest,verbose=0) # type: ignore
    if save == True:
        tf.keras.models.save_model(lstm, somePath&quot;)
    
    test_predictions1 = lstm.predict(xTest).flatten()

    X_test_list = []
    for i in range(len(xTest)):
        X_test_list.append(xTest[i][0])
    
    test_predictions_df1 = pd.DataFrame({'X_test':list(X_test_list), 
                                    'LSTM Prediction':list(test_predictions1)})

    test_predictions_df1.plot(title=f'{itemName} LSTM Prediction vs Actual',ylabel='Price')
    plt.show()
    
    if savePlot == True:
        plt.figure()
        test_predictions_df1.plot(title=f'{itemName} LSTM Prediction vs Actual',ylabel='Price')
        plt.savefig(f'{path/itemName}_prediction_plot.png')

        print(history.history.keys())
        plt.figure()
        plt.plot(history.history['loss'],label='loss')
        plt.plot(history.history['val_loss'],label='val_loss')
        plt.title('loss')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend()
        plt.savefig(f'{path/itemName}_loss_plot.png')
        plt.figure()
        plt.plot(history.history['accuracy'],label='accuracy')
        plt.plot(history.history['val_accuracy'],label='val_accuracy')
        plt.title('accuracy')
        plt.ylabel('accuracy_values')
        plt.xlabel('epoch')
        plt.legend()
        plt.savefig(f'{path/itemName}_accuracy_plot.png')
        plt.figure()
        plt.plot(history.history['root_mean_squared_error'],label='root_mean_squared_error')
        plt.plot(history.history['val_root_mean_squared_error'],label='val_root_mean_squared_error')
        plt.title('root_mean_squared_error')
        plt.ylabel('root_mean_squared_values')
        plt.xlabel('epoch')
        plt.legend()
        plt.savefig(f'{path/itemName}_root_mean_squared_error_plot.png')
</code></pre>
<p><a href=""https://i.sstatic.net/a6M9f.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/a6M9f.png"" alt=""RMSE"" /></a>
<a href=""https://i.sstatic.net/rKds4.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/rKds4.png"" alt=""Loss"" /></a>
<a href=""https://i.sstatic.net/WygKi.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/WygKi.png"" alt=""Accuracy"" /></a>
<a href=""https://i.sstatic.net/4ZQtt.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4ZQtt.png"" alt=""Predicted vs Test"" /></a></p>
","2023-09-27 05:00:33","0","Question"
"77175057","77029483","","<blockquote>
<p>When you use <code>tf.data.Dataset.from_tensor_slices((X, y))</code>, TensorFlow
attempts to create a dataset where each element is a pair <code>(X[i], y[i])</code>. If the dataset is too large, this can consume a significant
amount of memory, especially if X and y are large.</p>
</blockquote>
<p>To address this memory issue, we can modify the data loading process using a generator to load the data in batches, during runtime.</p>
<p>You'll have to define a generator that yields batches of data <code>(X_batch, y_batch)</code> and then to create the dataset use:</p>
<p><code>tf.data.Dataset.from_generator</code></p>
<p>Full documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""noreferrer"">here</a>.</p>
<p><strong>And an example could look like this:</strong></p>
<pre><code>import numpy as np
import tensorflow as tf

# Assume X and y are your data
X = np.random.rand(500, 1024, 1024, 3)
y = np.random.rand(500, 1024, 1024)

# Define a generator to yield batches of data
def data_generator(X, y, batch_size):
    num_samples = X.shape[0]
    for i in range(0, num_samples, batch_size):
        yield X[i:i+batch_size], y[i:i+batch_size]

# Parameters
batch_size = 16

# Create a generator
generator = data_generator(X, y, batch_size)

# Create a tf.data.Dataset using the generator
dataset = tf.data.Dataset.from_generator(
    lambda: generator,
    output_signature=(
        tf.TensorSpec(shape=(None, 1024, 1024, 3), dtype=tf.float32),
        tf.TensorSpec(shape=(None, 1024, 1024), dtype=tf.float32)
    )
)

# Model and training code would go here...
</code></pre>
","2023-09-25 18:43:33","5","Answer"
"77174989","","Tensorflow shape error: Asking for input and output shape to match?","<p>I am new to Tensorflow, and I realize there are lots of posts out there about shape issues, but I haven't been able to quite apply their solutions to my problem. So please excuse me if this is a common/redundant issue.</p>
<p>Context: I am using image data to predict the genre of an image. More specifically, I have the pixel data (50x50x3) of many images that go into 1 of 4 categories [lanscape, portrait, abstract, other].</p>
<p>Code Specifics:
I'll try to display the code that might have the problem. There's of course other code in this project, but for simplicity I will omit it (or else it would be a hard post to read); however in a follow up I will go into more detail if a solution isn't found.</p>
<p>I one-hot encoded the labels using the following</p>
<p><code>train_labels = to_categorical(train_labels, num_classes=NUM_CLASSES, dtype='float32')</code></p>
<p>Then I loaded in the pixel data by supplying a tensor object with a list of image paths, and running the <code>load_image</code> function on all the paths (not shown).</p>
<pre><code>train_data = tf.data.Dataset.from_tensor_slices((train_files, train_labels)) 
train_data = train_data.map(load_image, num_parallel_calls=AUTOTUNE) 
train_data = train_data.map(normalize, num_parallel_calls=AUTOTUNE) 
train_data = train_data.shuffle(buffer_size=shuffle_buffer_size) 
train_data = train_data.batch(batch_size)`
</code></pre>
<p>the <code>train_data</code> object appears as such:</p>
<p><code>&lt;_BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))&gt;</code></p>
<p>Which I believe makes sense because the input data is 50x50x3 (with a batch dimension) and the output dimension is 4 because of the one-hot encoding of 4 classes (with a batch dimension). The whole process and result is the same with my validation data.</p>
<p>However when I try to train my model there is a shape error:</p>
<pre><code>def simple_FFNN(image_height, image_width, num_channels, num_classes):
    input_shape = \[image_height, image_width, num_channels\] # height, width, channels
    model = Sequential()
    model.add(layers.Input(shape=input_shape))
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(units=num_classes, activation='softmax'))

    return model

learning_rate = 0.01
epochs = 3
model = simple_FFNN(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, NUM_CLASSES)
optimizer = optimizers.SGD(learning_rate=learning_rate)
loss = losses.categorical_crossentropy
model.compile(loss=loss,
optimizer=optimizer,
metrics='accuracy')

training_results = model.fit(
    train_data,
    validation_data=validation_data,
    epochs=epochs,
    verbose=1)`
</code></pre>
<p>The error is:</p>
<p><code>ValueError: Shapes (None, 4) and (None, 50, 50, 4) are incompatible</code></p>
<p>The first shape is my output shape, and the 2nd shape is ALMOST my input shape but with the number of channels slightly off... Almost like the number of classes got subbed in.</p>
<p>Anyway, I can't figure out why the output shape and input shape would have to match in the first place. I must be misunderstanding the problem. Anyone got any ideas?</p>
<p>Thanks</p>
<p>I tried removing the batching in <code>train_data.batch()</code> but then I got an error saying (None, 50, 50, 3) and (50, 50, 3) don't match (which made sense to me). Interestingly it showed (50, 50, 3) and not (50, 50, 4), so I can't figure out why the last dimension is getting swapped with a 4.</p>
","2023-09-25 18:29:13","0","Question"
"77172953","77169367","","<p>not sure exactly what you want to achieve but it seems like you want something like a dataset class in Torch. I will a link for a work I did before, hope it will work for you:</p>
<p><a href=""https://github.com/Khaliladib11/INM705-CW-Khalil-Aziz/blob/main/Semnatic%20Segmentation/CityScapes.py"" rel=""nofollow noreferrer"">https://github.com/Khaliladib11/INM705-CW-Khalil-Aziz/blob/main/Semnatic%20Segmentation/CityScapes.py</a></p>
","2023-09-25 13:11:22","2","Answer"
"77170946","77169367","","<p>You usually do have those things separately, however they should be in the same order. Let <code>X</code> be the images and <code>y</code> be the labels, then you can do this:</p>
<pre><code># allows to concatenate path fragments
from os.path import join
# allows to search for all files of a type
from glob import glob
# allows you to handle csv files
import pandas as pd

IMG_DIR = &quot;my/img/dir/&quot;

# your sorted img files
img_paths = list(sorted(glob(join(IMG_DIR, &quot;*.png&quot;)))

def read_img(path):
  # your image load method of choice
  img = ...
  return img

# all loaded imgs
imgs = [read_img(p) for p in img_paths]

# labels
df = pd.read_csv(&quot;my.csv&quot;, sep=&quot;,&quot;)
labels = list(sorted(df.sort_values(by=&quot;identifier that is the same as the image name&quot;)[&quot;mylabelcolumn&quot;].tolist()))

# this does not work if there is no 1:1 mapping from imgs to labels
len(labels) == len(img_paths)

# here, label[123] corresponds to img_paths[123] / imgs[123]


</code></pre>
<p>Note: There are many ways to load image data (OpenCV, tensorflow, pytorch, PIL, ...).</p>
<p>Note: this loads all imgs to memory... this won't work for big datasets.</p>
","2023-09-25 08:16:44","0","Answer"
"77169367","","How to attach labels to dataset in PyTorch?","<p>I am attempting to create machine learning models (GNB and decision tree models) using pytorch + tensorflow. The dataset is split into images as png files and there is a csv file with labels for each image. Each image is referenced in the csv file as e.g., img0001.png. I need the labels to be with the images rather than separate so that I can use the in the model. What is the best way to go about this?</p>
<p>'''
labels = np.array(labels)
labels = labels.reshape(1, -1)</p>
<p>model = GaussianNB()
model.fit(IMG_DIR, labels)
'''</p>
<p>error:    1203         &quot;y should be a 1d array, got an array of shape {} instead.&quot;.format(shape)
1204     )</p>
<p>ValueError: y should be a 1d array, got an array of shape (1, 656) instead.</p>
","2023-09-25 00:18:45","0","Question"
"77164153","77163685","","<p>Change your random generator to:</p>
<pre><code>import numpy as np
def gen_data(N=10):
    size = (N, 2)
    data = np.random.uniform(-1, 1, size)
    point1, point2 = np.random.uniform(-1, 1, (2,2))
    m = (point2[1] - point1[1]) / (point2[0] - point1[0])
    c = point1[1] - m * point1[0]
    labels = np.array([+1 if y &gt;= m * x + c else -1 for x, y in data])
    data = np.column_stack((data, labels))
    return data, point1, point2

</code></pre>
<p>In my simulations:</p>
<pre><code>
total = 0
for i in range(1000):
  d,x,y = gen_data()
  w = PLA(d)
  w.fit()
  print(w.count)
  total+=w.count
total/1000
</code></pre>
<p>The result is closer to 15, but with the previous generator, it can get stuck in separating the points chosen to be near the line.</p>
","2023-09-23 17:16:48","1","Answer"
"77164077","77163685","","<p>the problem is not in your right loop but in your data generation function.</p>
<p>You choose two points from the <code>N</code> random points to define your decision line:</p>
<pre><code>point1, point2 = data[np.random.choice(data.shape[0], 2, replace=False), :]
</code></pre>
<p>Yet they stay afterwards in your dataset so they are labeled 1 and are exactly on your decision line.</p>
<p>If you take two random points that are not in your dataset, then the algorithm should converge in 10 steps approximately from what I tested (just sample <code>N + 2</code> points and choose the first two to define your decision line, the others for your dataset).</p>
<p><em>So why is this small difference slowing that much the number of steps needed to converge ?</em></p>
<p>I would say that because two points in the dataset are on the decision line, it may be hardest to learn a zero error model, especially if others points are close to it as one model update may result in a still not perfect model.</p>
<p><a href=""https://i.sstatic.net/0iYnb.png"" rel=""nofollow noreferrer"">Easy case</a></p>
<p><a href=""https://i.sstatic.net/SJvEM.png"" rel=""nofollow noreferrer"">Hard case</a></p>
<p><em>Is it relevent to define your decision line such that no point in your dataset is on it ?</em></p>
<p>I would say yes as the domain space is continuous.</p>
","2023-09-23 16:58:32","3","Answer"
"77163869","77161846","","<p>Thanks to <a href=""https://stackoverflow.com/a/77163422/4794"">lejlot's patient answer</a>, I found my silly sorting bug. However, my model still didn't work.</p>
<pre><code>model = keras.Sequential(
    [layers.Conv2D(num_channels,
                   kernel_size,
                   padding='same',
                   activation='relu',
                   input_shape=(image_height, image_width, 1),
                   activity_regularizer=regularizer),
     layers.Dense(64, activation='relu'),
     layers.Dense(64, activation='relu'),
     layers.Dense(1)])
</code></pre>
<p>His model was much simpler, but I wanted to learn how to use <code>Conv2D</code> layers for more complex problems. After reading <a href=""https://www.tensorflow.org/tutorials/images/cnn"" rel=""nofollow noreferrer"">another tutorial</a> on using them for classification, I tried adding a <code>Flatten</code> layer before the <code>Dense</code> layers.</p>
<pre><code>model = keras.Sequential(
    [layers.Conv2D(num_channels,
                   kernel_size,
                   padding='same',
                   activation='relu',
                   input_shape=(image_height, image_width, 1),
                   activity_regularizer=regularizer),
     layers.Flatten(),
     layers.Dense(64, activation='relu'),
     layers.Dense(64, activation='relu'),
     layers.Dense(1)])
</code></pre>
<p>That works really well, and can fit the data in 25 epochs.</p>
<pre><code>Trained for 0:00:09.873203
           Mean absolute error [angle]
dnn_model                     4.833055
7/7 [==============================] - 0s 3ms/step
[210.474 147.593 327.796 120.112 163.402 178.04  333.604 342.488 119.694
 240.8  ]
[206.194 147.967 317.917 120.808 161.737 177.634 327.112 342.938 120.33
 231.055]
</code></pre>
<p>lejlot's recommended model is much simpler:</p>
<pre><code>model = keras.Sequential(
    [
        layers.Flatten(),
        layers.Dense(32),
        layers.Dense(1)])
</code></pre>
<p>But it doesn't perform as well, even after 300 epochs.</p>
<pre><code>Trained for 0:00:10.439293
           Mean absolute error [angle]
dnn_model                     21.22843
7/7 [==============================] - 0s 833us/step
[210.474 147.593 327.796 120.112 163.402 178.04  333.604 342.488 119.694
 240.8  ]
[225.25  156.989 325.547 123.832 111.674  89.614 308.756 331.706 122.509
 237.6  ]
</code></pre>
","2023-09-23 16:09:05","2","Answer"
"77163685","","Implementation of Perceptron algorithm, but not efficent when I run it","<p>When the sample size is set to 10, the average number of iterations until convergence should be around 15. However, when implementing the algorithm in my code, it takes approximately 225(or more!) iterations to reach convergence. This leads me to suspect that there may be an issue with the while loop in my code, but I'm unable to identify it.</p>
<pre class=""lang-py prettyprint-override""><code>def gen_data(N=10):
    size = (N, 2)
    data = np.random.uniform(-1, 1, size)
    point1, point2 = data[np.random.choice(data.shape[0], 2, replace=False), :]
    m = (point2[1] - point1[1]) / (point2[0] - point1[0])
    c = point1[1] - m * point1[0]
    labels = np.array([+1 if y &gt;= m * x + c else -1 for x, y in data])
    data = np.column_stack((data, labels))
    return data, point1, point2


class PLA:
    def __init__(self, data):
        m, n = data.shape
        self.X = np.hstack((np.ones((m, 1)), data[:, :2]))
        self.w = np.zeros(n)
        self.y = data[:, -1]
        self.count = 0

    def fit(self):
        while True:
            self.count += 1
            y_pred = self.predict(self.X)
            misclassified = np.where(y_pred != self.y)[0]
            if len(misclassified) == 0:
                break

            idx = np.random.choice(misclassified)
            self.update_weight(idx)

    def update_weight(self, idx):
        self.w +=  self.y[idx] * self.X[idx]

    def sign(self, z):
        return np.where(z &gt; 0, 1, np.where(z &lt; 0, -1, 0))

    def predict(self, x):
        z = np.dot(x, self.w)
        return self.sign(z)
</code></pre>
","2023-09-23 15:22:05","1","Question"
"77163422","77161846","","<p>The problem lies in the way you process your data. In general it is a very unsafe idea to rely on some files ordering for your ML model. Instead store inputs and corresponding labels in one spot, in a database of some sort.</p>
<pre><code> for i, image_path in enumerate(sorted(image_folder.glob('*.png'))):
        image = Image.open(image_path)
        bits = np.array(image)
        images[i, :, :] = bits
</code></pre>
<p>This specific loop is wrong, because <strong>string ordering</strong> is not the same as <strong>number ordering</strong>. So if you sort file names you will get for example</p>
<p>image234.png &lt; image3.png</p>
<p>as this is <strong>lexicographic</strong> sorting.</p>
<p>Consequently your entire data has completely shuffled labels, and thus your model can't learn anything but to predict a mean (which you see now). If you were to generate just 12 images, you would end up with something like:</p>
<pre><code>  Image1  -&gt; Label1
  Image10 -&gt; Label2
  Image11 -&gt; Label3
  Image12 -&gt; Label4
  Image2  -&gt; Label5
  Image3  -&gt; Label6
  Image4  -&gt; Labe7
  Image5  -&gt; Label8
  Image6  -&gt; Label9
  Image7  -&gt; Label10
  Image8  -&gt; Label11
  Image9  -&gt; Label12
</code></pre>
<p>One fix could be to change the loop above to</p>
<pre><code> for i in range(len(label_data)):
        image_path = image_folder / f&quot;image{i}.png&quot; # some logic here to point into the correct file using i
        image = Image.open(image_path)
        bits = np.array(image)
        images[i, :, :] = bits
</code></pre>
<p>After fixing it, you should be able to learn your mapping even with a tiny MLP, you don't even need a convolution for that.</p>
<pre><code>
    model = keras.Sequential(
        [
            layers.Flatten(),
            layers.Dense(32),
            layers.Dense(1)])
</code></pre>
<p>and training for 300 epochs gives</p>
<p><a href=""https://i.sstatic.net/VVxTo.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/VVxTo.png"" alt=""enter image description here"" /></a></p>
","2023-09-23 14:21:17","2","Answer"
"77162065","77161846","","<p>make a deeper model</p>
<pre><code>model = keras.Sequential(
    [layers.Conv2D(32,
                   3,
                   padding='same',
                   activation='relu',
                   input_shape=(image_height, image_width, 1),
                   activity_regularizer=regularizer),
     layers.Conv2D(64,
                   3,
                   padding='same',
                   activation='relu',
                   input_shape=(image_height, image_width, 1),
                   activity_regularizer=regularizer),
     layers.Dense(128, activation='relu'),
     layers.Dense(64, activation='relu'),
     layers.Dense(1)])
</code></pre>
","2023-09-23 07:33:46","-2","Answer"
"77161846","","Model structure for regression from images","<p>I'm trying to build a tensorflow model for analysing board games, so I started with a simpler 2D dataset. I generated 1000 images of black semicircles like these:</p>
<p><a href=""https://i.sstatic.net/07Ik7.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/07Ik7.png"" alt=""input image 1"" /></a> <a href=""https://i.sstatic.net/S5Gzn.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/S5Gzn.png"" alt=""input image 2"" /></a></p>
<p>I thought it would be a good exercise to try and recover the angle of the flat side. I labeled these two example images as 210.474° and 147.593°.</p>
<p>Unfortunately, the results I get are terrible. All the predictions on the test data are roughly 180°, presumably close to the mean value of the labels.</p>
<p>Can anyone give me advice on how to improve my model architecture or otherwise improve my results? If all of the input data is boolean pixels, do I need to normalize it?</p>
<p>I create the model like this:</p>
<pre><code>def build_and_compile_model():
    num_channels = 200
    kernel_size = 3
    image_height = 64
    image_width = 64
    regularizer = regularizers.l2(0.0001)

    model = keras.Sequential(
        [layers.Conv2D(num_channels,
                       kernel_size,
                       padding='same',
                       activation='relu',
                       input_shape=(image_height, image_width, 1),
                       activity_regularizer=regularizer),
         layers.Dense(64, activation='relu'),
         layers.Dense(64, activation='relu'),
         layers.Dense(1)])

    model.compile(loss='mean_absolute_error',
                  optimizer=tf.keras.optimizers.Adam(0.001))
    return model
</code></pre>
<p>When I try to fit the model, it improves for a few epochs, then stabilizes at a high error.</p>
<p><a href=""https://i.sstatic.net/2juM0.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/2juM0.png"" alt=""Plot of model training"" /></a></p>
<p>Here's the complete example:</p>
<pre><code>import math
import shutil
import typing
from datetime import datetime
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from PIL import Image, ImageDraw
import tensorflow as tf
from space_tracer import LivePillowImage
from tensorflow import keras
from tensorflow.python.keras import layers, regularizers


def build_and_compile_model():
    num_channels = 200
    kernel_size = 3
    image_height = 64
    image_width = 64
    regularizer = regularizers.l2(0.0001)

    model = keras.Sequential(
        [layers.Conv2D(num_channels,
                       kernel_size,
                       padding='same',
                       activation='relu',
                       input_shape=(image_height, image_width, 1),
                       activity_regularizer=regularizer),
         layers.Dense(64, activation='relu'),
         layers.Dense(64, activation='relu'),
         layers.Dense(1)])

    model.compile(loss='mean_absolute_error',
                  optimizer=tf.keras.optimizers.Adam(0.001))
    return model


def main():
    image_folder = Path(__file__).parent / 'circle_images'
    num_images = 1000
    image_data, label_data = read_input_data(num_images, image_folder)

    # Make NumPy printouts easier to read.
    np.set_printoptions(precision=3, suppress=True)

    image_count = image_data.shape[0]
    image_data = image_data.reshape(image_data.shape + (1, ))

    train_size = math.floor(image_count * 0.8)
    train_dataset = image_data[:train_size, :, :]
    test_dataset = image_data[train_size:, :, :]
    train_labels = label_data[:train_size]
    test_labels = label_data[train_size:]

    test_results = {}

    dnn_model = build_and_compile_model()

    print('training dataset:', train_dataset.shape)
    print('training labels:', train_labels.shape)

    start = datetime.now()
    history = dnn_model.fit(
        train_dataset,
        train_labels,
        validation_split=0.2,
        verbose=0, epochs=25)
    print('Trained for', datetime.now() - start)

    test_results['dnn_model'] = dnn_model.evaluate(test_dataset, test_labels, verbose=0)
    print(pd.DataFrame(test_results, index=['Mean absolute error [game value]']).T)

    test_predictions = dnn_model.predict(test_dataset).flatten()
    print(test_labels[:10])
    print(test_predictions[:10])

    plot_loss(history)


def create_images(num_images: int, image_folder: Path) -&gt; None:
    print(f'Creating {num_images} images.')
    image_folder.mkdir()
    start_angles = np.random.random(num_images)
    start_angles *= 360
    rng = np.random.default_rng()
    rng.shuffle(start_angles)
    for i, start_angle in enumerate(start_angles):
        image_path = image_folder / f'image{i}.png'
        image = create_image(start_angle)
        image.save(image_path)
    label_text = '\n'.join(str(start_angle) for start_angle in start_angles)
    (image_folder / 'labels.csv').write_text(label_text)


def create_image(start_angle: float) -&gt; Image.Image:
    image = Image.new('1', (64, 64))  # B&amp;W 64x64
    drawing = ImageDraw.Draw(image)
    drawing.rectangle((0, 0, 64, 64), fill='white')
    drawing.pieslice(((0, 0), (63, 63)),
                     -start_angle,
                     -start_angle+180,
                     fill='black')
    return image


def read_input_data(num_images: int, image_folder: Path) -&gt; typing.Tuple[
        np.ndarray,
        np.ndarray]:
    &quot;&quot;&quot; Read input data from the image folder.

    :returns: (images, labels)
    &quot;&quot;&quot;
    labels = []
    if image_folder.exists():
        with (image_folder / 'labels.csv').open() as f:
            for line in f:
                labels.append(float(line))
    image_count = len(labels)
    if image_count != num_images:
        # Size has changed, so recreate the input data.
        shutil.rmtree(image_folder, ignore_errors=True)
        create_images(num_images, image_folder)
        return read_input_data(num_images, image_folder)
    label_data = np.array(labels)
    images = np.zeros((image_count, 64, 64))
    for i, image_path in enumerate(sorted(image_folder.glob('*.png'))):
        image = Image.open(image_path)
        bits = np.array(image)
        images[i, :, :] = bits
    return images, label_data


def plot_loss(history):
    plt.plot(history.history['loss'], label='loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.ylim(bottom=0)
    plt.xlabel('Epoch')
    plt.ylabel('Error [angle]')
    plt.legend()
    plt.grid(True)
    plt.show()


def demo():
    image = create_image(226.634)
    LivePillowImage(image).display()


if __name__ == '__main__':
    main()
elif __name__ == '__live_coding__':
    demo()
</code></pre>
<p>At the end, I see this output:</p>
<pre><code>Trained for 0:00:09.155005
           Mean absolute error [game value]
dnn_model                         92.051697
7/7 [==============================] - 0s 4ms/step
[210.474 147.593 327.796 120.112 163.402 178.04  333.604 342.488 119.694
 240.8  ]
[177.15  181.242 181.242 181.242 181.242 181.242 181.242 181.242 181.242
 181.242]
</code></pre>
<p>You can see that all the predictions are close to 180°.</p>
","2023-09-23 06:02:33","0","Question"
"77160789","77029483","","<p>Tensorflow <code>from_tensor_slices</code> is not efficient for memory and it loads all the data to the memory as the <a href=""https://www.tensorflow.org/guide/data#consuming_numpy_arrays"" rel=""nofollow noreferrer"">documentation</a> says:</p>
<blockquote>
<p>If all of your input data fits in memory, the simplest way to create a <code>Dataset</code> from them is to convert them to <code>tf.Tensor</code> objects and use <code>Dataset.from_tensor_slices</code>.</p>
<p><strong>Note:</strong> The above code snippet will embed the features and labels arrays in your TensorFlow graph as tf.constant() operations. This works well for a small dataset, but wastes memory---because the contents of the array will be copied multiple times---and can run into the 2GB limit for the tf.GraphDef protocol buffer.</p>
</blockquote>
<p>To stream big datasets without memory limit, you can use <code>tf.data.TFRecordDataset</code> as <a href=""https://www.tensorflow.org/guide/data#consuming_tfrecord_data"" rel=""nofollow noreferrer"">documentation</a> referred.</p>
<blockquote>
<p>The <code>tf.data</code> API supports a variety of file formats so that you can process <strong>large datasets that do not fit in memory</strong>. For example, the TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data. The <code>tf.data.TFRecordDataset</code> class enables you to stream over the contents of one or more TFRecord files as part of an input pipeline.</p>
</blockquote>
<p>What you have to do is to convert your dataset to <code>TFRecord</code> format. There are some tutorials about converting datasets to TFRecord format. These links may help. <a href=""https://medium.com/nerd-for-tech/how-to-create-tensorflow-tfrecords-out-of-any-dataset-c64c3f98f4f8"" rel=""nofollow noreferrer"">link 0</a>, <a href=""https://keras.io/examples/keras_recipes/creating_tfrecords/"" rel=""nofollow noreferrer"">link 1</a>, <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md"" rel=""nofollow noreferrer"">link 2</a></p>
","2023-09-22 21:35:50","-1","Answer"
"77154334","77149319","","<p>For <code>TfidfVectorizer</code>, <code>CountVectorizer</code>, etc. in <em>scikit-learn</em>, to define your own <code>tokenizer</code>, you also need to set <code>token_pattern</code> to <code>None</code>:</p>
<pre class=""lang-py prettyprint-override""><code>vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, token_pattern=None)
</code></pre>
<p><em>scikit-learn</em> will use the <code>token_pattern</code> for tokenisation, if not specified, it will use the default value <code>r”(?u)\b\w\w+\b”</code>. this will override the <code>tokenizer</code> you define. So you need to set <code>token_pattern</code> to <code>None</code>, and <em>scikit-learn</em> will use the function you pass to <code>tokenizer</code> for the tokenization step.</p>
","2023-09-22 00:47:34","3","Answer"
"77149319","","the parameter 'token_pattern' will not be used since 'tokenizer' is not none'","<p>I am trying to remove punctuation and spaces (which includes newlines) and filter for tokens consisting of alphabetic
characters only, and return the token text.
I first define the function</p>
<pre><code>  return [t.text for t in nlp(doc) if \
          not t.is_punct and \
          not t.is_space and \
          t.is_alpha]
</code></pre>
<p>And then i vectorize</p>
<pre><code>vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)
train_feature_vects = vectorizer.fit_transform(train_data)
</code></pre>
<p>The terminal gets stuck, and says the parameter 'token_pattern' will not be used since 'tokenizer' is not none'.
What am I doing wrong?</p>
","2023-09-21 10:17:24","1","Question"
"77135923","77131746","","<p>This is most likely happening due to a network issue. You can try either of the following solutions:</p>
<p><strong>1.</strong> Add the following in your script:</p>
<pre><code>import nltk
import ssl

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

nltk.download('punkt')
</code></pre>
<p><strong>2.</strong> If the above solution doesn't help, then:</p>
<ul>
<li>Manually download <code>'punkt'</code> from <a href=""https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/tokenizers/punkt.zip"" rel=""nofollow noreferrer"">here</a>.</li>
<li>Unzip the file and then go to <code>'C:/Users/adars/AppData/Local/Programs/Python/Python310/lib/'</code> where you need to create a folder named <code>nltk_data</code>.</li>
<li>Under <code>nltk_data</code>, create another folder named <code>tokenizers</code> and place the extracted folder <code>punkt</code> there so that you get a new directory <code>tokenizers/punkt</code> which would contain all the <code>.pickle</code> files.</li>
<li>Once that's done, you don't need to do <code>nltk.download('punkt')</code>
again, just directly run your code.</li>
</ul>
","2023-09-19 15:26:07","3","Answer"
"77133324","77131746","","<ol>
<li>just open any prompt or anaconda prompt &amp; activate env in which your running the script</li>
<li>type python</li>
<li>press enter</li>
<li>execute <code>import nltk</code></li>
<li><code>nltk.download('punkt')</code></li>
</ol>
<p>onced downloaded you can continue with your code ide</p>
","2023-09-19 09:29:05","0","Answer"
"77131746","","How to download punkt tokenizer in nltk?","<p>I installed the NLTK library using</p>
<pre><code>pip install nltk
</code></pre>
<p>and while using the lib</p>
<pre><code>from nltk.tokenize import sent_tokenize 
sent_tokenize(text)
</code></pre>
<p>I am getting this error</p>
<pre><code>LookupError: 
**********************************************************************
  Resource punkt not found.
  Please use the NLTK Downloader to obtain the resource:

  &gt;&gt;&gt; import nltk
  &gt;&gt;&gt; nltk.download('punkt')
  
  For more information see: https://www.nltk.org/data.html

  Attempted to load tokenizers/punkt/english.pickle

  Searched in:
    - 'C:\\Users\\adars/nltk_data'
    - 'C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\nltk_data'
    - 'C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\share\\nltk_data'
    - 'C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\nltk_data'
    - 'C:\\Users\\adars\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - ''
</code></pre>
<p>So in order to solve this error i tried</p>
<pre><code>import nltk
nltk.download('punkt')
</code></pre>
<p>but then i am unable to download this package because everytime i run this i get error that says</p>
<pre><code>[nltk_data] Error loading punkt: &lt;urlopen error [WinError 10060] A
[nltk_data]     connection attempt failed because the connected party
[nltk_data]     did not properly respond after a period of time, or
[nltk_data]     established connection failed because connected host
[nltk_data]     has failed to respond&gt;
</code></pre>
<p>please help me out here</p>
","2023-09-19 04:36:59","4","Question"
"77126285","77126001","","<p>SHAP is guaranteed to be additive in raw space (logits). To understand why additivity in raw scores doesn't extend to additivity in class predictions you may think for a while why <code>exp(x+y) != exp(x) + exp(y)</code></p>
<p><strong>Re: Just keen to understand how was explainer.expected_value calculated for XGBoost classifier. Do you happen to know?</strong></p>
<p>As I stated in comments expected value comes either from the model trees or from your data.</p>
<p>Let's try reproducible:</p>
<pre><code>from sklearn.model_selection import train_test_split
import xgboost
import shap

X, y = shap.datasets.adult()
X_display, y_display = shap.datasets.adult(display=True)

# create a train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)
d_train = xgboost.DMatrix(X_train, label=y_train)
d_test = xgboost.DMatrix(X_test, label=y_test)

params = {
    &quot;eta&quot;: 0.01,
    &quot;objective&quot;: &quot;binary:logistic&quot;,
    &quot;subsample&quot;: 0.5,
    &quot;base_score&quot;: np.mean(y_train),
    &quot;eval_metric&quot;: &quot;logloss&quot;,
}
model = xgboost.train(
    params,
    d_train,
    num_boost_round=5000,
    evals=[(d_test, &quot;test&quot;)],
    verbose_eval=100,
    early_stopping_rounds=20,
)
</code></pre>
<h2>Case 1. No data available, trees only.</h2>
<pre><code>explainer = shap.TreeExplainer(model)
ev_trees = explainer.expected_value[0]

from shap.explainers._tree import XGBTreeModelLoader

xgb_loader = XGBTreeModelLoader(model)
ts = xgb_loader.get_trees()

v = []
for t in ts:
    v.append(t.values[0][0])
sv = sum(v)

import struct
from scipy.special import logit
size = struct.calcsize('f')
buffer = model.save_raw().lstrip(b'binf')
v = struct.unpack('f', buffer[0:0+size])[0]
# if objective &quot;binary:logistic&quot; or &quot;reg:logistic&quot; 
bv = logit(v)

ev_trees_raw = sv+bv

np.isclose(ev_trees, ev_trees_raw)
</code></pre>
<hr />
<pre><code>True
</code></pre>
<h2>Case 2. Background data set supplied.</h2>
<pre><code>background = X_train[:100]

explainer = shap.TreeExplainer(model, background)
ev_background = explainer.expected_value
</code></pre>
<p>Take a note that:</p>
<pre><code>np.isclose(ev_trees, ev_background)
</code></pre>
<hr />
<pre><code>False
</code></pre>
<p>but</p>
<pre><code>d_train_background = xgboost.DMatrix(background, y_train[:100])
preds = model.predict(d_train_background, pred_contribs = True)

np.isclose(ev_background, preds.sum(1).mean())
</code></pre>
<hr />
<pre><code>True
</code></pre>
<p>or simply</p>
<pre><code>output_margin = model.predict(d_train_background, output_margin=True)
np.isclose(ev_background, output_margin.mean())
</code></pre>
<hr />
<pre><code>True
</code></pre>
","2023-09-18 10:05:34","3","Answer"
"77126001","","Calculation of expected_value in SHAP explanations of XGBoost Classifier","<p>How do we make sense of SHAP <code>explainer.expected_value</code>? Why is it not the same with <code>y_train.mean()</code> after sigmoid transformation?</p>
<p>Below is a summary of the code for quick reference. Full code available in this notebook: <a href=""https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb"" rel=""nofollow noreferrer"">https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb</a></p>
<pre><code>model = xgb.XGBClassifier()
model.fit(X_train, y_train)
explainer = shap.Explainer(model)
shap_test = explainer(X_test)
shap_df = pd.DataFrame(shap_test.values)

#For each case, if we add up shap values across all features plus the expected value, we can get the margin for that case, which then can be transformed to return the predicted prob for that case:
np.isclose(model.predict(X_test, output_margin=True),explainer.expected_value + shap_df.sum(axis=1))
#True
</code></pre>
<p>But why isn't the below true? Why after sigmoid transformation, the <code>explainer.expected_value</code> is not the same with <code>y_train.mean()</code> for XGBoost classifiers?</p>
<pre><code>expit(explainer.expected_value) == y_train.mean()
#False
</code></pre>
","2023-09-18 09:28:55","2","Question"
"77101463","77101192","","<p>This is happening due to the newer version of diffusers library.
At the very start, run <code>pip install diffusers==0.20.2</code> and then execute the cells.</p>
","2023-09-14 02:40:25","7","Answer"
"77101192","","cannot import name 'randn_tensor' from 'diffusers.utils'","<p><a href=""https://i.sstatic.net/akrEb.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/akrEb.png"" alt=""enter image description here"" /></a></p>
<p>I was using this autotrain collab and when i labbelled and put my images into images folder and tried to run it , It says this error how do i solve this ?</p>
<p>to reproduce :</p>
<ol>
<li><p>click link of ipynb</p>
</li>
<li><p>make a new folder name images</p>
</li>
<li><p>add some images and replace the prompt to something which describes your images</p>
</li>
<li><p>go to runtime and run all</p>
</li>
</ol>
<p><a href=""https://colab.research.google.com/github/huggingface/autotrain-advanced/blob/main/colabs/AutoTrain_Dreambooth.ipynb"" rel=""noreferrer"">ipynb link</a></p>
","2023-09-14 00:51:19","5","Question"
"77100654","","CUDA not working with TensorFlow after install on new computer ""ptxas returned an error during compilation of ptx to sass""","<p>I have been struggling with getting CUDA to work on my new computer with Windows 11. After I installed drivers, tensorflow, CUDA, and cuDNN I got this error when trying to train my model.
My versions are these:
CUDA: 11.2, cuDNN: 8.9, TensorFlow: 2.10, python 3.10</p>
<p>At first I attempted to install it with miniconda, which I hadn't done before, but it did not work, so I uninstalled it and downloaded python 3.10 and tried again, importing everything back and reinstalling CUDA and cuDNN. I also added CUDA to path:</p>
<p>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\bin
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\libnvvp</p>
<p>Here's the full log:</p>
<pre><code>2023-09-13 23:15:01.935221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-13 23:15:02.279467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9392 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (24, 64)                  20736     
                                                                 
 batch_normalization (BatchN  (24, 64)                 256       
 ormalization)                                                   
                                                                 
 dropout (Dropout)           (24, 64)                  0         
                                                                 
 dense (Dense)               (24, 8)                   520       
                                                                 
 batch_normalization_1 (Batc  (24, 8)                  32        
 hNormalization)                                                 
                                                                 
 dropout_1 (Dropout)         (24, 8)                   0         
                                                                 
 dense_1 (Dense)             (24, 1)                   9         
                                                                 
=================================================================
Total params: 21,553
Trainable params: 21,409
Non-trainable params: 144
_________________________________________________________________
2023-09-13 23:15:03.550772: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4608000000 exceeds 10% of free system memory.
Epoch 1/10
2023-09-13 23:15:06.027973: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8905
Could not load symbol cublasGetSmCountTarget from cublas64_11.dll. Error code 127
2023-09-13 23:15:06.342783: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-09-13 23:15:06.385428: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x22167e1f550 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-09-13 23:15:06.385546: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9
2023-09-13 23:15:06.389863: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-09-13 23:15:06.470150: F tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:453] ptxas returned an error during compilation of ptx to sass: 'INTERNAL: ptxas exited with non-zero error code -1, output: '  If the error message indicates that a file could not be written, please verify that sufficient filesystem space is provided.



Process finished with exit code -1073740791 (0xC0000409)
</code></pre>
<p>Here's my code:</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import AdamW
import tensorflow as tf
import data_formatting
import pandas as pd
from sklearn.preprocessing import Normalizer



data = 'data/'
X_train, y_train, X_cv, y_cv, X_test, y_test, init_bias, class_weight = data_formatting.transform(data=data)
output_bias = tf.keras.initializers.Constant(init_bias)
model1 = Sequential([
    InputLayer(batch_input_shape=(24, 300, 16)),
    LSTM(units=64, stateful=True),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    Dense(units=8, activation='tanh', kernel_regularizer=tf.keras.regularizers.L2(0.16)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    Dense(units=1, activation='sigmoid', bias_initializer=output_bias)
])

model1.summary()

cp = ModelCheckpoint('ModelTest/', save_best_only=True)


model1.compile(loss=BinaryCrossentropy(), optimizer=AdamW(learning_rate=0.0001), metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])

model1.fit(X_train, y_train, validation_data=(X_cv, y_cv), epochs=10, batch_size=24, callbacks=[cp], class_weight=class_weight)
</code></pre>
<p>I have clicked on just about every link when I copy in the final error message with ptxas, and can't seem to find a solution.</p>
","2023-09-13 21:41:04","0","Question"
"77094436","75814047","","<p>you can create batch file eg script.sh for running on 8 gpus.</p>
<pre><code>#! /bin/bash
#SBATCH -N 1
#SBATCH --ntasks-per-node=256
#SBATCH --gres=gpu:A100-SXM4:8
#SBATCH --time=35:00:00
#SBATCH --error=job.%J.err
#SBATCH --output=job.%J.out

echo &quot;Starting at `date`&quot;
echo &quot;Running on hosts: $SLURM_NODELIST&quot;
echo &quot;Running on $SLURM_NNODES nodes.&quot;
echo &quot;Running $SLURM_NTASKS tasks.&quot;
echo &quot;Job id is $SLURM_JOBID&quot;
echo &quot;Job submission directory is : $SLURM_SUBMIT_DIR&quot;
cd $SLURM_SUBMIT_DIR


#activating environment
source Conda/bin/activate
conda activate trocr1

#python script for running. 

python -m torch.distributed.launch \
    --nproc_per_node 8 demo.py \     #num_gpu
    --tokenizer processor.feature_extractor\
    --args training_args\
    --compute_metrics compute_metrics\
    --train_dataset train_dataset\
    --eval_dataset eval_dataset\
    --data_collator default_data_collator\
    --predict_with_generate True\
    --evaluation_strategy &quot;epoch&quot;\
    --save_strategy &quot;epoch&quot;\
    --load_best_model_at_end True\
    --greater_is_better False\
    --metric_for_best_model &quot;eval_cer&quot;\
    --per_device_train_batch_size 8\
    --per_device_eval_batch_size 8\
    --fp16 False\
    --bf16 True\
    --output_dir &quot;./model/&quot;\
    --num_train_epochs 5\
    --save_total_limit 3\
    --warmup_steps 500\
    --weight_decay 0.01\
    --logging_steps 10000\
    --save_steps 5000\
    --eval_steps 5000\
    --report_to 'tensorboard'\
    --seed 42
</code></pre>
<p>then submit this file using &quot;sbatch script.sh&quot; command on terminal.
I used this for fine tuning trocr mode using HF Trainer. And it worked.
I was using dgx server.</p>
<p>This helped me a lot</p>
<p><a href=""https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling"" rel=""nofollow noreferrer"">https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling</a></p>
<p><a href=""https://github.com/huggingface/transformers/tree/main/examples/pytorch#distributed-training-and-mixed-precision"" rel=""nofollow noreferrer"">https://github.com/huggingface/transformers/tree/main/examples/pytorch#distributed-training-and-mixed-precision</a></p>
<p>or if you want to go with the interactive session, request for resources using command, after allocation just run the python script. Change specifications in script.sh as per your server.</p>
","2023-09-13 06:09:52","0","Answer"
"77094149","","How to use both gpus in kaggle for training in pytorch?","<p>I was training a model in kaggle gpu.
But as I can see only one GPU is working.
<a href=""https://i.sstatic.net/8E0H3.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/8E0H3.png"" alt=""enter image description here"" /></a>
I use the ordinary method for training like</p>
<pre class=""lang-py prettyprint-override""><code>device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model = model.to(device)
</code></pre>
<p>How can I use both the gpus?</p>
","2023-09-13 04:56:24","3","Question"
"77084813","77068899","","<p>Thanks to help from @Sandipan Dey, @Tal Galili and @r2evans I have a plot I'm happy with. I figured I would post my final plot and code block here just so others could see it. I still have pretty bad data but the code should be usable for smaller more managebale datasets in any case</p>
<p>Here is my code</p>
<pre><code># Load in relevant packages
library(ggplot2)
library(ggdendro)
library(scales)

# Load in phenograph data using read.csv then store it as a dataframe
CSV &lt;- (read.csv(&quot;~/TotalPercentage.csv&quot;, header=TRUE))
TotalPercentage &lt;- as.data.frame(CSV)

# Cluster your data using hclust, type of clustering can be specified if desired
## The only thing that needs to be changed here is [5:43], 
###just tell it which columns you want to consider for clustering
tree &lt;- hclust(dist(TotalPercentage[5:43]))
tree &lt;- dendro_data(tree)

# Here you same as above change [,5:43] to the colums you want to consider
## Scale defines the size of the tree on the X axis, this can be modulated per preference
data &lt;- cbind(TotalPercentage, x = match(rownames(TotalPercentage), tree$labels$label))
data[,5:43] &lt;- data[,5:43] / rowSums(data[,5:43]) # row-normalize
scale &lt;- 3e-3

##ggplot allows us to make our graph, Look for # to see why certain commands are there
ggplot() +
  geom_col(
    # Be sure to change (,5:43) as above so it fits your data
    # Here we are making our data more readble to R by making it &quot;longer&quot; and using that to make a bar graph
    data = tidyr::pivot_longer(data, c(,5:43)),
    aes(x = x,
        y = value, fill = factor(name)),
  ) +
   # These are our labels, you can specify the labels, not the x and y axis are flipped because we use the coordflip() function in the last line
   ## To be honest I dont love how this looks and will try to fix the presentation in the 
   labs(title=&quot;Unsupervised Clustering of Phenograph Output&quot;,
       y =&quot;Cluster Representation (%)&quot;, x = &quot;Participant Sample&quot;
  ) +
  # Here we attach the tree to the bar graph and specify where it goes using y = and yend = 
  ## I personally like how this looks but if you wanted your tree on the left that can be done
  geom_segment(
    data = tree$segments,
    aes(x = x, y = y * scale + 1, xend = xend, yend = yend * scale + 1)
  ) +
 
  # Here we add the labels for each sample next to its respective bar and also do some formatting
  geom_text(data = label(tree), 
    aes(x = x, y = y, label = data$Cluster, hjust = 1), 
    size = 3
  ) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank()
  ) +
  scale_y_continuous(limits=c(-.5,1.5), labels = scales::percent, breaks = c(0, .50, 1.00)) +
  
  # I couldn't figure out a better way to do this but here I label each cluster 
  ## If you do the work to determine what is in each cluster you can replace for example 'Cluster 1' with 'CD4+ proliferating cells'
  scale_fill_discrete(labels=c('Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4',
                               'Cluster 5', 'Cluster 6', 'Cluster 7', 'Cluster 8',
                               'Cluster 9', 'Cluster 10', 'Cluster 11', 'Cluster 12',
                               'Cluster 13', 'Cluster 14', 'Cluster 15', 'Cluster 16',
                               'Cluster 17', 'Cluster 18', 'Cluster 19', 'Cluster 20',
                               'Cluster 21', 'Cluster 22', 'Cluster 23', 'Cluster 24',
                               'Cluster 25', 'Cluster 26', 'Cluster 27', 'Cluster 28',
                               'Cluster 29', 'Cluster 30', 'Cluster 31', 'Cluster 32',
                               'Cluster 33', 'Cluster 34', 'Cluster 35', 'Cluster 36',
                               'Cluster 37', 'Cluster 38', 'Cluster 39')
                      ) +
  guides(fill=guide_legend(title=&quot;Cluster&quot;)) +
  # some final formatting, I think the plot looks better left to right so I went with coord_flip which moves it on its side
  theme(
  axis.text.y = element_blank(),
  axis.ticks.y = element_blank()
  ) +
  coord_flip()
</code></pre>
<p>And here is the plot it gave me
<a href=""https://i.sstatic.net/UaFU0.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/UaFU0.png"" alt="""" /></a></p>
","2023-09-11 21:15:25","1","Answer"
"77081186","77077474","","<p>Here's the updated/ working version,</p>
<pre><code>import pandas as pd

def evaluate_preds(y_true, y_preds):
    &quot;&quot;&quot;
    Performs Evaluation comp on y_true labels and y_preds labels on a classification
    &quot;&quot;&quot;
    accuracy = accuracy_score(y_true,y_preds)
    precision = precision_score(y_true,y_preds)
    recall = recall_score(y_true,y_preds)
    f1 = f1_score(y_true,y_preds)
    metric_dict = {&quot;accuracy&quot;: round(accuracy,2),
                      &quot;precision&quot;: round(precision,2),
                      &quot;recall&quot;: round(recall,2),
                      &quot;f1&quot;: round(f1,2)}
    
    print(f&quot;Accuracy :{ accuracy *100:.2f}%&quot;)
    print(f&quot;Precision :{ precision:.2f}&quot;)
    print(f&quot;Recall :{ recall:.2f}&quot;)
    print(f&quot;F1 :{ f1:.2f}&quot;)
    return metric_dict
</code></pre>
<p>
<pre><code>from sklearn.ensemble import RandomForestClassifier

np.random.seed(42)

heart_disease_shuffled= heart_disease.sample(frac=1)

X= heart_disease_shuffled.drop(&quot;target&quot;,axis =1)
y = heart_disease_shuffled[&quot;target&quot;]

train_split = round(0.7 * len(heart_disease_shuffled))
valid_split = round(train_split + 0.15 * len(heart_disease_shuffled))

X_train,y_train = X[:train_split], y[:train_split]
X_valid,y_valid = X[train_split:valid_split], y[train_split:valid_split]

X_test,y_test = X[valid_split:], y[:valid_split]

clf = RandomForestClassifier()
clf.fit(X_train,y_train)

# Make Baseline preds
y_preds = clf.predict(X_valid)
# Evaluate classifier on validation set
baseline_metrics = evaluate_preds(y_valid, y_preds) 
baseline_metrics
 
</code></pre>
","2023-09-11 11:21:52","0","Answer"
"77077608","77077474","","<p>You are trying to print functions instead of the values they return. For instance, you assign</p>
<pre><code>accuracy = accuracy_score(y_true,y_preds)
</code></pre>
<p>but then try to format the function, not the result</p>
<pre><code>f&quot;Accuracy :{ accuracy_score*100:.2f}%&quot;
</code></pre>
<p>Instead, you should use the calculated value</p>
<pre><code>f&quot;Accuracy :{ accuracy*100:.2f}%&quot;
</code></pre>
<p>But you've also created a dictionary with rounded values. You could use that dictionary with an f-string or use the <code>.format</code> method instead</p>
<pre><code>f&quot;Accuracy :{ metric_dict['accuracy']:.2f}&quot;
# -- or --
&quot;Accuracy : {accuracy:.2f}&quot;.format(**metric_dict)
</code></pre>
","2023-09-10 19:28:31","0","Answer"
"77077474","","TypeError:unsupported format string passed to function .__format__","<p>Working on jupyter notebooks, I came across this problem:</p>
<pre><code>TypeError:unsupported format string passed to function .__format__
</code></pre>
<p>This is where the code starts:</p>
<pre><code>def evaluate_preds(y_true, y_preds):
    &quot;&quot;&quot;
    Performs Evaluation comp on y_true labels and y_preds labels on a classification
    &quot;&quot;&quot;
    accuracy = accuracy_score(y_true,y_preds)
    precision = precision_score(y_true,y_preds)
    recall = recall_score(y_true,y_preds)
    f1 = f1_score(y_true,y_preds)
    metric_dict = {&quot;accuracy&quot;: round(accuracy,2),
                  &quot;precision&quot;: round(precision,2),
                  &quot;recall&quot;: round(recall,2),
                  &quot;f1&quot;: round(f1,2)}

    print(f&quot;Accuracy :{ accuracy_score*100:.2f}%&quot;)
    print(f&quot;Precision :{ precision_score:.2f}&quot;)
    print(f&quot;Recall :{ recall_score:.2f}&quot;)
    print(f&quot;F1 :{ f1_score:.2f}&quot;)

    return metric_dict
</code></pre>
<p>This below code is being run on a different cell in jupyter notebook</p>
<pre><code>from sklearn.ensemble import RandomForestClassifier

np.random.seed(42)

heart_disease_shuffled= heart_disease.sample(frac=1)

X= heart_disease_shuffled.drop(&quot;target&quot;,axis =1)
y = heart_disease_shuffled[&quot;target&quot;]

train_split = round(0.7 * len(heart_disease_shuffled))
valid_split = round(train_split + 0.15 * len(heart_disease_shuffled))

X_train,y_train = X[:train_split], y[:train_split]
X_valid,y_valid = X[train_split:valid_split], y[train_split:valid_split]

X_test,y_test = X[valid_split:], y[:valid_split]

clf = RandomForestClassifier()
clf.fit(X_train,y_train)


# Make Baseline preds

y_preds = clf.predict(X_valid)

# Evaluate classifier on validation set

baseline_metrics = evaluate_preds(y_valid, y_preds) 
baseline_metrics
</code></pre>
<p>How can I resolve it?</p>
<p>Tried changing the parameters and a bunch of other things but all of them popped up some errors like the one listed above</p>
","2023-09-10 18:48:31","0","Question"
"77071166","77068899","","<p>Something like this, with randomly generated data:</p>
<pre><code># randomly generated phenograph data
set.seed(1)
TotalPercentage &lt;- data.frame(
  `Participant ID` = c(&quot;123&quot;, &quot;456&quot;, &quot;789&quot;),
  `1` = 125*runif(72),
  `2` = 75*runif(72),
  `3` = 175*runif(72),
  `4` = 10*runif(72),
  `5` = 100*runif(72),
  `6` = 150*runif(72),
  `7` = 200*runif(72)
)
</code></pre>
<p>Now cluster, normalize and plot:</p>
<pre><code>tree &lt;- hclust(dist(TotalPercentage))
tree &lt;- dendro_data(tree)
data &lt;- cbind(TotalPercentage, x = match(rownames(TotalPercentage), tree$labels$label))
data[,2:8] &lt;- data[,2:8] / rowSums(data[,2:8]) # row-normalize
scale &lt;- 3e-4
ggplot() +
  geom_col(
    data = tidyr::pivot_longer(data, c(2, 3 , 4, 5, 6, 7, 8)),
    aes(x = x,
        y = value, fill = factor(name)),
  ) +
  labs(title=&quot;Unsupervised Clustering of Phenograph Output&quot;,
       x =&quot;Cluster Representation (%)&quot;, y = &quot;Participant Sample&quot;
  ) +
  geom_segment(
    data = tree$segments,
    aes(x = x, y = -y * scale, xend = xend, yend = -yend * scale)
  ) +
  coord_flip()
</code></pre>
<p><a href=""https://i.sstatic.net/Dk3av.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Dk3av.png"" alt=""enter image description here"" /></a></p>
","2023-09-09 06:59:35","1","Answer"
"77068899","","How to add categorical variables to a percentage stacked bar chart?","<p>First time posting here so let me know if I left out any details that are normally included.
I am using ggplot2 and ggdendro to make a stacked bar percentage chart with a heirarchical clustered tree where each node is associated with one of my bars.</p>
<p><img src=""https://i.sstatic.net/f5XmB.png"" alt=""1"" /></p>
<p>As you can see I have more or less figured this out (note this is just a subset of my data. I now want to associate a categorical variable with each my bars, where each variable would be represented by a color (in my case this is HIV+ or HIV- and each bar represents % of cells in a given category). Additionally I want to figure out how to add the sample name to each dendrogram node but this issue is less pressing.
Below is the code block I am using.</p>
<pre><code>library(ggplot2)
library(ggdendro)

# Load in phenograph data
TotalPercentage &lt;- read.csv(&quot;~/TotalPercentage.csv&quot;, header=TRUE)

#generate tree
tree &lt;- hclust(dist(TotalPercentage))
tree &lt;- dendro_data(tree)

data &lt;- cbind(TotalPercentage, x = match(rownames(TotalPercentage), tree$labels$label))



# plot below stacked bar, in &quot;data = tidyr::pivot_longer(data, c(2...&quot; include
## all columns (clusters) but exclude colun 1 as this value is our sample ID

scale &lt;- .5
p &lt;- ggplot() +
  geom_col(
    data = tidyr::pivot_longer(data, c(2, 3 , 4, 5, 6, 7, 8)),
    aes(x = x,
        y = value, fill = factor(name)),
  ) +
  labs(title=&quot;Unsupervised Clustering of Phenograph Output&quot;,
          x =&quot;Cluster Representation (%)&quot;, y = &quot;Participant Sample&quot;
  ) +
  geom_segment(
    data = tree$segments,
    aes(x = x, y = -y * scale, xend = xend, yend = -yend * scale)
  )

p
</code></pre>
<p>Here is a sample dataset with fewer rows for simplicity</p>
<pre class=""lang-r prettyprint-override""><code>data.frame(
  `Participant ID` = c(&quot;123&quot;, &quot;456&quot;, &quot;789&quot;),
  `1` = c(.1933, .1721, 34.26),
  `2` = c(20.95, 4.97, 2.212),
  `3` = c(11.31, 35.34, .027),
  `4` = c(35.55, 15.03, 0),
  `5` = c(.26, .87, 7.58),
  `6` = c(12.85, 33.44, .033),
  `7` = c(2.04, 3.77, 4.32)
)
</code></pre>
<p>Where Patient one and three have HIV but patient 2 is HIV negative</p>
<p>And finally here is an example of what I am ultimately trying to produce</p>
<p>(<a href=""https://i.sstatic.net/uAWxR.png"" rel=""nofollow noreferrer"">https://i.sstatic.net/uAWxR.png</a>)</p>
<p>I've looked all over to see how to do this but I'm new to R so I'm kind of free floating and don't know what to do next. Thanks in advance for any help.</p>
","2023-09-08 17:36:00","2","Question"
"77065006","76633836","","<p>Similar to <code>CharacterTextSplitter</code>, <code>RecursiveCharacterTextSplitter</code> module explains with more sense to me.</p>
<p><strong>Recursively split by character</strong></p>
<blockquote>
<p>This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to <strong>split on them in order until the chunks are small enough</strong>. The default list is [&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;]. This has the effect of trying to <strong>keep all paragraphs (and then sentences, and then words) together as long as possible</strong>, as those would generically seem to be the strongest <strong>semantically</strong> related pieces of text.</p>
</blockquote>
<p>Reference &gt; <a href=""https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter"" rel=""noreferrer"">https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter</a></p>
","2023-09-08 07:40:39","5","Answer"
"77061898","","Incomplete Output with LLM with max_new_tokens","<p>I am experimenting with Huggingface LLM models.</p>
<p>And one issue I noticed is that output of the model ends abruptly and I ideally want it to complete the paragraph/sentences/code which it was it between of. (or altogether try to complete the answer within some fixed num of tokens)</p>
<p>Although I have provided max_new_tokens = 300 and also in prompt I write:
&quot;Output should be maximum of 300 words.&quot;</p>
<p>The response is always incomplete and ends abruptly. Any way I can ask for a complete output within desired number of output tokens?</p>
<p>Code:</p>
<pre><code>checkpoint = &quot;HuggingFaceH4/starchat-alpha&quot;
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot; 
class StarCoderModel:
  def __init__(self):
    self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)
    # make sure `--gpus all` is provided in docker run command if gpu is required
    self.model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map='auto')

  def infer(self, input_text, token_count):
    inputs = self.tokenizer.encode(input_text, return_tensors=&quot;pt&quot;).to(device)
    outputs = self.model.generate(inputs,  max_new_tokens=token_count, pad_token_id=self.tokenizer.eos_token_id)
    return self.tokenizer.decode(outputs[0])[len(input_text):]
</code></pre>
<p>Sample-Output:</p>
<pre><code>private DataType FuntionName(String someId) {
    // TODO: Replace with implementation that utilizes someId to obtain information
    return DataType.Value;
}


The comment:

- If someId is present in the code, use the getAPI from Client with someId as a parameter to obtain some information.
- If the

</code></pre>
","2023-09-07 18:02:00","2","Question"
"77055022","75883084","","<p>Had the same issue and at first I was unable to resolve it. What eventually worked for me was the following (Note this appears to be a predominant problem on machines with the M1/M2 chip):</p>
<p>I created a virtual environment folder using the Terminal where I will store all environments. Later you can pass it to VS Code:</p>
<pre><code>$ pip install virtualenv
$ cd ~
$ mkdir .virtualenvs
$ cd .virtualenvs
</code></pre>
<p>Inside the newly created directory, you can create your environment and activate it:</p>
<pre><code>$ virtualenv VENV_NAME
$ source VENV_NAME/bin/activate
</code></pre>
<p>In the VS Code preferences you can search for 'venv' and set the 'Python: Venv Path' option to ~/.virtualenvs (or whatever you decided to call your environment folder). Then I was able to select the newly created environment as a kernel. You might need to add it by searching for 'Python: Select Interpreter' after pressing (Cmd + Shift + P) - you only need this step if you are planning to use the environment in VS Code.</p>
<p>After these steps I simply installed tensorflow according to the apple developer page (<a href=""https://developer.apple.com/metal/tensorflow-plugin/"" rel=""nofollow noreferrer"">https://developer.apple.com/metal/tensorflow-plugin/</a>):</p>
<pre><code>$ python -m pip install tensorflow
</code></pre>
<p>And tensorflow-metal which allows for training on Mac GPUs:</p>
<pre><code>$ python -m pip install tensorflow-metal
</code></pre>
<p>This allowed me to run tensorflow without any issues. Hope this might resolve the issue for some.</p>
","2023-09-06 20:13:11","1","Answer"
"77039363","77030715","","<p>This is due to incompatibility with the torch version.
To fix this error, you can add the parameter <code>strict=False</code>to perform that the target model and the original model are not identical:
<code>model.load_state_dict(state,strict=False)</code></p>
","2023-09-04 16:28:39","0","Answer"
"77038380","77038120","","<p>I imagine there are multiple ways to do this, but another one (that's not particularly neat) would be to use <a href=""https://pytorch.org/docs/stable/generated/torch.repeat_interleave.html"" rel=""nofollow noreferrer""><code>repeat_interleave</code></a> and <a href=""https://pytorch.org/docs/stable/generated/torch.tile.html?highlight=tile#torch.tile"" rel=""nofollow noreferrer""><code>tile</code></a>:</p>
<pre class=""lang-py prettyprint-override""><code>x = torch.arange(0, 1, 0.2)

twod_arange = torch.hstack(
    (
        torch.repeat_interleave(x.unsqueeze(1), 5, dim=0),
        torch.tile(x, (1, 5)).T,
    )
)
</code></pre>
","2023-09-04 14:00:41","2","Answer"
"77038187","77038120","","<p>I achieved it by this:</p>
<pre><code>x = torch.arange(0, 1, 0.2)

xx, yy = torch.meshgrid(x, x) # Get 2D coordinate grids
xx, yy = xx.flatten(), yy.flatten()

result = torch.stack((xx, yy), dim=1) # Reshape and stack them together
</code></pre>
<p>This is the output:</p>
<pre><code>tensor([[0.0000, 0.0000],
        [0.0000, 0.2000],
        [0.0000, 0.4000],
        [0.0000, 0.6000],
        [0.0000, 0.8000],
        [0.2000, 0.0000],
        [0.2000, 0.2000],
        [0.2000, 0.4000],
        [0.2000, 0.6000],
        [0.2000, 0.8000],
        [0.4000, 0.0000],
        [0.4000, 0.2000],
        [0.4000, 0.4000],
        [0.4000, 0.6000],
        [0.4000, 0.8000],
        [0.6000, 0.0000],
        [0.6000, 0.2000],
        [0.6000, 0.4000],
        [0.6000, 0.6000],
        [0.6000, 0.8000],
        [0.8000, 0.0000],
        [0.8000, 0.2000],
        [0.8000, 0.4000],
        [0.8000, 0.6000],
        [0.8000, 0.8000]])
</code></pre>
","2023-09-04 13:35:53","0","Answer"
"77038120","","How to create a 2D tensor of points with PyTorch, each dimension going from 0 to 1?","<p>I'm trying to create a 2D tensor where each dimension ranges from 0 to 1.</p>
<p>For a 1D tensor, I can use:</p>
<pre class=""lang-py prettyprint-override""><code>torch.arange(0, 1, 0.2)
</code></pre>
<p>This gives me:</p>
<pre><code>tensor([0.0, 0.2, 0.4, 0.6, 0.8])
</code></pre>
<p>But, I want to extend this to 2D points. My desired output is [with the shape (25, 2)]:</p>
<pre><code>tensor([
    [0.0, 0.0], [0.0, 0.2], [0.0, 0.4], [0.0, 0.6], [0.0, 0.8],
    [0.2, 0.0], [0.2, 0.2], [0.2, 0.4], [0.2, 0.6], [0.2, 0.8],
    [0.4, 0.0], [0.4, 0.2], [0.4, 0.4], [0.4, 0.6], [0.4, 0.8],
    [0.6, 0.0], [0.6, 0.2], [0.6, 0.4], [0.6, 0.6], [0.6, 0.8],
    [0.8, 0.0], [0.8, 0.2], [0.8, 0.4], [0.8, 0.6], [0.8, 0.8]
])
</code></pre>
<p>How can I achieve this using PyTorch?</p>
","2023-09-04 13:25:27","2","Question"
"77030715","","Installation of ZoeDepth in Google Colab Notebook","<p>I'm currently trying to run ZoeDepth in google colab and I have been following the instructions in <a href=""https://github.com/isl-org/ZoeDepth"" rel=""nofollow noreferrer"">https://github.com/isl-org/ZoeDepth</a>
Here are the lines that I have successfully run:</p>
<pre><code>!pip install torch
!pip install timm
</code></pre>
<pre><code>import torch
torch.hub.help(&quot;intel-isl/MiDaS&quot;, &quot;DPT_BEiT_L_384&quot;, force_reload=True)  # Triggers fresh download of MiDaS repo
</code></pre>
<p>The next step was to fetch the pretrained model from the github repository:</p>
<pre><code>import torch

repo = &quot;isl-org/ZoeDepth&quot;
# Zoe_N
model_zoe_n = torch.hub.load(repo, &quot;ZoeD_N&quot;, pretrained=True)
</code></pre>
<p>However, I can't run this block successfully, here are the full logs that shows under that block:</p>
<pre><code>Using cache found in /root/.cache/torch/hub/isl-org_ZoeDepth_main

img_size [384, 512]

Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

Params passed to Resize transform:
    width:  512
    height:  384
    resize_target:  True
    keep_aspect_ratio:  True
    ensure_multiple_of:  32
    resize_method:  minimal
Using pretrained resource url::https://github.com/isl-org/ZoeDepth/releases/download/v1.0/ZoeD_M12_N.pt

---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

&lt;ipython-input-1-9357dea39a86&gt; in &lt;cell line: 5&gt;()
      3 repo = &quot;isl-org/ZoeDepth&quot;
      4 # Zoe_N
----&gt; 5 model_zoe_n = torch.hub.load(repo, &quot;ZoeD_N&quot;, pretrained=True)
      6 
      7 # Zoe_K

/usr/local/lib/python3.10/dist-packages/torch/hub.py in load(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)
    556                                            verbose=verbose, skip_validation=skip_validation)
    557 
--&gt; 558     model = _load_local(repo_or_dir, model, *args, **kwargs)
    559     return model
    560 

/usr/local/lib/python3.10/dist-packages/torch/hub.py in _load_local(hubconf_dir, model, *args, **kwargs)
    585 
    586         entry = _load_entry_from_hubconf(hub_module, model)
--&gt; 587         model = entry(*args, **kwargs)
    588 
    589     return model

~/.cache/torch/hub/isl-org_ZoeDepth_main/hubconf.py in ZoeD_N(pretrained, midas_model_type, config_mode, **kwargs)
     67 
     68     config = get_config(&quot;zoedepth&quot;, config_mode, pretrained_resource=pretrained_resource, **kwargs)
---&gt; 69     model = build_model(config)
     70     return model
     71 

~/.cache/torch/hub/isl-org_ZoeDepth_main/zoedepth/models/builder.py in build_model(config)
     49         raise ValueError(
     50             f&quot;Model {config.model} has no get_version function.&quot;) from e
---&gt; 51     return get_version(config.version_name).build_from_config(config)

~/.cache/torch/hub/isl-org_ZoeDepth_main/zoedepth/models/zoedepth/zoedepth_v1.py in build_from_config(config)
    248     @staticmethod
    249     def build_from_config(config):
--&gt; 250         return ZoeDepth.build(**config)

~/.cache/torch/hub/isl-org_ZoeDepth_main/zoedepth/models/zoedepth/zoedepth_v1.py in build(midas_model_type, pretrained_resource, use_pretrained_midas, train_midas, freeze_midas_bn, **kwargs)
    243         if pretrained_resource:
    244             assert isinstance(pretrained_resource, str), &quot;pretrained_resource must be a string&quot;
--&gt; 245             model = load_state_from_resource(model, pretrained_resource)
    246         return model
    247 

~/.cache/torch/hub/isl-org_ZoeDepth_main/zoedepth/models/model_io.py in load_state_from_resource(model, resource)
     82     if resource.startswith('url::'):
     83         url = resource.split('url::')[1]
---&gt; 84         return load_state_dict_from_url(model, url, progress=True)
     85 
     86     elif resource.startswith('local::'):

~/.cache/torch/hub/isl-org_ZoeDepth_main/zoedepth/models/model_io.py in load_state_dict_from_url(model, url, **kwargs)
     59 def load_state_dict_from_url(model, url, **kwargs):
     60     state_dict = torch.hub.load_state_dict_from_url(url, map_location='cpu', **kwargs)
---&gt; 61     return load_state_dict(model, state_dict)
     62 
     63 

~/.cache/torch/hub/isl-org_ZoeDepth_main/zoedepth/models/model_io.py in load_state_dict(model, state_dict)
     47         state[k] = v
     48 
---&gt; 49     model.load_state_dict(state)
     50     print(&quot;Loaded successfully&quot;)
     51     return model

/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict)
   2039 
   2040         if len(error_msgs) &gt; 0:
-&gt; 2041             raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
   2042                                self.__class__.__name__, &quot;\n\t&quot;.join(error_msgs)))
   2043         return _IncompatibleKeys(missing_keys, unexpected_keys)

RuntimeError: Error(s) in loading state_dict for ZoeDepth:
    Unexpected key(s) in state_dict: &quot;core.core.pretrained.model.blocks.0.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.1.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.2.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.3.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.4.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.5.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.6.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.7.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.8.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.9.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.10.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.11.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.12.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.13.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.14.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.15.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.16.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.17.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.18.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.19.attn.relative_position_index&quot;, &quot;core.core.pretrained.model.blocks.20.attn.relative_position_index&quot;, &quot;core.core.pretrained.mo...
</code></pre>
<p>How can I resolve this?</p>
<p>Update: I found someone else reporting the same problem on ZD's GitHub:
<a href=""https://github.com/isl-org/ZoeDepth/issues/70"" rel=""nofollow noreferrer"">https://github.com/isl-org/ZoeDepth/issues/70</a>
(It seems that the problem doesn't occur just because I used Google Colab)</p>
","2023-09-03 02:32:35","0","Question"
"77029483","","Why do I run out of memory when training with a large dataset, but have no problems with a small dataset?","<p>I'm trying to build a keypoint detection system using Keras. I've got a UNet like model, with a series of convolutions, batch normalization, and max pooling, followed by a symmetric series of up sampling, convolution, and batch normalization layers (and skip connections). When given 100 instances, I'm able to call <code>model.fit()</code> without a problem. However, if I leave the model the same but use 500 instances, Keras crashes with an OOM exception. Why does this happen, and is there anything I can do to fix it?</p>
<p>Here's (what I think is) the relevant part of the code where I call <code>model.fit</code>:</p>
<pre class=""lang-py prettyprint-override""><code>model = build_model(
    filters=50,
    filter_step=1,
    stages=5,
    stage_steps=1,
    initial_convolutions=0,
    stacks=1,
)

print(model.summary()) 

dataset = tf.data.Dataset.from_tensor_slices((X, y))
dataset = dataset.batch(1)

model.fit(
    dataset,
    epochs=2**7,
    callbacks=[
        EarlyStopping(monitor=&quot;loss&quot;, patience=5, min_delta=1e-7, start_from_epoch=10),
        LearningRateScheduler(step_decay)
    ],
)
</code></pre>
<p><code>X</code> and <code>y</code> are Numpy arrays with the following shapes:</p>
<ul>
<li><code>X</code>: (100, 1024, 1024, 3)</li>
<li><code>y</code>: (100, 1024, 1024)</li>
</ul>
<p>100 here is the data set size. If I increase this to 500 (or more), I get the out-of-memory exception. It appears to me that Keras is perhaps trying to load the entire data set into memory, despite using <code>from_tensor_slices</code> and <code>batch(1)</code>, so I'm clearly misunderstanding something.</p>
","2023-09-02 18:10:13","3","Question"
"77011724","75208167","","<p>You are using <a href=""https://github.com/amueller/introduction_to_ml_with_python/tree/master/mglearn"" rel=""nofollow noreferrer"">old github repo</a></p>
<p><a href=""https://github.com/amueller/mglearn"" rel=""nofollow noreferrer"">this is the new github repo</a></p>
<p>Once you clone it, it will be downloaded as <code>mglearn</code> directory. If you copy it to your work directory, you can use</p>
<pre><code> import mglearn
</code></pre>
<p>You could also use</p>
<pre><code>pip install mglearn
</code></pre>
<p>That package is updated:</p>
<p><a href=""https://i.sstatic.net/1GbXk.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/1GbXk.png"" alt=""enter image description here"" /></a></p>
","2023-08-30 21:52:38","0","Answer"
"77000171","76997620","","<p>Here is a good method how you can tune the learning rate (eventually you'll be able to do it more intuitively): <a href=""https://medium.com/deep-learning-hk/some-techniques-in-deep-learning-optimization-1-learning-rate-b4669d5bb568"" rel=""nofollow noreferrer"">link</a></p>
<p>I'm summarizing the key steps to tuning the learning rate programmatically here:</p>
<ul>
<li>Create an array of learning rates value you want to try. They should include orders of magnitudes, e.g. <code>np.logspace(-9, -1, 21)</code></li>
<li>Loop through the learning rate and train your model for a fixed (low) number of epochs. The choice depends on the calculation time per epoch.
Save the validation loss after each run and plot the result.</li>
<li>If you change the architecture significantly, you should tune the learning</li>
</ul>
","2023-08-29 12:22:54","0","Answer"
"76997834","76997620","","<p>the learning_rate is too high I think, check the loss function and the codes。</p>
","2023-08-29 06:33:10","-1","Answer"
"76997620","","Loss stops to decrease in self-supervised learning","<p>I am using pytorch implementation of SIMCLR, training it on my own dataset.</p>
<p>The problem is, after 100 epoch, the loss dropped from 5.6 to 5.0, and it cease to decrease anymore. I wonder what might be the problem of it, or is it a normal situation?</p>
<p>The learning rate i set is is 0.2 and I wrap the optimizer with LARS with eeta=0.001, and the batch size is 512. (around 200000 small image with resnet18)</p>
<p>As you could see, the learning rate is rather moderate, right (not inappropriately large)?. So what do you think might be the problem?</p>
","2023-08-29 05:51:16","-2","Question"
"76988701","75730103","","<p>!CUDA_VISIBLE_DEVICES=0,1 WANDB_MODE=dryrun yolo detect train resume data=/kaggle/working/newyolov8files/custom_original_datayolov8.yaml model=/kaggle/working/runs/detect/train/weights/last.pt epochs=1000 cache=True imgsz=640 batch=64 patience=100 optimizer=RAdam</p>
<p>as above code you can resume training or train over pre-trained model using &quot;model=last.pt&quot; of last trained model</p>
","2023-08-27 19:49:21","1","Answer"
"76982508","75259774","","<p>I faced a similar issue. The datatype of the weight matrix didn't match the datatype of the input vector.</p>
<p>In my case I defined the model as follows</p>
<pre><code>class Multiclass(nn.Module):
def __init__(self, input_size, hidden_size1, output_size):
    super().__init__()
    self.hidden = nn.Linear(input_size, hidden_size1)
    self.act = nn.ReLU()
    self.output = nn.Linear(hidden_size1, output_size)
    
def forward(self, x):
    x = self.act(self.hidden(x))
    x = self.output(x)
    return x
</code></pre>
<p>And tested the datatype of the weight matrix using</p>
<pre><code>print(model.hidden.weight.dtype)
</code></pre>
<p>They didn't match. So I had to explicitly define the datatype when defining my tensor, something like:</p>
<pre><code>x_train_t = torch.tensor(X_hot_train, dtype=torch.float32)
</code></pre>
","2023-08-26 10:19:45","0","Answer"
"76971960","76661319","","<pre><code>    db = SQLDatabase.from_uri(&quot;postgresql://username:password@localhost:5432/db_name?connect_timeout=10&amp;target_session_attrs=primary&quot;,
                                  include_tables=['table_name'])
    chain = SQLDatabaseChain(llm=CustomLLM(), database=db, verbose=True)
    chain.run(&quot;How many users are there?&quot;)
        
    class CustomLLM(LLM):
        model_name = &quot;microsoft/tapex-base-finetuned-wtq&quot;
        tokenizer = TapexTokenizer.from_pretrained(&quot;microsoft/tapex-base-finetuned-wtq&quot;)
        streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)
        model = BartForConditionalGeneration.from_pretrained(&quot;microsoft/tapex-base-finetuned-wtq&quot;)
    
        def _call(self, prompt, stop=None, **kwargs):
            prompt = f&quot;### User:\n{prompt}\n\n### Assistant:\n&quot;
            inputs = self.tokenizer(prompt, return_tensors=&quot;pt&quot;).to(self.model.device)
            output = self.model.generate(**inputs, streamer=self.streamer, use_cache=True, max_new_tokens=float('inf'))
            return self.tokenizer.decode(output[0], skip_special_tokens=True)
    
        @property
        def _identifying_params(self):
            return {&quot;name_of_model&quot;: self.model_name}
    
        @property
        def _llm_type(self):
            return &quot;custom&quot;
</code></pre>
","2023-08-24 18:11:48","0","Answer"
"76970757","76776695","","<pre><code>chain = LLMChain(llm=llm_model, prompt=PromptTemplate(template=template, input_variables=['context', 'prompt']))
</code></pre>
<p>If you assign prompt variable inline, it should work</p>
","2023-08-24 15:20:08","0","Answer"
"76954499","76603178","","<p>Add <code>search_kwargs={&quot;k&quot;: k}</code> as an argument to the retriever class and replace k with the desired number of results.</p>
","2023-08-22 14:50:12","4","Answer"
"76946327","76938435","","<p>Two plausible solutions:</p>
<ol>
<li>The error message references the computing of the input batch size. It says 64x7696, meaning it interprets the input as a batch of 64 items each of size 7696. So, with that being said, your data inputs of size (batch_size, 3, 110, 80).</li>
</ol>
<p>To debug, print X var before passing it to the model:</p>
<pre><code>print(X.shape)
</code></pre>
<p>Check and validate batch size, as well as image augmentation or preprocessing is changing it.</p>
<ol start=""2"">
<li><p>The other potential mismatch between the output shape of the last convolutional layer and the input shape of the fully connected layer. The error message is about multiplying a matrix of size (64x7696) with another matrix of size (492544x2), which isnt valid. The main change is the linear layers: I've added an additional linear layer with an output size of 128 units after the first one. You can adjust the output size of this linear layer based on your experimentations. The last linear layer outputs 2 units without an activation function since you're using the sigmoid activation in the loss function.</p>
<pre><code> class GenderClassifier(nn.Module): 
    def __init__(self): 
       super().__init__() 
       self.model = nn.Sequential(
           nn.Conv2d(3, 32, (3, 3)), 
           nn.ReLU(), 
           nn.Conv2d(32, 64, (3, 3)), 
           nn.ReLU(), 
           nn.Conv2d(64, 64, (3, 3)), 
           nn.ReLU(), 
           nn.Flatten(), 
           nn.Linear(64 * 104 * 74, 128), 
           nn.ReLU(), nn.Linear(128, 2),
          )

     def forward(self, x):
        return self.model(x)
</code></pre>
</li>
</ol>
","2023-08-21 14:36:16","0","Answer"
"76945342","76776695","","<p>from my understanding Langchain requires <code>{context}</code> in the template</p>
<p>The modified code below should work.</p>
<pre><code>template = &quot;&quot;&quot;You are a chatbot having a conversation with a human.

Given the following extracted parts of a long document and a question, create a final answer.

{context}

{chat_history}
Human: {user_query}
Chatbot:&quot;&quot;&quot;

prompt = PromptTemplate(
input_variables=[&quot;chat_history&quot;, &quot;user_query&quot;, &quot;context&quot;],
template=template
)

memory = ConversationBufferMemory(memory_key=&quot;chat_history&quot;, input_key=&quot;user_query&quot;)

llm = OpenAI()
llm_chain = LLMChain(
    llm=llm,
    prompt=prompt,
    memory=memory,
)

chain = load_qa_chain(
    llm, chain_type=&quot;stuff&quot;, memory=memory, prompt=prompt
)

</code></pre>
","2023-08-21 12:37:51","0","Answer"
"76939499","76938435","","<p>First, your input shape structure should look like following:</p>
<p>(N_BATCH_SIZE, C_CHANNEL_SIZE, H_HEIGHT, W_WIDTH)</p>
<p>But you have provided shape (3, 110, 180) and it is not compatible for network.</p>
<p>I tested with (5, 3, 110, 180), (1000, 3, 110, 180) [different batch sizes) shape and network was working well.</p>
<p>But when I fed into the model (3, 110, 180) I got same error with you.</p>
","2023-08-20 13:00:23","0","Answer"
"76938435","","Pytorch matrix multiplication error (shape mismatch)","<p>I have implemented a class from pytorch which looks like</p>
<pre><code>class GenderClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,(3,3)),
            nn.ReLU(),
            nn.Conv2d(32,64,(3,3)),
            nn.ReLU(),
            nn.Conv2d(64,64,(3,3)),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64*104*74,2),
            nn.Sigmoid()
        )
        
    def forward(self,x):
        return self.model(x)
</code></pre>
<p>I'm getting this error when I'm training it <code>RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x7696 and 492544x2)</code>. The input shape is 110*80 size image with 3 channels (3,110,80).</p>
<p>The training code looks like</p>
<pre><code>for epoch in range(30): # train for 10 epochs    
    for batch in dataset: 
        
        X,y = batch 
        X, y = X.to('cuda'), y 
        yhat = clf(X) 
        loss = loss_fn(yhat, y) 

        # Apply backprop 
        opt.zero_grad()
        loss.backward() 
        opt.step() 

    print(f&quot;Epoch:{epoch} loss is {loss.item()}&quot;)
with open(&quot;model.pt&quot;,&quot;wb&quot;) as f:
    save(clf.state_dict(),f)```
</code></pre>
","2023-08-20 07:42:35","0","Question"
"76920988","76919033","","<p>You can calculate batch-wise f1 score in the evalution step using this code:</p>
<pre><code>from sklearn.metrics import f1_score
def validation_step(self, batch, batch_idx):
  input_ids = batch['input_ids']
  attention_mask = batch['attention_mask']
  labels = batch['labels']
  loss, outputs = self(input_ids, attention_mask, labels)
  prediction = outputs.argmax(dim=1, keepdim=True)
  f1 = f1_score(labels, prediction)
  self.log('val_loss', loss, prog_bar=True, logger=True)
  return loss
</code></pre>
","2023-08-17 11:16:52","0","Answer"
"76919339","76919033","","<p>I don't know what your actual predictions and outputs are, but I recommend this function for n-D F1-score calculator, using flatten and confusion matrix.</p>
<pre><code>from sklearn.metrics import confusion_matrix

def f1_score_calc(np_pred, np_gt,):
    f1m = []

    epsilon = 2.22045e-16

    for i in range(np_pred.shape[0]):
        label = np_gt[i, :, :]
        pred = np_pred[i, :, :]
        label = label.flatten()
        pred = pred.flatten()

        try:
            tn, fp, fn, tp = confusion_matrix(y_true=label, y_pred=pred).ravel()
        except ValueError: # exception for all-zero
            tn, fp, fn, tp = 0, 0, 0, 0
        sensitivity = tp / (tp + fn + epsilon)
        precision = tp / (tp + fp + epsilon)
        f1_score = (2 * sensitivity * precision) / (sensitivity + precision + epsilon)

        f1m.append(f1_score)

    return np.array(f1m).mean()
</code></pre>
<p>Notice that the 'np_pred' and 'np_gt' are shape of (N, H, W) in np.ndarray, and elements are formatted with argmax value.</p>
","2023-08-17 07:33:00","0","Answer"
"76919033","","Compute F1-Score inside Validation Step","<p>I am fine-tuning the mT5 model for QA.</p>
<p>I am using PyTorch Lightning, and currently, my validation step looks like this:</p>
<pre><code>  def validation_step(self, batch, batch_idx):
    input_ids = batch['input_ids']
    attention_mask = batch['attention_mask']
    labels = batch['labels']
    loss, outputs = self(input_ids, attention_mask, labels)
    self.log('val_loss', loss, prog_bar=True, logger=True)
    return loss
</code></pre>
<p>Instead of logging the <code>val_loss</code> and choosing the best checkpoint based on that, I want to calculate the F1-Score, and choose the best checkpoint based on the best overall F1.</p>
<p>I successfully calculated the predictions after the training loop is completed:</p>
<pre><code>predictions = []
ground_truths = []
for batch in tqdm(data_module.test_dataloader(), desc=&quot;Evaluating&quot;):
    input_ids = batch['input_ids'].to(DEVICE)
    attention_mask = batch['attention_mask'].to(DEVICE)
    labels = batch['labels'].to(DEVICE)
    with torch.no_grad():
        generated_ids = trained_model.model.generate(
            input_ids=input_ids,
            attention_mask=attention_mask,
        )

    predicted_answers = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)
    predictions.extend(predicted_answers)

    mask = labels != -100
    labels = torch.masked_select(labels, mask)
    true_text = tokenizer.decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    ground_truths.append(true_text)
</code></pre>
<p>How can I compute the prediction / ground_truth inside the validation step in order to compute the F1-Score there?</p>
","2023-08-17 06:41:15","0","Question"
"76909439","76901604","","<p>The base gradio <a href=""https://www.gradio.app/docs/interface"" rel=""nofollow noreferrer"">&quot;Interface&quot;</a> class has parameters (title, description &amp; article) that take strings and are rendered as helpful text for the app.  These are the simplest ways to provide some context and instruction.</p>
<p>For example:</p>
<pre><code>title = &quot;Awesome ML App&quot;
desc = &quot;This is an awesome ML App.  I'm really excited to show you&quot;
long_desc = &quot;Let me tell you ALL about this awesome ML App&quot;
iface = gr.Interface(fn=classify_image, inputs=image, outputs=label, theme=gr.themes.Glass(), 
                examples=[example1, ref_example, example2], title=title, 
                description=desc, article=long_desc)
</code></pre>
","2023-08-15 22:21:15","2","Answer"
"76905143","76866418","","<p>I have encountered exactly the same issue when setting up a new tf environment. I believe it is because tflearn==0.5.0 which is too old and cannot work with latest tensorflow=2.13.0.</p>
<p>I have to fall back tensorflow to older version such as 2.12.0 to make it works.</p>
<p>There is also a PR on tflearn to fix this problem but it is still work in progress:
<a href=""https://github.com/tflearn/tflearn/pull/1173/commits"" rel=""nofollow noreferrer"">https://github.com/tflearn/tflearn/pull/1173/commits</a></p>
<p>Basically <em>is_sequence(args)</em> will be replaced with <em>is_sequence_or_composite(args)</em>.</p>
<pre><code>from tensorflow.python.util.nest import is_sequence_or_composite
</code></pre>
<pre><code>if args is None or (is_sequence_or_composite(args) and not args):
 raise ValueError(&quot;`args` must be specified&quot;)
if not is_sequence_or_composite(args):
 args = [args]
</code></pre>
<p>Besides, the Pillow-10.0 gave the same issue which can be fixed by replacing it with Pillow-9.5 or you can replace the ANTIALIAS with LANCZOS by the utils.py file like we did for the reccurent.py file of tflearn library.</p>
<pre><code>pip uninstall Pillow
pip install Pillow==9.5.0
</code></pre>
<p>I just uploaded the previous version of PIL and it totally works right now.</p>
","2023-08-15 10:23:42","1","Answer"
"76902847","76247802","","<p>You don't <em>need</em> safetensors when you're using GPTQ content -- it's an alternative to pytorch's default (unsafe) &quot;pickle&quot; format.</p>
<p>GPTQ is already not using the unsafe pickle format, so safetensors are irrelevant and unnecessary (and consequently, safetensor-format files are not included in GPTQ repositories).</p>
","2023-08-15 00:28:16","0","Answer"
"76901604","","How to add heading or text before input/output in gradio?","<p>I did a machine learning project on MNIST and deployed that on gradio. Any user won't understand what he should input to use the model. So I want to add a heading or description on gradio live website so that anyone can understand.</p>
<p>I tried with gradio block, gradio.markdown but it's not working on Google colab</p>
","2023-08-14 19:17:22","2","Question"
"76875422","76533527","","<p>Here's a patch to make your program work. You helped me, so I hope can help you back.</p>
<pre><code>$ diff -c original.py new.py
*** original.py 2023-08-10 06:40:03.058934600 -0500
--- new.py      2023-08-10 06:40:17.938937500 -0500
***************
*** 27,32 ****
--- 27,33 ----
  options = HandLandmarkerOptions(
      base_options=BaseOptions(model_asset_path='hand_landmarker.task'),
      running_mode=VisionRunningMode.LIVE_STREAM,
+     num_hands=2,
      result_callback=print_result)
  with HandLandmarker.create_from_options(options) as landmarker:
      cap = cv2.VideoCapture(0)
</code></pre>
","2023-08-10 11:43:34","0","Answer"
"76875291","76875028","","<p>I think the issue is how you have specified <code>parameters</code>. To get the desired behaviour, use a single <code>dict</code> as follows:</p>
<pre><code>parameters = {'logreg__solver': ['saga'],
              'logreg__penalty':['l1', 'l2'],
              'logreg__C':[1e-3, 0.1, 1, 10, 100]
              }
</code></pre>
<p>You had specified it as a list of dicts, which gave <code>GridSearchCV</code> the option of picking some and ignoring others, meaning it sometimes encountered the request to use <code>l1</code> on the default (non-<code>saga</code>) solver. Those two options are not compatible.</p>
","2023-08-10 11:25:52","1","Answer"
"76875221","76875028","","<p>Why are you passing your parameters as a list of dictionaries, instead of a dictionary of lists?</p>
<p>Isn't</p>
<pre class=""lang-py prettyprint-override""><code>parameters = {'solver': ['saga'],
              'penalty':[ 'l1', 'l2'],
              'C':[0.001, 0.01, 0.1, 1, 10, 100]}
</code></pre>
<p>what you want?</p>
<p>Works here.</p>
","2023-08-10 11:17:03","0","Answer"
"76875028","","grid_pipeline.fit uses default value of solver parameter instead of GridSearchCV value","<p>I tried to find the best combination of hyperparameters for <code>LogisticRegression</code> in <code>sklearn</code>. Below is the example of my code:</p>
<pre class=""lang-py prettyprint-override""><code>pipeline = Pipeline([(&quot;scaler&quot;, StandardScaler()),
                     (&quot;smt&quot;,    SMOTE(random_state=42)),
                     (&quot;logreg&quot;, LogisticRegression())])


parameters = [{'logreg__solver': ['saga']},
              {'logreg__penalty':['l1', 'l2']},
              {'logreg__C':[1e-3, 0.1, 1, 10, 100]}]

grid_pipeline = GridSearchCV(pipeline,
                             parameters, 
                             scoring= 'f1', 
                             n_jobs=5, verbose=5,
                             return_train_score=True, 
                             cv=5) 

grid_result = grid_pipeline.fit(X_train,y_train)
</code></pre>
<p>During fitting I get the following error:</p>
<pre><code>ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.
</code></pre>
<p>For some reason, default value 'lbfgs' is used for <code>solver</code> parameter instead of chosen 'saga'. Why does it happen?</p>
","2023-08-10 10:50:19","0","Question"
"76868641","76862459","","<p>Let's start with a brief aside on metrics, the purpose of which is to assess the goodness of an algorithmic approach at completing a task <strong>with respect to a final use case of the approach.</strong> Your final application of the algorithm should significantly inform how you craft your metrics. If you care deeply that the performance of your algorithm is class-balanced even at the expense of average performance, then you should balance your results per class. But if you instead want the best average performance for your application, you should probably use a metric that doesn't weight each class equally irrespective of relative class frequency. (It's also worth considering whether your dataset is representative of class distributions in the wild or class-biased). In a safety-critical application where some classes indicate danger, you may want to opt for metrics that encourage high recall over high precision. And if you don't understand how the torchmetrics implementation of the JaccardIndex weights each of these things it may be worth implementing it yourself to give a bit more flexibility (IOU for labels is basically trivial to implement). <strong>Jaccard Index is also not incredibly useful for understanding multi-class performance as it doesn't distinguish between false positives and false negatives, and makes no determination of commonly confused classes.</strong> It is most commonly used for multi-class problems on image segmentation tasks, which have a spatial element for which the notion of <code>overlap</code> is useful.</p>
<p>But in any case, here's how you'd implement for your desired question. Let <code>c</code> be the number of classes in your dataset. Jaccard Index is the interstection of two sets divided by the union of the two sets, so we'll find the interstection per-class (<code>bin_hits</code>) and the <code>union</code>) then divide (there are several feasible ways to do this divide operation yielding starkly different scores.)</p>
<pre><code>bin_p = torch.bincount(pred,min_length = c)
bin_t = torch.bincount(target,min_length = c)

# mask is 1 if pred == target, 0 otherwise
hit_mask = 1 - torch.clamp((pred - target),min = 0, max = 1)

hits_class = pred[hit_mask.nonzero()]
bin_hits   = torch.bincount(hits_class,min_length = c)
union = bin_p + bin_t - bin_hits
</code></pre>
<p>At this point:</p>
<pre><code>bin_p      = [0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,1,0] 
bin_t      = [0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0] 
hit_mask   = [1,1,0,1,0]
hits_class = [1,2,17]
bin_hits   = [0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]
union      = [0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,2,0,1,0]
</code></pre>
<p>Per-class Jaccard Index (no reduction to a single value):</p>
<pre><code>jaccard = bin_hits / union 

&gt;&gt;&gt; result = [0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.5,0,0,0]
</code></pre>
<p>Basic Jaccard Index (no weighting by class). Note that classes with no predictions and no true labels do not affect the score as they affect neither sum:</p>
<pre><code>jaccard = bin_hits.sum() / union.sum() 

&gt;&gt;&gt; result = 3/7 = 0.42857
</code></pre>
<p>Mean Jaccard Index (each class counts for the same proportion of the total score). Note that classes with no predictions and no true labels do affect the score:</p>
<pre><code>jaccard = (bin_hits / union).mean()

&gt;&gt;&gt; result = 0.119
</code></pre>
<p><strong>Mean Jaccard Index with empty classes ignored</strong>:</p>
<pre><code>jaccard_per_class = (bin_hits / union)

# get class indices with at least one prediction or example
mask = (bin_p + bin_t).nonzero()         
jaccard = jaccard_per_class[mask] # takes mean of non-zero bins only

&gt;&gt;&gt; result = 0.41667
</code></pre>
<p>Once again though, I'd encourage you to explore other metrics that are a bit more well-aligned with your task.</p>
","2023-08-09 14:15:21","0","Answer"
"76866418","","error when I try to import tflearn : cannot import name 'is_sequence' from 'tensorflow.python.util.nest'","<p>I already have <code>tflearn</code> installed and I get the following error when I try to import it:</p>
<pre><code>ImportError: cannot import name 'is_sequence' from 'tensorflow.python.util.nest' (C:\Users\fsafi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\tensorflow\python\util\nest.py)
</code></pre>
<p>I tried the following:</p>
<pre><code>import tflearn
</code></pre>
","2023-08-09 09:36:03","1","Question"
"76864271","76862459","","<p>You can use <code>DeepLabV3Plus</code> metric class <a href=""https://github.com/VainF/DeepLabV3Plus-Pytorch/blob/master/metrics/stream_metrics.py"" rel=""nofollow noreferrer"">here</a>.</p>
<pre><code>metric = StreamSegMetrics(n_classes)
for batch_idx, _ in enumerate(dataLoader):
    metric.update(label_trues, label_preds) # update every iterations
    metrics_out = metric.get_results()
</code></pre>
","2023-08-09 02:51:30","0","Answer"
"76862459","","What is the correct way to calculate mean IoU in PyTorch when there are absent classes?","<p>My use case is pretty much the same with this example:</p>
<pre><code>from torchmetrics import JaccardIndex
import torch

pred = torch.tensor([1, 2, 19, 17, 17])
target = torch.tensor([1, 2, 3, 17, 4])

jaccard = JaccardIndex(num_classes=21)

jaccard(pred, pred)
Out: tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0.])
</code></pre>
<p>How can I correctly calculate mIoU between pred and target when there are non-present classes? In other words, I don't want it to simply assign zero to classes that were not even present in the test dataset. Also, we need to consider the zeros only if it is really a wrong prediction, instead of an absent class.</p>
","2023-08-08 18:54:21","0","Question"
"76846311","76321820","","<p>I got the same error while trying to fit BayesSearchCV</p>
<pre><code>BayesSearchCV(
            SVR(),
            param_distributions,
            n_iter,
            cv,
            scoring,
            random_state,
            n_jobs).fit(X_train, y_train). 
 
</code></pre>
<blockquote>
<p>AttributeError: module 'numpy' has no attribute 'int'.</p>
</blockquote>
<p>As @sanctus suggested:</p>
<ol>
<li>Replaced all <code>np.int</code> with <code>int</code> in the file
<em><strong>'anaconda3\envs\myenv\Lib\site-packages\skopt\space\transformers.py'</strong></em></li>
<li>Restarted kernel, or in my case exited pycharm app and opened again</li>
<li>run the code again and error fixed.</li>
</ol>
","2023-08-06 14:22:52","4","Answer"
"76843491","76838860","","<p>I was able to fix the dimension errors by applying max pooling after the middle layer and the decoder.<br>
I am not sure why this works, but now output and input sizes are consistent. <br>
The prediction results look bad right now, but I'm pretty sure that's because I set the number of channels down to between 2 to 8, and only trained for 1 epoch.<br>
It will be interesting to see how this architecture works as I apply normal hyper-parameters. I'm just glad that there are no more runtime errors or out of memory issues.</p>
","2023-08-05 20:49:46","0","Answer"
"76842878","76842353","","<p><code>LinearRegression</code> <em>used</em> to have a <code>normalize</code> parameter in older versions of scikit-learn; e.g. in v1.0, according to the <a href=""https://scikit-learn.org/1.0/modules/generated/sklearn.linear_model.LinearRegression.html"" rel=""nofollow noreferrer"">documentation</a>, the model used to be:</p>
<pre><code>class sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)
</code></pre>
<p>but the <code>normalize</code> parameter was already accompanied by a warning:</p>
<blockquote>
<p><em>Deprecated since version 1.0:</em> <code>normalize</code> <em>was deprecated in version 1.0 and will be removed in 1.2.</em></p>
</blockquote>
<p>Indeed, the <code>normalize</code> parameter is removed in newer scikit-learn versions; in the currently latest one, v1.3, according to the <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"" rel=""nofollow noreferrer"">documentation</a>, the class is</p>
<pre><code>class sklearn.linear_model.LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)
</code></pre>
<p>So, what is happening is that your are following a book based on an older scikit-learn version (1.1 or older) while using a newer version, so when you call <code>LinearRegression()</code> with the <code>normalize</code> argument, you unsurprisingly get the error message you report.</p>
<p>Depending on your exact intentions, you have 2 options:</p>
<ul>
<li>If you want to stick to the book by all means, you should install scikit-learn v1.1 or older</li>
<li>If you don't mind departing a bit from the book examples, you should remove <code>'params':{'normalize':[True, False]</code> from your <code>find_best_model_using_gridsearchcv</code> function</li>
</ul>
","2023-08-05 17:54:46","3","Answer"
"76842353","","Invalid parameter 'normalize' for estimator LinearRegression()","<p>I am implementing an example in 'Introduction to Machine Learning using Python'.</p>
<p>Code I am using:</p>
<pre><code>def find_best_model_using_gridsearchcv(x,y):
  algos = {
      'linear regression' : {
          'model': LinearRegression(),
          'params':{ 
              'normalize':[True, False]
          }
      },
      'lasso': {
          'model': Lasso(),
          'params':{
              'alpha':[1,2],
              'selection': ['random','cyclic']
          }
      },
      'decision tree':{
          'model': DecisionTreeRegressor(),
          'params':{
              'criterion':['mse', 'friedman_mse'],
              'splitter':['best', 'random']
          }
      }
  }
</code></pre>
<p>and</p>
<pre><code>  scores = []
  cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  for algo_name, config in algos.items():
    gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
    gs.fit(x_train, y_train)
    scores.append({
        'model': algo_name,
        'best_score': gs.best_score_,
        'best_params': gs.best_params_
    })

  return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])

find_best_model_using_gridsearchcv(x,y)
</code></pre>
<p>The error being returned boils down to:</p>
<pre><code>ValueError: Invalid parameter 'normalize' for estimator LinearRegression(). 
Valid parameters are: ['copy_X', 'fit_intercept', 'n_jobs', 'positive'].
</code></pre>
<p>Is this error actually releated to <code>LinearRegression</code> or <code>GridSearchCV</code>?</p>
","2023-08-05 15:35:39","0","Question"
"76841578","76841207","","<p>There are two things here which may cause issues:</p>
<ol>
<li>The data your developing the model with</li>
<li>Leakage your code is introducing</li>
</ol>
<p>From a data perspective, it looks like your predicting the target variable with only one feature, 'fh'. If this feature is highly correlated with the target variable, then I would expect an unusually high accuracy. I haven't analysed your data, so I can't decide if this kind of behaviour is unusual or not based on the data you've feed into the model.</p>
<p>But even ignoring my concerns around the dataset itself, you also need to remove this line of code to avoid leakage:</p>
<pre><code>model.fit(x_train, y_train.astype('int'))
</code></pre>
<p>Fitting the model before passing it to cross_val_score() will introduce leakage, since the model is being tested on data it's already seen. This might also explain why the accuracy of each fold is so high. Although I'm not certain why the first fold is an outlier.</p>
<p>When you increase test_size from 0.2 to 0.6 then you also reduce the sample size of the train dataset. This probably exacerbates the leakage problem, which is why the accuracy increase further to 1.0 for each fold. But again, I can't say for certain without knowing anything about the data your using.</p>
","2023-08-05 12:14:08","1","Answer"
"76841527","76841207","","<p>Regarding the second problem: when you increase the test set size to 0.6, this reduces the size of train set and makes it easier for the model to memorize your training data (overfitting). I think what you're seeing is that the model has overfit, attaining perfect accuracy. To regularise the model (reducing its tendency to overfit), increase the training data or make the <em>model</em> more regularised by introducing <code>priors=</code> for example.</p>
<p>Not sure about the first problem - it might just be 'sampling noise' where the first fold was a lot harder. If you've got a small test set there'll be more sampling-related variability in the folds. In your case, with 10-fold CV, the test set is 10% of the training data, and if the training set is small to begin with, then 10% of that is going to be even smaller. Set <code>random_state=0</code> in order to get repeatable results, and that'll allow you to dig deeper into fold 0 if needed.</p>
","2023-08-05 12:00:33","1","Answer"
"76841207","","Gaussian Naive Bayes gives weird results","<p>This is a basic implementation of Gaussian Bayes using sklearn. Can anyone tell me what I'm doing wrong here, my K-Fold CV results are a bit weird:</p>
<pre><code>import numpy as np
import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, classification_report
import csv
from sklearn.model_selection import cross_val_score

column_names = ['AS', 'fh', 'class2']
df = pd.read_csv(&quot;C:/Users/Jans/Music/docx/222/test.csv&quot;,  sep=';', header = 0, names = column_names)

x = df.drop(['AS', 'class2'], axis=1)
df['class2'] = df['class2'].astype(int)
y = df['class2'].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle = False, random_state = None)

model = GaussianNB()
model.fit(x_train, y_train.astype('int'))

k_fold_acc = cross_val_score(model, x_train, y_train, cv=10)
k_fold_mean = k_fold_acc.mean()
for i in k_fold_acc:
    print(i)
print(&quot;accuracy K Fold CV:&quot; + str(k_fold_mean))

grid_predictions = model.predict(x_test)
</code></pre>
<p>my 10 Fold CV results (especially the first fold is very strange...):</p>
<pre><code>0.36714285714285716
0.8271428571428572
0.9785714285714285
0.9357142857142857
0.9628571428571429
0.9957081545064378
1.0
1.0
0.994277539341917
0.9842632331902719
accuracy K Fold CV:0.90456774984672
</code></pre>
<p>Also, when I increase my test set from suppose 0.2 to 0.6 these are the results, which is also a bit strange.</p>
<p>Am I doing something wrong? And if yes, what?</p>
<pre><code>1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
accuracy K Fold CV:1.0
</code></pre>
","2023-08-05 10:30:58","0","Question"
"76841129","76834972","","<p>First try to update and upgrade repos:</p>
<pre><code>sudo apt update

sudo apt upgrade
</code></pre>
<p>To install pytesseract, run this command</p>
<pre><code>pip install pytesseract
</code></pre>
<p>To support languages other than English, use this command along with upper one:</p>
<pre><code>sudo apt install tesseract-ocr-tam
</code></pre>
<p>Language examples:</p>
<ul>
<li>eng -&gt; English</li>
<li>guj -&gt; Gujarati</li>
<li>tam -&gt; tamil</li>
</ul>
<p>You can find more: just use</p>
<pre><code>sudo apt install tesseract-ocr
</code></pre>
<p>and press tab to get all possibilities</p>
","2023-08-05 10:10:57","2","Answer"
"76840531","76834972","","<p>Add Tesseract OCR 5 PPA to your system.
To add the Tesseract OCR 5 PPA to your system, run the command below.</p>
<pre><code>sudo add-apt-repository ppa:alex-p/tesseract-ocr-devel
</code></pre>
<p>Install Tesseract on Ubuntu
Run the command :</p>
<pre><code>sudo apt install -y tesseract-ocr
</code></pre>
<p>Once installation is complete update your system</p>
<pre><code>sudo apt update
</code></pre>
","2023-08-05 07:15:43","3","Answer"
"76840487","76838860","","<p>It is because down sampling dimensions are not  equal to the up sampling dimensions.
Based on the data you provide, I think it is because you used <code>strides</code> in the decoder layer more than the encoder layer.</p>
<p>Modify the architecture to the code below and see if this one works:</p>
<pre><code> def __init__(self, input_channels, output_channels):
    super(UNet, self).__init__()

    self.encoder = nn.Sequential(
        nn.Conv3d(input_channels, 32, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv3d(32, 64, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
    )
    self.pool = nn.MaxPool3d(kernel_size=2, stride=2)
    self.middle = nn.Sequential(
        nn.Conv3d(64, 128, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv3d(128, 128, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
    )
    self.decoder = nn.Sequential(
        nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),
        nn.ReLU(inplace=True),
        nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),
        nn.ReLU(inplace=True),
        nn.Conv3d(32, output_channels, kernel_size=3, padding=1),
    )
</code></pre>
","2023-08-05 07:00:48","0","Answer"
"76838860","","How to Fix Slight Mismatch Between Dimensions of CNN Output Data and the Target?","<p>I am trying to create a version of the UNet CNN which will take in a certain type of MRI image volume as the source and use corresponding MRI image volume as the target.</p>
<p>After quite a bit of trial and error I am still getting a small mismatch between the size of the CNN's output and the dimensions of the target. The CNN output is 208x224x160, but the source/target data are both 210x224x160. This causes a runtime error during the calculation of the loss. What's strange is that the dimension mismatch doesn't occur when I put in randomly generated data, the output has the same dimensions as the input.</p>
<p>What could be causing this error and how should I go about fixing it?</p>
<p>Here is the code:</p>
<pre><code>import nibabel as nib
import os
import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F

# function using nibabel to load a single volume from the disk
def load_Volume(filepath):
    img = nib.load(filepath)
    data = img.get_fdata()
    return data

def preprocess_mri_data(data):
    # Normalize the data, other pre-processing can be added
    mean = np.mean(data)
    std = np.std(data)
    data = (data - mean) / std
    return data


# Dataset class to use with the data loader. Pairs sources with targets.
class MRISource_Target(Dataset):
    def __init__(self, source_dir, target_dir, transform=None):
        self.source_dir = source_dir
        self.target_dir = target_dir
        self.source_filenames = os.listdir(source_dir)
        self.target_filenames = os.listdir(target_dir)
        self.transform = transform

    def __len__(self):
        return len(self.source_filenames)

    def __getitem__(self, idx):
        source_filepath = os.path.join(self.source_dir, self.source_filenames[idx])
        target_filepath = os.path.join(self.target_dir, self.target_filenames[idx])

        source_data = load_Volume(source_filepath)
        target_data = load_Volume(target_filepath)

        source_data = preprocess_mri_data(source_data)
        target_data = preprocess_mri_data(target_data)

        if self.transform:
            source_data = self.transform(source_data)
            target_data = self.transform(target_data)

        return {'source': source_data, 'target': target_data}

# directories for the training and testing data
train_source_dir = '/content/drive/MyDrive/qsmData/Train/Source'
train_target_dir = '/content/drive/MyDrive/qsmData/Train/Target/'
test_source_dir = '/content/drive/MyDrive/qsmData/Test/Source/'
test_target_dir = '/content/drive/MyDrive/qsmData/Test/Target/'

# create the paired datasets
train_dataset = MRISource_Target(train_source_dir, train_target_dir)
test_dataset = MRISource_Target(test_source_dir, test_target_dir)

# make the datasets iteratable for training
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# visualize an arbitrary slice
def plot_mri_slice(volume, slice_num):
    plt.imshow(volume[:, :, slice_num], cmap='gray')
    plt.axis('off')
    plt.show()

import torch
import torch.nn as nn

# Define the U-Net architecture
class UNet(nn.Module):
    def __init__(self, input_channels, output_channels):
        super(UNet, self).__init__()

        self.encoder = nn.Sequential(
            nn.Conv3d(input_channels, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv3d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=2, stride=2)
        )

        self.middle = nn.Sequential(
            nn.Conv3d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv3d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=2, stride=2)
        )

        self.decoder = nn.Sequential(
            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),
            nn.ReLU(inplace=True),
            nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),
            nn.ReLU(inplace=True),
            nn.Conv3d(32, output_channels, kernel_size=3,padding=1),
            #nn.Tanh()  # Assuming magnetic susceptibility values are in a specific range
        )

    def forward(self, x):
        x1 = self.encoder(x)
        x2 = self.middle(x1)
        x3 = self.decoder(x2)
        return x3

# Example usage:
batch_size = 1
input_channels = 1  # Number of input channels (MRI phase)
output_channels = 1  # Number of output channels (Magnetic susceptibility)
depth = 64  # Updated depth to match cropped data
height = 64
width = 64

# Create the U-Net model
generator = UNet(input_channels, output_channels)

# Example input data
input_data = torch.randn(batch_size, input_channels, depth, height, width)

# Generate output
output = generator(input_data)

# Print the generated output shape
print(&quot;Generated Output Shape:&quot;, output.shape)
import nibabel as nib

def get_data_dimensions(filepath):
    img = nib.load(filepath)
    data = img.get_fdata()
    return data.shape

source_filepath = '/content/drive/MyDrive/qsmData/Train/Source/normPhaseSubj1.nii'
target_filepath = '/content/drive/MyDrive/qsmData/Train/Target/cosmos1.nii.gz'


source_dimensions = get_data_dimensions(source_filepath)
target_dimensions = get_data_dimensions(target_filepath)

print(&quot;Source data dimensions:&quot;, source_dimensions)
print(&quot;Target data dimensions:&quot;, target_dimensions)


# Define the loss function and optimizer
criterion = nn.MSELoss(reduce=None)
optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)

# Move the model to the device (CPU or GPU)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
generator.to(device)
num_epochs = 5
print_interval = 10
for epoch in range(num_epochs):
    generator.train()
    running_loss = 0.0
    for i, batch in enumerate(train_loader, 1):  # Enumerate to track batch index
        source_data = batch['source'].to(device).unsqueeze(1).float()  # Add the channel dimension
        target_data = batch['target'].to(device).unsqueeze(1).float()  # Add the channel dimension

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = generator(source_data)

        print(outputs.shape)

        print(&quot;Target shape:&quot;, target_data.shape)

        # Compute loss
        loss = criterion(outputs, target_data)

        # Backpropagation and optimization
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Print average loss for the epoch
        if i % print_interval == 0:
            avg_loss = running_loss / print_interval
            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{i}/{len(train_loader)}], Loss: {avg_loss:.4f}')
            running_loss = 0.0

predictions = []
generator.eval()  # Set the model to evaluation mode
with torch.no_grad():
    for batch in test_loader:
        source_patches = batch['source'].to(device).unsqueeze(1).float()  # Add the channel dimension

        # Forward pass and get the predictions
        outputs = generator(source_patches)

        # Store the predictions in the list
        predictions.append(outputs.cpu().squeeze().numpy())
</code></pre>
<p>I tried making a simpler architecture and still got dimension errors, in fact they were even larger. When I wasn't getting dimension errors I would just get out of memory errors. I also have tried verifying the dimensions of the data throughout different stages of the program, and even though the randomly generated data doesn't have a mismatch between input and output, my MRI data still does once it's put through the network.</p>
","2023-08-04 20:06:20","2","Question"
"76834972","","How can I run pytesseract Python library in ubuntu 22.04?","<p>I'm detecting text from images in python. I'm using <strong>pytesseract 0.3.10</strong> . but it seems this library is just working on windows OS while I'm using Ubuntu 22.04. in all examples codes using cmd address like this.</p>
<pre><code>pt.pytesseract.tesseract_cmd = 'C:/Program Files (x86)/Tesseract-OCR/tesseract'

</code></pre>
<p>how can I shange this to run on ubuntu. by the way I'm using jupyter-lab.</p>
<p>I changed this code to other fromats like this:</p>
<p>original example code:</p>
<pre><code>pt.pytesseract.tesseract_cmd = 'C:/Program Files (x86)/Tesseract-OCR/tesseract'

</code></pre>
<p>I changed code to :</p>
<pre><code>pt.pytesseract.tesseract_user_cmd = 'user/share/...'

</code></pre>
<p>or</p>
<pre><code>pt.pytesseract.tesseract_user_terminal = 'user/share/...'

</code></pre>
","2023-08-04 10:13:25","-1","Question"
"76832818","75759382","","<p>try this version, it worked for me</p>
<p>pip install 'openvino==2022.3.1'</p>
","2023-08-04 03:37:01","0","Answer"
"76832228","76815968","","<p>Changed my learning rate and iterations to</p>
<pre><code>iterations = 1000000
tmp_alpha = np.float64(1.0e-10)
</code></pre>
<p>And it worked:</p>
<pre class=""lang-none prettyprint-override""><code>&gt; Iteration    0: Cost 5.60e+19  dj_dw: -2.878e+12, dj_db: -7.626e+09   w:  2.878e+02, b:  7.62614e-01
Iteration 100000: Cost 1.72e+19  dj_dw: -1.186e+12, dj_db: -3.097e+09   w:  1.909e+07, b:  5.03158e+04
Iteration 200000: Cost 1.06e+19  dj_dw: -4.890e+11, dj_db: -1.231e+09   w:  2.696e+07, b:  7.05947e+04
Iteration 300000: Cost 9.51e+18  dj_dw: -2.015e+11, dj_db: -4.613e+08   w:  3.020e+07, b:  7.84937e+04
Iteration 400000: Cost 9.32e+18  dj_dw: -8.307e+10, dj_db: -1.442e+08   w:  3.154e+07, b:  8.12901e+04
Iteration 500000: Cost 9.29e+18  dj_dw: -3.424e+10, dj_db: -1.351e+07   w:  3.209e+07, b:  8.19834e+04
Iteration 600000: Cost 9.29e+18  dj_dw: -1.411e+10, dj_db:  4.036e+07   w:  3.231e+07, b:  8.18099e+04
Iteration 700000: Cost 9.29e+18  dj_dw: -5.816e+09, dj_db:  6.256e+07   w:  3.241e+07, b:  8.12791e+04
Iteration 800000: Cost 9.29e+18  dj_dw: -2.397e+09, dj_db:  7.172e+07   w:  3.245e+07, b:  8.06010e+04
Iteration 900000: Cost 9.29e+18  dj_dw: -9.883e+08, dj_db:  7.549e+07   w:  3.246e+07, b:  7.98622e+04
(w, b) found by gradient descent: (32469417.2368, 79098.4748)
</code></pre>
","2023-08-03 23:55:55","0","Answer"
"76830902","75168665","","<p>I had the same error shown above. The problem was due to an extra dimension in the third axis of the image that had no information content. This is likely a transparency layer. If this is the same problem you're having you can determine it easily by doing the following:</p>
<pre><code>import numpy as np
print(np.array(&lt;your_image&gt;).shape)
</code></pre>
<p>In my case image output shape was the following:
<code>(1016, 993, 4)</code></p>
<p>The fourth channel is a transparency layer which isn't handled by the image processor. The fix is easy. Simply cut out the fourth transparency layer with the following:</p>
<pre><code>image = PIL.Image.open(file_path)
image = np.array(image)
image = image[:, :, :3]
</code></pre>
<p>You can see why the fourth layer is there from this post:
<a href=""https://stackoverflow.com/questions/44955656/how-to-convert-rgb-pil-image-to-numpy-array-with-3-channels"">How to convert RGB PIL image to numpy array with 3 channels?</a></p>
","2023-08-03 18:50:58","0","Answer"
"76830397","76815968","","<p>Here is a linear regression solution using least squares.  This produces a line that seems to match the data pretty well, as witnessed by the plot at the end.</p>
<pre><code>import os
import openpyxl
import math
import numpy as np
import matplotlib.pyplot as plt

def get_x_train():
    x_train = np.array([]) 
    for x in range(2, 1011):
        data = ws.cell(row=x, column=5).value
        x_train = np.append(x_train, data)
    return x_train

def get_y_train():
    y_train = np.array([])
    for y in range(2, 1011):
        data = ws.cell(row=y, column=3).value
        y_train = np.append(y_train, data)
    return y_train

wb = openpyxl.load_workbook('DATA RUMAH.xlsx')
ws = wb.active

# Load our data set

x_train = get_x_train()   #features
y_train = get_y_train()  #target value

# Compute linear regression.
A = np.vstack([x_train,np.ones(len(x_train))]).T
m,b = np.linalg.lstsq(A, y_train, rcond=None)[0]
print(m,b)

plt.plot(x_train, y_train,'o')
plt.plot(x_train, m*x_train+b, 'r')
plt.show()
</code></pre>
<p><a href=""https://i.sstatic.net/kRotb.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/kRotb.png"" alt=""enter image description here"" /></a></p>
","2023-08-03 17:34:42","0","Answer"
"76827198","76825694","","<p>I solved my problems with '<code>from tensorflow.python.keras import backend</code>'</p>
","2023-08-03 10:27:59","0","Answer"
"76825718","76825694","","<p>Try like this</p>
<pre><code>from tensorflow.keras.models import Sequential
</code></pre>
","2023-08-03 07:20:00","0","Answer"
"76825694","","How to fix module 'tensorflow' has no attribute 'get_default_graph'","<p>I'm using InceptionV4 from <a href=""https://github.com/systemcorp-ai/InceptionV4/blob/master/inceptionv4.py"" rel=""nofollow noreferrer"">here</a></p>
<p>but i got this error message</p>
<p>My tensorflow and keras is 2.5.0</p>
<pre><code>AttributeError
module 'tensorflow' has no attribute 'get_default_graph'
  File &quot;C:\Labbb\inception\InceptionV4-master\inceptionv4.py&quot;, line 219, in create_inception_v4
    init = Input((299,299, 8))
  File &quot;C:\Labbb\inception\InceptionV4-master\inceptionv4.py&quot;, line 259, in &lt;module&gt;
    model = create_inception_v4(load_weights=check)
AttributeError: module 'tensorflow' has no attribute 'get_default_graph'
</code></pre>
<pre><code>def create_inception_v4(nb_classes=int(args[&quot;num_classes&quot;]), load_weights=check):
model = create_inception_v4(load_weights=check)
model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=float(args['learning_rate']), decay=1e-6, momentum=0.9, nesterov=True), metrics=[&quot;accuracy&quot;])
hist = model.fit_generator(train_datagen,steps_per_epoch=int(args['50']),epochs=int(args['3']),verbose=True,validation_data=val_datagen,validation_steps=10,callbacks=[mc, tensorboard])
</code></pre>
<p>I tried use this line &quot;from tensorflow.keras.&quot; instead of &quot;from keras.&quot;, but not work</p>
<pre><code>from keras.layers import Input, merge, Dropout, Dense, Flatten, Activation
from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D
from keras.layers.normalization import BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
from keras.utils.data_utils import get_file
from keras.utils.training_utils import multi_gpu_model
import tensorflow as tf
import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from tensorflow.keras.layers import concatenate
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import Sequence
</code></pre>
","2023-08-03 07:15:34","0","Question"
"76815968","","overflow encountered in scalar power error (Linear Regression & Gradient Descent With Large Digit)","<p>So i was trying out a manual gradient descent with a large digit and got overflow encountered in scalar power</p>
<p>I use this dataset from kaggle to calculate land price X = LT, Y = Harga <a href=""https://www.kaggle.com/datasets/wisnuanggara/daftar-harga-rumah"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/wisnuanggara/daftar-harga-rumah</a></p>
<p>The code i used to input into numpy array:</p>
<pre><code>import os
import openpyxl
from openpyxl import Workbook
import numpy as np

wb = openpyxl.load_workbook('DATA RUMAH.xlsx')
ws = wb.active

y_train_data = np.array([])
x_train_data = np.array([])

def get_x_train():
    x_train = np.array([])  # Initialize x_train as a local variable
    for x in range(2, 1011):
        data = ws.cell(row=x, column=5).value
        x_train = np.append(x_train, data)
    return x_train

def get_y_train():
    y_train = np.array([])  # Initialize y_train as a local variable
    for y in range(2, 1011):
        data = ws.cell(row=y, column=3).value
        y_train = np.append(y_train, data)
    return y_train
</code></pre>
<p>Full Code</p>
<pre><code>import math, copy
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('./deeplearning.mplstyle')
from lab_utils_uni import plt_house_x, plt_contour_wgrad, plt_divergence, plt_gradients

# Load our data set
x_train = get_x_train()   #features
y_train = get_y_train()  #target value

#Function to calculate the cost
def compute_cost(x, y, w, b):
   
    m = x.shape[0] 
    cost = 0
    
    for i in range(m):
        f_wb = w * x[i] + b
        cost = cost + (f_wb - y[i])**2
    total_cost = 1 / (2 * m) * cost

    return total_cost

def compute_gradient(x, y, w, b): 
    &quot;&quot;&quot;
    Computes the gradient for linear regression 
    Args:
      x (ndarray (m,)): Data, m examples 
      y (ndarray (m,)): target values
      w,b (scalar)    : model parameters  
    Returns
      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w
      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     
     &quot;&quot;&quot;
    
    # Number of training examples
    m = x.shape[0]    
    dj_dw = 0
    dj_db = 0
    
    for i in range(m):  
        f_wb = w * x[i] + b 
        dj_dw_i = (f_wb - y[i]) * x[i] 
        dj_db_i = f_wb - y[i] 
        dj_db += dj_db_i
        dj_dw += dj_dw_i 
    dj_dw = dj_dw / m 
    dj_db = dj_db / m 
        
    return dj_dw, dj_db

def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):
    &quot;&quot;&quot;
    Performs gradient descent to fit w,b. Updates w,b by taking 
    num_iters gradient steps with learning rate alpha
    
    Args:
        x (ndarray (m,))  : Data, m examples 
        y (ndarray (m,))  : target values
        w_in,b_in (scalar): initial values of model parameters  
        alpha (float):     Learning rate
        num_iters (int):   number of iterations to run gradient descent
        cost_function:     function to call to produce cost
        gradient_function: function to call to produce gradient
      
    Returns:
        w (scalar): Updated value of parameter after running gradient descent
        b (scalar): Updated value of parameter after running gradient descent
        J_history (List): History of cost values
        p_history (list): History of parameters [w,b] 
    &quot;&quot;&quot;
    
    # Specify data type as np.float64 for w, b
    w = np.float64(w_in)
    b = np.float64(b_in)
    
    # An array to store cost J and w's at each iteration primarily for graphing later
    J_history = []
    p_history = []
    
    for i in range(num_iters):
        # Calculate the gradient and update the parameters using gradient_function
        dj_dw, dj_db = gradient_function(x, y, w , b)     

        # Update Parameters using equation (3) above
        b = b - alpha * dj_db                            
        w = w - alpha * dj_dw                            

        # Save cost J at each iteration
        J_history.append(cost_function(x, y, w, b))
        p_history.append([w, b])

        # Print cost every at intervals 10 times or as many iterations if &lt; 10
        if i % math.ceil(num_iters/10) == 0:
            print(f&quot;Iteration {i:4}: Cost {J_history[-1]:0.2e} &quot;,
                  f&quot;dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  &quot;,
                  f&quot;w: {w: 0.3e}, b: {b: 0.5e}&quot;)
 
    return w, b, J_history, p_history  # Return w and J,w history for graphing

# Initialize parameters with np.float64 data type
w_init = np.float64(0)
b_init = np.float64(0)

# Some gradient descent settings
iterations = 100000
tmp_alpha = np.float64(1.0e-4)

# Run gradient descent
w_final, b_final, J_hist, p_hist = gradient_descent(x_train, y_train, w_init, b_init, tmp_alpha,
                                                    iterations, compute_cost, compute_gradient)

# Print the result
print(f&quot;(w, b) found by gradient descent: ({w_final:8.4f}, {b_final:8.4f})&quot;)
</code></pre>
<p>Output:</p>
<pre><code>    RuntimeWarning: overflow encountered in scalar add
  cost = np.float64(cost + (f_wb - y[i])**2)
    RuntimeWarning: overflow encountered in scalar power
  cost = np.float64(cost + (f_wb - y[i])**2)
    RuntimeWarning: overflow encountered in scalar add
  dj_dw += np.float64(dj_dw_i)
    RuntimeWarning: invalid value encountered in scalar subtract
  w = np.float64(w - alpha * dj_dw)
</code></pre>
<p>i tried to normalize but i think it skews the data too much, how do i  make it so that the gradient descent can process the huge digit?</p>
","2023-08-02 00:38:47","-2","Question"
"76812819","76812171","","<pre><code>node1 = keras.layers.Dense(2)(data[:,0:2])
node2 = keras.layers.Dense(2)(data[:,2:4])
node3 = keras.layers.Dense(2)(data[:,4:6])
node4 = keras.layers.Dense(2)(data[:,6:8])
hidden = keras.layers.concatenate([node1, node2, node3, node4])
</code></pre>
<p>This is different from the image you posted.</p>
<p>In the <a href=""https://i.sstatic.net/xw15C.png"" rel=""nofollow noreferrer"">image you posted</a>, the network has 4 neurons in the second layer. In the model.summary() output, the output of the concatenate layer is (None, 8), meaning it's the output of 8 neurons.</p>
<p>The fix is to change 2 to 1.</p>
<p>Alternately, you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LocallyConnected1D"" rel=""nofollow noreferrer"">LocallyConnected1D</a>, which is a built-in layer which can do the same thing.</p>
","2023-08-01 14:45:55","1","Answer"
"76812571","76812171","","<p>This  is a correct implementation (apart from Dense(2) leading to you
having extra hidden units, it should be Dense(1)). If you do summary you will see</p>
<pre><code>Model: &quot;model&quot;
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 8)]          0           []                               
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 2)           0           ['input_1[0][0]']                
 ingOpLambda)                                                                                     
                                                                                                  
 tf.__operators__.getitem_1 (Sl  (None, 2)           0           ['input_1[0][0]']                
 icingOpLambda)                                                                                   
                                                                                                  
 tf.__operators__.getitem_2 (Sl  (None, 2)           0           ['input_1[0][0]']                
 icingOpLambda)                                                                                   
                                                                                                  
 tf.__operators__.getitem_3 (Sl  (None, 2)           0           ['input_1[0][0]']                
 icingOpLambda)                                                                                   
                                                                                                  
 dense (Dense)                  (None, 2)            6           ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 dense_1 (Dense)                (None, 2)            6           ['tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 dense_2 (Dense)                (None, 2)            6           ['tf.__operators__.getitem_2[0][0
                                                                 ]']                              
                                                                                                  
 dense_3 (Dense)                (None, 2)            6           ['tf.__operators__.getitem_3[0][0
                                                                 ]']                              
                                                                                                  
 concatenate (Concatenate)      (None, 8)            0           ['dense[0][0]',                  
                                                                  'dense_1[0][0]',                
                                                                  'dense_2[0][0]',                
                                                                  'dense_3[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 3)            27          ['concatenate[0][0]']            
                                                                                                  
==================================================================================================
Total params: 51
Trainable params: 51
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre>
<p>The reason why youy see 11 elements is because you have:</p>
<ul>
<li>1 input node</li>
<li>4 &quot;input grouping nodes&quot; (those are responsible for extracting pairs of features)</li>
<li>4 hideen nodes</li>
<li>1 concatenation node</li>
<li>1 output node</li>
</ul>
<p>The &quot;input grouping nodes&quot; are created because of <code>data[:, 0:2]</code> like pieces of code. They of course have no weights, they are just data transformation operation (and thus when you look at weights you do not see any there)</p>
<blockquote>
<p>Also, is there a way to visualize with an image what is being done with tensorflow? it would be very useful.</p>
</blockquote>
<p>You can use <a href=""https://www.tensorflow.org/tensorboard/graphs"" rel=""nofollow noreferrer"">TensorBoard</a> for that.</p>
<blockquote>
<p>Finally, a conceptual question, does making a single network (8-4-3) like the one described or training 3 different networks with a single output (8-4-1) lead to differences in accuracy?</p>
</blockquote>
<p>These are very different. The main difference boils down to whether information about different targets can benefit from <strong>shared representation</strong> of the data (then 8-4-3 would be better) or not (8-4-1). Importantly also with 3x (8-4-1) you will probably get better results just because you have more weights. A &quot;fair&quot; comparison would train a wider joint model, so 3x (8*4+4 + 4*1+1) ~= 100 weights, while 8*4+4+4*3+3 ~= 40. 8-8-3 would be roughly of similar size then.</p>
","2023-08-01 14:16:23","0","Answer"
"76812171","","Pairwise connected (not fully connected) layer","<p>I would like to create a network in which I have 8 inputs, connected in pairs to 4 nodes in the hidden layer, and these are completely connected to 3 outputs (<a href=""https://i.sstatic.net/xw15C.png"" rel=""nofollow noreferrer"">Network image</a>)</p>
<p>I made this code but I'm not really sure if it represents what I would like. could you tell me if it's ok or advise me how to change it?</p>
<pre><code>import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
X_train = np.loadtxt('input.txt')
y_train = np.loadtxt('output.txt')
data = keras.layers.Input(shape=(8,))
node1 = keras.layers.Dense(2)(data[:,0:2])
node2 = keras.layers.Dense(2)(data[:,2:4])
node3 = keras.layers.Dense(2)(data[:,4:6])
node4 = keras.layers.Dense(2)(data[:,6:8])
hidden = keras.layers.concatenate([node1, node2, node3, node4])
output = keras.layers.Dense(3)(hidden)
model = keras.models.Model(data, output)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=1000, batch_size=1)
</code></pre>
<p>My inputs are numbers in the range 1-10 and the outputs in the range 0-1. I have a small dataset so I set <code>batch = 1</code> to use all of them for each cycle.</p>
<p>With <code>model.summary()</code> I expected 3 lines, or 6 (dividing the 4 hidden nodes) instead I see 11 and this makes me doubt.
Using <code>model.layers[i].weights</code>, for i 0 to 4 and also 9 = [], why?; i from 5 to 8 there are 2 weights but bias is always 0, why?; while i = 10 gives 12 weights and 3 biases as i would expect for the last layer.</p>
<p>Also, is there a way to visualize with an image what is being done with tensorflow?</p>
<p>Finally, a conceptual question, does making a single network (8-4-3) like the one described or training 3 different networks with a single output (8-4-1) lead to differences in accuracy?</p>
","2023-08-01 13:33:51","0","Question"
"76807845","76788751","","<p>I was a bit stupid. <code>label_fields=['person']</code> needs to be changed to <code>label_fields=['class_labels']</code></p>
<p>Also the <code>[1,2,3,4]</code> aren't normalized as in the format that the <code>albumentations</code> format requires. It's purely just there as a placeholder for an actual list.</p>
","2023-08-01 00:34:21","1","Answer"
"76803879","76803694","","<p>You could do (using the <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"" rel=""nofollow noreferrer""><code>Sequential</code></a>), the following:</p>
<pre class=""lang-py prettyprint-override""><code>class LR(torch.nn.Module):
    def __init__(self, n_features):
        super(LR, self).__init__()
        self.lr = torch.nn.Sequential(
            torch.nn.Linear(n_features, 64),        
            torch.nn.ReLU(),
            torch.nn.Linear(64, 36, bias=False),
            torch.nn.Softmax(dim=1),
        )

    def forward(self, x):
        return self.lr(x)
</code></pre>
<p>This could be used with, e.g.,</p>
<pre class=""lang-py prettyprint-override""><code>x = torch.ones(1, 1000)

lr = LR(x.shape[1])
lr(x)
</code></pre>
","2023-07-31 12:59:37","2","Answer"
"76803810","76803694","","<p>In your Torch model, you have overwritten the <code>self.lr</code> attribute 2 times.</p>
<pre><code>class LR(torch.nn.Module):
    def __init__(self, n_features):
        super(LR, self).__init__()
        self.lr = torch.nn.Linear(n_features, 64)        
        self.lr = nn.ReLU()                  # lr is over-written here
        self.lr = torch.nn.Linear(64, 36)    # and here
</code></pre>
<p>So you end up with a model that is just this:</p>
<pre><code>class LR(torch.nn.Module):
    def __init__(self, n_features):
        super(LR, self).__init__()
        self.lr = torch.nn.Linear(64, 36)
</code></pre>
<p>If you want the equivalent of the Keras model, you can use:</p>
<pre><code>from torch import nn

model = nn.Sequential(
    nn.Linear(384, 64),
    nn.ReLU()
    nn.Linear(64, 36, bias=False)
    nn.Softmax()
)
</code></pre>
<p>If you want to build a class for your model, you can use:</p>
<pre><code>import torch.nn as nn

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.L1 = nn.Linear(384, 64),
        self.RLU = nn.ReLU()
        self.L2 = nn.Linear(64, 36, bias=False)

    def forward(self, x):
        x = self.L1(x)
        x = self.RLU(x)
        x = self.L2(x)
        return x
</code></pre>
<p>I left off the softmax because the <code>CrossEntropyLoss</code> applies a log-softmax on it's own.  If you are making predictions, you can apply a softmax separately.</p>
","2023-07-31 12:50:48","2","Answer"
"76803694","","How to make the equivalent of Tensorflow sequential model in PyTorch?","<p>I have a simple shallow model in Tensorflow for multiclass classification.</p>
<pre><code>model = tf.keras.models.Sequential([  

    tf.keras.layers.Dense(64, input_shape = (384,), activation = &quot;relu&quot;),
    tf.keras.layers.Dense(36, activation=&quot;softmax&quot;, use_bias = False)
                          ])    
        
model.summary()  

Model: &quot;sequential_5&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_13 (Dense)            (None, 64)                24640     
                                                                 
 dense_14 (Dense)            (None, 36)                2304 

</code></pre>
<p>I want to replicate it in PyTorch where I am using softmax in the forward function.</p>
<pre><code># base model - it works but gives v low accuracy. need to add more layers.

class LR(torch.nn.Module):

    def __init__(self, n_features):
        super(LR, self).__init__()
        self.lr = torch.nn.Linear(n_features, 36)
        nn.ReLU()

        
    def forward(self, x):
        out = torch.softmax(self.lr(x),dim = 1,dtype=None)
        return out

# parameters
n_features = 384
n_classes = 36
optim = torch.optim.SGD(model.parameters(), lr=0.1)
criterion = torch.nn.CrossEntropyLoss()

accuracy_fn = Accuracy(task=&quot;multiclass&quot;,  num_classes=36)

</code></pre>
<p>I have tried modifying my base model like so and it gives me an error later on.</p>
<pre><code>class LR(torch.nn.Module):

    def __init__(self, n_features):
        super(LR, self).__init__()
        self.lr = torch.nn.Linear(n_features, 64)        
        self.lr = nn.ReLU()
        self.lr = torch.nn.Linear(64, 36)
        
    def forward(self, x):
        out = torch.softmax(self.lr(x),dim = 1,dtype=None)
        return out

epochs = 15

def train(model, optim, criterion, x, y, epochs=epochs):
    for e in range(1, epochs + 1):
        optim.zero_grad()
        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optim.step()
        print(f&quot;Loss at epoch {e}: {loss.data}&quot;)

    return model

model = LR(n_features)

model = train(model, optim, criterion, X_train, y_train)
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In[175], line 18
     12  #       acc = accuracy_fn(out, y)  
     13  #       acc.backward()
     14  #       optim.step()
     15  #       print(f&quot;Acc at epoch {e}: {acc.data}&quot;)
     16     return model
---&gt; 18 model = train(model, optim, criterion, X_train, y_train)

Cell In[175], line 6, in train(model, optim, criterion, x, y, epochs)
      4 for e in range(1, epochs + 1):
      5     optim.zero_grad()
----&gt; 6     out = model(x)
      7     loss = criterion(out, y)
      8     loss.backward()

File /usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)
   1496 # If we don't have any hooks, we want to skip the rest of the logic in
   1497 # this function, and just call forward.
   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
   1499         or _global_backward_pre_hooks or _global_backward_hooks
   1500         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1501     return forward_call(*args, **kwargs)
   1502 # Do not call functions when jit is used
   1503 full_backward_hooks, non_full_backward_hooks = [], []

Cell In[172], line 10, in LR.forward(self, x)
      9 def forward(self, x):
---&gt; 10     out = torch.softmax(self.lr(x),dim = 1,dtype=None)
     11     return out

File /usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)
   1496 # If we don't have any hooks, we want to skip the rest of the logic in
   1497 # this function, and just call forward.
   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
   1499         or _global_backward_pre_hooks or _global_backward_hooks
   1500         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1501     return forward_call(*args, **kwargs)
   1502 # Do not call functions when jit is used
   1503 full_backward_hooks, non_full_backward_hooks = [], []

File /usr/local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114, in Linear.forward(self, input)
    113 def forward(self, input: Tensor) -&gt; Tensor:
--&gt; 114     return F.linear(input, self.weight, self.bias)

RuntimeError: mat1 and mat2 shapes cannot be multiplied (155648x384 and 64x36)
</code></pre>
<p>my data shapes are:</p>
<pre><code>X_train.shape
torch.Size([155648, 384]) 
y_train.shape 
torch.Size([155648]).
</code></pre>
<p>Can someone give me a hand with my class LR and train function?</p>
","2023-07-31 12:35:50","0","Question"
"76798296","76795824","","<p>I figured it out. It was indeed a stupid mistake, and isn't because of mixed-up inputs. After double checking the documentation, I discovered that it's <code>TensorBoard</code> in camel case, not <code>Tensorboard</code>.</p>
","2023-07-30 14:53:58","1","Answer"
"76796364","76795824","","<p>This probably is that you are mixing tensorflow with keras in your imports.</p>
","2023-07-30 04:37:45","0","Answer"
"76795824","","AttributeError: module 'keras.api._v2.keras.callbacks' has no attribute 'Tensorboard'","<p>I wrote this code to use other models on tensorflow hub, like the following. I have the issue where it says that</p>
<pre><code>AttributeError: module 'keras.api._v2.keras.callbacks' has no attribute 'Tensorboard'
</code></pre>
<p>I googled it but I couldn't find anything. This is my code:</p>
<pre><code># %%
import zipfile

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip

zip_ref = zipfile.ZipFile(&quot;10_food_classes_10_percent.zip&quot;)
zip_ref.extractall()
zip_ref.close()

# %%
import os

for dirpath, dirnames, filenames in os.walk(&quot;10_food_classes_10_percent&quot;):
    print(f&quot;there are {len(dirnames)} directories and {len(filenames)} images in {dirpath}&quot;)

# %%
from keras.preprocessing.image import ImageDataGenerator

IMAGE_SHAPE = (224, 224)
BATCH_SIZE = 32

train_dir = &quot;10_food_classes_10_percent/train/&quot;
test_dir = &quot;10_food_classes_10_percent/test/&quot;

train_datagen = ImageDataGenerator(rescale=1/255.0)
test_datagen = ImageDataGenerator(rescale=1/255.0)

print(&quot;training images: &quot;)
train_data_10_percent = train_datagen.flow_from_directory(train_dir, 
                                                          target_size=IMAGE_SHAPE, 
                                                          batch_size=BATCH_SIZE, 
                                                          class_mode=&quot;categorical&quot;)
print(&quot;testing images: &quot;)
test_data = train_datagen.flow_from_directory(test_dir, 
                                                target_size=IMAGE_SHAPE, 
                                                batch_size=BATCH_SIZE, 
                                                class_mode=&quot;categorical&quot;)


# %%
import keras
import sklearn
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

# %%
import datetime

def create_tensorboard_callback(dir_name, experimment_name):
    log_dir = dir_name + &quot;/&quot; + experimment_name + &quot;/&quot; + datetime.datetime.now().strftime(&quot;%m%d%Y-%H%M%S&quot;)
    tensorboard_callback = tf.keras.callbacks.Tensorboard(log_dir=log_dir)
    print(f&quot;saving tensorboard log to {log_dir}&quot;)
    return tensorboard_callback
tf.keras.callbacks.TensorBoard

# %%
resnet_url = &quot;https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4&quot;

efficientnet_url = &quot;https://tfhub.dev/tensorflow/efficientnet/b0/feature_vector/1&quot;

# %%
import tensorflow_hub as hub

# %%
def create_model(model_url, num_classes=10):
    feature_extraction_layer = hub.KerasLayer(model_url,
                                             trainable=False,
                                             name=&quot;feature_extraction_layer&quot;,
                                             input_shape=IMAGE_SHAPE+(3,))
    
    model = tf.keras.Sequential([
        feature_extraction_layer,
        tf.keras.layers.Dense(num_classes, activation=&quot;softmax&quot;, name=&quot;output_layer&quot;)
    ])
    
    return model


# %%
resnet_model = create_model(resnet_url,
                            num_classes=train_data_10_percent.num_classes)

# %%
resnet_model.summary()

# %%
resnet_model.compile(loss=&quot;categorical_crossentropy&quot;,
                     optimizer=tf.keras.optimizers.Adam(),
                     metrics=[&quot;accuracy&quot;])

# %%
resnet_history = resnet_model.fit(train_data_10_percent,
                                  epochs=5,
                                  steps_per_epoch=len(train_data_10_percent),
                                  validation_data=test_data,
                                  callbacks=[create_tensorboard_callback(dir_name=&quot;tensorflow_hub&quot;,
                                                                         experimment_name=&quot;resnet50v&quot;)])



</code></pre>
<p>Originally, my code had <code>keras.callbacks.Tensorboard</code> before I found out that the newer tensorflow version uses <code>tf.keras</code>, hence <code>tf.keras.callbacks.Tensorboard</code>. It didn't fix it, so I searched online and found nothing. I thought maybe it was a stupid mistake and changed it from<code>Tensorboard</code> to <code>tensorboard</code> but it had the same result.</p>
","2023-07-29 23:39:26","1","Question"
"76788751","","'label_fields' are not valid even when assigning label fields in Albumentations","<p>I'm using albumentations with the following code:</p>
<pre class=""lang-py prettyprint-override""><code> augmentor = alb.Compose([alb.RandomCrop(width=450, height=450),
                             alb.HorizontalFlip(p=0.5),
                             alb.RandomBrightnessContrast(p=0.2),
                             alb.RandomGamma(p=0.2),
                             alb.RGBShift(p=0.2),
                             alb.VerticalFlip(p=.5)],
                             bbox_params=alb.BboxParams(format='albumentations', label_fields=['person']))

&quot;intermediary image-loading code&quot;

img = pyplot.imread(&quot;path&quot;)
coords = [1,2,3,4]
try:
    augmented = augmentor(image=img, bboxes=[coords], class_labels=['person'])

except Exception as e:
    print(e)

</code></pre>
<p>I get the exception: <code>Your 'label_fields' are not valid - them must have same names as params in dict</code></p>
<p>I looked online and found some other people with the same issue but never found a concrete solution. I also looked at the <a href=""https://programtalk.com/vs4/python/albumentations-team/albumentations/albumentations/augmentations/bbox_utils.py/"" rel=""nofollow noreferrer"">documentation</a>, and I couldn't decipher how <code>data</code> was supposed to relate to my issue. Any help on this would be much appreciated!</p>
<p>Also, for some reason, pressing &quot;tab&quot; doesn't work on this website, so the indentation might be off.</p>
","2023-07-28 14:32:09","0","Question"
"76780734","76780413","","<p>Based on the short code snippet, it seems like the variable <code>X</code> is a data frame, and when you do <code>X[y == label]</code>, it is filtering the data frame based on the condition where column <code>y</code> matches with the label.</p>
<p>Proceeding to the <code>.sum()</code>, it is taking the sum of the rows where column <code>y</code> has the value that matches the label. If this column happens to be a multi-dimensional array, it is taking the sum on the first axis, i.e. vertically.</p>
<p>Finally on the left hand side of the equal sign, it is adding this sum to the <code>counts</code> dictionary where the key is the label.</p>
","2023-07-27 14:27:48","0","Answer"
"76780730","76780413","","<p>Let's use an example.</p>
<pre><code>import numpy as np
X=np.array([[1,10],[2,20], [3,30], [4,40], [5,50], [6,60]])
y=np.array([11,22,33,11,22,11])
</code></pre>
<p><code>np.unique(y)</code> is <code>[11,22,33]</code></p>
<p>So label will successively be those.</p>
<p>When label is 11<br />
<code>y==label</code> is <code>[11,22,33,11,22,11]==11</code> which is <code>[True,False,False,True,False,True]</code><br />
so <code>X[y==label]</code> is <code>X[[True,False,False,True,False,True]]</code> so it is a selection of rows 0, 3 and 5 of X. So <code>[[1,10],[4,40],[6,60]]</code><br />
<code>sum(axis=0)</code> sum that along axis 0, so <code>X[y==label].sum(axis=0)</code> is <code>[1+4+6,10+40,60]</code> = <code>[11,110]</code><br />
so <code>counts[11]=[11,110]</code></p>
<p>Likewise, when label is 22, <code>y==label</code> is <code>[False,True,False,False,True,False]</code>, so <code>X[y==label]</code> is <code>[[2,20],[5,50]]</code> so <code>X[y==label].sum(axis=0)</code> is <code>[7,70]</code>, which is affected to <code>counts[22]</code>.</p>
<p>And when label is 33, <code>y==label</code> is just <code>[False,False,True,False,False,False]</code>, so <code>X[y==label]</code> is <code>[[3,30]]</code> so <code>X[y==label].sum(axis=0)</code> is <code>[3,30]</code> which is affected to <code>counts[33]</code>.</p>
<p>So at the end, if your X data are a list of k values, and y data a list of k classes, chosen among n possibilities, <code>counts</code> are, for each n possible classes, the k sums of the values of data matching that class.</p>
","2023-07-27 14:27:13","0","Answer"
"76780413","","How does this code for BernoulliNB classifier works?","<p>Can someone please explain what this code does? It's from the book &quot;Introduction to Machine Learning with Python&quot; on Bernoulli Naive Bayes classifier:</p>
<pre><code>counts = {}
for label in np.unique(y):
    # iterate over each class
    # count (sum) entries of 1 per feature
    counts[label] = X[y == label].sum(axis=0)
print(&quot;Feature counts:\n&quot;, counts)
</code></pre>
<p>I don't understand what happens on line5.</p>
","2023-07-27 13:48:12","0","Question"
"76776695","","ValidationError: 1 validation error for StuffDocumentsChain __root__","<p>I am getting this error <code>ValidationError: 1 validation error for StuffDocumentsChain __root__ document_variable_name context was not found in llm_chain input_variables: ['chat_history', 'user_query', 'relevant_context'] (type=value_error)</code>
while using <code>load_qa_chain</code> I have searched this error but did n't find anything related to this. Can anyone tell what I am missing here.</p>
<p>Code:</p>
<pre><code>template = &quot;&quot;&quot;You are a chatbot having a conversation with a human.

Given the following extracted parts of a long document and a question, create a final answer.

{relevant_context}

{chat_history}
Human: {user_query}
Chatbot:&quot;&quot;&quot;

prompt = PromptTemplate(
input_variables=[&quot;chat_history&quot;, &quot;user_query&quot;, &quot;relevant_context&quot;],
template=template
)

memory = ConversationBufferMemory(memory_key=&quot;chat_history&quot;, input_key=&quot;user_query&quot;)

llm = OpenAI()
llm_chain = LLMChain(
    llm=llm,
    prompt=prompt,
    memory=memory,
)

chain = load_qa_chain(
    llm, chain_type=&quot;stuff&quot;, memory=memory, prompt=prompt
)
</code></pre>
","2023-07-27 05:20:25","1","Question"
"76773665","76521642","","<p>You design the problem as a classification problem. However, your model is structured to be a regression one. If you do the following changes, you may get better predictions.</p>
<p>It seems like <code>model_age.add(base_model_age)</code> should be <code>model_age.add(base_model_age.output)</code></p>
<p>Second, change</p>
<pre><code>model_age.add(Dense(4, activation = 'relu'))
</code></pre>
<p>to:</p>
<pre><code>model_age.add(Dense(4, activation = 'softmax'))
</code></pre>
<p>Third, change</p>
<pre><code>model_age.compile(optimizer=Adam(adam),
              loss='mse',
              metrics=['accuracy'])
</code></pre>
<p>to:</p>
<pre><code>model_age.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
</code></pre>
<p>Finally, you seem to train the last 20 layers. You may not have to train so many layers though, only top dense layers should be enough.</p>
","2023-07-26 17:20:41","0","Answer"
"76772276","76771719","","<p>You can try to predict the log of the values as well as a multiplicative factor between -1 and 1. Then you can keep the original GT values but make a change in the model and loss:</p>
<pre class=""lang-py prettyprint-override""><code>log_dnn_out, factor = net(dnn_in)
loss = mse_loss(torch.tanh(factor)*torch.exp(log_dnn_out), gnd_truth)
</code></pre>
<p>I hope that the <code>exp</code> will not perturb the gradient too much.
If it is the case you can do a MSE on log and a separate binary classification for sign:</p>
<pre class=""lang-py prettyprint-override""><code>log_dnn_out, sign_logits = net(dnn_in)
loss_log = mse_loss(log_dnn_out, torch.abs(torch.log(gnd_truth)))
loss_sgn = cross_entropy(sign_logits, (torch.sign(gnd_truth)+1) // 2)
loss = loss_log + a*loss_sgn
</code></pre>
<p>This option is safer regarding gradients but introduces learning biases that are potentially non desired by splitting the main task in two sub-tasks.</p>
","2023-07-26 14:21:28","0","Answer"
"76771798","76771719","","<p>Unless it is also included in the things you already tried, it seems that your problem could be solved by predicting log(K) instead of K, and using exponential afterwards. Using base 10 log, your values would range from 2 to -5, which seems reasonable, and using the global min and max you could also normalize these log-values to [0,1] if needed.</p>
","2023-07-26 13:24:53","0","Answer"
"76771719","","Training a network with data having high and low values","<p>I am using Torch on Pyhton to train a network that approximates a complicated mathematic expression, i.e., for a 2D-input, I need a <code>K</code> length vector that is computed using the 2D-input using some mathematical calculations. However, in this vector, there are values (absolute) of the order of <code>10^2</code> and also values of the order of <code>10^-5</code>. The minimum value and maximum value are dependent on the input and a common normalization cannot be used. I have normalized the input to be between <code>0</code> and <code>1</code>. I have tried using mask while training using the following snippet.</p>
<pre><code>import torch
import numpy as np

gnd_truth = torch.from_numpy(np.array([20.42, -1.56e-4, -3.11, 4.2e-2, -7e-3, 10.11]))[None]  # Ground truth
dnn_in = torch.from_numpy(np.array([0.76, 0.34]))[None]  # Input to the network

# Training 
optimizer.zero_grad()

dnn_out = net(dnn_in)  # Forward prop

mask = (torch.abs(gnd_truth) &lt; 1e-2).float() * 100  # Multiplying by 100 to increase the value

loss = mse_loss(mask*dnn_out, gnd_truth) + mse_loss((1-mask)*dnn_out, (1-mask)*gnd_truth)

loss.backward()

optimizer.step()
</code></pre>
<p>This too did not give me the desired result. Can anyone please let me know on how such a training can be carried out?</p>
","2023-07-26 13:14:14","1","Question"
"76752339","76748362","","<p>Maybe you normalized your training data? if so apply scaler.transform on inference data</p>
","2023-07-24 07:44:04","0","Answer"
"76751951","76748362","","<p>There are several ways, why this could be the case:</p>
<ul>
<li>The new input could be not in the range of the existings paramets, i would check the range of the input data with something like:</li>
</ul>
<pre><code>data['rm'].min(), data['rm'].max()
</code></pre>
<p>If the new client is not in the range, the negative values can be logical, as the linear regression always at some point will have negativ values.
for example imagen the input data is on the left side of the x-axis:
<a href=""https://i.sstatic.net/apv3b.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/apv3b.png"" alt=""enter image description here"" /></a></p>
<ul>
<li>I would check if the dataframe has some negativ values inside, only because its the boston houseprice dataset does not mean that the values only are positive</li>
</ul>
","2023-07-24 06:37:48","0","Answer"
"76748362","","Negative Predictions in Linear Regression with Boston Housing Dataset","<p>I am working on predicting housing prices using the Boston Housing dataset and have encountered an issue where my model, a simple linear regression, is predicting negative values for certain inputs.</p>
<pre><code>from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Loading the data and selecting features
df = data.drop(&quot;medv&quot;, axis = &quot;columns&quot;)
X = data[[&quot;rm&quot;, &quot;lstat&quot;, &quot;ptratio&quot;]]
y = data['medv']

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Training the model
reg_all = LinearRegression()
reg = reg_all.fit(X_train, y_train)

# Making predictions and evaluating the model
y_pred = reg.predict(X_test)
print(&quot;R-squared:&quot;, reg.score(X_test,y_test))
print(&quot;RMSE:&quot;, mean_squared_error(y_test, y_pred, squared = False))

# Making a prediction for a new client
d = {&quot;rm&quot;: [4], 'lstat': [32], &quot;ptratio&quot; : [22] }
df_predict = pd.DataFrame(data=d)
predict_client = reg.predict(df_predict)
print(&quot;Prediction for client:&quot;, predict_client)
</code></pre>
<p>For the new client with 'rm' = 4, 'lstat' = 32, and 'ptratio' = 22, the model is predicting negative values, which doesn't make sense in the context of housing prices.</p>
<p>What could be causing these negative predictions and how can I correct for this?</p>
","2023-07-23 12:58:05","0","Question"
"76747135","76633836","","<p>CharacterTextSplitter will only split on separator (which is '\n\n' by default). chunk_size is the maximum chunk size that will be split <em>if splitting is possible</em>. If a string starts with n characters, has a separator, and has m more characters before the next separator then the first chunk size will be n if chunk_size &lt; n + m + len(separator).</p>
<p>Your example string has no matching separators so there's nothing to split on.</p>
<p>Basically, it attempts to make chunks that are &lt;= chunk_size, but will still produce chunks &gt; chunk_size if the minimum size chunks that can be created are &gt; chunk_size.</p>
","2023-07-23 07:45:02","23","Answer"
"76736713","76599896","","<p>For those who want to know the answer. I find the solution in &quot;nltk&quot;.  nltk as The Natural Language Toolkit library proposes various options for removing stop words, tokenizing, and Lemmatizing, which is ideal for my dataset. I tried many solutions such as fuzzy, counting and labeling characters, and dictionaries, but since my dataset is about 110k rows of data, I cannot process and know all the variations of the annotations and use mentioned methods.</p>
<pre><code>#importing
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk import pos_tag
from nltk.stem import WordNetLemmatizer
import pandas as pd

#dl additional resource and models
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download('stopwords')


def preprocess_label(label):
    # If the label is N/A, return it unchanged (I had missing values which I wanted to keep)
    if pd.isna(label):
        return label

    # First of all, Lowercase all labels
    label = label.lower()

    # Second, Tokenize all label
    words = word_tokenize(label)

    # Removing stop words, I keep &quot;it&quot; according to my dataset nature
    stop_words = set(stopwords.words('english'))
    stop_words.remove('it')
    words = [word for word in words if word not in stop_words]

    # preparing Part-of-speech tagging for separating adjectives(JJ)
    tagged_words = pos_tag(words)

    # After that I Lemmatize the words to merge plural and singular forms
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word, pos in tagged_words if pos.startswith('NN') or word == 'it']

    # If there are multiple words, join them with a space
    return ' '.join(words)

# Load the dataset
df = pd.read_csv('my_tsv_file_directory.tsv', sep='\t')

# Apply the function to the &quot;my column&quot; column
df['Class Name'] = df['Class Name'].apply(preprocess_label)
    
# Save the modified DataFrame to a new TSV file
df.to_csv('output_tsv_file.tsv', sep='\t', index=False)
</code></pre>
","2023-07-21 09:26:08","0","Answer"
"76735740","76735587","","<p>As per my opinion you can do followings.</p>
<p>first thing is you need to understand data or distribution.</p>
<ol>
<li>Tune the decision tree with max_depth and try with gini-index</li>
<li>Use cross-validation for testing the model insted of train-test</li>
<li>You can change a algorithm with extra-tree algorithm like
random-forest,gradient-boosting.</li>
</ol>
<p>tuning decisiion tree :- <a href=""https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680#:%7E:text=The%20best%20way%20to%20tune,samples%20belong%20to%20one%20class."" rel=""nofollow noreferrer"">reference</a></p>
","2023-07-21 06:54:46","0","Answer"
"76735699","76735587","","<p>I didn't see the pred function in your codes, so I assume you did everything right in there.</p>
<p>You probably should look at your data more carefully. You can try checking out exact look of your tree by using visualization techniques, e.g. <a href=""https://stackoverflow.com/questions/42621190/display-this-decision-tree-with-graphviz"">Display via graphviz</a></p>
<blockquote>
<p>I also read that it may be due to overfitting. But I split my test into 70% which I don't think counts as overfitting.</p>
</blockquote>
<p>It does count as overfitting if you get your train score way higher than your test. To get rid of it you may need to find more data, or manage to use <strong>K-fold cross-validation</strong> technique for your data.</p>
<p>Also, how did you find out these model hyper-parameters? You can try to tune your model using GridsearchCV or RandomizedSearchCV. <a href=""https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection"" rel=""nofollow noreferrer"">Hyper-parameter optimizers</a></p>
<p>It would be nice to see your final data representation, after the normalization.</p>
","2023-07-21 06:47:11","1","Answer"
"76735587","","My training score is ~99% but my test score is ~50%. Why is my test score so low?","<p>I am building a decision tree classification model. My data has 11 features + 1 target column (12 columns in total). I performed a train test split (70% training, 30% testing), used a z-score transformation on my x_train (x-mean/standard deviation). And when I built my model, my training accuracy is 0.995 and my testing accuracy is 0.501.</p>
<p>At first I was confused why there was such a big gap. I researched online and they say to do a split before transformations (which was what I did).</p>
<p>I created a copy and tried splitting AFTER transforming. I know thats wrong but it brought my scores closer together.</p>
<p>I also read that it may be due to overfitting. But I split my test into 70% which I don't think counts as overfitting.</p>
<p>Here are my codes:</p>
<pre><code>X.head().to_dict()
</code></pre>
<pre><code>{'col1': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},
 'col2': {0: 50, 1: 37, 2: 29, 3: 47, 4: 18},
 'col3': {0: 1, 1: 1, 2: 1, 3: 1, 4: 0},
 'col4': {0: 57, 1: 38, 2: 27, 3: 51, 4: 1},
 'col5': {0: 7, 1: 26, 2: 18, 3: 7, 4: 14},
 'col6': {0: 0, 1: 7, 2: 2, 3: 1, 4: 3},
 'col7': {0: 7, 1: 11, 2: 12, 3: 4, 4: 0},
 'col8': {0: 0, 1: 2, 2: 2, 3: 0, 4: 1},
 'col9': {0: 2, 1: 0, 2: 1, 3: 1, 4: 0},
 'col10': {0: 142, 1: 465, 2: 679, 3: 916, 4: 195},
 'col11': {0: 21, 1: 23, 2: 27, 3: 5, 4: 1}}
</code></pre>
<pre><code>y.head().to_dict()
</code></pre>
<pre><code>{0: 1, 1: 1, 2: 0, 3: 0, 4: 1}
</code></pre>
<p>my train test split</p>
<pre><code># Separate into training (70%) and testing (30%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)
X_train.shape, X_test.shape
</code></pre>
<p>my z-score transformer</p>
<pre><code># Create a function to load data
def transform_data(data):
    
    # Find mean of data
    mean=data.mean()
    
    # Find standard deviation of data
    sd=data.std()
    
    # Transform the data using a Z-score transformation
    data_tf = (data-mean)/sd
    
    # Returns dataset
    return data_tf

# Transform the train dataset
X_tf = transform_data(X_train)
</code></pre>
<p>my decision tree classifier</p>
<pre><code># Create improved model
dtc = DecisionTreeClassifier(criterion='entropy', max_depth = None, min_samples_leaf=4, 
                             min_samples_split=10, splitter='best', random_state = 0)

# Fit the model
dtc.fit(X_tf,y_train)

# Create function to print model accuracy scores
def print_accuracy(model, x_train, y_train, x_test, y_test):
    
    # Get train and test accuracy scores
    train_acc = model.score(x_train, y_train)
    test_acc = model.score(x_test, y_test)
    
    # Print score
    print(f'Training accuracy: {train_acc}')
    print(f'Testing accuracy: {test_acc}')

# Accuracy score
print_accuracy(dtc, X_tf, y_train, X_test, y_test)
</code></pre>
<p>Is there a way to improve my test scores? Any suggestions much appreciated. Cheers!</p>
<p><strong>EDIT 1</strong></p>
<p>My dtc hyperparameters are like that because I used GridSearchCV to find the best hyperparams.</p>
<p><strong>EDIT 2</strong></p>
<p>Could my test score be bad because I didnt transform them?</p>
","2023-07-21 06:26:52","-3","Question"
"76717039","74981734","","<p>I had the same issues. You can resolve this with the following:</p>
<pre><code>X = state_df.iloc[0:35,:]
shap_values = explainer(X)
</code></pre>
","2023-07-18 23:19:30","0","Answer"
"76712683","76704914","","<p>From the output you gave, it shows <code>ret: False</code>. That clearly indicates that there is no image there.
What you have done is, you have released the object (<code>cap.release()</code>) as soon as the first iteration has been completed. And later on, you have not recreated the object again. You need to shift that to the condition check.</p>
<pre><code>if cv2.waitKey(1) &amp; 0xFF == ord('q'):
    cap.release()
    break
</code></pre>
<p>That way only when you press 'q' the object is disposed. Hope this clears it up.</p>
","2023-07-18 12:15:44","0","Answer"
"76709088","76661319","","<p>Have you tried creating the sql query yourself by describing the database and example data in a template?
Then create a sequential or multi-chain to verify the sql query works and then perform the query yourself use SQL Agent or psycog2?</p>
","2023-07-18 01:57:21","0","Answer"
"76709083","75334085","","<p>Came here because I ran into this same problem with both OneHotEncoder and OrdinalEncoder on streamlit.</p>
<p>Specifying sklearn version in the requirements.txt file fixed the problem (i.e. making sure sklearn version matches the version used to train the model)</p>
","2023-07-18 01:55:48","0","Answer"
"76708246","76465909","","<pre><code>data[&quot;class&quot;] = [1 if each == &quot;Abnormal&quot; else 0 for each in data[&quot;class&quot;]]
</code></pre>
<p>I think you are trying to do a list comprehension but see you have data[&quot;class&quot;] instead of data [&quot;class&quot;] without a space at opening bracket.
hope this works.</p>
","2023-07-17 21:41:31","0","Answer"
"76705045","76704914","","<p>You put <code>cap.release()</code> in your for loop, after you read your first image, the cap stream no longer exists. Therefore, when you read it you get a <code>ret=False</code> and you can't obtain a frame from it.</p>
","2023-07-17 13:40:29","0","Answer"
"76704914","","OpenCV assertion failure","<p>I am trying to try to collected images using open cv but the problem is that it gives me assertation failure in which it fails to capture the frame. The first frame is captured successfully but the subsequent fails.</p>
<p>my code:</p>
<pre><code>import cv2
import uuid
import os
import time

imagesPath = &quot;Tensorflow/workspace/images/collectedimages&quot;

if not os.path.exists(imagesPath):
    os.makedirs(imagesPath)
    
labels = ['hello', 'thankyou', 'yes', 'no', 'iloveyou']
numberImages = 20

for label in labels:
    labelPath = os.path.join(imagesPath, label)
    
    if not os.path.exists(labelPath):
        os.makedirs(labelPath)
        
    cap = cv2.VideoCapture(0)
    print(&quot;Collecting images for {}&quot;.format(label))
    for num in range(numberImages):
        ret, frame = cap.read()
        print(&quot;ret:&quot;, ret)
        imageName = os.path.join(imagesPath, label, label + &quot;.&quot; + &quot;{}.jpg&quot;.format(str(uuid.uuid1())))
        print(&quot;imageName:&quot;, imageName)
        cv2.imwrite(imageName,frame)
        cv2.imshow('captureImages',frame)
        time.sleep(2)
        
        if cv2.waitKey(1) &amp; 0xFF == ord('q'):
            break
        cap.release()
</code></pre>
<p>Below are the output and error:</p>
<pre><code>Collecting images for hello
ret: True
imageName: Tensorflow/workspace/images/collectedimages\hello\hello.701b06f0-24a3-11ee-8d31-0068eb8c6ae0.jpg
ret: False
imageName: Tensorflow/workspace/images/collectedimages\hello\hello.717b980e-24a3-11ee-87ef-0068eb8c6ae0.jpg
---------------------------------------------------------------------------
error                                     Traceback (most recent call last)
Cell In[9], line 14
     12 imageName = os.path.join(imagesPath, label, label + &quot;.&quot; + &quot;{}.jpg&quot;.format(str(uuid.uuid1())))
     13 print(&quot;imageName:&quot;, imageName)
---&gt; 14 cv2.imwrite(imageName,frame)
     15 cv2.imshow('captureImages',frame)
     16 time.sleep(2)

error: OpenCV(4.6.0) C:\b\abs_d8ltn27ay8\croot\opencv-suite_1676452046667\work\modules\imgcodecs\src\loadsave.cpp:801: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'
</code></pre>
<p>Answer and find a solution to my problem</p>
","2023-07-17 13:23:14","0","Question"
"76696756","76696552","","<p>To sort by pixel colors ,</p>
<ol>
<li>turn MxNx3 RBG pixels into vectors of size (M<em>N</em>3)x1
[ use vector operations instead of loop to make this faster]</li>
<li>than you can sort by columns</li>
</ol>
","2023-07-16 05:03:14","0","Answer"
"76696637","76696552","","<p>I guess you could use a bit of machine learning here.</p>
<p>Just tag 1000 odd images manually with multiple appropriate labels. Post that I would recommend taking a pre-trained vision model like <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet"" rel=""nofollow noreferrer"">EfficientnetB0</a>
and <a href=""https://www.tensorflow.org/tutorials/images/transfer_learning"" rel=""nofollow noreferrer"">fine tune it</a>.</p>
<p>Vision DL models have come a long way and are very good at transfer learning from just a few examples.</p>
<p>Just a side note, be careful to not use color related augmentations while training the models. Also, if you don't have access to GPU you could use Google colab or Kaggle for training your models.</p>
","2023-07-16 04:10:26","0","Answer"
"76696552","","Most effective way to programmatically sort images into categories by color?","<p>I'm working on a project where I need to sort a large pool of images into a variety of color categories. It's pretty complicated because first, the sorting needs to happen at three levels:</p>
<ol>
<li><p>Very simple basic colors: &quot;blue&quot;, &quot;green&quot;, etc.</p>
</li>
<li><p>More specific colors: &quot;steel blue&quot;, &quot;crimson red&quot;, etc.</p>
</li>
<li><p>Very broad color groups: &quot;vibrant and colorful&quot;, &quot;warm colors&quot;, &quot;neutral colors&quot;, etc.</p>
</li>
</ol>
<p>It's even MORE complicated because, how humans would sort the images kind of depends and might vary image by image. What I mean is, in some cases, the actual surface area covered by a specific color might be small, but if it's a really prominent focal point (for example, a bright red barn amid a black and white landscape scene), the human might sort it into the &quot;red&quot; category since the red is so pronounced. In other cases, there might be a fairly large surface area spanned by a certain color, but maybe the distribution of the color across the image actually makes it not really stand out or even &quot;feel&quot; like an image of that color. This mostly comes down to &quot;surface area&quot; vs. &quot;color dominance/prominence&quot;.</p>
<p>While it felt like a simple task at first, the more I work on it, the more complex it seems to become.</p>
<p>Are there any standardized APIs, python libraries, or software tools that massively simplify this process by taking these different factors into consideration?</p>
<p>A few approaches I've tested so far are: Custom Python scripts that use kmeans to get the RGB color codes of the colors whose proportion in the image passes some specified threshold. I then tried taking that a step further, and mapping those more complex colors onto the closest match &quot;simple colors&quot;, by mapping &quot;steel blue&quot; onto just &quot;plain blue&quot;, etc. Really after lots of experimenting with this, the results simply weren't that good.</p>
<p>Others I've experimented with are: Using tools like Google Cloud Vision to get the &quot;dominant colors.&quot; This is really a mixed bag. For example, sometimes an entirely black and white image with just like a small dash of another color will show the &quot;another color&quot; as the dominant color and totally miss the black and white. Another API-based tool, Ximilar, seems to output probably some of the best results I've seen -- but it appears to mostly be based entirely on surface area vs. color prominence.</p>
<p>Other ideas / other standard solutions to this problem would be greatly appreciated, as I've been working for hours on it and haven't seemed to hit upon the optimal solution yet.</p>
","2023-07-16 03:20:59","-1","Question"
"76675634","75371176","","<p>I had the same issue on Databricks. The issue arose when I upgraded Numpy to 1.24.5. Before that, the code was working fine. So I needed to downgrade to 1.23 to resolve the issue. It worked for me.</p>
<pre><code>pip install Numpy==1.23.5
</code></pre>
","2023-07-13 03:05:42","6","Answer"
"76674834","76644713","","<p>Depending on what version of <code>gym</code> or <code>gymnasium</code> you are using, the agent-environment loop might differ. The reason why it states it needs to unpack too many values, is due to newer versions of <code>gym</code> and <code>gymnasium</code> in general using:</p>
<pre class=""lang-py prettyprint-override""><code>n_state, reward, done, truncated, info = env.step(action)
</code></pre>
<p>thus unpacking 5 values instead of 4. The <code>truncated</code> boolean states whether the environment had ended, but is applied when the reason for ending the environment is not because of the agent, but because of the environment. This could be the agent entering an invalid/faulty game state or exceeding a time/step limit within the environment. Either adjust your <code>env.step(action)</code> to unpack 5 values or downgrade <code>gym</code> (along with the environment) to a version supporting 4 values.</p>
","2023-07-12 22:28:59","0","Answer"
"76671441","75626974","","<p>Im my experience, when the model attribute under <code>model=</code> has erroneous path, it yields the mentioned error:
<code>OSError [...] does not appear to have the file names config.json</code></p>
<p>Make sure the pointer to the model folder (hence <code>config.json</code>) is correct.</p>
<p>Actually, the <code>OSError</code> itself already communicates there is probably something off path related.</p>
","2023-07-12 14:02:15","0","Answer"
"76670861","76644713","","<p>For future proof you should note that all development of Gym has been moved to Gymnasium. Read more <a href=""https://www.gymlibrary.dev/environments/classic_control/cart_pole/"" rel=""nofollow noreferrer"">here</a>.</p>
<p>I did the following changes to make it work partially.</p>
<h2>Change environment to CartPole v1 since v0 is obsoleted</h2>
<pre class=""lang-py prettyprint-override""><code>environment_name = 'CartPole-v1'
</code></pre>
<h2>Do not call <code>step()</code> after got <code>done = True</code> from the environment. That is UB.</h2>
<pre class=""lang-py prettyprint-override""><code>#env.step(1)
</code></pre>
<h2>Change the rendering code</h2>
<p>This works in <code>gym==0.23.1</code>:</p>
<pre class=""lang-py prettyprint-override""><code>prev_screen = env.render(mode='rgb_array')
plt.imshow(prev_screen)
plt.show()
</code></pre>
<p>and this works in <code>gym==0.26.2</code>:</p>
<pre class=""lang-py prettyprint-override""><code>env = gym.make(environment_name, render_mode='rgb_array')
</code></pre>
<h2>Final code that worked on my system</h2>
<pre class=""lang-py prettyprint-override""><code>
import tensorflow as tf
import os
import gym
import numpy as np
import matplotlib.pyplot as plt
from IPython import display as ipythondisplay
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.evaluation import evaluate_policy

from pyvirtualdisplay import Display

def main():
    display = Display(visible=0, size=(400, 300))
    display.start()

    environment_name = 'CartPole-v1'
    env = gym.make(environment_name)

    episodes = 5
    for episode in range(1, episodes+1):
      state = env.reset()
      done = False
      score = 0

      while not done:
        action = env.action_space.sample()
        n_state, reward , done , info = env.step(action)
        score += reward
        prev_screen = env.render(mode='rgb_array')
        plt.imshow(prev_screen)
        plt.show()
      print('Episode:{} Score:{}'.format(episode, score))
    env.close()

if __name__==&quot;__main__&quot;:
    main()
</code></pre>
<p>Note that I have no idea what you wanted to do after <code>env.close()</code> and I got some errors from those lines so you need to explain that first. I will edit my question afterwards. I hope this helps you.</p>
<p>Note that there is this warning:</p>
<blockquote>
<p>UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.</p>
</blockquote>
<p>It might be related to the error from these lines</p>
<pre class=""lang-py prettyprint-override""><code>env = gym.make(environment_name)
env = DummyVecEnv([lambda: env])
model = PPO('MlpPolicy', env, verbose = 1 , tensorboard_log = log_path)
</code></pre>
","2023-07-12 12:59:54","0","Answer"
"76667098","76667054","","<p>For alternatives to PCA, I think autoencoders could be helpful, as the other answer mentioned. Autoencoders are neural networks that are used to reduce the dimensionality of data. They will first learn an encoded (compressed) representation of the input data, which captures the main characteristics of the data. Then, the decoder part of the autoencoder then reconstructs the original data from the compressed representation.</p>
","2023-07-12 04:10:01","1","Answer"
"76667089","76667054","","<p>I think you can cluster the users based on these features. However, since the dimensions are different for each entity, it would be necessary address this issue before applying clustering algorithms.</p>
<p>One option is dimensionality reduction techniques such as PCA that can be applied to the second, fourth, and fifth features to lower their dimensions to match the first and third features.</p>
<p>Besides PCA, there are other dimensionality reduction methods that you could consider, such as t-SNE, LLE or autoencoders.</p>
","2023-07-12 04:07:32","0","Answer"
"76667054","","clustering for users with features having different shape","<p>&quot;I currently have 10 users, each with 5 features. The first feature is 1-dimensional, the second feature is 2-dimensional with a shape of [8,2], the third feature is 1-dimensional, the fourth feature is 2-dimensional with a shape of [6,2], and the fifth feature is 2-dimensional with a shape of [9,2]. In this scenario, can I cluster these users based on these features? Which clustering method should I use? Can anyone provide me with some advice?&quot;</p>
<p>i wonder if there is any other method other than using method like PCA to lower the dimension of features to the same shape.After dimension reduction, what kind of clustering algorithm can be used ?</p>
","2023-07-12 03:55:53","0","Question"
"76667044","76149628","","<p>Reposting comment from OP for visibility:</p>
<p>Make sure that the keyword &quot;render_mode='rgb_array'&quot; is in your gym.make() statement!</p>
","2023-07-12 03:53:16","0","Answer"
"76662590","76034640","","<p>Your state is a numpy array and you're trying to use it to access an index in the q-table which is a 2-d array.</p>
<pre><code>q_table = np.zeros((state_space_size, action_space_size))
...

q_table[state, action] = ...
</code></pre>
<p>Solution is to find a way to get an index of that state from the list of possible observation spaces in the env.</p>
","2023-07-11 13:38:06","0","Answer"
"76661319","","Using an open source LLM in SQL Chain","<p>Is it possible to use open source LLM models in SQL chain ?
I have tried using tapex/Flan models in SQL Chain, but getting a serialization error on dict[] classes.</p>
<p>Error:</p>
<pre><code>File &quot;pydantic\main.py&quot;, line 341, in pydantic.main.BaseModel.init
pydantic.error_wrappers.ValidationError: 1 validation error for SQLDatabaseChain
root -&gt; llm
value is not a valid dict (type=type_error.dict)
</code></pre>
<p>sample snippet</p>
<pre><code>tokenizer = TapexTokenizer.from_pretrained(&quot;microsoft/tapex-base-finetuned-wtq&quot;)
model = BartForConditionalGeneration.from_pretrained(&quot;microsoft/tapex-base-finetuned-wtq&quot;)
chain = SQLDatabaseChain(llm=model, database=db, verbose=True)
chain.run(&quot;context query ?&quot;)
</code></pre>
<p>Are there any samples/snippets are available for using open source LLM models in SQL Chain ?</p>
","2023-07-11 11:02:59","2","Question"
"76648468","76645604","","<p>Final code</p>
<pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense

# Step 1: Load and preprocess the data
data = pd.read_csv('spx_data.csv')
data['Date'] = pd.to_datetime(data['Date'])
data = data.set_index('Date')
close_prices = data['Close'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_prices = scaler.fit_transform(close_prices)

# Prepare training data
look_back = 250  # Number of previous days to use for prediction
X_train, y_train = [], []
for i in range(look_back, len(scaled_prices)):
    X_train.append(scaled_prices[i-look_back:i, 0])
    y_train.append(scaled_prices[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)

# Reshape input data for LSTM [samples, time steps, features]
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Step 2: Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# Compile and train the model
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=50, batch_size=32)

# Step 3: Make predictions for the future 30 days
look_back_days = scaler.transform(close_prices[-look_back:]).reshape(1, -1)
scaled_predictions = []
for _ in range(30):
    scaled_prediction = model.predict(look_back_days)
    scaled_predictions.append(scaled_prediction[0, 0])
    look_back_days = np.append(look_back_days[:, 1:], scaled_prediction, axis=1)

# Inverse transform the predictions to get actual values
predictions = scaler.inverse_transform(np.array(scaled_predictions).reshape(-1, 1))

# Step 4: Plot historical data and predicted data
plt.figure(figsize=(12, 6))
plt.plot(data.index, close_prices, color='blue', label='Historical Data')
plt.plot(pd.date_range(start=data.index[-1], periods=30, freq='D'), predictions, color='red', linestyle='dashed',
         label='Predicted Data')
plt.xlabel('Date')
plt.ylabel('SPX Close Price')
plt.title('SPX Close Price Prediction')
plt.legend()
plt.grid(True)
plt.show()
</code></pre>
<p><a href=""https://i.sstatic.net/kIWbe.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/kIWbe.png"" alt=""enter image description here"" /></a></p>
","2023-07-09 16:33:24","0","Answer"
"76648391","76644106","","<p>When you do</p>
<pre class=""lang-py prettyprint-override""><code>x1 = samples[:, 0:2] # (batch_size, features)
</code></pre>
<p>Insert a <code>None</code> into the slice to add the channel dimension similar to an <code>unsqueeze(1)</code> operation.
To avoid the unintuitve <code>None</code> value you can replace it with <code>np.newaxis</code> which is an alias of <code>None</code>.</p>
<pre class=""lang-py prettyprint-override""><code>x1 = samples[:, None, 0:2]  # (batch_size, 1, features)
</code></pre>
","2023-07-09 16:14:50","1","Answer"
"76648247","76644106","","<p>As you said, the input shape of the Conv1d layer should be 3d tensor [batch_size,1,2] where 1 is number of input channels and 2 is sequence length. However, you are passing a 2D tensor into Conv1d. you need to extend the tensor to be 3d where the second dimension represents the channels by using unsqueeze function. I beileve that in case you don't provide the channel dimension, the tensor is considered to not have a batch dimension. Therefore, it is added automatically. Check the following example:</p>
<p>Input1:</p>
<pre><code>import torch
from torch import nn
input = torch.randn( 50, 2) 
convolution_layer = nn.Conv1d(1, 1, kernel_size=1, stride=1) 
feature_map = convolution_layer(input)
</code></pre>
<p>Output1:</p>
<pre><code>RuntimeError: Given groups=1, weight of size [1, 1, 1], expected input[1, 50, 2] to have 1 channels, but got 50 channels instead
</code></pre>
<p>Input2:</p>
<pre><code>import torch
from torch import nn
input = input.unsqueeze(1) 
convolution_layer = nn.Conv1d(1, 1, kernel_size=1, stride=1) 
feature_map = convolution_layer(input)
</code></pre>
<p>Output2:</p>
<pre><code>No errors
</code></pre>
<p>Modify your model as follow:</p>
<pre><code>class Net(nn.Module):
  def __init__(self, Bias):
    super(Net, self).__init__()
    self.conv1 = nn.Conv1d(1, 1, kernel_size=1, stride=1) 
    self.relu = nn.ReLU()                                 
    self.fc1 = nn.Linear(2, 20, bias = False)            
    self.fc2 = nn.Linear(20, 2, bias = False)
  def forward(self, x):
    x = self.relu(self.conv1(x.unsqueeze(1)))
    x = x.reshape(x.size(0), -1)
    x = self.relu(self.fc1(x))
    x = self.fc2(x)
    return x
</code></pre>
<p>Or add &quot;.unsqueeze(1)&quot; in the training loop, as follow:</p>
<pre><code>cost = criterion(model(x1.unsqueeze(1)), y1.squeeze())
</code></pre>
","2023-07-09 15:38:03","1","Answer"
"76646087","76643983","","<p>You made typo on two occasions. First, when getting the predictions:</p>
<pre><code>y_train_pred = model_clf.predict(x_test)
y_test_pred= model_clf.predict(x_train)
</code></pre>
<p>which needs to be replaced by:</p>
<pre><code>y_train_pred = model_clf.predict(x_train)
y_test_pred= model_clf.predict(x_test)
</code></pre>
<p>Second, when calculating the classification report:</p>
<pre><code>class_train_rep = classification_report(y_test,y_train_pred)
print(&quot;Train:&quot;,&quot;\n&quot;,class_train_rep)

class_test_rep = classification_report(y_train,y_test_pred)
print(&quot;Test:&quot;,&quot;\n&quot;,class_test_rep)
</code></pre>
<p>which needs to be replaced by:</p>
<pre><code>class_train_rep = classification_report(y_train, y_train_pred)
print(&quot;Train:&quot;,&quot;\n&quot;,class_train_rep)

class_test_rep = classification_report(y_test, y_test_pred)
print(&quot;Test:&quot;,&quot;\n&quot;,class_test_rep)
</code></pre>
<p>As @Miriam Farber pointed out, both the 100% and 72% accuracy from the models are your training accuracy.</p>
","2023-07-09 05:57:52","0","Answer"
"76645713","76645604","","<p>On this line:</p>
<pre><code>look_back_days = close_prices[-look_back:].reshape(1, -1)
</code></pre>
<p>Remember that if you apply feature scaling during training, then you also have to apply feature scaling during inference, or your inputs will be 1000x as big as the model is expecting.</p>
<p>Therefore, scale your inputs before passing them to <code>predict()</code>.</p>
<pre><code>look_back_days = scaler.transform(close_prices[-look_back:]).reshape(1, -1)
</code></pre>
<p>Here's what the output looks like after making this change.</p>
<p><a href=""https://i.sstatic.net/LOuJj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/LOuJj.png"" alt=""predicted s&amp;p 500"" /></a></p>
","2023-07-09 02:56:00","2","Answer"
"76645604","","SP500 Prediction using LSTM","<p>I wrote some code to predict sp500 using daily OHLCV data using LSTM machine learning algorithm.
Here is the part of the data, data is from 2022-07-08 to 2023-07-08</p>
<pre><code>Date,Open,High,Low,Close,Volume
2022-07-08,3888.260009765625,3918.5,3869.340087890625,3899.3798828125,3521620000
2022-07-11,3880.93994140625,3880.93994140625,3847.219970703125,3854.429931640625,3423480000
2022-07-12,3851.949951171875,3873.409912109375,3802.360107421875,3818.800048828125,3817210000
</code></pre>
<p>And here is the code</p>
<pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense

# Step 1: Load and preprocess the data
data = pd.read_csv('spx_data.csv')
data['Date'] = pd.to_datetime(data['Date'])
data = data.set_index('Date')
close_prices = data['Close'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_prices = scaler.fit_transform(close_prices)

# Prepare training data
look_back = 250  # Number of previous days to use for prediction
X_train, y_train = [], []
for i in range(look_back, len(scaled_prices)):
    X_train.append(scaled_prices[i-look_back:i, 0])
    y_train.append(scaled_prices[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)

# Reshape input data for LSTM [samples, time steps, features]
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Step 2: Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# Compile and train the model
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=50, batch_size=32)

# Step 3: Make predictions for the future 30 days
look_back_days = close_prices[-look_back:].reshape(1, -1)
scaled_predictions = []
for _ in range(30):
    scaled_prediction = model.predict(look_back_days)
    scaled_predictions.append(scaled_prediction[0, 0])
    look_back_days = np.append(look_back_days[:, 1:], scaled_prediction, axis=1)

# Inverse transform the predictions to get actual values
predictions = scaler.inverse_transform(np.array(scaled_predictions).reshape(-1, 1))

# Step 4: Plot historical data and predicted data
plt.figure(figsize=(12, 6))
plt.plot(data.index, close_prices, color='blue', label='Historical Data')
plt.plot(pd.date_range(start=data.index[-1], periods=30, freq='D'), predictions, color='red', linestyle='dashed',
         label='Predicted Data')
plt.xlabel('Date')
plt.ylabel('SPX Close Price')
plt.title('SPX Close Price Prediction')
plt.legend()
plt.grid(True)
plt.show()
</code></pre>
<p>Here is the prediction result
<a href=""https://i.sstatic.net/4xPR2.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4xPR2.png"" alt=""enter image description here"" /></a></p>
<p>Obviously, it's not correct, it's impossible for sp500  to go to 4800+ next Monday.
Anything wrong I did? how to fix it?</p>
","2023-07-09 01:49:30","-1","Question"
"76645128","76643983","","<p>Looks like you switched between train and test here</p>
<pre><code>y_train_pred = model_clf.predict(x_test)
y_test_pred= model_clf.predict(x_train)
</code></pre>
<p>So what you really got is 100% accuracy on the train and 78% accuracy on the test, meaning your model is overfitting to the train.</p>
","2023-07-08 22:09:14","0","Answer"
"76644713","","OpenAi gym: Too many variables to unpack","<p>I an creating a model for theCartapole-v0 in google collab , but i am getting too many variable to unpack issue while training it</p>
<pre><code>pip install stable-baselines3[extra]
!apt-get install x11-utils &gt; /dev/null 2&gt;&amp;1
!pip install pyglet &gt; /dev/null 2&gt;&amp;1
!apt-get install -y xvfb python-opengl &gt; /dev/null 2&gt;&amp;1
!pip install gym pyvirtualdisplay &gt; /dev/null 2&gt;&amp;1

import tensorflow as tf
import os
import gym
import numpy as np
import matplotlib.pyplot as plt
from IPython import display as ipythondisplay
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.evaluation import evaluate_policy

from pyvirtualdisplay import Display
display = Display(visible=0, size=(400, 300))
display.start()

environment_name = 'CartPole-v0'
env = gym.make(environment_name)

episodes = 5
for episode in range(1, episodes+1):
  state = env.reset()
  done = False
  score = 0

  while not done:
    prev_screen = env.render(mode='rgb_array')
    plt.imshow(prev_screen)
    action = env.action_space.sample()
    n_state, reward , done , info = env.step(action)
    score += reward
  print('Episode:{} Score:{}'.format(episode, score))
env.close()

env.step(1)

log_path = os.path.join('Training','Logs')

env = gym.make(environment_name)
env = DummyVecEnv([lambda: env])
model = PPO('MlpPolicy', env, verbose = 1 , tensorboard_log = log_path)

model.learn(total_timesteps=20000)
</code></pre>
<p>Giving error in the last line.</p>
","2023-07-08 19:54:39","0","Question"
"76644106","","How to resolve runtime error in CNN model related to mismatch input size?","<p>I am trying to run a CNN model on a synthetic dataset consisting of 4000 sample of semi simple random points with 2 features and 1 cluster per class and input data size x is [4000,2] and corresponding labels size is [4000].</p>
<p>I understand that as original input tensor has shape [4000,2] where 4000=total number of samples and 2=number of features and my input to Conv1d layer should be 3d tensor [batch_size,1,2] where 1 is number of input channels and 2 is sequence length but when it runs through dataloader and train function it becomes [1,batch_size,2] and that’s where issue arising.
CNN is defined with its parameters as:</p>
<pre class=""lang-py prettyprint-override""><code>class Net(nn.Module):
    def __init__(self, Bias):
        super(Net, self).__init__()
        self.conv1 = nn.Conv1d(1, 1, kernel_size=1, stride=1) 
        self.relu = nn.ReLU()                                 
        self.fc1 = nn.Linear(2, 20, bias = False)            
        self.fc2 = nn.Linear(20, 2, bias = False)
    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = x.reshape(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

epochs = 50
alpha = 1e-2
batch_size = 50
criterion = nn.CrossEntropyLoss()
model = Net(biases).to(device)
model = train(model.to(device),criterion,x,y,alpha,epochs,batch_size)
</code></pre>
<p>And I used following train function:</p>
<pre><code>def train(model,criterion, x, y, alpha, epochs, batchsize):
    costs = []
    optimizer = torch.optim.SGD(model.parameters(), lr=alpha)    
    trainx, trainy, testx, testy= dataloader(x,y)
    x=trainx.float()
    y=trainy.float()
    data_train = torch.cat((x, y), dim=1)
    data_train_loader = DataLoader(data_train, batch_size=batchsize, shuffle=True)
    model.train()
    j = 0
    for i in range(epochs):
        for index,samples in enumerate(data_train_loader):
            j += 1
            x1 = samples[:,0:2]
            y1 = samples[:,2].long().reshape(-1,1)
            if (j%50 == 0):
                model.eval()
                acc = accuracy(model,testx,testy)
                print(f'Test accuracy is #{acc:.2f} , Iteration number is = {j}')
                model.train()
            cost = criterion(model(x1), y1.squeeze())
            optimizer.zero_grad()
            cost.backward()
            optimizer.step()        
            costs.append(float(cost))
    return model
</code></pre>
<p>And following is the error I get:</p>
<pre><code>RuntimeError                              Traceback (most recent call last)
Cell In[17], line 7
      5 criterion = nn.CrossEntropyLoss()
      6 model = Net(biases).to(device)
----&gt; 7 model=train(model.to(device),criterion,x,y,alpha,epochs,batch_size)
Cell In[15], line 40, in train(model, criterion, x, y, alpha, epochs, batchsize)
     38     print(f'Test accuracy is #{acc:.2f} , Iteration number is = {j}')
     39     model.train()
---&gt; 40 cost = criterion(model(x1), y1.squeeze())
Cell In[16], line 11, in Net.forward(self, x)
     10 def forward(self, x):
---&gt; 11     x = self.relu(self.conv1(x))

RuntimeError: Given groups=1, weight of size [1, 1, 1], expected input[1, 50, 2] to have 1 channels, but got 50 channels instead
</code></pre>
<p>How to solve this input dimension problem or to change the dimension requirement of model input?</p>
","2023-07-08 17:14:07","0","Question"
"76643983","","Random Forest Classifier giving 100% accuracy on the test split","<p>While training the model I got:
Random Forest Classifier: 78%
SVC: 65%</p>
<p>But while testing the model i got:
Random Forest Classifier: 100%
SVC: 72%</p>
<pre><code>x_status = train_path.drop(['Loan_Status'],axis=1)
y_status = train_path['Loan_Status']
x_status.shape,y_status.shape
  
x_train, x_test, y_train, y_test = train_test_split(x_status, y_status, test_size=0.4,random_state=42)
x_train.shape, x_test.shape, y_train.shape, y_test.shape

def clf(model_clf,x_status, y_status,x_train, x_test, y_train, y_test):
    model_clf.fit(x_train, y_train)
    y_train_pred = model_clf.predict(x_test)
    y_test_pred= model_clf.predict(x_train)
    
    class_train_rep = classification_report(y_test,y_train_pred)
    print(&quot;Train:&quot;,&quot;\n&quot;,class_train_rep)
    
    class_test_rep = classification_report(y_train,y_test_pred)
    print(&quot;Test:&quot;,&quot;\n&quot;,class_test_rep)
</code></pre>
<p>Shape:
x_train (368, 11)
x_test (246, 11)
y_train (368,)
y_test (246,))</p>
<p>Classification Report:
Random Forest:</p>
<pre><code>Train: 
               precision    recall  f1-score   support

           0       0.82      0.47      0.60        85
           1       0.77      0.94      0.85       161

    accuracy                           0.78       246
   macro avg       0.79      0.71      0.72       246
weighted avg       0.79      0.78      0.76       246

Test: 
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       107
           1       1.00      1.00      1.00       261

    accuracy                           1.00       368
   macro avg       1.00      1.00      1.00       368
weighted avg       1.00      1.00      1.00       368
</code></pre>
<p>SVC:</p>
<pre><code>Train: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00        85
           1       0.65      0.99      0.79       161

    accuracy                           0.65       246
   macro avg       0.33      0.50      0.39       246
weighted avg       0.43      0.65      0.52       246

Test: 
               precision    recall  f1-score   support

           0       1.00      0.03      0.05       107
           1       0.72      1.00      0.83       261

    accuracy                           0.72       368
   macro avg       0.86      0.51      0.44       368
weighted avg       0.80      0.72      0.61       368
</code></pre>
<p>Is it alright if the test_split is 100% accuracy</p>
","2023-07-08 16:41:12","-1","Question"
"76643375","75783524","","<p>I would use a fine-tuned model to first classify each email on whether it is a basic question that can be answered with AI or requires a human response.</p>
<p>Most likely, you will still want to route certain urgent or complex requests (from high-value customers, perhaps) directly to a real person, and try to have your AI bot handle the simpler ones.</p>
<p>Then I would use embeddings to answer the basic questions from your index of support information.</p>
","2023-07-08 14:15:22","0","Answer"
"76633836","","What does langchain CharacterTextSplitter's chunk_size param even do?","<p>My default assumption was that the <code>chunk_size</code> parameter would set a ceiling on the size of the chunks/splits that come out of the <code>split_text</code> method, but that's clearly not right:</p>
<pre><code>from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter

chunk_size = 6
chunk_overlap = 2

c_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)

text = 'abcdefghijklmnopqrstuvwxyz'

c_splitter.split_text(text)
</code></pre>
<p>prints: <code>['abcdefghijklmnopqrstuvwxyz']</code>, i.e. one single chunk that is much larger than <code>chunk_size=6</code>.</p>
<p>So I understand that it didn't split the text into chunks because it never encountered the separator. But so then the question is what <em>is</em> the <code>chunk_size</code> even doing?</p>
<p>I checked the documentation page for <code>langchain.text_splitter.CharacterTextSplitter</code> <a href=""https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/character_text_splitter"" rel=""noreferrer"">here</a> but did not see an answer to this question. And I asked the &quot;mendable&quot; chat-with-langchain-docs search functionality, but got the answer &quot;The chunk_size parameter of the CharacterTextSplitter determines the maximum number of characters in each chunk of text.&quot;...which is not true, as the code sample above shows.</p>
","2023-07-07 03:50:27","19","Question"
"76630297","76613438","","<p>The problem is the <code>TransformerMixin</code> which implements <code>fit_transform</code> does only use <code>y</code> for the fitting but the transformation:</p>
<pre class=""lang-py prettyprint-override""><code>def fit_transform(self, X, y=None, **fit_params):
    &quot;&quot;&quot;
    Fits transformer to `X` and `y` with optional parameters `fit_params`
        and returns a transformed version of `X`.
    &quot;&quot;&quot;
    if y is None:
        # fit method of arity 1 (unsupervised transformation)
        return self.fit(X, **fit_params).transform(X)
    else:
        # fit method of arity 2 (supervised transformation)
        return self.fit(X, y, **fit_params).transform(X) # &lt;-- here is the problem
</code></pre>
<p><strong>Solution implement <code>fit_transform</code> yourself.</strong>
(That is the main purpose of the <code>TransformerMixin</code> class - beside alsoinheriting from <code>_SetOutputMixin</code> <a href=""https://github.com/scikit-learn/scikit-learn/blob/7f9bad99d6e0a3e8ddf92a7e5561245224dab102/sklearn/base.py#L875"" rel=""nofollow noreferrer"">source</a>).</p>
<pre><code>class DataUndersampler(BaseEstimator):

    def fit_transform(self, X, y):  # add your method
        return self.fit(X, y).transform(X, y)

    ...  # rest of your code
</code></pre>
<hr />
<p>NOTE:
You might run into problems further down the line if only a single output from transform is expected.
In that case you have to update Y inplace and only return X.</p>
<pre class=""lang-py prettyprint-override""><code>y[:] = y_resampled
return X_resampled
</code></pre>
<p>Should do the job.</p>
","2023-07-06 15:14:28","1","Answer"
"76628503","76625564","","<p>The <code>'max_features'</code> parameter in the <code>RandomForestRegressor</code> does not refer to the top 3 most important features used by the model but rather determines the number of features to consider when looking for the best split.</p>
<p>Specifically:</p>
<ul>
<li>If <code>max_features</code> is an integer, then it considers that many features at each split.</li>
<li>If <code>max_features</code> is a float, it is a percentage and <code>int(max_features * n_features)</code> features are considered at each split.</li>
<li>If <code>max_features</code> is <code>auto</code>, then <code>max_features=sqrt(n_features)</code>.</li>
<li>If <code>max_features</code> is <code>sqrt</code>, then <code>max_features=sqrt(n_features)</code> (same as <code>auto</code>).</li>
<li>If <code>max_features</code> is <code>log2</code>, then <code>max_features=log2(n_features)</code>.</li>
<li>If <code>max_features</code> is <code>None</code>, then <code>max_features=n_features</code>.</li>
</ul>
<p>So, when you find <code>'max_features': 3</code> in your best parameters, it means that the random forest is using 3 features to make the best split at each node, not necessarily the same 3 features each time. The features might change for each tree and each split in your random forest.</p>
<p>In the context of random forests, you can get the feature importances, which gives you the importance score of each feature in making predictions. Here is how you can do it:</p>
<pre class=""lang-py prettyprint-override""><code>feature_importances = grid_search.best_estimator_.feature_importances_
feature_names = features.columns
important_features_dict = {}
for x in range(len(feature_names)):
    important_features_dict[feature_names[x]] = feature_importances[x]
important_features_list = sorted(important_features_dict,
                                 key=important_features_dict.get,
                                 reverse=True)
print('Most important features: %s' %important_features_list[:3])
</code></pre>
<p>This gives you the top 3 features that are most important across all trees in the forest, not necessarily the ones used at each individual split. You should interpret this as a general measure of which features the model considers important overall, rather than a specific indication of which 3 features were used in any particular decision within the model.</p>
","2023-07-06 11:46:08","0","Answer"
"76626815","76625564","","<p>See this thread : <a href=""https://stackoverflow.com/questions/23939750/understanding-max-features-parameter-in-randomforestregressor"">Understanding max_features parameter in RandomForestRegressor</a></p>
<p>At each split, you select max_features from all the features at random without replacement.</p>
<p>You use all yours features at the end.</p>
<p>You #1 point implicitly suggest that you do features selection to remove the least important features, which is not the case.</p>
","2023-07-06 08:16:21","0","Answer"
"76625564","","Sklearn Random Forest: determine the name of features ascertained by parameter grid for model fit and prediction","<p>New to ML here and trying my hands on fitting a model using Random Forest. Here is my simplified code:</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.15, random_state=42)

model = RandomForestRegressor()
    param_grid = {
        'n_estimators': [100, 200, 500],#, 300],
        'max_depth': [3, 5, 7],
        'max_features': [3, 5, 7],
        'random_state': [42]
    }
</code></pre>
<p>Next, I perform grid search for the best parameters:</p>
<pre><code>grid_search = GridSearchCV(model, param_grid, cv=5)
grid_search.fit(X_train, y_train)
print(grid_search.best_params_)
</code></pre>
<p>This yields <strong>the output</strong>:</p>
<pre><code>{'max_depth': 7, 'max_features': 3, 'n_estimators': 500, 'random_state': 42}
</code></pre>
<p>Next, I implement prediction for the model. I get <strong>the output</strong> R2= 0.998 for test and train data:</p>
<pre><code>y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)
</code></pre>
<p><strong>Question:</strong></p>
<p>The above code did ascertain the <code>'max features'</code> to be 3.</p>
<ol>
<li>I suppose those 3 features were used to predict the model and then calculate R2. Is that right?</li>
<li>If #1 is correct then how do I print the 3 features which were used for the best prediction and obtain a R2 of 0.998?</li>
</ol>
","2023-07-06 04:45:41","-1","Question"
"76618260","76164679","","<p>This error is due to the computed loss value for the model output and labels being <code>None</code>.</p>
<p>Perhaps it is not your case, but it can come up when the model has no outputs for some reason (<code>len(model.outputs) == 0</code>). You could check the model architecture with <code>model.summary()</code> or the outputs with <code>model.outputs</code> just to verify that the structure is correct and matches the structure of the <code>labels</code>.</p>
","2023-07-05 08:04:01","1","Answer"
"76616110","76109675","","<p>Try using the Faker library in Python - its really easy to set up and start using</p>
<p><a href=""https://towardsdatascience.com/free-resources-for-generating-realistic-fake-data-da63836be1a8"" rel=""nofollow noreferrer"">https://towardsdatascience.com/free-resources-for-generating-realistic-fake-data-da63836be1a8</a></p>
","2023-07-04 22:18:23","0","Answer"
"76613603","76613438","","<p>Let's slowly take this step by step. First let's look at the error.</p>
<blockquote>
<p>TypeError: DataUndersampler.transform() missing 1 required positional argument: 'y'</p>
</blockquote>
<p>This error happens when a function expects 2 arguments but gets only one. For example:</p>
<pre><code>def func (x , y):
    return x, y # Fummy function

# This causes the error:
func(3) # Not enough arguments
</code></pre>
<p>Thus, whatever is calling <code>transform()</code> is only expecting transform to accept 1 argument.</p>
<p>Indeed, if you look at the <a href=""https://github.com/scikit-learn/scikit-learn/blob/7f9bad99d/sklearn/multiclass.py#L669"" rel=""nofollow noreferrer"">source code</a> for <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier.fit"" rel=""nofollow noreferrer""><code>OneVsOneClassifier.fit()</code></a>, we see this line:</p>
<pre><code>     # Note transform is called with only 1 argument!
     Y = self.label_binarizer_.fit_transform(y)
</code></pre>
<hr />
<p>I'm not super familiar with Sklearn, but I suspect that you need a classifier that can handle 2 input variables. I looked but couldn't figure out what that would be, though.</p>
","2023-07-04 14:23:29","1","Answer"
"76613438","","What is responsible for this TypeError: DataUndersampler.transform() missing 1 required positional argument: 'y'?","<p>This is a custom support vectorbased data undersampler answer from my previous <a href=""https://stackoverflow.com/a/76396909/10309712"">question</a>.</p>
<p>The main idea is to undersample the majority class in an informed way, by fitting an SVC to the data, find the support vectors, and then undersample the majority class based on the distances to these support vectors.</p>
<p>Code:</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.utils import resample
from sklearn.svm import SVC
import numpy as np
from sklearn.multiclass import OneVsOneClassifier
from imblearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier

class DataUndersampler(BaseEstimator, TransformerMixin):
    def __init__(self, random_state=None):
        self.random_state = random_state
        self.svc = SVC(kernel='linear')

    def fit(self, X, y):
        # Fit SVC to data
        self.svc.fit(X, y)
        return self

    def transform(self, X, y):
        # Get support vectors
        support_vectors = self.svc.support_vectors_
        # Get indices of support vectors
        support_vector_indices = self.svc.support_

        # Separate majority and minority classes
        majority_class = y.value_counts().idxmax()
        minority_class = y.value_counts().idxmin()
        X_majority = X[y == majority_class]
        y_majority = y[y == majority_class]
        X_minority = X[y == minority_class]
        y_minority = y[y == minority_class]

        # Calculate distances of majority class samples to nearest support vector
        distances = np.min(np.linalg.norm(X_majority.values[:, np.newaxis] - support_vectors, axis=2), axis=1)

        # Sort the majority class samples by distance and take only as many as there are in minority class
        sorted_indices = np.argsort(distances)
        indices_to_keep = sorted_indices[:len(y_minority)]

        # Combine the undersampled majority class with the minority class
        X_resampled = pd.concat([X_majority.iloc[indices_to_keep], X_minority])
        y_resampled = pd.concat([y_majority.iloc[indices_to_keep], y_minority])

        return X_resampled, y_resampled
</code></pre>
<p>MWE:</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.datasets import make_classification

X, y = make_classification(n_samples=10_000, n_classes=5, weights=[22.6, 3.7, 16.4, 51.9],
                           n_informative=4)

rf_clf = model = RandomForestClassifier()
resampler = DataUndersampler(random_state=234)

pipeline = Pipeline([('sampler', resampler), ('clf', rf_clf)])
classifier = OneVsOneClassifier(estimator=pipeline)

classifier.fit(X, y)
</code></pre>
<p>Produces the error:</p>
<pre class=""lang-py prettyprint-override""><code>----&gt; 7 classifier.fit(X, y)

18 frames
/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py in wrapped(self, X, *args, **kwargs)
    138     @wraps(f)
    139     def wrapped(self, X, *args, **kwargs):
--&gt; 140         data_to_wrap = f(self, X, *args, **kwargs)
    141         if isinstance(data_to_wrap, tuple):
    142             # only wrap the first output for cross decomposition

TypeError: DataUndersampler.transform() missing 1 required positional argument: 'y'
</code></pre>
","2023-07-04 14:03:04","3","Question"
"76607423","76237951","","<p>pip install altair
was not working for me. I used:</p>
<pre><code>pip install altair==4
</code></pre>
<p>See: <a href=""https://discuss.streamlit.io/t/modulenotfounderror-no-module-named-altair-vegalite-v4/42921"" rel=""nofollow noreferrer"">Discussion</a></p>
","2023-07-03 18:52:41","2","Answer"
"76603178","","Self-querying retrieval in langchain returning only 4 results","<p>I want all the articles related to specific tag example sustainability from documents. But it is only returing me Four articles. There are total 7 articles related to sustainability in vectorstore out of 20 articles.</p>
<p>Here is my code:</p>
<pre><code>import pinecone
from langchain.schema import Document
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
import os
from langchain.llms import OpenAI
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain.chains.query_constructor.base import AttributeInfo


pinecone_api_key = &quot;xxxxxxxx&quot;
pinecone_env = &quot;xxxxxxxxxx&quot;
# pinecone.init(api_key=os.environ[&quot;PINECONE_API_KEY&quot;], environment=os.environ[&quot;PINECONE_ENV&quot;])
pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)

embeddings = OpenAIEmbeddings()

index_name=&quot;langchain-self-retriever-ppo&quot;
index = pinecone.Index(index_name)
text_field = &quot;text&quot;

# vectorstore = Pinecone.from_documents(
#     docs, embeddings, index_name=&quot;langchain-self-retriever-demo&quot;
# )

vectorstore = Pinecone(
    index, embeddings.embed_query, text_field
)

metadata_field_info=[
    AttributeInfo(
        name=&quot;headline&quot;,
        description=&quot;The headline of the news article&quot;, 
        type=&quot;string or list[string]&quot;, 
    ),
    AttributeInfo(
        name=&quot;date&quot;,
        description=&quot;The date, news article was published&quot;, 
        type=&quot;integer&quot;, 
    ),
    AttributeInfo(
        name=&quot;publication&quot;,
        description=&quot;The name of the publication which published this news article&quot;, 
        type=&quot;string&quot;, 
    ),
    AttributeInfo(
        name=&quot;domain&quot;,
        description=&quot;The domain of the news article&quot;,
        type=&quot;float&quot;
    ),
]
document_content_description = &quot;Brief summary of a news article&quot;
llm = OpenAI(temperature=0)
# retriever = SelfQueryRetriever.from_llm(llm, vectorstore, document_content_description, metadata_field_info, verbose=True)

retriever = SelfQueryRetriever.from_llm(
    llm, 
    vectorstore, 
    document_content_description, 
    metadata_field_info, 
    enable_limit=True,
    verbose=True
)

# This example only specifies a relevant query
retrieved_docs = retriever.get_relevant_documents(&quot;Articles which are related to sustainability&quot;)
print(retrieved_docs)
print(len(retrieved_docs))
</code></pre>
<p>I have gone inside <code>get_relevant_documents</code> method here it uses <code>self.vectorstore.search</code> which calls <code>self.similarity_search</code> method which by defaults sets limit to 4 if not given.</p>
<p>I tried setting limit to 7 it returned 7 <code>sustainability</code> articles.
But I wouldn't know how much articles will be related to <code>sustainability</code> so I can't by default set the limit.</p>
","2023-07-03 08:45:41","6","Question"
"76600375","76598217","","<p>The SVD decomposition of a matrix <em>A</em> does not change the dimensions of <em>A</em>. And it wouldn't be a valuable thing to just reduce and image size, for, it would reduce the image <strong>quality</strong>. But we want to preserve image quality!</p>
<p>Instead, the SVD decomposition <em>A = U Σ V^T</em> means that we keep the same dimension for <em>A</em>, but we can replace three matrices <em>U</em>, <em>Σ</em>, <em>V</em> by much <strong>smaller</strong> matrices <em>U_r</em>, <em>\Sigma_r</em>, <em>V_r</em> which require much less numbers to write, but the product <em>A_r = U_r Σ_r V_r^T</em> of which is very close to our original matrix <em>A</em>.</p>
<p>These lecture notes explain the thing in detail:
<a href=""https://www.researchgate.net/publication/318066716_Linear_Algebra_Theory_and_Algorithms?o=Linear_Algebra"" rel=""nofollow noreferrer"">https://www.researchgate.net/publication/318066716_Linear_Algebra_Theory_and_Algorithms?o=Linear_Algebra</a></p>
<p>In particular, please see <strong>Section 38.2</strong> and <strong>Section 41.1</strong> (this section deals with images exactly!).</p>
","2023-07-02 18:57:03","2","Answer"
"76600019","76599896","","<p>Hope you want to find a sub string ('building') within a given string (e.g a tall building, a large building). You can use regexp for such searching.</p>
<pre><code>import re
#re.I for case insensitive search
re.search('building', 'a large buildinG', re.I)
</code></pre>
","2023-07-02 17:15:50","0","Answer"
"76599896","","Grouping Similar Annotation Semantically","<p>I have a TSV file that is the output of the Semantic-Segment-Anything model. In the model, the detection of objects may have different annotations. For instance, I am detecting my objects based on their X and Y coordinates. In my table, there is a column with results such as “building,” “a building,” and “a tall building.” However, I want to analyze the data in a way that considers all of these variations of “building” to be the same, so that my analysis will have more meaningful output. However, I don’t know what kind of annotation output Semantic-Segment-Anything would create to be clear that it targets those strings. Good to know that &quot;building&quot; is not just my case and this string variation happening to all annotations, actually this is the tricky part of the question which make it a bit complicated.
I want to know what the easiest way is to consider all of these variables of close output as one class.</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th style=""text-align: left;"">Frame Number</th>
<th style=""text-align: left;"">Class Name</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: left;"">0</td>
<td style=""text-align: left;"">building</td>
</tr>
<tr>
<td style=""text-align: left;"">1</td>
<td style=""text-align: left;"">a building</td>
</tr>
<tr>
<td style=""text-align: left;"">2</td>
<td style=""text-align: left;"">building</td>
</tr>
<tr>
<td style=""text-align: left;"">3</td>
<td style=""text-align: left;"">a tall building</td>
</tr>
<tr>
<td style=""text-align: left;"">4</td>
<td style=""text-align: left;"">a large building</td>
</tr>
<tr>
<td style=""text-align: left;"">5</td>
<td style=""text-align: left;"">building</td>
</tr>
<tr>
<td style=""text-align: left;"">6</td>
<td style=""text-align: left;"">a building</td>
</tr>
<tr>
<td style=""text-align: left;"">7</td>
<td style=""text-align: left;"">a building</td>
</tr>
<tr>
<td style=""text-align: left;"">8</td>
<td style=""text-align: left;"">building</td>
</tr>
<tr>
<td style=""text-align: left;"">9</td>
<td style=""text-align: left;"">tall building</td>
</tr>
<tr>
<td style=""text-align: left;"">10</td>
<td style=""text-align: left;"">a building</td>
</tr>
<tr>
<td style=""text-align: left;"">11</td>
<td style=""text-align: left;"">building</td>
</tr>
</tbody>
</table>
</div>
<p>I have seen some solutions that use dice coefficients or fuzzy string matching, but I want to know if there is a more semantic way of doing this.</p>
","2023-07-02 16:47:00","1","Question"
"76598288","76598217","","<p>As you have realized the dimension is the same.
The principal of SVD is that you decompose a matrix into three parts <code>M=USV^T</code>.
By using only the first <em>x</em> singular vectors and values you can reduce a data point to <code>x</code> dimensions.</p>
<p>For this you only use two of the matrices:</p>
<pre><code>img_cut = U[:, :x] @ np.diag(S[:x, :x])
</code></pre>
<p>You can likewise do it with V which is a reduction.
When thinking about tabular data, doing it this was is not a reduction in features but in samples.</p>
<hr />
<p>By using the other matrix you can reconstruct your original data - with some error depending on <em>x</em>. This reconstructed data is a <em>low rank approximation</em> with rank <em>x</em>.</p>
<pre><code>img_reconstructed = img_cut @ V[:x, :]
</code></pre>
","2023-07-02 09:42:54","2","Answer"
"76598217","","Picture dimension reduction","<p>I need to reduce my picture dimension by means of <em>singular value decomposition</em>.</p>
<p>I've seen a lot of sources for this theme. They advise to use the following:</p>
<pre class=""lang-python prettyprint-override""><code>m, n = img.shape
U, S, V = np.linalg.svd(img)
#U.shape = m * m; S.shape = m * n; V.shape = n * n
img_cut = U[:, :x] @ np.diag(S[:x, :x]) @ V[:x, :]
</code></pre>
<p>This is supposed to reduce the size of the image down to <code>x</code>. But the size of the image will be the same <code>m * n</code>, because <code>U.shape[0]</code> and <code>V.shape[1]</code> are remained the same. What can I do?</p>
","2023-07-02 09:21:55","0","Question"
"76597127","76013119","","<ol>
<li><p>TPOT optimizes pipelines and hyperparams together. Since it is using genetic algorithm, you can run it several times with different random seeds to see if there is a better [pipeline with set of hyperparameters] together. Or, use different population settings</p>
</li>
<li><p>If you don't want the pipeline to change. Import that in Sklearn and use something similar to TPOT. You can tune hyperparameters in Sklearns with Pipelines easily</p>
</li>
</ol>
<p>Here is an example: <a href=""https://medium.com/@kocur4d/hyper-parameter-tuning-with-pipelines-5310aff069d6"" rel=""nofollow noreferrer"">https://medium.com/@kocur4d/hyper-parameter-tuning-with-pipelines-5310aff069d6</a> search for (ctrl F) &quot;grid_params&quot; and see how it is configurated -- and, you can even export the tune grid from TPOT to your pipeline</p>
<p>If the pipeline is not big ( and you have tune dictionaries ) use GridSearchCV.</p>
<p>If the pipeline is big or the hyperparameter space have a lot of options, maybe use <a href=""https://sklearn-nature-inspired-algorithms.readthedocs.io/en/latest/introduction/nature-inspired-search-cv.html"" rel=""nofollow noreferrer"">https://sklearn-nature-inspired-algorithms.readthedocs.io/en/latest/introduction/nature-inspired-search-cv.html</a> (NaturalInspiredSearchCV) this has similar grammar, and can use the 'runs' to configure parallel training. You can also modify the population settings to avoid it sink into local critical points.</p>
","2023-07-02 01:51:18","1","Answer"
"76593869","76593747","","<p><strong>Approach 1:</strong> Assuming, you have a 2D array of predictions and true values, where each row corresponds to a different observation and each column corresponds to a different time step in the future. You can calculate the MAE for each observation and then average these to get the overall MAE.</p>
<p>Using this code snippet:</p>
<pre><code>import numpy as np
from sklearn.metrics import mean_absolute_error

# Assuming preds and trues are your arrays of predictions and true values
# They should have shape (65, 20)

# Calculate the MAE for each observation
mae_per_observation = np.mean(np.abs(preds - trues), axis=1)

# Calculate the overall MAE
overall_mae = np.mean(mae_per_observation)

print(f&quot;Overall MAE: {overall_mae}&quot;)
</code></pre>
<p>The above code calculates the absolute difference between the predicted and true values for each time step and each observation. It then averages these to get the MAE for each observation and then averages these to get the overall MAE.</p>
<p><strong>Approach 2:</strong> The other approach you mentioned, where the predictions and true values are concatenated into 1D arrays, is also valid. This would give you the MAE across all time steps and all observations, rather than averaging the MAE for each observation.</p>
<p>Like so:</p>
<pre><code># Concatenate the predictions and true values into 1D arrays
preds_1d = preds.ravel()
trues_1d = trues.ravel()

# Calculate the MAE
overall_mae = mean_absolute_error(preds_1d, trues_1d)

print(f&quot;Overall MAE: {overall_mae}&quot;)
</code></pre>
<p>The choice between the two methods depends on what you're interested in understanding from your model.</p>
<ol>
<li><p><strong>Per-observation MAE</strong>: This method calculates the MAE for each observation (i.e., each stock price time series) separately and then averages them. This approach gives equal weight to each time series, regardless of its length. This might be useful if you're interested in understanding how well your model performs on average for each stock price time series.
For example, <em><strong>if you have multiple stocks and you want to ensure your model performs reasonably well for each individual stock</strong></em>, this would be more appropriate.</p>
</li>
<li><p><strong>Overall MAE</strong>: This method calculates the MAE across all time steps and all observations. This approach gives equal weight to each individual prediction, regardless of which observation (stock) it belongs to. This might be useful if you're interested in the overall performance of your model across all predictions. For instance, <em><strong>if you're using the model to make a large number of trades/portfolio and care more about the total profit or loss across all trades, rather than the performance for individual stocks</strong></em>. This would be the way to go.</p>
</li>
</ol>
","2023-07-01 08:40:58","0","Answer"
"76593796","76593747","","<p>Assuming you are using PyTorch it is a little simpler (<code>preds</code> and <code>trues</code> should be <code>torch.Tensor</code>):</p>
<pre><code>import torch

preds = torch.randn(64, 20)
trues = torch.randn(64, 20)

# (64, 20) - (64, 20) and mean of all the values
loss = torch.nn.functional.l1_loss(preds, trues)
print(loss)
</code></pre>
<p>This calculates mean across sample (batch) and timestep. If you want to calculate mean MAE across samples only, you can do the following instead:</p>
<pre><code>loss = torch.nn.functional.l1_loss(preds, trues, reduction=&quot;sum&quot;) / preds.shape[0]
</code></pre>
","2023-07-01 08:15:57","0","Answer"
"76593747","","The standard way to evaluate multi-step timeseries predicted values with the true values?","<p>I'm working in a time series forecasting: if I have the target column (y) as a stock price to be forecasted,</p>
<p>I have a test data set size of 65 observations,</p>
<p>suppose that the prediction length (predicated prices for future days) = 20.</p>
<p>So, each observation of the test dataset will generate 20 predictions
= array(65,20).</p>
<p>Now,  to calculate the evaluation metrics MAE between(predictions, trues).
what is the standard way to do so? I mean, should I:
Take the first 20 predicted values and compare them with the first 20 true values.
Calculate the absolute difference between each predicted value and its corresponding true value.
or what?
Can you please give me hints or some codes?
This is what I have done:</p>
<pre><code>preds = np.array(np.reshape(predictions, (65, 20)))
trues = np.array(np.reshape(values, (65, 20)))
preds= mm.inverse_transform(preds)
trues= mm.inverse_transform(trues)
preds= preds[0:,1]
trues= trues[0:,1]
metrics = metric(preds, trues)
</code></pre>
<p>I have seen other developers do it like that:</p>
<pre><code>vals = np.concatenate(values, axis=0).ravel()
preds = np.concatenate(predictions, axis=0).ravel()
</code></pre>
","2023-07-01 07:58:02","0","Question"
"76586656","76538597","","<p>The problem i believe was how i prompted the model, It is a text generation model so in my case i was giving a transcript and i had to write in the end &quot;Summary: &quot;.</p>
<p>So this <strong>DID NOT</strong> work: &quot;Summarize this transcript. Transcript: ...&quot;</p>
<p>This <strong>WORKED</strong>: &quot;Transcript: .... , Summary: &quot;</p>
<p>Full Working code below:</p>
<pre><code>model_path=&quot;tiiuae/falcon-7b&quot;

config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, load_in_4bit=True, device_map=&quot;auto&quot;)

tokenizer = AutoTokenizer.from_pretrained(model_path)
input_text = &quot;What is a giraffe?&quot;
input_ids = tokenizer(input_text, return_tensors=&quot;pt&quot;).input_ids.to(&quot;cuda&quot;)
attention_mask = torch.ones(input_ids.shape)

outputs = model.generate(input_ids,
            attention_mask=attention_mask,
            max_length=2000,
            do_sample=True,
            top_k=10,
            num_return_sequences=1,
            eos_token_id=tokenizer.eos_token_id,)

for output in outputs:
  output_text = tokenizer.decode(output, skip_special_tokens=True)
  print(&quot;GENERATED TEXT: ------------&quot;)
  print(output_text)
</code></pre>
","2023-06-30 06:51:56","0","Answer"
"76564123","76563882","","<p><code>LinearRegression</code> class expects a 2D array as input for the predict method. so,
pass a 2D array directly like this <code>reg.predict([[3300]])</code> or reshape the array using the reshape function like this</p>
<pre><code>reg.predict(np.array([3300]).reshape(-1, 1))
</code></pre>
","2023-06-27 10:52:23","0","Answer"
"76564028","76563882","","<p>reg.predict() is waiting for X in the same dimension as it was in reg.fit().
If you check <code>df[['area']].shape</code> you can see something like (n, 1). It means that there is 1 column and n rows, in oreder to make a prediction you need to have the same amount of columns (1 in your case) and number of rows is flexible (1 in your case).
So the solution is:</p>
<pre><code>reg = LinearRegression()
reg.fit(df[['area']], df.price)
reg.predict([[3300]])
</code></pre>
<p>or</p>
<pre><code>reg = LinearRegression()
reg.fit(df[['area']], df.price)
reg.predict(np.array([[3300]]))
</code></pre>
<p>or</p>
<pre><code>reg = LinearRegression()
reg.fit(df[['area']], df.price)
reg.predict(pd.DataFrame([[3300]], columns=['area']))
</code></pre>
<p>All these structures are the 2-dimensional with 1 column and 1 row</p>
","2023-06-27 10:39:37","0","Answer"
"76563882","","how do i stop the error code ""EXPECTED 2D ARRAY""","<p>I tried predicting  the outcome of a particular data in a data frame. please i need solution to this problem.</p>
<pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
df = pd.read_csv(r'C:\Users\USER\Downloads\homeprices.csv')

reg = LinearRegression()
reg.fit(df[['area']], df.price)
reg.predict(3300)
</code></pre>
<p>This returns</p>
<pre><code>ValueError: Expected 2D array, got 1D array instead:

array=[3300].
</code></pre>
","2023-06-27 10:20:39","0","Question"
"76561854","76538597","","<p>I tried your code and I changed the <strong>max-length to 100</strong> to check its run time.</p>
<p>I create a <strong>VM size of 140GB</strong> with <strong>CPU</strong> as below,</p>
<p><img src=""https://i.imgur.com/Aei9ghR.png"" alt=""enter image description here"" /></p>
<p>I made small changes with your code as below,</p>
<p><strong>Code:</strong></p>
<pre class=""lang-py prettyprint-override""><code>import conda
%conda install cudatoolkit

%pip install torch
%pip install einops
%pip install accelerate
%pip install transformers==4.27.4
%pip install huggingface-hub
%pip install chardet
%pip install cchardet

from transformers import AutoTokenizer, AutoModelForCausalLM, TFAutoModelForCausalLM
import transformers
import torch
print(&quot;Done1&quot;)

model = &quot;tiiuae/falcon-7b&quot;
rrmodel = AutoModelForCausalLM.from_pretrained(model, 
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    device_map=&quot;auto&quot;)
tokenizer = AutoTokenizer.from_pretrained(model)

print(&quot;Done2&quot;)
input_text = &quot;What is a giraffe?&quot;

input_ids = tokenizer.encode(input_text, return_tensors='pt')

attention_mask = torch.ones(input_ids.shape)
output = rrmodel.generate(input_ids, 
            attention_mask=attention_mask, 
            max_length=100,
            do_sample=True,
            pad_token_id = 50256,
            top_k=10,
            num_return_sequences=1,
            eos_token_id=tokenizer.eos_token_id)

print(f&quot;Got output: {output}&quot;)
output_text = tokenizer.decode(output[0], skip_special_tokens=True)

print(output_text)
</code></pre>
<p>Then, I started running the code in my <strong>ML Studio</strong> like below,</p>
<p><img src=""https://i.imgur.com/1p7ZF8C.png"" alt=""enter image description here"" /></p>
<p><img src=""https://i.imgur.com/zkrFmK7.png"" alt=""enter image description here"" /></p>
<p><img src=""https://i.imgur.com/AzQgdQk.png"" alt=""enter image description here"" /></p>
<p>It almost took <strong>3:30 hrs</strong> to run like below,</p>
<p><img src=""https://i.imgur.com/nZUWyHg.png"" alt=""enter image description here"" /></p>
<p><img src=""https://i.imgur.com/oCPcTOi.png"" alt=""enter image description here"" /></p>
<p><strong>Output:</strong></p>
<p>It runs successfully as below,</p>
<p><img src=""https://i.imgur.com/JUzpimA.png"" alt=""enter image description here"" /></p>
<p><strong>With 100 max-length it took 3:30 hrs, it will take much time for 2000 max-length. Deploy the VM that runs your notebook with higher GPU size.</strong></p>
","2023-06-27 05:29:57","0","Answer"
"76546533","75867322","","<p>The warning suggests to use <code>learning_rate</code> or the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD. Try out the code below it should fix the error.</p>
<p><code>optimizer = tf.keras.optimizers.legacy.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=nesterov)</code></p>
","2023-06-24 14:30:41","0","Answer"
"76540078","76539887","","<p>You could use mean-shift clustering or k-means clustering or DBSCAN on the labelled data to consolidate the labels into your 3 to 8 bins.  The parameters of these methods can be used to control the final number or binnings.</p>
<p>After clustering your labelled data.  You use the new binnings as your labels.  To apply the new labels to the non-labelled data, you could use k-nearest neighbors or DBSCAN again.</p>
","2023-06-23 12:21:34","0","Answer"
"76539964","76539887","","<p>You can use KMeans from scikit-learn to achieve this, let us say your dataframe is df something like this:</p>
<pre><code>from sklearn.cluster import KMeans

X = df.drop(columns=['Label']).values

kmeans = KMeans(n_clusters=3, random_state=0, n_init=&quot;auto&quot;).fit(X)
df['cluster'] = kmeans.labels_
print(df) # df should contain label and cluster for all the datapoints
</code></pre>
<p>Mixing of classes will happen no matter what clustering algorithm you use on the whole dataset. The other Idea is that you somehow embed all the datapoints of one class to a single vector by doing that you will have only 100+ vectors each representing one class after that cluster these 100+ vectors to any number of clusters you desire, then you will have no mixing.</p>
","2023-06-23 12:06:48","1","Answer"
"76539887","","Do clustering on dataset but don't divide items with the same label","<p>I have a dataset with 10k+ points. Some of the data is labeled into 100+ labels. The rest is to classify.</p>
<p>I cannot classify the new data directly as the number of labels is too high and the result doesn't look good enough.</p>
<p>So I want to learn clustering algorithm on the labeled dataset and divide roughly into 3-8 bins. I don't care which labels go into which group, but I want them to be concise. So the new data will be assigned into the correct cluster. And later on classified within model trained on a single bin.</p>
<p>Question: How to cluster dataset but force the algorithm to keep the different points in the same label in the same cluster?</p>
<p>Data:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Id</th>
<th>Label</th>
<th>Feature 1</th>
<th>Feature 2</th>
<th>[...]</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>A</td>
<td>1</td>
<td>3</td>
<td>...</td>
</tr>
<tr>
<td>2</td>
<td>A</td>
<td>7</td>
<td>7</td>
<td>...</td>
</tr>
<tr>
<td>3</td>
<td>B</td>
<td>10</td>
<td>9</td>
<td>...</td>
</tr>
<tr>
<td>4</td>
<td>B</td>
<td>50</td>
<td>11</td>
<td>...</td>
</tr>
<tr>
<td>5</td>
<td>C</td>
<td>91</td>
<td>15</td>
<td>...</td>
</tr>
<tr>
<td>6</td>
<td>C</td>
<td>31</td>
<td>17</td>
<td>...</td>
</tr>
<tr>
<td>7</td>
<td>D</td>
<td>0</td>
<td>19</td>
<td>...</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<p>Expected outcome:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Id</th>
<th>Label</th>
<th><strong>Cluster</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>A</td>
<td><strong>1</strong></td>
</tr>
<tr>
<td>2</td>
<td>A</td>
<td><strong>1</strong></td>
</tr>
<tr>
<td>3</td>
<td>B</td>
<td><strong>2</strong></td>
</tr>
<tr>
<td>4</td>
<td>B</td>
<td><strong>2</strong></td>
</tr>
<tr>
<td>5</td>
<td>C</td>
<td><strong>1</strong></td>
</tr>
<tr>
<td>6</td>
<td>C</td>
<td><strong>1</strong></td>
</tr>
<tr>
<td>7</td>
<td>D</td>
<td><strong>2</strong></td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<p>I was trying to find a way to include the division in the loss function</p>
","2023-06-23 11:57:37","0","Question"
"76538597","","Falcon LLM no output running on Azure Notebook","<p>I have been unable to get any output from the model even waiting 10 minutes. Running on a Azure Notebook with a Compute instance Standard_E4ds_v4, 4 core, 32GB.
Any assistance is appreciated.</p>
<p>Code:</p>
<pre><code>!source activate llm_env

%pip install conda
import conda
%conda install cudatoolkit

%pip install torch
%pip install einops
%pip install accelerate
%pip install transformers==4.27.4
%pip install huggingface-hub
%pip install chardet
%pip install cchardet

from transformers import AutoTokenizer, AutoModelForCausalLM, TFAutoModelForCausalLM
import transformers
import torch

model = &quot;tiiuae/falcon-7b&quot;
rrmodel = AutoModelForCausalLM.from_pretrained(model, 
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    device_map=&quot;auto&quot;,)
tokenizer = AutoTokenizer.from_pretrained(model)

input_text = &quot;What is a giraffe?&quot;
input_ids = tokenizer.encode(input_text, return_tensors='pt')

attention_mask = torch.ones(input_ids.shape)
output = rrmodel.generate(input_ids, 
            attention_mask=attention_mask, 
            max_length=2000,
            do_sample=True,
            pad_token_id = 50256,
            top_k=10,
            num_return_sequences=1,
            eos_token_id=tokenizer.eos_token_id,)
#Never goes into this section
print(f&quot;Got output: {output}&quot;)
output_text = tokenizer.decode(output[0], skip_special_tokens=True)

print(output_text)
</code></pre>
","2023-06-23 09:04:57","0","Question"
"76537874","75962760","","<p>For conv2D the input shape should be like this:
input_shape = (4, 28, 28, 3)</p>
","2023-06-23 07:18:59","0","Answer"
"76537275","76537113","","<p>The correct way to implement Cross Validation using LeaveOneOut() is as below for iris dataset:</p>
<pre><code>from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import LeaveOneOut

iris = load_iris() # Load the iris dataset

x = iris.data
y = iris.target
cv = LeaveOneOut()

y_true, y_pred = [], []

for train_ix, test_ix in cv.split(x):
    train_x, test_x = x[train_ix, :], x[test_ix, :]
    train_y, test_y = y[train_ix], y[test_ix]
    lr = LogisticRegression(solver='newton-cg')
    lr.fit(train_x, train_y)

    predicted_y = lr.predict(test_x)

    y_true.append(test_y[0])
    y_pred.append(predicted_y[0])

print(f&quot;Accuracy Score of Logistic Regression model is {round(accuracy_score(y_true, y_pred), 2)}&quot;)
</code></pre>
","2023-06-23 05:19:11","-1","Answer"
"76537113","","Why cross_val_score using LeaveOneOut() leads to nan validationscore?","<p>I was trying to fit different cross_val_score type(k-fold(),LeaveOneOut(),LeavepOut()) in iris dataset of sklearn.But LeaveOneOut() leads to  nan score list.why is this happening?Can anyone explain?Let me attach my part of code here==&gt;</p>
<pre><code>kfindex=LeaveOneOut()
model=LinearRegression()
scores=cross_val_score(model,iris.data,iris.target,cv=kfindex)
print(scores.mean(),scores.shape,scores)
</code></pre>
<p>output==&gt;(score)
[nan (150,) [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan]]</p>
<p>I tried cross_val_score manualy.it also lead to the same output</p>
<pre><code>i=0
scores=[]
for train_x_indices,test_x_indeces in kfindex.split(iris.data):
    xtrain,xtest=iris.data[train_x_indices],iris.data[test_x_indices]
    ytrain,ytest=iris.target[train_x_indices],iris.target[test_x_indices]
#     print(xtrain.shape)
    i+=1

    model.fit(xtrain,ytrain)
    a=model.score(xtest,ytest)
    scores.append(a)
print(i)
print(scores,np.mean(scores))
</code></pre>
<p>There are somany questions relating this nan value of cross_val_score.But none of them are leading to my solution.Please someone help</p>
","2023-06-23 04:39:09","0","Question"
"76535922","76535146","","<p><strong>UPDATE:</strong> There are now exposed API methods to <a href=""https://cloud.google.com/document-ai/docs/workbench/create-dataset#dataset_operations"" rel=""nofollow noreferrer"">create datasets</a> and <a href=""https://cloud.google.com/document-ai/docs/workbench/create-dataset#import_documents_rpc"" rel=""nofollow noreferrer"">import documents</a> using the <code>v1beta3</code> endpoint.</p>
<p>Similar answer as <a href=""https://stackoverflow.com/questions/76482896/train-a-custom-classifier-on-document-ai-through-api"">Train a custom classifier on Document AI through API</a></p>
<p>There's not currently an exposed API method to create datasets, import documents, or label documents. This all must be done through the UI.</p>
","2023-06-22 22:03:25","0","Answer"
"76535686","76526487","","<p>Focus on data preparation. Feature engineering, feature selection. You can try various methods like PCA, ICA, Polynomial features, Feature Agglomeration, Autoencoder latent representations and most importantly using your domain knowledge of the subject to choose appropriate features to engineer.</p>
<p>For feature selection, you can use simple algorithms like SelectKBest or more advanced methods such as Recursive Feature Elimination and Feature Importance from Tree-based Models.</p>
<p>After that, you can use a TPE optimizer like Optuna to efficiently explore the hyperparameter space for your models. Then you can build an ensemble such as a voting classifier using Ridge regressor coefficients or <code>scipy.minimize</code> to find the optimal weights.</p>
<p>Remember, always trust your cross validation scores! Good luck.</p>
","2023-06-22 21:13:47","1","Answer"
"76535146","","It's possible create a dataset in document ai processor and import documents via python API?","<p>It's possible, to do the steps in the below guide, using the Python API? I saw some documentation about creating processors and training processors via Python API. But, none about creating the dataset and importing documents in the processor.</p>
<p><a href=""https://cloud.google.com/document-ai/docs/workbench/create-dataset"" rel=""nofollow noreferrer"">https://cloud.google.com/document-ai/docs/workbench/create-dataset</a></p>
<p>Documentations that I already know:</p>
<ul>
<li><p>Train processors: <a href=""https://cloud.google.com/document-ai/docs/workbench/train-processor"" rel=""nofollow noreferrer"">https://cloud.google.com/document-ai/docs/workbench/train-processor</a></p>
</li>
<li><p>Manipulation of processors: <a href=""https://cloud.google.com/document-ai/docs/samples/documentai-create-processor"" rel=""nofollow noreferrer"">https://cloud.google.com/document-ai/docs/samples/documentai-create-processor</a></p>
</li>
</ul>
","2023-06-22 19:36:59","0","Question"
"76533527","","Why isn't mediapipe drawing the landmarks on the live feed","<p>This is the code I got from the mediapipe documentation. I tried a lot of ways to which how I can showcase the landmark graph onto live feed but nothing seems to work. I could really use some help to understand what is going on here that I am missing out.</p>
<pre><code>import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import cv2
import time
import mediapipe as mp
import numpy as np
from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2
import numpy as np

MARGIN = 10  # pixels
FONT_SIZE = 1
FONT_THICKNESS = 1
HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green

BaseOptions = mp.tasks.BaseOptions
HandLandmarker = mp.tasks.vision.HandLandmarker
HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions
HandLandmarkerResult = mp.tasks.vision.HandLandmarkerResult
VisionRunningMode = mp.tasks.vision.RunningMode

# Create a hand landmarker instance with the live stream mode:
def print_result(result: mp.tasks.vision.HandLandmarkerResult, output_image: mp.Image, timestamp_ms: int):
    print('hand landmarker result: {}'.format(result))

options = HandLandmarkerOptions(
    base_options=BaseOptions(model_asset_path='hand_landmarker.task'),
    running_mode=VisionRunningMode.LIVE_STREAM,
    result_callback=print_result)
with HandLandmarker.create_from_options(options) as landmarker:
    cap = cv2.VideoCapture(0)
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_np = np.array(frame)
        timestamp = int(round(time.time()*1000))
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_np)
        frame = mp_image.numpy_view()
        result = landmarker.detect_async(mp_image, timestamp)
        if type(result) is not type(None):
           hand_landmarks_list = result.hand_landmarks
           for idx in range(len(hand_landmarks_list)):
                hand_landmarks = hand_landmarks_list[idx]

                # Draw the hand landmarks.
                hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
                hand_landmarks_proto.landmark.extend([
                landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks
                ])
                solutions.drawing_utils.draw_landmarks(
                    frame,
                    hand_landmarks_proto,
                    solutions.hands.HAND_CONNECTIONS,
                    solutions.drawing_styles.get_default_hand_landmarks_style(),
                    solutions.drawing_styles.get_default_hand_connections_style())                      
        else: 
            print('else')
        cv2.imshow('Frame', frame)
        if cv2.waitKey(1) &amp; 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()
</code></pre>
<p>I also keep getting this NoneType error everytime I pass the &quot;results function&quot;. I have no clue how to handle that as well. THe mediapipe documentation does not give any insight on how to show this in a live feed.</p>
","2023-06-22 15:33:46","0","Question"
"76532067","76528650","","<p>Run the code in kaggle or google colab notebooks. Then run this <code>!nvidia-smi</code></p>
<p>find you have cuda, it shows cuda version. and use <code>device = torch.device(&quot;cpu&quot;)</code>.</p>
<p>When you training the model use <code>model_0 = modelname().to(&quot;cuda&quot;)</code></p>
","2023-06-22 12:45:37","0","Answer"
"76529144","76528932","","<p>The first Conv1D will have an Ouput of (60,3000,3000) as it has the kernel size one, so it doesn't change the length.
The secound Conv1D will have an Output of (60,1,3000) as again, the kernel size is one, so it won't change the sequence length.
Yet each time you specifiy the amout of channels to be 3000 / 1.
The sigmoid function is an element wise function, so it doen't change the size at all.
As Kilian said, you need to increase the kernel size (and/or stride) to change the size of the third dimension.</p>
","2023-06-22 06:35:44","1","Answer"
"76529107","76528932","","<p>The input for Conv1d is in_channels, out_channels, kernelsize.
in_channels is the depth of your data. In a colour picture with RBG it would be 3. out_channels is the depth of the output and not the length of the sequence. You are projecting your one input channel into 3000 output channels. You should also increase the kernel size :)</p>
","2023-06-22 06:28:47","1","Answer"
"76528932","","Pytorch Conv1D produces more channels than expected","<p>I have the following neural network:</p>
<pre><code>class Discriminator(nn.Module):
    def __init__(self, input_size, output_size):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv1d(1, 3000, 1),
            nn.LeakyReLU(0.2),
            nn.Conv1d(3000, 1, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.main(x.float())

Discriminator = Discriminator()
</code></pre>
<p>Then I train this discriminator as follows:</p>
<pre><code>        for d_index in range(d_steps):
            Discriminator.zero_grad()
            prediction = Discriminator(d_real_data).view(-1) 
</code></pre>
<p>The shape of real_data is [60, 1, 3000] where</p>
<ul>
<li>batch size: 60</li>
<li>number of channels: 1</li>
<li>sequence length: 3000</li>
</ul>
<p>This input follows the documentation for <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html"" rel=""nofollow noreferrer"">Pytorch</a> Conv1D. What I'm expecting is <code>prediction</code> to be [60, 1, 1] and so flattening it with .view(-1) shapes it into a 1D array with 60 values. However, what I actually end up getting for the shape of <code>prediction</code> is [60, 1, 3000] and flattening it gives me a 1D array with 180000 values. Why is Conv1D with Sigmoid returning an output with the same shape as my input?</p>
","2023-06-22 05:56:34","1","Question"
"76528773","76528650","","<p>I think you are getting this error because the server of Streamlit does not have GPU instances so try to load your model in CPU rather than GPU(CUDA)</p>
<p>use this:</p>
<pre><code>device = torch.device(&quot;cpu&quot;)
</code></pre>
","2023-06-22 05:14:49","0","Answer"
"76528650","","A machine learning model that classifies dogs","<p>#question
Hello.
There was a problem deploying to streamlit. I did the same as in the video but it says something wrong.</p>
<p>I wrote the code correctly, I used <code>venv</code>. but for some reason it is not working.
<a href=""https://i.sstatic.net/xpNIU.jpg"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p><a href=""https://github.com/sitbayevalibek/dog-classification/issues/1"" rel=""nofollow noreferrer"">text</a></p>
<p>My GitHub profile shows the problem in full.</p>
","2023-06-22 04:41:13","-2","Question"
"76527562","76526487","","<p>A 0.77 accuracy is pretty much a good accuracy given the size of your data (3,500 records). When dealing with non-linear models, such data is insufficient for high model performance. I would suggest the following:</p>
<ol>
<li><p>Use a pre-trained model (if one exists). Fine-tune the model and then test it with your records.</p>
</li>
<li><p>Try changing your splitting ratio. It's possible that 3,500 records with a ratio of 80:20 and 90:10 will have similar features appearing in both the train and test datasets.</p>
</li>
<li><p>Please note that Ensemble is a &quot;bucket of models&quot;. It's possible that while trying out other models to see their accuracies, they could be part of those used with Ensemble. Try using a different alternative.</p>
</li>
<li><p>Do more data exploration and visualization to further understand your data and find definitive patterns that you wish to see in your model.</p>
</li>
</ol>
<p>All the best.</p>
","2023-06-21 22:36:34","1","Answer"
"76526743","76526487","","<p>First and foremost, 3500 records is not very much data. Given that, I think your results (accuracy =0.77, f1 score =0.75) are actually pretty reasonable (not knowing anything else about the problem). It's very common to deploy models with this type of performance depending on the application.
With 3500 records, most nonlinear methods won't perform well, so model-wise there isn't much to be done. However, here is what I would suggest trying:</p>
<ul>
<li>try encoding your columns in different ways</li>
<li>think about your problem space and see if there's any feature generation you can do based off your current features. This can remove some of the heavy-lifting from the model fitting process</li>
<li>spend time investigating your data distribution (do some clustering, plotting, investigation)</li>
<li>also investigate the distribution of classes/features in your FPs, TPs, FNs, and FPs. Sometimes an informative pattern will emerge</li>
</ul>
<p>Finally, you can often find blog articles where people are solving similar problems. These can be a wealth of anecdotal advice and unintuitive tips/tricks.</p>
<p>Good luck!</p>
","2023-06-21 20:00:25","1","Answer"
"76526487","","Getting similar results from different classifiers","<p>I have a dataset with about3500 record and I want to do classification models on it.I use different models and preprocessing things but the results for different models are close to each other and doesn’t change that much.
I don’t know where is the problem, and I can’t change the data I’m using. What should I do to get better results?</p>
<p>I tried different models(simple,ensemble), different hyper parameter tuning methods, differing scaling methods,different outlier detection methods and whatever I knew I could do, but with all of these the results stays about the same (about: accuracy =0.77, f1 score =0.75, AUROC=0.84,..)
I also tried different feature selection methods and with different number of features but the result didn’t change that much.</p>
","2023-06-21 19:19:32","0","Question"
"76521642","","Model is not learning when using transfer learning","<p>I am a beginner in machine learning and I am trying to develop a model that can predict age from a face dataset. However, my model is not learning and I am struggling to figure out why. I am importing the VGG16 architecture and it is still not learning. I have searched through forums and even tried training the model on only 2 examples and it is still unable to overfit.
Training accuracy barely increases and validation accuracy does not increase throughout training.</p>
<pre><code>path = &quot;../input/agedetection/dataset/dataset&quot;
files = os.listdir(path)
X = []
age_temp = []

for file in files:
    img = cv2.imread(path+'/'+file)
    img = cv2.resize(img, dsize = target_size)
    X.append(img)
    fields = file.split('_')
    age_temp.append(fields[0])

X = np.array(X).astype('float32')
X = X/255

#converting age into different brackets  - 0-20, 21-40, 41-60,61+
age = np.zeros(len(age_temp))

for i in range(len(age_temp)):
    curr_age = int(age_temp[i])
    if curr_age &lt;= 20:
        val = 0
    elif curr_age &lt;= 40:
        val = 1
    elif curr_age &lt;= 60:
        val = 2
    else:
        val = 3
    age[i] = val

age = to_categorical(age, num_classes = 4)
age = age.astype('float32')

base_model_age = tf.keras.applications.VGG16(input_shape=input_shape,include_top=False,weights=&quot;imagenet&quot;)
for layer in base_model_age.layers[:-20]:
    layer.trainable=False
model_age = Sequential()
model_age.add(base_model_age)
model_age.add(Flatten())
model_age.add(Dense(1024, activation='relu'))
model_age.add(Dense(4, activation = 'relu'))

model_age.compile(optimizer=Adam(adam),
              loss='mse'
              ,metrics=['accuracy'])

hist_age = model_age.fit(X_train, age_train,
                         validation_data=(X_validation, age_validation),
                         epochs=10, steps_per_epoch=256, 
                         callbacks=[lrd, mcp])
</code></pre>
","2023-06-21 09:05:40","0","Question"
"76518663","76503158","","<p>Maybe this...</p>
<pre><code>import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

# Step 1: Load and preprocess the dataset
data = pd.read_csv('sentiment_data.csv') # whatever your data is...
X = data['text']
y = data['label']

# Step 2: Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Feature extraction
vectorizer = CountVectorizer()
X_train_features = vectorizer.fit_transform(X_train)
X_test_features = vectorizer.transform(X_test)

# Step 4: Model training
model = MultinomialNB()
model.fit(X_train_features, y_train)

# Step 5: Model evaluation
accuracy = model.score(X_test_features, y_test)
print(&quot;Accuracy:&quot;, accuracy)

# Step 6: Predict sentiment for new text
new_text = [&quot;I love this product!&quot;]
new_text_features = vectorizer.transform(new_text)
prediction = model.predict(new_text_features)
print(&quot;Predicted sentiment:&quot;, prediction[0])
</code></pre>
<p>In this example, we assume that you have a dataset called 'sentiment_data.csv' with two columns: 'text' (containing the text data) and 'label' (containing the corresponding sentiment labels). You'll need to replace 'sentiment_data.csv' with your own dataset or modify the code accordingly.</p>
<p>The code uses the CountVectorizer class from scikit-learn to convert the text data into a numerical representation. It then splits the dataset into training and testing sets using the train_test_split function. The Naive Bayes algorithm (implemented as MultinomialNB) is trained on the training set and evaluated on the testing set.</p>
<p>Finally, the trained model is used to predict the sentiment of a new text (&quot;I love this product!&quot;) by transforming it into the same feature representation as the training data and calling the predict method.</p>
<p>Note that this is just a basic example, and there are many ways to improve the performance of sentiment analysis models, such as using more sophisticated feature representations (e.g., TF-IDF) or exploring different ML algorithms or deep learning approaches.</p>
","2023-06-20 22:06:23","-1","Answer"
"76517945","76502318","","<p>Is the data normally distributed? If not, normalize it, then take a random sample.</p>
<pre><code>df = df.sample(frac=0.50)
</code></pre>
","2023-06-20 19:45:05","0","Answer"
"76513388","76509990","","<p>-This code helps to shorten the sentence and also try to keep the semantic meaning , hope it helps you</p>
<pre><code>import spacy

#Load the English language model in spaCy
nlp = spacy.load('en_core_web_sm')

#Define a function to get the meaning of a sentence
def get_meaning(sentence):

   # Parse the sentence using spaCy
   doc = nlp(sentence)

   # Extract the main verb of the sentence
   main_verb = [token for token in doc if token.pos_ == 'VERB'][0]

   # Extract the main subject of the sentence
   main_subject = [token for token in doc if token.dep_ == 'nsubj'][0]

   # Extract the meaning of the sentence
   meaning = main_verb.lemma_ + &quot; &quot; + main_subject.lemma_

   return meaning

#Example sentence
sentence = &quot;In June 2017 Kaggle announced that it passed 1 million 
registered users..&quot;

#Get the meaning of the sentence
meaning = get_meaning(sentence)

#Print the sentence and its meaning
print(&quot;Sentence:&quot;, sentence)
print(&quot;Meaning:&quot;, meaning)

#Output:

Sentence: In June 2017 Kaggle announced that it passed 1 million registered users..

Meaning: announce Kaggle
</code></pre>
","2023-06-20 09:43:15","1","Answer"
"76511710","76502318","","<p>The <code>xgboost.DMatrix</code> class is an XGBoost-specific data container class, and it is generally not supported  by the Scikit-Learn framework as a valid argument in <code>fit(X, y)</code> and <code>predict(X)</code> method calls. Talking about <code>XGBClassifier</code> and <code>XGBRegressor</code> model classes in particular, then they expect that the incoming data containers are fully Scikit-Learn compatible (meaning Numpy arrays, and Pandas data frames); they will perform the &quot;conversion&quot; into <code>xgboost.DMatrix</code> data container class automatically.</p>
<p>The workaround to your problem would be to create your own Scikit-Learn style model class(es), which would accept/expect <code>xgboost.DMatrix</code> arguments, and if present, passed them on directly to the underlying XGBoost Learner API methods as-is, without performing any extra conversions on them. Please note that your <code>fit(X, y)</code> method implementation must disregard the <code>y</code> argument (because this information is already contained in the <code>X</code> argument).</p>
<p>Something like this:</p>
<pre class=""lang-py prettyprint-override""><code>class MyXGBTrainer(BaseEstimatir):

  def __init__(self):
    pass

  def fit(self, X, y):
    if not isinstance(X, DMatrix):
      raise TypeError()
    self.model_ = xgb.train(data = X)

  def predict(self, X):
    if not isinstance(X, DMatrix):
      raise TypeError()
    return self.model_.predict(data = X)
</code></pre>
","2023-06-20 05:49:50","0","Answer"
"76510869","76509562","","<p>Batch_size determines how many examples will be processed simultaneously in parallel. For example, in your code, as batch_size=1000, it means 1000 instances will be processed at the same time.</p>
<p>Block_size determines the fixed length of each sequence. The concatenated_examples list is divided into sequences of length block_size using a sliding window approach.</p>
<pre><code> Column 4 named input_ids expected length 1000 but got length 328
</code></pre>
<p>You may need to promise instances number divisible by 1000, as you only have 328 instances, you may use a little batch_size like 8.</p>
","2023-06-20 01:28:47","1","Answer"
"76510607","76509990","","<p>I don't have a ton of experience with NLP Systems but I would approach this in one of two ways to get your desire outcome (if I understand correctly):</p>
<h3>1. Find what defines sentences for you, for me I would do:</h3>
<ul>
<li>in English, subject-verb is required;</li>
<li>conjunctions, subjunctions, etc. are mostly unnecessary;</li>
<li>prepositions are unnecessary;</li>
<li>etc...</li>
</ul>
<h3>2. Check out this other post on Stack Overflow to see how you could extract meanings:</h3>
<ul>
<li><a href=""https://stackoverflow.com/q/52280334/21798546"">How to Grab meaning of sentence using NLP?</a> with spacy.io</li>
<li>Once you extract meanings, create your criteria like above and potentially run it througha regex</li>
<li>This might help with the <a href=""https://realpython.com/nltk-nlp-python"" rel=""nofollow noreferrer"">NLTK package</a></li>
</ul>
<p>And this can vary drastically depending on what you need but I hope this helps guide you towards a path that best serves you.</p>
","2023-06-19 23:40:37","1","Answer"
"76509990","","Question about how to shorten a long sentence while keeping its semantic meaning","<p>We are building a NLP system to compare semantic similarity between two sentences. Before sentence embedding, we'd like to 'shorten/compress' the sentences a bit because it is quite long.</p>
<p>Can we know how to shorten a long sentence in NLP task while keeping the semantic meaning of the sentence as much as possible? We've known a possible and simplest solution which uses a sliding window to extract various chunks from the input sentence:</p>
<p>For example, the input sentence is <code>In June 2017 Kaggle announced that it passed 1 million registered users.</code>. Several chunks can be extracted as follows:</p>
<pre><code>In June 2017 Kaggle announced that # chunk 1
announced that it passed 1 million # chunk 2
1 million registered users # chunk 3
</code></pre>
<p>Actually, this method may lose some semantic information of the sentence. Except for this simplest way, is there any other smarter way to shorten the sentence while keep semantic meaning?</p>
<p>Thanks!</p>
","2023-06-19 20:48:21","-1","Question"
"76509562","","ArrowInvalid: Column 4 named input_ids expected length 1000 but got length 328","<pre><code># Formatting
block_size = 128  # or any number suitable to your context


def group_texts(examples):
    # Concatenate all 'input_ids'
    concatenated_examples = sum(examples[&quot;input_ids&quot;], [])
    total_length = len(concatenated_examples)
    # Organize into sequences of fixed length
    sequences = [
        concatenated_examples[i : i + block_size]
        for i in range(0, total_length, block_size)
    ]
    result = {
        &quot;input_ids&quot;: sequences,
        # Shift the labels for CLM
        &quot;labels&quot;: [sequence[1:] + [tokenizer.eos_token_id] for sequence in sequences],
    }
    return result


tokenized_dataset = tokenized_dataset.map(
    group_texts,
    batched=True,
    batch_size=1000,  # or any number suitable to your context
</code></pre>
<p>I am not getting what the block_size and the batch_size refers to?</p>
","2023-06-19 19:27:58","3","Question"
"76509483","76248695","","<pre><code>!pip install setuptools==65.5.0 &quot;wheel&lt;0.40.0&quot;
</code></pre>
","2023-06-19 19:11:38","0","Answer"
"76506834","76506467","","<p>For the sake of clarity, I will write here how to check the correct result. As said by @Lescurel, if one validates at each epoch, the same result will be delivered as it should be. The fit line in my original code can be replaced by:</p>
<pre><code>model_2.fit(data, epochs = 5, validation_data = data)
</code></pre>
","2023-06-19 12:53:43","0","Answer"
"76506596","76506467","","<p>The accuracy reported during the last training epoch is the accumulated accuracy during the epoch. Because you're doing mini batch gradient descent, the weights of the model used for the first batch are different than for the last batch during training.</p>
<p>If you were validating at each epoch, and then doing one more evaluation, you would see the same number.</p>
","2023-06-19 12:23:06","1","Answer"
"76506467","","Different values of accuracy in model.fit and model.evaluate on the same generator","<p>I obtain a different accuracy on the same generator by using the <code>model.fit</code> and <code>model.evaluate</code> in <code>tensorflow</code>. This is my sample code</p>
<pre><code>import tensorflow as tf
from nChannelGenerator import nChannelGenerator
from databaseSplitter import automaticPath
from keras.preprocessing.image import ImageDataGenerator

nClasses = 5

height = 200
width = 200
batch_size = 32


    model_1 = tf.keras.Sequential([
    tf.keras.layers.Rescaling(scale = 1./255, input_shape=[None, None, 3]),
    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.GlobalMaxPooling2D(),
    tf.keras.layers.Dense(nClasses, activation = &quot;softmax&quot;),
])

model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), metrics=[&quot;accuracy&quot;], loss = &quot;categorical_crossentropy&quot;)

datagen = ImageDataGenerator(rescale=1.)
data = datagen.flow_from_directory(&quot;database_prova&quot;)
model_2.fit(data, epochs = 5)
print(&quot;This is the evaluation step&quot;)
model_2.evaluate(data)
</code></pre>
<p>Then this is the output</p>
<pre><code>Found 1302 images belonging to 5 classes.
Epoch 1/5
41/41 [==============================] - 6s 84ms/step - loss: 1.5366 - accuracy: 0.2888
Epoch 2/5
41/41 [==============================] - 3s 64ms/step - loss: 1.3420 - accuracy: 0.4117
Epoch 3/5
41/41 [==============================] - 3s 63ms/step - loss: 0.9565 - accuracy: 0.5799
Epoch 4/5
41/41 [==============================] - 3s 64ms/step - loss: 0.7061 - accuracy: 0.6920
Epoch 5/5
41/41 [==============================] - 3s 64ms/step - loss: 0.6357 - accuracy: 0.7143
This is the evaluation step
41/41 [==============================] - 1s 26ms/step - loss: 0.5574 - accuracy: 0.7957
</code></pre>
<p>Both the accuracies and the losses are different between the last training step and the evaluation. I have no batch normalization here as you can see, I then expected the same values. I have seen a previous <a href=""https://stackoverflow.com/questions/61851737/why-does-keras-gives-me-different-results-between-model-evaluate-model-predicts"">response</a>, but I cannot figure out where is the problem.</p>
","2023-06-19 12:06:32","0","Question"
"76503709","76503158","","<p>Tune your model. For example. Increase n_estimators, increase max_depth value.
Try using libraries like:</p>
<p><a href=""https://optuna.org/"" rel=""nofollow noreferrer"">https://optuna.org/</a> OR <a href=""https://hyperopt.github.io/hyperopt/"" rel=""nofollow noreferrer"">https://hyperopt.github.io/hyperopt/</a></p>
<p>A lot of things can be done to tune the model.
Also make sure that you are not overfitting or underfitting.</p>
","2023-06-19 04:59:00","0","Answer"
"76503158","","Sentiments analysis with ML","<p>hello am trying to train a model to use it to predict some news sentiments in my project but am stuck cause i only get a accuracy of 58%, i have already tried 2 different ML algorithms still the same percentage i would love to have some advices to enhance my accuracy</p>
<p>here is my code below please fell free to share with me tips am new in this domain :</p>
<pre><code>
#representation with word2vec model
model_headline= Word2Vec(sentences=all_headlines_clr, vector_size= 300, min_count= 5, window=5, sg=1 )

#vectorization
vectors=[]
for headline in all_headlines_clr :
  headline_vector = [model_headline.wv[word] for word in headline
                             if word in model_headline.wv.key_to_index ]
  vectors.append(headline_vector)

#normilization
max_length = max(len(headline_vector) for headline_vector in vectors)
x_normalized = [headline_vector/ np.linalg.norm(headline_vector) for headline_vector in vectors]
x_padded= pad_sequences(x_normalized, maxlen= max_length, padding='post')
print(x_padded.shape)
x=np.array(x_padded)


x_padded_flat = x_padded.reshape(x_padded.shape[0], -1)
#buiding model
label_encoder = LabelEncoder()
labels_numeric= label_encoder.fit_transform(etiquettes)
x_train, x_test,y_train, y_test= train_test_split(x_padded_flat, labels_numeric, test_size=0.2, random_state=42)

rf_model= RandomForestClassifier(n_estimators=100, random_state= 42)
rf_model.fit(x_train, y_train)
y_pred = rf_model.predict(x_test)
accuracy= accuracy_score(y_test, y_pred)
print('prediction : {:.2F}%'.format(accuracy* 100))
</code></pre>
","2023-06-19 01:34:43","-1","Question"
"76502318","","XGBoost: How to use a DMatrix with scikit-learn interface .fit","<p>I am currently using the scikit-learn interface for XGBoost in my project. However, I have an extremely large dataset, and each time I call <code>.fit</code>, the data is converted to a DMatrix, which is very time-consuming, especially when using a GPU that trains relatively fast. I've benchmarked using the native interface by using a single DMatrix for each fit, and the results show a significant difference (14s per fit vs 0.9s per fit). The problem is, I need a scikit-learn model so that it works with the rest of my program.</p>
<p>Is there a way to use a DMatrix with the scikit-learn interface in XGBoost, or any workarounds to avoid the repeated conversion to DMatrix while still maintaining compatibility with scikit-learn?</p>
<p>See the below code to get a reproducible way to cause this issue.</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.datasets import make_classification
from xgboost import XGBClassifier
import xgboost as xgb

# Large synthetic dataset
X, y = make_classification(n_samples=500_0000, n_features=20,
                           n_informative=10, n_redundant=10, random_state=42)

# scikit-learn
t = time.time()
model = XGBClassifier(tree_method=&quot;gpu_hist&quot;, gpu_id=0,
                      predictor=&quot;gpu_predictor&quot;, max_bin=256)
model.fit(X, y)
print(&quot;scikit-learn interface: &quot;, time.time() - t)

# scikit-learn again
t = time.time()
model.fit(X, y)
print(&quot;scikit-learn (2nd) interface: &quot;, time.time() - t)

print()

# DMatrix
dtrain = xgb.DMatrix(data=X, label=y)
t = time.time()
model = xgb.train({&quot;tree_method&quot;: &quot;gpu_hist&quot;, &quot;gpu_id&quot;: 0,
                  &quot;predictor&quot;: &quot;gpu_predictor&quot;}, dtrain)
print(&quot;native interface: &quot;, time.time() - t)

# DMatrix again
t = time.time()
model = xgb.train({&quot;tree_method&quot;: &quot;gpu_hist&quot;, &quot;gpu_id&quot;: 0,
                  &quot;predictor&quot;: &quot;gpu_predictor&quot;}, dtrain)
print(&quot;native (2nd) interface:: &quot;, time.time() - t)
</code></pre>
<p>Output:</p>
<pre><code>scikit-learn interface:  14.393212795257568
scikit-learn (2nd) interface:  14.048950433731079

native interface:  3.9494242668151855
native (2nd) interface::  0.9888997077941895
</code></pre>
<p>As you can see, there is a big time discrepancy between scikit-learn and native.</p>
","2023-06-18 19:56:25","3","Question"
"76498324","76495768","","<p>The <code>vector</code> example you gave only has 7 elements, not 9 ... but this incantation will give you all combinations of 5, 6, 7 elements:</p>
<pre class=""lang-r prettyprint-override""><code>r &lt;- lapply(5:7, combn, x = vector, simplify = FALSE) |&gt; 
   unlist(recursive=FALSE)
length(r) ## 29 = choose(7,5) + choose(7,6) + choose(7,7)
</code></pre>
<pre class=""lang-r prettyprint-override""><code>head(r,2)
[[1]]
[1] &quot;blood pressure&quot; &quot;sugar level&quot;    &quot;bmi&quot;            &quot;weight&quot;        
[5] &quot;skin thickness&quot;

[[2]]
[1] &quot;blood pressure&quot; &quot;sugar level&quot;    &quot;bmi&quot;            &quot;weight&quot;        
[5] &quot;weight&quot;   
</code></pre>
<p>You could then do something like:</p>
<pre class=""lang-r prettyprint-override""><code>lapply(r, function(v) lm(reformulate(v, response = &quot;your_response&quot;), data = your_data)
</code></pre>
<p>Note that if you're doing linear regression, <code>leaps::regsubsets()</code> will do this sort of thing much more efficiently ... and in general penalized regression (ridge, lasso, or elastic-net e.g. via the <code>glmnet()</code> package) will produce better predictive accuracy, more efficiently, then fitting separate models to loads of parameter combinations ...</p>
","2023-06-17 22:03:45","1","Answer"
"76498253","76495768","","<p>Your question is not entirely clear.  It seems that you want to run regressions for all 9 variables taken 5, 6, 7, 8. 9 at a time?  If so, that would be 256 regressions.  However, since the independent variables are assumed to be mutually independent you can simply run a regression using all 9 independent variables and then run a test to rank order variable importance.  Then take the top 5, 6, 7, 8, 9 highest ranked independent variables and test for RMSE or other statistic.</p>
<p>Here is a tutorial that shows you how to do it using the tidymodels platform if you are interested: <a href=""https://gmubusinessanalytics.netlify.app/lesson-05-r-tutorial.html"" rel=""nofollow noreferrer"">https://gmubusinessanalytics.netlify.app/lesson-05-r-tutorial.html</a></p>
","2023-06-17 21:39:27","1","Answer"
"76496435","76495768","","<pre><code>install.packages(&quot;gtools&quot;)
library(gtools)
combined5&lt;-combinations(n = 10, r = 5, v = combinations, repeats.allowed = FALSE)
</code></pre>
","2023-06-17 13:38:23","0","Answer"
"76495768","","R find composition for machine learning","<p>I would like to find the best variables out of all variables,
For instance I have 9 variables,</p>
<pre><code>vector=c(&quot;blood pressure&quot;, &quot;sugar level&quot;, &quot;bmi&quot;, &quot;weight&quot;,&quot;skin thickness&quot;,&quot;weight&quot;, &quot;gender&quot;)
</code></pre>
<p>I would like to take composition of all five variables, to calculate the best RMSE, than check for all 6 and then 7, 8 and 9, I would like to create a vector for all five possible, all six, all seven, all eight, what would be the script</p>
","2023-06-17 10:27:15","0","Question"
"76484921","76471584","","<ul>
<li>The main difference is that, let's say if you are using word2vec embeddings then when the unknown word come then the model gets confused as it doesn't know/understands the context.</li>
<li>Second thing is that, if you are using contextual embedding like wordpiece encoding, then when the new word comes then the model will try to find its embedding in its vocabulary. And if the embedding is not there, then it will break the word into subwords, and then it will try to find the embeddings for those subwords. And it will go on till the character level. And wordpiece will almost always have embeddings for the character. (Of course, to get those characters level embeddings, the wordpiece should be trained on enough data).
For e.g. text = &quot;My name is Harshad.&quot;
There is high probability that there are embeddings for the words &quot;My&quot;, &quot;name&quot;, &quot;is&quot; in word2vec and wordpiece encoding. But what about the word &quot;Harshad&quot;. The word2vec simply can't handle this word and will name is as &quot;Unknown&quot; word (in a way). But in wordpiece encoding the word will get divided like this: &quot;Har##&quot;, &quot;##shad&quot; Now the model will look for the embedding for these 2 words. If it doesn't find them, then it will go one step forward like this: &quot;Ha##&quot;, &quot;##r&quot;. Now it's highly likely that there is encoding for &quot;r&quot; but probably not for &quot;Ha&quot; then it will keep looking for embeddings until it find something even on character level.
But let's take an extreme case, let's say there is no embedding for &quot;Harshad&quot; then what? In this case, the model will tokenize it as &quot;UNK&quot;. It will tell the model that, this word is not present in its vocabulary.</li>
</ul>
","2023-06-15 19:22:39","0","Answer"
"76483846","75664004","","<p>I had this same issue and was able to fix it.</p>
<h2>My Setup</h2>
<ul>
<li>postgres v 14</li>
<li>installed via Postgres.app</li>
</ul>
<h2>First Mistake (mixed PG config)</h2>
<p>Even though I installed PG via the PG app, I tried to install this
extension using Homebrew.
This messed up some of the PG config settings.</p>
<p>Running this on the command line,</p>
<pre><code>pg_config --libdir
</code></pre>
<blockquote>
<p>Gave this output: /opt/homebrew/share/postgresql@14</p>
</blockquote>
<p>This is not good for a Postgres.app install.</p>
<p><strong>The Fix (reset pg configs)</strong></p>
<p><em>Assuming Postgres.app install!</em></p>
<pre><code>brew uninstall pgvector

brew uninstall postgresql
</code></pre>
<p>Now run:</p>
<pre><code>pg_config --libdir
</code></pre>
<blockquote>
<p>I get: /Applications/Postgres.app/Contents/Versions/14/lib</p>
</blockquote>
<p>Now, install pgvector using the Makefile approach.</p>
<h2>2nd Mistake (Extension files in the wrong place)</h2>
<p>Don't (as OP did), just copy the pgvector files to the Postgress extensions directory. This will create an invalid directory structure.</p>
<p>I believe make install will place the files in the proper place.
If
CREATE EXTENSION vector; still fails, you can check the following to ensure the files are in the right place.</p>
<p><strong>The Fix</strong></p>
<p>You should have the following files installed in the following directories.</p>
<p>All .SQL and .control files.
Ensure these files are in the following directory</p>
<blockquote>
<p>/Applications/Postgres.app/Contents/Versions/14/share/postgresql/extension</p>
</blockquote>
<p>vector.so is in the following directory</p>
<blockquote>
<p>/Applications/Postgres.app/Contents/Versions/14/lib/postgresql</p>
</blockquote>
<p>Install the extension</p>
<pre><code>psql &lt;your db&gt;
CREATE EXTENSION vector;
</code></pre>
","2023-06-15 16:44:26","5","Answer"
"76474507","75102134","","<p>The reason for this is because the parameters dtype of <code>nn.Linear</code> doesn't match your input's dtype; the default dtype for <code>nn.Linear</code> is <code>torch.float32</code> which is in your case different from your input data - <code>float64</code>.</p>
<p>The solution to <a href=""https://stackoverflow.com/questions/67456368/pytorch-getting-runtimeerror-found-dtype-double-but-expected-float"">this question</a> solves your problem and explains why @Anonymous answer works.</p>
<p>In short, add <code>self.double()</code> at the end of your constructor and things should run.</p>
","2023-06-14 14:10:31","11","Answer"
"76471584","","Difference between Word2Vec and contextual embedding","<p>am trying to understand the difference between word embedding and contextual embedding.</p>
<p>below is my understanding, please add if you find any corrections.</p>
<p>word embedding algorithm has a global vocabulary (dictionary) of words. when we are performing word2vec then the input corpus(unique words) maps with the global dictionary and it will return the embeddings.</p>
<p>contextual embedding is used to learn sequence-level semantics by considering the sequence of all words in the documents.</p>
<p>but I don't understand where we considered the context in a word embedding.</p>
","2023-06-14 08:33:37","1","Question"
"76471059","76470927","","<p><code>random.permutation</code> produces a 'shuffled' List of numbers which can be used as indices into the array. This index List is then used to re-order the data. See basic example below and note how the changed data order follows the indices (remember Python is 0 index based so the first data element <code>a</code> is an index 0). The <code>seed</code> can be defined so the same shuffling order is produced each time.</p>
<pre><code>import numpy as np

idx = np.random.permutation(5)

print(idx)

data = np.array(['a', 'b', 'c', 'd', 'e'])
new_data = data[idx]
print(new_data)
</code></pre>
<p>shows:</p>
<pre><code>[4 0 1 2 3]
['e' 'a' 'b' 'c' 'd']
</code></pre>
","2023-06-14 07:26:04","1","Answer"
"76471013","76470927","","<p>I presume shuffle_indices, data and labels are numpy arrays.</p>
<p>Numpy array can be indexed using another array. For example:</p>
<pre><code>x = np.array([2, 1, 0])
y = np.array(['a', 'b', 'c'])
z = y[x]

print(z)  # ['c', 'b', 'a']
</code></pre>
<p>In this case, z is the reverse of y (a special case of shuffling).</p>
","2023-06-14 07:19:47","0","Answer"
"76470927","","How did we shuffle the data and the labels?","<p>Greetings software engineers, it is requested to help me. I am confused that how were the data and the labels shuffled in this code(the specific code i am referring to is in the 2nd picture)?</p>
<p><a href=""https://i.sstatic.net/AlaJj.png"" rel=""nofollow noreferrer"">enter image description here</a>
<a href=""https://i.sstatic.net/AFwDS.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>I am curious how are the data and the labels shuffled in this piece of code? I mean look what it's saying is basically(suppose we have 10 elements in data):</p>
<pre><code>shuffle_indices = array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random
data = data[array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6])]
labels = labels[array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6])]
</code></pre>
<p>Please explain how does this work?????</p>
","2023-06-14 07:05:53","-2","Question"
"76469533","76465909","","<pre><code>ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0
</code></pre>
<p>This error means the label column only contains one type of label.</p>
<p>For example, we have a dataset looks like below:</p>
<pre><code>label | f1 | f2
1 | a1 | b1
1 | a1 | b2
...
1 | aN | bM
</code></pre>
<p>As all instances belong to 1 or 0, classification couldn't build a model for it.</p>
<p>Not sure why you treat a string column as label, if you couldn't get origin data, could you provide your transferred data as example? It may be helpful to check detail data example</p>
","2023-06-14 00:58:23","0","Answer"
"76465909","","ValueError: Need 2 classes but I have 0","<p>I need two classes but I have just one class so I got ValueError:</p>
<p>For Logistic Regression to understand, I converted string data types to integer data type. While there are Abnormal and Normal string values in the Class column, I updated them to 1 and 0. When I tried to fit Logistic Regression it gave an error. It says I need at least 2 classes but I have 1 class. I can't go back to the master data because I didn't copy the data before how can i fix it ?</p>
<pre><code>from sklearn.linear_model import LogisticRegression
</code></pre>
<pre><code>data[&quot;class&quot;] = [1 if each == &quot;Abnormal&quot; else 0 for each in data [&quot;class&quot;]]
</code></pre>
<pre><code>data.head()
</code></pre>
<pre><code>lr = LogisticRegression()
lr.fit(x_train.T, y_train.T)
</code></pre>
<pre><code>ValueError                                Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_16508\1381464910.py in &lt;module&gt;
      1 #Eğitim
      2 lr = LogisticRegression()
----&gt; 3 lr.fit(x_train.T, y_train.T)

~\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py in fit(self, X, y, sample_weight)
   1552         classes_ = self.classes_
   1553         if n_classes &lt; 2:
-&gt; 1554             raise ValueError(
   1555                 &quot;This solver needs samples of at least 2 classes&quot;
   1556                 &quot; in the data, but the data contains only one&quot;

ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0
</code></pre>
<p>I wanted to return to the original data, but I cannot return to the main data because I did not copy the master data before. I tried changing the data in the Class column to 1 and 0 but they are all corrected to 1 i.e. Abnormal.</p>
","2023-06-13 14:18:55","0","Question"
"76465074","76463707","","<p>Install Microsoft Visual C++ Build Tools with  appropriate version for your computer. This might help about this and upgrade &quot;pip&quot;</p>
<p><code>https://visualstudio.microsoft.com/visual-cpp-build-tools/</code></p>
<p><code>python -m pip install --upgrade pip</code></p>
<p>and after this, try again with:</p>
<p><code>pip install lap==0.4.0</code></p>
","2023-06-13 12:41:37","2","Answer"
"76463707","","unable to install lap==0.4.0 library in python","<p>I was trying to install lap for object detection but i cloud not do it.</p>
<p>I have try to installed it on python version 9 , 10 and 11 also but i cant do it</p>
<p>I am learning object detection from
Murtaza's Workshop - Robotics and AI.</p>
<p>or is  there any way to fix this problem</p>
<pre><code>C:\\Users\\ACER\\Desktop\\Object-Detection-Yolo\\venv39\\Scripts\\activate.bat
pip install lap==0.4.0
</code></pre>
<p>the error:</p>
<pre><code>Collecting lap==0.4.0
  Using cached lap-0.4.0.tar.gz (1.5 MB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Building wheels for collected packages: lap
  Building wheel for lap (setup.py): started
  Building wheel for lap (setup.py): finished with status 'error'
  Running setup.py clean for lap
Failed to build lap
Installing collected packages: lap
  Running setup.py install for lap: started
  Running setup.py install for lap: finished with status 'error'

  error: subprocess-exited-with-error
  
  python setup.py bdist_wheel did not run successfully.
  exit code: 1
  
  [39 lines of output]
  Partial import of lap during the build process.
  C:\Users\ACER\AppData\Local\Temp\pip-install-a82najcq\lap_e14dabff97d544e59d3633db1f44d15e\setup.py:223: DeprecationWarning:
  
    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result
    of the deprecation of `distutils` itself. It will be removed for
    Python &gt;= 3.12. For older Python versions it will remain present.
    It is recommended to use `setuptools &lt; 60.0` for those Python versions.
    For more details, see:
      https://numpy.org/devdocs/reference/distutils_status_migration.html
  
  
    from numpy.distutils.core import setup
  Generating cython files
  running bdist_wheel
  running build
  running config_cc
  INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options
  running config_fc
  INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options
  running build_src
  INFO: build_src
  INFO: building extension &quot;lap._lapjv&quot; sources
  INFO: building data_files sources
  INFO: build_src: building npy-pkg config files
  C:\Users\ACER\Desktop\Object-Detection-Yolo\venv39\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.
    warnings.warn(
  running build_py
  creating build
  creating build\lib.win-amd64-cpython-39
  creating build\lib.win-amd64-cpython-39\lap
  copying lap\lapmod.py -&gt; build\lib.win-amd64-cpython-39\lap
  copying lap\__init__.py -&gt; build\lib.win-amd64-cpython-39\lap
  running build_ext
  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils
  INFO: customize MSVCCompiler
  INFO: customize MSVCCompiler using build_ext
  INFO: CCompilerOpt.cc_test_flags[1077] : testing flags (/O2)
  error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/
  INFO: CCompilerOpt.cache_flush[857] : write cache to path -&gt; C:\Users\ACER\AppData\Local\Temp\pip-install-a82najcq\lap_e14dabff97d544e59d3633db1f44d15e\build\temp.win-amd64-cpython-39\Release\ccompiler_opt_cache_ext.py
  [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for lap
  error: subprocess-exited-with-error
  
  Running setup.py install for lap did not run successfully.
  exit code: 1
  
  [39 lines of output]
  Partial import of lap during the build process.
  C:\Users\ACER\AppData\Local\Temp\pip-install-a82najcq\lap_e14dabff97d544e59d3633db1f44d15e\setup.py:223: DeprecationWarning:
  
    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result
    of the deprecation of `distutils` itself. It will be removed for
    Python &gt;= 3.12. For older Python versions it will remain present.
    It is recommended to use `setuptools &lt; 60.0` for those Python versions.
    For more details, see:
      https://numpy.org/devdocs/reference/distutils_status_migration.html
  
  
    from numpy.distutils.core import setup
  Generating cython files
  running install
  C:\Users\ACER\Desktop\Object-Detection-Yolo\venv39\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.
    warnings.warn(
  running build
  running config_cc
  INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options
  running config_fc
  INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options
  running build_src
  INFO: build_src
  INFO: building extension &quot;lap._lapjv&quot; sources
  INFO: building data_files sources
  INFO: build_src: building npy-pkg config files
  running build_py
  creating build
  creating build\lib.win-amd64-cpython-39
  creating build\lib.win-amd64-cpython-39\lap
  copying lap\lapmod.py -&gt; build\lib.win-amd64-cpython-39\lap
  copying lap\__init__.py -&gt; build\lib.win-amd64-cpython-39\lap
  running build_ext
  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils
  INFO: customize MSVCCompiler
  INFO: customize MSVCCompiler using build_ext
  INFO: CCompilerOpt.cc_test_flags[1077] : testing flags (/O2)
  error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/
  INFO: CCompilerOpt.cache_flush[857] : write cache to path -&gt; C:\Users\ACER\AppData\Local\Temp\pip-install-a82najcq\lap_e14dabff97d544e59d3633db1f44d15e\build\temp.win-amd64-cpython-39\Release\ccompiler_opt_cache_ext.py
  [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: legacy-install-failure

Encountered error while trying to install package.

lap

note: This is an issue with the package mentioned above, not pip.
hint: See above for output from the failure.

[notice] A new release of pip available: 22.3.1 -&gt; 23.1.2
[notice] To update, run: python.exe -m pip install --upgrade pip
</code></pre>
","2023-06-13 09:55:26","1","Question"
"76459068","76457346","","<p>I am not entirely sure what is making that high of a loss but i would suggest you increase your dataset size that may help. I mean a lot bigger. Why dont you try using some survey reports or even kaggle(altough the risk is upto you because the data from kaggle isnt authenticated)</p>
","2023-06-12 17:39:08","1","Answer"
"76458952","76457346","","<p>For applying regression on the data,any linear activation should be used in the output layer. Remove the sigmoid activation as it reduces the continuous values in the height. To further improve accuracy units inside &quot;tf.keras.layers.Dense()&quot; could also be increased.</p>
","2023-06-12 17:21:08","1","Answer"
"76457346","","Why are my loss and accuracy number are too much in neural net?","<p>Machine learning newbie here, i am currently learning on how to do neural net with tensorflow. I have this dataset below:</p>
<p><a href=""https://i.sstatic.net/QPfCJ.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/QPfCJ.png"" alt=""enter image description here"" /></a></p>
<p>out of curiosity, i wonder how will neural net perform on this dataset instead of using Linear Regression,so i typed this code below:</p>
<pre><code>x = file.drop(columns= &quot;Height&quot;).values
y = file.drop(columns= &quot;Weight&quot;).values
y = np.reshape(y, (-1, 1))
x = np.reshape(x, (-1, 1))

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
x = ss.fit_transform(x)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)


import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Dense(16, activation = &quot;relu&quot;),
    tf.keras.layers.Dense(16, activation = &quot;relu&quot;),
    tf.keras.layers.Dense(1, activation = &quot;sigmoid&quot;)
])

model.compile(optimizer= tf.keras.optimizers.Adam(),
loss = tf.keras.losses.BinaryCrossentropy(), metrics= &quot;accuracy&quot;)

model.fit(x_train, y_train, epochs = 10, batch_size = 16)#I actually dont fully know what batch size is, im adding that just for kicks
</code></pre>
<p>i scaled the data with the basic knowledge of by scaling it, the accuracy of neural net will increase slightly. However, when i run the code above, i get this &quot;ugly looking&quot; Accuracy and losses:
<a href=""https://i.sstatic.net/goCJ3.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/goCJ3.png"" alt=""enter image description here"" /></a></p>
<p><strong>What can i do to make the accuracy and loss better?</strong></p>
","2023-06-12 13:51:21","-1","Question"
"76444014","75800779","","<p>I was facing similar issue, for me increasing the batch size from 256 to 2048 avoided that error, so I also believe it might have to do with hyper parameter tunings and like mentioned above try normalization. Each model depends on the data.</p>
","2023-06-09 22:46:22","1","Answer"
"76420637","75775979","","<p>You should be careful when giving the parameters and act like this</p>
<pre><code>mfcc = librosa.feature.mfcc(y=signal[start:finish],sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length) 
</code></pre>
","2023-06-07 06:57:58","4","Answer"
"76408199","76067104","","<p>As explained in this topic<a href=""https://stackoverflow.com/questions/76364446/use-llamaindex-to-load-custom-llm-model"">similar issue</a>
my problem is the usage of VRAM is doubled. And i found the solution is: put the creation of the model and the tokenizer before the &quot;class&quot;. I think it could be possible to solve the problem either if put the creation of the model in an <strong>init</strong> of the class.</p>
","2023-06-05 16:05:24","0","Answer"
"76401009","76396140","","<p>Try executing your training method in a different process or thread and displaying your message when the thread is finished. I believe your issue is that you are using a <strong>for loop</strong> in a gui.</p>
","2023-06-04 15:00:26","0","Answer"
"76396140","","Issue with training a face recognition model using Tkinter and OpenCV","<p><strong>Description:</strong>
I'm currently working on a face recognition project using Tkinter for the GUI and OpenCV for image processing on visual studio. My goal is to train the model with a dataset of images and display a popup message indicating the completion of training. However, I'm encountering an issue where nothing happens when I click the &quot;TRAIN DATA&quot; button. The window doesn't open and there are no error messages displayed.</p>
<p><strong>Code</strong>:</p>
<pre><code>from tkinter import *
from tkinter import ttk
from PIL import Image, ImageTk
from tkinter import messagebox
import mysql.connector
import cv2
import os
import numpy as np

class Train:
    def __init__(self, root):
        self.root = root
        self.root.geometry(&quot;1530x790+0+0&quot;)
        self.root.title(&quot;Face Recognition System&quot;)  
        
        title_lbl= Label(self.root, text= &quot;TRAIN DATA SET&quot;,font=(&quot;times new roman&quot;,35,&quot;bold&quot;), bg=&quot;white&quot;,fg=&quot;darkgreen&quot;)
        title_lbl.place(x=0,y=0,width=1530, height=45)
        
        img_top= Image.open(r&quot;C:\Users\The-Javeira\Desktop\test\images\b.jpg&quot;)
        img_top= img_top.resize((1530,325), Image.ANTIALIAS)
        self.photoimg_top= ImageTk.PhotoImage(img_top)
        
        f_lbl2= Label(self.root,image=self.photoimg_top)
        f_lbl2.place(x=0,y=55,width=1530,height=325)  
        
         #button
        b1_1=Button(self.root ,text=&quot;TRAIN DATA&quot;, command=self.train_classifier, cursor=&quot;hand2&quot;,font=(&quot;times new roman&quot;,30,&quot;bold&quot;), bg=&quot;red&quot;,fg=&quot;white&quot;)
        b1_1.place(x=0,y=380,width=1530,height=60)
        
        img_bottom= Image.open(r&quot;C:\Users\The-Javeira\Desktop\test\images\train2.JPEG&quot;)
        img_bottom= img_bottom.resize((1530,325), Image.ANTIALIAS)
        self.photoimg_bottom= ImageTk.PhotoImage(img_bottom)
        
        f_lbl2= Label(self.root,image=self.photoimg_bottom)
        f_lbl2.place(x=0,y=440 ,width=1530,height=325)  
        
    def train_classifier(self):
        data_dir=(&quot;images data&quot;)
        path=[os.path.join(data_dir,file) for  file in os.listdir(data_dir)]
        
        faces=[]
        ids=[]
        
        for image in  path:
            img=Image.open(image).convert('L')    #Gray Scale Image
            imageNp=np.array(img,'uint8')
            id=int(os.path.split(image)[1].split('.')[1])
            
            faces.append(imageNp)
            ids.append(id)  
            cv2.imshow(&quot;Training Data&quot;,imageNp)
            cv2.waitKey(1)==13
        
        ids=np.array(ids)
        
        #============Train the classifier and Save ===========
      
        clf=cv2.face.LBPHFaceRecognizer_create()
        clf.train(faces,ids)
        clf.write(&quot;Classifier.xml&quot;)
        messagebox.showinfo(&quot;Result&quot;,&quot;Training Datasets Completed!!&quot;)
        cv2.destroyAllWindows()


if __name__ == &quot;__main__&quot;:
    root = Tk()
    obj = Train(root)
    root.mainloop()
        

        
        
        
            
            
        
             
     
</code></pre>
<p><strong>Expected Behavior:</strong>
When I click the &quot;TRAIN DATA&quot; button, I expect a window to open showing the training progress with images being displayed.
Once the training is complete, I expect a popup message saying &quot;Training Datasets Completed!!&quot; to appear.
The classifier should be saved as &quot;Classifier.xml&quot; in the specified directory.</p>
<p><strong>Actual Behavior:</strong>
When I click the &quot;TRAIN DATA&quot; button, nothing happens. The window doesn't open, and there are no error messages displayed.
The expected popup message indicating the completion of training doesn't appear.
No &quot;Classifier.xml&quot; file is created in the specified directory</p>
<p><strong>additional Information</strong>
All the required dependencies are installed.</p>
","2023-06-03 12:40:21","0","Question"
"76366991","76366880","","<p>The model expects an input shape of (30, 30, 3), but the data being fed into the model has a shape of (None, 26). Try modifying the input shape in your model to match your data. I.e. you should change the input shape in the model to (26, 26, 3) assuming that the data has 3 colour channels.</p>
<pre class=""lang-py prettyprint-override""><code>model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(26,26,3)))
</code></pre>
<p>Let me know how it goes.</p>
","2023-05-30 16:49:05","0","Answer"
"76366962","76366880","","<p>Working with TensorFlow, I have found that reading the error conveys most of the problem and its solution. Here you can see that the error is caused by a shape mismatch between the input shape expected by the model and the actual shape of the input data.</p>
<p>The model you defined expects input data of the form (None, 30, 30, 3). As such it expects a stack of images that are 30 pixels high and wide with 3 RGB color channels. However, the input data you provide is of the form (None, 26), which means that it does not have the required dimensions for processing by the convolution layer.</p>
<p>To solve this problem, make sure your input data has the correct shape (None, 30, 30, 3) before feeding it to the model. After that, they can be passed to the model without raising a ValueError.</p>
","2023-05-30 16:43:41","0","Answer"
"76366880","","ValueError: Input 0 of layer ""sequential"" is incompatible with the layer: expected shape=(None, 30, 30, 3), found shape=(None, 26)","<p>I have a small problem with CNN. I want to use my CNN to predict L a b color values. Unfortunately, I keep getting this error. Since this is my first time working with a CNN, I have no idea what this error code means.</p>
<p>Here is the error code:</p>
<pre><code>2023-05-30 16:57:03.347650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Traceback (most recent call last):
  File &quot;C:\Users\Desktop\src\main.py&quot;, line 57, in &lt;module&gt;
    main()
  File &quot;C:\Users\Desktop\src\main.py&quot;, line 31, in main
    models.train.main(model='cnn', color='gray', type='sig', vis=False, explain=False,
  File &quot;C:\Users\Desktop\src\models\train.py&quot;, line 571, in main
    train_cv(df, model, color, type, vis, explain, store_train, store_val, store_cv_model)
  File &quot;C:\Users\Desktop\src\models\train.py&quot;, line 314, in train_cv
    model.fit(X_train, y_train)
  File &quot;C:\Users\Anaconda3\envs\lib\site-packages\keras\utils\traceback_utils.py&quot;, line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File &quot;C:\Users\AppData\Local\Temp\__autograph_generated_file2mx7mlql.py&quot;, line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError: in user code:

    File &quot;C:\Users\Anaconda3\envs\lib\site-packages\keras\engine\training.py&quot;, line 1249, in train_function  *
        return step_function(self, iterator)
    File &quot;C:\Users\Anaconda3\envs\lib\site-packages\keras\engine\training.py&quot;, line 1233, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File &quot;C:\Users\Anaconda3\envs\lib\site-packages\keras\engine\training.py&quot;, line 1222, in run_step  **
        outputs = model.train_step(data)
    File &quot;C:\Users\Anaconda3\envs\lib\site-packages\keras\engine\training.py&quot;, line 1023, in train_step
        y_pred = self(x, training=True)
    File &quot;C:\Users\Anaconda3\envs\lib\site-packages\keras\utils\traceback_utils.py&quot;, line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File &quot;C:\Users\Anaconda3\envs\lib\site-packages\keras\engine\input_spec.py&quot;, line 295, in assert_input_compatibility
        raise ValueError(

    ValueError: Input 0 of layer &quot;sequential&quot; is incompatible with the layer: expected shape=(None, 30, 30, 3), found shape=(None, 26)
</code></pre>
<p>And this is my code:</p>
<pre><code>elif algorithm == 'cnn':

        model = Sequential()

        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(30,30,3)))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dense(3))
        model.compile(optimizer='adam', loss='mean_squared_error')
</code></pre>
<p>I wanted to try an cnn model</p>
","2023-05-30 16:31:06","0","Question"
"76352106","76247802","","<p>you need to tell it to look for the safetensors</p>
<pre><code>AutoModelForCausalLM.from_pretrained(
    &lt;path&gt;,
    use_safetensors=True,
    &lt;rest_of_args&gt;
)
</code></pre>
<p>This assumes you have the safetensors weights map in the same folder ofc</p>
<pre><code>model.safetensors.index.json
</code></pre>
","2023-05-28 15:01:08","1","Answer"
"76335064","75872880","","<p>This is kind of off-target, since you wanted to do it from scratch. But if you are interested in machine learning for Go, it's worth check out <a href=""https://github.com/gomlx/gomlx"" rel=""nofollow noreferrer"">github.com/gomlx/gomlx</a>, kind of like Jax/TensorFlow for Go.</p>
<p>While the matrix multiplication is done in the accelerator (XLA), you can check out there a clean (and well documented) the implementation of the other parts you probably will want to learn about, like the various optimizers (Adam in particular), normalization (layer and batch), dropout, losses, metrics and related things. They play a large role in the success of NN.</p>
<p>There is also a tutorial and some examples.</p>
","2023-05-25 17:57:30","0","Answer"
"76322621","76320365","","<p>I might change your Python code to also accept values from environment variables.  Probably the easiest way to do this is to set <code>default</code> values for the arguments using <code>os.getenv</code>; the <code>argparse</code> module doesn't do this on its own.</p>
<pre class=""lang-py prettyprint-override""><code>parser.add_argument('--image-path', type=str, default=os.getenv('IMAGE_PATH'))
parser.add_argument('--model-dir', type=str, default=os.getenv('MODEL_DIR'))
</code></pre>
<p>Once you've done that, you can set the default value as an environment variable in the Dockerfile, and not worry about the <code>ENTRYPOINT</code>/<code>CMD</code> split.</p>
<pre class=""lang-bash prettyprint-override""><code>ENV MODEL_DIR=./model.pth.tar
ENTRYPOINT [&quot;python3&quot;, &quot;./model.py&quot;]
</code></pre>
<pre class=""lang-bash prettyprint-override""><code>docker run -v /tmp:/data my_model --image-path=/data/happy.jpg
docker run -v /tmp:/data -e IMAGE_PATH=/data/happy.jpg my_model
</code></pre>
<p>In your original code it seems like the <code>--image-path</code> is read as a normal file; I've used an absolute path here to make it clear where it comes from.</p>
","2023-05-24 10:39:57","1","Answer"
"76321865","76321820","","<p>It's not clear which line of code is raising the exception but I suspect the culprit is skopt not having caught up with the full deprecation of <code>np.int</code> in numpy. You could downgrade numpy to <code>&lt;1.24</code> or this change could do:
from</p>
<pre class=""lang-py prettyprint-override""><code>        'degree': (1, 8),  # integer valued parameter
</code></pre>
<p>to</p>
<pre class=""lang-py prettyprint-override""><code>        'degree': np.arange(1,9),
</code></pre>
<p>to pass the integer dimension as a array of integer.</p>
<p>Edit: I found this ongoing <a href=""https://github.com/scikit-optimize/scikit-optimize/pull/1166"" rel=""noreferrer"">MR</a> to fix the issue</p>
","2023-05-24 09:10:30","5","Answer"
"76321820","","How to fix the 'numpy.int' attribute error when using skopt.BayesSearchCV in scikit-learn?","<p>When I run the following code on the official documentation, it has an error.</p>
<p><a href=""https://scikit-optimize.github.io/stable/auto_examples/sklearn-gridsearchcv-replacement.html"" rel=""noreferrer"">Minimal example</a></p>
<pre class=""lang-py prettyprint-override""><code>from skopt import BayesSearchCV
from sklearn.datasets import load_digits
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

X, y = load_digits(n_class=10, return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=.25, random_state=0)

# log-uniform: understand as search over p = exp(x) by varying x
opt = BayesSearchCV(
    SVC(),
    {
        'C': (1e-6, 1e+6, 'log-uniform'),
        'gamma': (1e-6, 1e+1, 'log-uniform'),
        'degree': (1, 8),  # integer valued parameter
        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter
    },
    n_iter=32,
    cv=3
)

opt.fit(X_train, y_train)
</code></pre>
<p>The last line produces an error:</p>
<blockquote>
<p><strong>AttributeError</strong>
module 'numpy' has no attribute 'int'.
<code>np.int</code> was a deprecated alias for the builtin <code>int</code>. To avoid this error in existing code, use <code>int</code> by itself. Doing this will not modify any behavior and is safe. When replacing <code>np.int</code>, you may wish to use e.g. <code>np.int64</code> or <code>np.int32</code> to specify the precision. If you wish to review your current use, check the release note link for additional information.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
<a href=""https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"" rel=""noreferrer"">https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations</a></p>
</blockquote>
<p>How can I solve this problem? Are there other ways to implement Bayesian search?</p>
<p>Perhaps the version of skopt is too old. Are there other ways to implement Bayesian search? Besides grid search, random search, and bayes search, is there any other way to help me choose the hyperparameters of the machine learning model?</p>
","2023-05-24 09:06:15","8","Question"
"76320629","76320365","","<p>Your Dockerfile has a typo in the <code>--model_dir</code> part. Try the following
<code>ENTRYPOINT [&quot;python3&quot;, &quot;./model.py&quot;, &quot;--model-dir&quot;]</code></p>
","2023-05-24 06:28:20","1","Answer"
"76320507","76320365","","<p>In general, containers don't have access to the host file system without being given explicit access through mounts. This is for security reasons.</p>
<p>The only way I can think of giving a container access to a file without mounting the file, is to pipe it into the container and then read it from stdin inside the container. You need to use the <code>-i</code> option on <code>docker run</code> when you do that.</p>
<p>As an example, you can take the contents of <code>/etc/os-release</code> on the host and pass it to <code>cat</code> inside the container like this</p>
<pre><code>cat /etc/os-release | docker run --rm -i debian cat
</code></pre>
<p>The container will then print out the contents of the host's <code>/etc/os-relase</code>.</p>
<p>Of course, this way only lets you read the content of the file. You can't update it. But if I'm reading your question correctly, you don't need to update the model data.</p>
","2023-05-24 06:07:57","1","Answer"
"76320365","","Pass file (model weight) as an argument to Docker Image","<p>I have a problem with loading a file to a Docker image. I would like to pass the file path as an argument and then be able to access (read) it from inside the image.</p>
<h3>File <em>model.py</em></h3>
<pre><code>if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument('--image-path', type=str)
  parser.add_argument('--model-dir', type=str)
  args, _ = parser.parse_known_args()

  sample_image = args.image_path
  print(&quot;Sample:&quot;, sample_image)
  print(&quot;Model:&quot;, args.model_dir)
  print(&quot;Done.&quot;)
</code></pre>
<h3>File <em>Dockerfile</em></h3>
<pre class=""lang-yaml prettyprint-override""><code>FROM python:3.10

WORKDIR /usr/src/app

RUN apt update &amp;&amp; apt install -y python3-pip

COPY model.py model.pth.tar ./

ENTRYPOINT [&quot;python3&quot;, &quot;./model.py&quot;, &quot;--model_dir&quot;]
CMD [&quot;./model.pth.tar&quot;]
</code></pre>
<p>From my understanding, the combination of these ENTRYPOINT and CMD should have worked. But I don't have any luck.</p>
<p>I managed to pass the required image (picture) by mounting:</p>
<p><code>docker build -t my_model --progress=plain .</code></p>
<p><code>docker run -v /tmp:/tmp/myfilesdocker my_model --image-path=happy.jpg</code></p>
<p>However, I don't want to do that with my <code>model.pth.tar</code> (model weight). I want it to be passed by default (or any other way that works and doesn't require mounting).</p>
","2023-05-24 05:38:42","0","Question"
"76320164","75640068","","<p>Just replace <code>lines.pop(0)</code> with <code>lines[0].remove()</code> or</p>
<pre><code>for line in lines:
    line.remove()
</code></pre>
","2023-05-24 04:46:17","5","Answer"
"76319656","76319374","","<p>You are receiving the error when you call <code>client.romanize_text</code> in your function because there is no <code>romanize_text</code> function in the <a href=""https://github.com/googleapis/python-translate/blob/main/google/cloud/translate_v3/services/translation_service/client.py"" rel=""nofollow noreferrer"">source code</a> for the client.</p>
<p>The <a href=""https://cloud.google.com/translate/docs/advanced/translating-text-v3#transliteration"" rel=""nofollow noreferrer"">transliteration documentation</a> for &quot;advanced translating text v3&quot; says that:</p>
<blockquote>
<p>Transliteration is a configuration setting in the <code>translateText</code> method. When you enable transliteration, you translate romanized text (Latin script) directly to a target language.</p>
</blockquote>
<p>However, you want to translate from a specified language to romanized text so this feature doesn't seem to be available (yet) via the Google Cloud Translate API. This observation is substantiated/alluded to in <a href=""https://stackoverflow.com/a/74571174/20087266"">this Stack Overflow answer</a> to a question similar to yours.</p>
<p>It seems like the PyPI package <a href=""https://pypi.org/project/ai4bharat-transliteration/"" rel=""nofollow noreferrer"">ai4bharat-transliteration</a> by the researchers at <a href=""https://ai4bharat.org"" rel=""nofollow noreferrer"">AI4Bharat</a> is a viable non-Google alternative for transliteration from Hindi to romanized text.</p>
","2023-05-24 02:06:47","1","Answer"
"76319374","","Transliteration from a source language to Roman (English) script","<p>We need the Romanization feature badly. Can someone please help? We want to transliterate (<strong>not translate</strong>) from Hindi (Devanagiri script) language to English (Roman script) language.</p>
<p><strong>Input</strong><br />
<code>romanize_text('अंतिम लक्ष्य क्या है')</code></p>
<p><strong>Expected Output</strong><br />
<code>'antim lakshya kya hai'</code></p>
<p>As per the <a href=""https://cloud.google.com/translate/docs/advanced/romanize-text#romanize_text"" rel=""nofollow noreferrer"">Google Romanize text docs</a>, I wrote the following Python code to transliterate from some language script to Roman script.</p>
<pre class=""lang-py prettyprint-override""><code># Authenticate using credentials.
import os
os.environ[&quot;GOOGLE_APPLICATION_CREDENTIALS&quot;] = &quot;translate.json&quot;

PROJECT_ID = &quot;project-id&quot;
LOCATION = &quot;global&quot;

# Imports the Google Cloud Translation library
from google.cloud import translate_v3

# Transliteration.
def romanize_text(text, src_lang=&quot;hi&quot;, tgt_lang=&quot;en&quot;):

    client = translate_v3.TranslationServiceClient()
    parent = f&quot;projects/{PROJECT_ID}/locations/{LOCATION}&quot;

    response = client.romanize_text(
        request={
            &quot;parent&quot;: parent,
            &quot;contents&quot;: [text],
            &quot;source_language_code&quot;: src_lang,
            &quot;target_language_code&quot;: tgt_lang,
        }
    )

    # Display the romanized for each input text provided
    for romanization in response.romanizations:
        print(f&quot;Romanized text: {romanization.romanized_text}&quot;)

romanize_text('अंतिम लक्ष्य क्या है')
</code></pre>
<p>Running the above code, gives the following error:</p>
<pre><code>AttributeError: 'TranslationServiceClient' object has no attribute 'romanize_text'
</code></pre>
<p>Also, in the <a href=""https://cloud.google.com/translate/docs/reference/rest/v3/projects/romanizeText"" rel=""nofollow noreferrer"">Google's API reference of romanizeText</a>, the right-hand side API Explorer is broken. Whereas, if you select any other method from the left-hand side - its API Explorer works correctly.</p>
<p>We need the Romanization feature badly: so either a solution to the aforementioned problem, or an alternative non-Google solution for romanization would be fine.</p>
","2023-05-24 00:24:08","2","Question"
"76297984","76252700","","<p>after viewing your code, I don't think this model weight could be update in julia,</p>
<p>the model should be contained in your loss code.
here is an example for how to set your loss func.</p>
<pre><code>loss3(model, x, y) = norm(model(x) .- y)        # the model is the first argument
</code></pre>
<p>PS. and there is also a simple syntax of Flux train:</p>
<pre><code>train!(loss, model, data, opt_state)
</code></pre>
<p>hope these help, and above code from the help of <code>?Flux.train!</code> in julia.</p>
","2023-05-21 01:47:48","1","Answer"
"76295619","76285998","","<p>@steve-landiss</p>
<p>DistilBERT model is trained to predict masked or missing words in a sentence. However, it's important to note that the models are not guaranteed to always produce meaningful results. DistilBERT generates outputs based on the probabilities learned during training, but they can still produce nonsensical outputs.
To improve the quality, you can fine-tune it with a dataset you have. Also, there are a couple of ways to get better results, like 1. increasing the value of top_k may give you a broader range of predicted words. 2. Ensembling: Instead of relying on a single language model, you can use an ensemble of multiple models. 3. Using larger models: Consider using a larger language model, like BERT or GPT-2. 4. Post-processing: Apply post-processing techniques to refine the model's outputs. You can even eliminate some of the outputs that you may get, like the &quot;period&quot; you said. 5. Context window: Adjust the context window size used for generating predictions. Here I provide you the code with some of these adjustments that may give you a deeper understanding of how to play with that:</p>
<pre><code>import torch
from transformers import DistilBertTokenizer, DistilBertForMaskedLM
import string
import nltk


model_name = 'distilbert-base-uncased'
tokenizer = DistilBertTokenizer.from_pretrained(model_name)
model = DistilBertForMaskedLM.from_pretrained(model_name)

####################################################################
sentence = &quot;I want to go to&quot;
context_window = 10  # Adjust the context window size

tokens = tokenizer.tokenize(sentence)
token_ids = tokenizer.convert_tokens_to_ids(tokens)
token_ids = [tokenizer.cls_token_id] + token_ids + [tokenizer.sep_token_id]
input_ids = torch.tensor([token_ids])
####################################################################
with torch.no_grad():
    outputs = model(input_ids)
    predictions = outputs.logits[0, -1]  # Predictions for the last token
####################################################################
temperature = 0.8  # Adjust the temperature value

# Sampling
probabilities = torch.softmax(predictions / temperature, dim=-1)
sampled_token_ids = torch.multinomial(probabilities, num_samples=top_k)
predicted_token_ids = sampled_token_ids.tolist()

predicted_words = tokenizer.convert_ids_to_tokens(predicted_token_ids)
print(f&quot;Original Sentence: {sentence}&quot;)
print(&quot;Predicted Next Words:&quot;)
for word in predicted_words:
    print(word)
####################################################################
# Top-k Sampling
top_k = 15  # Adjust the top-k value
topk_probabilities, topk_indices = torch.topk(probabilities, k=top_k)
sampled_token_ids = torch.multinomial(topk_probabilities.squeeze(), num_samples=1)
predicted_token_ids = topk_indices.squeeze(0)[sampled_token_ids].tolist()

predicted_words = tokenizer.convert_ids_to_tokens(predicted_token_ids)
print(f&quot;Original Sentence: {sentence}&quot;)
print(&quot;Predicted Next Words:&quot;)
for word in predicted_words:
    print(word)
####################################################################
# Beam Search
beam_width = 10  # Adjust the beam width
predicted_token_ids = []

for _ in range(beam_width):
    sampled_token_ids = torch.multinomial(probabilities, num_samples=1)
    predicted_token_ids.append(sampled_token_ids.item())

predicted_words = tokenizer.convert_ids_to_tokens(predicted_token_ids)
print(f&quot;Original Sentence: {sentence}&quot;)
print(&quot;Predicted Next Words:&quot;)
for word in predicted_words:
    print(word)
####################################################################
# Promoting context preservation
context_ids = input_ids[:, -context_window:]  # Select the last few tokens as context

with torch.no_grad():
    outputs = model(context_ids)
    predictions = outputs.logits[0, -1]  # Predictions for the last token

####################################################################
# Cleaning or filtering predictions: you can filter out the special tokens that you may have in your vocabulary
# this is a typical way to narrow down the vocabulary
filtered_predictions = []

for token_id in predicted_token_ids:
    predicted_word = tokenizer.convert_ids_to_tokens([token_id])[0]
    if predicted_word not in [&quot;[CLS]&quot;, &quot;[SEP]&quot;, &quot;[PAD]&quot;]:
        filtered_predictions.append(predicted_word)

####################################################################
# Experimenting with different models
# here  I give you the example model with gpt2 but you can also use different models like BERT, RoBERTa, etc.


nltk.download('words')
model_name = 'gpt2' # TODO: try to use different models here
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Rest of the code remains the same
with torch.no_grad():
    outputs = model(context_ids)
    predictions = outputs.logits[0, -1]  # Predictions for the last token
####################################################################
top_k = 20  # Number of top-k predictions to consider
probabilities = torch.softmax(predictions, dim=-1)
sampled_token_ids = torch.multinomial(probabilities, num_samples=top_k)
predicted_token_ids = sampled_token_ids.tolist()
####################################################################
predicted_words = tokenizer.convert_ids_to_tokens(predicted_token_ids)
print(f&quot;Original Sentence: {sentence}&quot;)
print(&quot;Predicted Next Words:&quot;)
for word in predicted_words:
    print(word)

# It is even possible to do post processing on the outputs:
# Like Im trying to Filter out non-English words and punctuation
english_words = set(nltk.corpus.words.words())
punctuation = set(string.punctuation)

filtered_predictions = []

for word in predicted_words:
    # Check if the word is an English word and not punctuation, # TODO: you can add more conditions here
    if word in english_words and word not in punctuation:
        filtered_predictions.append(word)

# Apply additional post-processing rules if needed
modified_predictions = []
for word in filtered_predictions:
    # Apply specific rules to modify the word if necessary
    # For example, convert to lowercase, remove leading/trailing whitespace, etc.
    modified_word = word.lower().strip()
    modified_predictions.append(modified_word)

# Print the modified predictions
print(&quot;Modified Predicted Words:&quot;)
print(f&quot;Original Sentence: {sentence}&quot;)
for word in modified_predictions:
    print(word) 
</code></pre>
","2023-05-20 14:01:10","1","Answer"
"76292443","76285998","","<p>I think it is because of the way of using top-k sampling to predict the next word. In this code, you take the top-k predictions based on their probabilities but not sampling from them, so you always get the exact top-k predictions, leading to the consistent prediction of a &quot;period&quot; as the next token.</p>
<p>To fix it, you need to apply sampling to the top-k predictions to obtain a more diverse set of next-word predictions. Here's what I think if you change in your code, it includes top-k sampling:</p>
<pre><code>import torch
from transformers import DistilBertTokenizer, DistilBertForMaskedLM
model_name = 'distilbert-base-uncased'
tokenizer = DistilBertTokenizer.from_pretrained(model_name)
model = DistilBertForMaskedLM.from_pretrained(model_name)
####################################################################
sentence = &quot;I want to go to the&quot;

tokens = tokenizer.tokenize(sentence)
token_ids = tokenizer.convert_tokens_to_ids(tokens)
token_ids = [tokenizer.cls_token_id] + token_ids + [tokenizer.sep_token_id]
input_ids = torch.tensor([token_ids])
####################################################################
with torch.no_grad():
    outputs = model(input_ids)
    predictions = outputs.logits[0, -1]  # Predictions for the last token
####################################################################
top_k = 5  # Number of top-k predictions to consider
probabilities = torch.softmax(predictions, dim=-1)
sampled_token_ids = torch.multinomial(probabilities, num_samples=top_k)
predicted_token_ids = sampled_token_ids.tolist()
####################################################################
predicted_words = tokenizer.convert_ids_to_tokens(predicted_token_ids)
print(f&quot;Original Sentence: {sentence}&quot;)
print(&quot;Predicted Next Words:&quot;)
for word in predicted_words:
    print(word)
</code></pre>
","2023-05-19 21:11:37","0","Answer"
"76286069","76248695","","<p><strong>TL;DR</strong>
Downgrade your <code>setuptools==65.5.0</code> and <code>wheel&lt;0.40.0</code></p>
<pre><code>!pip install setuptools==65.5.0 &quot;wheel&lt;0.40.0&quot;
</code></pre>
<p><strong>A bit more detail:</strong></p>
<p>The issue is related to <a href=""https://stackoverflow.com/questions/76129688/why-is-pip-install-gym-failing-with-python-setup-py-egg-info-did-not-run-succ/76286033#76286033"">this post</a> where the version of <code>wheel</code> and <code>setuptools</code> that Colab comes with by default is unable to install <code>gym==0.21.0</code>, which is a dependency of the version of <code>d2l==1.0.0b0</code> cached in Colab.</p>
<p>The authors of <code>d2l</code> have updated 1.0.0b0 to remove this dependency, but the changes are not reflected in the current versions of Colab.</p>
<p>To summarize <a href=""https://stackoverflow.com/questions/76129688/why-is-pip-install-gym-failing-with-python-setup-py-egg-info-did-not-run-succ/76286033#76286033"">the linked post</a>, the issue is with the latest version of <code>wheel</code> no longer being able to parse a dependency version string in the setup.py of <code>gym==0.21.0</code>. There is a workaround, which is to downgrade your versions of <code>wheel</code> and <code>setuptools</code>:</p>
<pre><code># I have read that 0.66.0 also works, but I haven't been able to
# verify this
!pip install setuptools==66.0.0 &quot;wheel&lt;0.40.0&quot;
</code></pre>
<p>You should then be able to successfully run the following after restarting your kernel:</p>
<pre><code>!pip install d2l==1.0.0b0
</code></pre>
","2023-05-19 04:48:34","1","Answer"
"76285998","","This code always predicts a ""period"" as the next text sequence","<p>I am trying to learn how to use the transformers library to make predictions on the next word given a sentence.  My code always predicts a &quot;period&quot; as the next token.  Can someone help me see what I am doing wrong?</p>
<pre><code>import torch
from transformers import DistilBertTokenizer, DistilBertForMaskedLM

# Load the pre-trained model and tokenizer
model_name = 'distilbert-base-uncased'
tokenizer = DistilBertTokenizer.from_pretrained(model_name)
model = DistilBertForMaskedLM.from_pretrained(model_name)

# Example sentence for predicting the next word
sentence = &quot;I want to go to the&quot;

# Tokenize the sentence
tokens = tokenizer.tokenize(sentence)

# Convert tokens to token IDs
token_ids = tokenizer.convert_tokens_to_ids(tokens)

# Add [CLS] and [SEP] tokens to the token IDs
token_ids = [tokenizer.cls_token_id] + token_ids + [tokenizer.sep_token_id]

# Create tensor input with the token IDs
input_ids = torch.tensor([token_ids])

# Get the predictions for the next word using top-k sampling
with torch.no_grad():
    outputs = model(input_ids)
    predictions = outputs.logits[0, -1]  # Predictions for the last token

# Apply top-k sampling to obtain the predicted next word
top_k = 5  # Number of top-k predictions to consider
probabilities = torch.softmax(predictions, dim=-1)
top_k_predictions = torch.topk(probabilities, k=top_k)
predicted_token_ids = top_k_predictions.indices.tolist()

# Convert predicted token IDs to actual words
predicted_words = tokenizer.convert_ids_to_tokens(predicted_token_ids)

# Print the predicted next words
print(f&quot;Original Sentence: {sentence}&quot;)
print(&quot;Predicted Next Words:&quot;)
for word in predicted_words:
    print(word)

</code></pre>
","2023-05-19 04:25:54","0","Question"
"76284289","75633185","","<p>You could use <code>pipwin</code> to install the appropriate build for your operating system and specific Python version:</p>
<p>Steps:</p>
<ol>
<li><p>Uninstall current version of sklearn:</p>
<p><code>pip uninstall scikit-learn -y</code></p>
</li>
<li><p>Install pipwin:</p>
<p><code>pip install pipwin</code></p>
</li>
<li><p>Install sklearn using pipwin:</p>
<p><code>pipwin install scikit-learn</code></p>
</li>
</ol>
","2023-05-18 20:32:20","0","Answer"
"76257299","76252700","","<p>Based on my comment about skipping <code>sigmoid</code> when using <code>logitbinarycrossentropy</code>, I had a quick go at testing this for some scrap data, and with your current implementation I also ended up at 0.5 ish loss, while after removing the <code>sigmoid</code> I reached much lower values.</p>
<p>You can also choose to keep the <code>sigmoid</code> and use <code>binarycrossentropy</code> instead, though it seems that is not as numerically stable so it is better to do it with <code>logitbinarycrossentropy</code>.</p>
","2023-05-15 19:12:45","1","Answer"
"76252700","","Same model performs very diferent in Keras and Flux","<p>In a class I'm taking, the professor gave us two datasets, one of 301 late-type galaxies and the other one of 301 early-type galaxies, and we build a model in Keras so it can differentiate them:</p>
<pre><code>input_img = Input(shape=(128,128,3))

x = Conv2D(filters = 16, kernel_size= (3,3), strides = (1,1), activation='relu', padding = 'same')(input_img)
x = MaxPooling2D((2,2),padding = 'same')(x)

x = Conv2D(filters = 32, kernel_size= (3,3), strides = (1,1), activation='relu', padding = 'same')(x)
x = MaxPooling2D((2,2),padding = 'same')(x)

x = Conv2D(filters = 64, kernel_size= (3,3), strides = (1,1), activation='relu', padding = 'same')(x)
x = MaxPooling2D((2,2),padding = 'same')(x)

x = Flatten()(x)
x = Dense(32, activation = 'relu')(x)
x = Dropout(0.3)(x)
x = Dense(16, activation = 'relu')(x)
out = Dense(1, activation = 'sigmoid')(x)

model = Model(inputs = input_img, outputs = out)
model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
history = model.fit(X_train, Y_train, batch_size = 32, epochs = 20)
</code></pre>
<p>Since I like Julia more than Python, I tried to build the same model in Flux.jl and according to what I read in the Flux Docs this is what the Flux model looks like:</p>
<pre><code>model2 = Chain(            
    Conv((3, 3), 3 =&gt; 16, relu, pad=SamePad(), stride=(1, 1)),
    MaxPool((2,2), pad=SamePad()),
    Conv((3, 3), 16 =&gt; 32, relu, pad=SamePad(), stride=(1, 1)),
    MaxPool((2,2), pad=SamePad()),
    Conv((3, 3), 32 =&gt; 64, relu, pad=SamePad(), stride=(1, 1)),
    MaxPool((2,2), pad=SamePad()),
    Flux.flatten,
    Dense(16384 =&gt; 32, relu),
    Dense(32 =&gt; 16, relu),

    Dense(16 =&gt; 1),
    sigmoid
)
</code></pre>
<p>But when I train the models in what I think are the same conditions, I get very different results. In Keras the final lost after 20 Epochs is <code>loss: 0.0267</code> and in Flux after 30 Epochs the loss is <code>0.4082335f0</code>, so I don't know where this difference in loss could come from since I'm using the same batch size in both models and the data treatment is the same (I think).
Python:</p>
<pre><code>X1 = np.load('/home/luis/Descargas/cosmo-late.npy')
X2 = np.load('/home/luis/Descargas/cosmo-early.npy')
X = np.concatenate((X1,X2), axis = 0).astype(np.float32)/256.0
Y = np.zeros(X.shape[0])
Y[0:len(X1)] = 1
rand_ind = np.arange(0,X.shape[0])
np.random.shuffle(rand_ind)
X = X[rand_ind]
Y = Y[rand_ind]
X_train = X[50:]
Y_train = Y[50:]
X_test = X[0:50]
Y_test = Y[0:50]
</code></pre>
<p>Julia:</p>
<pre><code>X1 = npzread(&quot;./Descargas/cosmo-late.npy&quot;)
X2 = npzread(&quot;./Descargas/cosmo-early.npy&quot;)
X = cat(X1,X2,dims=1)
X = Float32.(X)./256
Y = zeros(1,size(X)[1])
Y[1,1:length(X1[:,1,1,1])] .= 1
ind = collect(1:length(Y[1,:]))
shuffle!(ind)
X = X[ind,:,:,:]
Y = Y[:,ind]
X_train = X[51:length(X[:,1,1,1]),:,:,:]
Y_train = Y[:,51:length(Y)]
X_test = X[1:50,:,:,:]
Y_test = Y[:,1:50]
X_train = permutedims(X_train, (2, 3, 4, 1))
X_test = permutedims(X_test, (2, 3, 4, 1))
</code></pre>
<p>And the training in Julia goes:</p>
<pre><code>train_set = Flux.DataLoader((X_train, Y_train), batchsize=32)
loss(x, y) = Flux.logitbinarycrossentropy(x, y)
opt = Flux.setup(Adam(), model2)
loss_history = Float32[]

for epoch = 1:30
    Flux.train!(model2, train_set, opt) do m,x,y
        err = loss(m(x), y)
        ChainRules.ignore_derivatives() do
            push!(loss_history, err)
        end
        return err
    end
end
</code></pre>
<p>Can anyone pls help me, I can't figure it out.</p>
","2023-05-15 09:31:06","0","Question"
"76248695","","d2l package installation on google colab","<p>I need to intall d2l package with</p>
<pre><code>pip install d2l==1.0.0b0
</code></pre>
<p>However, whenever I try to download it to google colab, the following error occurs:</p>
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting d2l==1.0.0-beta0
  Using cached d2l-1.0.0b0-py3-none-any.whl (141 kB)
Collecting jupyter (from d2l==1.0.0-beta0)
  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0-beta0) (1.22.4)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0-beta0) (3.7.1)
Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0-beta0) (0.1.6)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0-beta0) (2.27.1)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0-beta0) (1.5.3)
Collecting gym==0.21.0 (from d2l==1.0.0-beta0)
  Using cached gym-0.21.0.tar.gz (1.5 MB)
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─&gt; See above for output.
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  Preparing metadata (setup.py) ... error
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─&gt; See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</code></pre>
<p>How can I install d2l package on google colab?</p>
","2023-05-14 16:59:35","1","Question"
"76248362","76248184","","<p>I cannot test this as I do not have the dataset for your network, but from the docs:</p>
<blockquote>
<p>objective: A string, keras_tuner.Objective instance, or a list of keras_tuner.Objectives and strings. If a string, the direction of the optimization (min or max) will be inferred. If a list of keras_tuner.Objective, we will minimize the sum of all the objectives to minimize subtracting the sum of all the objectives to maximize. The objective argument is optional when Tuner.run_trial() or HyperModel.fit() returns a single float as the objective to minimize.</p>
</blockquote>
<p>It looks like there is built-in support for more than one metric. It is unclear how to define complexity, one example can be <code>math.log(num_layers) * math.log(num_parameters)</code> or another example can be the time needed to run inference over a large batch of random data (maybe averaged over multiple trials). I suggest the following (untested) code, that will probably help you  towards a correct and satisfying implementation.</p>
<pre><code>import math
import keras_tuner as kt


# Define the composite objective function to be used in model_builder
def composite_objective(hp):
    global val_dataset
    global train_dataset
    global test_dataset
    
    # Define the model architecture
    model = keras.Sequential([
        # ... Define your model layers here ...
    ])
    
    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])
    
    # Compile the model with the specified learning rate
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
        loss='mean_absolute_error',
        metrics=['accuracy']
    )
    
    # Calculate the model complexity
    num_layers = len(model.layers)
    num_parameters = model.count_params()
    complexity = - (math.log(num_layers) * math.log(num_parameters))  
    # Adjust this formula as per your preference, complexity should be low, so negative sign in front
    
    return {'accuracy': model.evaluate(...), 'complexity': complexity}

# Define the tuner with the custom objective
tuner = kt.Hyperband(
    composite_objective,
    max_epochs=10,
    overwrite=True,
    directory='my_dir30',
    project_name='intro_to_kt30'
)

# Rest of your code...
</code></pre>
<p>You can multiply the performance metric by a constant to regulate the tradeoff towards accuracy or efficiency.</p>
","2023-05-14 15:48:23","0","Answer"
"76248184","","Keras tuning that prefers faster models?","<p>I'm trying to tune hyperparameters to get a sense of what values are best in tensorflow keras models. I'm going to use the best model in a minimax algorithm, so speed of evaluation is important due to the amount of estimations for the algorithm. Also, the speed of tuning is made much longer by evaluating models that I can see are barely adding accuracy but take much longer to fit.</p>
<p>In short, some of the models kt.Hyperband spits out have marginally higher accuracy but take much more time to fit and predict. Is there a way to value accuracy while preferring simpler, faster models?</p>
<p>Here is my current code:</p>
<pre><code>!pip install -q -U keras-tuner
import keras_tuner as kt

def model_builder(hp):
    global val_dataset
    global train_dataset
    global test_dataset
    model = keras.Sequential([
        tf.keras.layers.Conv2D(hp.Int('conv1filter', min_value=32, max_value=512*3, step=512/2),
                               hp.Int('conv1kernal', min_value=2, max_value=20, step=2), 
                               padding=&quot;same&quot;, 
                               activation=&quot;relu&quot;, 
                               input_shape=(14,8,8)),
        tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-05),
        tf.keras.layers.Conv2D(hp.Int('conv2filter', min_value=32, max_value=512*3, step=512/2),
                               hp.Int('conv2kernal', min_value=2, max_value=20, step=2), 
                               padding=&quot;same&quot;, 
                               activation=&quot;relu&quot;),
        tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-05),
        layers.Flatten(),
        tf.keras.layers.Dense(hp.Int('dense1', min_value=32, max_value=512, step=32), activation='relu'),
        tf.keras.layers.Dense(hp.Int('dense2', min_value=32, max_value=512, step=32),  activation='relu'),
        tf.keras.layers.Dense(hp.Int('dense3', min_value=32, max_value=512, step=32), activation='relu'),
        tf.keras.layers.Dense(1, activation='tanh'),

  ])
    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
                loss='mean_absolute_error',
                metrics=['accuracy'])

    return model

tuner = kt.Hyperband(model_builder,
                     objective='val_accuracy',
                     max_epochs=10,
                     overwrite=True,
                     directory='my_dir30',
                     project_name='intro_to_kt30')
stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)
tuner.search(x_train, y_train,validation_data = (x_val, y_val), epochs=50, callbacks=[stop_early])

# Get the optimal hyperparameters
best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]

model = tuner.hypermodel.build(best_hps)
# Build the model with the optimal hyperparameters and train it on the data for 50 epochs
history = model.fit(x_train, y_train,validation_data = (x_val, y_val), epochs=50)

val_acc_per_epoch = history.history['val_accuracy']
best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1
hypermodel = tuner.hypermodel.build(best_hps)

# Retrain the model
hypermodel.fit(x_train, y_train,validation_data = (x_val, y_val), epochs=best_epoch)
eval_result = hypermodel.evaluate(x_test, y_test)
print(&quot;[test loss, test accuracy]:&quot;, eval_result)
hypermodel.save('/notebooks/saved_model/my_model')
</code></pre>
","2023-05-14 15:07:49","1","Question"
"76247934","76246837","","<p>Instead of making a list of columns beforehand you can use scikit-learn's <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_selector.html#sklearn.compose.make_column_selector"" rel=""nofollow noreferrer""><code>make_column_selector</code></a> to dynamically specify the columns that each transformer will be applied to.</p>
<p>In your example:</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.compose import make_column_selector as selector

preprocessor = ColumnTransformer([
    ('num_pipeline', num_pipeline, selector(dtype_exclude=object)),
    ('cat_pipeline', cat_pipeline, selector(dtype_include=object))
])

</code></pre>
<p>Under the hood it uses pandas' <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"" rel=""nofollow noreferrer""><code>select_dtypes</code></a> for the type selection. You can pass a regex and select based on column name as well.</p>
<p>I also recommend you checking out <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html#sklearn.compose.make_column_transformer"" rel=""nofollow noreferrer""><code>make_column_transformer</code></a> for more control over the pipeline.</p>
","2023-05-14 14:16:41","3","Answer"
"76247802","","Loading a safetensor file in transformers","<p>I have downloaded this <a href=""https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g"" rel=""nofollow noreferrer"">model</a> from huggingface. I am trying to load this model in transformers so I can do inferencing:</p>
<pre><code>from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(&quot;path_to/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g&quot;)

model = AutoModelForCausalLM.from_pretrained(&quot;path_to/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g&quot;)
</code></pre>
<p>But i get the error saying that it expects a .bin or .h5 or .ckpt files but the above has only .safetensors or .pt files</p>
<p>How do i load the model?</p>
","2023-05-14 13:46:18","3","Question"
"76247477","76246837","","<p>the process is OK, as you said the type changes, and on many occasions, you <code>encode</code> the data to use it. To prevent this from happening label columns as <code>categorical</code> and <code>numerical</code> then change their types as you wish; for example use <code>LabelEncoder</code>. in many situations, a missing value makes an <code>integer</code> column into an <code>object</code> making you miserable in reporting results.
so forget about total automation in this field and try methods to get each columns <code>dtype</code> and save them, then give the data to the <code>pipeline</code>.</p>
<pre><code># Define numerical and categorical columns
numerical_cols = ['numerical_col_1', 'numerical_col_2', ...]
categorical_cols = ['categorical_col_1', 'categorical_col_2', ...]

num_pipeline = Pipeline(
    steps=[        ('scaler', StandardScaler())    ]
)

cat_pipeline = Pipeline(
    steps=[        ('onehotencoder', OneHotEncoder(handle_unknown='ignore'))    ]
)

preprocessor = ColumnTransformer([    ('num_pipeline', num_pipeline, numerical_cols),    ('cat_pipeline', cat_pipeline, categorical_cols)])

</code></pre>
<p>With this modification, you can update the <code>numerical_cols</code> and <code>categorical_cols</code> lists whenever you have new data with different columns, and the pipeline will adapt accordingly.</p>
<p>you can always do this methods and methods like this to find each columns <code>dtype</code>.</p>
<pre><code>non_integer_columns = []
new_data = data.dropna()
for col in data.columns:
   try:
      new_data[col] = new_data[col].astype(int)
   except:
     non_integer_columns.append(col)
</code></pre>
","2023-05-14 12:26:22","1","Answer"
"76246837","","How do I drop and change dtype in a Pipeline with sklearn?","<p>I have some scraped data that needs some cleaning. After the cleaning, I want to create a &quot;numerical and categorical pipelines&quot; inside a ColumnTransformer such as:</p>
<pre><code>categorical_cols = df.select_dtypes(include='object').columns
numerical_cols = df.select_dtypes(exclude='object').columns

num_pipeline = Pipeline(
    steps=[
    ('scaler', StandardScaler())
    ]
)

cat_pipeline = Pipeline(
    steps=[
        ('onehotencoder', OneHotEncoder(handle_unknown='ignore'))
    ]
)

preprocessor = ColumnTransformer([
    ('num_pipeline', num_pipeline, numerical_cols),
    ('cat_pipeline', cat_pipeline, categorical_cols)
])
</code></pre>
<p>My idea was to create a transformer <code>class Transformer(BaseEstimator, TransformerMixin):</code> and create a pipeline with it. That transformer would include all the cleaning steps. My problem is that some of the steps change the dtype from object to integer mostly so I'm thinking that instead of defining the categorical_cols and numerical_cols with dtypes, instead, do it with column names.</p>
<p>Would that be the correct approach? The idea would be to automate the process so I can train the model with new data every time.</p>
","2023-05-14 09:52:34","3","Question"
"76245414","76244904","","<p>The following might prove useful.</p>
<pre><code>WITH classes AS (SELECT my_data.predict_value AS class
                   FROM my_data
                 UNION
                 SELECT my_data.real_value AS class
                   FROM my_data),
     t AS (SELECT c.class,
                  COUNT(*) FILTER (WHERE c.class = d.predict_value)                                              AS SUPPORT,
                  (COUNT(*) FILTER (WHERE c.class = d.predict_value AND d.predict_value = d.real_value))::float  AS tp,
                  (COUNT(*) FILTER (WHERE c.class = d.predict_value AND d.predict_value &lt;&gt; d.real_value))::float AS fp,
                  (COUNT(*) FILTER (WHERE c.class &lt;&gt; d.predict_value AND c.class &lt;&gt; d.real_value))::float        AS tn,
                  (COUNT(*) FILTER (WHERE c.class &lt;&gt; d.predict_value AND c.class = d.real_value))::float         AS fn
             FROM classes c
               CROSS JOIN my_data d
             GROUP BY c.class),
     pr AS (SELECT t.class::text                                               AS class,
                   CASE t.support WHEN 0 THEN NULL ELSE t.tp / t.support END   AS precision,
                   CASE t.support WHEN 0 THEN NULL ELSE tp / (t.tp + t.fn) END AS recall,
                   t.support
              FROM t
            UNION ALL
            SELECT 'Accuracy'                          AS class,
                   SUM(t.tp) / SUM(t.support)          AS precision,
                   SUM(t.tp) / (SUM(t.tp) + SUM(t.fn)) AS recall,
                   SUM(t.support)                      AS support
              FROM t)
SELECT pr.class,
       pr.precision,
       pr.recall,
       2 * pr.precision * pr.recall / (pr.precision + pr.recall) AS &quot;f1-score&quot;,
       pr.support
  FROM pr
  ORDER BY pr.class;
</code></pre>
<p>This query works for any positive number of classes, not just binary classification.</p>
","2023-05-14 00:55:50","2","Answer"
"76245028","76244904","","<p>I have next ugly sql as soltion</p>
<pre><code>with _tmp as (select 'accuracy' as class,
                     null       as pricission,
                     null       as recall,
                     count(*)   as support
              from my_data
              UNION
              select 'True'                                                          as class,
                     (count(*) filter ( where predict_value = True and real_value = True ))::float
                         /
                     (count(*) filter ( where predict_value = True))::numeric(12, 6) as pricission,
                     (count(*) filter ( where predict_value = True and real_value = True ))::float
                         /
                     (
                                     count(*) filter ( where predict_value = FALSE and real_value = True)
                             +
                                     count(*) filter ( where predict_value = True and real_value = True )
                         )::float                                                    as recall,
                     null                                                            as f1_score,
                     count(*) filter ( where predict_value = True)                   as support
              from my_data
              Union
              select 'False'                                                          as class,
                     (count(*) filter ( where predict_value = FALSE and real_value = FALSE ))::float
                         /
                     (count(*) filter ( where predict_value = FALSE))::numeric(12, 6) as pricission,
                     (count(*) filter ( where predict_value = FALSE and real_value = FALSE ))::float
                         /
                     (
                                     count(*) filter ( where predict_value = True and real_value = FALSE)
                             +
                                     count(*) filter ( where predict_value = FALSE and real_value = FALSE )
                         )::float                                                     as recall,
                     null                                                             as f1_score,
                     count(*) filter ( where fixed_predict = FALSE)                   as support
              from my_data)
select &quot;class&quot;,
       pricission::numeric(12, 3),
       recall::numeric(12, 3),
       (2 * pricission * recall / (pricission + recall))::numeric(12, 3) as f1_score,
       support
from _tmp
order by support
</code></pre>
","2023-05-13 21:52:13","1","Answer"
"76244904","","How to count classification_report ( precision recall f1-score support) in sql","<p>I have table with classification result of binary classification.</p>
<p>something like</p>
<pre><code>id, predict_value, real_value
1,  true, true
2,  true, false
...
</code></pre>
<p>I want to get with sql classification_report, something like</p>
<pre><code>   class   precision    recall  f1-score   support

   False       0.97      1.00      0.98     57241
    True       0.68      0.22      0.33      2323
accuracy       NULL      NULL      0.97     59564
</code></pre>
<p>Can you help me with sql query ?</p>
","2023-05-13 21:14:05","-1","Question"
"76241847","76237951","","<p>Did you try</p>
<pre><code>pip install altair
</code></pre>
","2023-05-13 08:45:12","1","Answer"
"76237951","","I made a model using Jupyter Notebook and then I am trying to deploy the model using streamlit but it is showing ModuleNotFoundError","<p>I created a model and deployed using streamlit. I am running in a virtual environement and inspite of running pip install streamlit it is still not working. The following error is shown</p>
<p><a href=""https://i.sstatic.net/FC9pS.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>The error that is shown is this</p>
<pre><code>Traceback (most recent call last):
  File &quot;C:\Python39\lib\runpy.py&quot;, line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File &quot;C:\Python39\lib\runpy.py&quot;, line 87, in _run_code
    exec(code, run_globals)
  File &quot;D:\Machine Learning\sms-spam-classifier\venv\Scripts\streamlit.exe\__main__.py&quot;, line 4, in &lt;module&gt;
  File &quot;d:\machine learning\sms-spam-classifier\venv\lib\site-packages\streamlit\__init__.py&quot;, line 70, in &lt;module&gt;
    from streamlit.delta_generator import DeltaGenerator as _DeltaGenerator
  File &quot;d:\machine learning\sms-spam-classifier\venv\lib\site-packages\streamlit\delta_generator.py&quot;, line 90, in &lt;module&gt;
    from streamlit.elements.arrow_altair import ArrowAltairMixin
  File &quot;d:\machine learning\sms-spam-classifier\venv\lib\site-packages\streamlit\elements\arrow_altair.py&quot;, line 35, in &lt;module&gt;
    from altair.vegalite.v4.api import Chart
ModuleNotFoundError: No module named 'altair.vegalite.v4'
PS D:\Machine Learning\sms-spam-classifier&gt; 
</code></pre>
","2023-05-12 15:43:05","3","Question"
"76224891","76223977","","<ol>
<li>Instead of subtracting 3 from the image, you can directly check for the presence of any pixel with a value of 3 using numpy.</li>
<li>Use the <code>numpy.all()</code> function along with logical indexing to check if all pixels in the image have a value of 3. If all pixels are 3, then consider the image as black and delete it.</li>
</ol>
<pre class=""lang-py prettyprint-override""><code>import os
import cv2
import numpy as np
from sklearn.feature_extraction import image

def generate_patches(input_dir, output_dir):
    # Define the patch size and stride
    patch_size = 448
    stride = 224

    # Loop over all files in the input directory
    for filename in os.listdir(input_dir):
        # Check if the file is an image
        if not filename.endswith('.JPG') and not filename.endswith('.png') and not filename.endswith('.jpeg'):
            continue

        # Load the input image using cv2
        input_image = cv2.imread(os.path.join(input_dir, filename), cv2.IMREAD_GRAYSCALE)

        # Check if all pixels have a value of 3
        if np.all(input_image == 3):
            # If all pixels are 3, delete the image
            os.remove(os.path.join(input_dir, filename))
            continue

        # Get the dimensions of the input image
        height, width = input_image.shape

        # Calculate the number of patches in each dimension
        num_rows = (height - patch_size) // stride + 1
        num_cols = (width - patch_size) // stride + 1

        # Generate patches from the input image using sklearn.feature_extraction.image.extract_patches_2d
        patches = image.extract_patches_2d(input_image, (patch_size, patch_size), max_patches=num_rows * num_cols)

        # Reshape patches into a 2D array
        patches = patches.reshape(-1, patch_size, patch_size)

        # Loop over all patches and save them to the output directory
        for i, patch in enumerate(patches):
            patch_filename = os.path.splitext(filename)[0] + '_{}.jpg'.format(i)
            output = os.path.join(output_dir, patch_filename)
            cv2.imwrite(output, patch)

            # Check if all pixels in the patch are black (value 0)
            if np.all(patch == 0):
                # If the patch is empty, delete it
                os.remove(output)
</code></pre>
","2023-05-11 07:00:33","0","Answer"
"76224835","76223977","","<p>Addressing the overflow: e.g. .png images are usually stored in uint8, meaning that you have values ranging from 0 to 2**8-1 (255). If the image is grayscale, you just have one color dimension, if the image is RGB, then you have three channels (R, G, B).</p>
<p>Now if you subtract 3 from values that are smaller than 3, you are causing an overflow as unsigned datatypes cannot contain negative values.</p>
<p>One naive approach would be to simply check if the array contains values other than 3.</p>
<p>Consider the following example:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np

arr = np.ones((512, 512)) * 3

if len(arr[arr != 3]) == 0:
    print('Image is empty!')
</code></pre>
<p>Small hint: You should probably consider checking if the image is empty first prior to storing, otherwise you are just writing and deleting the same images. By conditionally saving them if they are not considered 'empty', you are eliminate overhead and make the overarching logic cleaner.</p>
","2023-05-11 06:50:26","0","Answer"
"76223977","","How can I delete all images that have a constant pixel value greater than 0?","<p>I am trying to generate patches of an image for a machine learning piepline and the base value of the essentially black patch is 3 for some reason. As a result, I am struggling to figure out a way to delete an image if it has a constant pixel value of 3, <strong>while also maintaining the correct pixel values of the non-black images.</strong></p>
<p>So far, my solution is to use simple pixel algebra and subtract 3 from the image. Then use the cv2.countNonZeroes() to delete the images. The issue arises when the images that contain actual important values have pixel values lower than 3 and it overflows into white. (Don't ask me why the important sections have values lower than 3, I have no clue haha!).</p>
<p><strong>How can I find find and delete the images that contain the constant value 3 while also maintaining the integrity/value of non-black (px!=3) images?</strong></p>
<p>I would also greatly appreciate any input on the re-reading in the countNonZero stage, the performance is already pretty bad, that just puts the cherry on top...</p>
<pre><code>def generate_patches(input_dir, output_dir):
    # Define the patch size and stride
    patch_size = 448
    stride = 224

    # Loop over all files in the input directory
    for filename in os.listdir(input_dir):
    # Check if the file is an image
        if not filename.endswith('.JPG') and not filename.endswith('.png') and not filename.endswith('.jpeg'):
            continue

        # Load the input image using cv2
        input_image = cv2.imread(os.path.join(input_dir, filename), cv2.IMREAD_GRAYSCALE)

        ######## My Attempt ########
        input_image = input_image - 3
        ########            ########

        # Get the dimensions of the input image
        height, width = input_image.shape

        # Calculate the number of patches in each dimension
        num_rows = (height - patch_size) // stride + 1
        num_cols = (width - patch_size) // stride + 1

        # Generate patches from the input image using sklearn.feature_extraction.image.extract_patches_2d
        patches = extract_patches_2d(input_image, (patch_size, patch_size), max_patches = num_rows * num_cols)
    
        # Reshape patches into a 2D array
        patches = patches.reshape(-1, patch_size, patch_size)

        # Loop over all patches and save them to the output directory
        for i, patch in enumerate(patches):
            patch_filename = os.path.splitext(filename)[0] + '_{}.jpg'.format(i)

            # If the image is not empty
            output = os.path.join(output_dir, patch_filename)
            cv2.imwrite(output, patch)

            ######### Here as well ##########

            input_image = cv2.imread(output, cv2.IMREAD_GRAYSCALE)

            # Check if all pixels in the image are black (value 0)
            if cv2.countNonZero(input_image) == 0:
                # If the image is empty, delete it
                os.remove(output)
</code></pre>
","2023-05-11 03:33:13","0","Question"
"76221711","75814047","","<p>I used one of following python scripts (e.g. run_clm.py) where trainer.train() is in there:
<a href=""https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling"" rel=""nofollow noreferrer"">https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling</a></p>
<p>Make a finetune.sh bash file, execute a python script inside</p>
<pre><code>#!/bin/bash
export LD_LIBRARY_PATH=/home/miniconda3/envs/HF/lib/python3.7/.../nvidia/cublas/lib/:$LD_LIB
export CUDA_VISIBLE_DEVICES=0,1  # will use two GPUs
###############################
python run_clm.py --options...
</code></pre>
<p>Then run it via bash, it'll run over the two GPUs as defined.</p>
<pre><code>$ nohup ./finetune.sh &amp; 
</code></pre>
<p>If you want to run over all available 8 GPUs,<br />
simply comment the following line</p>
<pre><code>#export CUDA_VISIBLE_DEVICES=0,1 # will use all GPUs
</code></pre>
","2023-05-10 18:48:21","4","Answer"
"76221120","75194136","","<p>Try this....</p>
<p>inputs = (47.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
0.,   0.,   0.,   0.,   0.,   2.,  49.,   2.,  55.,   0.,   0.,
0.,   1)</p>
<p>input_data_as_numpy_array = np.asarray(inputs)</p>
<p>input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)</p>
<p>prediction = xgb_model.predict(input_data_reshaped)</p>
","2023-05-10 17:24:58","0","Answer"
"76214174","76173111","","<pre><code> for name, parameter in yournetwork.named_parameters():
     if 'key' in name:
         parameter.requires_grad = False
</code></pre>
<p>You can change the 'key' into the parametes you want to fix and this operation will freezes the weights of the layer you chose.</p>
","2023-05-10 00:31:41","0","Answer"
"76211444","76185139","","<p>Thanks for the help.  Davide's comment helped me recognize that I didn't understand the task perfectly.  I was able to figure out a working solution.</p>
<pre><code>def naivebayesPXY(X,Y):
&quot;&quot;&quot;
naivebayesPXY(X, Y) returns [posprob,negprob]

Input:
    X : n input vectors of d dimensions (nxd)
    Y : n labels (-1 or +1) (n)

Output:
    posprob: probability vector of p(x_alpha = 1|y=1)  (d)
    negprob: probability vector of p(x_alpha = 1|y=-1) (d)
&quot;&quot;&quot;

## The next three lines were provided by the challenge. 
n, d = X.shape
X = np.concatenate([X, np.ones((2,d)), np.zeros((2,d))])
Y = np.concatenate([Y, [-1,1,-1,1]])

# Separate data by gender
X_boys = X[Y == 1]
X_girls = X[Y == -1]

## Count total hot(1)counts for each feature for the boys class
boys_ones = X_boys.sum(axis=0)
## Count total not(0)counts for each feature for the boys class
boys_zeroes = X_boys.shape[0] - boys_ones
## Divide hot count for boys by total features
pos_prob = boys_ones / (boys_ones + boys_zeroes)

## Same process from above, for the girls class
girls_ones = X_girls.sum(axis=0)
girls_zeroes = X_girls.shape[0] - girls_ones
neg_prob = girls_ones / (girls_ones + girls_zeroes)

return pos_prob, neg_prob
</code></pre>
","2023-05-09 16:13:40","0","Answer"
"76210758","76204705","","<p>As the manual page for <code>boot()</code> explains:</p>
<blockquote>
<p>For most of the boot methods the resampling is done in the master process, but not if <code>simple = TRUE</code> nor <code>sim = &quot;parametric&quot;</code>.</p>
</blockquote>
<p>As you are not doing parametric bootstrapping and you don't need to specify <code>simple = TRUE</code>, the code displayed when you type <code>boot::boot</code> at the R prompt  shows how the resampled data indices are generated. The critical code is:</p>
<pre><code>if (!simple) 
            i &lt;- index.array(n, R, sim, strata, m, L, weights)
</code></pre>
<p>where <code>n</code> is the number of data rows, <code>R</code> is the number of bootstrap samples, and the other arguments are defined in the call to <code>boot()</code> and don't seem to apply to your situation. Typing <code>boot:::index.array</code> shows the code for that function, which in turn calls <code>boot:::ordinary.array</code> for your situation. In your situation, <code>i</code> is just a matrix showing which data rows to use for each bootstrap sample.</p>
<p>It should be reasonably straightforward to tweak the code for <code>boot()</code> to return that matrix of indices along with the other values the function normally returns.</p>
<p>An alternative might be to return <code>indices</code> directly in your <code>lasso_Select()</code> function, although I'm not sure how well the <code>boot()</code> function would handle that.</p>
","2023-05-09 15:03:03","1","Answer"
"76204705","","Feature Selection Using Bootstrap Resampling, LASSO and Stepwise Regression","<p>In <a href=""https://pubmed.ncbi.nlm.nih.gov/33984349/"" rel=""nofollow noreferrer"">this paper</a>, the authors perform radiomics feature selection for survival prediction by:</p>
<ol>
<li>Bootstrap resampling the dataset x 1000</li>
<li>Fitting cross-validated LASSO models to each the resampled data sets</li>
<li>Retaining the 10 most common features with non-zero coefficients across all 1000 models</li>
<li>Fitting reverse stepwise regression using the ten selected features to the resampled datasets ( the same data sets as generated in step 1)</li>
<li>Choosing the final features based on the most common cox-regression model.</li>
</ol>
<p>I would like to replicate this approach (albiet for logistic regression rather than cox-regression).</p>
<p>I am able to use the following R code to obtain the top K features from the Lasso models using the 'boot' library:</p>
<pre><code>lasso_Select &lt;- function(x, indices){ 
   x &lt;- x[indices,]
   y &lt;- x$Outcome
   x = subset(x, select = -Outcome)
   x2 &lt;- as.matrix(x)
   fit &lt;- glmnet(x2, y , family=&quot;binomial&quot;,alpha=1, standardize=TRUE)
   cv &lt;- cv.glmnet(x2, y, family=&quot;binomial&quot;,alpha=1,  standardize=TRUE)
   fit &lt;- glmnet(x2, y, family=&quot;binomial&quot;,alpha=1, lambda=cv$lambda.min,  standardize=TRUE)
     return(coef(fit)[,1])
   }

myBootstrap &lt;- boot(scaled_train, lasso_Select, R = 1000, parallel = &quot;multicore&quot;, ncpus=5)
</code></pre>
<p>However, I don't believe I can access the individual resampled datasets to then run the multiple logistic regression models and choose the most common.</p>
<p>Any advice on how to approach this?</p>
","2023-05-08 21:06:44","1","Question"
"76193418","76192991","","<p>The score difference is because your using cv, so you should expect a different score as the different splits of your data will produce different scores. The following will help more generally:</p>
<ol>
<li>Change <code>clf.fit(X,Y)</code> to <code>clf.fit(X_train,y_train)</code> to stope leaking data.</li>
<li>Carefully monitor your training and testing scores, and use the differences to check what overfitting, underfitting, leakage etc... is happening.</li>
<li>Think about introducing a third validation set. Split your data into training, validation and holdout (60/20/20 is a sensible default). Train your models on training, tune your parameters by evaluating the model on your validation set. Then, once you are happy with your models performance, do a final test on the holdout set to get a good representation of how your model will perform in production.</li>
<li>Depending on the size of data, and variation within, <code>cv=10</code> could be too high making it less practical.</li>
<li>Consider not using accuracy for multiclass classification.</li>
</ol>
","2023-05-07 10:42:45","1","Answer"
"76193068","76192991","","<p>The fluctuation of test accuracy is not necessarily a problem. Since the best hyperparameters are recommended based on the best CV score, it does not always correspond to the best test set accuracy. In your example, the difference is very minor.</p>
<p>However, there appear to be multiple issues with the code you provided:</p>
<ul>
<li>It seems like your test set is getting leaked into the training procedure.</li>
<li>You are using 1000 iterations, but there are only 2 possible combinations for hyperparameters. Is this just an example?</li>
</ul>
","2023-05-07 09:23:10","1","Answer"
"76192991","","Why does my accuracy score drop after hyperparameter tuning in XGBoost (multiclass model)?","<p>I am trying to tune the multiclass model I've built, but every time I change hyperparameters my accuracy score drops significantly. I'm using RandomizedSearchCV and best_params_ to determine which parameters I need to change. In this specific case best_params_ recommends a learning rate of .29, while dropping the accuracy score from 0.6238 to 0.6192. The code I use to tune the parameters is below:</p>
<pre><code>xgb = XGBClassifier(booster='gbtree', objective='multi:softmax', random_state=42, eval_metric=&quot;auc&quot;, 
                    num_class=num_of_classes, tree_method='gpu_hist', importance_type='gain')

xgb.fit(X_train,y_train)

params={
    &quot;colsample_bytree&quot;:[1],
    &quot;gamma&quot;:[0],
    &quot;learning_rate&quot;:[0.3,0.29], 
    &quot;max_delta_step&quot;:[0], 
    &quot;max_depth&quot;:[6],
    &quot;min_child_weight&quot;:[1],
    &quot;n_jobs&quot;:[12],
    &quot;subsample&quot;:[1]
    }

clf=RandomizedSearchCV(xgb,param_distributions=params,n_iter=1000,scoring='accuracy',cv=10,verbose=3)
clf.fit(X,Y)
</code></pre>
<p>And this is the code for measuring accuracy:</p>
<pre><code>val = clf.predict(X_test)

lb = preprocessing.LabelBinarizer()
lb.fit(y_test)

y_test_lb = lb.transform(y_test)
val_lb = lb.transform(val)

accuracy_score(y_test_lb, val_lb)
</code></pre>
","2023-05-07 09:00:55","0","Question"
"76188493","76109675","","<p>If you want to obtain a realistic &quot;fake&quot; dataset, you could try to train a generative model on your real data.</p>
<p>Assuming you are working with tabular data, there are architectures like CTGAN or TVAE that might be handy.</p>
<p>Some useful links regarding the topic:</p>
<p><a href=""https://towardsdatascience.com/how-to-generate-tabular-data-using-ctgans-9386e45836a6"" rel=""nofollow noreferrer"">https://towardsdatascience.com/how-to-generate-tabular-data-using-ctgans-9386e45836a6</a></p>
<p><a href=""https://sdv.dev/"" rel=""nofollow noreferrer"">https://sdv.dev/</a></p>
","2023-05-06 10:59:14","0","Answer"
"76185425","76185139","","<p>First of all there is confusion in the question since the text says x can be 0 or -1 and y is 0 or -1 but the docstring says x_alpha = 1 and y=1 or y=-1. I'll assume x is 0 or 1 and y is 0 or 1.</p>
<p>You need to compute the probabilities of each feature being 0 or -1 given that y is either 0 or 1. This can be done using maximum likelihood estimation (MLE) by counting the number of times each feature is 0 or -1 for each class and then dividing by the total number of examples in that class.</p>
<p>Here an example for the positive (y=1) class without considering smoothing nor possible division by 0 error:</p>
<pre><code>pos_counts = np.sum(X[Y == 1] == -1, axis=0)
total_pos = np.sum(Y == 1) 
posprob = pos_counts / total_pos
</code></pre>
","2023-05-05 19:36:49","2","Answer"
"76185139","","Using Naive Bayes to calculate X given Y","<p>I am learning the Naïve Bayes Classifier.</p>
<p>I have a matrix of vectors.  Some vectors have the class label 1 (boy), the other vectors have the class label 0 (girl).</p>
<p>There are 128 features in each vector.  Each feature can either be 0 or -1.  I need to determine the probability of each feature being 0 or -1 given that y is either 0 or 1.</p>
<p>I've been provided the starter code below.  The general guidance during the course is to avoid loops.</p>
<p>I've been through all of the provided material numerous times and just can't get how to do this.  I'm not asking for the answer, just some guidance to get me started.</p>
<pre><code>def naivebayesPXY(X,Y):
    &quot;&quot;&quot;
    naivebayesPXY(X, Y) returns [posprob,negprob]
    
    Input:
        X : n input vectors of d dimensions (nxd)
        Y : n labels (-1 or +1) (n)
    
    Output:
        posprob: probability vector of p(x_alpha = 1|y=1)  (d)
        negprob: probability vector of p(x_alpha = 1|y=-1) (d)
    &quot;&quot;&quot;
    
    # add one positive and negative example to avoid division by zero (&quot;plus-one smoothing&quot;)
    n, d = X.shape
    X = np.concatenate([X, np.ones((2,d)), np.zeros((2,d))])
    Y = np.concatenate([Y, [-1,1,-1,1]])
    

    
    return posprob,negprob

</code></pre>
<p>I think I have to sum all the features in the Boy vectors and then divide by ... something.
And sum all the features in the Girl vectors and then divide by ... something.</p>
<p>But everything I try related to this fails the autograding tests.</p>
","2023-05-05 18:49:17","0","Question"
"76184312","76164679","","<p>Use the class instead of the loss's name:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf


# ...

model.compile(
  loss=tf.keras.losses.MeanSquaredError(),
  optimizer='sgd',
  metrics=[metrics.categorical_accuracy]
)

# ...
</code></pre>
<p>Source: <a href=""https://keras.io/api/losses/"" rel=""nofollow noreferrer"">https://keras.io/api/losses/</a></p>
","2023-05-05 16:37:10","0","Answer"
"76178578","76082746","","<p>Based on the lack of code I will get some inspiration from your <a href=""https://github.com/learnables/learn2learn/blob/master/learn2learn/vision/datasets/mini_imagenet.py"" rel=""nofollow noreferrer"">issue #333</a> one year ago. I guess it changed a lot and you are not working on the same thing. Although, I think you kept the basic data structure.</p>
<p>You want to create your <code>MetaDataset</code> based on your QuickDraw dataset. I do not think QuickDraw can be indexed directly by <code>MetaDataset</code> because <code>MetaDataset</code> <a href=""https://github.com/learnables/learn2learn/blob/0b9d3a3d540646307ca5debf8ad9c79ffe975e1c/learn2learn/data/meta_dataset.pyx#L96"" rel=""nofollow noreferrer"">calls each element</a>. If you apply a <strong>data</strong> transform on a bad data format -&gt; you get incompatibility.</p>
<p>Actually, if you look at quickdraw on the repo, the <code>MetaDataset</code> is not instantiate anywhere from it. This is because it does not work: this is your bug.</p>
<p>The problem is the following: how to do the book keeping (indexing) on quickdraw which seems to be very big compared to the other dataset?</p>
<p>I suggest you the following:</p>
<ol>
<li>Perform the book keeping yourself based on the annotations file from the quickdraw repo. Then you can put it has an attribute to your new <code>QuickDraw</code> class. You won't have the (very long) book keeping in <code>MetaDataset</code>. This indexing can be stored in <code>.pkl</code> file so you can do it only once.</li>
<li>Then add a pre-transform only for QuickDraw. Actually, if you really do not want to touch your transform in your class, let's say, I do not know your constraints, you can monkey patch the object, in worst case. But the more reasonable fix would be to insert into your <strong>data</strong> transform a function to convert the <code>np.memmap</code> to <code>PIL</code> or <code>Tensor</code> object.</li>
</ol>
","2023-05-05 03:05:24","0","Answer"
"76173886","76173111","","<p>From <a href=""https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor"" rel=""nofollow noreferrer"">PyTorch example for using a trained CNN as a fixed feature extractor for a single layer perceptron</a>, doing the following :</p>
<pre class=""lang-py prettyprint-override""><code>model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')
for param in model_conv.parameters():
    param.requires_grad = False
</code></pre>
<p>freezes the parameters of <code>model_conv</code>. The example on PyTorch website then proceeds to pass the output of <code>model_conv</code> to a <code>Linear</code> layer which is trained as usual.</p>
<p>According to <a href=""https://pytorch.org/docs/master/notes/autograd.html#setting-requires-grad"" rel=""nofollow noreferrer"">the documentation for the <code>requires_grad</code> parameter</a>, this is the recommended way to freeze parts of your model :</p>
<blockquote>
<p>Setting requires_grad should be the main way you control which parts of the model are part of the gradient computation, for example, if you need to freeze parts of your pretrained model during model fine-tuning.</p>
</blockquote>
<p>By adding an <code>if</code> conditional to the example above, you should be able to freeze only some of the parameters while leaving the other trainable.</p>
","2023-05-04 13:42:44","1","Answer"
"76173400","","ValueError: expected sequence of length 4 at dim 2 (got 0)","<p>I am learning Reinforcement learning, i wrote the following code using cross-entropy algorithm to train cartpole game, <a href=""https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter04/01_cartpole.py"" rel=""nofollow noreferrer"">official source code from book</a></p>
<p>But i am getting the following error :</p>
<pre><code>UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\torch\csrc\utils\tensor_new.cpp:248.)
  obs_t = torch.FloatTensor([obs])

Traceback (most recent call last):
  File &quot;C:\Users\tiklu\OneDrive\Desktop\DRL Resources\codes\basic_rl\cartpole_cross_entropy.py&quot;, line 101, in &lt;module&gt;

    for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):
  File &quot;C:\Users\tiklu\OneDrive\Desktop\DRL Resources\codes\basic_rl\cartpole_cross_entropy.py&quot;, line 43, in iterate_batches
    obs_t = torch.FloatTensor([obs])
ValueError: expected sequence of length 4 at dim 2 (got 0)
</code></pre>
<p>Here is the function causing the error :</p>
<pre><code>def iterate_batches(env,net,batch_size):
    batch = [] #List of episodes
    episode_reward = 0.0
    episode_steps = []
    obs = env.reset()
    sm = nn.Softmax(dim=1)

    while True:
        #this line 
        obs_t = torch.FloatTensor([obs]) 
        # obs_t = obs_t.view(1, -1)  
        action_props_t = sm(net(obs_t)) #net expects a batch of items
        action_props = action_props_t.data.numpy()[0]

        action = np.random.choice(len(action_props),p = action_props)
        next_obs, reward, is_done, _, _ = env.step(action)

        episode_reward += reward
        episode_steps.append(EpisodeStep(observation=obs,action=action))

        if is_done:
            batch.append(Episode(reward=episode_reward,steps=episode_steps))
            episode_steps = []
            episode_reward = 0.0
            next_obs = env.reset()
            if len(batch)==batch_size:
                yield batch
                batch = []
        obs = next_obs
</code></pre>
<p>Here is the requirements.txt, if you want to try</p>
<pre><code>gym==0.26.2
numpy==1.24.3
tensorboardX==2.6
torch==2.0.0
</code></pre>
<p>since the code from book is giving the error, and i don't have much experience with numpy and tensor library. I would really appreciate if you could help.</p>
","2023-05-04 12:50:15","2","Question"
"76173111","","Is it possible to fix some weights for selected neurons during training? If yes? how can I do it?","<p>I have a NN with several layers, but in one of the layers, <strong>I need to vary the weights and biases (w &amp; b) of some neurons</strong> and yet, allow others w &amp; b of other neurons in the same layer to change during the training. I'm using PyTorch.</p>
<p>So let's say that <em>layer n</em> has <strong>X1 + X2 = X</strong> neurons. I need to fix w &amp; b for <strong>X1</strong> neurons and let the others for <strong>X2</strong> neurons change during training.</p>
<p>A simple starter idea would do me well, on how to even go about it!</p>
<p>I have tried to use <code>LocallyConnected1D</code> layers but a visualization of the network depicts something very different from what I need.</p>
","2023-05-04 12:20:00","2","Question"
"76171331","76164038","","<p>The answers given here are correct. There is no built in function for L2 Denormalization in MXNet. However it is easy to simply compute and save these values. Here is my approach in Python:</p>
<pre><code>saved_norm_vals = []
def l2_normalize(row):
    norm = np.linalg.norm(row)
    saved_norm_vals.append(norm)
    if norm == 0:
        return row
    return row / norm


def l2_denormalize(row):
    val = saved_norm_vals.pop(0)
    return row*val
</code></pre>
<p>Both function take in the row of a pandas dataframe. You can use this function by using the .apply method. Keep in mind that you have to strictly contain the order for that to work. Or you always need to clear out the list if there are values you don't want to denormalize.</p>
","2023-05-04 08:57:23","0","Answer"
"76170928","76082746","","<p>try this code out and let me know how it goes</p>
<pre><code>import torch
import torchvision.transforms as transforms
from PIL import Image
from learn2learn.data import QuickDraw

quickdraw = QuickDraw(root='path/to/quickdraw/data', train=True, transform=None)
transform = transforms.Compose([
    transforms.Resize(84),
    transforms.CenterCrop(84),
    transforms.ToTensor(),
])

# Get an example QuickDraw image
img, _ = quickdraw[0]

# Convert to PIL image
img = Image.fromarray(img)

# Apply transform
img = transform(img)

# Add a batch dimension
img = img.unsqueeze(0)

# Display the transformed image
print(img.shape)  # torch.Size([1, 1, 84, 84])
</code></pre>
","2023-05-04 08:08:45","0","Answer"
"76167821","76164038","","<p>Since l2-normalization divides each component <code>x_i</code> in a vector <code>x</code> by the l2-norm of <code>x</code>, that is <code>norm = sqrt(sum(square(x_i)))</code>, you should pre-compute that value, and then multiply by it to get the actual predictions.</p>
<p>Say your normalized vector is <code>x'</code>, you can recover <code>x</code> by multiplying <code>x'</code> by the previously computed <code>norm</code>.</p>
","2023-05-03 20:41:47","1","Answer"
"76167583","76164038","","<p>You can't &quot;denormalize&quot; if you used a function to normalize. Normalization <strong>removes information</strong>, norm of your data  is completely lost. Since you are doing per-instance normalization this means you have to store norm of every single instance manually to reverse the process.</p>
","2023-05-03 19:59:33","1","Answer"
"76166967","75886125","","<p>PyTorch dev here but there's a lot of variables to your question</p>
<ol>
<li>What kind of hardware are you using? speedups will be most dramatic on A100 or A10G GPU</li>
<li>If yes did you enable tensor cores?</li>
<li>Compilation happens during the first batch, what was your batch size? If small then indeed using mode=reduce-overhead would indeed make things faster because it enables CUDA graphs which help reduce the overhead of launching small kernels</li>
<li>You should opt to compile the whole model that you're actually running, in practice we have some utilities to allow or disallow compilation of subgraphs that you can check out here <a href=""https://pytorch.org/docs/master/_dynamo.html"" rel=""noreferrer"">https://pytorch.org/docs/master/_dynamo.html</a></li>
</ol>
","2023-05-03 18:24:31","8","Answer"
"76164679","","No Loss Found In Tensorflow Model Despite Compiling","<p>I'm currently working on TensorFlow 2.9.2 and I can't seem to get the loss function to work. I've tried creating a model with tf.keras.Sequential() and using model.add for the layers and I've also tried creating a function that creates the model. No matter what I do I always get the following error:</p>
<pre><code>ValueError                                Traceback (most recent call last)
Cell In [82], line 23
     17 #inputs = keras.Input(shape=(800,66000))
     18 #outputs = tf.keras.layers.Dense(1, activation='softmax')(inputs)
     19 # If there is a loss passed in `compile`, the regularization
     20 # losses get added to it
     21 model.compile(optimizer=&quot;Adam&quot;, loss=&quot;mse&quot;, metrics=[&quot;mae&quot;])
---&gt; 23 model.fit(train_x, labels, epochs=2, steps_per_epoch=10)
     24 print('My custom loss: ', model.loss_tracker.result().numpy())
     26 #model.summary()
     27 
     28 #loss, accuracy = model.evaluate(test_ds)
     29 #print(&quot;Accuracy&quot;, accuracy)

File /usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
     65 except Exception as e:  # pylint: disable=broad-except
     66   filtered_tb = _process_traceback_frames(e.__traceback__)
---&gt; 67   raise e.with_traceback(filtered_tb) from None
     68 finally:
     69   del filtered_tb

File /tmp/__autograph_generated_filejv83ofjv.py:15, in outer_factory.&lt;locals&gt;.inner_factory.&lt;locals&gt;.tf__train_function(iterator)
     13 try:
     14     do_return = True
---&gt; 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
     16 except:
     17     do_return = False

ValueError: in user code:

    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 1051, in train_function  *
        return step_function(self, iterator)
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 1040, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 1030, in run_step  **
        outputs = model.train_step(data)
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 891, in train_step
        self._validate_target_and_loss(y, loss)
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 857, in _validate_target_and_loss
        raise ValueError(

    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.
</code></pre>
<p>Attempt Number 1:</p>
<pre><code>from keras.layers import Conv2D, MaxPooling2D, Dense
import keras
from keras import losses 
from keras import optimizers 
from keras import metrics 
def create_model(): 
    
    model = tf.keras.Sequential([
    tf.keras.layers.Dense(65000/train.shape[0], input_shape=(65000,)),
    layers.Dense(128, activation='relu'),
    layers.Dense(256, activation='relu'),
    layers.Dense(3,activation='sigmoid'),
    ])
    
    #model.add_loss(tf.keras.losses.MeanSquaredError())


    model.compile(loss = 'mean_squared_error',  optimizer = 'sgd', metrics = [metrics.categorical_accuracy])
    
    return model

model = create_model()
model.fit(train_x, labels, epochs=10)
</code></pre>
<p>Attempt Number 2:</p>
<pre><code>from keras.layers import Conv2D, MaxPooling2D, Dense
import keras
from keras import losses 
from keras import optimizers 
from keras import metrics 
model =tf.keras.Sequential()
model.add(Dense(100, activation='relu'))
model.add(tf.keras.layers.Dense(1, activation='softmax'))
model.compile(optimizer=&quot;Adam&quot;, loss=&quot;mse&quot;, metrics=[&quot;mae&quot;])
model.fit(train_x, labels, epochs=2, steps_per_epoch=10)
print('My custom loss: ', model.loss_tracker.result().numpy())
</code></pre>
<p>Both attempts lead me to the ValueError that no loss is found.</p>
<p>Here are my version information:</p>
<pre><code>tensorflow version 2.9.2
numpy version 1.23.4
pandas version 1.5.0
keras version 2.9.0
python Version:- 3.9.16 (main, Dec  7 2022, 01:11:51) 
[GCC 9.4.0]
</code></pre>
<p>I am running on a paperspace.com Jupyter Notebook. I have tried creating another Notebook on a different graphics card and still no luck.</p>
<p>Output of !jupyter--version:</p>
<pre><code>Selected Jupyter core packages...
IPython          : 8.5.0
ipykernel        : 6.16.0
ipywidgets       : 8.0.2
jupyter_client   : 7.3.4
jupyter_core     : 5.1.5
jupyter_server   : 1.23.5
jupyterlab       : 3.4.6
nbclient         : 0.7.2
nbconvert        : 7.2.9
nbformat         : 5.7.3
notebook         : 6.5.2
qtconsole        : not installed
traitlets        : 5.8.1
</code></pre>
","2023-05-03 13:52:23","0","Question"
"76164038","","How do I denormalize L2-Normalized Data in MXNet?","<p>I normalized my Data with the built in L2Normalization from MXNet ndarray.
Since I want to know the actual value of the prediction I have to denormalize the data to analyze it properly. For normalization I used:</p>
<pre><code>mx.nd.L2Normalization(x, mode='instance')
</code></pre>
<p>It computed me the correct values and I also understand how the calculation works. Now I want to reverse it. Is there a built in method?</p>
<p>My idea would be to swap x and y in the function and to solve for x. However I don't know the sum of the instance nor anything else. So I can't simply do it. Is there a function to denormalize? Or do I have to normalize all by myself? That would sadly make the L2Normalization function useless in many cases.</p>
","2023-05-03 12:51:22","0","Question"
"76155870","76153894","","<p>The problem is due probably to the unbalanced dataset</p>
<p>As you can see the class 1 has only 1 sample (support class 1 = 1).</p>
<p><a href=""https://i.sstatic.net/G1cSW.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/G1cSW.png"" alt=""enter image description here"" /></a></p>
<p>Now, I don't know if the results are of your test set, but to me it seems that to handle this problem it would be better to handle the unbalanced dataset somehow (there are a lot of methods to handle the problem, search on google)</p>
<p>Also, because your dataset is unbalanced, accuracy is not the metric to go. You should use metric more reliable. As start for example you could check the precision and recall singularly for each class to see how the model handle them.</p>
<p>To make this more clear, if your model would predict always the class 0 for every instance, your accuracy would be of almost 100% (you can make a dummy predictor that output always 0 to check this)</p>
<pre><code>105/106 = 0.99
</code></pre>
","2023-05-02 14:21:04","1","Answer"
"76153938","76153894","","<p>My first thought is to make sure your PSO algorithm works properly.</p>
<p>Try replacing your code for PSO with another implementation.</p>
<p>I recommend <a href=""https://pyswarms.readthedocs.io/en/latest/"" rel=""nofollow noreferrer"">PySwarms</a> library.</p>
<hr />
<p>Also, from my experience, most of the time grid search or random search for hyperparameters works okay and is easier to implement. Try using grid or random search and compare the results with PSO.</p>
<p>If there is no improvement, maybe you should focus on using different algorithm (linear model, decision tree, gradient boosting, ...) and/or adding new features. From my experience, careful feature selection beats hyperparameter tuning.</p>
","2023-05-02 10:27:14","1","Answer"
"76153894","","Trying to tune the hyperparameters of SVM using PSO but getting model accuracy very low","<p>I built a classification model using SVM and now trying to tune the parameters of SVM using PSO and PSO with passive congregation, however, the accuracy of the model is way too low. Below is the code and results.</p>
<pre><code>def pso(n_particles, iterations, dimensions, inertia):

# Range of SVR's hyperparameters (Particles' search space)
# C, Epsilon and Gamma
max_c = 1e4
min_c = 1e-3
max_e = 1e-1
min_e = 1e-8
max_g = 1e3
min_g = 1e-3

# Initializing particles' positions randomly, inside
# the search space
x = np.random.rand(n_particles, 1)*(max_c - min_c) + min_c
#y = np.random.rand(n_particles, 1)*(max_e - min_e) + min_e
z = np.random.rand(n_particles, 1)*(max_g - min_g) + min_g
c = np.concatenate((x,z), axis=1)

# Initializing particles' parameters
v = np.zeros((n_particles, dimensions))
c1 = 1
c2 = 1
c3 = 2
p_best = np.zeros((n_particles, dimensions))
p_best_val = np.zeros(n_particles) + sys.maxsize  
g_best = np.zeros(dimensions)
g_best_val = sys.maxsize
best_iter = np.zeros(iterations)
R = np.random.rand(n_particles)

# Initializing regression variables
p_best_RGS = np.empty((n_particles), dtype = object);
g_best_RGS = sys.maxsize

 from sklearn.metrics import mean_squared_error, accuracy_score, hamming_loss, f1_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for i in range(iterations):
    for j in range(n_particles):
      # Starting Regression
      clf = svm.SVC(kernel = 'rbf', C = c[j][0], gamma = c[j][1])
      #rgs1 = svm.SVC(C = c[j][0], gamma = c[j][2])
    
      # Fitting the curve
      clf.fit(x_train, y_train)
      y_predict = clf.predict(x_test)
      #print(y_predict)
      #y_pred= sc.fit_transform(y_predict)
      #print(y_pred)
      # Using Mean Squared Error to verify prediction accuracy
      #print(Y_test)
      mse = roc_auc_score(y_test, y_predict) 
      
      
      # If mse value for that search point, for that particle,
      # is less than its personal best point,
      # replace personal best
      if(mse &lt; p_best_val[j]):   # mse &lt; p_best_val[j]
          # The value below represents the current least Mean Squared Error
          p_best_val[j] = mse
          p_best_RGS[j] = clf
          # The value below represents the current search coordinates for
          # the particle's current least Mean Squared Error found
          p_best[j] = c[j].copy()
          
      # Using auxiliar variable to get the index of the
      # particle that found the configuration with the 
      # minimum MSE value
      aux = np.argmin(p_best_val)        
    
      if(p_best_val[aux] &lt; g_best_val):
          # Assigning Particle's current best MSE to the Group's best    
          g_best_val = p_best_val[aux]

          # Assigning Particle's current best configuration to the Group's best
          g_best = p_best[aux].copy()

          # Group best regressor:
          # the combination of C, Epsilon and Gamma
          # that computes the best fitting curve
          g_best_RGS = p_best_RGS[aux]

    
          rand1 = np.random.random()
          rand2 = np.random.random()
          rand3 = np.random.random()

      # The variable below influences directly the particle's velocity.
      # It can either make it smaller or bigger. 
      w = inertia

      # The equation below represents Particle's velocity, which is
      # the rate of change in its position
      #v[j] = w*v[j] + c1*(p_best[j] - c[j])*rand1 + c2*(g_best - c[j])*rand2 + c3*(R[j] - c[j])*rand3
      v[j] = w*v[j] + c1*(p_best[j] - c[j])*rand1 + c2*(g_best - c[j])*rand2 
      # Change in the Particle's position 
      c[j] = c[j] + v[j]

      # Below is a series of conditions that stop the particles from
      # leaving the search space
      if(c[j][1] &lt; min_g):
        c[j][1] = min_g
      if(c[j][1] &gt; max_g):
        c[j][1] = max_g
      #if(c[j][1] &lt; min_e):
        #c[j][1] = min_e
      #if(c[j][1] &gt; max_e):
        #c[j][1] = max_e
      if(c[j][0] &lt; min_c):
        c[j][0] = min_c
      if(c[j][0] &gt; max_c):
        c[j][0] = max_c
        
 
    # The variable below represents the least Mean Squared Error
    # of the current iteration
    best_iter[i] = g_best_val
            
    print('Best value iteration # %d = %f\n'%(i, g_best_val))
</code></pre>
<p>Results
The accuracy is lower than the untuned model and gamma values greater than 1.</p>
<p><strong>Accuracy:</strong></p>
<p><a href=""https://i.sstatic.net/7DsiN.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/7DsiN.png"" alt=""enter image description here"" /></a></p>
<p><strong>Hyperparameters:</strong></p>
<p><a href=""https://i.sstatic.net/n0TxH.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/n0TxH.png"" alt=""enter image description here"" /></a></p>
","2023-05-02 10:19:57","0","Question"
"76153288","75886125","","<p>the default mode of torch.compile does not seem to work, but it has another mode that can really accelerate your model.
&quot;&quot;&quot;
torch.compile(${yourmodel}, mode=&quot;reduce-overhead&quot;)
&quot;&quot;&quot;</p>
","2023-05-02 09:00:36","1","Answer"
"76149743","76149628","","<p>The error is self-explanatory. The problem is that the second argument in</p>
<pre><code>env = gym.make(&quot;MountainCar-v0&quot;, 'rgb_array')
</code></pre>
<p>is a <code>str</code>, but it's expected to be <code>int</code>, so the comparison in the function <code>step</code> defined on line 39 of the <a href=""https://github.com/openai/gym/blob/master/gym/wrappers/time_limit.py"" rel=""nofollow noreferrer"">source code</a> can perform the operation with valid types.</p>
","2023-05-01 19:44:00","1","Answer"
"76149628","","'>=' not supported between instances of 'int' and 'str' when using env.step from gym","<p>I have the following code that I keep getting an error saying <code>'&gt;=' not supported between instances of 'int' and 'str'</code> coming from env.step() from gym. It seems to be the <code>terminated</code> value that is causing the error but I can not see where from:</p>
<pre><code>%matplotlib notebook
import gym
import time
import matplotlib.pyplot as plt
import numpy as np
from IPython.display import clear_output

env = gym.make(&quot;MountainCar-v0&quot;, 'rgb_array')
env.reset()


def create_bins(num_bins_per_observation):
    # CODE HERE
    car_velocity = np.linspace(-0.07, 0.07, num_bins_per_observation)  # based off highest and lowest possible values
    car_position = np.linspace(-1.2, 0.6,
                               num_bins_per_observation)  # run the above loop and see a reasonable range for velocity as it can be -inf - inf

    bins = np.array([car_position, car_velocity])
    return bins

NUM_BINS = 10
BINS = create_bins(NUM_BINS)

def discretize_observation(observations, bins):
    binned_observations = []
    for i,observation in enumerate(observations):
        discretized_observation = np.digitize(observation, bins[i])
        binned_observations.append(discretized_observation)
    return tuple(binned_observations) # Important for later indexing

# CREATE THE Q TABLE
q_table_shape = (NUM_BINS,NUM_BINS,env.action_space.n)
q_table = np.zeros(q_table_shape)


def epsilon_greedy_action_selection(epsilon, q_table, discrete_state):
    if np.random.random() &gt; epsilon:
        action = np.argmax(q_table[discrete_state])
    else:
        action = np.random.randint(0, env.action_space.n)
    return action


def compute_next_q_value(old_q_value, reward, next_optimal_q_value):
    return old_q_value + ALPHA * (reward + GAMMA * next_optimal_q_value - old_q_value)

def reduce_epsilon(epsilon, epoch):
    if BURN_IN &lt;= epoch &lt;= EPSILON_END:
        epsilon -= EPSILON_REDUCE
    return epsilon


EPOCHS = 30000
BURN_IN = 100
epsilon = 1

EPSILON_END= 10000
EPSILON_REDUCE = 0.0001

ALPHA = 0.8
GAMMA = 0.9

log_interval = 100  # How often do we update the plot? (Just for performance reasons)
### Here we set up the routine for the live plotting of the achieved points ######
fig = plt.figure()
ax = fig.add_subplot(111)
plt.ion()
fig.canvas.draw()
##################################################################################

max_position_log = []  # to store all achieved points
mean_positions_log = []  # to store a running mean of the last 30 results
epochs = []  # store the epoch for plotting

for epoch in range(EPOCHS):
    # TODO: Get initial observation and discretize them. Set done to False
    initial_state = env.reset()[0]  # get the initial observation
    discretized_state = discretize_observation(initial_state, BINS)  # map the observation to the bins
    done = False  # to stop current run when the car reaches the top or the time limit is reached

    max_position = -np.inf  # for plotting
    epochs.append(epoch)

    # TODO: As long as current run is alive (i.e not done) perform the following steps:
    while not done:  # Perform current run as long as done is False (as long as there is still time to reach the top)

        # TODO: Select action according to epsilon-greedy strategy
        
        action = epsilon_greedy_action_selection(epsilon, q_table, discretized_state)  # Epsilon-Greedy Action Selection
        
        # TODO: Perform selected action and get next state. Do not forget to discretize it
        
        next_state, reward, done, test, info = env.step(action)  # perform action and get next state
        position, velocity = next_state
        next_state_discretized = discretize_observation(next_state, BINS)  # map the next observation to the bins

        # TODO: Get old Q-value from Q-Table and get next optimal Q-Value
        
        old_q_value = q_table[discretized_state + (action,)]  # get the old Q-Value from the Q-Table
        next_optimal_q_value = np.max(q_table[next_state_discretized])  # Get the next optimal Q-Value

        # TODO: Compute next Q-Value and insert it into the table
        
        next_q = compute_next_q_value(old_q_value, reward, next_optimal_q_value)  # Compute next Q-Value
        q_table[discretized_state + (action,)] = next_q  # Insert next Q-Value into the table

        # TODO: Update the old state with the new one
        discretized_state = next_state_discretized  # Update the old state with the new one

        if position &gt; max_position:  # Only for plotting the results - store the highest point the car is able to reach
            max_position = position

    # TODO: Reduce epsilon
    
    epsilon = reduce_epsilon(epsilon, epoch)  # Reduce epsilon
    
    ##############################################################################

    max_position_log.append(max_position)  # log the highest position the car was able to reach
    running_mean = round(np.mean(max_position_log[-30:]), 2)  # Compute running mean of position over the last 30 epochs
    mean_positions_log.append(running_mean)  # and log it

    ################ Plot the points and running mean ##################
    if epoch % log_interval == 0:
        ax.clear()
        ax.scatter(epochs, max_position_log)
        ax.plot(epochs, max_position_log)
        ax.plot(epochs, mean_positions_log, label=f&quot;Running Mean: {running_mean}&quot;)
        plt.legend()
        fig.canvas.draw()
######################################################################

env.close()


</code></pre>
<p>This is the full error I am receiving too from Jupyter notebook:</p>
<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/var/folders/jn/59brf9ps68b366pxgyt4hpfw0000gn/T/ipykernel_55458/601254501.py in &lt;module&gt;
     29         action = epsilon_greedy_action_selection(epsilon, q_table, discretized_state)  # Epsilon-Greedy Action Selection
     30         # TODO: Perform selected action and get next state. Do not forget to discretize it
---&gt; 31         next_state, reward, done, test, info = env.step(action)  # perform action and get next state
     32         position, velocity = next_state
     33         next_state_discretized = discretize_observation(next_state, BINS)  # map the next observation to the bins

~/anaconda3/envs/ai_env/lib/python3.7/site-packages/gym/wrappers/time_limit.py in step(self, action)
     51         self._elapsed_steps += 1
     52 
---&gt; 53         if self._elapsed_steps &gt;= self._max_episode_steps:
     54             truncated = True
     55 

TypeError: '&gt;=' not supported between instances of 'int' and 'str'
</code></pre>
","2023-05-01 19:26:20","0","Question"
"76147809","76133572","","<p>You could just use <code>tfd.Beta.experimental_fit</code> to get an MLE distribution.</p>
<p>Or you can use <code>tfp.util.make_trainable(tfd.Beta)</code> to get a trainable distribution.</p>
","2023-05-01 14:43:07","0","Answer"
"76145270","76082746","","<p>If you are using <code>torchvision.transforms.ToTensor</code> this is not possible directly, because as stated in the <a href=""https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html"" rel=""nofollow noreferrer"">documentation</a></p>
<blockquote>
<p>this transformation should not be used when transforming target image masks</p>
</blockquote>
<p>check out <a href=""https://github.com/pytorch/vision/blob/main/references/segmentation/transforms.py"" rel=""nofollow noreferrer"">this</a> instead to see the proper way of resizing</p>
<p>And here is an example quoted from this <a href=""https://stackoverflow.com/a/56748776/16930239"">answer</a>:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import torch
&gt;&gt;&gt; np_arr = np.ones((5289, 38))
&gt;&gt;&gt; torch_tensor = torch.from_numpy(np_arr).long()
&gt;&gt;&gt; type(np_arr)
&lt;class 'numpy.ndarray'&gt;
&gt;&gt;&gt; type(torch_tensor)
&lt;class 'torch.Tensor'&gt;
</code></pre>
","2023-05-01 07:09:53","0","Answer"
"76137587","76133572","","<p>You need to constrain the variables to be positive before using them. Otherwise gradient steps may take them negative and give nans. You can just call softplus on them before passing in. You could also check out tfp.util.TransformedVariable. It should have some examples in the docs.</p>
","2023-04-29 17:42:33","1","Answer"
"76136147","76135488","","<p>The issue is that you're re-using the same random key three times, so your random draws are not independent. If you do this instead, you should get the results you expect:</p>
<pre class=""lang-py prettyprint-override""><code>key1, key2, key3 = random.split(key, 3)

X = random.uniform(key1, (n, p - 1))
X = jnp.concatenate([jnp.ones((n, 1)), X], axis=1)
B = random.randint(key2, (p, 1), 0, 10)

epsilon = random.normal(key3, (n, 1))*0.3
</code></pre>
<p>JAX's random number generator is different than <code>numpy</code> and other tools in that it is not stateful, so you must explicitly generate additional keys when creating multiple independent streams. You can read more about this at <a href=""https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#random-numbers"" rel=""nofollow noreferrer"">JAX Sharp Bits: Random Numbers</a>.</p>
<p>If you're curious to read more of the design considerations behind this API, you might start with <a href=""https://jax.readthedocs.io/en/latest/jep/263-prng.html"" rel=""nofollow noreferrer"">JEP 263: JAX PRNG Design</a>.</p>
","2023-04-29 12:07:42","2","Answer"
"76135688","76135488","","<p>I think this might be the cause:
As @slothrop was pointing out, using the same key might yield some correlation. In the source code, you can see that it's basically applying a monotonic transformation to epsilon.</p>
<pre><code>@partial(jit, static_argnums=(1, 2), inline=True)
def _normal_real(key, shape, dtype) -&gt; jnp.ndarray:
  _check_shape(&quot;normal&quot;, shape)
  lo = np.nextafter(np.array(-1., dtype), np.array(0., dtype), dtype=dtype)
  hi = np.array(1., dtype)
  u = uniform(key, shape, dtype, lo, hi)  # type: ignore[arg-type]
  return np.array(np.sqrt(2), dtype) * lax.erf_inv(u)
</code></pre>
<p>The correlation coefficient is almost 1</p>
<pre><code>jnp.corrcoef(X[:,1], epsilon)
</code></pre>
","2023-04-29 10:23:14","0","Answer"
"76135488","","JAX Random generator: random normal numbers, seem to be returned sorted and not completely random","<p>I'm trying to learn <code>jax</code> from 0. I've been trying to do some synthetic linear relationship data, so that</p>
<p>Y = B1*X + B0 + epsilon</p>
<p>My surprise has been that, when using the raw epsilons, the data seems to be ordered, so the points at the extremes get a higher error than the ones at the center. The shuffled version works fine, with errors normally distributed around the linear relationship</p>
<pre><code>import jax.numpy as jnp
from jax import grad, jit, vmap
from jax import random
import matplotlib.pyplot as plt

n = 100
p = 2  # number of parameters including linear bias
key = random.PRNGKey(0)

X = random.uniform(key, (n, p - 1))
X = jnp.concatenate([jnp.ones((n, 1)), X], axis=1)
B = random.randint(key, (p, 1), 0, 10)

epsilon = random.normal(key, (n, 1))*0.3

y = X.dot(B) + epsilon
y_s = X.dot(B) + random.shuffle(key, epsilon)
plt.scatter(X[:,1], y, label='Original order')
plt.scatter(X[:,1], y_s, label='Shuffled')
plt.legend()
</code></pre>
<p><a href=""https://i.sstatic.net/4XaCr.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4XaCr.png"" alt=""enter image description here"" /></a>
Why is this happening?</p>
","2023-04-29 09:32:13","1","Question"
"76135354","76135165","","<p>When someone wants to encode categories (e.g. &quot;apple&quot;, &quot;pineapple&quot;). Then you can set the task as: &quot;Encode categorial features&quot;. For this task we have a huge number of solutions.
Suppose we have the following dataset:</p>
<pre><code>import pandas as pd
data = pd.DataFrame()
data['cat'] = ['BMW', 'Mercedes', 'Nissan']
data
</code></pre>
<p>Output:</p>
<pre><code>    cat
0   BMW
1   Mercedes
2   Nissan
</code></pre>
<p>Let's use BinaryEncoder. This encoder uses less space than One Hot Encoder.</p>
<pre><code>from category_encoders.binary import BinaryEncoder
bn = BinaryEncoder()
bn.fit_transform(data.values)
</code></pre>
<p>Output:</p>
<pre><code>  0_0 0_1
0   0   1
1   1   0
2   1   1
</code></pre>
<p>If you want to use more advanced solutions, take a look at this <a href=""https://contrib.scikit-learn.org/category_encoders/"" rel=""nofollow noreferrer"">framework</a>.</p>
<p>Edit:</p>
<pre><code>But I am unsure about using Label Encoding because the regression may treat the values as numerical.
</code></pre>
<p>It's okay to use Label Encoding for linear regression. Because linear regression &quot;know&quot; difference only between exogenous variables and endogenous variables. And don't &quot;know&quot; difference between categorial and non categorial features. You must use numerical represantation of categorial features. But Label Encoding have a big problem. This method add linear dependence between categorials. Example:</p>
<pre><code>&quot;first&quot;, &quot;second&quot; --&gt; &quot;1&quot;, &quot;2&quot;   
</code></pre>
<p>But &quot;first&quot; not bigger than &quot;second&quot;. So we can get wrong results from linear regression.</p>
","2023-04-29 09:00:55","0","Answer"
"76135222","76135165","","<p>If you have a categorical feature with many unique values, try using <a href=""https://towardsdatascience.com/dealing-with-categorical-variables-by-using-target-encoder-a0f1733a4c69"" rel=""nofollow noreferrer"">target encoding</a></p>
<p>The idea is to calculate average price for each city and then replace city name with that average for each row. This average price will tell your model how attractive this city in general.</p>
<p>One possible implementation is this:</p>
<pre class=""lang-py prettyprint-override""><code>mean_by_city = df.groupby(&quot;city&quot;).agg({&quot;price&quot;: &quot;mean&quot;}).squeeze().to_dict()
df[&quot;city_mean_encoding&quot;] = df[&quot;city&quot;].map(mean_by_city)
</code></pre>
<p>One advice: don't forget to check for rare categories. If your dataset has only few examples of houses in some small town, the mean might not be accurate. In this case I can recommend to add a dummy &quot;Rare&quot; category.</p>
","2023-04-29 08:22:36","2","Answer"
"76135165","","How do I encode location data for linear regression in Python?","<p>I am doing a beginner project to predict house prices. I have one category called 'city' with values such as Boston, Detroit, NY, etc.</p>
<p>If I use One Hot Encoder I will end up with a very huge dataset because there are around 100 unique values. But I am unsure about using Label Encoding because the regression may treat the values as numerical.</p>
<p>I thought that would be plenty explained on the internet as it is a typical exercise but I am unable to find a solution. How do I encode location data?</p>
","2023-04-29 08:05:47","0","Question"
"76133572","","How would I learn parameters of a beta distribution in TensorFlow Probability?","<p>I'm trying to use TensorFlow Probability to learn the alpha and beta parameters of a beta distribution. I can't get it to work for some reason - the loss is all NaN values. Here's what I have:</p>
<pre class=""lang-py prettyprint-override""><code>from scipy.stats import beta
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_probability as tfp
tfd = tfp.distributions

beta_sample_data = beta1 = beta.rvs(5,5,size=1000)
beta_train = tfd.Beta(concentration1=tf.Variable(1.,name='alpha'),concentration0=tf.Variable(1.,name='beta'),name='beta_train')

def nll(x_train,distribution):
    return -tf.reduce_mean(distribution.log_prob(x_train))

# Define a function to compute the loss and gradients
@tf.function
def get_loss_and_grads(x_train,distribution):
    with tf.GradientTape() as tape:
        tape.watch(distribution.trainable_variables)
        loss = nll(x_train, distribution)
        grads = tape.gradient(loss,distribution.trainable_variables)
        
    return loss,grads

def beta_dist_optimisation(data, distribution):

    # Keep results for plotting
    train_loss_results = []
    train_rate_results = []
    
    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)

    num_steps = 10

    for i in range(num_steps):
        loss,grads = get_loss_and_grads(data,distribution)
        print(loss,grads)
        optimizer.apply_gradients(zip(grads,distribution.trainable_variables))
        alpha_value = distribution.concentration1.value()
        beta_value = distribution.concentration0.value()
        train_loss_results.append(loss)
        train_rate_results.append((alpha_value,beta_value))
        
        
        
        print(&quot;Step {:03d}: Loss: {:.3f}: Alpha: {:.3f} Beta: {:.3f}&quot;.format(i,loss,alpha_value,beta_value))
        
    return train_loss_results, train_rate_results


sample_data = tf.cast(beta_sample_data, tf.float32)

train_loss_results, train_rate_results = beta_dist_optimisation(sample_data,beta_train)
</code></pre>
<p>I'm trying to use maximum likelihood to learn the alpha and beta parameters of 5,5.</p>
","2023-04-28 22:12:22","0","Question"
"76126226","75808596","","<p>error message:</p>
<pre><code>'str' object has no attribute '__name__' Invalid Classifier(s)
too many values to unpack (expected 2)
</code></pre>
<p>means we try to call the object. So we need to import the object instead.</p>
<pre><code>from lazypredict.Supervised import LazyClassifier
from sklearn.datasets import load_iris
from sklearn.ensemble._forest import RandomForestClassifier
from sklearn.linear_model._logistic import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.neighbors._classification import KNeighborsClassifier

data = load_iris()
X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Updated Line
clf = LazyClassifier(verbose=0,
                     ignore_warnings=True,
                     custom_metric=None,
                     predictions=True,
                     classifiers=[RandomForestClassifier, LogisticRegression, KNeighborsClassifier])
models, predictions = clf.fit(X_train, X_test, y_train, y_test)
print(models[:3])
</code></pre>
<p>Result:</p>
<pre><code>                        Accuracy  Balanced Accuracy  ... F1 Score  Time Taken
Model                                                ...                     
RandomForestClassifier      0.98               0.98  ...     0.98        0.12
LogisticRegression          0.98               0.98  ...     0.98        0.01
KNeighborsClassifier        0.98               0.98  ...     0.98        0.01
</code></pre>
","2023-04-28 04:18:22","0","Answer"
"76124648","76119596","","<p>In 1.24</p>
<pre><code>In [83]: &gt;&gt;&gt; a = np.array([np.array([1, 2, 3]), 1],object)
    ...: &gt;&gt;&gt; b = np.array([np.array([1, 2, 3]), 1],object)

In [84]: a==b
&lt;ipython-input-84-a6f7ccb4d5ba&gt;:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.
  a==b
Out[84]: False
</code></pre>
","2023-04-27 21:03:31","0","Answer"
"76124050","76117170","","<p>dear friend I become too curios about this problem, so I search for a proper solution :)</p>
<p>I think <a href=""https://stackoverflow.com/questions/69050266/how-to-imply-a-different-loss-function-for-each-batch"">this</a> maybe is what you're looking for. You could change the input tensor in the way it contains the input and the corresponding masks, then in your custom loss function manage to calculate loss properly.</p>
","2023-04-27 19:37:27","0","Answer"
"76123997","76013119","","<p>TPOT is only for searching for pipelines and tuning hyperparameters <strong>at the same time</strong>. If you have a pipeline and you just want to tune the parameters, try hyperopt, optuna, or GridSearchCV.</p>
<p>If you're somewhat flexible on the pipeline and you really want to use TPOT, you could always use a custom configuration like this and then set config_dict=custom_regression_config when calling TPOTRegressor:</p>
<pre><code>custom_regression_config = {

    'xgboost.XGBRegressor': {
        'n_estimators': [100],
        'max_depth': range(1, 11),
        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],
        'subsample': np.arange(0.05, 1.01, 0.05),
        'min_child_weight': range(1, 21),
        'n_jobs': [1],
        'verbosity': [0],
        'objective': ['reg:squarederror']
    },

    'sklearn.linear_model.SGDRegressor': {
        'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],
        'penalty': ['elasticnet'],
        'alpha': [0.0, 0.01, 0.001] ,
        'learning_rate': ['invscaling', 'constant'] ,
        'fit_intercept': [True, False],
        'l1_ratio': [0.25, 0.0, 1.0, 0.75, 0.5],
        'eta0': [0.1, 1.0, 0.01],
        'power_t': [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]
    },

    'tpot.builtins.OneHotEncoder': {
        'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25],
        'sparse': [False],
        'threshold': [10]
    },

    'sklearn.feature_selection.SelectPercentile': {
        'percentile': range(1, 100),
        'score_func': {
            'sklearn.feature_selection.f_regression': None
        }
    }

}
</code></pre>
<p>Be aware however that this would potentially arrive at pipelines where the order and stacking are different. That said, maybe that's a good thing if you let TPOT innovate not only on hyperparameters but also on the exact nature of the pipeline.</p>
","2023-04-27 19:29:02","1","Answer"
"76120600","76119596","","<p>Indeed, the <code>object</code> type seems to be the problem – note that you can even simplify your example as follows (tested with Numpy 1.24.3 on Python 3.10.10):</p>
<pre class=""lang-py prettyprint-override""><code>vgg = vgg16(pretrained=True)
vgg.load_state_dict(torch.load(&quot;vgg16_model.pth&quot;, map_location='cpu'), strict=True)
params_list = [param.detach().numpy() for param in vgg.parameters()]
params1 = np.array(params_list, dtype=object)
params2 = np.array(params_list, dtype=object)
print(np.array_equal(params1, params2))
# &gt;&gt;&gt; False
</code></pre>
<p>That is, even if the elements inside your <code>params1</code> and <code>params2</code> object arrays are <em>identical</em> float arrays (not only <em>equal/equivalent</em> ones), the comparison will return <code>False</code>.</p>
<p>The comparison of Numpy arrays of type <code>object</code> to me seems rather unintuitive and is not very well documented. The only documentation hinting at this behavior that I could find is in some old <a href=""https://numpy.org/doc/1.19/release/1.9.0-notes.html#object-array-equality-comparisons"" rel=""nofollow noreferrer"">Numpy release notes</a>:</p>
<blockquote>
<h5>Object array equality comparisons</h5>
<p>In the future object array comparisons both <em>==</em> and <em>np.equal</em> will not make use of identity checks anymore. For example:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; a = np.array([np.array([1, 2, 3]), 1])
&gt;&gt;&gt; b = np.array([np.array([1, 2, 3]), 1])
&gt;&gt;&gt; a == b
</code></pre>
<p>will consistently return False (and in the future an error) even if the array in <em>a</em> and <em>b</em> was the same object.</p>
</blockquote>
<p>While your observed behavior is described there, the decision as to <em>why</em> this comparison returns <code>False</code> is not really motivated.</p>
<p><em>Bottom line:</em> If you want to have element-wise comparisons of Numpy arrays, maybe don't use the <code>object</code> type. For further reading, maybe also have a look at <a href=""https://stackoverflow.com/questions/52715049/"">this related question</a>.</p>
","2023-04-27 12:46:31","2","Answer"
"76119596","","numpy assert_equals for nested floating point","<p>I got a strange behaviour regarding an equal check for the weights for the vgg16 machine learning model</p>
<p>loading two times the model</p>
<pre><code>import torch
from torch import nn
from torchvision.models import vgg16
import numpy as np
import torchvision.models as models

model = models.vgg16(weights='IMAGENET1K_V1')
torch.save(model.state_dict(), 'vgg16_model.pth')

vgg = vgg16(pretrained=True)
vgg.load_state_dict(torch.load(&quot;vgg16_model.pth&quot;, map_location='cpu'), strict=True)
params1 = np.array([param.detach().numpy() for param in vgg.parameters()], dtype=object)

vgg2 = vgg16(pretrained=True)
vgg2.load_state_dict(torch.load(&quot;vgg16_model.pth&quot;, map_location='cpu'), strict=True)
params2 = np.array([param.detach().numpy() for param in vgg2.parameters()], dtype=object)
</code></pre>
<p>note that I didn't replace any layer, if I do the check with <code>np.assert_equals</code></p>
<pre><code>np.array_equal(params1, params2)
</code></pre>
<p>I got <code>False</code></p>
<p>But if I check the nested arrays iteratively the arrays are equals:</p>
<pre><code>for val1, val2 in zip(params1, params2):
    print(np.array_equal(val1, val2))
</code></pre>
<p>What am I missing? Is it due to the way of how I create the array at the start, as <code>dtype=object</code>?</p>
<pre><code>python version 3.9.13
numpy version 1.21.5
</code></pre>
","2023-04-27 10:59:31","1","Question"
"76118934","75026592","","<p>In most case custom methods 'transform' return numpy arrays. To convert them back to pandas DataFrame you need to extract columns while fitting. After that you need to add method get_feature_names_out, which returns column names. Try to use this code:</p>
<pre><code>from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np

class StandardScalerCustom(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        self.columns_ = X.columns
        self.mean = np.mean(X, axis=0)
        self.std = np.std(X, axis=0)
        return self

    def transform(self, X):
        return (X - self.mean) / self.std
    
    def get_feature_names_out(self, *args, **params):
        return self.columns_
</code></pre>
","2023-04-27 09:40:25","5","Answer"
"76118090","76117170","","<p>For defining a custom loss function you should define a new class with a &quot;call&quot; method which is called when using a loss function for training. you could add as many as needed arguments to it and use them to calculate the loss value.</p>
<p>this <a href=""https://medium.com/@Bloomore/how-to-write-a-custom-loss-function-with-additional-arguments-in-keras-5f193929f7a0"" rel=""nofollow noreferrer"">link</a> could help you.</p>
<p>Please if you get your answer, mark it as &quot;Answered&quot;.</p>
","2023-04-27 08:01:19","0","Answer"
"76117170","","How do I use a mask based mse loss for images in tensorflow","<p>I want to develop a custom MSE (mean squared error) loss function based on mask region. I have images and corresponding masks. So what I want my loss function to do is to just calculate the mean squared error (MSE) loss over mask pixels and train that way. The issue I face is how to supply a mask to the loss function that is to be used while training as TensorFlow only allows two arguments (y_true,y_pred) for the custom loss function.</p>
<p>I have searched for this everywhere and tried lots of workarounds but found no luck. I would be utterly grateful if you can help me here.</p>
<p>For better representation, showing it what I've already tried:</p>
<pre><code>def outer(mask):
    def mask_mse_loss(y_true, y_pred):
        #SomeCode
        return mse_loss
    return mask_mse_loss

model.compile(loss=outer(mask_y_train), optimizer='adam')
</code></pre>
<p>mask_y_train is list of masks corresponding to y_train which I use for training. The issue is, when I supply mask_y_train to outer(mask) function, it takes it as it is of shape (150,504,504) but X_train, y_train are taken batchwise while training with batch size of 16. So getting this error:
Incompatible shapes: [16,504,504] vs. [150,504,504]</p>
","2023-04-27 05:59:19","0","Question"
"76109675","","How can i create a ""fake"" dataset based on a real one?","<p>I am in the process of creating a &quot;fake&quot; dataset. Let me explain, I already have a dataset (of course I tried to study its topology as much as possible. That is with a study of correlation as well as the relations of variables to variables). My question is now that I &quot;know the characteristics&quot; of the dataset, how can I approach in the best possible way the creation of a dataset resembling as much as possible my original one while wanting to be able to integrate perturbations.</p>
<p>As i said, i only take a look at the data 'topology'. From here i am not convinced on what/how to do.</p>
","2023-04-26 10:23:15","-1","Question"
"76103973","75775979","","<p>I also meet this problem during doing my graduation project, you can uninstall librosa0.9.0 version, download the 0.8.0 version and have a try, the Tsinghua mirror source can't be used to install librosa 0.8.0,you'd better to get a vpn to download the version 0.8.0 from the official</p>
","2023-04-25 17:36:37","0","Answer"
"76102150","76075845","","<p>The issue was with the implementation of the template html and the code both.
I used the following code as reference:</p>
<p>app.py</p>
<pre><code>from flask import Flask, render_template, Response
import cv2

app = Flask(__name__)

# list of camera accesses
cameras = ['xyx.haha, abc.hehe']


def find_camera(list_id):
    return cameras[int(list_id)]


def gen_frames(camera_id):
    cam = find_camera(camera_id)  # return the camera access link with credentials. Assume 0?
    # cam = cameras[int(id)]
    cap = cv2.VideoCapture(cam)  # capture the video from the live feed

    while True:

        # # Capture frame-by-frame. Return boolean(True=frame read correctly. )
        success, frame = cap.read()  # read the camera frame
        if not success:
            break
        else:
            ret, buffer = cv2.imencode('.jpg', frame)
            frame = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')  # concat frame one by one and show result


@app.route('/video_feed/&lt;string:list_id&gt;/', methods=[&quot;GET&quot;])
def video_feed(list_id):
    return Response(gen_frames(list_id),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


@app.route('/', methods=[&quot;GET&quot;])
def index():
    return render_template('index_ip.html', camera_list=len(cameras), camera=cameras)


if __name__ == '__main__':
    app.run()
</code></pre>
<p>index.html</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;head&gt;


&lt;/head&gt;
&lt;body&gt;

    {% for camera_number in range(0, camera_list) %}
    &lt;div&gt;
        &lt;img src=&quot;{{ url_for('video_feed', list_id=camera_number) }}&quot; width=&quot;100%&quot;&gt;&lt;br/&gt;
    &lt;/div&gt;
{% endfor %}

&lt;/body&gt;
</code></pre>
","2023-04-25 14:12:52","0","Answer"
"76100020","76097942","","<p>Yes, we need a train and test data to work with ML models:</p>
<ul>
<li>In beginning we build a model on train data [ x_train(independent variables) , y_train( dependent variable )]</li>
<li>then now our aim is to test model performance on some unknown data i.e., test data here [ x_test , y_test ] then calculate the prediction error / MAPE and conclude whether this model is good fit or not.</li>
<li>we usually take 70% train and 30% test data.</li>
</ul>
","2023-04-25 10:13:35","0","Answer"
"76097997","76097942","","<blockquote>
<p>I see many videos and read some blogs, they explain a lot of reasons. No one agree with each other.</p>
</blockquote>
<p>There are not &quot;a lot of reasons&quot;. (If you find so, it would help to summarise your understanding on what these &quot;lot of reasons&quot; are, so we can address them.)</p>
<blockquote>
<p>why Train/Test-split in ML?</p>
</blockquote>
<p>When you test the model you want to test its <em>predictive power</em>, not the power of <em>memorisation</em>.</p>
<p>Imagine a meteorologist who went to the university for years and years in order to only be correct on what the weather was <em>yesterday</em> (because he has seen it happen). Imagine a doctor who can't diagnose any people correctly, except those who come with a medical chart with diagnosis someone else already made. Imagine a student of mathematics who can only add two numbers together if he was taught to add those specific two numbers together before: he knows <code>2+2</code> and <code>4+3</code>, but not <code>2+3</code> because no-one showed him the result before.</p>
<p>If you teach someone a topic by example, and only check their understanding by testing on those examples, you are checking for rote memorisation. Even if the test scores are high, they might have no understanding, no generalisation on the topic. It is equivalent to giving students a test after letting them see the answer sheet: the grade has no meaning. You have to test on new examples, <em>unseen</em> ones, to accurately check whether the learning produced the capacity to infer the knowledge about the unseen examples from the examples showed in training. You have to teach <code>2+2=4</code> and <code>4+3=7</code>, and test on <code>2+3</code> which you <em>haven't</em> taught, to avoid passing students who only remember <code>2+2=4</code> and <code>4+3=7</code>, and shrug their shoulders when asked about <code>2+3</code>, because &quot;the teacher never told them that&quot;.</p>
<blockquote>
<p>And why this train-test-split algorithm gives four parameters(x_train, x_test, y_train, y_test)?</p>
</blockquote>
<p>Each example consists of two parts: the question and the answer. <code>x</code> is the question part, <code>y</code> is the answer. In this simplified example, the teacher will show the students:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>x</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>2 + 2</td>
<td>4</td>
</tr>
<tr>
<td>4 + 3</td>
<td>7</td>
</tr>
</tbody>
</table>
</div>
<p>then give them the test like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>x</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>2 + 3</td>
<td>_</td>
</tr>
</tbody>
</table>
</div>
<p>and expect the filled test to be like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>x</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>2 + 3</td>
<td>5</td>
</tr>
</tbody>
</table>
</div>
<p>This gives you the four arrays: <code>x_train</code> and <code>y_train</code> (the questions and answers you teach), <code>x_test</code> (the questions you ask on the test) and <code>y_test</code> (the answers you expect on the answer sheet).</p>
","2023-04-25 05:59:55","4","Answer"
"76097961","76097942","","<p>we use train,test split to split the data.
if we don't use it how can we check the performance of the data with the unseen data other than the train data.
train data is used to train the model
test data is used to check the accuracy of the model.</p>
","2023-04-25 05:50:52","0","Answer"
"76097942","","why Train/Test-split in ML?","<p>I can't understand why we need to split dataset in machine learning. And why this train-test-split algorithm gives four parameters(x_train, x_test, y_train, y_test)?</p>
<p>I see many videos and read some blogs, they explain a lot of reasons. No one agree with each other. Is there any common reason to use this algorithm?</p>
","2023-04-25 05:47:20","-1","Question"
"76085393","76082746","","<p>Try converting the numpy.memmap object to a NumPy array and then to a PIL image.</p>
","2023-04-23 14:22:53","0","Answer"
"76082746","","How to transform a quickdraw image to 84 by 84 in pytorch using the learn2learn library?","<p>I was trying to use learn2learn's QuickDraw but it seems like I'm getting errors when I attempt to apply transformations (resizing to 84x84, random crop) on it. The issue stems from when l2l's quickdraw library attempts to apply transformations onto a quickdraw image (that is apparently in the form of a np.memmap/.npy record that PIL can't understand) and so I get the following error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;/home/pzy2/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/dataloaders/maml_patricks_l2l.py&quot;, line 2300, in &lt;module&gt;
    loop_through_l2l_indexable_benchmark_with_model_test()
  File &quot;/home/pzy2/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/dataloaders/maml_patricks_l2l.py&quot;, line 2259, in loop_through_l2l_indexable_benchmark_with_model_test
    for benchmark in [quickdraw_l2l_tasksets()]: #hdb8_l2l_tasksets(),hdb9_l2l_tasksets(), delaunay_l2l_tasksets()]:#[dtd_l2l_tasksets(), cu_birds_l2l_tasksets(), fc100_l2l_tasksets()]:
  File &quot;/home/pzy2/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/dataloaders/maml_patricks_l2l.py&quot;, line 2216, in quickdraw_l2l_tasksets
    _transforms: tuple[TaskTransform, TaskTransform, TaskTransform] = get_task_transforms_quickdraw(_datasets,
  File &quot;/home/pzy2/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/dataloaders/maml_patricks_l2l.py&quot;, line 2184, in get_task_transforms_quickdraw
    train_transforms: TaskTransform = DifferentTaskTransformIndexableForEachDataset(train_dataset,
  File &quot;/home/pzy2/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/dataloaders/common.py&quot;, line 130, in __init__
    self.indexable_dataset = MetaDataset(indexable_dataset)
  File &quot;learn2learn/data/meta_dataset.pyx&quot;, line 59, in learn2learn.data.meta_dataset.MetaDataset.__init__
  File &quot;learn2learn/data/meta_dataset.pyx&quot;, line 96, in learn2learn.data.meta_dataset.MetaDataset.create_bookkeeping
  File &quot;learn2learn/data/meta_dataset.pyx&quot;, line 65, in learn2learn.data.meta_dataset.MetaDataset.__getitem__
  File &quot;/home/pzy2/miniconda3/envs/metalearning3.9/lib/python3.9/site-packages/learn2learn/vision/datasets/quickdraw.py&quot;, line 511, in __getitem__
    image = self.transform(image)
  File &quot;/home/pzy2/miniconda3/envs/metalearning3.9/lib/python3.9/site-packages/torchvision/transforms/transforms.py&quot;, line 60, in __call__
    img = t(img)
  File &quot;/home/pzy2/miniconda3/envs/metalearning3.9/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File &quot;/home/pzy2/miniconda3/envs/metalearning3.9/lib/python3.9/site-packages/torchvision/transforms/transforms.py&quot;, line 900, in forward
    i, j, h, w = self.get_params(img, self.scale, self.ratio)
  File &quot;/home/pzy2/miniconda3/envs/metalearning3.9/lib/python3.9/site-packages/torchvision/transforms/transforms.py&quot;, line 859, in get_params
    width, height = F._get_image_size(img)
  File &quot;/home/pzy2/miniconda3/envs/metalearning3.9/lib/python3.9/site-packages/torchvision/transforms/functional.py&quot;, line 67, in _get_image_size
    return F_pil._get_image_size(img)
  File &quot;/home/pzy2/miniconda3/envs/metalearning3.9/lib/python3.9/site-packages/torchvision/transforms/functional_pil.py&quot;, line 26, in _get_image_size
    raise TypeError(&quot;Unexpected type {}&quot;.format(type(img)))
TypeError: Unexpected type &lt;class 'numpy.memmap'&gt;
</code></pre>
<p>original:</p>
<ul>
<li><a href=""https://github.com/learnables/learn2learn/issues/392"" rel=""nofollow noreferrer"">https://github.com/learnables/learn2learn/issues/392</a></li>
<li><a href=""https://discuss.pytorch.org/t/how-to-transform-a-quickdraw-image-to-84-by-84-in-pytorch-using-the-learn2learn-library/178292"" rel=""nofollow noreferrer"">https://discuss.pytorch.org/t/how-to-transform-a-quickdraw-image-to-84-by-84-in-pytorch-using-the-learn2learn-library/178292</a></li>
</ul>
","2023-04-23 01:45:24","2","Question"
"76079506","76075845","","<p>I had the same issue with flask, then i changed to FastApi. Now it's working fine</p>
","2023-04-22 11:57:30","1","Answer"
"76075845","","Flask based object detection python script wont show output for IP cameras","<p>I am trying to detect objects in multiple streams of IP Cameras using yolov8 and display the output of these streams with bounding boxes on the browser using flask.
However, the output wont show anything. I tried printing text for debugging but it would only print text from <code>___name___=='___main___'</code> after stopping the process (ctrl+c)</p>
<p><a href=""https://i.sstatic.net/IwPXd.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/IwPXd.png"" alt=""enter image description here"" /></a></p>
<p>predict_ip.py</p>
<pre><code>from flask import Flask, render_template, Response
from ultralytics import YOLO
import cv2
import threading
import torch 
import argparse

CAMERAS = []

app = Flask(__name__)

class_names = [....]

def generate_frames(models, caps):
    while True:
        # read frames from cameras
        frames = []
        for cap in caps:
            success, img = cap.read()
            if success:
                frames.append(img)
        
        # predict objects in frames from cameras
        results = [model(frames[i], stream=True) for i, model in enumerate(models)]
        for i, result in enumerate(results):
            for r in result:
                boxes = r.boxes
                for box in boxes:
                    .
                    .

        # encode processed frames as jpg images
        for frame in frames:
            _, buffer = cv2.imencode('.jpg', frame)
            frame = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')


@app.route('/')
def index():
    return render_template('index_ip.html',cameras=CAMERAS)

@app.route('/video_feed')
def video_feed():
    print('IN video feed')
    args = parse_args()
    caps = [cv2.VideoCapture(url) for url in args.urls]
    global CAMERAS
    CAMERAS = [url for url in args.urls]
    models = [YOLO(&quot;./models/best_10Class_20Epochs.pt&quot;) for i in range(len(args.urls))]
    return Response(generate_frames(models, caps), mimetype='multipart/x-mixed-replace; boundary=frame')

def parse_args():
    print('parsing args')
    parser = argparse.ArgumentParser(description='Multi-Camera Object Detection')
    parser.add_argument('-urls', nargs='+', help='List of URLs for the cameras', required=True)
    args = parser.parse_args()
    print(args.urls)
    return args

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=3000)
    print('Main method')
</code></pre>
<p>index_ip.html</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Multi-Camera Object Detection&lt;/title&gt;
    &lt;style&gt;
        .grid-container {
      ......}
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class=&quot;grid-container&quot;&gt;
        {% for camera in cameras %}
        &lt;div class=&quot;grid-item&quot;&gt;
            &lt;img src=&quot;{{ url_for('video_feed') }}&quot; alt=&quot;{{camera}}&quot;&gt;
            &lt;div class=&quot;overlay&quot;&gt;
                &lt;p&gt;Camera {{ camera }}&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        {% endfor %}
    &lt;/div&gt;
&lt;/body&gt;

&lt;/html&gt;
</code></pre>
<p>The output in the browser is just a blank screen. For testing, I am using IP Cams available on a website called opentopia.
Am running the code as : <code>python predict_ip.py -urls http://xxx.xx.xxx.xx/abc/video.mjpg http://yyy.yy.yy.yy/abc/video.mjpg</code></p>
<p>All suggestions are much appreciated. Thank you !!</p>
","2023-04-21 18:28:31","0","Question"
"76074046","76067104","","<p>length is too long, 9999 will consume huge amount of GPU RAM, especially using 13b model. try 7b model. And try using something like peft/bitsandbytes to reduce GPU RAM usage. set load_in_8bit=True is a good start.</p>
","2023-04-21 14:17:09","2","Answer"
"76074008","76034640","","<p><code>env.reset()</code> returns 2 elements in new versions of gym, making your <code>state</code> a tuple that crashes numpy indexing. Either add an additional underscore to the result of <code>reset</code> call or downgrade your gym version. With <code>gym=0.21.0</code> your initial code works.</p>
<p>P.S. I advise you also to:</p>
<ul>
<li>recondisder using such a high <code>learning_rate</code></li>
<li>check for all-zero Q-values for the given state and if true, use a random action to encourage the exploration</li>
</ul>
","2023-04-21 14:11:46","0","Answer"
"76072156","76071825","","<p>I don't think that you need a machine learning algorithm for your problem here. It's always a good approach to conduct some statistical analysis to gain a good understanding of your data</p>
<h2>Correlation tests</h2>
<p>You should start by measuring the correlation between the file_name and your other variables or conducting other independancy tests first (Pearson, Kendall-Tau, etc). (you'll have to encode your file_name to numerical space to do that), but it should give you a good idea, if your file_name is actually independant or not of your content or features (if that's the case then it's useless to apply any machine learning algorithm to predict your file_name)</p>
<h2>Machine learning approach</h2>
<p>If you determine that your features / content and target aren't exactly independant, you can then go through the machine learning route.
For example if you're trying to predict the file_name from the content of the file itself. Then it might be set up as a classification problem, if your file_name has a specified cardinality (eg : file_name is either 'fileA', 'fileB', or 'fileC'). That way you can use supervised or unsupervised learning methods as specified in the previous answer.</p>
","2023-04-21 10:12:06","1","Answer"
"76071892","76071825","","<p>Finding a meaningful relationship between file names and their content may not be guaranteed, as the relationship could be weak or nonexistent. If the ML algorithms do not provide satisfactory results, you may need to consider alternative approaches or gather additional data to enhance your analysis.</p>
<p>Since you want to find relationships between the file name features and the presence/absence of functions, you can use the following ML algorithms:</p>
<p><strong>Supervised learning:</strong> If you have a specific function that you want to predict based on the file name features, you can use classification algorithms like <strong>Logistic Regression</strong>, <strong>Random Forest</strong> or <strong>Support Vector Machines (SVM)</strong>.</p>
<p><strong>Unsupervised learning:</strong> If you don't have a specific function to predict and just want to find patterns or groupings in the data, you can use clustering algorithms like <strong>K-Means</strong>, <strong>DBSCAN</strong>, or <strong>Hierarchical Clustering</strong>.</p>
<p>Have a look at the python module <a href=""https://scikit-learn.org/stable/tutorial/basic/tutorial.html"" rel=""nofollow noreferrer"">scikit-learn</a>.</p>
","2023-04-21 09:38:44","1","Answer"
"76071825","","What ML algorithm to use in order to find a pattern between file name and the content of the file?","<p>I am working on a ML project and got stuck on what approach to take in that problem:</p>
<p>I have a table (.csv file) that contains in a column 'file' list of all my <strong>.txt files</strong> that are called BAM_xxxx, where xxxx is a combination of digits and letters. All other columns of the table are functions, that is <strong>function1, function2, function3,...., function30.</strong></p>
<p>If the function is present in the .txt file there is 1 in the table in that cell, if not there is 0. It looks somehow like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>index</th>
<th>file</th>
<th>function1</th>
<th>function2</th>
<th>...</th>
<th>function30</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>BAM_123A.txt</td>
<td>1</td>
<td>1</td>
<td>...</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>BAM_CD0X.txt</td>
<td>0</td>
<td>1</td>
<td>...</td>
<td>1</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>1000</td>
<td>BAM_1A3B.txt</td>
<td>1</td>
<td>1</td>
<td>...</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<p><strong>I want to investigate if there is a relationship between the name of .txt file (that is: xxxx) and the functions present in the file. What ML Algorithm would be best for that task?</strong></p>
<p>I was thinking about some kind of clustering (though dont have an idea yet what how would the clusters look like) such as Random Forest, ut I suppose first I need to create features from the file names somehow.</p>
","2023-04-21 09:30:22","-1","Question"
"76068327","75951962","","you can reduce the number of columns/rows selected, increase max iterations, reduce subsample, increase min tree child weight, use a different data split method like random instead of seq</p>
","2023-04-20 21:13:49","0","Answer"
"76067104","","Using Vicuna + langchain + llama_index for creating a self hosted LLM model","<p>I want to create a self hosted LLM model that will be able to have a context of my own custom data (Slack conversations for that matter).</p>
<p>I've heard Vicuna is a great alternative to ChatGPT and so I made the below code:</p>
<pre><code>from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTListIndex, \
    GPTSimpleVectorIndex, PromptHelper, LLMPredictor, Document, ServiceContext
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
import torch
from langchain.llms.base import LLM
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    
class CustomLLM(LLM):
    model_name = &quot;eachadea/vicuna-13b-1.1&quot;
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)

    pipeline = pipeline(&quot;text2text-generation&quot;, model=model, tokenizer=tokenizer, device=0,
                        model_kwargs={&quot;torch_dtype&quot;:torch.bfloat16})

    def _call(self, prompt, stop=None):
        return self.pipeline(prompt, max_length=9999)[0][&quot;generated_text&quot;]
 
    def _identifying_params(self):
        return {&quot;name_of_model&quot;: self.model_name}

    def _llm_type(self):
        return &quot;custom&quot;


llm_predictor = LLMPredictor(llm=CustomLLM())
</code></pre>
<p>But sadly I'm hitting the below error:</p>
<pre><code>OutOfMemoryError: CUDA out of memory. Tried to allocate 270.00 MiB (GPU 0; 22.03 GiB total capacity; 21.65 GiB 
already allocated; 94.88 MiB free; 21.65 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated 
memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and 
PYTORCH_CUDA_ALLOC_CONF
</code></pre>
<p>Here's the output of <code>!nvidia-smi</code> (before running anything):</p>
<pre><code>Thu Apr 20 18:04:00 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A10G                     Off| 00000000:00:1E.0 Off |                    0 |
|  0%   23C    P0               52W / 300W|      0MiB / 23028MiB |     18%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
</code></pre>
<p>Any idea how to modify my code to make it work?</p>
","2023-04-20 18:14:37","6","Question"
"76060886","76057512","","<p>I have found out the mistake i made. I am not knowledge enough to explain this but it seems the embedding_dim I defied earlier in the code doesn't support when it comes to the implementing the fasttext functionalities.</p>
<pre><code># Mapping FastText word vectors with word in the dataset 
embedding_dim = ft.get_dimension()
embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))
for word, i in word_index.items():
    embedding_vector = ft.get_word_vector(word)
    if embedding_vector is not None:
        embeddings_matrix[i] = embedding_vector
</code></pre>
<p>Thank you for your help</p>
","2023-04-20 05:37:37","0","Answer"
"76058679","76057512","","<p>You're not showing the values of <code>vocab_size</code> &amp; <code>embedding_dim</code> that you're using to create your <code>embeddings_matrix</code>. (Also, at the time you're operating on it, <code>word_index</code> hasn't yet been established to hold any value.)</p>
<p>But, that seems like an error one might get trying to put a 300-dimensional vector into another array where it doesn't fit.</p>
<p>What are the values of <code>vocab_size</code> &amp; <code>embedding_dim</code> – or equivalently what's <code>embeddings_matrix.shape</code> just before you get the error? If its 2nd dimension isn't <code>300</code>, it should be, and you should change your (unshown) code that sets up the controlling values to ensure that <code>embedding_matrix</code> is the right size.</p>
<p>(More foundationally, are you sure you need to copy each word's vector out of the <code>ft</code> model into your own matrix? You might not, depending on what you're planning to do next.)</p>
","2023-04-19 20:47:03","1","Answer"
"76057512","","Could not broadcast input array from shape (300,) into shape when mapping FastText word vectors with word in the dataset","<p>I am working on creating a NLP model for my final year project. I am currently using Tensorflow Keras LSTM model to train the model. I have found a online guide for this as my dataset is in Sinhala but the code in that tutorial is old or has some issues. Currently when ever I runs</p>
<pre><code>import fasttext
import fasttext.util

ft = fasttext.load_model(&quot;cc.si.300.bin&quot;)
ft.get_dimension()

# Mapping FastText word vectors with word in the dataset 
embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));
for word, i in word_index.items():
    embedding_vector = ft.get_word_vector(word)
    print(word)
    if embedding_vector is not None:
        embeddings_matrix[i] = embedding_vector;
</code></pre>
<p>I get the error below.</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-44-797ce5392360&gt; in &lt;cell line: 9&gt;()
     11     print(word)
     12     if embedding_vector is not None:
---&gt; 13         embeddings_matrix[i] = embedding_vector;

ValueError: could not broadcast input array from shape (300,) into shape (16,)
</code></pre>
<p>As I am new to this, I don't know how to fix this issue exactly and I was not able to find a proper answer in the site too.</p>
","2023-04-19 17:54:52","0","Question"
"76056952","75664004","","<p>Had the same issue.
After installation, you have to login to your Postgres DB, for example via</p>
<pre><code>psql postgres
</code></pre>
<p>and run</p>
<pre><code>CREATE EXTENSION vector;
</code></pre>
","2023-04-19 16:41:33","0","Answer"
"76051692","76051674","","<p>You can use <code>value_counts</code> as mapping dict:</p>
<pre><code>&gt;&gt;&gt; df['CategoryName'].replace(df.value_counts())
0    3
1    3
2    3
3    2
4    2
5    1
Name: CategoryName, dtype: int64
</code></pre>
<p><strong>Note</strong>: take care if some values have the same frequency like <code>['Blue', 'Blue', 'Yellow', 'Yellow', 'Red']</code>, the result will be <code>[2, 2, 2, 2, 1]</code></p>
<p><strong>Update</strong></p>
<p>To get only one line:</p>
<pre><code>&gt;&gt;&gt; df.value_counts().to_frame().T
  Blue Yellow Red
0    3      2   1
</code></pre>
<p><strong>Update 2</strong></p>
<blockquote>
<p>The target variable can be influenced by how many applications the orchard has had, not just whether it had an application or not.</p>
</blockquote>
<p>It makes sense so in this case, all fertilizers should be process as separated variables:</p>
<pre><code>&gt;&gt;&gt; df
  Orchad Fertilizer
0      A         F1
1      A         F1
2      A         F1
3      A         F1
4      A         F2
5      A         F2
6      B         F1
7      B         F1
8      B         F1
9      B         F3

&gt;&gt;&gt; pd.crosstab(df['Orchad'], df['Fertilizer'])
Fertilizer  F1  F2  F3
Orchad                
A            4   2   0
B            3   0   1

# Use normalize={'all'|'index'|'columns'} or StandardScaler
&gt;&gt;&gt; pd.crosstab(df['Orchad'], df['Fertilizer'], normalize='columns')
Fertilizer        F1   F2   F3
Orchad                        
A           0.571429  1.0  0.0
B           0.428571  0.0  1.0
</code></pre>
","2023-04-19 07:17:01","2","Answer"
"76051688","76051674","","<p>With <a href=""/questions/tagged/pandas"" class=""post-tag"" title=""show questions tagged &#39;pandas&#39;"" aria-label=""show questions tagged &#39;pandas&#39;"" rel=""tag"" aria-labelledby=""tag-pandas-tooltip-container"">pandas</a> you can use a self <a href=""https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html"" rel=""nofollow noreferrer""><code>groupby.transform('size')</code></a>:</p>
<pre><code>out = df.groupby('CategoryName')['CategoryName'].transform('size')
</code></pre>
<p>If you already calculated the dummies, just <a href=""https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html"" rel=""nofollow noreferrer""><code>map</code></a> their <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html"" rel=""nofollow noreferrer""><code>sum</code></a>:</p>
<pre><code>dummies = pd.get_dummies(df['CategoryName'])
out = df['CategoryName'].map(dummies.sum())
</code></pre>
<p>Output:</p>
<pre><code>0    3
1    3
2    3
3    2
4    2
5    1
Name: CategoryName, dtype: int64
</code></pre>
","2023-04-19 07:16:06","2","Answer"
"76051674","","Frequency encoding - should I make dummy columns?","<p>I am busy prepping data to train a machine learning model. Many of the features can work well with one-hot encoding. For one feature, the frequency is related to the target variable. I have been reading up a bit about frequency encoding and everything I find has to do with replacing the category with the frequency, like so:</p>
<pre><code>CategoryName
------------
Blue
Blue
Blue
Yellow
Yellow
Red
</code></pre>
<p>Turning into:</p>
<pre><code>CategoryName
------------
3
3
3
2
2
1
</code></pre>
<p>If I had done one-hot, I would have had:</p>
<pre><code>Blue   Yellow   Red
1      0        0
1      0        0
1      0        0
0      1        0
0      1        0
0      0        0
</code></pre>
<p>All of the above may be related to a single line in the data I want to join it to, so I was wondering if this would be useful:</p>
<pre><code>Blue   Yellow   Red
3      2        1
</code></pre>
<p>If so, is there a simple way to do it, like <code>get_dummies()</code>?</p>
","2023-04-19 07:13:34","1","Question"
"76035401","76034630","","<p>your mask is not correctly set. you have a batch size of 8 and a sequence length of 320. try adding:</p>
<pre><code>mask = torch.ones(8, 320, 320)
mask = mask.masked_fill(mask == 0, float('-inf'))
</code></pre>
<p>before using:</p>
<pre><code>output = transformer_encoder(latent, mask)
</code></pre>
","2023-04-17 12:56:26","0","Answer"
"76034640","","Why is q_table[state, action] giving me an index error?","<p>I am trying to make a reinforcement learning model using GYM library by OpenAI and using the Frozen Lake environment initialized as:</p>
<pre><code>env = gym.make(&quot;FrozenLake-v1&quot;)
</code></pre>
<p>While coding the q-learning algorithm, I am running into index error.</p>
<p>I initially tried the following lines:</p>
<pre><code>
import numpy as np
import gym

# Create the FrozenLake environment
env = gym.make('FrozenLake-v1')

# Set the hyperparameters
num_episodes = 10000
max_steps_per_episode = 100
learning_rate = 0.8
discount_rate = 0.95
exploration_rate = 1.0
max_exploration_rate = 1.0
min_exploration_rate = 0.01
exploration_decay_rate = 0.001

# Initialize the Q-table
action_space_size = env.action_space.n
state_space_size = env.observation_space.n
q_table = np.zeros((state_space_size, action_space_size))

# Create a list to hold the rewards for each episode
rewards_all_episodes = []

# Q-learning algorithm
for episode in range(num_episodes):
    # Reset the environment
    state = env.reset()
    done = False
    rewards_current_episode = 0
    
    for step in range(max_steps_per_episode):
        # Exploration-exploitation trade-off
        exploration_rate_threshold = np.random.uniform(0, 1)
        if exploration_rate_threshold &gt; exploration_rate:
            # Exploitation (taking the biggest Q-value for this state)
            action = np.argmax(q_table[state,:])
        else:
            # Exploration (random action)
            action = env.action_space.sample()
        
        # Take the chosen action and observe the new state and reward
        new_state, reward, done, info = env.step(action)
        
        # Update the Q-table using the Q-learning formula
        q_table[state, action] = (1 - learning_rate) * q_table[state, action] + \
                                 learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))
        
        state = new_state
        rewards_current_episode += reward
        
        if done == True:
            break
    
    # Decay the exploration rate for the next episode
    exploration_rate = min_exploration_rate + \
                       (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)
    
    # Append the rewards for this episode to the list
    rewards_all_episodes.append(rewards_current_episode)

# Print the rewards for all episodes
print(&quot;Rewards per episode:&quot;)
print(rewards_all_episodes)

# Print the Q-table
print(&quot;\nQ-table:&quot;)
print(q_table)
</code></pre>
<p>This gave me the error in <code>env.step()</code> saying <code>too many values to unpack</code></p>
<p>I then changed it to <code>new_state, rewards, done, truncate, info</code> which shifted the error to an index error:</p>
<pre><code>IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices
</code></pre>
<p>I have tried ChatGPT but can't seem to find any answer. Could someone help?</p>
","2023-04-17 11:25:23","0","Question"
"76034630","","How do I send an attention-mask ""Mask"" matrix in transformer encoder along with my latent in pytorch's nn.TransformerEncoder?","<p>I have a transformer_encoder initialized in pytorch as:</p>
<pre><code>transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads), num_layers=num_layers)
</code></pre>
<p>Now I have a latent, which is of shape [8, 320, 512], where 8 is the batch_size, 320 is the sequence length, and 512 is the embedding dimension.</p>
<p>I also have an attention mask of shape [320, 320].</p>
<p>And I want to pass it into transformer encoder like:</p>
<pre><code>latent = torch.rand(8, 320, 512)
mask = torch.rand(320, 320)

output = transformer_encoder(latent, mask)
</code></pre>
<p>But it is giving me error:<br>
&quot;The shape of the 2D attn_mask is torch.Size([320, 320]), but should be (8, 8).&quot;<br><br>
Now I repeated the matrix along batch dimension creating 8 of those (320, 320) matrices, making the shape of 'mask', [8, 320, 320]. When I ran again the above code</p>
<pre><code>latent.shape = [8, 320, 512]
mask.shape = [8, 320, 320]

output = transformer_encoder(latent, mask)
</code></pre>
<p>It gives me this error:<br>
&quot;The shape of the 3D attn_mask is torch.Size([8, 320, 320]), but should be (2560, 8, 8).&quot;</p>
<p>Can someone explain what is the problem here? And how can I solve it? Or the correct way to implement it?</p>
","2023-04-17 11:24:23","0","Question"
"76024887","76020437","","<p>After a ton of more research online I found a resolution that worked for me:</p>
<p><a href=""https://datascience.stackexchange.com/questions/89511/how-to-use-inverse-transform-in-minmaxscaler-for-pred-answer-in-a-matrix"">https://datascience.stackexchange.com/questions/89511/how-to-use-inverse-transform-in-minmaxscaler-for-pred-answer-in-a-matrix</a></p>
<p>I realized I did not need to unscale the entire dataset so I just went with the predicted columns.</p>
<p>In case anyone is interested in how I coded it:</p>
<pre><code>## - BA
batting[['BA_DTR']] = round(batting[['BA_DTR']], 3)

## - RBI
bat_rbi_dtr = batting[['RBI_DTR']]
#scaled from 0 to 165
min = 0
max = 165
bat_rbi_dtr * min + (max - min)

batting['RBI_DTR'] = bat_rbi_dtr.astype(int)


## - HR
bat_hr_dtr = batting[['HR_DTR']]
#scaled from 0 to 73
min = 0
max = 73
bat_hr_dtr * min + (max - min)

batting['HR_DTR'] = bat_hr_dtr.astype(int)

## - BB
bat_bb_dtr = batting[['BB_DTR']]
#scaled from 0 to 232
min = 0
max = 232
bat_bb_dtr * min + (max - min)

batting['BB_DTR'] = bat_bb_dtr.astype(int)

## - SO
bat_so_dtr = batting[['SO_DTR']]
#scaled from 0 to 223
min = 0
max = 223
bat_so_dtr * min + (max - min)

batting['SO_DTR'] = bat_so_dtr.astype(int)
</code></pre>
<p>If anyone has any better/cleaner options please feel free to still respond</p>
","2023-04-15 21:40:32","1","Answer"
"76020437","","Trouble unscaling data after predictions","<p>I am working on a project where I am trying to predict mlb player stats from 1970 - 2022. I have 2 datasets, one for batters where I am predicting on 5 stats with 20 features and another for pitchers where I am predicting on 6 stats with 25 features. I am currently working on a Decision Tree Model, but also plan to work with Linear Regression and LSTM models as well.</p>
<p>Prior to initially scaling the dataset I removed the string columns, year, and columns I was using to compare results with.</p>
<pre><code>remove_bat_cols = ['Name', 'Tm', 'Year', 'Nxt_BA', 'Nxt_RBI', 'Nxt_HR', 'Nxt_BB', 'Nxt_SO']
remove_pitch_cols = ['Name', 'Tm', 'Year', 'Nxt_ERA', 'Nxt_SO', 'Nxt_WHIP', 'Nxt_BB', 'Nxt_W', 'Nxt_SV']

bat_cols = batting.columns[~batting.columns.isin(remove_bat_cols)]
pitch_cols = pitching.columns[~pitching.columns.isin(remove_pitch_cols)]
</code></pre>
<p>I then scaled my data</p>
<pre><code>scaler = MinMaxScaler()
batting.loc[:, bat_cols] = scaler.fit_transform(batting[bat_cols])
pitching.loc[:, pitch_cols] = scaler.fit_transform(pitching[pitch_cols])
</code></pre>
<p>I initially tried to just reverse my steps to unscale</p>
<pre><code>batting.loc[:, bat_cols] = scaler.inverse_transform(batting[bat_cols])
pitching.loc[:, pitch_cols] = scaler.inverse_transform(pitching[pitch_cols])
</code></pre>
<p>But I receive the below error:</p>
<pre><code>ValueError: operands could not be broadcast together with shapes (26768,29) (31,) (26768,29) 
</code></pre>
<p>I've also tried adding the predicted columns and even tried only predicted columns and receive the same.</p>
","2023-04-15 05:00:54","3","Question"
"76013119","","TPOT for hyperparameter tuning","<p>I want to used TPOT for hyperparameter tunning of model. I know that TPOT can give me best machine learning pipeline with best hyperparameter. But in my case I have pipeline and I want to just tune its parameter</p>
<p>my pipeline is as follow</p>
<pre><code>exported_pipeline = make_pipeline(
    StackingEstimator(estimator=SGDRegressor(alpha=0.001, eta0=0.1, fit_intercept=False, l1_ratio=1.0, learning_rate=&quot;constant&quot;, loss=&quot;epsilon_insensitive&quot;, penalty=&quot;elasticnet&quot;, power_t=10.0)),
    SelectPercentile(score_func=f_regression, percentile=90),
    OneHotEncoder(minimum_fraction=0.2, sparse=False, threshold=10),
    XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=100, n_jobs=1, objective=&quot;reg:squarederror&quot;, subsample=0.45, verbosity=0)
</code></pre>
<p>please tell me way to do tunning of hyperparameter and if it is not possible in TPOT please tell some other possible alternative library for this. Thank you</p>
","2023-04-14 08:40:04","0","Question"
"76008033","76007746","","<p>hello bloowy im here to tell you to use sigmoid which equals to softmaxx**2e
andl ike this you can find a solution to your problem</p>
","2023-04-13 16:57:43","0","Answer"
"76007850","76007746","","<p>The goal of gradient descent is to minimize the cost function C(w, x). Notice that it is parameterized by the weights in addition to x, itself. Since the function is highly complex, we use a variant of Newton's method called gradient descent rather than simply solving for w s.t C(w, x) = 0. We take C'(x) which is moving towards the maximum and move w opposite of it to minimize C. However, to avoid overshooting, we use eta or learning rate to move only small steps at a time. Through each step, we get approach a minimum of the function. It's might not be the absolute minimum or a 0 of the function but it will be at least a relatively minimum at the end.</p>
","2023-04-13 16:35:29","0","Answer"
"76007746","","Understanding the calculation of Perceptron weights in Python","<p>I am trying to undersand how the Perceptron's weights are calculated, for example, with this method <code>fit</code>:</p>
<pre><code>def fit(self, X,y):
       
        self.w_ = np.zeros(1 + X.shape[1])
        self.errors_ = []
        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                update = self.eta * (target - self.predict(xi))
                self.w_[1:] += update * xi
                self.w_[0] += update
                errors += int(update !=0.0)
            self.errors_.append(errors)
        return self
</code></pre>
<p>Let's imagine that on the first iteration of the <code>for</code> loop we have:</p>
<pre><code>xi = array([5.1, 1.4])
target = int(-1)
self.eta = float(0.01)
self.w_=array([0., 0., 0.])
</code></pre>
<p>Then <code>self.predict(xi)</code> occurs to get <code>update</code>:</p>
<pre><code>def predict(self,X):
        return np.where(self.net_input(X) &gt;= 0.0, 1, -1)
</code></pre>
<p>And it calls <code>self.net_input(X)</code>:</p>
<pre><code>def net_input(self,X):
        return np.dot(X, self.w_[1:]) + self.w_[0]
</code></pre>
<p>Then we have these calculations:</p>
<pre><code>np.where(X, self.w_[1:]) + self.w_[0] equals ([5.1, 1.4]*[0.,0.]) + 0 = 0

np.where(self.net_input(X) &gt;= 0.0, 1, -1) equals 1 (because *self.net_input(X)* = 0)

update = self.eta * (target - self.predict(xi)) equals update = 0.01 * (-1-1) = -0.02

self.w_[1:] += update * xi equals [0.,0.] += -0.02 * 0.01 = [-0.0002, -0.0002]

self.w_[0] = update(-0.02)
</code></pre>
<p>And that's what we 'have':</p>
<p><code>self.w_ = array([-0.02 , -0.0002, -0.0002])</code></p>
<p>However, what I see after first the first iteration on the breakpoint is:</p>
<p><code>self.w_ = array([-0.02 , -0.102, -0.028])</code></p>
<p>I started learning ML 2 days ago, so maybe I'm missing something important?</p>
<p><em>P.S. Code is working well</em></p>
","2023-04-13 16:24:28","0","Question"
"76000219","75918536","","<p><code>cross_val_score</code> average the scores across folds, so with <code>cv=LeaveOneOut()</code> yes, it's computing the score per row (by a model trained on all other rows).  With RMSE, that's equivalent to MAE; and R2 will just fail.</p>
<p>You could use <code>cross_val_predict</code> to get the individual predictions, then score that collection all at once, to reproduce your manual work.</p>
","2023-04-12 22:14:18","0","Answer"
"75995443","75867322","","<p>It looks like you are using code that references old libraries.
The decay argument is deprecated for optimizers since Keras 2.3.</p>
<p>You basically have two options</p>
<ul>
<li>downgrade Tensorflow to a version with Keras backend &lt;2.3</li>
<li>upgrade canaro to a version that supports TF &gt;=2.3</li>
</ul>
<p>Another answer was given here which also points out (<a href=""https://stackoverflow.com/questions/74734685/how-to-fix-this-value-error-valueerror-decay-is-deprecated-in-the-new-keras-o"">here</a>), that if you are not married to canaro you can use folowing options to get your code to wokr:</p>
<p><strong>TF&lt;2.3 - style</strong></p>
<pre><code>import tensorflow as tf
epochs = 50
learning_rate = 0.01
decay_rate = learning_rate / epochs
optimizer = tf.keras.optimizers.Adam(lr=learning_rate, decay=decay_rate)
</code></pre>
<p><strong>TF&gt;=2.3 - style</strong></p>
<pre><code>import tensorflow as tf
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=10000,
    decay_rate=0.9)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)
</code></pre>
","2023-04-12 12:27:18","1","Answer"
"75983245","75982832","","<p>To resolve this issue you have to upgrade your keras and tensorflow in to the latest versions.You can do it using following command:</p>
<pre><code>pip install --upgrade keras tensorflow
</code></pre>
","2023-04-11 07:06:55","0","Answer"
"75982832","","Cannot import name 'CallFunctionSpec' from 'keras.utils.layer_utils' (/usr/local/lib/python3.9/dist-packages/keras/utils/layer_utils.py)","<p>the code was running fine yesterday
the code is:</p>
<pre><code>from sklearn import metrics
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.models import Sequential
from tensorflow.python.keras.optimizers import Adam
</code></pre>
<p>and the error shown is:</p>
<pre><code>ImportError                               Traceback (most recent call last)
&lt;ipython-input-71-00e64660885b&gt; in &lt;cell line: 2&gt;()
      1 from sklearn import metrics
----&gt; 2 from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
      3 from tensorflow.keras.models import Sequential
      4 from tensorflow.python.keras.optimizers import Adam

7 frames
/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/utils.py in &lt;module&gt;
     28 from keras.utils import tf_contextlib
     29 from keras.utils.generic_utils import LazyLoader
---&gt; 30 from keras.utils.layer_utils import CallFunctionSpec
     31 
     32 training_lib = LazyLoader(&quot;training_lib&quot;, globals(), &quot;keras.engine.training&quot;)

ImportError: cannot import name 'CallFunctionSpec' from 'keras.utils.layer_utils' (/usr/local/lib/python3.9/dist-packages/keras/utils/layer_utils.py)

</code></pre>
<p>it say it cannot import 'CallFunctionSpec' from 'keras.utils.layer_utils'
but i'm not using utils in it
i don't need utils in it what i need is layers but it shows error in utils</p>
<p>what should i do to solve the <code>cannot import name 'CallFunctionSpec' from 'keras.utils.layer_utils'</code>
and this error has been shown in multiple occurrences</p>
","2023-04-11 06:07:53","2","Question"
"75980931","75979420","","<p>Why are you passing <code>device=0</code>? If <code>isinstance(device, int)</code>, PyTorch will assume <code>device</code> is the index of a CUDA device, hence the error. Try <code>device=&quot;cpu&quot;</code> (or maybe simply removing the <code>device</code> kwarg), and this issue should disappear.</p>
","2023-04-10 21:38:08","1","Answer"
"75979420","","using llama_index with mac m1","<p><strong>Question #1:</strong></p>
<p>Is there a way of using Mac with M1 CPU and <code>llama_index</code> together?</p>
<p>I cannot pass the bellow assertion:</p>
<pre><code>AssertionError                            Traceback (most recent call last)
&lt;ipython-input-1-f2d62b66882b&gt; in &lt;module&gt;
      6 from transformers import pipeline
      7 
----&gt; 8 class customLLM(LLM):
      9     model_name = &quot;google/flan-t5-large&quot;
     10     pipeline = pipeline(&quot;text2text-generation&quot;, model=model_name, device=0, model_kwargs={&quot;torch_dtype&quot;:torch.bfloat16})

&lt;ipython-input-1-f2d62b66882b&gt; in customLLM()
      8 class customLLM(LLM):
      9     model_name = &quot;google/flan-t5-large&quot;
---&gt; 10     pipeline = pipeline(&quot;text2text-generation&quot;, model=model_name, device=0, model_kwargs={&quot;torch_dtype&quot;:torch.bfloat16})
     11 
     12     def _call(self, prompt, stop=None):

~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/__init__.py in pipeline(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)
    868         kwargs[&quot;device&quot;] = device
    869 
--&gt; 870     return pipeline_class(model=model, framework=framework, task=task, **kwargs)

~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/text2text_generation.py in __init__(self, *args, **kwargs)
     63 
     64     def __init__(self, *args, **kwargs):
---&gt; 65         super().__init__(*args, **kwargs)
     66 
     67         self.check_model_type(

~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/base.py in __init__(self, model, tokenizer, feature_extractor, modelcard, framework, task, args_parser, device, binary_output, **kwargs)
    776         # Special handling
    777         if self.framework == &quot;pt&quot; and self.device.type != &quot;cpu&quot;:
--&gt; 778             self.model = self.model.to(self.device)
    779 
    780         # Update config with task specific parameters

~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py in to(self, *args, **kwargs)
   1680             )
   1681         else:
-&gt; 1682             return super().to(*args, **kwargs)
   1683 
   1684     def half(self, *args):

~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py in to(self, *args, **kwargs)
   1143             return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
   1144 
-&gt; 1145         return self._apply(convert)
   1146 
   1147     def register_full_backward_pre_hook(

~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py in _apply(self, fn)
    795     def _apply(self, fn):
    796         for module in self.children():
--&gt; 797             module._apply(fn)
    798 
    799         def compute_should_use_set_data(tensor, tensor_applied):

~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py in _apply(self, fn)
    818             # `with torch.no_grad():`
    819             with torch.no_grad():
--&gt; 820                 param_applied = fn(param)
    821             should_use_set_data = compute_should_use_set_data(param, param_applied)
    822             if should_use_set_data:

~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py in convert(t)
   1141                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,
   1142                             non_blocking, memory_format=convert_to_format)
-&gt; 1143             return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
   1144 
   1145         return self._apply(convert)

~/Library/Python/3.9/lib/python/site-packages/torch/cuda/__init__.py in _lazy_init()
    237                 &quot;multiprocessing, you must use the 'spawn' start method&quot;)
    238         if not hasattr(torch._C, '_cuda_getDeviceCount'):
--&gt; 239             raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)
    240         if _cudart is None:
    241             raise AssertionError(

AssertionError: Torch not compiled with CUDA enabled
</code></pre>
<p>Obviously I've no Nvidia card, but I've read Pytorch is now supporting Mac M1 as well</p>
<p>I'm trying to run the below example:</p>
<pre><code>from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTListIndex,GPTSimpleVectorIndex, PromptHelper
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from llama_index import LLMPredictor, ServiceContext
import torch
from langchain.llms.base import LLM
from transformers import pipeline

class customLLM(LLM):
    model_name = &quot;google/flan-t5-large&quot;
    pipeline = pipeline(&quot;text2text-generation&quot;, model=model_name, device=0, model_kwargs={&quot;torch_dtype&quot;:torch.bfloat16})

    def _call(self, prompt, stop=None):
        return self.pipeline(prompt, max_length=9999)[0][&quot;generated_text&quot;]
 
    def _identifying_params(self):
        return {&quot;name_of_model&quot;: self.model_name}

    def _llm_type(self):
        return &quot;custom&quot;


llm_predictor = LLMPredictor(llm=customLLM())
</code></pre>
<p><strong>Question #2:</strong></p>
<p>Assuming the answer for the above is no - I don't mind using Google Colab with GPU, but once the index will be made, will it be possible to download it and use it on my Mac?</p>
<p>i.e. something like:</p>
<p>on Google Colab:</p>
<pre><code>service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)
index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)
index.save_to_disk('index.json')
</code></pre>
<p>... and later on my Mac use <code>load_from_file</code></p>
","2023-04-10 17:46:58","2","Question"
"75973323","75972052","","<p>In Numpy this is effectively</p>
<pre><code>w = x.dot(y) / x.dot(x)
</code></pre>
<p>Both inner products are best represented as dot-products.</p>
","2023-04-09 23:09:46","0","Answer"
"75972182","75972052","","<p><a href=""https://i.sstatic.net/GqDle.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/GqDle.png"" alt=""enter image description here"" /></a></p>
<p>Looks like this term is a scalar value. I assume <code>n</code> is number of examples.</p>
","2023-04-09 18:19:30","2","Answer"
"75972052","","Correctly implementing specific formula into python","<p>This may be more of a math question, rather than a programing question but I am absolutely stuck and the problem occured to me while implementing it in python via <code>numpy</code>.
So, in my Machine Learning course the professor constructed an estimator for <code>Linear Regression</code> which resulted into the following equation for finding the <code>weight vector</code> with the labels <code>y</code> and data <code>x</code>:</p>
<img src=""https://latex.codecogs.com/svg.image?%5Cwidetilde%7B%5Comega%7D&space;&space;=&space;%5Cleft&space;(&space;&space;%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Cwidetilde%7Bx%7D%5E%7B(i)%7D[%5Cwidetilde%7Bx%7D%5E%7Bi%7D]%5ET&space;%5Cright&space;)%5E%7B-1%7D&space;%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Cwidetilde%7Bx%7D%5E%7B(i)%7Dy%5E%7B(i)%7D"" title=""https://latex.codecogs.com/svg.image?\widetilde{\omega} = \left ( \sum_{i=1}^{n}\widetilde{x}^{(i)}[\widetilde{x}^{i}]^T \right )^{-1} \sum_{i=1}^{n}\widetilde{x}^{(i)}y^{(i)}"" />
<p>As I understood it for the first part of the equation, I should just multiply the <code>vector x</code> with the <code>vector x transposed</code>. This results into a <code>matrix</code> which I should take the <code>inverse</code> from. Unfortunately taking the <code>inverse</code> isn't possible because the resulting matrix has a <code>determinant with the value of 0</code>. The way I understand it is that no matter how I change the x-vector, the equation will always result in a determinant with a value of zero.</p>
<p>Could it be that I am interpreting the equation in a wrong way? Or that I shouldn't do the calculation on a whole vector but rather run through the equation with every single datapoint iteratively (Imo it wouldn't make sense to transpose a single x value). So I'm not sure about that.</p>
<p>In Python code I had the equation as follows: <code>a = (np.linalg.inv(x * x.reshape(-1,1)))*(x*y)</code></p>
<p>With x and y being simple <code>numpy arrays</code>, it throws the following Error: <code>LinAlgError: Singular matrix</code>.</p>
","2023-04-09 17:59:33","0","Question"
"75963120","75962760","","<p>have you tried reshaping the input data?</p>
<p><code>facial_training_set = np.array(facial_training_set).reshape((-1, 48, 48, 1))</code>
<code>facial_testing_set = np.array(facial_testing_set).reshape((-1, 48, 48, 1))</code></p>
","2023-04-08 03:06:39","0","Answer"
"75962781","75962760","","<pre><code>face_model = Sequential()
input_shape_face = (48, 48, 1)
face_model.add(input_layer.Input(shape=input_shape_face))
face_model.add(Conv2D(8, kernel_size=(3, 3), padding='same', activation='LeakyReLU'))
face_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
face_model.add(Conv2D(16, kernel_size=(3, 3), padding='same', activation='LeakyReLU'))
face_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
face_model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='LeakyReLU'))
face_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
face_model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='LeakyReLU'))
face_model.add(Flatten())
face_model.add(Dense(128, activation='LeakyReLU'))
face_model.add(Dense(6, activation='softmax'))

face_model.summary()
</code></pre>
<p>Try this if it works! I guess the input shape is not compatible.</p>
","2023-04-08 00:47:31","0","Answer"
"75962760","","Trouble with incompatible layers CNN","<p>I'm attempting to fit() my CNN model and I am having issues with layers working together.</p>
<pre><code>from keras.engine import input_layer
from keras.models import Sequential
from keras.layers import Dense , Activation , Dropout ,Flatten, BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D

# The model is as follows...

face_model = Sequential()
input_shape_face = (48, 48, 1)
face_model.add(Conv2D(8, kernel_size= (3, 3), input_shape = input_shape_face, padding= 'same', activation = 'LeakyReLU'))
face_model.add(MaxPooling2D(pool_size = (2, 2), padding= 'same'))
face_model.add(Conv2D(16, kernel_size= (3, 3), padding= 'same', activation = 'LeakyReLU'))
face_model.add(MaxPooling2D(pool_size = (2, 2), padding= 'same'))
face_model.add(Conv2D(32, kernel_size= (3, 3), padding= 'same', activation = 'LeakyReLU'))
face_model.add(MaxPooling2D(pool_size = (2, 2),  padding= 'same'))
face_model.add(Conv2D(64, kernel_size= (3, 3), padding= 'same', activation = 'LeakyReLU'))
face_model.add(Flatten())
face_model.add(Dense(128, activation = 'LeakyReLU'))
face_model.add(Dense(6, activation = 'softmax'))


face_model.summary()
</code></pre>
<p>Summary of my layers:</p>
<pre><code>Model: &quot;sequential_34&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_92 (Conv2D)          (None, 48, 48, 8)         80        
                                                                 
 max_pooling2d_69 (MaxPoolin  (None, 24, 24, 8)        0         
 g2D)                                                            
                                                                 
 conv2d_93 (Conv2D)          (None, 24, 24, 16)        1168      
                                                                 
 max_pooling2d_70 (MaxPoolin  (None, 12, 12, 16)       0         
 g2D)                                                            
                                                                 
 conv2d_94 (Conv2D)          (None, 12, 12, 32)        4640      
                                                                 
 max_pooling2d_71 (MaxPoolin  (None, 6, 6, 32)         0         
 g2D)                                                            
                                                                 
 conv2d_95 (Conv2D)          (None, 6, 6, 64)          18496     
                                                                 
 flatten_8 (Flatten)         (None, 2304)              0         
                                                                 
 dense_57 (Dense)            (None, 128)               295040    
                                                                 
 dense_58 (Dense)            (None, 6)                 774       
                                                                 
=================================================================
Total params: 320,198
Trainable params: 320,198
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<pre><code># Compiling the model

face_model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy'])

face_model.fit(facial_training_set, batch_size= batch_size, epochs= epochs, verbose= 1, validation_data= facial_testing_set)
</code></pre>
<p>The error I am recieving:</p>
<pre><code>/usr/local/lib/python3.9/dist-packages/keras/engine/training.py in tf__train_function(iterator)
     13                 try:
     14                     do_return = True
---&gt; 15                     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
     16                 except:
     17                     do_return = False

ValueError: in user code:

    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 1284, in train_function  *
        return step_function(self, iterator)
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 1249, in run_step  **
        outputs = model.train_step(data)
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/training.py&quot;, line 1050, in train_step
        y_pred = self(x, training=True)
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py&quot;, line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File &quot;/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py&quot;, line 280, in assert_input_compatibility
        raise ValueError(

    ValueError: Exception encountered when calling layer 'sequential_34' (type Sequential).
    
    Input 0 of layer &quot;dense_57&quot; is incompatible with the layer: expected axis -1 of input shape to have value 2304, but received input with shape (48, 384)
    
    Call arguments received by layer 'sequential_34' (type Sequential):
      • inputs=tf.Tensor(shape=(48, 48, 1), dtype=float32)
      • training=True
      • mask=None
</code></pre>
","2023-04-08 00:35:45","0","Question"
"75962580","75951962","","<p>Before that, have you tried to exclude some columns from your input data? This can be done in SQL by using the except() command or you can simply only include the features you care about.</p>
<pre><code>SELECT * EXCEPT



WITH orders AS
  (SELECT 5 as order_id,
  &quot;sprocket&quot; as item_name,
  200 as quantity)
SELECT * EXCEPT (order_id)
FROM orders;

/*-----------+----------*
 | item_name | quantity |
 +-----------+----------+
 | sprocket  | 200      |
 *-----------+----------*/
</code></pre>
<p>Trying to tune down the max_tree_depth or using early stop might also help.</p>
","2023-04-07 23:27:56","-1","Answer"
"75951962","","ML Model on BigQuery Aborts due to Max Session Time Limit","<p>I'm trying to create a BQ ML Model that Aborts pre-maturely due to the Max Session Time Limit constraint of 30 minutes on the Project I'm executing under.</p>
<p>Is there some way to create this Model in chunks/sections so that it doesn't abort due to time constraints? Either by reducing the number of columns selected (460 columns) or the numbers of rows (~1 Million) or tweak any parameters in the OPTIONS section?</p>
<p>These are the OPTIONS I'm selecting while creating the Model:</p>
<pre><code>model_type = 'BOOSTED_TREE_CLASSIFIER',
data_split_method = 'SEQ',
data_split_eval_fraction = 0.2,
data_split_col = 'DATE_COL',

booster_type = 'GBTREE',
max_iterations = 50, 
early_stop = false,
subsample = 0.8,
MIN_TREE_CHILD_WEIGHT = 1000,
COLSAMPLE_BYTREE = 0.3,
MAX_TREE_DEPTH = 6,
SUBSAMPLE = 0.7,

input_label_cols = ['COLx']
</code></pre>
","2023-04-06 16:53:20","0","Question"
"75942627","75942327","","<p>It's hard to tell without example input data, but you may be inducing a single output result (likely, the majority class) due to the model being unable to extract any meaningful correlations between the input and targets.</p>
<p>Based on your problem and input shape, it appears your inputs are integer encoded sentences or other blocks of text (the last dimension of your input is 1, indicating a scalar representation of tokens). Unless the tokens are derived from some pretrained model/ scalar embedding space, it's difficult to see how a CNN model could learn anything of use from arbitrary integer token assignments.</p>
<p>If this is the case, you may have better results by inserting an embedding layer between your Input layer and the first convolutional layer.
(See: <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding</a>)</p>
<p>To do this, you'll need to know the vocabulary size (number of unique integers across all samples) in your input/training corpus. You may wish to set the output dimension to a non-scalar value, (likely a multiple 8 to make efficient use of GPUs).</p>
<p>Side note -- generally speaking, convolutional architectures start with larger kernel sizes, and gradually decrease them relative to layer depth. This is because the receptive field of each convolution naturally increases each time a convolution is applied.</p>
","2023-04-05 17:52:51","0","Answer"
"75942397","75942327","","<p>Your code is not easy to compile since it is not complete but you can try using class weights and give importance to minority class in training something like this:</p>
<pre><code>from sklearn.utils import class_weight

#Use balanced to show we want to balance the weights based on the number of samples in each class.
class_weights = compute_class_weight(
                                        class_weight = &quot;balanced&quot;,
                                        classes = np.unique(y_train),
                                        y = y_train
                                    )
class_weights = dict(zip(np.unique(y_train), class_weights))

# Fit the model
history_cnn=model_cnn.fit(x_train, y_train, epochs=50, batch_size=16, validation_data=(x_test, y_test), class_weight=class_weights)
</code></pre>
","2023-04-05 17:26:27","0","Answer"
"75942327","","Underfitting in CNN model","<p>I am machine learning beginner and making a CNN model for binary text classification into 0 and 1 but model always predicts 0 or always predict 1. Used dataset size is 22000 and dataset is labeled with &quot;0 and 1&quot;.
preprocessed dataset is as:
<a href=""https://i.sstatic.net/xWCsS.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/xWCsS.png"" alt=""enter image description here"" /></a>
Code:</p>
<pre><code>from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout

model_cnn = Sequential()
model_cnn.add(Conv1D(filters=64, kernel_size=2, strides=1, activation='relu',input_shape=(x_train.shape[1],1)))
model_cnn.add(MaxPooling1D())
model_cnn.add(Conv1D(filters=128, kernel_size=4, strides=2, activation='linear'))
model_cnn.add(MaxPooling1D())
model_cnn.add(Conv1D(filters=256, kernel_size=6, strides=3, activation='sigmoid'))
model_cnn.add(MaxPooling1D())
model_cnn.add(Conv1D(filters=356, kernel_size=8, strides=4, activation='linear'))
model_cnn.add(Flatten())
model_cnn.add(Dense(512, activation='relu'))
model_cnn.add(Dropout(0.2))
model_cnn.add(Dense(256, activation='relu'))
model_cnn.add(Dropout(0.2))
model_cnn.add(Dense(1, activation='sigmoid'))

model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model_cnn.summary()
from scipy import sparse
x_train = sparse.csr_matrix((x_train), dtype=np.int8, shape = (x_train.shape[0], x_train.shape[1])).toarray()
x_test = sparse.csr_matrix((x_test), dtype=np.int8, shape = (x_test.shape[0], x_test.shape[1])).toarray()
history_cnn=model_cnn.fit(x_train, y_train, epochs=50, batch_size=16, validation_data=(x_test, y_test))
</code></pre>
<p>Is there a way to eliminate or reduce under sampling?</p>
","2023-04-05 17:18:30","0","Question"
"75933494","75928974","","<p>If I understand correctly, you would like to filter out stringified ints which end in <code>'0'</code> (the int is a multiple of 10), AND when stripped of trailing 0's, is of length 2+ and is a substring of <code>'123456789'</code>?</p>
<p>If so, I believe this will work:</p>
<pre><code>from pandas import DataFrame, Series

# Some test data
df = DataFrame({
    'i': [
        1,
        10,
        11,
        12,
        120, # Dropped
        122,
        123,
        1230, # Dropped
        12300, # Dropped
        1240,
        13,
        130,
        134,
        1340,
        2,
        20,
        21,
        210,
        2120,
        23,
        230, # Dropped
        2340, # Dropped
        234000, # Dropped
        2350,
        123456789,
        1234567890 # Dropped
    ]})

filt = Series(s.endswith('0') and len(s.rstrip('0')) &gt; 1 and s.rstrip('0') in '123456789' for s in df['i'].astype(str))

filtered_df = df.loc[~filt]
</code></pre>
<p>You could split the logic up to make it more readable, and string filters together with the <code>&amp;</code> operator:</p>
<pre><code>stringified = df['i'].astype(str)

filt_1 = Series(s.endswith('0') for s in stringified)
filt_2 = Series(len(s.rstrip('0')) &gt; 1 for s in stringified)
filt_3 = Series(s.rstrip('0') in '123456789' for s in stringified)

filtered_df = df.loc[~(filt_1 &amp; filt_2 &amp; filt_3)]
</code></pre>
<p>(There may also be ways to make the filtering more efficient)</p>
","2023-04-04 20:16:03","0","Answer"
"75929006","75928974","","<p>You can use a list comprehension:</p>
<pre><code>consecutive = '123456789'

m = [not (s.endswith('0') and s.rstrip('0') in consecutive)
     for s in df['prix'].astype(str)]

out = df[m]
</code></pre>
<p>Output:</p>
<pre><code>    prix
1  12378
2  12345
</code></pre>
<p>How this works:</p>
<pre><code>consecutive = '123456789'

df['keep'] = [not(s.endswith('0') and s.rstrip('0') in consecutive)
              for s in df['prix'].astype(str)]

print(df)
</code></pre>
<p>Output:</p>
<pre><code>     prix   keep
0  123450  False
1   12378   True
2   12345   True
3   45670  False
</code></pre>
<p>Reproducible input:</p>
<pre><code>df = pd.DataFrame({'prix': [123450, 12378, 12345, 45670]})
</code></pre>
<h4>2 digits numbers</h4>
<p>If you want to keep 2 digits numbers such as <code>20</code>:</p>
<pre><code>consecutive = '123456789'

m1 = np.array([not(s.endswith('0') and s.rstrip('0') in consecutive)
               for s in df['prix'].astype(str)])
m2 = df['prix'].lt(100)

out = df[m1|m2]
</code></pre>
<p>Or:</p>
<pre><code>m = [not (s.endswith('0') and len(s) &gt; 2 and s.rstrip('0') in consecutive)
     for s in df['prix'].astype(str)]

out = df[m]
</code></pre>
<p>Output:</p>
<pre><code>    prix
1  12378
2  12345
4     20
</code></pre>
<p>Used input:</p>
<pre><code>df = pd.DataFrame({'prix': [123450, 12378, 12345, 45670, 20]})
</code></pre>
","2023-04-04 11:47:55","2","Answer"
"75928974","","how to remove consecutive digits from a df","<p>I want to remove rows which contains consecutive digits in a df and at the end a 0 such as 12340 or 45670. I tried this code but nothing changed</p>
<pre><code>rows_to_remove = []
for i, row in df.iterrows():
    digits = [int(d) for d in str(row['prix'])]
    if all([digits[j+1]-digits[j] == 1 for j in range(len(digits)-1)]) and digits[-1] == 0:
        rows_to_remove.append(i)

df = df.drop(rows_to_remove)
</code></pre>
","2023-04-04 11:45:11","0","Question"
"75925642","75924736","","<p>You can add <code>type = &quot;class&quot;</code> within <code>predict</code> function to have the class names. You have not provided any data, so I am using <code>iris</code> data like</p>
<pre><code>library(nnet) 
library(NeuralNetTools)

#training model on training dataset
nnet_model &lt;- nnet(Species~. ,size=10,data=iris, maxit=1500)
#generating predictions
nnet_prediction &lt;- predict(nnet_model, iris, type = &quot;class&quot;)
</code></pre>
","2023-04-04 04:56:30","1","Answer"
"75924752","75924736","","<p>Use <code>max.col</code>:</p>
<pre><code>colnames(nnet_prediction_prob)[max.col(nnet_prediction_prob)]
[1] &quot;Red&quot; &quot;Red&quot; &quot;Red&quot;
</code></pre>
","2023-04-04 00:59:29","2","Answer"
"75924736","","Converting neural net probablities into predictions in R","<p>Excuse me for my ignorance, as I am learning the theory behind models and in this case neural nets. I trying to train a model using the <code>library(nnet) library(NeuralNetTools)</code> packages.</p>
<p>For example, if my code was:</p>
<pre><code>#training model on training dataset
nnet_model &lt;- nnet(Morphology~. ,size=10,data=morph_scaled_train, maxit=1500)
#generating predictions
nnet_prediction_prob &lt;- predict(nnet_model,morph_test)
</code></pre>
<p>This gives the prediction output as numbers. I.e.</p>
<pre><code>         Blue           Red           Green       Yellow
1   1.020685e-180  1.000000e+00 4.496185e-255 4.079526e-254
2   1.020685e-180  1.000000e+00 4.496185e-255 4.079526e-254
3   1.020685e-180  1.000000e+00 4.496185e-255 4.079526e-254
</code></pre>
<p>How could I convert this to a factor i.e. Row 1 is Red, row 2 is blue for example ... Giving the overall prediction. When I use predict function for other models e.g. random forest, logistic regression, it gives it as the overall prediction and not numbers, and this is what I wish for nnets. Is this possible? Or just the way the model works this cannot be interpreted. Thanks!</p>
","2023-04-04 00:56:04","1","Question"
"75918536","","Scikit-Learn LOOCV vs doing it manually give different results, why?","<p>So i have built a model for a small dataset and since it was a small dataset, i made a Leave-One-out Cross-Validation (LOOCV) check for its accuracy. so in short, i would remove one sample manually, train the model, predict the left out sample and save the prediction and repeat the process for all the samples. then i would use the list of predictions and the actual values to get a RMSE and R2.
and today i found out that there was a Scikit-Learn implementation <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html"" rel=""nofollow noreferrer"">sklearn.model_selection.LeaveOneOut</a>, however, when i tried it, it gave me different results for the RMSE, and refused to use R-squared as accuracy in the LOOCV method (it seems to calculate the accuracy per sample which does not work with R2).</p>
<p>here is a brief example of the code:</p>
<pre><code>from numpy import mean
from numpy import std
from sklearn.datasets import make_blobs
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

cv = LeaveOneOut()
model = RandomForestRegressor(n_estimators=200, max_depth=6,n_jobs=40, random_state=0)

scores = cross_val_score(model, data2SN, labelCL, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))
</code></pre>
<p>my guess is that I'm calculating the RMSE for the whole dataset, while the LOOCV is doing it per sample and eventually i would take the mean and this is what causes the discrepancy between the two codes output, however, when i tried to calculate the RMSE per sample it failed (citing this TypeError: Singleton array 3021.0 cannot be considered a valid collection).   so I'm not sure how the RMSE is calculated inside the LOOCV. and I'm not sure to trust my code or just blindly use scikit-learn implementation.<br />
I'm lost at what to do and chatGPT was just confusing as hell, so my human brethren please help</p>
","2023-04-03 10:38:08","0","Question"
"75918458","75917795","","<blockquote>
<p>&quot;But both these solutions will break next time you fetch <strong>an updated
dataset</strong>&quot;</p>
</blockquote>
<p>The key part of the quoted text is highlighted. An updated dataset is not the same as the original dataset.</p>
<p>If you have set the same random seed then <code>np.random.permutation()</code> should return the same permutation of numbers, however the data is not the same so you are not going to get the same train/test split. You could use different datasets each with an identical number of rows, and they will be split on the same indices.</p>
<p>A hash function generates a number for a given input. Instead of using the number of rows in the dataset, the function can generate a value which could be used as an index to identify each row of the dataset. You could then use the index to perform the train/test split.</p>
<p>You choose the point in the index at which to split the data and so long as you keep this the same then the data will be consistent.</p>
<p>This gives you the certainty that if you update the dataset, then using a hash function will ensure that the original data will still have the same hash value and so won't move between the training and testing set. Any new data will be added to the training or testing set depending on the generated hash value.</p>
<p>You may need to perform an additional piece of work if the dataset does not contain a unique identifier for use in the hash function.</p>
","2023-04-03 10:28:08","0","Answer"
"75918016","75917795","","<p>First of all it makes sense, that the algorithm won't get a glimpse of <em>all</em> the data, otherwise a test split would be obsolete, as you well understood.</p>
<p>So all these arguments address the case, that the program is run more than once. This could happen, for example, if the user will re-run the training, or further trains a pre-trained network. If such thing happens we need to make sure that the test-split remains hidden. The test data is used to compare different models, so if two models are evaluated on different test data, they cannot be compared in proper way. Please also note that people usually make a difference between train, test AND validation data...</p>
<p>Therefore, it is a bad idea to make a random split every time.</p>
<p>Alternatively he suggests to make a &quot;deterministic&quot; random split by using a seed. Setting the seed to the same value every time the program start, it will create the same sequence of random numbers, which is good. However, if the order of the data changes, for example, the file names change or are unordered in the first place, a deterministic sequence of &quot;random&quot; numbers won't address the issue anymore.</p>
<p>He then suggests that a test split could be saved separately to disc to prevent splitting the data more than once. This is a good work-around for the random-number issue.</p>
<p>However, when new data is available that has a new species, a new split needs to be created that also contains, say birds. If the pre-trained dog-cat network is now fine-tuned it is not guaranteed that a new naive split will leak old training data to the new test data set and therefore make you believe your model is better than it actual is.</p>
<p>I think the author wants to warn the reader, that these things happen easier than you expect and wants the reader to think about what will or can happen when a network is fine-tuned on new data or when updating training and test data. When you are aware of this you will always find a way to merge new data without causing trouble.</p>
","2023-04-03 09:39:47","0","Answer"
"75917795","","Why does the author advise against using random.seed in Hands on machine learning book?","<p>I've been reading Hands on machine learning with scikit-learn, keras, ... by Aurélien Géron (2nd edition) and on pages 54-55 he discusses the steps to creating a test set.</p>
<p>He uses numpy's random.permutation method, but says that this has an issue i. e. everytime we run this program it will create a different test set and eventually our algorithm will see the entire set which isn't good so he says to either generate the dataset once and load it everytime after that or just use numpy's random.seed to get the same instance everytime.</p>
<p>This is the code for the numpy method:</p>
<pre><code>import numpy as np
def split_train_test(data, test_ratio):
    shuffled_indices = np.random.permutation(len(data))
    test_set_size = int(len(data) * test_ratio)
    test_indices = shuffled_indices[:test_set_size]
    train_indices = shuffled_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]
</code></pre>
<p>Further he says that &quot;But both these solutions will break next time you fetch an updated dataset&quot;, now I understand that will be the case with the save once and load method. But I don't understand why that would be the case with the numpy method, as it is creating the test set from the input data set, so if we provide it the updated data set everytime, any changes in the original data set should persist right?</p>
<p>And I've also read an article as to why it's bad to use the numpy.random's global seed and instead we should use a generator instance's method which makes sense.</p>
<p>But I'm still struggling to understand the author's reasoning as to why both methods would break and why he has gone onto create test set using hashing and stuff</p>
","2023-04-03 09:12:46","-2","Question"
"75911541","75883084","","<p>I recently have a similar issue. It is it probably a compatibility issue between keras and tensorflow. A temporary solution is to use the <code>tensorflow.python</code> module, (although it is experimental, it should suffice a small machine learning project).</p>
<pre><code>import tensorflow as tf
from tensorflow.python.keras import layers
from tensorflow.python.keras.models import Sequential
</code></pre>
<p>Sequential is imported so you can directly use it.</p>
","2023-04-02 10:45:48","2","Answer"
"75909446","75208167","","<p>I just tried this:</p>
<pre><code>conda install scikit-learn=1.1
</code></pre>
<p>and it &quot;seems&quot; to have succeeded.  That is, the 01-introduction.ipynb notebook runs to completion.  There are a few FutureWarnings starting at In [28]:, but I can accept those.  When I finish the book I'll upgrade scikit-learn and avoid load_boston()</p>
","2023-04-01 23:50:47","0","Answer"
"75909423","75906819","","<p>scaling would help without changing lr</p>
<pre><code># X_pandas = bg['temp']
# y_pandas = bg['atemp']

data_x = data_x/data_x.max()
data_y = data_y

# covert to tensors
# data_x = X_pandas.head(100).values
# data_y = y_pandas.head(100).values
X = torch.tensor(data_x, dtype=torch.float32).reshape(-1, 1)
y = torch.tensor(data_y, dtype=torch.float32).reshape(-1, 1)

# create the model
model = nn.Linear(1, 1)
loss_fn = nn.MSELoss()  # mean square error
optimizer = optim.SGD(model.parameters(), lr=0.01)

# train the model
n_epochs = 40   # number of epochs to run
for epoch in range(n_epochs):
    # forward pass
    y_pred = model(X)
    # compute loss
    loss = loss_fn(y_pred, y)
    # backward pass
    loss.backward()
    # update parameters
    optimizer.step()
    # zero gradients
    optimizer.zero_grad()
    # print loss
    print(f'epoch: {epoch + 1}, loss = {loss.item():.4f}')

# display the predicted values
predicted = model(X).detach().numpy()
display(predicted)

epoch: 1, loss = 210.4702
epoch: 2, loss = 198.8098
epoch: 3, loss = 187.8156
epoch: 4, loss = 177.4496
epoch: 5, loss = 167.6758
epoch: 6, loss = 158.4604
epoch: 7, loss = 149.7714
epoch: 8, loss = 141.5789
epoch: 9, loss = 133.8544
epoch: 10, loss = 126.5711
epoch: 11, loss = 119.7039
epoch: 12, loss = 113.2290
epoch: 13, loss = 107.1239
epoch: 14, loss = 101.3676
epoch: 15, loss = 95.9400
epoch: 16, loss = 90.8225
epoch: 17, loss = 85.9972
epoch: 18, loss = 81.4475
epoch: 19, loss = 77.1577
epoch: 20, loss = 73.1128
epoch: 21, loss = 69.2989
epoch: 22, loss = 65.7028
epoch: 23, loss = 62.3120
epoch: 24, loss = 59.1148
epoch: 25, loss = 56.1002
epoch: 26, loss = 53.2576
epoch: 27, loss = 50.5773
epoch: 28, loss = 48.0500
epoch: 29, loss = 45.6670
epoch: 30, loss = 43.4200
epoch: 31, loss = 41.3012
epoch: 32, loss = 39.3033
epoch: 33, loss = 37.4193
epoch: 34, loss = 35.6429
epoch: 35, loss = 33.9678
epoch: 36, loss = 32.3883
epoch: 37, loss = 30.8988
epoch: 38, loss = 29.4943
epoch: 39, loss = 28.1699
epoch: 40, loss = 26.9209
array([[ 8.267589 ],
       [ 8.287247 ],
       [ 8.562464 ],
       [ 8.837682 ],
       [ 9.0342655],
       [ 9.191533 ],
       [ 9.211191 ],
       [ 9.250508 ],
       [ 9.250508 ],
       [ 9.250508 ],
       [ 9.171875 ],
       [ 9.014607 ],
       [ 8.935974 ],
       [ 8.876999 ],
       [ 8.876999 ],
       [ 8.85734  ],
       [ 8.798365 ],
       [ 8.719731 ],
       [ 8.719731 ],
       [ 8.680414 ],
       [ 8.582123 ],
       [ 8.464172 ],
       [ 8.385539 ],
       [ 8.36588  ],
       [ 8.444513 ],
       [ 8.739389 ],
       [ 8.994949 ],
       [ 9.171875 ],
       [ 9.270166 ],
       [ 9.368459 ],
       [ 9.407776 ],
       [ 9.407776 ],
       [ 9.427434 ],
       [ 9.368459 ],
       [ 9.250508 ],
       [ 8.994949 ],
       [ 8.680414 ],
       [ 8.326564 ],
       [ 8.090663 ],
       [ 8.012029 ],
       [ 8.012029 ],
       [ 8.031688 ],
       [ 8.071004 ],
       [ 8.012029 ],
       [ 7.9530535],
       [ 7.7761283],
       [ 7.6385193],
       [ 7.4615936],
       [ 7.520569 ],
       [ 8.090663 ],
       [ 8.562464 ],
       [ 8.916315 ],
       [ 9.171875 ],
       [ 9.348801 ],
       [ 9.486409 ],
       [ 9.5650425],
       [ 9.60436  ],
       [ 9.584702 ],
       [ 9.407776 ],
       [ 9.073583 ],
       [ 8.798365 ],
       [ 8.641098 ],
       [ 8.48383  ],
       [ 8.385539 ],
       [ 8.287247 ],
       [ 8.24793  ],
       [ 8.188955 ],
       [ 8.149638 ],
       [ 8.071004 ],
       [ 8.012029 ],
       [ 7.9333954],
       [ 7.87442  ],
       [ 7.9923706],
       [ 8.503489 ],
       [ 8.935974 ],
       [ 9.309484 ],
       [ 9.643677 ],
       [ 9.918894 ],
       [10.095819 ],
       [10.21377  ],
       [10.233429 ],
       [10.154795 ],
       [ 9.899236 ],
       [ 9.525726 ],
       [ 9.23085  ],
       [ 9.0342655],
       [ 8.85734  ],
       [ 8.719731 ],
       [ 8.601781 ],
       [ 8.523148 ],
       [ 8.464172 ],
       [ 8.424855 ],
       [ 8.405197 ],
       [ 8.405197 ],
       [ 8.405197 ],
       [ 8.444513 ],
       [ 8.562464 ],
       [ 8.97529  ],
       [ 9.388117 ],
   [ 9.72231  ]], dtype=float32)
</code></pre>
","2023-04-01 23:40:39","1","Answer"
"75908800","","Detect Hand Orientation (Rotation) in a video","<p>I want to detect the rotation of my hand in a video, but I still don't know how to correctly do it.</p>
<p>I tried to use PCA method but it only works for images only not videos.
I can detect the hand and its landmarks correctly</p>
","2023-04-01 20:54:44","0","Question"
"75907887","75907378","","<pre><code>model.add(LSTM(lstm_out1, Dropout(0.2), Dropout(0.2)))
</code></pre>
<p>this Dropout layers do not look correct. I think you should use dropout=0.2,
recurrent_dropout=0.2. Refer the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM</a>.</p>
<p>Also, your embedding initialisation could contain nan values in weights=[embed_matrix]</p>
","2023-04-01 17:47:35","1","Answer"
"75907604","75907378","","<p>But why are you using binary_crossentropy? You have 2 output neurons. It's strange that you have sigmoid activation with 2 output neurons.
In this case you have 2 options:</p>
<ol>
<li><p>You can use sparse_categorical_crossentropy (or categorical_crossentropy depending if you have one_hot) with 2 output neurons and with softmax activation.</p>
</li>
<li><p>You can use binary_crossentropy with only 1 output neuron and with sigmoid activation.</p>
</li>
</ol>
<p>I guess that was the mistake.</p>
<p>Edit:
I am going to give you a working example based on your code so you can compare.</p>
<pre><code>x_train = np.random.randint(0, 100, (1000, 10))
y_train = np.random.randint(0, 2, (1000,))

vocab_size = 100
embed_dim = 10
max_tweet_len = 10

model = keras.models.Sequential()
model.add(layers.Embedding(vocab_size, embed_dim, input_length=max_tweet_len, trainable=False))
model.add(layers.LSTM(10, dropout=0.2, recurrent_dropout=0.2))
#model.add(MaxPooling1D(2))
model.add(layers.Dense(64, activation='relu'))

model.add(layers.Dense(1, activation='sigmoid'))

opt = keras.optimizers.Adam(learning_rate=0.001)
  
model.compile(loss='binary_crossentropy',
                  optimizer=opt,
                  metrics=['accuracy'])

model.fit(x_train, y_train, epochs=10, batch_size=32)
</code></pre>
","2023-04-01 16:54:39","1","Answer"
"75907378","","Why does LSTM produce NaN losses?","<p>I'm implementing my LSTM model for sarcasm detection (binary). I wrote the following code:</p>
<pre><code>model = Sequential()
model.add(Embedding(vocab_size, embed_dim,
          weights=[embed_matrix], input_length=max_tweet_len, trainable=False))
model.add(LSTM(lstm_out1, Dropout(0.2), Dropout(0.2)))
#model.add(MaxPooling1D(2))
model.add(Dense(64, activation='relu'))

model.add(Dense(1, activation='sigmoid'))

opt = Adam(learning_rate=0.001)
  
model.compile(loss='binary_crossentropy',
                  optimizer=opt,
                  metrics=['accuracy'])
</code></pre>
<p>My model predicts NaNs.</p>
<pre><code>[[nan nan]
 [nan nan]
 [nan nan]
 ...
 [nan nan]
 [nan nan]
 [nan nan]]
</code></pre>
<p>Why is it happening? My input dimension is (75830, 79). I've checked for missing values/nans. No such anomaly in data. I used this code. In all cases code returned false.</p>
<pre><code>check_nan = df['is_sarcastic'].isnull().values.any()
print(check_nan)
check_na = df['is_sarcastic'].isna().values.any()
print(check_na)
check_nan_ = df['tweet_text'].isnull().values.any()
print(check_nan_)
check_na_ = df['tweet_text'].isna().values.any()
print(check_na_)
</code></pre>
<p><strong>Edit</strong></p>
<ol>
<li>Used grad clipping</li>
<li>smaller learning rate</li>
</ol>
<p>Still NaN loss.</p>
","2023-04-01 16:15:32","0","Question"
"75906871","75906819","","<p>It seems that my problem was that learning rate of 0.01 was too high for this problem and the amount of data.</p>
<p>Changing this bit fixed the issue:</p>
<p><code>optimizer = optim.SGD(model.parameters(), lr=0.01)</code></p>
<p>to</p>
<p><code>optimizer = optim.SGD(model.parameters(), lr=0.005)</code></p>
","2023-04-01 14:35:46","1","Answer"
"75906819","","Simple linear regression in pyTorch - why loss is increasing with each epoch?","<p>I'm trying to make a simple linear regression model with PyTorch to predict the perceived temperature <code>atemp</code> based on actual temperature <code>temp</code>.</p>
<p>I cannot understand why this code results in loss increasing with each epoch, instead of decreasing. And all predicted values are very far from the truth.</p>
<h2>sample data used</h2>
<pre><code>data_x = array([11.9, 12. , 13.4, 14.8, 15.8, 16.6, 16.7, 16.9, 16.9, 16.9, 16.5,
       15.7, 15.3, 15. , 15. , 14.9, 14.6, 14.2, 14.2, 14. , 13.5, 12.9,
       12.5, 12.4, 12.8, 14.3, 15.6, 16.5, 17. , 17.5, 17.7, 17.7, 17.8,
       17.5, 16.9, 15.6, 14. , 12.2, 11. , 10.6, 10.6, 10.7, 10.9, 10.6,
       10.3,  9.4,  8.7,  7.8,  8.1, 11. , 13.4, 15.2, 16.5, 17.4, 18.1,
       18.5, 18.7, 18.6, 17.7, 16. , 14.6, 13.8, 13. , 12.5, 12. , 11.8,
       11.5, 11.3, 10.9, 10.6, 10.2,  9.9, 10.5, 13.1, 15.3, 17.2, 18.9,
       20.3, 21.2, 21.8, 21.9, 21.5, 20.2, 18.3, 16.8, 15.8, 14.9, 14.2,
       13.6, 13.2, 12.9, 12.7, 12.6, 12.6, 12.6, 12.8, 13.4, 15.5, 17.6,
       19.3])
data_y = array([ 8.9,  9.3, 10.7, 12.1, 13.1, 13.8, 14. , 14.1, 14.3, 14.5, 14.3,
       13.7, 13.2, 12.7, 12.7, 12.5, 11.9, 11.7, 11.7, 11.5, 11.1, 10.6,
       10.3, 10.2, 10.9, 12.5, 12.8, 13.8, 14.6, 14.9, 14.9, 15.1, 15.5,
       15.6, 15.8, 14.7, 13.1, 11.2,  9.6,  9.1,  9.4,  9.7,  9.9,  9.6,
        9.2,  8. ,  7.1,  6.1,  6.5, 10.2, 12.7, 14.3, 15.5, 16.6, 17.4,
       17.7, 17.8, 17.6, 17.2, 15.3, 13.4, 12.4, 11.5, 10.8, 10.1, 10. ,
        9.8,  9.6,  9.3,  9. ,  8.5,  8.1,  8.8, 12. , 14.4, 16.6, 18.5,
       20.1, 21. , 21.3, 21.2, 21.2, 20.1, 17.9, 16.1, 14.6, 13.8, 13.1,
       12.3, 11.8, 11.6, 11.4, 11.3, 11.3, 11.3, 11.4, 12. , 14.6, 16.8,
       18.8])
</code></pre>
<p>Plotted data:</p>
<p><img src=""https://i.postimg.cc/28fztLmb/OOO.png"" alt=""Plotted data"" /></p>
<h2>Code</h2>
<pre><code># import data from CSV to pandas Dataframe
bg = pd.read_csv('data.csv')
X_pandas = bg['temp']
y_pandas = bg['atemp']

# covert to tensors
data_x = X_pandas.head(100).values
data_y = y_pandas.head(100).values
X = torch.tensor(data_x, dtype=torch.float32).reshape(-1, 1)
y = torch.tensor(data_y, dtype=torch.float32).reshape(-1, 1)

# create the model
model = nn.Linear(1, 1)
loss_fn = nn.MSELoss()  # mean square error
optimizer = optim.SGD(model.parameters(), lr=0.01)

# train the model
n_epochs = 40   # number of epochs to run
for epoch in range(n_epochs):
    # forward pass
    y_pred = model(X)
    # compute loss
    loss = loss_fn(y_pred, y)
    # backward pass
    loss.backward()
    # update parameters
    optimizer.step()
    # zero gradients
    optimizer.zero_grad()
    # print loss
    print(f'epoch: {epoch + 1}, loss = {loss.item():.4f}')

# display the predicted values
predicted = model(X).detach().numpy()
display(predicted)

</code></pre>
<h2>Output</h2>
<pre><code>epoch: 1, loss = 16.5762
epoch: 2, loss = 191.0379
epoch: 3, loss = 2291.5081
epoch: 4, loss = 27580.5195
epoch: 5, loss = 332052.6875
epoch: 6, loss = 3997804.2500
epoch: 7, loss = 48132328.0000
epoch: 8, loss = 579498624.0000
epoch: 9, loss = 6976988160.0000
epoch: 10, loss = 84000866304.0000
epoch: 11, loss = 1011344670720.0000
epoch: 12, loss = 12176279470080.0000
epoch: 13, loss = 146598776537088.0000
epoch: 14, loss = 1765004462260224.0000
epoch: 15, loss = 21250117348622336.0000
epoch: 16, loss = 255844948350337024.0000
epoch: 17, loss = 3080297218377252864.0000
epoch: 18, loss = 37085819119396192256.0000
epoch: 19, loss = 446502312996857970688.0000
epoch: 20, loss = 5375748153858603352064.0000
epoch: 21, loss = 64722396677244886974464.0000
epoch: 22, loss = 779237667397586303057920.0000
epoch: 23, loss = 9381773651754967424303104.0000
epoch: 24, loss = 112953739724808869434621952.0000
epoch: 25, loss = 1359928800566679308764971008.0000
epoch: 26, loss = 16373128158657455337028714496.0000
epoch: 27, loss = 197127444146361433227589058560.0000
epoch: 28, loss = 2373354706586702693378941779968.0000
epoch: 29, loss = 28574463232459721913615454830592.0000
epoch: 30, loss = 344027831021918449557295178186752.0000
epoch: 31, loss = 4141990153063893156517557464727552.0000
epoch: 32, loss = 49868270370463502095675094080684032.0000
epoch: 33, loss = 600398977963427833849804206813216768.0000
epoch: 34, loss = inf
epoch: 35, loss = inf
epoch: 36, loss = inf
epoch: 37, loss = inf
epoch: 38, loss = inf
epoch: 39, loss = inf
epoch: 40, loss = inf
</code></pre>
<p>Predicted values:</p>
<pre><code>array([[1.60481241e+21],
       [1.61822441e+21],
       [1.80599158e+21],
       [1.99375890e+21],
       [2.12787834e+21],
       [2.23517393e+21],
       [2.24858593e+21],
       [2.27540965e+21],
       [2.27540965e+21],
       [2.27540965e+21],
       ...
</code></pre>
<p>What could be the reason for this strange result?</p>
","2023-04-01 14:25:59","2","Question"
"75903700","75902400","","<p>25K observations is a small amount of data for a complex model especially with a non-negligible number of parameters: in this case two hidden layers and an input-shape of 10K.  The model can basically <em>memorize</em> the inputs.  You have not added any <em>dropout</em> or <em>regularization</em> and you did not do <em>early stopping</em> as the other answers mention so there's nothing to prevent being able to recreate the training data almost exactly.</p>
<p>But then your model has not really learnt any ability to <em>generalize</em> the data. It has not found patterns in the data instead when asked &quot;what's next?&quot; it just regurgitates what you already fed it.</p>
","2023-04-01 00:42:17","0","Answer"
"75903630","75902400","","<p>This is very common, and it happens due to overfitting. Your model may learn the training dataset very well but not be able to generalize well to the test dataset.</p>
<p>The main reason why your model is not achieving high accuracy is type of neural network you are using. A simple fully connected architecture is not very good for most ML problems. You should learn about sequential models like LSTMs and GRUs, or Transformers. Here is a great course by Andrew Ng from Stanford: <a href=""https://www.coursera.org/learn/nlp-sequence-models"" rel=""nofollow noreferrer"">https://www.coursera.org/learn/nlp-sequence-models</a>.
Depending on your experience with ML, you may need to check out its precursors. If you don't feel like taking a long course, you should look at Keras documentation to see examples of implementations of LSTMs and Transformers.</p>
<p>If you still are not satisfied with your accuracy, @feelsgood 's response contains some useful methods that have been historically used to alleviate overfitting. You try experimenting with hyperparameters in dropout, regularizers, and such. In the end, the best and easiest—although not always possible—way to overcome overfitting is by getting more data. If you can't find any other datasets, you can try using data augmentation techniques. I don't know if there are any well-known data augmentation techniques for sentiment classification, but you can probably experiment with adding filler words and replacing words with synonyms in inputs.</p>
","2023-04-01 00:22:45","0","Answer"
"75902878","75902400","","<p>Meh, the biggest problem I see there is that your model is not suitable for the problem.<br />
You are doing the a text clasification, for this kind of problem you have several options:</p>
<ol>
<li>A 1D CNN.</li>
<li>A RNN like LSTM.</li>
<li>Use more complex models that are based on transformers.</li>
</ol>
<p>Here is a basic model you can use for text classification:</p>
<pre><code>model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))
model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=3, activation='softmax'))
</code></pre>
","2023-03-31 21:29:28","1","Answer"
"75902400","","What can be the cause of poor performance of my neural network on testing data, but a very high accuracy on the training data?","<p>I've made an attempt at developing a simple model to tackle a multi-classification problem. I've found a dataset on Kaggle of 25k+ tweets labeled with sentiment of the text (positive, neutral, negative). I've processed the data and came up with a simple model of a network. The network reaches around 98-99% accuracy on the training data, but around 60% on the testing data. What could be the cause of such discrepancy between the performance, and how can I optimize the model to achieve better evaluation performance?</p>
<p>Here is the code:</p>
<pre class=""lang-python prettyprint-override""><code>df = pd.read_csv('Tweets.csv');

df = df.drop(columns=['textID', 'selected_text'])

data = df['text']
labels = df['sentiment']

labels = np.unique(labels, return_inverse=True)
lookup = labels[0]
labels = labels[1]

data = np.array(data).astype(str)
tokenizer = keras_preprocessing.text.Tokenizer(num_words=10000)
tokenizer.fit_on_texts(data)
sequences = tokenizer.texts_to_sequences(data)
one_hot_results = tokenizer.texts_to_matrix(data, mode='binary')

all_tweets = one_hot_results[:20000]
all_labels = labels[:20000]

train_data = all_tweets[:10000]
test_data = all_tweets[10000:]


train_labels = all_labels[:10000]
test_labels = all_labels[10000:]


model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000, )))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(3, activation='softmax'))
model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(train_data, train_labels, batch_size=512, epochs=20, validation_split=0.3)

test_loss, test_acc = model.evaluate(test_data, test_labels)
print(&quot;test_acc:&quot;, test_acc)
</code></pre>
<p>Here is my console output:</p>
<pre><code>Epoch 19/20
14/14 [==============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 0.9903 - val_loss: 1.9351 - val_accuracy: 0.6063
Epoch 20/20
14/14 [==============================] - 0s 14ms/step - loss: 0.0365 - accuracy: 0.9920 - val_loss: 2.0434 - val_accuracy: 0.6013
313/313 [==============================] - 1s 3ms/step - loss: 1.9856 - accuracy: 0.6086
test_acc: 0.6086000204086304
</code></pre>
<p>I've tried changing the amount of layers, their size, batch size, amount of epochs, adjusting the vocabulary size of the vectorized test data, but nothing seems to improve the evaluation.</p>
","2023-03-31 20:09:00","-1","Question"
"75901902","75208167","","<p>look at the error prompt, find:</p>
<p>C:&lt; path-to-your-local-system &gt;\site-packages\sklearn\datasets_<em>init</em>_.py</p>
<p>uncomment the <a href=""https://i.sstatic.net/PkT2a.png"" rel=""nofollow noreferrer"">uncomment the line here, &amp;,</a></p>
<p>uncomment the function addressing to this import:
<a href=""https://i.sstatic.net/2Bn7m.png"" rel=""nofollow noreferrer"">this function is to be commented out</a></p>
<p>hope it helps!</p>
","2023-03-31 18:59:33","0","Answer"
"75896673","75819291","","<p>I can suggest to try to <code>cache</code> the dataset after the second filtering. As the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache"" rel=""nofollow noreferrer"">docs</a> say, you can either store it in memory or to a file. Basically, after the first iteration <code>tf</code> will save the dataset, which will be then reused: this should also imply that the first random filtering will determine the remaining samples, that will be the same for each epoch.</p>
<p>Otherwise, you can try the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#rejection_resample"" rel=""nofollow noreferrer"">rejection_resample</a> function: I never tried it, but as far as I understand it implements a behaviour similar to you custom resampling function (increasing or decreasing the size of the dataset), perhaps faster.</p>
<p>As a side note: consider that the first training epoch is always the slowest because <code>tf</code> has to compile the model to obtain a static computational graph (or, at least, it compiles every piece of code that is wrapped in a <code>tf.function</code>.)</p>
","2023-03-31 09:05:22","0","Answer"
"75895003","75192505","","<p>And you can make ReLU 2 sided by considering the weights it is forward connected to (not backward connected to!) <a href=""https://ai462qqq.blogspot.com/2023/03/2-siding-relu-via-forward-projections.html"" rel=""nofollow noreferrer"">Blog Post</a></p>
","2023-03-31 05:03:18","0","Answer"
"75886125","","How should I use torch.compile properly?","<p>I'm currently trying to use pytorch 2.0 for boosting training performance with my project. And I've heard that torch.compile might be boost some models.</p>
<p>So my question (for now) is simple; how should I use torch.compile with large model?</p>
<p>Such as, should I use torch.model like this?</p>
<pre class=""lang-py prettyprint-override""><code>class BigModel(nn.Module):
    def __init__(self, ...):
        super(BigModel, self).__init__()
        self.model = nn.Sequential(
            SmallBlock(), 
            SmallBlock(), 
            SmallBlock(), 
            ...
        )
        ...

class SmallBlock(nn.Module):
    def __init__(self, ...):
        super(SmallBlock, self).__init__()
        self.model = nn.Sequential(
            ...some small model...
        )

model = BigModel()
model_opt = torch.compile(model)
</code></pre>
<p>,or like this?</p>
<pre class=""lang-py prettyprint-override""><code>class BigModel(nn.Module):
    def __init__(self, ...):
        super(BigModel, self).__init__()
        self.model = nn.Sequential(
            SmallBlock(), 
            SmallBlock(), 
            SmallBlock(), 
            ...
        )
        ...

class SmallBlock(nn.Module):
    def __init__(self, ...):
        super(SmallBlock, self).__init__()
        self.model = nn.Sequential(
            ...some small model...
        )
        self.model = torch.compile(self.model)

model = BigModel()
model_opt = torch.compile(model)
</code></pre>
<p>For summary,</p>
<ol>
<li>Should compile each layer? or torch.compile do this automatically?</li>
<li>Is there any tips for using torch.compile properly?</li>
</ol>
<p>To be honest, I tried both, but there are no differences..</p>
<p>And also, it didn't speed up dramatically, I just checked speed up rate for my model just about 5 ~ 10%.</p>
","2023-03-30 08:59:07","10","Question"
"75883084","","cannot import name 'deserialize_keras_object' from partially initialized module 'keras.saving.legacy.serialization'most likely due to a circular impor","<p>I was trying to run simple Machine Learning algorithm on Visua Studio Code. I downloaded Tensorflow 2 and installed it. Code I was trying to run was:</p>
<pre><code>import tensorflow as tf
import numpy as np
from tensorflow import keras
model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
</code></pre>
<p>As I understood this shows how machine learning model works in general.</p>
<p>Then on line 4 it says</p>
<pre><code>Exception has occurred: ImportError&quot;
&quot;cannot import name 'deserialize_keras_object' from partially initialized module 'keras.saving.legacy.serialization' (most likely due to a circular import) (C:\Users\Erdemdavaa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\keras\saving\legacy\serialization.py)
  File &quot;D:\study\semester 6\Project laborotory(team)\ML_experiment.py&quot;, line 4, in &lt;module&gt;
    model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
ImportError: cannot import name 'deserialize_keras_object' from partially initialized module 'keras.saving.legacy.serialization' (most likely due to a circular import) (C:\Users\Erdemdavaa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\keras\saving\legacy\serialization.py)
</code></pre>
<p>What is this and how do I fix this?</p>
","2023-03-29 23:55:20","3","Question"
"75879609","75584625","","<p>You are calling the HTTP server in synchronous mode, which means when the socket is connected your script would wait until the data is received and the connection is closed, or you have pressed <code>^C</code>. This is a trick implemented by the firewall/web-server of the service you are trying to use.</p>
<p>You can switch to <code>aiohttp</code> to be able to perform several calls in asynchronous mode. You need to be careful to adjust your connection rate properly and introduce some proper gaps between your calls.
This answer might help you: <a href=""https://stackoverflow.com/questions/48682147/aiohttp-rate-limiting-parallel-requests"">aiohttp: rate limiting parallel requests</a></p>
<p>You can use <code>asyncio.sleep</code> after creating a set of requests, and if they don't finish in the expected time, you can <em>drop</em> the future objects - which effectively means you are dropping your side of the connectin.</p>
","2023-03-29 16:03:48","2","Answer"
"75874179","75872880","","<p>I think you are using <code>mean-square error</code> and forget <code>-</code> after the differential.</p>
<p>So change:</p>
<pre><code>outputErrors[k] =  (targets[k] - nn.OutputLayer[k])
</code></pre>
<p>To:</p>
<pre><code>outputErrors[k] = -(targets[k] - nn.OutputLayer[k])
</code></pre>
","2023-03-29 07:11:51","3","Answer"
"75872880","","My Neural Network (from scratch) training, leaves it further away from target","<p>This is my first time ever creating a neural network, and I've decided to create it in golang, which is not typically a language used for this, however I wanted to create a good understanding of how they work from scratch with only <strong>basic</strong> libraries.</p>
<p>The goal of the program is to train a Neural Network to be able to add two numbers, 1-10, together. To do this I have created a Neural Network class called RawAI (Best name I could come up with), and given it a 1 input layer (array of size 2), 1 hidden layer (array of size 2) and 1 output layer (array of size 1).</p>
<p>There are 2 2D arrays for weights, one is IH (input to Hidden) [2,2] and one is HO, [2,1].</p>
<p>Below is the code which initiates the AI, trains it, and tests it. You will see a couple of the debugging statements I have used, and any other function which is not native to golang or its package will be shown in the following code for my RawAI class. This is called by my main function.:</p>
<pre><code>func AdditionNeuralNetworkTest() {
    nn := NewRawAI(2, 2, 1, 1/math.Pow(10, 15))
    fmt.Printf(&quot;Weights IH Before: %v\n\nWeights HO After: %v\n&quot;, nn.WeightsIH, nn.WeightsHO)
    //Train Neural Network
    //
    for epoch := 0; epoch &lt; 10000000; epoch++ {
        for i := 0; i &lt;= 10; i++ {
            for j := 0; j &lt;= 10; j++ {
                inputs := make([]float64, 2)
                targets := make([]float64, 1)
                inputs[0] = float64(i)
                inputs[1] = float64(j)
                targets[0] = float64(i) + float64(j)
                nn.Train(inputs, targets)
                if epoch%20000 == 0 &amp;&amp; i == 5 &amp;&amp; j == 5 {
                    fmt.Printf(&quot;[TRAINING] [EPOCH %d] %f + %f = %f TARGETS[%f]\n&quot;, epoch, inputs[0], inputs[1], nn.OutputLayer[0], targets[0])
                }

            }

        }
    }
    // Test neural network
    a := rand.Intn(10) + 1
    b := rand.Intn(10) + 1
    inputs := make([]float64, 2)
    inputs[0] = float64(a)
    inputs[1] = float64(b)
    prediction := nn.FeedForward(inputs)[0]
    fmt.Printf(&quot;%d + %d = %f\n&quot;, a, b, prediction)
    fmt.Printf(&quot;Weights IH: %v\n\nWeights HO: %v\n&quot;, nn.WeightsIH, nn.WeightsHO)

}
</code></pre>
<p>Below is all of the code in the RawAI File:</p>
<pre><code>type RawAI struct {
    InputLayer   []float64   `json:&quot;input_layer&quot;`
    HiddenLayer  []float64   `json:&quot;hidden_layer&quot;`
    OutputLayer  []float64   `json:&quot;output_layer&quot;`
    WeightsIH    [][]float64 `json:&quot;weights_ih&quot;`
    WeightsHO    [][]float64 `json:&quot;weights_ho&quot;`
    LearningRate float64     `json:&quot;learning_rate&quot;`
}

func NewRawAI(inputSize, hiddenSize, outputSize int, learningRate float64) *RawAI {
    nn := RawAI{
        InputLayer:   make([]float64, inputSize),
        HiddenLayer:  make([]float64, hiddenSize),
        OutputLayer:  make([]float64, outputSize),
        WeightsIH:    randomMatrix(inputSize, hiddenSize),
        WeightsHO:    randomMatrix(hiddenSize, outputSize),
        LearningRate: learningRate,
    }
    return &amp;nn
}
func (nn *RawAI) FeedForward(inputs []float64) []float64 {
    // Set input layer
    for i := 0; i &lt; len(inputs); i++ {
        nn.InputLayer[i] = inputs[i]
    }

    // Compute hidden layer
    for i := 0; i &lt; len(nn.HiddenLayer); i++ {
        sum := 0.0
        for j := 0; j &lt; len(nn.InputLayer); j++ {
            sum += nn.InputLayer[j] * nn.WeightsIH[j][i]
        }
        nn.HiddenLayer[i] = sum
        if math.IsNaN(sum) {
            panic(fmt.Sprintf(&quot;Sum is NaN on Hidden Layer:\nInput Layer: %v\nHidden Layer: %v\nWeights IH: %v\n&quot;, nn.InputLayer, nn.HiddenLayer, nn.WeightsIH))
        }

    }

    // Compute output layer
    for k := 0; k &lt; len(nn.OutputLayer); k++ {
        sum := 0.0
        for j := 0; j &lt; len(nn.HiddenLayer); j++ {
            sum += nn.HiddenLayer[j] * nn.WeightsHO[j][k]
        }
        nn.OutputLayer[k] = sum
        if math.IsNaN(sum) {
            panic(fmt.Sprintf(&quot;Sum is NaN on Output Layer:\n Model: %v\n&quot;, nn))
        }

    }

    return nn.OutputLayer
}
func (nn *RawAI) Train(inputs []float64, targets []float64) {
    nn.FeedForward(inputs)

    // Compute output layer error
    outputErrors := make([]float64, len(targets))
    for k := 0; k &lt; len(targets); k++ {
        outputErrors[k] = targets[k] - nn.OutputLayer[k]
    }

    // Compute hidden layer error
    hiddenErrors := make([]float64, len(nn.HiddenLayer))
    for j := 0; j &lt; len(nn.HiddenLayer); j++ {
        errorSum := 0.0
        for k := 0; k &lt; len(nn.OutputLayer); k++ {
            errorSum += outputErrors[k] * nn.WeightsHO[j][k]
        }
        hiddenErrors[j] = errorSum * sigmoidDerivative(nn.HiddenLayer[j])
        if math.IsInf(math.Abs(hiddenErrors[j]), 1) {
            //Find out why
            fmt.Printf(&quot;Hidden Error is Infinite:\nTargets:%v\nOutputLayer:%v\n\n&quot;, targets, nn.OutputLayer)
        }
    }

    // Update weights
    for j := 0; j &lt; len(nn.HiddenLayer); j++ {
        for k := 0; k &lt; len(nn.OutputLayer); k++ {
            delta := nn.LearningRate * outputErrors[k] * nn.HiddenLayer[j]
            nn.WeightsHO[j][k] += delta
        }
    }
    for i := 0; i &lt; len(nn.InputLayer); i++ {
        for j := 0; j &lt; len(nn.HiddenLayer); j++ {
            delta := nn.LearningRate * hiddenErrors[j] * nn.InputLayer[i]
            nn.WeightsIH[i][j] += delta
            if math.IsNaN(delta) {
                fmt.Print(fmt.Sprintf(&quot;Delta is NaN.\n Learning Rate: %f\nHidden Errors: %f\nInput: %f\n&quot;, nn.LearningRate, hiddenErrors[j], nn.InputLayer[i]))
            }
            if math.IsNaN(nn.WeightsIH[i][j]) {
                fmt.Print(fmt.Sprintf(&quot;Delta is NaN.\n Learning Rate: %f\nHidden Errors: %f\nInput: %f\n&quot;, nn.LearningRate, hiddenErrors[j], nn.InputLayer[i]))
            }
        }
    }

}
func (nn *RawAI) ExportWeights(filename string) error {
    weightsJson, err := json.Marshal(nn)
    if err != nil {
        return err
    }
    err = ioutil.WriteFile(filename, weightsJson, 0644)
    if err != nil {
        return err
    }
    return nil
}
func (nn *RawAI) ImportWeights(filename string) error {
    weightsJson, err := ioutil.ReadFile(filename)
    if err != nil {
        return err
    }
    err = json.Unmarshal(weightsJson, nn)
    if err != nil {
        return err
    }
    return nil
}

//RawAI Tools:
func randomMatrix(rows, cols int) [][]float64 {
    matrix := make([][]float64, rows)
    for i := 0; i &lt; rows; i++ {
        matrix[i] = make([]float64, cols)
        for j := 0; j &lt; cols; j++ {
            matrix[i][j] = 1.0
        }
    }
    return matrix
}
func sigmoid(x float64) float64 {
    return 1.0 / (1.0 + exp(-x))
}
func sigmoidDerivative(x float64) float64 {
    return x * (1.0 - x)
}

func exp(x float64) float64 {
    return 1.0 + x + (x*x)/2.0 + (x*x*x)/6.0 + (x*x*x*x)/24.0
}
</code></pre>
<p>The example of the output is this: <a href=""https://i.sstatic.net/wGfhb.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/wGfhb.png"" alt=""Example Output"" /></a>
As you can see it slowly moves further from target and continues to do so.
After asking around, googling, and searching through this website I could not find what seemed to be my error, so I decided to ask this question.</p>
","2023-03-29 03:28:39","2","Question"
"75867322","","ValueError: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer","<p>I'm pretty new on deep learning and I got some errors.<br />
Here's my code:</p>
<pre class=""lang-py prettyprint-override""><code>import os
import caer
import canaro
import numpy as np
import cv2 as cv
import gc
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import LearningRateScheduler

IMG_SIZE = (80,80)
channels = 1
char_path = r&quot;simpsons_dataset&quot;
char_dict = {}
for char in os.listdir(char_path):
    char_dict[char] = len(os.listdir(os.path.join(char_path,char)))
# sorth in descending order
char_dict = caer.sort_dict(char_dict, descending=True)
# print(char_dict)
characters = []
count = 0
for i in char_dict:
    characters.append(i[0])
    count += 1
    if count &gt;= 10:
        break
print(characters)
# create the training data
train = caer.preprocess_from_dir(char_path, characters, channels=channels, IMG_SIZE=IMG_SIZE, isShuffle=True)
len(train)
plt.figure(figsize=(30,30))
plt.imshow(train[0][0], cmap='gray')
plt.show()
featureSet, labels = caer.sep_train(train, IMG_SIZE=IMG_SIZE)
# Normalize the featureSet ==&gt; (0,1)
featureSet = caer.normalize(featureSet)
labels = to_categorical(labels, len(characters))
x_train, x_val, y_train, y_val = caer.train_val_split(featureSet, labels, val_ratio=.2)
del train
del featureSet
del labels
gc.collect()
BATCH_SIZE = 32
EPOCHS = 10
# Image data generator
datagen = canaro.generators.imageDataGenerator()
train_gen = datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)
# Creating the model. returns the compiled model
model = canaro.models.createSimpsonsModel(IMG_SIZE=IMG_SIZE, channels=channels, output_dim=len(characters),loss='binary_crossentropy', decay=1e-6, learning_rate=0.001, momentum=0.9, nesterov=None)
model.summary()
callbacks_list = [LearningRateScheduler(canaro.lr_schedule())]
training = model.fit(train_gen, steps_per_epoch = len(x_train)//BATCH_SIZE, epochs=EPOCHS, validation_data = (x_val, y_val), validation_steps=len(y_val)//BATCH_SIZE, callbacks = callbacks_list)
</code></pre>
<p>The error I get:</p>
<pre class=""lang-py prettyprint-override""><code>WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD. &lt;br&gt;
Traceback (most recent call last): &lt;br&gt;
model = canaro.models.createSimpsonsModel(IMG_SIZE=IMG_SIZE, channels=channels, output_dim=len(characters),
optimizer = SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=nesterov)
ValueError: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer
</code></pre>
<p>I've searched for the solution but still don't have the right answer.
How can I solve it?</p>
","2023-03-28 14:04:03","0","Question"
"75864735","75863850","","<p>You can setup a SSH server on your stationary PC and connect your IDE from there.</p>
<p><a href=""https://code.visualstudio.com/docs/remote/ssh"" rel=""nofollow noreferrer"">The instructions page for VSCode</a> also includes how to setup the host (your stationary PC), so it's worth checking out. You can also connect through SSH with PyCharm Professional (Add Interpreter -&gt; On SSH).</p>
<p>If your laptop is on the same network as your host, you can just use your host's IP address to connect to it. (On Windows, run <code>ipconfig</code> in the terminal on your host PC. It should be &quot;IPv4 Address&quot;, and should have the format 192.168.X.X). If you want to connect to it from another network, you'll need to set up port forwarding on your router.</p>
<p>Alternatively, you can push your code to github, connect to the host over SSH, pull it there, and then run the code. This works better if your model needs to run over several hours/days+. Just make sure that the path to your training data is set correctly.</p>
<p>Edit: Or you can use remote desktop applications like AnyDesk or Teamviewer or Parsec. <a href=""https://github.com/moonlight-stream/moonlight-docs/wiki/NVIDIA-GameStream-End-Of-Service-Announcement-FAQ"" rel=""nofollow noreferrer"">Moonlight is going to break sometime soon, anyway.</a></p>
","2023-03-28 09:53:03","1","Answer"
"75864555","75863850","","<p>I use the home pc with laptop using SSH.</p>
<ol>
<li>You have to config your router for granting ssh port forwarding. It's pretty easy and there are many resources for this.</li>
<li>Install SSH in stationary pc</li>
</ol>
<blockquote>
<p>sudo apt-get install SSH</p>
</blockquote>
<ol start=""3"">
<li>Install ssh client on your laptop</li>
</ol>
<blockquote>
<pre><code>sudo apt-get update 

sudo apt-get upgrade 

sudo apt-get install openssh-client
</code></pre>
</blockquote>
<ol start=""4"">
<li>Then you can do <code>&quot;ssh userName@serverName:/path/to/folder&quot;</code> to login to stationary pc.</li>
</ol>
<p>I normally use vs code for remote development. You can use remote explorer extension(<code>https://code.visualstudio.com/docs/remote/ssh</code>) in vscode to edit, run and code neural nets.</p>
","2023-03-28 09:36:07","1","Answer"
"75863850","","How to train PyTorch remotely on another computer?","<p>I am going to train a Neural Net using PyTorch. I will be working from a laptop without a dedicated GPU, but I have a stationary computer with a RTX 2070 at home. Is there any way to use the computing power of my stationary computer when working from my laptop?</p>
<p>The only possible solution I have now is programming everything remotely with something like Moonlight Game Streaming. Would perhaps work but introduces unnecessary elements.</p>
","2023-03-28 08:19:41","0","Question"
"75863411","75649038","","<p>To eliminate the difference between LightGBM(lgb) API and SKlearn(lgb.sklearn) API, you can try the following steps:</p>
<ol>
<li><strong>Compare the models</strong> trained through lgb API and lgb.sklearn API, pay special attention to <code>the hyperparameters with different values</code>(i.e., n_estimators, bagging_seed and so on) and set them as the same value in your code.</li>
<li><strong>Make sure the format and content of your data is valid</strong>, different APIs have different prerequisities for the training data.</li>
</ol>
<p>With the same hyperparameters and training data, different types of APIs will   call the same C++ code(API is just a wrapper) and you'll get the same model trained through different APIs.</p>
","2023-03-28 07:25:26","1","Answer"
"75862900","75783524","","<p>In many respects this is similar to how support teams might prepare &quot;knowledgebase&quot; articles. There is no panacea to this, you have to decide what constitutes worthwhile knowledge, and filter the emails to locate practical examples of this.</p>
<p>e.g.</p>
<pre><code>From: customer@example.com
To: support@example.com
Subject: Problem with account

Hi,

I'm having trouble accessing my account. Can you help?

Thanks,
Customer
</code></pre>
<p>This response is likely to be considered unimportant:</p>
<pre><code>From: support@example.com
To: customer@example.com
Subject: Re: Problem with account

Hello Customer,

I'm sorry to hear that you're having trouble accessing your account. Can you provide more details about the issue you're experiencing?

Regards,
Support Team
</code></pre>
<p>But a different response, such as this may be worthwhile:</p>
<pre><code>From: support@example.com
To: customer@example.com
Subject: Re: Problem with account

Hello Customer,

Sorry to hear that you're having trouble accessing your account. Here are some steps you can try to resolve the issue:

1. Make sure you're using the correct username and password. (Check that your caps lock is OFF.)
2. Clear your browser's cache and cookies, and re-try.
3. Try resetting your password.

If you continue to have trouble, please don't hesitate to contact us for further assistance.

Regards,
Support Team
</code></pre>
<p>So you must decide which question/answer sets found in email constitute worthwhile learning and then format into an input-output pair for training:</p>
<pre><code>Input: I'm having trouble accessing my account. Can you help?
Output: Sorry to hear that you're having trouble accessing your account. Here are some steps you can try to resolve the issue: 1. Make sure you're using the correct username and password. (Check that your caps lock is OFF.) 2. Clear your browser's cache and cookies, and re-try. 3. Try resetting your password. If you continue to have trouble, please don't hesitate to contact us for further assistance.
</code></pre>
<p>Note this will also require stripping emails of all irrelevant information, such as email headers, signatures, urls, marketing etc.</p>
<p>see: <a href=""https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset"" rel=""nofollow noreferrer"">https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset</a></p>
","2023-03-28 06:19:45","2","Answer"
"75860925","75860385","","<p>You may want to consider reducing the dimensionality of your dataset to avoid overfitting with such a large number of features. You can use any method of feature selection, including filter-wrapper-embedded methods.</p>
<p>feature selection will<br />
1- Improve model generalization and avoid overfitting.<br />
2- Avoid dimension explosions.<br />
3- Reduce training time.</p>
<p>Regarding bootstrapping, it's a helpful method for determining a model's performance. It is not, however, a solution for overfitting.</p>
<p>this can help very little with your problem. , <strong>you need more data</strong></p>
","2023-03-27 22:34:47","0","Answer"
"75860474","75190328","","<p>If you want to calculate the AUC of each feature for each segment (i.e., month), you can use the pandas <code>pivot_table</code> function. Here's an example code snippet that you can use:</p>
<pre><code>import pandas as pd
from sklearn import metrics

# load the dataset
df = pd.read_csv(&quot;your_dataset.csv&quot;)

# preprocess the dataset
df[&quot;label&quot;] = df[&quot;label&quot;].apply(lambda x: 1 if x == &quot;Rejected&quot; else 0)
df[&quot;Month_Year&quot;] = pd.to_datetime(df[&quot;datetime&quot;]).dt.to_period(&quot;M&quot;)

# calculate AUC for each feature and segment
feature_cols = [&quot;feature1&quot;, &quot;feature2&quot;, &quot;feature3&quot;]  # replace with your feature column names
auc_dict = {}
for feature_col in feature_cols:
    pivot_df = pd.pivot_table(df, index=&quot;Month_Year&quot;, columns=feature_col, values=[&quot;label&quot;, &quot;probability&quot;], aggfunc=&quot;mean&quot;)
    pivot_df = pivot_df.dropna()
    for feature_value in pivot_df.columns.levels[1]:
        y_true = pivot_df[&quot;label&quot;, feature_value]
        y_score = pivot_df[&quot;probability&quot;, feature_value]
        auc = metrics.roc_auc_score(y_true, y_score)
        auc_dict[(feature_col, feature_value)] = auc

# convert the AUC dictionary to a dataframe
auc_df = pd.DataFrame.from_dict(auc_dict, orient=&quot;index&quot;, columns=[&quot;AUC&quot;]).reset_index()
auc_df = auc_df.rename(columns={&quot;level_0&quot;: &quot;features&quot;, &quot;level_1&quot;: &quot;value&quot;})

# display the output
print(auc_df.head())

</code></pre>
<p>This code will create a pivot table where the rows are the segments (i.e., months), the columns are the feature values, and the values are the mean label and probability values for each group. Then, for each feature value, the code calculates the AUC and stores it in a dictionary. Finally, the AUC dictionary is converted to a dataframe and displayed.</p>
<p>Note that this code assumes that your dataset is stored in a CSV file named &quot;your_dataset.csv&quot;. You'll need to replace this with the actual filename of your dataset. Also, you'll need to replace the list of feature column names with the actual names of the feature columns in your dataset.</p>
","2023-03-27 21:21:47","0","Answer"
"75860428","75860385","","<p>I'd say you cannot possibly hope to train a model with just four samples (and if you were to split, even less).</p>
<p>While assessing the needed number of samples a priori is not trivial and depends on many factors, a major one being data quality, the rules of thumb I have read in the past were along the lines of</p>
<ul>
<li>1,000 samples per class</li>
<li>at least 10 times the number of features</li>
</ul>
<p>While these are most certainly oversimplifications, I guess with 4 samples or less, you are most certainly out of luck.</p>
","2023-03-27 21:14:57","1","Answer"
"75860385","","What is a good way of carrying out test train split with only 4 samples, and a large number of features?","<p>I have a dataset comprising of four samples, ~25,000 features, and two labels (it is a gene count dataset). What is a good way of splitting the data? When I run my model I am getting an accuracy of <code>1</code> on the training set, but <code>0</code> on the validation set.</p>
<p>Is bootstrapping worth trying out?</p>
<pre><code>Labels = [0,1,0,1]

X_train,X_test,y_train,y_test = train_test_split(data,labels,test_size=0.3,random_state=42)
</code></pre>
<p>Any thoughts of advice?</p>
","2023-03-27 21:08:10","0","Question"
"75856015","75855180","","<p>I do not know what is your context, but .fillna is a good method.</p>
<pre><code>df = df.astype(str).fillna('')
</code></pre>
<p>It will change the columns to string and fill missing values with an empty string. I you need to keep a specific datatype you can do it separately and provide a filling value for each.</p>
","2023-03-27 12:55:42","0","Answer"
"75855383","75855180","","<p>One option could be to use the successive time difference and a threshold to group your data with <a href=""https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.first.html"" rel=""nofollow noreferrer""><code>groupby.first</code></a> (or <a href=""https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.mean.html"" rel=""nofollow noreferrer""><code>groupby.mean</code></a>):</p>
<pre><code>out = df.groupby(df['Timestamp'].diff().ge('1s').cumsum(), as_index=False).first()
</code></pre>
<p>Output:</p>
<pre><code>                Timestamp  Variable A  Variable B  Variable C
0 2023-01-01 00:00:00.000         1.0         3.0         4.0
1 2023-01-01 05:00:00.450         7.0         5.0         6.0
</code></pre>
<p>With <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html"" rel=""nofollow noreferrer""><code>resample</code></a>:</p>
<pre><code>out = df.resample('5H', on='Timestamp').mean().reset_index()
</code></pre>
<p>Output:</p>
<pre><code>            Timestamp  Variable A  Variable B  Variable C
0 2023-01-01 00:00:00         1.5         3.0         4.0
1 2023-01-01 05:00:00         7.0         5.0         6.0
</code></pre>
<p>Used input:</p>
<pre><code>                Timestamp  Variable A  Variable B  Variable C
0 2023-01-01 00:00:00.000         1.0         NaN         NaN
1 2023-01-01 00:00:00.050         2.0         NaN         NaN
2 2023-01-01 00:00:00.150         NaN         3.0         4.0
3 2023-01-01 05:00:00.450         NaN         5.0         6.0
4 2023-01-01 05:00:00.500         7.0         NaN         NaN
</code></pre>
","2023-03-27 11:46:55","0","Answer"
"75855180","","How can I process data with a lot of missing values because of different sources?","<p>I have data that looks like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Timestamp</th>
<th>Variable A</th>
<th>Variable B</th>
<th>Variable C</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023-01-01 00:00:00.000</td>
<td>Value</td>
<td>Nan</td>
<td>Nan</td>
</tr>
<tr>
<td>2023-01-01 00:00:00.050</td>
<td>Value</td>
<td>Nan</td>
<td>Nan</td>
</tr>
<tr>
<td>2023-01-01 00:00:00.150</td>
<td>Nan</td>
<td>Value</td>
<td>Value</td>
</tr>
<tr>
<td>2023-01-01 05:00:00.450</td>
<td>Nan</td>
<td>Value</td>
<td>Value</td>
</tr>
<tr>
<td>2023-01-01 05:00:00.500</td>
<td>Value</td>
<td>Nan</td>
<td>Nan</td>
</tr>
</tbody>
</table>
</div>
<p>Variable A comes from one source and Variable B and C from a second, so the timestamps are different which gives me a lot of missing data (the data comes from a dozen sources, this is just a simplified example).</p>
<p>I tried to use the <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html"" rel=""nofollow noreferrer""><code>resample</code></a> method of pandas.
But this method creates too many lines for me, in the example above there would be new lines between 2023-01-01 00:00:00.150 and 2023-01-01 05:00:00.450, which I do not want.</p>
<p>Can you help me?
Thank you</p>
","2023-03-27 11:25:28","0","Question"
"75851547","75737232","","<p>I recently ran into this problem as well, and it stems from the use of <code>255</code> as the background class label and how <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy"" rel=""nofollow noreferrer"">SparseCategoricalCrossentropy</a> works <a href=""https://github.com/huggingface/transformers/blob/v4.27.1/src/transformers/models/segformer/modeling_tf_segformer.py#L800"" rel=""nofollow noreferrer"">under the hood.</a> They attempt to mask out the nan values but a NaN * mask is still a nan</p>
<pre><code>&gt;&gt;&gt; y_true = [255, 1] #any number greater than the length of your predictions will nan
&gt;&gt;&gt; y_pred = [[0.05, 0, 0.95], [0.1, 0.8, 0.1]]
&gt;&gt;&gt; scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction=&quot;none&quot;)
&gt;&gt;&gt; scce(y_true, y_pred).numpy()
array([       nan, 0.22314355], dtype=float32)
</code></pre>
<p>You have two ways to address this issue.</p>
<ul>
<li>Include the background class as part of your labels, non ideal or to fix this function under the hood.</li>
<li>fix the loss function to properly ignore the background class</li>
</ul>
<p>I went with the second option because I also wanted to include class weights for my loss, my hacky but working solution looks like this by overriding the underlying loss function.</p>
<pre class=""lang-py prettyprint-override""><code>constant_weights = tf.constant(weights)

#based off the currently used loss https://github.com/huggingface/transformers/blob/v4.27.1/src/transformers/models/segformer/modeling_tf_segformer.py#L800
def custom_loss(logits, labels):
    # `labels` is of shape (batch_size, height, width)
    # logits are predicted as (batch_size, classes, height//2, width//2)
    logits = tf.transpose(logits, [0, 2, 3, 1])
    label_interp_shape = train_batch['labels'].shape[1:]
    upsampled_logits = tf.image.resize(logits, size=label_interp_shape, method=&quot;bilinear&quot;)
    
    loss_fct = tf.keras.losses.SparseCategoricalCrossentropy(
        from_logits=True,
        reduction=&quot;none&quot;,
        ignore_class=model.config.semantic_loss_ignore_index # missing from original 
    )
    
    def masked_loss(real, pred):
        label_weights = tf.one_hot(real, len(weights))*constant_weights
        label_weights = tf.reduce_sum(label_weights, axis=-1)
        unmasked_loss = loss_fct(real, pred)
        unmasked_loss *= label_weights
        mask = tf.cast(real != model.config.semantic_loss_ignore_index, dtype=unmasked_loss.dtype)
        masked_loss = unmasked_loss * mask
        reduced_masked_loss = tf.reduce_sum(masked_loss) /  tf.reduce_sum(mask)
        return tf.reshape(reduced_masked_loss, (1,))

    return masked_loss(labels, upsampled_logits)

model.hf_compute_loss = custom_loss
</code></pre>
","2023-03-27 01:44:06","0","Answer"
"75851122","75819291","","<p>It seems that most of the time is spent on the dataset operations rather than the network itself. From examining the evidence, my theory would be that if this is executed on GPU (dataset operations are executed on the CPU regardless) then the GPU has to wait for the dataset between batches.
So as the dataset operation always takes the same time, this is why on the progress bar it would seem that batches take longer.</p>
<p>If executed on a GPU, the right way to assert if this theory is correct is to observe the GPU utilization (you can use <code>watch -n 0.5 nvidia-smi</code> as it runs, or better yet use <code>nvtop</code> or any other GPU monitoring tool). If there are times where the utilization (not memory! but utilization) is not close to 100%, then that would be an indicator that this is indeed the problem. Notice it should never drop from 90% even not for half a second.</p>
<p>To solve this, you should use the <code>Dataset.prefetch</code> as the last dataset operation in your code, this will cause the CPU to over-fetch batches so it has batches available for the network to use so it won't wait.</p>
","2023-03-26 23:23:35","1","Answer"
"75833903","75448991","","<p>an other way could be to convert your hImage to a bitmap and then serialize this bitmap as a byte array.</p>
<p>heres a function to convert a hImage to a System.Drawing.Bitmap</p>
<pre><code>public static Bitmap HImageToBitmap(HImage ho_Image) {
        int iWidth, iHeight, iNumChannels;
        IntPtr ip_R, ip_G, ip_B, ip_Gray;
        String sType;
        // null return object
        Bitmap bitmap = null;
        try {
            //
            // Note that pixel data is stored differently in System.Drawing.Bitmap
            // a) Stride:
            // stride is the width, rounded up to a multiple of 4 (padding)
            // Size of data array HALCON: heigth*width, Bitmap: heigth*stride
            // compare: https://msdn.microsoft.com/en-us/library/zy1a2d14%28v=vs.110%29.aspx
            // b) RGB data
            // HALCON: three arrays, Bitmap: one array (alternating red/green/blue)
            iNumChannels = ho_Image.CountChannels();
            if (iNumChannels != 1 &amp;&amp; iNumChannels != 3)
                throw new Exception(&quot;Conversion of HImage to Bitmap failed. Number of channels of the HImage is: &quot; +
                    iNumChannels + &quot;. Conversion rule exists only for images with 1 or 3 chanels&quot;);
            if (iNumChannels == 1) {
                //
                // 1) Get the image pointer
                ip_Gray = ho_Image.GetImagePointer1(out sType, out iWidth, out iHeight);
                //
                // 2) Calculate the stride
                int iPadding = (4 - (iWidth % 4)) % 4;
                int iStride = iWidth + iPadding;
                //
                // 3) Create a new gray Bitmap object, allocating the necessary (managed) memory 
                bitmap = new Bitmap(iWidth, iHeight, PixelFormat.Format8bppIndexed);
                // note for high performance: in case of padding=0, image can be copied by reference.
                // however, then the bitmap's validity relies on the HImage lifetime.
                // bitmap = new Bitmap(iWidth, iHeight, iWidth, PixelFormat.Format8bppIndexed, ip_Gray);
                //
                // 4) Copy the image data directly into the bitmap data object, re-arranged in the required bitmap order
                // BitmapData lets us access the data in memory
                BitmapData bmpData = bitmap.LockBits(new Rectangle(0, 0, iWidth, iHeight),
                    ImageLockMode.WriteOnly, bitmap.PixelFormat);
                // System.Threading.Tasks.Parallel processing requires .NET framework &gt;= 4.0 
                Parallel.For(0, iHeight, r =&gt; {
                    IntPtr posRead = ip_Gray + r * iWidth;
                    IntPtr posWrite = bmpData.Scan0 + r * iStride;
                    for (int c = 0; c &lt; iWidth; c++)
                        Marshal.WriteByte((IntPtr)posWrite, c, Marshal.ReadByte((IntPtr)posRead, c));
                });
                //
                // 5) Let the windows memory management take over control
                bitmap.UnlockBits(bmpData);
                //
                // 6) Adjust palette to grayscale (linearized grayscale)
                // ColorPalette has no constructor -&gt; obtain it from the static member
                ColorPalette cp_P = bitmap.Palette;
                for (int i = 0; i &lt; 256; i++) {
                    cp_P.Entries[i] = Color.FromArgb(i, i, i);
                }
                bitmap.Palette = cp_P;
            }
            if (iNumChannels == 3) {
                //
                // 1) Get the image pointer
                ho_Image.GetImagePointer3(out ip_R, out ip_G, out ip_B, out sType, out iWidth, out iHeight);
                //
                // 2) Calculate the stride
                int iPadding = (4 - ((iWidth * 3) % 4)) % 4;
                int iStride = iWidth * 3 + iPadding;
                //
                // 3) Create a new RGB Bitmap object, allocating the necessary (managed) memory 
                bitmap = new Bitmap(iWidth, iHeight, PixelFormat.Format24bppRgb);
                //
                // 4) Copy the image data directly into the bitmap data object, re-arranged in the required bitmap order
                // BitmapData lets us access the data in memory
                BitmapData bmpData = bitmap.LockBits(new Rectangle(0, 0, iWidth, iHeight),
                ImageLockMode.WriteOnly, bitmap.PixelFormat);
                Parallel.For(0, iHeight, r =&gt; {
                    IntPtr posReadR = (IntPtr)((long)ip_R + r * iWidth);
                    IntPtr posReadG = (IntPtr)((long)ip_G + r * iWidth);
                    IntPtr posReadB = (IntPtr)((long)ip_B + r * iWidth);
                    IntPtr posWrite = (IntPtr)((long)bmpData.Scan0 + r * iStride);
                    for (int c = 0; c &lt; iWidth; c++) {
                        Marshal.WriteByte(posWrite, 3 * c, Marshal.ReadByte(posReadB, c));
                        Marshal.WriteByte(posWrite, 3 * c + 1, Marshal.ReadByte(posReadG, c));
                        Marshal.WriteByte(posWrite, 3 * c + 2, Marshal.ReadByte(posReadR, c));
                    }
                });
                //
                // 5) Let the windows memory management take over control
                bitmap.UnlockBits(bmpData);
            }
        }
        catch (Exception ex) {
            throw new Exception(&quot;Conversion of HImage to Bitmap failed.&quot;, ex);
        }
        return bitmap;
    }
</code></pre>
","2023-03-24 12:52:58","1","Answer"
"75833416","75820659","","<p>There is only one global minimum in the <code>rosen</code> function. It's not clear why you expect there to be multiple solutions. <code>differential_evolution</code> is designed to have a greater probability of finding that global minimum.
If you have a solution with multiple minima and you want to record them all then <code>shgo</code> might be your best option. Alternatively you could track the progress of the differential_evolution population to identify different minima in the energy surface.</p>
","2023-03-24 12:02:11","0","Answer"
"75828814","75584625","","<p>This error message...</p>
<pre><code>HTTP error occurred: 403 Client Error: Forbidden. Please comply with the User-Agent policy: https://meta.wikimedia.org/wiki/User-Agent_policy for url: https://upload.wikimedia.org/wikipedia/commons/1/13/1986_944_Turbo.jpg
</code></pre>
<p>...implies that <strong>HTTP</strong> <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403"" rel=""nofollow noreferrer""><strong>403 Forbidden</strong></a> response status code was encountered while accessing a valid URL.</p>
<hr />
<h2>Deep Dive</h2>
<p>Possibly it's the same issue of <a href=""https://stackoverflow.com/a/75740850/7429447""><strong>Invalid Status code=403 text=Forbidden</strong></a> which we had been discussing for quite sometime now.</p>
<hr />
<h2>Solution</h2>
<p>A blanket solution would be to add the argument <em><code>--remote-allow-origins=*</code></em> through an instance of <code>Options</code> as follows:</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.chrome.options import Options

options = Options()
options.add_argument(&quot;--remote-allow-origins=*&quot;)
DRIVER_PATH = &quot;chromedriver&quot;
wd = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)
</code></pre>
","2023-03-23 23:25:26","0","Answer"
"75821365","75820659","","<p>There are several hyperparameters that you can set for the evolution algorithm to diverge.</p>
<p><a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html"" rel=""nofollow noreferrer"">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html</a></p>
<p>E.g.</p>
<pre><code>import numpy as np
from scipy.optimize import rosen, differential_evolution
bounds = [(0,2), (1, 3), (1, 2), (4, 7), (500, 900)]

result = differential_evolution(rosen, bounds, seed=234)
print(result.x, result.fun)

result = differential_evolution(rosen, bounds, seed=42)
print(result.x, result.fun)

result = differential_evolution(rosen, bounds, seed=42)
print(result.x, result.fun)

result = differential_evolution(rosen, bounds, seed=23, mutation=(0.9, 1), recombination=0.8)
print(result.x, result.fun)

result = differential_evolution(rosen, bounds, seed=23, maxiter=2, mutation=(0.9, 1), recombination=0.8)
print(result.x, result.fun)

result = differential_evolution(rosen, bounds, seed=23, maxiter=2, mutation=(0.9, 1), recombination=0.8)
print(result.x, result.fun)
</code></pre>
<p>[out]:</p>
<pre><code>
(array([  1.1880044 ,   1.41300298,   2.        ,   7.        ,
        500.        ]),
 20341037.207360283)

(array([  1.18838044,   1.41362179,   2.        ,   7.        ,
        500.        ]),
 20341037.207038924)
​
(array([  1.18891057,   1.41438122,   2.        ,   7.        ,
        500.        ]),
 20341037.207497682)

(array([  1.1885353 ,   1.41414795,   2.        ,   7.        ,
        500.        ]),
 20341037.207302164)
</code></pre>
<hr />
<h4>Having a large variance in the bounds</h4>
<p>But since rosen function is formulaic, the variance in the bounds needs to be large enough to see significant changes in the results.</p>
<pre><code>import numpy as np
from scipy.optimize import rosen, differential_evolution
bounds = [(0,221529234), (123121, 31231232), (1231, 291231235), (30434, 1232317), (500, 900)]

result = differential_evolution(rosen, bounds, seed=234)
print(result.x, result.fun)

result = differential_evolution(rosen, bounds, seed=42)
print(result.x, result.fun)

</code></pre>
<p>[out]:</p>
<pre><code>(array([  8141.41766062, 123121.        ,   1231.        ,  30434.        ,
           813.59702423]),
 2.3065086995396433e+22)

(array([     0.        , 123121.        ,   3838.30391681,  30434.        ,
           881.09558529]),
 2.30646627657552e+22)
</code></pre>
","2023-03-23 09:41:00","0","Answer"
"75821202","75584625","","<p>It was quite helpful to read the error message:</p>
<pre><code>HTTP error occurred: 403 Client Error: Forbidden. 
    Please comply with the User-Agent policy: https://meta.wikimedia.org/wiki/User-Agent_policy 
    for url: https://upload.wikimedia.org/wikipedia/commons/1/13/1986_944_Turbo.jpg
</code></pre>
<p>You obviously are violating the policies of the website. To protect themself they can take any countermeasures as they like, also sending fake content to you.</p>
<p>In this case (wikimedia.org) they tell you how they will accept you scrapping their files:  <a href=""https://meta.wikimedia.org/wiki/User-Agent_policy"" rel=""nofollow noreferrer"">https://meta.wikimedia.org/wiki/User-Agent_policy</a></p>
<p>They expect a proper user agent that allows them to classify the access and contact you. They urge you to send a proper agent-string to identify you as an individual, identifiable bot. – Else they take countermeasures.</p>
<p>They expect the word &quot;bot&quot; within the agent-string.
The Syntax of the agent-string expected:</p>
<pre><code>&lt;client name&gt;/&lt;version&gt; (&lt;contact information&gt;) &lt;library/framework name&gt;/&lt;version&gt; [&lt;library name&gt;/&lt;version&gt; ...]

# Example:
User-Agent: CoolBot/0.0 (https://example.org/coolbot/; coolbot@example.org) generic-library/0.0
</code></pre>
<p>For Python, they also give a sample code scrap:</p>
<pre><code>import requests

url = 'https://example/...'
headers = {'User-Agent': 'CoolBot/0.0 (https://example.org/coolbot/; coolbot@example.org)'}

response = requests.get(url, headers=headers)
</code></pre>
<p>So I would suggest to</p>
<ul>
<li>setup a webpage as contact page / vcard for your bot, including an e-mail address. A small introduction of your project might be helpful.</li>
<li>Customize the agent string to identify the keyword &quot;bot&quot;, your intent and the contact page</li>
</ul>
<p>Then give the bot a run and tell, if things got better.</p>
<h4>About the 403 - Forbidden</h4>
<p>This is a qualified response to a GET or POST request. By this answer the HTTP request is finished and your script has to decide what to do next.<br />
=&gt; Your script decides to continue after writing to the log.</p>
<p>If you would have been block generally (i.e. by access rule for your IP address) you would see 403 for every single access to this server.<br />
=&gt; This is not the case within this logfile.</p>
<p>'Forbidden' occurs when accessing a restricted resource. As you get your URLs form a google search URLs to restricted files are possible, as the URLs might be published in the public area of a website.<br />
=&gt; There is nothing special with a 403 at the first glance.</p>
<p>The possibility with a 403 being a trigger is the combination of a 403-hit followed by a problem on a regular basis at the same site (or sites hosted by the same guys).</p>
<p>=&gt; Some more details about these 403 combined with the problem would be nice.</p>
<p>As you write the problem disappeared: what have you changed?<br />
Or did you just get a new search result form Google prioritizing other sites?</p>
<h3>The answer to your question</h3>
<p>Your statement significantly increases the probability of the 403-causing URL as a trigger URL:</p>
<blockquote>
<p>I didn't change anything except bypassing the url causing the first 403 error which led to my script stopping. I didn't find yet the best behavior for this algorithm but this workaround allowed me to enrich my dataset</p>
</blockquote>
<p>By doing this you bypassed the trigger.</p>
<p>The best thing for your project to avoid the problem is to gain acceptance by the scrapped websites (see above).</p>
<p>When they notice their trigger is discovered and bypassed, they choose another URL as trigger and the game restarts. — Don't be astonished, when your IP(-range) or fingerprinted profile gets blacklisted.</p>
<h5>Summary</h5>
<p>The problem does not come from your code but from the bot-tool and its settings. Violation of the usage policy will cause a reaction and is a common effect in the internet.</p>
<hr />
<p><em>(I'm sure, you don't like the answer...)</em></p>
","2023-03-23 09:25:05","5","Answer"
"75820659","","How to get multiple possible solutions for differential evolution algorithm?","<p>the tutorial from scipy only shows one possible solution for differential evolution (<a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html"" rel=""nofollow noreferrer"">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html</a>).</p>
<p>How can i get multiple solutions? And if not, is it because of scipy implementation or are differential evolutions algorithm just designed that way?</p>
<pre><code>import numpy as np
from scipy.optimize import rosen, differential_evolution
bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)]
result = differential_evolution(rosen, bounds)
result.x, result.fun
</code></pre>
","2023-03-23 08:26:17","1","Question"
"75819291","","Keras: time per step increases with a filter on the number of samples, epoch time continues the same","<p>I'm implementing a simple sanity check model on Keras for some data I have. My training dataset is comprised of about 550 files, and each contributes to about 150 samples. Each training sample has the following signature:</p>
<pre class=""lang-py prettyprint-override""><code>({'input_a': TensorSpec(shape=(None, 900, 1), dtype=tf.float64, name=None),
  'input_b': TensorSpec(shape=(None, 900, 1), dtype=tf.float64, name=None)},
   TensorSpec(shape=(None, 1), dtype=tf.int64, name=None)
)
</code></pre>
<p>Essentially, each training sample is made up of two inputs with shape (900, 1), and the target is a single (binary) label. The first step of my model is a concatenation of inputs into a (900, 2) Tensor.</p>
<p>The total number of training samples is about 70000.</p>
<p>As input to the model, I'm creating a tf.data.Dataset, and applying a few preparation steps:</p>
<ol>
<li><code>tf.Dataset.filter</code>: to filter some samples with invalid labels</li>
<li><code>tf.Dataset.shuffle</code></li>
<li><code>tf.Dataset.filter</code>: <strong>to undersample my training dataset</strong></li>
<li><code>tf.Dataset.batch</code></li>
</ol>
<p>Step 3 is the most important in my question. To undersample my dataset I apply a simple function:</p>
<pre class=""lang-py prettyprint-override""><code>def undersampling(dataset: tf.data.Dataset, drop_proba: Iterable[float]) -&gt; tf.data.Dataset:
    def undersample_function(x, y):

        drop_prob_ = tf.constant(drop_proba)

        idx = y[0]

        p = drop_prob_[idx]
        v = tf.random.uniform(shape=(), dtype=tf.float32)

        return tf.math.greater_equal(v, p)

    return dataset.filter(undersample_function)
</code></pre>
<p>Essentially, the function accepts a a vector of probabilities <code>drop_prob</code> such that <code>drop_prob[l]</code> is the probability of dropping a sample with label <code>l</code> (the function is a bit convoluted, but it's the way I found to implement it as <code>Dataset.filter</code>). Using equal probabilities, say <code>drop_prob=[0.9, 0.9]</code>, I`ll be dropping about 90% of my samples.</p>
<p>Now, the thing is, I've been experimenting with different undersamplings for my dataset, in order to find a sweet spot between performance and training time, but when I undersample, <strong>the epoch duration is the same, with time/step increasing instead</strong>.</p>
<p>Keeping my <code>batch_size</code> fixed at 20000, for the complete dataset I have a total of 4 batches, and the following time for an average epoch:</p>
<pre><code>Epoch 4/1000
1/4 [======&gt;.......................] - ETA: 9s
2/4 [==============&gt;...............] - ETA: 5s
3/4 [=====================&gt;........] - ETA: 2s
4/4 [==============================] - ETA: 0s
4/4 [==============================] - 21s 6s/step
</code></pre>
<p>While if I undersample my dataset with a <code>drop_prob = [0.9, 0.9]</code> (That is, I'm getting rid of about 90% of the dataset), and keeping the same <code>batch_size</code> of 20000, I have 1 batch, and the following time for an average epoch:</p>
<pre><code>Epoch 4/1000
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 22s 22s/step 
</code></pre>
<p>Notice that while the number of batches is only 1, the epoch time is the same! It just takes longer to process the batch.</p>
<p>Now, as a sanity check, I tried a different way of undersampling, by filtering the files instead. So I selected about 55 of the training files (10%), to have a similar number of samples in a single batch, and removed the undersampling from the <code>tf.Dataset</code>. The epoch time decreates as expected:</p>
<pre><code>Epoch 4/1000
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 2s 2s/step 
</code></pre>
<p>Note that the original dataset has 70014 training samples, while the undersampled dataset by means of tf.Dataset.filter had 6995 samples and the undersampled dataset by means of file filtering had 7018 samples, thus the numbers are consistent.</p>
<p>Much faster. In fact, it takes about 10% of the time as the epoch takes with the full dataset. So there is an issue with the way I'm performing undersampling (by using <code>tf.data.Dataset.filter</code>) when creating the <code>tf.Dataset</code>, I would like to ask for help to figure it out what is the issue. Thanks.</p>
","2023-03-23 04:36:41","1","Question"
"75818612","75815500","","<p>I would recommend to use assertion for debugging to ensure that your paths are valid. As the others previously stated, there should be something wrong with them, probably a space in a filename, or whatever.</p>
<pre><code>from os import path


def extract_features(image_paths):
    features = []
    for image_path in image_paths:
        assert path.exists(image_path), f'Path {image_path} does not exist!'
        image = Image.open(image_path)
        image = image.resize((224, 224))
        image = np.array(image)
        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
        image = vgg.predict(image)
        image = np.reshape(image, image.shape[1]*image.shape[2]*image.shape[3])
        features.append(image)
    return np.array(features)
</code></pre>
","2023-03-23 01:39:50","0","Answer"
"75818502","75793658","","<p>Here is a further improvement that adds gains on the saturation and brightness so that one can deepen or lighten the colors. In the following I use sfact=3 and vfact=1.5 to make a deeper green color.</p>
<pre><code>import cv2
import numpy as np
import skimage.exposure

# specify desired bgr color for lips and make into array
#desired_color = (170,130,255)    # pink
#desired_color = (255,0,0)        # blue
desired_color = (0,255,0)         # green

print(desired_color)

# create swatch
swatch = np.full((200,200,3), desired_color, dtype=np.uint8)

# read image
img = cv2.imread(&quot;lady2.jpg&quot;)

# read mask
mask = cv2.imread(&quot;lady2_mask.png&quot;, cv2.IMREAD_GRAYSCALE)


# convert input to HSV and separate channels
hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
h, s, v = cv2.split(hsv_img)

# dilate mask to make it better fit the lips
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))
mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)

# get average bgr color of lips as array
ave_color = cv2.mean(img, mask=mask)[:3]
print(ave_color)

# create 1 pixel image of average color
ave_color_img = np.full((1,1,3), ave_color, dtype=np.float32)
print(ave_color_img)

# create 1 pixel image of desired color
desired_color_img = np.full((1,1,3), desired_color, dtype=np.float32)
print(desired_color_img)

# convert desired color image to HSV
desired_hsv = cv2.cvtColor(desired_color_img, cv2.COLOR_BGR2HSV)

# convert average color image to HSV
ave_hsv = cv2.cvtColor(ave_color_img, cv2.COLOR_BGR2HSV)

# compute difference in HSV color arrays and separate channel values
diff_hsv = desired_hsv - ave_hsv
diff_h, diff_s, diff_v = cv2.split(diff_hsv)
print(diff_hsv)

# shift input image color
sfact=3
vfact=1.5
hnew = np.mod(h + diff_h/2, 180).astype(np.uint8)
snew = (sfact*(s + diff_s)).clip(0,255).astype(np.uint8)
vnew = (vfact*(v + diff_v)).clip(0,255).astype(np.uint8)

# merge channels back to HSV image
hsv_new = cv2.merge([hnew,snew,vnew])

# convert new HSV image to BGR
new_img = cv2.cvtColor(hsv_new, cv2.COLOR_HSV2BGR)

# antialias mask, convert to float in range 0 to 1 and make 3-channels
mask = cv2.GaussianBlur(mask, (0,0), sigmaX=5, sigmaY=5, borderType = cv2.BORDER_DEFAULT)
mask = skimage.exposure.rescale_intensity(mask, in_range=(128,255), out_range=(0,1)).astype(np.float32)
mask = cv2.merge([mask,mask,mask])

# combine img and new_img using mask 
result = (img * (1 - mask) + new_img * mask)
result = result.clip(0,255).astype(np.uint8)

# save result
cv2.imwrite('lady2_swatch.png', swatch)
cv2.imwrite('lady2_recolor.jpg', result)

cv2.imshow('swatch', swatch)
cv2.imshow('mask', mask)
cv2.imshow('new_img', new_img)
cv2.imshow('result', result)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p>Deep Green Result:</p>
<p><a href=""https://i.sstatic.net/gG3y4.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/gG3y4.jpg"" alt=""enter image description here"" /></a></p>
","2023-03-23 01:12:56","-1","Answer"
"75818268","75793658","","<p>Here is a revised script that works better for most colors. It does the color difference in HSV color space.</p>
<p>Input:</p>
<p><a href=""https://i.sstatic.net/ORKUe.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/ORKUe.jpg"" alt=""enter image description here"" /></a></p>
<p>Mask:</p>
<p><a href=""https://i.sstatic.net/KzcXr.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/KzcXr.png"" alt=""enter image description here"" /></a></p>
<pre><code>import cv2
import numpy as np
import skimage.exposure

# specify desired bgr color for lips and make into array
#desired_color = (170,130,255)    # pink
#desired_color = (255,0,0)        # blue
desired_color = (0,255,0)         # green

print(desired_color)

# create swatch
swatch = np.full((200,200,3), desired_color, dtype=np.uint8)

# read image
img = cv2.imread(&quot;lady2.jpg&quot;)

# read mask
mask = cv2.imread(&quot;lady2_mask.png&quot;, cv2.IMREAD_GRAYSCALE)


# convert input to HSV and separate channels
hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
h, s, v = cv2.split(hsv_img)

# dilate mask to make it better fit the lips
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))
mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)

# get average bgr color of lips as array
ave_color = cv2.mean(img, mask=mask)[:3]
print(ave_color)

# create 1 pixel image of average color
ave_color_img = np.full((1,1,3), ave_color, dtype=np.float32)
print(ave_color_img)

# create 1 pixel image of desired color
desired_color_img = np.full((1,1,3), desired_color, dtype=np.float32)
print(desired_color_img)

# convert desired color image to HSV
desired_hsv = cv2.cvtColor(desired_color_img, cv2.COLOR_BGR2HSV)

# convert average color image to HSV
ave_hsv = cv2.cvtColor(ave_color_img, cv2.COLOR_BGR2HSV)

# compute difference in HSV color arrays and separate channel values
diff_hsv = desired_hsv - ave_hsv
diff_h, diff_s, diff_v = cv2.split(diff_hsv)
print(diff_hsv)

# shift input image color
hnew = np.mod(h + diff_h/2, 180).astype(np.uint8)
snew = (s + diff_s).clip(0,255).astype(np.uint8)
vnew = (v + diff_v).clip(0,255).astype(np.uint8)

# merge channels back to HSV image
hsv_new = cv2.merge([hnew,snew,vnew])

# convert new HSV image to BGR
new_img = cv2.cvtColor(hsv_new, cv2.COLOR_HSV2BGR)

# antialias mask, convert to float in range 0 to 1 and make 3-channels
mask = cv2.GaussianBlur(mask, (0,0), sigmaX=5, sigmaY=5, borderType = cv2.BORDER_DEFAULT)
mask = skimage.exposure.rescale_intensity(mask, in_range=(128,255), out_range=(0,1)).astype(np.float32)
mask = cv2.merge([mask,mask,mask])

# combine img and new_img using mask 
result = (img * (1 - mask) + new_img * mask)
result = result.clip(0,255).astype(np.uint8)

# save result
cv2.imwrite('lady2_swatch.png', swatch)
cv2.imwrite('lady2_recolor.jpg', result)

cv2.imshow('swatch', swatch)
cv2.imshow('mask', mask)
cv2.imshow('new_img', new_img)
cv2.imshow('result', result)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p>Pink Result:</p>
<p><a href=""https://i.sstatic.net/0EzNj.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/0EzNj.jpg"" alt=""enter image description here"" /></a></p>
<p>Blue Result:</p>
<p><a href=""https://i.sstatic.net/nbSV1.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/nbSV1.jpg"" alt=""enter image description here"" /></a></p>
<p>Green Result:</p>
<p><a href=""https://i.sstatic.net/etaNo.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/etaNo.jpg"" alt=""enter image description here"" /></a></p>
","2023-03-23 00:10:35","-1","Answer"
"75817478","75737232","","<p>You didn't set your loss function in your model.compile. Change your model.compile line to this</p>
<pre><code>model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])
</code></pre>
<p>This should make your code work just fine</p>
","2023-03-22 21:39:55","1","Answer"
"75816959","75810246","","<p>You can use <a href=""https://huggingface.co/docs/huggingface_hub/v0.13.3/en/index"" rel=""noreferrer"">huggingface_hub</a> with <a href=""https://huggingface.co/docs/huggingface_hub/v0.13.3/en/package_reference/hf_api#huggingface_hub.HfApi.list_models"" rel=""noreferrer"">list_models</a> and a <a href=""https://huggingface.co/docs/huggingface_hub/v0.13.3/en/package_reference/hf_api#huggingface_hub.ModelFilter"" rel=""noreferrer"">ModelFilter</a>:</p>
<pre class=""lang-py prettyprint-override""><code>from huggingface_hub import HfApi, ModelFilter
api = HfApi()
models = api.list_models(
    filter=ModelFilter(
        task=&quot;automatic-speech-recognition&quot;
    )
)
models = list(models)
print(len(models))
print(models[0].modelId)
</code></pre>
<p>Output:</p>
<pre><code>7195
13048909972/wav2vec2-common_voice-tr-demo
</code></pre>
","2023-03-22 20:24:25","6","Answer"
"75816002","75815207","","<p><code>cols_with_missing = [col for col in X.columns if X[col].isnull().any()] </code> you are checking columns with missing values only in training data. And there are some columns that did not have any null values in the training set but do have null values in the test set. That's how you carried those nulls in the entire code.</p>
","2023-03-22 18:25:31","1","Answer"
"75815973","75815207","","<p>I think I found your issue.</p>
<p>See the code below:</p>
<pre><code>cols_with_missing = [col for col in X.columns if X[col].isnull().any()] 
X.drop(cols_with_missing, axis=1, inplace=True)
X_test.drop(cols_with_missing, axis=1, inplace=True)
</code></pre>
<p>What you did here is that you identified columns with missing values in dataframe X and then dropped these columns from <strong>both</strong> X and <strong>X_test</strong>. That is where your problem begins. You have also missing data in several columns of X_test.</p>
<p>I checked with;</p>
<pre><code>[col for col in X_test.columns if X_test[col].isna().any()
</code></pre>
<p>Which resulted:</p>
<blockquote>
<p>['MSZoning',
'Utilities',
'Exterior1st',
'Exterior2nd',
'BsmtFinSF1',
'BsmtFinSF2',
'BsmtUnfSF',
'TotalBsmtSF',
'BsmtFullBath',
'BsmtHalfBath',
'KitchenQual',
'Functional',
'GarageCars',
'GarageArea',
'SaleType']</p>
</blockquote>
<p>So you might consider filling these with mean of each column from X, or delete these rows as well.</p>
","2023-03-22 18:21:59","1","Answer"
"75815877","75815500","","<p>It is easier if you debug the issue, as the error is coming on line Image.open(image_path)</p>
<p>Use the following lines to debug:</p>
<pre><code>print(&quot;Image paths for training set:&quot;)
print(image_paths_train)
print(&quot;\nImage paths for testing set:&quot;)
print(image_paths_test)

features_train = extract_features(image_paths_train)
features_test = extract_features(image_paths_test)
</code></pre>
<p>If the printed file paths are incorrect or don't exist, you will need to investigate how these variables were created and ensure that they contain the correct file paths.</p>
","2023-03-22 18:11:00","1","Answer"
"75815838","75793658","","<p>Here is a slight variation and I hope improvement over my method posted in <a href=""https://stackoverflow.com/questions/71860084/how-can-i-change-the-color-of-the-lip-that-got-its-landmarks-without-disturbing/71864126?r=SearchResults&amp;s=1%7C35.9414#71864126"">How can I change the color of the lip that got its landmarks without disturbing its texture? in opencv python</a>.</p>
<p>The main differences are: 1) the mask is provided, but does not match the lips as well as possible. So I dilate them a little. 2) I change the cv2.add to cv2.addWeighted to blend the new color with the lips. The weight on the new color determines the amount of lip color applied. I mixed the image (weight 1) with the new color (weight 0.75). Change weight 0.75 as desired. 3) I increased the anti-alias distance on the mask for doing a soft blend at the edges of the lips.</p>
<p>Input:</p>
<p><a href=""https://i.sstatic.net/RZZRf.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/RZZRf.jpg"" alt=""enter image description here"" /></a></p>
<p>Mask:</p>
<p><a href=""https://i.sstatic.net/fShAp.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/fShAp.png"" alt=""enter image description here"" /></a></p>
<pre><code>import cv2
import numpy as np
import skimage.exposure

# specify desired bgr color for lips and make into array
desired_color = (170, 130, 255)
desired_color = np.asarray(desired_color, dtype=np.float64)

# create swatch
swatch = np.full((200,200,3), desired_color, dtype=np.uint8)

# read image
img = cv2.imread(&quot;lady2.jpg&quot;)

# read mask
mask = cv2.imread(&quot;lady2_mask.png&quot;, cv2.IMREAD_GRAYSCALE)

# dilate mask to make it better fit the lips
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))
mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)

# get average bgr color of lips
ave_color = cv2.mean(img, mask=mask)[:3]
print(ave_color)

# compute difference colors and make into an image the same size as input
diff_color = desired_color - ave_color
diff_color = np.full_like(img, diff_color, dtype=np.uint8)

# shift input image color
new_img = cv2.addWeighted(img, 1.0, diff_color, 0.75, 0)

# antialias mask, convert to float in range 0 to 1 and make 3-channels
mask = cv2.GaussianBlur(mask, (0,0), sigmaX=15, sigmaY=15, borderType = cv2.BORDER_DEFAULT)
mask = skimage.exposure.rescale_intensity(mask, in_range=(128,255), out_range=(0,1)).astype(np.float32)
mask = cv2.merge([mask,mask,mask])

# combine img and new_img using mask
result = (img * (1 - mask) + new_img * mask)
result = result.clip(0,255).astype(np.uint8)

# save result
cv2.imwrite('lady2_swatch.png', swatch)
cv2.imwrite('lady2_mask.png', (255*mask).clip(0,255).astype(np.uint8))
cv2.imwrite('lady2_recolor.jpg', result)

cv2.imshow('swatch', swatch)
cv2.imshow('mask', mask)
cv2.imshow('result', result)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p>New Lip Color Swatch:</p>
<p><a href=""https://i.sstatic.net/UKGLl.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/UKGLl.png"" alt=""enter image description here"" /></a></p>
<p>Result:</p>
<p><a href=""https://i.sstatic.net/NmU2h.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/NmU2h.jpg"" alt=""enter image description here"" /></a></p>
","2023-03-22 18:07:15","1","Answer"
"75815500","","File not found error even I didn't mentioned or used the error file name or directory name in code","<p>Am getting an error for file not found for a non existing file name in the code. I haven't used file or directory name in the entire code, still error is thrown.</p>
<pre><code># Extract the features from the images
def extract_features(image_paths):
    features = []
    for image_path in image_paths:
        image = Image.open(image_path)
        image = image.resize((224, 224))
        image = np.array(image)
        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
        image = vgg.predict(image)
        image = np.reshape(image, image.shape[1]*image.shape[2]*image.shape[3])
        features.append(image)
    return np.array(features)

features_train = extract_features(image_paths_train)
features_test = extract_features(image_paths_test)
</code></pre>
<p>error am getting for the above code is -</p>
<pre><code>---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
/tmp/ipykernel_785/4261382143.py in &lt;module&gt;
     12     return np.array(features)
     13 
---&gt; 14 features_train = extract_features(image_paths_train)
     15 features_test = extract_features(image_paths_test)

/tmp/ipykernel_785/4261382143.py in extract_features(image_paths)
      3     features = []
      4     for image_path in image_paths:
----&gt; 5         image = Image.open(image_path)
      6         image = image.resize((224, 224))
      7         image = np.array(image)

/opt/conda/lib/python3.7/site-packages/PIL/Image.py in open(fp, mode, formats)
   3129 
   3130     if filename:
-&gt; 3131         fp = builtins.open(filename, &quot;rb&quot;)
   3132         exclusive_fp = True
   3133 

FileNotFoundError: [Errno 2] No such file or directory: 't'
</code></pre>
<p>pl help</p>
","2023-03-22 17:31:09","-1","Question"
"75815207","","After dropping columns with missing values, sklearn still throwing ValueError","<p>I am currently taking the intermediate machine learning course on kaggle, and am quite new to machine learning.</p>
<p>I'm currently trying to create a Random Forest model and implementing OH Encoding on my data, but as it is my first time have been struggling a bit.</p>
<p>To keep things simple, I dropped all data with missing values:</p>
<pre><code>import pandas as pd
from sklearn.model_selection import train_test_split

X = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv', index_col='Id') 
X_test = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv', index_col='Id')

X.dropna(axis=0, subset=['SalePrice'], inplace=True)
y = X.SalePrice
X.drop(['SalePrice'], axis=1, inplace=True)

cols_with_missing = [col for col in X.columns if X[col].isnull().any()] 
X.drop(cols_with_missing, axis=1, inplace=True)
X_test.drop(cols_with_missing, axis=1, inplace=True)

X_train, X_valid, y_train, y_valid = train_test_split(X, y,
                                                      train_size=0.8, test_size=0.2,
                                                      random_state=0)
</code></pre>
<p>I then encoded my data with OH Encoding:</p>
<pre><code>from sklearn.preprocessing import OneHotEncoder

object_cols = [col for col in X_train.columns if X_train[col].dtype == &quot;object&quot;]

low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() &lt; 10]

num_X_train = X_train.drop(object_cols, axis=1)
num_X_valid = X_valid.drop(object_cols, axis=1)
num_X_test = X_test.drop(object_cols, axis=1)

OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)

OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))
OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))
OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))

OH_cols_train.index = X_train.index
OH_cols_valid.index = X_valid.index
OH_cols_test.index = X_test.index

OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)
OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)
OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)
</code></pre>
<p>I'm not worried about using my validation data for now. When I then go on to create the model and predict values:</p>
<pre><code>from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(OH_X_train, y_train)
preds = model.predict(OH_X_test)
</code></pre>
<p>I get the following error:
<code>ValueError: Input contains NaN, infinity or a value too large for dtype('float32').</code></p>
<p>I'm a little confused as to why I'm getting this error, considering that I've followed the same method for both the training data and the test data. I'm able to create the model fine, but when I attempt to predict is when I get the error. Any help would be greatly appreciated!</p>
","2023-03-22 17:00:35","0","Question"
"75814047","","How to use Huggingface Trainer with multiple GPUs?","<p>Say I have the following model (from <a href=""https://huggingface.co/course/chapter7/6"" rel=""noreferrer"">this</a> script):</p>
<pre><code>from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig

config = AutoConfig.from_pretrained(
    &quot;gpt2&quot;,
    vocab_size=len(tokenizer),
    n_ctx=context_length,
    bos_token_id=tokenizer.bos_token_id,
    eos_token_id=tokenizer.eos_token_id,
)
model = GPT2LMHeadModel(config)
</code></pre>
<p>I'm currently using this training arguments for the Trainer:</p>
<pre><code>from transformers import Trainer, TrainingArguments

args = TrainingArguments(
    output_dir=&quot;codeparrot-ds&quot;,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    evaluation_strategy=&quot;steps&quot;,
    eval_steps=5_000,
    logging_steps=5_000,
    gradient_accumulation_steps=8,
    num_train_epochs=1,
    weight_decay=0.1,
    warmup_steps=1_000,
    lr_scheduler_type=&quot;cosine&quot;,
    learning_rate=5e-4,
    save_steps=5_000,
    fp16=True,
    push_to_hub=True,
)

trainer = Trainer(
    model=model,
    tokenizer=tokenizer,
    args=args,
    data_collator=data_collator,
    train_dataset=tokenized_datasets[&quot;train&quot;],
    eval_dataset=tokenized_datasets[&quot;valid&quot;],
)
trainer.train()
</code></pre>
<p>How can I adapt this so the Trainer will use multiple GPUs (e.g., 8)?</p>
<p>I found <a href=""https://stackoverflow.com/questions/61736317/huggingface-transformers-gpt2-generate-multiple-gpus"">this</a> SO question, but they didn't use the Trainer and just used PyTorch's <code>DataParallel</code></p>
<pre><code>model = torch.nn.DataParallel(model, device_ids=[0,1])
</code></pre>
<p>The Huggingface <a href=""https://huggingface.co/docs/transformers/perf_train_gpu_many"" rel=""noreferrer"">docs on training with multiple GPUs</a> are not really clear to me and don't have an example of using the Trainer. Instead, I found <a href=""https://huggingface.co/docs/transformers/run_scripts#distributed-training-and-mixed-precision"" rel=""noreferrer"">here</a> that they add arguments to their python file with <code>nproc_per_node</code>, but that seems too specific to their script and not clear how to use in general. This is in contrary to <a href=""https://discuss.huggingface.co/t/training-using-multiple-gpus/1279"" rel=""noreferrer"">this</a> discussion on their forum that says <code>&quot;The Trainer class automatically handles multi-GPU training, you don’t have to do anything special.&quot;</code>. So this is confusing as on one hand they're mentioning that there are things needed to be done to train on multiple GPUs, and also saying that the Trainer handles it automatically. So I'm not sure what to do.</p>
","2023-03-22 15:10:23","12","Question"
"75812532","75810246","","<p>Try something like:</p>
<pre><code>import re

import requests
from bs4 import BeautifulSoup


def list_models(task, sort_by):
  &quot;&quot;&quot;Returns first page of results from available models on huggingface.co&quot;&quot;&quot;
  url = f&quot;https://huggingface.co/models?pipeline_tag={task}&amp;sort={sort_by}&quot;

  response = requests.get(url)
  soup = BeautifulSoup(response.content.decode('utf8'))

  for model in soup.find_all('article'):
    parsed_text = [line.strip() for line in re.sub(' +', ' ', model.text.replace('\n', ' ').replace('\t', ' ').replace('•', '\n')).strip().split('\n')]
    model_name_str, last_updated_str, downloaded, *liked = parsed_text
    liked = int(liked[0]) if liked else 0

    model_name = model.find('a').attrs['href'][1:]
    timestamp = model.find('time').attrs['datetime']
    yield {&quot;model_name&quot;: model_name, &quot;last_updated&quot;: timestamp, &quot;downloaded&quot;: downloaded.strip(), &quot;liked&quot;: liked}



task = &quot;automatic-speech-recognition&quot;
sort_by = &quot;downloads&quot;

list(list_models(task, sort_by))

</code></pre>
<p>[out]:</p>
<pre><code>[{'model_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-english',
  'last_updated': '2022-12-14T02:02:32',
  'downloaded': '13.7M',
  'liked': 31},
 {'model_name': 'pyannote/voice-activity-detection',
  'last_updated': '2022-10-28T13:46:55',
  'downloaded': '1.06M',
  'liked': 37},
 {'model_name': 'pyannote/speaker-diarization',
  'last_updated': '2022-11-17T13:45:04',
  'downloaded': '855k',
  'liked': 171},
 {'model_name': 'facebook/wav2vec2-large-960h-lv60-self',
  'last_updated': '2022-05-23T16:13:42',
  'downloaded': '636k',
  'liked': 71},
 {'model_name': 'yongjian/wav2vec2-large-a',
  'last_updated': '2022-10-22T07:21:15',
  'downloaded': '272k',
  'liked': 5},
 {'model_name': 'jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli',
  'last_updated': '2022-02-25T19:07:57',
  'downloaded': '248k',
  'liked': 4},
 {'model_name': 'facebook/wav2vec2-base-960h',
  'last_updated': '2022-11-14T21:37:23',
  'downloaded': '222k',
  'liked': 109},
 {'model_name': 'openai/whisper-tiny.en',
  'last_updated': '2023-02-23T15:31:39',
  'downloaded': '66.4k',
  'liked': 35},
 {'model_name': 'facebook/wav2vec2-xlsr-53-espeak-cv-ft',
  'last_updated': '2021-12-10T17:18:39',
  'downloaded': '62.1k',
  'liked': 11},
 {'model_name': 'maxidl/wav2vec2-large-xlsr-german',
  'last_updated': '2021-07-06T12:32:21',
  'downloaded': '60k',
  'liked': 0},
 {'model_name': 'pyannote/overlapped-speech-detection',
  'last_updated': '2022-10-28T13:46:33',
  'downloaded': '45.9k',
  'liked': 4},
 {'model_name': 'openai/whisper-tiny',
  'last_updated': '2023-03-10T17:15:01',
  'downloaded': '43.6k',
  'liked': 41},
 {'model_name': 'ceyda/wav2vec2-base-760-turkish',
  'last_updated': '2021-07-06T00:16:04',
  'downloaded': '42.1k',
  'liked': 2},
 {'model_name': 'openai/whisper-large-v2',
  'last_updated': '2023-03-10T17:15:07',
  'downloaded': '41.7k',
  'liked': 275},
 {'model_name': 'openai/whisper-small',
  'last_updated': '2023-03-10T17:15:13',
  'downloaded': '39.7k',
  'liked': 37},
 {'model_name': 'techiaith/wav2vec2-xlsr-ft-en-cy',
  'last_updated': '2023-03-02T06:30:13',
  'downloaded': '32.5k',
  'liked': 1},
 {'model_name': 'facebook/wav2vec2-xlsr-53-phon-cv-babel-ft',
  'last_updated': '2021-11-10T12:02:20',
  'downloaded': '31.2k',
  'liked': 1},
 {'model_name': 'comodoro/wav2vec2-xls-r-300m-cs-250',
  'last_updated': '2022-03-23T18:26:50',
  'downloaded': '31.1k',
  'liked': 0},
 {'model_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-russian',
  'last_updated': '2022-12-14T01:58:43',
  'downloaded': '29.3k',
  'liked': 12},
 {'model_name': 'facebook/hubert-large-ls960-ft',
  'last_updated': '2022-05-24T10:43:42',
  'downloaded': '23.8k',
  'liked': 27},
 {'model_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-japanese',
  'last_updated': '2022-12-14T01:58:09',
  'downloaded': '21.7k',
  'liked': 9},
 {'model_name': 'openai/whisper-base',
  'last_updated': '2023-03-10T17:13:49',
  'downloaded': '20.5k',
  'liked': 52},
 {'model_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-dutch',
  'last_updated': '2022-12-14T01:58:20',
  'downloaded': '20.1k',
  'liked': 0},
 {'model_name': 'openai/whisper-medium',
  'last_updated': '2023-03-10T17:15:08',
  'downloaded': '20k',
  'liked': 40},
 {'model_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-portuguese',
  'last_updated': '2022-12-14T01:59:47',
  'downloaded': '19.2k',
  'liked': 11},
 {'model_name': 'facebook/wav2vec2-large-960h',
  'last_updated': '2022-04-05T16:40:42',
  'downloaded': '15.5k',
  'liked': 14},
 {'model_name': 'facebook/data2vec-audio-base-960h',
  'last_updated': '2022-05-24T10:41:22',
  'downloaded': '15.4k',
  'liked': 7},
 {'model_name': 'theainerd/Wav2Vec2-large-xlsr-hindi',
  'last_updated': '2023-03-20T05:28:11',
  'downloaded': '15.3k',
  'liked': 2},
 {'model_name': 'tyoc213/wav2vec2-large-xlsr-nahuatl',
  'last_updated': '2021-04-07T02:59:04',
  'downloaded': '12.5k',
  'liked': 1},
 {'model_name': 'openai/whisper-large',
  'last_updated': '2023-03-10T17:15:11',
  'downloaded': '12k',
  'liked': 228}]
</code></pre>
<p>Also posted a feature request on <a href=""https://discuss.huggingface.co/t/feature-request-listing-available-models-datasets-and-metrics/34389"" rel=""nofollow noreferrer"">https://discuss.huggingface.co/t/feature-request-listing-available-models-datasets-and-metrics/34389</a></p>
","2023-03-22 12:54:56","1","Answer"
"75810348","75809852","","<p>I would suggest to use the <a href=""https://contrib.scikit-learn.org/category_encoders/targetencoder.html"" rel=""nofollow noreferrer"">TargetEncoder</a> from the category_encoders package.</p>
<pre><code>from category_encoders import TargetEncoder

cat_columns = [1, 5, 6, 7, 8, 9, 13, 14]
enc = TargetEncoder(cols=cat_columns).fit(X, y)
# Where X is your exogenous variables pandas dataframe or array and y is your endogenous variable pandas series or array.

numeric_train = enc.transform(X)
</code></pre>
<p>This solution does not change the shape of the original data and it is a better solution thatn just using an ordinal encoding method (replacing variables with 0, 1, 2... with no criteria at all) because it takes into account the relationship between the categorical exogenous variables and the endogenous one. In the linked page there is a more detailed explanation.</p>
<p>Hope this helps!</p>
","2023-03-22 09:20:09","0","Answer"
"75810336","75809852","","<p>I understand that you want to use <code>OneHotEncoder</code>, but only on part of the array, not on all columns.<br />
You can use <code>np.c_</code> to add <code>train_encoded</code> to the non-encoded columns:</p>
<pre class=""lang-py prettyprint-override""><code># train = subset of data used for training, shape (7000, 15)
cat_columns = [1, 5, 6, 7, 8, 9, 13, 14]
ohe = OneHotEncoder(sparse_output=False)

# Encoded columns
train_encoded = ohe.fit_transform(train[:, cat_columns])

# Non encoded columns
train_not_encoded = np.delete(train, cat_columns, 1)

# Merging the two
train_2 = np.c_[train_not_encoded , train_encoded]
</code></pre>
<p>Even easier is using <a href=""https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html"" rel=""nofollow noreferrer""><code>pd.get_dummies</code></a>, which allows you to specify which columns to encode:</p>
<pre class=""lang-py prettyprint-override""><code>import pandas as pd
df = pd.DataFrame(train)
train_2  = pd.get_dummies(df, columns=cat_columns)
</code></pre>
","2023-03-22 09:18:52","1","Answer"
"75810279","75809852","","<p>I don't think you understand the <code>OneHotEncoder</code> correctly. <a href=""https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features"" rel=""nofollow noreferrer"">This</a> here will answer your question far better than I can ever do.</p>
<p><code>OneHotEncoder</code> turns your categorical values to bytes. Bytes are yes/no, true/false, 1/0, whatever; but always just two possibilities.</p>
<p>If your categorical values now are male/female --&gt; Ok, you are good to go turning it to ones and zeros.
If your categorical values are blue/red/green --&gt; Damn, the one/zero representation is not enough.</p>
<p>That's why the <code>OneHotEncoder</code> turns every single value to an array! If you fit red/blue/green to the <code>OneHotEncoder</code> and then transform the value &quot;blue&quot; its representation will be [0, 1, 0], standing for 0 no red, 1 yes blue, 0 no green.</p>
<p>I think what you are looking for is the <code>OrdinalEncoder</code>. That one should not change the shape because it just replaces your &quot;blue&quot; with one number and not a byte array.</p>
<p>Anyway you'll find the <code>OrdinalEncoder</code> also at the Source that I linked you. It should give far more insights than my talk. Hope it helps</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.preprocessing import OrdinalEncoder

data = [['39', 'State-gov', '77516', 'Bachelors', '13', 'Never-married',
  'Adm-clerical', 'Not-in-family', 'White', 'Male', '2174', '0', '40',
  'United-States', '&lt;=50K'],
 ['50', 'Self-emp-not-inc', '83311', 'Bachelors', '13', 'Married-civ-spouse',
  'Exec-managerial', 'Husband' ,'White', 'Male' ,'0', '0', '13' ,'United-States',
  '&lt;=50K'],
 ['38' ,'Private', '215646' ,'HS-grad' ,'9', 'Divorced' ,'Handlers-cleaners',
  'Not-in-family' ,'White' ,'Male', '0', '0', '40', 'United-States' ,'&lt;=50K']
]
df = pd.DataFrame(data)
print(df[cat_columns].shape)  # (3,8)

cat_columns = [1, 5, 6, 7, 8, 9, 13, 14]
ohe = OrdinalEncoder(sparse_output=False)
train_encoded = ohe.fit_transform(df[cat_columns])
print(train_encoded.shape)  # (3,8)
df[cat_columns] = train_encoded
</code></pre>
","2023-03-22 09:11:50","1","Answer"
"75810246","","How to get all hugging face models list using python?","<p>Is there any way to get list of models available on Hugging Face? E.g. for Automatic Speech Recognition (ASR).</p>
","2023-03-22 09:08:48","2","Question"
"75810119","75798983","","<p>You can clone this project into your local .
run command git clone (ssh link)
ssh-in code button you can copy ssh .
then run code . to open vs code</p>
","2023-03-22 08:55:10","0","Answer"
"75809852","","One Hot Encoding for machine learning","<p>I have a dataset stored in a <code>(10000, 15)</code> numpy array. Columns <code>[1, 5, 6, 7, 8, 9, 13, 14]</code> are all categorical, while the rest are numerical data. I need to change the categorical data to numerical to be able to use it in the models (using sklearn).</p>
<p>I have attempted to use OneHotEncoder from the sklearn.preprocessing library,</p>
<pre class=""lang-py prettyprint-override""><code># train = subset of data used for training, shape (7000, 15)
cat_columns = [1, 5, 6, 7, 8, 9, 13, 14]
ohe = OneHotEncoder(sparse_output=False)
train_encoded = ohe.fit_transform(train[:, cat_columns)
train[:, cat_columns] = train_encoded
</code></pre>
<p>Unfortunately, this doesn't work because the data changes shape after being encoded. I would appreciate any suggestions on how to turn this categorical data into numerical.</p>
<p>Here is an example of the first 3 rows of data, the last feature is what will be split off and predicted later on.</p>
<pre><code>[['39' 'State-gov' '77516' 'Bachelors' '13' 'Never-married'
  'Adm-clerical' 'Not-in-family' 'White' 'Male' '2174' '0' '40'
  'United-States' '&lt;=50K']
 ['50' 'Self-emp-not-inc' '83311' 'Bachelors' '13' 'Married-civ-spouse'
  'Exec-managerial' 'Husband' 'White' 'Male' '0' '0' '13' 'United-States'
  '&lt;=50K']
 ['38' 'Private' '215646' 'HS-grad' '9' 'Divorced' 'Handlers-cleaners'
  'Not-in-family' 'White' 'Male' '0' '0' '40' 'United-States' '&lt;=50K']
]
</code></pre>
","2023-03-22 08:24:08","0","Question"
"75808719","75808596","","<p><code>custom_model</code> is removed <a href=""https://github.com/shankarpandala/lazypredict/blob/aad245d602f080575d05ec68750fa9c229aeea30/lazypredict/Supervised.py#L205"" rel=""nofollow noreferrer"">in the latest version</a>. I see the new param <code>classifiers</code> which accepts list, so maybe you can try:</p>
<pre class=""lang-py prettyprint-override""><code>..., classifiers=['random_forest', 'logistic_regression', 'k_nearest_neighbor'])
</code></pre>
","2023-03-22 05:32:03","0","Answer"
"75808596","","How to add custom models in Lazypredict","<p>I am using Lazypredict to run multiple classification models, as my dataset is huge, I am not able to run all the models which are pre-selected in LazyClassifier, rather than using all the models, I am trying to use some selected models i.e. Random Forest and Decision Tree etc. Below is my sample script, But I am getting an error that Custom_Models is not available, May I know if there is any other way to select the customs models in LazyClassifier, I am using 0.2.12 version of lazy predict.</p>
<p>#Updated code as per below suggestion, but still i am getting error,
Below is my script,</p>
<pre><code>import lazypredict
from lazypredict.Supervised import LazyClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

data = load_iris()
X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

#Updated Line
clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None, predictions=True , classifiers=['random_forest', 'logistic_regression', 'k_nearest_neighbor'])
models, predictions = clf.fit(X_train, X_test, y_train, y_test)
</code></pre>
<p>error message:</p>
<pre><code>    'str' object has no attribute '__name__' Invalid Classifier(s)
     too many values to unpack (expected 2)
</code></pre>
","2023-03-22 05:02:20","2","Question"
"75806460","75190328","","<p>You need to loop over the different columns you want to aggregate with</p>
<pre><code>from sklearn.metrics import roc_auc_score as auc

def group_auc(x,y_name,p_name='probability'):
    try:
        return auc(x[y_name],x[p_name])
    except ValueError:
        return np.nan

y_name = 'label'

df[y_name] = df[y_name].apply(lambda x:{'Rejected':1,'Approved':0}.get(x,x))
df = df.dropna(subset = [y_name])

group_data_list = []
for feature in ['feature1','feature2','feature3']:
    temp = df.groupby([pd.Grouper(key='datetime',freq='m'),feature])
    temp = temp.apply(lambda x: group_auc(x,y_name))
    temp = temp.reset_index()
    temp['features'] = feature
    temp = temp.rename(columns={feature:'value',0:'AUC'})
    group_data_list.append(temp.copy())
group_data = pd.concat(group_data_list)   
group_data[['datetime','features','value','AUC']]
</code></pre>
<p>Note that the <code>group_auc</code> function also needs an exception handling otherwise an exception will be raised when a group only contains 1 point.</p>
<p>Lastly I have taken the liberty of substituting the creation of an explicit <code>Month_Year</code> column with a <code>pd.Grouper</code> which gives a little more versatility. As the code is written the Time-Grouper can be removed and the code will still function.</p>
","2023-03-21 21:22:42","0","Answer"
"75806018","75798983","","<p>First off, this project seems to be made for Linux, but alright!</p>
<p>Here are the steps I would recommand:<br>
1 - Follow this tutorial <a href=""https://www.geeksforgeeks.org/how-to-install-rubygems-in-windows/"" rel=""nofollow noreferrer"">https://www.geeksforgeeks.org/how-to-install-rubygems-in-windows/</a><br>
2 - Run the following command on PowerShell using Administrator Mode</p>
<pre class=""lang-bash prettyprint-override""><code>gem install anystyle
</code></pre>
<p>3 - Follow the rest of the tutorial on the rest of the github page you gave<br></p>
<p>Also, here is a small advice:
Give more details to where you are stuck. I assumed you have not tried installing Ruby, but I may be wrong!</p>
<p>Hope to have helped you</p>
","2023-03-21 20:21:48","0","Answer"
"75804690","75800779","","<p>Since you are getting the same output irrespective of whatever input you are giving to the network, it seems that the network has learned a constant value which minimizes the loss function for all the inputs. In other words, the network hasn't &quot;learned&quot; anything. It would have been useful if you could also plot the loss curves.</p>
<p>Also, from the code snippets you shared and looking at the dataset, it seems like you are just training on the raw input data without doing any form of pre-processing. Your network, right now, takes in a 7-dimensional input, the raw values of which are different units, ranges etc. (For example, age and height have a completely different range of values). It will be very difficult to train a neural network like this. You could start with normalising/standardising all your input values to be within a common range eg. [0,1] or [-1,1].</p>
","2023-03-21 17:43:41","0","Answer"
"75804678","75791020","","<p>The ModelCheckpoint callback in PyTorch Lightning saves the best model based on a monitored metric, specified by the monitor parameter. In this case, the monitor parameter is set to val_loss, which means the ModelCheckpoint is trying to save the model based on the validation loss. However, the error message is indicating that the val_loss metric is not found in the returned metrics from the LightningModule.</p>
<p>To resolve this error, you need to make sure that the LightningModule is logging the val_loss metric using the log method. For example, in your validation loop, you can log the validation loss like this:</p>
<pre><code>def validation_step(self, val_batch, val_batch_idx):
    x, y = val_batch
    pred = self.forward(x)
    loss = self.loss_fn(pred, y)
    self.log('val_loss', loss, prog_bar=True)
    return loss
</code></pre>
<p>self.loss_fn: is defined by yourself what ever you want to compute the loss of model</p>
","2023-03-21 17:42:17","2","Answer"
"75800779","","I get the same prediction for different inputs (PyTorch Neural Network regression problem)","<p>I am trying to predict the number of calories burned in exercise using an ANN in PyTorch</p>
<p>Dataset can be found here: <a href=""https://www.kaggle.com/datasets/fmendes/fmendesdat263xdemos"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/fmendes/fmendesdat263xdemos</a></p>
<p>My issue is that the predictions that are being outputted by my model are the same for every row (I have attached an image to this post). I have tried varying the learning rates of my model to see if this would help but it hasn't. I have also tried asking ChatGPT but it hasn't given me any real solution to the problem.</p>
<p>Here is the code I have used so far:</p>
<h3>Library Imports</h3>
<pre><code>import numpy as np 
import pandas as pd 
import torch 
import torch.nn as nn
</code></pre>
<h3>Data Pre-Processing</h3>
<pre><code>calories = pd.read_csv(&quot;calories.csv&quot;)
excercise = pd.read_csv(&quot;exercise.csv&quot;)
df = pd.concat(\[excercise,calories\],axis=1,join=&quot;outer&quot;)


df = df.drop('User_ID',axis=1)
df.head()

data = pd.get_dummies(df,drop_first=True)

X = torch.tensor(np.array(data.drop(&quot;Calories&quot;,axis=1))).float()
y = torch.tensor(data\['Calories'\],dtype=torch.float).reshape(-1,1)
</code></pre>
<h3>Creating ANN Class</h3>
<pre><code>class Ann_Predictor(nn.Module):
def __init__(self, n_layers, n_units):
super().__init__()
        self.n_layers = n_layers
        self.layers = nn.ModuleDict()
    
        self.layers[&quot;input&quot;] = nn.Linear(7,n_units)
    
        for i in range(n_layers):
            self.layers[f&quot;hidden{i}&quot;] = nn.Linear(n_units,n_units)
        
        self.layers[&quot;output&quot;] = nn.Linear(n_units,1)
    
    def forward(self, x):
    
        # forward pass
    
        x = self.layers['input'](x)
    
        for i in range(self.n_layers):
            x = F.relu(self.layers[f&quot;hidden{i}&quot;](x))
    
        x = self.layers[&quot;output&quot;](x)
    
        return x
</code></pre>
<h3>Function to instantiate Model, Loss Function and Optimizer</h3>
<pre><code>def create_model():

    ann = Ann_Predictor(3,8)
    loss_func = nn.MSELoss()
    learning_rate = 0.005
    optimizer = torch.optim.SGD(ann.parameters(),lr=learning_rate)
    
    return ann, loss_func, optimizer
</code></pre>
<h3>Model Training &amp; Predictions</h3>
<pre><code>numepochs = 500
losses = torch.zeros(numepochs)

ann, loss_func, optimizer = create_model()

for epoch in range(numepochs):
y_hat = ann(X)
loss = loss_func(y_hat, y)
losses\[epoch\] = loss

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# Predicting Using Model

predictions  = ann(X)
print(predictions)
</code></pre>
<p>Here is an image of the predictions output (same value everywhere): <a href=""https://i.sstatic.net/xITzK.png"" rel=""nofollow noreferrer"">Predictions Output</a></p>
<p>As stated earlier I have tried varying the learning rates and asking ChatGPT but have found no solution to the problem.</p>
","2023-03-21 11:47:38","1","Question"
"75799317","75759382","","<p>The &quot;openvino.runtime&quot; module is used to create a Core Object in the new OpenVINO API 2.0 Inference Engine Pipeline. The new API 2.0 was introduced starting in 2022.1.</p>
<p>Use  &quot;from openvino.runtime import Core&quot; to import OpenVINO.</p>
","2023-03-21 09:24:10","0","Answer"
"75798983","","How to run following ruby project?","<p>I want to run following ruby project in my local vs code editor in Windows 10.
<a href=""https://github.com/inukshuk/anystyle"" rel=""nofollow noreferrer"">https://github.com/inukshuk/anystyle</a>
Can somebody please please help?</p>
<p>I don't know how to run it in local.</p>
","2023-03-21 08:48:37","-2","Question"
"75793658","","How to achieve realistic lip color change using OpenCV and Mediapipe?","<p>I need help with changing the lip color of a person in a video using Mediapipe. I've used Mediapipe for facial landmark detection and tracking, but I'm not sure how to proceed with changing the lip color. I couldn't find any resources on how to achieve this in the Mediapipe documentation.</p>
<p>This has to do more with OpenCV than Mediapipe. You might want to search for how to fill a polygon using cv2.fillPoly. You will need the landmarks to define the contour you can refer to this image here to find which landmarks.</p>
<p>I'm using Python and OpenCV. Running the code on Google Colab.
I did try the method suggested by @fadiaburaid but the result was not up to the mark. The polygons seems to dance as the coords detected by Mediapipe were continuously changing and the polygons drawn on the image seemed visibly heterogenous. I tried feathering, but it didn't bring quality of results to an acceptable level.</p>
<p>Any suggestion to improve and stabilize the polygon blending are welcome!!</p>
<h1>Face Cropping</h1>
<pre><code>from google.colab import output
from google.colab.patches import cv2_imshow

import cv2
import mediapipe as mp

# Load the MediaPipe Face Detection model
mp_face_detection = mp.solutions.face_detection

# Initialize the Face Detection model
face_detection = mp_face_detection.FaceDetection()

# Load the image
image = cv2.imread('/content/wallpaper.png')

# Convert the image to RGB
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Detect faces in the image
results = face_detection.process(image)

# Get the first detected face
face = results.detections[0]

# Get the bounding box of the face
x1 = int(face.location_data.relative_bounding_box.xmin * image.shape[1])
y1 = int(face.location_data.relative_bounding_box.ymin * image.shape[0])
x2 = int(x1 + face.location_data.relative_bounding_box.width * image.shape[1])
y2 = int(y1 + face.location_data.relative_bounding_box.height * image.shape[0])

# Calculate the size of the square bounding box
size = max(x2 - x1, y2 - y1)

# Calculate the center of the bounding box
center_x = (x1 + x2) // 2
center_y = (y1 + y2) // 2

# Calculate the coordinates of the square bounding box
x1_square = center_x - size // 2
y1_square = center_y - size // 2

x2_square = x1_square + size 
y2_square= y1_square + size 

# Crop and show square face region from original image 
square_face_region=image[y1_square:y2_square,x1_square:x2_square]

resized_image=cv2.resize(square_face_region,(480,480))
resized_image_bgr = cv2.cvtColor(resized_image, cv2.COLOR_RGB2BGR)

# Save the image
cv2.imwrite('resized_image.jpg', resized_image_bgr)

</code></pre>
<h1>Mask Generation</h1>
<pre><code>import itertools
import numpy as np

# Load the MediaPipe Face Mesh model
mp_face_mesh = mp.solutions.face_mesh

# Initialize the Face Mesh model
face_mesh = mp_face_mesh.FaceMesh( static_image_mode=True,refine_landmarks=True,min_detection_confidence=0.5)

image = resized_image_bgr

# Define the left eye landmark indices
# LIPS = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LIPS)))

# upper = [409,405,375,321,314,267,269,270,291,146,181,185,91,84,61,37, 39, 40,0,17]
# lower = [402,415,312,311,310,308,324,318,317,178,191,80, 81, 82,87, 88,95,78,13, 14]

upper_new = [0,267,269,270,409,291,375,321,405,314,17,84,181,91,146,61,185,40,39,37]
lower_new = [13,312,311,310,415,308,324,318,402,317,14,87,178,88,95,78,191,80,81,82]


# Detect the face landmarks
results = face_mesh.process(image)

# Create an empty mask with the same shape as the image
mask_upper = np.zeros(image.shape[:2], dtype=np.uint8)

# Draw white polygons on the mask using the upper landmarks
for face_landmarks in results.multi_face_landmarks:
    points_upper = []
    for i in upper_new:
        landmark = face_landmarks.landmark[i]
        x = int(landmark.x * image.shape[1])
        y = int(landmark.y * image.shape[0])
        points_upper.append((x, y))
    cv2.fillConvexPoly(mask_upper, np.int32(points_upper), 255)


# Create an empty mask with the same shape as the image
mask_lower = np.zeros(image.shape[:2], dtype=np.uint8)

# Draw white polygons on the mask using the lower landmarks
for face_landmarks in results.multi_face_landmarks:
    points_lower = []
    for i in lower_new:
        landmark = face_landmarks.landmark[i]
        x = int(landmark.x * image.shape[1])
        y = int(landmark.y * image.shape[0])
        points_lower.append((x, y))
    cv2.fillPoly(mask_lower, np.int32([points_lower]), 255)

# Subtract the lower mask from the upper mask
mask_diff = cv2.subtract(mask_upper, mask_lower)

# Apply morphology operations to smooth mask 
kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5 ,5))
mask_diff=cv2.morphologyEx(mask_diff,cv2.MORPH_OPEN,kernel)
mask_diff=cv2.morphologyEx(mask_diff,cv2.MORPH_CLOSE,kernel)

cv2_imshow(mask_diff)
</code></pre>
<h1>Mask Blending</h1>
<pre><code># Convert the mask to 3 channels
mask_diff_3ch = cv2.cvtColor(mask_diff, cv2.COLOR_GRAY2BGR)

image = cv2.imread('/content/resized_image.jpg')

# Apply the mask to the original image
masked_image = cv2.bitwise_and(image, mask_diff_3ch)

cv2_imshow(masked_image)

def create_colored_mask(hex_color, shape):
    # Convert the hex color code to an RGB tuple
    rgb_color = tuple(int(hex_color[i:i+2], 16) for i in (0, 2 ,4))
    
    # Create a blank mask with the given shape
    colored_mask = np.zeros(shape, dtype=np.uint8)
    
    # Set the color channels according to the chosen RGB color
    colored_mask[:,:,0] = rgb_color[2]
    colored_mask[:,:,1] = rgb_color[1]
    colored_mask[:,:,2] = rgb_color[0]
    
    return colored_mask

# Create a 3-channel version of your mask_diff array
mask_diff_3ch = cv2.cvtColor(mask_diff,cv2.COLOR_GRAY2BGR)

# Ask the user to enter a hex color code for their mask
hex_color = input('Enter a hex color code for your mask (e.g. FF0000 for red): ')

# Create a colored mask with the chosen hex color and same shape as your original mask
colored_mask = create_colored_mask(hex_color, mask_diff_3ch.shape)

# Apply the colored mask where your original mask is True
masked_image = cv2.bitwise_and(colored_mask,colored_mask ,mask=mask_diff)

# Superimpose the colored mask on your original image
final_image = cv2.addWeighted(image, 1 , masked_image ,1 ,0)

cv2_imshow(final_image)
</code></pre>
<h1>I'm getting following results from above code. But I want much higher quality result from both video or photo input.</h1>
<p><a href=""https://i.sstatic.net/7kDlr.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>Input Image: <a href=""https://i.sstatic.net/1jd0u.png"" rel=""nofollow noreferrer"">Input Image</a></p>
<p>Cropped Input Image: <a href=""https://i.sstatic.net/GSBeF.jpg"" rel=""nofollow noreferrer"">Cropped Input Image</a></p>
<p>Mask Image: <a href=""https://i.sstatic.net/GkluB.png"" rel=""nofollow noreferrer"">Mask Image</a></p>
<p>Final Image: <a href=""https://i.sstatic.net/rGz1K.png"" rel=""nofollow noreferrer"">Final Image with Masking</a></p>
","2023-03-20 17:50:46","1","Question"
"75791020","","Why doesn't PyTorch Lightning module save logged val loss? ModelCheckpoint error","<p>I'm running an LSTM-based model training on Kaggle. I use Pytorch Lightning and wandb logger for that.</p>
<p>That's my model's class:</p>
<pre><code>class Model(pl.LightningModule):
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        bidirectional: bool = False,
        lstm_layers: int = 1,
        lstm_dropout: float = 0.4,
        fc_dropout: float = 0.4,
        lr: float = 0.01,
        lr_scheduler_patience: int = 2,
    ):
        super().__init__()
        self.lr = lr
        self.save_hyperparameters()

        # LSTM
        self.encoder_lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=lstm_layers,
            bidirectional=bidirectional,
            dropout=lstm_dropout if lstm_layers &gt; 1 else 0,
            batch_first=True,
        )

        # Fully-connected
        num_directions = 2 if bidirectional else 1
        self.fc = nn.Sequential(
            nn.Linear(
                hidden_size * num_directions, hidden_size * num_directions * 2
            ),
            nn.ReLU(),
            nn.Dropout(fc_dropout),
            nn.Linear(hidden_size * num_directions * 2, input_size),
        )

        self.loss_function = nn.MSELoss()

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)
        return {
            &quot;optimizer&quot;: optimizer,
            &quot;lr_scheduler&quot;: {
                &quot;scheduler&quot;: torch.optim.lr_scheduler.ReduceLROnPlateau(
                    optimizer, patience=self.hparams.lr_scheduler_patience
                ),
                &quot;monitor&quot;: &quot;val_loss&quot;,
            },
        }

    def forward(self, x, prev_state):
        ...

    def training_step(self, batch, batch_idx):
        loss, _ = self._step(batch)

        self.log(&quot;train_loss&quot;, loss)
        return loss

    def validation_step(self, batch, batch_idx):
        loss, embeddings = self._step(batch)

        self.log(&quot;val_loss&quot;, loss)
        
        return {
            'val_loss': loss,
            'preds': embeddings # this is consumed by my custom callback
        }

    def test_step(self, batch, batch_idx):
        loss, _ = self._step(batch)

        self.log(&quot;test_loss&quot;, loss)
</code></pre>
<p>And that's how I use it:</p>
<pre><code>model = Model(
    bidirectional=False,
    lstm_layers=1,
    lstm_dropout=0.4,
    fc_dropout=0.4,
    lr=0.01,
    lr_scheduler_patience=2
)

...

checkpoint_callback = ModelCheckpoint(
    monitor=&quot;val_loss&quot;,
    every_n_train_steps=100,
    verbose=True
)

trainer = pl.Trainer(
    accelerator='gpu',
    precision=16,
    max_epochs=100,
    callbacks=[early_stopping, checkpoint_callback, lr_monitor, custom_callback],
    log_every_n_steps=50,
    logger=wandb_logger,
    auto_lr_find=True,
)

trainer.tune(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)

trainer.fit(model, train_dataloader, val_dataloader)
</code></pre>
<p>When I don't run <code>trainer.tune(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)</code> <code>trainer.fit</code> works perfectly but when I run 'trainer.tune' I get such ModelCheckpoint error:</p>
<pre><code>MisconfigurationException: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['train_loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?

</code></pre>
<p>So even though I log <code>val_loss</code> it doesn't get saved. On the Trainer object I set <code>log_every_n_steps=50</code> and on the ModelCheckpoint I set <code>every_n_train_steps=100</code> so it seems that it should have 'val_loss' logged by the moment ModelCheckpoint gets going.</p>
<p>I printed val loss in <code>validation_step</code> and it gets computed before ModelCheckpoint is run. I also defined an <code>on_train_batch_end</code> function in my custom callback to see saved trainer metrics. It turns out that val loss is in fact missing.</p>
","2023-03-20 13:43:02","1","Question"
"75790706","75737232","","<h1>Update</h1>
<p>I've published a starter notebook on kaggle with BD100K dataset, by using HuggingFace and KerasCV library.</p>
<p><a href=""https://www.kaggle.com/code/ipythonx/bdd100k-huggingface-kerascv-segmentation/"" rel=""nofollow noreferrer"">BDD100K HuggingFace &amp; KerasCV Segmentation</a></p>
<hr />
<p>As there is no reproducible code, it is hard to spot the main issue. But I've successfully trained SegFormer model with BDD10K dataset on semantic segmentation task. I'm sharing the solutions. I've used data and tested on kaggle environment, <a href=""https://www.kaggle.com/datasets/solesensei/solesensei_bdd100k"" rel=""nofollow noreferrer"">bdd100k-dataset</a>. Here is the complete <a href=""https://colab.research.google.com/drive/1A8dzjo5LrmjDDUSwjrTv7-zxx0gI1rdz?usp=sharing"" rel=""nofollow noreferrer"">code</a>. To make the test more complete, I've used this dataset on huggingface model (seg-former) and also with open source segmentation model (unet-efficientnet-b0).</p>
<p>One of the key difference perhaps in the above gist is how the data is being processed. The functionality likes <code>DatasetDict</code>, <code>DefaultDataCollator</code>, <code>AutoImageProcessor</code> are abset in the above gist. Only <code>TFSegformerForSemanticSegmentation</code> is present. It is better to perform data processing by looking at the code rather than relying on some auto tools.</p>
<p>Another difference for the huggingfacae model is, we can't pass custom or built-in loss function (also metrics), that is real unfortunate. In their <a href=""https://github.com/stevhliu/transformers/blob/4522ed39d29009e16e833b524350d6b9278bee73/docs/source/en/tasks/semantic_segmentation.mdx"" rel=""nofollow noreferrer"">doc</a>, they showed some approach to evaluate the model but the procedure is for torch model. To realize on this issue, it would be better to reach huggingface forum.</p>
<p>Here is the <a href=""https://colab.research.google.com/drive/1A8dzjo5LrmjDDUSwjrTv7-zxx0gI1rdz?usp=sharing"" rel=""nofollow noreferrer"">Full code</a>, and below are some highlights.</p>
<p><strong>Preprocess and Dataloader (BDD100K)</strong></p>
<pre><code>data_path = 'bdd100k/seg/'
image_path = os.path.join(data_path, 'images', 'train')
label_path = os.path.join(data_path, 'labels', 'train')

def read_files(image_path, mask=False):
    image = tf.io.read_file(image_path)
    if mask:
        image = tf.image.decode_png(image, channels=1)
        image.set_shape([None, None, 1])
        image = tf.image.resize(
            images=image, 
            size=[IMAGE_SIZE, IMAGE_SIZE], 
            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR
        )
        image = tf.where(image == 255, np.dtype('uint8').type(0), image)
        image = tf.cast(image, tf.int32)
    else:
        image = tf.image.decode_png(image, channels=3)
        image.set_shape([None, None, 3])
        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])
        image = image / 255.
    return image
</code></pre>
<pre><code>def load_data_HF(image_list, mask_list):
    image = read_files(image_list)
    mask  = read_files(mask_list, mask=True)
    image = tf.transpose(image, (2, 0, 1))
    mask = tf.squeeze(mask)
    return {&quot;pixel_values&quot;: image, &quot;labels&quot;: mask}

def data_generator_HF(image_list, mask_list, split='train'):
    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))
    dataset = dataset.shuffle(10 * BATCH_SIZE) if split == 'train' else dataset 
    dataset = dataset.map(load_data_HF, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)
    return dataset.prefetch(tf.data.AUTOTUNE)

images = image_path
masks = label_path

train_ds_hf = data_generator_HF(images, masks)
val_ds_hf = data_generator_HF(images, masks, split='validation')
</code></pre>
<p><strong>Segformer (Huggingface-Transformer)</strong></p>
<pre><code>from transformers import TFSegformerForSemanticSegmentation

model_checkpoint = &quot;nvidia/mit-b0&quot;
num_labels = n_classes
model_hf = TFSegformerForSemanticSegmentation.from_pretrained(
    model_checkpoint,
    num_labels=num_labels,
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True,
)

optim = tf.keras.optimizers.Adam(0.001)
model_hf.compile(optimizer=optim)

model_hf.fit(
    train_ds_hf, 
    validation_data=val_ds_hf,
    epochs=5
)
</code></pre>
<pre><code>73s 954ms/step - loss: 1.3698 - val_loss: 1.0942
Epoch 2/5
7s 382ms/step - loss: 0.8068 - val_loss: 1.0197
Epoch 3/5
7s 375ms/step - loss: 0.7110 - val_loss: 0.8641
Epoch 4/5
7s 388ms/step - loss: 0.6365 - val_loss: 0.8025
Epoch 5/5
7s 377ms/step - loss: 0.5678 - val_loss: 0.7920
&lt;keras.callbacks.History at 0x7f5f11bf9710&gt;
---
</code></pre>
<p>Some resource</p>
<ul>
<li><a href=""https://www.kaggle.com/code/ipythonx/stanford-background-scene-understanding-starter"" rel=""nofollow noreferrer"">stanford-background-scene-understanding-starter</a></li>
</ul>
","2023-03-20 13:11:21","2","Answer"
"75789024","75788864","","<p>There's a pretty different approach to solving this question.</p>
<p>Create a dictionary for the items where the key represents the city name and the value represents the number(index)</p>
<pre><code>cities = {'new york': 1, 'Tokyo': 2, 'Miami':3, 'Dallas': 4}
data = ['new york', 'Tokyo', 'Miami', 'new york', 'Dallas']
</code></pre>
<p>then create a list from the data available using a list comprehension to create the list from the ids</p>
<pre><code>cities_id = [cities[city] for city in data]
print(cities_id) // [1, 2, 3, 1, 4]
</code></pre>
","2023-03-20 10:16:15","0","Answer"
"75789002","75788864","","<p>You could create a dictionary assigning a number to a city:</p>
<pre class=""lang-py prettyprint-override""><code>CityDict={
    &quot;new york&quot; : 1,
    &quot;los angoles&quot; : 2,
    &quot;miami&quot; : 3,
    &quot;dallas&quot; : 4,
}
</code></pre>
<p>Then replace the list of data by the index:</p>
<pre class=""lang-py prettyprint-override""><code>cities=[&quot;new york&quot;, &quot;los angeles&quot;, &quot;miami&quot;, &quot;new york&quot;, &quot;dallas&quot;]
cityindexes=[CityDict[x] for x in cities]

</code></pre>
","2023-03-20 10:13:54","0","Answer"
"75788990","75788864","","<p>With a sample dataframe as the following:</p>
<pre><code>df = pd.DataFrame({'cities': ['new york', 'los angeles', 'miami', 'new york', 'dallas'], 'values': [100, 200, 300, 400, 500]})
print(df)

        cities  values
0     new york     100
1  los angeles     200
2        miami     300
3     new york     400
4       dallas     500
</code></pre>
<p>You can do the following to get the codes:</p>
<pre><code>df['code'] = pd.factorize(df['cities'])[0]
print(df)

        cities  values  code
0     new york     100     0
1  los angeles     200     1
2        miami     300     2
3     new york     400     0
4       dallas     500     3
</code></pre>
<p>If you want to set specific codes for each city you can do the following instead.</p>
<pre><code>mappings = {'new york': 14, 'los angeles': 21, 'miami': 35, 'dallas': 0}
# Set your desired codes in te mappings dictionary
df['code'] = df['cities'].map(mappings)

print(df)

        cities  values  code
0     new york     100    14
1  los angeles     200    21
2        miami     300    35
3     new york     400    14
4       dallas     500     0
</code></pre>
","2023-03-20 10:12:38","0","Answer"
"75788894","75788864","","<p>You can use the <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"" rel=""nofollow noreferrer"">LabelEncoder</a> from scikit-learn.</p>
<p>Example (from the <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"" rel=""nofollow noreferrer"">docs</a>):</p>
<pre><code>&gt;&gt;&gt; le = preprocessing.LabelEncoder()
&gt;&gt;&gt; le.fit([&quot;paris&quot;, &quot;paris&quot;, &quot;tokyo&quot;, &quot;amsterdam&quot;])
LabelEncoder()
&gt;&gt;&gt; list(le.classes_)
['amsterdam', 'paris', 'tokyo']
&gt;&gt;&gt; le.transform([&quot;tokyo&quot;, &quot;tokyo&quot;, &quot;paris&quot;])
array([2, 2, 1]...)
&gt;&gt;&gt; list(le.inverse_transform([2, 2, 1]))
['tokyo', 'tokyo', 'paris']
</code></pre>
","2023-03-20 10:03:09","1","Answer"
"75788864","","Converting datas in string to integer","<p>I need some advice, i have some data like example (new york, los angeles, miami, new york, dallas, etc). And i want to convert this list to number like (1, 2, 3, 1, 4, etc) in python. What keywords is it or how to do it?</p>
<p>I have searching for hours and just found how to convert the dataype. I want that data of some cities to become some number for data mining.</p>
","2023-03-20 09:59:13","-1","Question"
"75784441","75521999","","<p>I also find the same error with the below code.</p>
<pre><code>  final_preds = [mode([i,j,k])[0][0] for i,j,k in zip(svm_preds, 
  nb_preds, rf_preds)]
</code></pre>
<p>Then I update code:</p>
<pre><code>final_preds = [mode([i,j,k], keepdims=True)[0][0] for i,j,k in 
zip(svm_preds, nb_preds, rf_preds)]
</code></pre>
<p>And found no error.</p>
<p>You can also try by adding &quot;keepdims=True&quot;</p>
","2023-03-19 19:23:13","0","Answer"
"75783524","","Train gpt-3 on email conversations","<p>I have to train gpt-3 on email data, so that the support team can get a quick answer from a chat-bot, for questions that were asked before by customers. There are email conversations between customers and the support team (Customer1 ask question, Support answers, Customer1 asks another question … ). I have to:</p>
<ol>
<li>Filter important conversations and only feed gpt-3 with them.</li>
<li>prepare and convert them into the right format, so that I can train the model.</li>
</ol>
<p>Are there any ideas about how to realize these steps and whether to use fine tuning or embeddings?</p>
<p>gpt-3 has to connect the questions to the answers that were given by the support team.</p>
","2023-03-19 16:44:07","-1","Question"
"75778097","75773430","","<p>Thanks to ChatGPT and all who responded here.  I've got the complete solution below:</p>
<pre><code>import numpy as np
import pandas as pd
from sklearn.compose import make_column_transformer
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

# https://towardsdatascience.com/guide-to-encoding-categorical-features-using-scikit-learn-for-machine-learning-5048997a5c79

if __name__ == '__main__':
    df = pd.read_csv('../../resources/StudentsPerformance.csv')
    print(df.info())
    print(df.describe())

    # five categorical independent variables, three numeric dependent variables
    # calculate correlation for math, reading, and writing scores
    numerical_attributes = ['math score', 'reading score', 'writing score']
    numerical_data = df[numerical_attributes]
    categorical_attributes = ['gender', 'race/ethnicity', 'lunch', 'test preparation course']
    categorical_data = df[categorical_attributes]
    ordinal_attributes = ['parental level of education']
    ordinal_data = df[ordinal_attributes]

    corr_matrix = numerical_data.corr()
    # https://stackoverflow.com/questions/31698861/add-column-to-the-end-of-pandas-dataframe-containing-average-of-previous-data
    df = df.assign(mean_score = df[numerical_attributes].mean(axis=1, numeric_only=True))

    # Begin data analysis
#    score_by_gender = numeric_data_with_mean_score.groupby('gender')['mean_score'].mean()
#    score_by_race   = numeric_data_with_mean_score.groupby('race/ethnicity')['mean_score'].mean()
#    score_by_edu    = numeric_data_with_mean_score.groupby('parental level of education')['mean_score'].mean()
#    score_by_lunch  = numeric_data_with_mean_score.groupby('lunch')['mean_score'].mean()
#    score_by_prep   = numeric_data_with_mean_score.groupby('test preparation course')['mean_score'].mean()
#
#    c = ['red', 'orange', 'yellow', 'green', 'blue']
#    for i in range(0, len(categorical_attributes)):
#        plt.bar(numeric_data_with_mean_score[categorical_attributes[i]], numeric_data_with_mean_score['mean_score'])
#        plt.show()
#
#    # https://www.machinelearningplus.com/plots/matplotlib-histogram-python-examples/
#    plt.hist(numeric_data_with_mean_score['mean_score'], bins=50, color='red')
#    # https://www.machinelearningplus.com/plots/matplotlib-histogram-python-examples/
#    sns.displot(numeric_data_with_mean_score['mean_score'], color='dodgerblue')
#    plt.show()
    # End exploratory data analysis

    # Begin data cleaning
    X = df.drop(columns=['math score', 'reading score', 'writing score', 'mean_score'], axis=1)
    y = df['mean_score']
    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform='pandas')
    education_levels = [
        &quot;some high school&quot;,
        &quot;high school&quot;,
        &quot;some college&quot;,
        &quot;associate's degree&quot;,
        &quot;bachelor's degree&quot;,
        &quot;master's degree&quot;,
        &quot;doctorate&quot;]
    oe  = OrdinalEncoder(categories=[education_levels])
    # encoded_data = pd.DataFrame(ohe.fit_transform(df[categorical_attributes]))
    # df = df.join(encoded_data)
    # encoded_data = pd.DataFrame(ohe.fit_transform(df[ordinal_attributes]))
    # df = df.join(encoded_data)
    column_transformer = make_column_transformer(
        (ohe, categorical_attributes),
        (oe, ordinal_attributes))
    # End data cleaning

    # Model pipelines
    # linear and gradient boost regressions
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)
    lm = LinearRegression()
    lm_pipeline = make_pipeline(column_transformer, lm)
    lm_pipeline.fit(X_train, y_train)
    lm_predictions = lm_pipeline.predict(X_test)
    lm_mae = mean_absolute_error(lm_predictions, y_test)
    lm_rmse = np.sqrt(mean_squared_error(lm_predictions, y_test))

    gbm = GradientBoostingRegressor()
    gbm_pipeline = make_pipeline(column_transformer, gbm)
    gbm_pipeline.fit(X_train, y_train)
    gbm_predictions = gbm_pipeline.predict(X_test)
    gbm_mae = mean_absolute_error(gbm_predictions, y_test)
    gbm_rmse = np.sqrt(mean_squared_error(gbm_predictions, y_test))
</code></pre>
","2023-03-18 19:12:51","-1","Answer"
"75776358","75737232","","<p>This might be due to a variety of factors, including:</p>
<p>It seems that there is a discrepancy in the number of classes. Check that the prediction dimension of your model matches the number of classes in the dataset you're working on. Please check your dataset labels.</p>
<p>Try this colab notebook: <a href=""https://shorturl.at/hBHLR"" rel=""nofollow noreferrer"">shorturl.at/hBHLR</a></p>
","2023-03-18 14:02:04","1","Answer"
"75776056","75773430","","<p>The below quick fix worked for me.</p>
<pre><code>np_education_levels = [np.array(education_levels, dtype=object)]
</code></pre>
<p>The above representation is the same format when you access the attribute <strong>oe.categories</strong> after you <strong>fit()</strong></p>
<p>But, when using list() instead of [] gave me the same error :(
Full code below</p>
<pre><code>import pandas as pd
import numpy as np
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

X = pd.read_csv(r&quot;datasets/StudentsPerformance.csv&quot;)

categorical_attributes = ['gender', 'race/ethnicity', 'lunch', 'test preparation course']
ordinal_attributes = ['parental level of education']

education_levels = [
    &quot;some high school&quot;,
    &quot;high school&quot;,
    &quot;some college&quot;,
    &quot;associate's degree&quot;,
    &quot;bachelor's degree&quot;,
    &quot;master's degree&quot;]

# the modified line below
np_education_levels = [np.array(education_levels, dtype=object)]

ohe = OneHotEncoder(sparse_output=False)
oe = OrdinalEncoder(categories=np_education_levels)

column_transformer = make_column_transformer(
    (ohe, categorical_attributes),
    (oe, ordinal_attributes)).set_output(transform=&quot;pandas&quot;)

X_transformed = column_transformer.fit_transform(X)
</code></pre>
","2023-03-18 13:00:51","1","Answer"
"75775979","","TypeError in librosa, MFCC","<p>I have the code below, which takes an data set(GTZAN) and turns it into an MFCC in dictionary:</p>
<pre><code>DATASET_PATH = '/content/drive/MyDrive/ColabNotebooksNew/PROJECT/ProjectMusic/Data/genres_original'
JSON_PATH = &quot;data_10.json&quot;
SAMPLE_RATE = 22050 #each song is 30s long, with a 22,050 Hz sample rate
TRACK_DURATION = 30 # measured in seconds
SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION #=661,500


def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):

    # dictionary to store mapping, labels, and MFCCs
    data = {
        &quot;mapping&quot;: [], #label names. size - (10,)
        &quot;labels&quot;: [],  #Stores the 'real' song type(value from 0-9). size - (5992,)
        &quot;mfcc&quot;: []     #store the mfccs.size - (5992, 216, 13)
    }

    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)  #=110250
    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length) #=216(math.ceil of 215.332)
    # loop through all genre sub-folder
    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):

      # ensure we're processing a genre sub-folder level
      if dirpath is not dataset_path:

          # save genre label (i.e., sub-folder name) in the mapping
          semantic_label = dirpath.split(&quot;/&quot;)[-1]
          data[&quot;mapping&quot;].append(semantic_label)
          print(&quot;\nProcessing: {}&quot;.format(semantic_label))
          # process all audio files in genre sub-dir
          for f in filenames:

            # load audio file

            file_path = os.path.join(dirpath, f)
        
            if file_path != '/content/drive/MyDrive/ColabNotebooksNew/PROJECT/ProjectMusic/Data/genres_original/jazz/jazz.00054.wav': 
              &quot;&quot;&quot;fileError: Error opening '/content/drive/MyDrive/ColabNotebooksNew/PROJECT/ProjectMusic/Data/genres_original/jazz/jazz.00054.wav': File contains data in an unknown format.&quot;&quot;&quot;

              signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE) #signal= how much samples in the audio file, sample rate = num of sample rate of the audio file, sample=22050

              # process all segments of audio file
              for d in range(num_segments):

                # calculate start and finish sample for current segment
                start = samples_per_segment * d
                finish = start + samples_per_segment

                # extract mfcc
                mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length) #mfcc - time and Coef(13 because num_mfcc=13), 
                mfcc = mfcc.T #[216,13]
                # store only mfcc feature with expected number of vectors
                if len(mfcc) == num_mfcc_vectors_per_segment: #==216
                    data[&quot;mfcc&quot;].append(mfcc.tolist())
                    data[&quot;labels&quot;].append(i-1)
                    print(&quot;{}, segment:{}&quot;.format(file_path, d+1))
    # save MFCCs to json file
    with open(json_path, &quot;w&quot;) as fp:
        json.dump(data, fp, indent=4) #puts everything in the Json File
</code></pre>
<pre><code># Runs Data Processing     
save_mfcc(DATASET_PATH, JSON_PATH, num_segments=6)
</code></pre>
<p>I have been using this code for a long while, it has worked great until today I got an error as below:</p>
<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-10-4a9371926618&gt; in &lt;module&gt;
      1 # Runs Data Processing
----&gt; 2 save_mfcc(DATASET_PATH, JSON_PATH, num_segments=6)

&lt;ipython-input-9-8ba1c6e78747&gt; in save_mfcc(dataset_path, json_path, num_mfcc, n_fft, hop_length, num_segments)
     56 
     57                 # extract mfcc
---&gt; 58                 mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length) #mfcc - time and Coef(13 because num_mfcc=13),
     59                 mfcc = mfcc.T #[216,13]
     60                 # store only mfcc feature with expected number of vectors

TypeError: mfcc() takes 0 positional arguments but 2 positional arguments (and 1 keyword-only argument) were given
</code></pre>
<p>About the save_mfcc function:</p>
<p>Extracts MFCCs from music dataset and saves them into a json file along with genre labels.</p>
<pre><code>    :param dataset_path (str): Path to dataset
    :param json_path (str): Path to json file used to save MFCCs
    :param num_mfcc (int): Number of coefficients to extract 
    :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples
    :param hop_length (int): Sliding window for FFT. Measured in # of samples
    :param: num_segments (int): Number of segments we want to divide sample tracks into
    :return:
</code></pre>
<p>I don't understand why the problem just appeared today, and how to fix it.</p>
<p>How can I solve the error?</p>
","2023-03-18 12:46:34","4","Question"
"75774155","75168665","","<p>I ran into the same issue when following the Huggingface CLIPSeg zero-shot semantic segmentation tutorial. I was trying to provide it a single channel, numpy array of an IRB TIF image in the shape (500,500).</p>
<p>I turned the the three IRB channel into numpy arrays and stacked them with:</p>
<pre><code>irb = np.dstack((i, r, b))
</code></pre>
<p>The shape was then (500,500,3) and worked.</p>
","2023-03-18 06:15:55","1","Answer"
"75773430","","Problem With Scikit Learn One Hot and Ordinal Encoders","<p>I'm having a problem with Scikit Learn's one-hot and ordinal encoders that I hope someone can explain to me.</p>
<p>I'm following along with a <a href=""https://towardsdatascience.com/guide-to-encoding-categorical-features-using-scikit-learn-for-machine-learning-5048997a5c79"" rel=""nofollow noreferrer"">Towards Data Science article</a> that uses a <a href=""https://www.kaggle.com/datasets/spscientist/students-performance-in-exams"" rel=""nofollow noreferrer"">Kaggle data set</a> to predict student academic performance.  I'm running on a MacBook Pro M1 and  Python 3.11 using a virtual environment.</p>
<p>The data set has four nominal independent variables <code>['gender', 'race/ethnicity', 'lunch', 'test preparation course']</code> , one ordinal independent variable <code>['parental level of education']</code>, and aspires to create a regression model that predicts the average of math, reading, and writing scores.</p>
<p>I'd like to set up an SKLearn pipeline that uses their <code>OneHotEncoder</code> and <code>OrdinalEncoder</code>.  I am not interested in using Pandas DataFrame <code>get_dummies</code>.  My goal is a pure SK Learn pipeline.</p>
<p>I tried to approach the problem in steps.  The first attempt uses the encoders without a <code>column_transformer</code>:</p>
<pre><code>ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform='pandas')
education_levels = [
    &quot;some high school&quot;,
    &quot;high school&quot;,
    &quot;some college&quot;,
    &quot;associate's degree&quot;,
    &quot;bachelor's degree&quot;,
    &quot;master's degree&quot;,
    &quot;doctorate&quot;]
oe  = OrdinalEncoder(categories=education_levels)
encoded_data = pd.DataFrame(ohe.fit_transform(df[categorical_attributes]))
df = df.join(encoded_data)
encoded_data = pd.DataFrame(ohe.fit_transform(df[ordinal_attributes]))
df = df.join(encoded_data)
</code></pre>
<p>The data frame <code>df</code> has both ordinal and categorical variables encoded perfectly.  It's ready to feed to whatever regression algorithm I want.  Note the <code>.join</code> steps that add the encoded data to the data frame.</p>
<p>The second attempt instantiates a column transformer:</p>
<pre><code>column_transformer = make_column_transformer(
    (ohe, categorical_attributes),
    (oe, ordinal_attributes))
column_transformer.fit_transform(X)
</code></pre>
<p>The data frame <code>X</code> contains only the ordinal and categorical independent variables.</p>
<p>When I run this version I get a stack trace that ends with the following error:</p>
<pre><code>ValueError: Shape mismatch: if categories is an array, it has to be of shape (n_features,).ValueError: Shape mismatch: if categories is an array, it has to be of shape (n_features,).
</code></pre>
<p>Is the error telling me that I need to turn the categories list into an array and transpose it?  Why does it work perfectly when I apply <code>.fit_transform</code> for each encoder sequentially without the pipeline?</p>
<p>The code I have appears to be what the article recommends.</p>
<p>I'm troubled by the column transformer.  If it applies <code>.fit_transform</code> for each encoder sequentially it won't be doing those intermediate <code>.join</code> steps that my first solution has.  Those are key to adding the new columns to the data frame.</p>
<p>I want to make the pipeline work.  What am I missing, and how do I fix it?</p>
<p>Edit:</p>
<p>I logged into ChatGPT and asked it for comments on my code.  Making this change got me almost there:</p>
<pre><code># Wrapping education_levels with [] did it.
oe  = OrdinalEncoder(categories=[education_levels])
</code></pre>
<p>I have just one question remaining.  The Pandas DataFrame that I get out has all the right values, but the column names are missing.  How do I add them?  Why were they not generated for me, as they were in the solution that did not use the pipeline?</p>
","2023-03-18 01:56:12","0","Question"
"75759382","","ImportError: cannot import name 'runtime' in OpenVINO","<p>I am trying to run the openvino notebook for object detection task as follows</p>
<pre><code>from openvino import runtime as ov
</code></pre>
<p>But I get the following error</p>
<pre><code>---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-5-5dff2ebd5508&gt; in &lt;module&gt;
      8 import numpy as np
      9 from IPython import display
---&gt; 10 from openvino import runtime as ov
     11 from openvino.tools.mo.front import tf as ov_tf_front
     12 

ImportError: cannot import name 'runtime'
</code></pre>
","2023-03-16 17:02:31","0","Question"
"75758616","75753825","","<p>The model you built was basically a regression model. Given that the output ranges from 1 to 5, and the loss you specified was <code>&quot;mean_squared_error&quot;</code>, the loss of 0.48 (what you mistook for accuracy -- there is no accuracy metrics currently in your model) is actually not that bad.</p>
<p>But of course a classifier model is better for the task. Here are things to do.</p>
<ol>
<li>One-hot-encode the labels. This converts a single value from 1 to 5 into an 5-size array. For example, <code>[4]</code> becomes <code>[0, 0, 0, 1, 0]</code>.</li>
</ol>
<pre><code>from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder()
y = encoder.fit_transform(y).toarray()
</code></pre>
<ol start=""2"">
<li>For the last layer, give it 5 units and use <code>&quot;softmax&quot;</code> activation.</li>
</ol>
<pre><code>model.add(Dense(5, activation=&quot;softmax&quot;))
</code></pre>
<ol start=""3"">
<li>Use correct loss and metrics. For classifier model, the loss should be <code>&quot;categorical_crossentropy&quot;</code> and metrics should be <code>&quot;accuracy&quot;</code>.</li>
</ol>
<pre><code>model.compile(optimizer=Adam(learning_rate=0.01), loss=&quot;categorical_crossentropy&quot;, metrics=&quot;accuracy&quot;)
</code></pre>
","2023-03-16 15:54:28","1","Answer"
"75757659","75753825","","<p>-New Answer-</p>
<p>Lenet is an initial Convolution neural network to create the concept of CNN. This architecture is like:</p>
<pre><code>model = models.Sequential()
model.add(layers.Conv2D(6, 5, activation='tanh', input_shape=x_train.shape[1:]))
model.add(layers.AveragePooling2D(2))
model.add(layers.Activation('sigmoid'))
model.add(layers.Conv2D(16, 5, activation='tanh'))
model.add(layers.AveragePooling2D(2))
model.add(layers.Activation('sigmoid'))
model.add(layers.Conv2D(120, 5, activation='tanh'))
model.add(layers.Flatten())
model.add(layers.Dense(84, activation='tanh'))
model.add(layers.Dense(10, activation='softmax'))
model.summary()
Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 6)         156       
_________________________________________________________________
average_pooling2d (AveragePo (None, 14, 14, 6)         0         
_________________________________________________________________
activation (Activation)      (None, 14, 14, 6)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      
_________________________________________________________________
average_pooling2d_1 (Average (None, 5, 5, 16)          0         
_________________________________________________________________
activation_1 (Activation)    (None, 5, 5, 16)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1, 1, 120)         48120     
_________________________________________________________________
flatten (Flatten)            (None, 120)               0         
_________________________________________________________________
dense (Dense)                (None, 84)                10164     
_________________________________________________________________
dense_1 (Dense)              (None, 10)                850       
=================================================================
Total params: 61,706
Trainable params: 61,706
Non-trainable params: 0
</code></pre>
<p>I referred to this <a href=""https://medium.com/analytics-vidhya/lenet-with-tensorflow-a35da0d503df"" rel=""nofollow noreferrer"">article</a> to create the summary of model.</p>
<p>So, why do we this? There is better explanation for this (refer to the below references that I mention.), so to sum it up, as input data passes the Conv2D, the layer extracts some features from the input. And these features have different characteristics each layer because the shape of an input image is decreasing. Note that each Conv2D layers have a different feature.</p>
<p><a href=""https://vinodsblog.com/2020/05/03/role-of-convolutional-layer-in-cnn/"" rel=""nofollow noreferrer"">This</a> is a good material to understand what a role of convolutional layer is. Also, <a href=""https://www.kaggle.com/code/niranjanjagannath/lenet-5-architecture-for-mnist-using-tensorflow"" rel=""nofollow noreferrer"">here</a> is a good reference to try yourself.</p>
","2023-03-16 14:29:41","0","Answer"
"75754832","75753825","","<p>As @Felix_Fourcolor mentioned in the comment, the last layer should be another one to generate an appropriate value of loss.</p>
<p>Think about it, the ReLU calculates the output of model every single layer in range (0, max). Therefore, if you do that as your last layer, the gap between the prediction and target would be so huge, which makes the trouble.</p>
<p>Therefore, you should change the activation function to another.</p>
<pre><code>#if your classification is for distinguishing binary-classes.
model.add(Dense(1, activation='sigmoid'))

#if your classification is for distinguishing multi-classes.
model.add(Dense(1, activation='softmax'))
</code></pre>
","2023-03-16 10:18:50","0","Answer"
"75753825","","I'm trying to create a ML algorithm to predict ratings for movies using the MovieLens Dataset, but the loss and accuracy always stay the same","<p>This is my code:</p>
<pre><code>import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from keras.layers import Dense
from keras.optimizers import SGD, Adam, Adagrad
import numpy as np
from sklearn.model_selection import train_test_split
from scipy import stats
from keras import regularizers
from keras.layers import Dropout

# load in the dataset
dataset = pd.read_csv(r'C:\Users\danie\Desktop\Book11.csv')

# reshaping the data
scaler = MinMaxScaler()
dataset['rating'] = scaler.fit_transform(dataset['rating'].values.reshape(-1, 1))

# remove outliers
z = np.abs(stats.zscore(dataset))
dataset = dataset[(z &lt; 3).all(axis=1)]

# initializing the X and Y variable
x = dataset.drop(columns=['rating'])
y = dataset['rating']

# initialise training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

# creating the model
model = tf.keras.models.Sequential()

# reshape input data for a conv2d layer
x_train = np.reshape(x_train.values, (x_train.shape[0], x_train.shape[1], 1, 1))
x_test = np.reshape(x_test.values, (x_test.shape[0], x_test.shape[1], 1, 1))

# create the model
model.add(tf.keras.layers.Conv2D(filters=4, kernel_size=(3, 3),
                                 input_shape=(x_train.shape[1], 1, 1), activation='relu',
                                 padding='same', strides=(1, 1),
                                 kernel_regularizer=regularizers.l2(0.001)))
model.add(tf.keras.layers.Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.05))
model.add(Dense(1, activation='relu'))


# compile the model
model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error', metrics=['mean_squared_error'])
model.fit(x_train, y_train, epochs=100)

# evaluate the model
model.evaluate(x_test, y_test)
</code></pre>
<p>There are 100k data entries in the data so I don't think the size of the dataset is the problem.</p>
<p>I've messed around with regularization, dropout, learning rate and the complexity of the model, but no matter what I do, the accuracy and loss always stay around ~0.4800 throughout each epoch of the model. How can I improve my model or make changes to make it improve accuracy and decrease loss over time?</p>
","2023-03-16 08:48:27","-1","Question"
"75750666","75746687","","<p>One way of proceeding might be the following: you can access <em>training</em> and <em>evaluation</em> losses via the <code>trainer.state.log_history</code> object after training. An example below (<em>accuracy</em> and <em>f1</em> might be ignored as they derive from the <em>specific</em> <code>compute_metrics</code> function passed as parameter to the <code>trainer</code> instance):</p>
<p><a href=""https://i.sstatic.net/SIgRB.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/SIgRB.png"" alt=""enter image description here"" /></a></p>
<p>It is a <em>list of dicts</em> which contains some logged values per logged step; among the keys of the different dictionaries you should find <code>'loss'</code> and <code>'eval_loss'</code>, whose values you might retrieve as follows (analogously for validation losses).</p>
<pre><code>train_loss = []
for elem in trainer.state.log_history:
    if 'loss' in elem.keys():
        train_loss.append(elem['loss'])
</code></pre>
<p>The <em>loss</em> is computed via the <a href=""https://github.com/huggingface/transformers/blob/2355e463955a5392c1acf1964d89747e8b146a6f/src/transformers/trainer.py#L2667"" rel=""nofollow noreferrer""><code>.compute_loss()</code></a> method of the <code>Trainer</code> class, which you might override for custom behaviour as described at <a href=""https://huggingface.co/docs/transformers/v4.27.1/en/main_classes/trainer#trainer"" rel=""nofollow noreferrer"">https://huggingface.co/docs/transformers/v4.27.1/en/main_classes/trainer#trainer</a>.</p>
","2023-03-15 22:33:38","4","Answer"
"75749441","75745710","","<p>Here is a small example that reproduces the error:</p>
<pre><code>import org.apache.log4j.{Level, Logger}
import org.apache.spark.sql.SparkSession
import org.apache.spark.mllib.clustering.KMeans
import org.apache.spark.mllib.linalg.Vectors

object example {

  def main(args: Array[String]): Unit = {

    val data = List(Vectors.dense(Array(-1.2067543462416856,1.3095550194913217)),
      Vectors.dense(Array(0.07214871343256794,1.2317180069067792)),
      Vectors.dense(Array(1.2382694463625876,1.498952083293292)),
      Vectors.dense(Array(1.4227882484992194,1.1326606729937694)),
      Vectors.dense(Array(0.028564865614650627,1.1697757168356784)),
      Vectors.dense(Array(1.3008028016732505,1.3992632244080325)),
      Vectors.dense(Array(-0.4515288119480808,-0.44940482288858774)),
      Vectors.dense(Array(1.3912470190900275,-1.2895692645735999)),
      Vectors.dense(Array(-0.5498887597576244,-0.4937628444210279)),
      Vectors.dense(Array(0.03640545102051686,-1.3540754314126295)),
      Vectors.dense(Array(-1.2520223542111055,1.2709646562853476)))

    Logger.getLogger(&quot;org&quot;).setLevel(Level.OFF)

    val SS = SparkSession
      .builder()
      .appName(&quot;example&quot;)
      .config(&quot;spark.master&quot;, &quot;local[*]&quot;).getOrCreate()
    val sc = SS.sparkContext

    val rdd = sc.parallelize(data)
    val kmeans = KMeans.train(rdd,10,100)
  }
}
</code></pre>
","2023-03-15 19:50:48","1","Answer"
"75747540","75745710","","<p>Looks like an issue with dependencies.</p>
<p>In Breeze 1.3- <code>breeze.storage.Zero.DoubleZero</code> was defined as</p>
<pre><code>@SerialVersionUID(1L)
implicit object DoubleZero extends Zero[Double] {
  override def zero = 0.0
}
</code></pre>
<p><a href=""https://github.com/scalanlp/breeze/blob/releases/v1.3/math/src/main/scala/breeze/storage/Zero.scala#L77"" rel=""nofollow noreferrer"">https://github.com/scalanlp/breeze/blob/releases/v1.3/math/src/main/scala/breeze/storage/Zero.scala#L77</a></p>
<p>and <code>breeze.storage.Zero.DoubleZero.getClass</code> produced <code>breeze.storage.Zero$DoubleZero$</code>.</p>
<p>But in Breeze 2.0+ <code>DoubleZero</code> is defined as</p>
<pre><code>implicit val DoubleZero: Zero[Double] = Zero(0.0)
</code></pre>
<p><a href=""https://github.com/scalanlp/breeze/blob/releases/v2.0/math/src/main/scala/breeze/storage/Zero.scala#L46"" rel=""nofollow noreferrer"">https://github.com/scalanlp/breeze/blob/releases/v2.0/math/src/main/scala/breeze/storage/Zero.scala#L46</a></p>
<pre><code>@SerialVersionUID(1L)
case class Zero[@specialized T](zero: T) extends Serializable
</code></pre>
<p>and <code>breeze.storage.Zero.DoubleZero.getClass</code> produces <code>breeze.storage.Zero$mcD$sp</code> (because of <code>@specialized</code>) while <code>Class.forName(&quot;breeze.storage.Zero$DoubleZero$&quot;)</code> throws <code>ClassNotFoundException</code>.</p>
<p>You should look what dependency still uses Breeze 1.3-</p>
<hr />
<p><strong>Update.</strong> Thanks for MCVE.</p>
<p>Debugging shows that <code>NoClassDefFoundError</code>/<code>ClassNotFoundException</code> is thrown here</p>
<pre><code>  private lazy val loadableSparkClasses: Seq[Class[_]] = {
    Seq(
      // ...
      &quot;org.apache.spark.ml.linalg.SparseMatrix&quot;,   // &lt;---
      // ...
    ).flatMap { name =&gt;
      try {
        Some[Class[_]](Utils.classForName(name))   // &lt;---
      } catch {
        case NonFatal(_) =&gt; None // do nothing
        case _: NoClassDefFoundError if Utils.isTesting =&gt; None // See SPARK-23422.
      }
    }
  }
</code></pre>
<p><a href=""https://github.com/apache/spark/blob/v3.3.0/core/src/main/scala/org/apache/spark/serializer/KryoSerializer.scala#L521"" rel=""nofollow noreferrer"">https://github.com/apache/spark/blob/v3.3.0/core/src/main/scala/org/apache/spark/serializer/KryoSerializer.scala#L521</a></p>
<p>Simpler reproduction is</p>
<pre><code>Class.forName(&quot;org.apache.spark.ml.linalg.SparseMatrix&quot;)
// java.lang.NoClassDefFoundError: breeze/storage/Zero$DoubleZero$ ...
// Caused by: java.lang.ClassNotFoundException: breeze.storage.Zero$DoubleZero$ ...
</code></pre>
<p>As I said, one of dependencies uses Breeze 1.3- although you're thinking that you're using Breeze 2.1.0. Namely, <code>org.apache.spark.ml.linalg.SparseMatrix</code> is from <code>spark-mllib-local</code> and <code>spark-mllib-local</code> 3.3.0 uses Breeze 1.2</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.scalanlp&lt;/groupId&gt;
    &lt;artifactId&gt;breeze_2.13&lt;/artifactId&gt;
    &lt;version&gt;1.2&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
    &lt;exclusions&gt;
        &lt;exclusion&gt;
            &lt;artifactId&gt;commons-math3&lt;/artifactId&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
        &lt;/exclusion&gt;
    &lt;/exclusions&gt;
&lt;/dependency&gt;
</code></pre>
<p><a href=""https://repo1.maven.org/maven2/org/apache/spark/spark-mllib-local_2.13/3.3.0/spark-mllib-local_2.13-3.3.0.pom"" rel=""nofollow noreferrer"">https://repo1.maven.org/maven2/org/apache/spark/spark-mllib-local_2.13/3.3.0/spark-mllib-local_2.13-3.3.0.pom</a></p>
<p>So Spark 3.3.0 (and 3.3.2) is incompatible with Breeze 2.0+. Use Breeze 1.3-</p>
<pre><code>scalaVersion := &quot;2.13.0&quot;

libraryDependencies ++= Seq(
  &quot;org.apache.spark&quot; %% &quot;spark-sql&quot;   % &quot;3.3.0&quot;,
  &quot;org.apache.spark&quot; %% &quot;spark-mllib&quot; % &quot;3.3.0&quot;,
  &quot;org.scalanlp&quot;     %% &quot;breeze&quot;      % &quot;1.3&quot;
)
</code></pre>
<p>Then your code runs successfully.</p>
<p>Compatibility issues between different versions of Spark and Breeze are not rare:</p>
<p><a href=""https://github.com/scalanlp/breeze/issues/710"" rel=""nofollow noreferrer"">https://github.com/scalanlp/breeze/issues/710</a></p>
<p><a href=""https://stackoverflow.com/questions/43169853/apache-spark-java-lang-nosuchmethoderror-breeze-linalg-vector-scalaroflbre"">Apache Spark - java.lang.NoSuchMethodError: breeze.linalg.Vector$.scalarOf()Lbreeze/linalg/support/ScalarOf</a></p>
<p><a href=""https://github.com/scalanlp/breeze/issues/690"" rel=""nofollow noreferrer"">https://github.com/scalanlp/breeze/issues/690</a></p>
<p>Breeze should be upgraded to 2.0 in Spark 3.4.0</p>
<p><a href=""https://issues.apache.org/jira/browse/SPARK-39616"" rel=""nofollow noreferrer"">https://issues.apache.org/jira/browse/SPARK-39616</a></p>
<p>Meanwhile you can try it with the following <code>build.sbt</code></p>
<pre><code>scalaVersion := &quot;2.13.0&quot;

resolvers += &quot;apache-repo&quot; at &quot;https://repository.apache.org/content/groups/snapshots&quot;

libraryDependencies ++= Seq(
  &quot;org.apache.spark&quot; %% &quot;spark-sql&quot;   % &quot;3.4.0-SNAPSHOT&quot;,
  &quot;org.apache.spark&quot; %% &quot;spark-mllib&quot; % &quot;3.4.0-SNAPSHOT&quot;,
  &quot;org.scalanlp&quot;     %% &quot;breeze&quot;      % &quot;2.1.0&quot;
)
</code></pre>
<p>Then your code runs successfully too.</p>
","2023-03-15 16:31:45","1","Answer"
"75746687","","Is it possible to save the training/validation loss in a list during training in HuggingFace?","<p>I'm currently training my model using the HuggingFace <code>Trainer</code> class:</p>
<pre><code>from transformers import Trainer, TrainingArguments

args = TrainingArguments(
    output_dir=&quot;codeparrot-ds&quot;,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    evaluation_strategy=&quot;steps&quot;,
    eval_steps=5_000,
    logging_steps=5_000,
    gradient_accumulation_steps=8,
    num_train_epochs=1,
    weight_decay=0.1,
    warmup_steps=1_000,
    lr_scheduler_type=&quot;cosine&quot;,
    learning_rate=5e-4,
    save_steps=5_000,
    fp16=True,
    push_to_hub=True,
)

trainer = Trainer(
    model=model,
    tokenizer=tokenizer,
    args=args,
    data_collator=data_collator,
    train_dataset=tokenized_datasets[&quot;train&quot;],
    eval_dataset=tokenized_datasets[&quot;valid&quot;],
)
</code></pre>
<p>This prints the loss during training, but I can't figure out how to save it so that I can plot it later. Note that I need both the training and validation losses during training.</p>
","2023-03-15 15:16:07","5","Question"
"75745710","","ClassNotFoundException: breeze.storage.Zero$DoubleZero$","<p>I'm trying to run a distributed Kmeans using a distributed Kmeans of Spark MLLIB and I'm getting the following error:</p>
<pre><code>Caused by: java.lang.ClassNotFoundException: breeze.storage.Zero$DoubleZero$
    at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
</code></pre>
<p>I'm using scala 2.13.0 and spark 3.3.0. and breeze 2.1.0 Does anyone know how to solve it?</p>
","2023-03-15 13:56:26","1","Question"
"75741001","75740699","","<p>using <code>activation='relu'</code> is a shorthand for <code>activation=tf.keras.activations.relu</code>. so one is from the TF's library and the other from Keras. So which one you should use depends on whether you would use TF to create a NN or use keras to make a sequential model. For more detail you can see <a href=""https://stackoverflow.com/a/54761708/"">this post</a>.</p>
","2023-03-15 05:56:53","0","Answer"
"75740913","75740699","","<p>They are the same. Keras did this to give a clearer UX for users if they don't want to customize the inner workings if a function.</p>
<p><a href=""https://github.com/keras-team/keras/blob/e6784e4302c7b8cd116b74a784f4b78d60e83c26/keras/layers/core/dense.py#L125"" rel=""nofollow noreferrer"">This line of code</a> from the Dense layer gets the activation function from the <code>activations</code> file. In the <code>activations</code> file, you can see that this <a href=""https://github.com/keras-team/keras/blob/e6784e4302c7b8cd116b74a784f4b78d60e83c26/keras/activations.py#L281"" rel=""nofollow noreferrer""><code>relu</code></a> function is wrapped with <code>@keras_export</code>, which means &quot;you can specify it as a string&quot;.</p>
<p>Some users might want to specify additional params like <code>tf.keras.activations.relu(x, alpha=0.5)</code>, that's why both ways exist, and you can use either way.</p>
","2023-03-15 05:41:32","0","Answer"
"75740699","","difference calling activation function","<p>While I'm study tensorflow, I got a question.</p>
<p>There are two way to define activation function.</p>
<p>activation = 'relu' and activation = tf.nn.relu</p>
<p>I want to know difference between of them.</p>
<p>(Actually, I think other activation functions are include in this case.)</p>
<p>I tried two way.</p>
<p>First one is</p>
<pre><code>model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape = (28, 28)),
    tf.keras.layers.Dense(128, activation = 'relu'),
    tf.keras.layers.Dense(10, activation = tf.nn.softmax)
])
</code></pre>
<p>Second one is</p>
<pre><code>model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape = (28, 28)),
    tf.keras.layers.Dense(128, activation = tf.nn.relu),
    tf.keras.layers.Dense(10, activation = tf.nn.softmax)
])
</code></pre>
<p>I think they gave me same result.</p>
<p>What is the difference of them?</p>
","2023-03-15 04:56:42","0","Question"
"75737232","","Loss is Nan for SegFormer vision transformer trained on BDD10k","<p>I'm trying to implement a <a href=""https://huggingface.co/docs/transformers/model_doc/segformer"" rel=""nofollow noreferrer"">SegFormer</a> pretrained with a <a href=""https://huggingface.co/nvidia/mit-b0"" rel=""nofollow noreferrer"">mit-b0</a> model to perform semantic segmentation on images obtained from the <a href=""https://doc.bdd100k.com/download.html"" rel=""nofollow noreferrer"">bdd100k</a> dataset. Specifically, semantic segmentation has masks for only a subset of the 100k images, being 10k with appropriate masks for segmentation where the <a href=""https://doc.bdd100k.com/format.html#semantic-segmentation"" rel=""nofollow noreferrer"">pixel value</a> of the mask is the label between 0 - 18, or 255 for unknown labels. I'm also following this example from <a href=""https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/segformer.ipynb"" rel=""nofollow noreferrer"">collab</a> on a simple segmentation of three labels.</p>
<p>The problem I have is that any further training I do on the training data ends up with nan as a loss. Inspecting any predicted masks ends up with values of Nan which is not right. I've tried to ensure that the input images for training are normalized, reduced the learning rate, increased the epochs for learning, changed the pretrained model, but still end up with nan as a loss right away.</p>
<p>I have my datasets as:</p>
<pre><code>dataset = tf.data.Dataset.from_tensor_slices((image_train_paths, mask_train_paths))
val_dataset = tf.data.Dataset.from_tensor_slices((image_val_paths, mask_val_paths))
</code></pre>
<p>with this method to preprocess and normalize the data</p>
<pre><code>height = 512
width = 512
mean = tf.constant([0.485, 0.456, 0.406])
std = tf.constant([0.229, 0.224, 0.225])

def normalize(input_image):
    input_image = tf.image.convert_image_dtype(input_image, tf.float32)
    input_image = (input_image - mean) / tf.maximum(std, backend.epsilon())
    return input_image

# Define a function to load and preprocess each example
def load_and_preprocess(image_path, mask_path):
    # Load the image and mask
    image = tf.image.decode_jpeg(tf.io.read_file(image_path), channels=3)
    mask = tf.image.decode_jpeg(tf.io.read_file(mask_path), channels=1)

    # Preprocess the image and mask
    image = tf.image.resize(image, (height, width))
    mask = tf.image.resize(mask, (height, width), method='nearest')
    image = normalize(image)
    mask = tf.squeeze(mask, axis=-1)
    image = tf.transpose(image, perm=(2, 0, 1))
    return {'pixel_values': image, 'labels': mask}
</code></pre>
<p>Actually created the datasets:</p>
<pre><code>batch_size = 4
train_dataset = (
    dataset
    .cache()
    .shuffle(batch_size * 10)
    .map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(batch_size)
    .prefetch(tf.data.AUTOTUNE)
)

validation_dataset = (
    val_dataset
    .map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(batch_size)
    .prefetch(tf.data.AUTOTUNE)
)
</code></pre>
<p>Setting up the labels and pre-trained model:</p>
<pre><code>id2label = {
    0:  'road',
    1:  'sidewalk',
    2:  'building',
    3:  'wall',
    4:  'fence',
    5:  'pole',
    6:  'traffic light',
    7:  'traffic sign',
    8:  'vegetation',
    9:  'terrain',
    10: 'sky',
    11: 'person',
    12: 'rider',
    13: 'car',
    14: 'truck',
    15: 'bus',
    16: 'train',
    17: 'motorcycle',
    18: 'bicycle',
}
label2id = { label: id for id, label in id2label.items() }
num_labels = len(id2label)

model = TFSegformerForSemanticSegmentation.from_pretrained('nvidia/mit-b0', num_labels=num_labels, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001))
</code></pre>
<p>Finally fitting the data to the model, using only 1 epoch just to see if I can figure out why the loss in nan:</p>
<pre><code>epochs = 1

history = model.fit(train_dataset, validation_data=validation_dataset, epochs=epochs)
</code></pre>
<p>Segformer implements it's own loss function, so I don't need to supply one. I see the collab example I was following has some sort of loss, but I can't figure out why mine is nan.</p>
<p>Did I approach this correctly, or am I missing something along the way? What else can I try to figure out on why the loss is nan?  I did also make sure my labels used match between validation and training data sets. The pixel values ranged from 0 - 18 with 255 as unknown as supplied by the docs.</p>
<p><strong>Edit: 3/16</strong></p>
<p>I did find <a href=""https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb"" rel=""nofollow noreferrer"">this example</a> which pointed out some flaws I had in my approach, but even after following this example with everything besides how the dataset is gathered, I was still unable to produce any loss other than nan.</p>
<p>My new code is mostly the same, other then how I am pre-processing the data with numpy before converting them to tensors.</p>
<p>Dataset dict definition for training and validation data:</p>
<pre><code>dataset = DatasetDict({
    'train': Dataset.from_dict({'pixel_values': image_train_paths, 'label': mask_train_paths}).cast_column('pixel_values', Image()).cast_column('label', Image()),
    'val': Dataset.from_dict({'pixel_values': image_val_paths, 'label': mask_val_paths}).cast_column('pixel_values', Image()).cast_column('label', Image())
})

train_dataset = dataset['train']
val_dataset = dataset['val']

train_dataset.set_transform(preprocess)
val_dataset.set_transform(preprocess)
</code></pre>
<p>where preprocess is where I am processing the images using the <a href=""https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoImageProcessor"" rel=""nofollow noreferrer"">AutoImageProcessor</a> to get the inputs.</p>
<pre><code>image_processor  = AutoImageProcessor.from_pretrained('nvidia/mit-b0', semantic_loss_ignore_index=255) # This is a SegformerImageProcessor 

def transforms(image):
    image = tf.keras.utils.img_to_array(image)
    image = image.transpose((2, 0, 1))  # Since vision models in transformers are channels-first layout
    return image


def preprocess(example_batch):
    images = [transforms(x.convert('RGB')) for x in example_batch['pixel_values']]
    labels = [x for x in example_batch['label']]
    inputs = image_processor(images, labels)
    # print(type(inputs))
    return inputs
</code></pre>
<p>transforming the sets to a tensorflow dataset:</p>
<pre><code>batch_size = 4

data_collator = DefaultDataCollator(return_tensors=&quot;tf&quot;)

train_set = dataset['train'].to_tf_dataset(
    columns=['pixel_values', 'label'],
    shuffle=True,
    batch_size=batch_size,
    collate_fn=data_collator,
)
val_set = dataset['val'].to_tf_dataset(
    columns=['pixel_values', 'label'],
    shuffle=False,
    batch_size=batch_size,
    collate_fn=data_collator,
)
</code></pre>
<p>fitting the model</p>
<pre><code>history = model.fit(
    train_set,
    validation_data=val_set,
    epochs=10,
)
</code></pre>
<p><code>1750/1750 [==============================] - ETA: 0s - loss: nan</code></p>
","2023-03-14 18:48:22","1","Question"
"75730103","","How to continue to further train a pre-trained YOLOv8 model","<p>I've trained a YOLOv8 model for object detection with 4 classes on a custom dataset.</p>
<p>Now I want to train it to detect more classes by increasing my dataset.</p>
<p>Instead of training the model from the start can I further train it specifically on the new dataset?</p>
","2023-03-14 07:23:23","0","Question"
"75722122","75640068","","<p>I had a similar problem when using colour-science. Apparently, matplotlib 3.7.x does not have the lines.pop(0) function implemented. For me, it worked when downgrading back to matplotlib 3.6.3. I hope that works for you too.</p>
","2023-03-13 12:53:44","5","Answer"
"75715492","75648179","","<p>for D2GO just comment out the error line</p>
<pre><code>#16 from torch.ao.pruning import fqn_to_module
</code></pre>
<p>it will work!</p>
","2023-03-12 18:35:48","1","Answer"
"75703435","75676943","","<p>Your model is basically predicting the previous day's price. Whether or not it has overfit isn't really the right question, as it's basically stuck making a very naive prediction.</p>
<p>You should focus on how to reformulate the problem, such as maybe prediction the price difference for the next day, and plot that out.</p>
","2023-03-11 07:26:54","0","Answer"
"75689252","75684685","","<p>As Scka said, the problem occurred due to the update of Python by colab.</p>
<p>Python 3.7 can be installed every time on the notebook: with the following commands:</p>
<p>!sudo apt-get install python3.7</p>
<p>!sudo update-alternatives --install /usr/bin/python3 python3
/usr/bin/python3.7 1</p>
<p>!sudo update-alternatives --config python3</p>
<p>!sudo apt install python3-pip</p>
<p>after it</p>
<p>!python --version</p>
<p>then</p>
<p>!sudo apt-get install python3.7-distutils</p>
","2023-03-09 19:34:49","1","Answer"
"75688040","75684685","","<p>Colab has recently upgraded to Python 3.9. There is a temporary mechanism for users to run Python 3.8 runtime (Linux-5.10.147+-x86_64-with-glibc2.29 platform). This is available from the Command Palette via the &quot;Use fallback runtime version&quot; command when connected to a runtime. The issue can be tracked <a href=""https://github.com/googlecolab/colabtools/issues/3450"" rel=""nofollow noreferrer"">here</a>.</p>
","2023-03-09 17:25:17","3","Answer"
"75684685","","Failure to install old versions of transformers in colab","<p>I recently had a problem installing Transformer version 2.9.0 in colab.</p>
<p><a href=""https://i.sstatic.net/l1bHf.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/l1bHf.png"" alt=""Its image"" /></a></p>
<p><a href=""https://i.sstatic.net/Q0mfj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Q0mfj.png"" alt=""enter image description here"" /></a></p>
","2023-03-09 12:34:01","0","Question"
"75677016","75676943","","<p>Your model doesn't seem neither to overfit nor to underfit. For both plots, training loss was quite similar to validation loss, and predicted price was similar to the actual price. From your plots, it seems that the 30 timesteps model fits better than the first one.</p>
<p>You could try to use other hyperparameters, for example 40 timesteps,  and see if model fits even well.</p>
","2023-03-08 18:43:49","1","Answer"
"75676983","75665576","","<p>Here are my 2 cents:</p>
<p>Create a dataframe, extract all the distinct values/create a list of distinct values. Iterate over those values and extract the values based on the column values</p>
<pre><code>data = [
    [1,'A','C'],
    [2,'B','A']
]

df = spark.createDataFrame(data,['ID','cat_col1','cat_col2'])

df.show()

import pyspark.sql.functions as F

# If you want to create columns which are only present in the cat_col1 &amp; cat_col2
# distinct_col1_values = df.select('cat_col1').distinct().rdd.map(lambda x:x[0]).collect()
# distinct_col2_values = df.select('cat_col2').distinct().rdd.map(lambda x:x[0]).collect()

distinct_col1_values=distinct_col2_values=['A','B','C']

# You can club the 2 withColumn statements in a single one, if required.
for value1 in distinct_col1_values:
    df = df.withColumn(f&quot;cat_col1_{value1}&quot;,F.expr(f&quot;&quot;&quot;CASE WHEN cat_col1 ='{value1}' THEN '1' ELSE '0' END&quot;&quot;&quot;))

for value1 in distinct_col2_values:
    df = df.withColumn(f&quot;cat_col2_{value1}&quot;,F.expr(f&quot;&quot;&quot;CASE WHEN cat_col2 ='{value1}' THEN '1' ELSE '0' END&quot;&quot;&quot;))
            
df = df.drop(*['cat_col1','cat_col2'])  

df.show()
</code></pre>
<p>Check the below image for input and output:
<a href=""https://i.sstatic.net/Vni7k.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Vni7k.png"" alt=""enter image description here"" /></a></p>
","2023-03-08 18:40:34","0","Answer"
"75676943","","LSTM Model overfitting or under-fitting?","<p>I am working on an LSTM model that predicts Bitcoin price.
Using: time_steps = 20, epochs = 100, batch_size = 256.</p>
<p>I get the attached Model Loss Plot.<a href=""https://i.sstatic.net/g9LpY.jpg"" rel=""nofollow noreferrer"">MODEL LOSS PLOT</a></p>
<p>And I also attached the actual vs predicted BTC prices.
<a href=""https://i.sstatic.net/cMz9r.jpg"" rel=""nofollow noreferrer"">Actual VS Predict PLOT</a></p>
<p>Is this model overfitting or under-fitting...?
THANKS!</p>
<pre><code>import numpy as np
import pandas as pd
import tensorflow as tf
import plotly.graph_objects as go
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Ensure the same results are produced each time
np.random.seed(42)
tf.random.set_seed(42)

# Load the normalized data from a CSV file
df = pd.read_csv('normalized_dataBTC.csv',parse_dates=['Date'], index_col='Date')

# Split the data into training and testing sets
train_size = int(len(df) * 0.8)  # 80% of data for training
train_data = df.iloc[:train_size].values
test_data = df.iloc[train_size:].values

# Define the number of time steps and features for the LSTM model
time_steps = 20  # number of time steps to use for each input sequence
num_features = 6  # number of features in the input data

# Create training sequences for the LSTM model
X_train = []
y_train = []
for i in range(time_steps, train_size):
    X_train.append(train_data[i-time_steps:i, :])
    y_train.append(train_data[i, 4])  # use the &quot;Close&quot; price as the target

# Convert the training data to numpy arrays
X_train = np.array(X_train)
y_train = np.array(y_train)

# Reshape the training data to fit the LSTM model input shape
X_train = np.reshape(X_train, (X_train.shape[0], time_steps, num_features))

# Create testing sequences for the LSTM model
X_test = []
y_test = []
for i in range(time_steps, len(test_data)):
    X_test.append(test_data[i-time_steps:i, :])
    y_test.append(test_data[i, 4])  # use the &quot;Close&quot; price as the target

# Convert the testing data to numpy arrays
X_test = np.array(X_test)
y_test = np.array(y_test)

# Reshape the testing data to fit the LSTM model input shape
X_test = np.reshape(X_test, (X_test.shape[0], time_steps, num_features))

# Create the LSTM model
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.LSTM(units=64, input_shape=(time_steps, num_features)))
model.add(tf.keras.layers.Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Fit the model to the training data
history = model.fit(X_train, y_train, epochs=100, batch_size=256, validation_data=(X_test, y_test))

# Make predictions
predictions = model.predict(X_test)

# Load the original data from a CSV file
df_orig = pd.read_csv('BTC-USD 2014 2023.csv',parse_dates=['Date'], index_col='Date')
# Define the scale factor for the &quot;Close&quot; price
close_scale = df_orig.iloc[train_size:, 4].values.max()
# Un-normalize the predictions
predictions_unscaled = predictions * close_scale

# Plot the actual vs predicted BTC price using Plotly
fig = go.Figure()
fig.add_trace(go.Scatter(x=df_orig.index[train_size+time_steps:], y=y_test*close_scale, name='Actual'))
fig.add_trace(go.Scatter(x=df_orig.index[train_size+time_steps:], y=predictions_unscaled[:,0], name='Predicted'))
fig.update_layout(title='Actual vs Predicted BTC Price', xaxis_title='Date', yaxis_title='Price ($)')
fig.update_layout(title_x=0.5, title_font_size=24, xaxis_title_font_size=18, yaxis_title_font_size=18)
fig.update_xaxes(tickformat='%d/%m/%Y') #Format x-axis as dates
fig.show()

# Plot the training and validation loss over the epochs
plt.plot(history.history['loss'], label='Training loss')
plt.plot(history.history['val_loss'], label='Validation loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Calculate the mean squared error
mse = mean_squared_error(y_test, predictions)
print('Mean squared error:', mse)

# Calculate the root mean squared error
rmse = np.sqrt(mse)
print('Root mean squared error:', rmse)

# Calculate the mean absolute error
mae = np.mean(np.abs(y_test - predictions))
print('Mean absolute error:', mae)

</code></pre>
<p><a href=""https://i.sstatic.net/s21Pc.jpg"" rel=""nofollow noreferrer"">PLOTS</a></p>
<p>Results when trying 30 time steps, 100 epochs, and 256 batch size.</p>
","2023-03-08 18:35:44","0","Question"
"75672026","75671807","","<p>If you are looking for the <strong>standard error</strong> (standard deviation of the error relative to 0) you can use <code>mean_squared_error</code> :</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.metrics import mean_squared_error

rmse = mean_squared_error(y_test, preds, squared=False)
31.5
</code></pre>
<p>RMSE is the Root Mean Squared Error, aka standard error.</p>
<p>Note: <code>squared=False</code> in <code>mean_squared_error</code> returns the RMSE instead of MSE (MSE=RMSE**2).</p>
","2023-03-08 10:46:47","-1","Answer"
"75672019","75671807","","<p>As far I know you can't compute the standard deviation (STD) from a Mean Absolute Error (MAE) but you can compute STD from the Absolute Error (AE):</p>
<pre><code>&gt;&gt;&gt; y_test.sub(preds).abs().std()
22.231790301278032

&gt;&gt;&gt; y_test.sub(preds).abs().mean()  # same as mean_absolute_error(y_test, preds)
25.75
</code></pre>
","2023-03-08 10:46:08","0","Answer"
"75671807","","Is there a function to automatically calculate standard deviation from mean absolute error in python?","<p>I was wondering if there is some function to automatically calculate standard deviation from mean absolute error derived from sklearn.</p>
<p>here is an example dataset</p>
<pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression

df = {
&quot;a&quot;: [0.06 , 0.07, 0.45, 0.98, 0.97 ],
&quot;b&quot;: [12,45,65, 56, 34],
&quot;c&quot;: [2,5,5, 5, 3],
&quot;d&quot;: [23,55,25, 15, 34],
&quot;e&quot;: [0.0005,0.55555,0.383825, 0.4747477415, 0.348344334],
&quot;f&quot;: [0.0236 , 0.3407, 0.4545, 0.9658, 0.4597 ],
&quot;g&quot;: [70 , 90, 123, 154, 99 ],    
}

#load into df:
df = pd.DataFrame(df)

print(df) 
</code></pre>
<p>and ml model</p>
<pre><code>X = df.iloc[:, 0:6]
y = df.iloc[:, 6]
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5,random_state = 0)
model = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)
</code></pre>
<p>then I use this all the way to calculate mean absolute error</p>
<pre><code>from sklearn.metrics import mean_absolute_error
model.fit(X_train, y_train)

# Preprocessing of validation data, get predictions
preds = model.predict(X_test)

# Evaluate the model
score = mean_absolute_error(y_test, preds)
print('The mean absolute error is:', score) 

# Preprocessing of test data, fit model
preds_val =model.predict(X_test) 
</code></pre>
<p>As a result, score is helping me to get MAE. I tried to apply python function from statistics package to calculate the std and it does not worked. Could anyone suggest something from sklearn that can help to get the standard deviation of MAE?</p>
<p>Thanks in advance!</p>
","2023-03-08 10:22:39","0","Question"
"75671497","75665576","","<p>i could think of a couple of ways, and both of them require unpivoting the data.</p>
<ul>
<li>create distinct column names within the dataframe</li>
<li>create column names using distinct values from all categories (requires a <code>collect</code>)</li>
</ul>
<p>within dataframe</p>
<pre class=""lang-py prettyprint-override""><code>data_sdf. \
    withColumn('attr', 
               func.array(*[func.struct(func.lit(c).alias('c_name'), 
                                        func.col(c).alias('c_val')
                                        ) for c in data_sdf.drop('id').columns]
                          )
               ). \
    selectExpr('id', 'inline(attr)'). \
    withColumn('all_val', func.collect_set('c_val').over(wd.partitionBy(func.lit(1)))). \
    select('*', func.explode('all_val').alias('all_val_exp')). \
    withColumn('pivot_col', func.concat_ws('_', 'c_name', 'all_val_exp')). \
    groupBy('id'). \
    pivot('pivot_col'). \
    agg(func.max(func.col('c_val') == func.col('all_val_exp')).cast('int')). \
    show()

# +---+----------+----------+----------+----------+----------+----------+
# | id|cat_col1_A|cat_col1_B|cat_col1_C|cat_col2_A|cat_col2_B|cat_col2_C|
# +---+----------+----------+----------+----------+----------+----------+
# |  1|         1|         0|         0|         0|         0|         1|
# |  2|         0|         1|         0|         1|         0|         0|
# +---+----------+----------+----------+----------+----------+----------+
</code></pre>
<p>using list to create required column names</p>
<pre class=""lang-py prettyprint-override""><code>cats = data_sdf.select(func.array_distinct(func.flatten(func.collect_list(func.array('cat_col1', 'cat_col2'))))).collect()[0][0]

fnl_cat_cols = sorted([x+'_'+y for x in data_sdf.drop('id').columns for y in cats])

# ['cat_col1_A',
#  'cat_col1_B',
#  'cat_col1_C',
#  'cat_col2_A',
#  'cat_col2_B',
#  'cat_col2_C']

data_sdf. \
    withColumn('attr', 
               func.array(*[func.struct(func.lit(c).alias('c_name'), 
                                        func.col(c).alias('c_val')
                                        ) for c in data_sdf.drop('id').columns]
                          )
               ). \
    selectExpr('id', 'inline(attr)'). \
    withColumn('pivot_col', func.concat_ws('_', 'c_name', 'c_val')). \
    groupBy('id'). \
    pivot('pivot_col', values=fnl_cat_cols). \
    agg(func.lit(1)). \
    fillna(0, subset=fnl_cat_cols). \
    show()

# +---+----------+----------+----------+----------+----------+----------+
# | id|cat_col1_A|cat_col1_B|cat_col1_C|cat_col2_A|cat_col2_B|cat_col2_C|
# +---+----------+----------+----------+----------+----------+----------+
# |  1|         1|         0|         0|         0|         0|         1|
# |  2|         0|         1|         0|         1|         0|         0|
# +---+----------+----------+----------+----------+----------+----------+
</code></pre>
<hr />
<p>the first approach seems memory intensive given the 2 explodes. so, you can try the second approach which seems lighter of the two.</p>
","2023-03-08 09:49:07","0","Answer"
"75665576","","One hot encoder Pyspark for multiple columns with each columns having different number of categorical labels","<p>I'm new to pyspark and I need to display all unique labels that are present in different categorical columns</p>
<p>I have a pyspark dataframe with the following columns</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>ID</th>
<th>cat_col1</th>
<th>cat_col2</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>A</td>
<td>C</td>
</tr>
<tr>
<td>2</td>
<td>B</td>
<td>A</td>
</tr>
</tbody>
</table>
</div>
<p>I want the final output to look like</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>ID</th>
<th>cat_col1_A</th>
<th>cat_col1_B</th>
<th>cat_col1_C</th>
<th>cat_col2_A</th>
<th>cat_col2_B</th>
<th>cat_col2_C</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<pre><code>categorical_columns = ['cat_col1 ','cat_col2']
# The index of string values multiple columns
indexers = [
    StringIndexer(inputCol=c, outputCol=&quot;{0}_indexed&quot;.format(c)).setHandleInvalid(&quot;keep&quot;)
    for c in categorical_columns
]

# The encode of indexed values multiple columns
encoders = [OneHotEncoder(dropLast=False,inputCol=indexer.getOutputCol(), outputCol=&quot;{0}_encoded&quot;.format(indexer.getOutputCol())) for indexer in indexers]


pipeline = Pipeline(stages=indexers + encoders) #+[assembler])
model=pipeline.fit(temp_df).transform(temp_df)
model.display()
</code></pre>
<p>The OP is something like this</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>ID</th>
<th>Cat_col_1_A_indexed</th>
<th>Cat_col_1_B_indexed</th>
<th>Cat_col_1_unknown_indexed</th>
<th>Cat_col_2_A_indexed</th>
<th>Cat_col_2_C_indexed</th>
<th>Cat_col_2_unknown_indexed</th>
</tr>
</thead>
</table>
</div>
<p>Only the unique labels in each column are displayed. I want to display the unique labels present in all categorical columns</p>
","2023-03-07 17:52:47","1","Question"
"75665005","75649038","","<p>I used train_test_split and lasso to find the significant features for prediction a thyroid class using softmax and multi-class. I achieved 96 percent accuracy.</p>
<pre><code>import pandas as pd
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score

df=pd.read_csv(&quot;thyroid.csv&quot;)


le=LabelEncoder()
df[&quot;Classes&quot;]=le.fit_transform(df[&quot;Classes&quot;])
df[&quot;Sex&quot;]=le.fit_transform(df[&quot;Sex&quot;])
for col in df.columns:
        if df[col].dtype == 'object':
            #print(col)
            df[col] = df[col].map({'f': 0, 't': 1})
            
df[&quot;TSH&quot;]=df[&quot;TSH&quot;].astype(float)   
df[&quot;T3&quot;]=df[&quot;T3&quot;].astype(float)
df[&quot;TT4&quot;]=df[&quot;TT4&quot;].astype(float)   
df[&quot;T4U&quot;]=df[&quot;T4U&quot;].astype(float)    
df[&quot;FTI&quot;]=df[&quot;FTI&quot;].astype(float)

sns.scatterplot(x='TSH',y='T3',hue='Classes', data=df)
plt.title(&quot;TSH and T3&quot;)
plt.show()

sns.scatterplot(x='TSH',y='TT4',hue='Classes', data=df)
plt.title(&quot;TSH and TT4&quot;)
plt.show()

sns.scatterplot(x='TSH',y='T4U',hue='Classes', data=df)
plt.title(&quot;TSH and T4U&quot;)
plt.show()

sns.scatterplot(x='TSH',y='FTI',hue='Classes', data=df)
plt.title(&quot;TSH and FTI&quot;)
plt.show()

x_columns=[&quot;TSH&quot;,&quot;T3&quot;,&quot;T4U&quot;,&quot;FTI&quot;]
target=&quot;Classes&quot;
X=df[x_columns]
y=df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

lgb_clf.fit(X_train, y_train)
y_pred = lgb_clf.predict(X_test)

print(accuracy_score(y_pred, y_test))
cm=confusion_matrix(y_pred, y_test)
sns.heatmap(cm,annot=True,cmap=plt.cm.Blues)
plt.show()

lgb_clf = LGBMClassifier(objective='multiclass',
    boosting_type='gbdt',
    max_depth=10,
    num_leaves=500,
    learning_rate=0.3,
    eval_metric=['accuracy','softmax'],
    num_class=3,
    n_jobs=1,
    #early_stopping_rounds=100,
    num_iterations=500)


lgb_clf.fit(X_train, y_train)
y_pred = lgb_clf.predict(X_test)

print(accuracy_score(y_pred, y_test))
cm=confusion_matrix(y_pred, y_test)
sns.heatmap(cm,annot=True,cmap=plt.cm.Blues)
plt.show()
</code></pre>
","2023-03-07 16:57:42","0","Answer"
"75664004","","Install pgvector extension on mac","<p>I'm trying to install postgres vector extension on my mac but am getting</p>
<pre><code>ERROR:  extension &quot;vector&quot; has no installation script nor update path for version &quot;0.4.0&quot;.
</code></pre>
<p>Here's what I did:</p>
<ol>
<li>Follow the installation guide as shown on <a href=""https://github.com/pgvector/pgvector"" rel=""noreferrer"">github</a>:
<a href=""https://i.sstatic.net/44h43.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/44h43.png"" alt=""enter image description here"" /></a></li>
</ol>
<p>But when I ran <code>CREATE EXTENSION vector;</code> got an error:</p>
<pre><code>ERROR:  could not open extension control file &quot;/Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/vector.control&quot;: No such file or directory
</code></pre>
<ol start=""2"">
<li><p>I copied the content of pgvector into posgresql/extension using:</p>
<p>sudo cp -r ~/Downloads/pgvector/* /Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/</p>
</li>
</ol>
<p>Tried running <code>CREATE EXTENSION vector;</code> now the error is:</p>
<pre><code>ERROR:  extension &quot;vector&quot; has no installation script nor update path for version &quot;0.4.0&quot;.
</code></pre>
<p>Anyone here seen this problem?</p>
<p>By the way am using <code>PostgreSQL 13.10</code></p>
","2023-03-07 15:32:42","10","Question"
"75657094","75639076","","<p>Here's some intuition for the theory of what AUCROC is, and why it is useful, and how you don't really need a library to this for you, and how AUCROC can be applied to a classifier that predicts a binary outcome.</p>
<p>Here's how I would calculate the AUCROC for a binary classifier.  First you make a 2 dimensional scatterplot with true positives from <code>0%-&gt;100%</code> on the vertical axis, and false negatives <code>0%-&gt;100%</code> on the horizontal axis.  You can draw a diagonal line from the lower left to upper right as a visual aid for what comes next.</p>
<p>Split your labeled training data into 10 groups with 10% of the labeled training data each.  Have your model predict the answers for each of the ten groups, compare that with the correct answers, that produces a number for a &quot;true positive percentage rate&quot; and a &quot;false negative percentage rate&quot;.  Place a dot on your scatterplot accordingly.  It should appear above the diagonal line.  Do this for all 10 labeled training set groups, you'll get 10 dots above the diagonal line.  Connect the dots with a straight line.  Calculate the distance between every point and the diagonal line.  The sum of each pillar width * height, is the &quot;The area under the curve&quot;.  Models with larger AUCROC's are better overall for every group.</p>
<p>The reason we do all this extra work rather than just simply calculating <code>(Correct Answers / Total Answers) = accuracy</code> or more correctly: <code>((True Positives / Num False Positives) + (True negatives / Num False negatives) / 2)</code> is because you want the model to perform at the stated accuracy at every named segment of the dataset, not just &quot;Has 100% accuracy for even numbered years, but only 40% accuracy for odd numbered years&quot; due to information gain your model lifts only being present on even numbered years.  The AUCROC value and the shape of the curve gives you a way to know if your model needs some specific characteristic to be the case in order to perform at the stated accuracy.</p>
<p>So every word in the Area under the curve for the receiver operating characteristic makes sense.  It tells you if there's a characteristic in the data that your model needs to get all its accuracy from, and it's just guessing on the others.  Generally, a model that performs a 90% accurately across all examples is superior to another model that performs at 100% accuracy on even numbered years, but performs at 80% accuracy on the odd numbered years, due to the model being rewarded into existence for generalizing on some characteristic that only exists in some of the training rows.  If you pull out that characteristic as a new input feature the classifier will in theory perform better.</p>
<p>Roll your own solution, convince yourself it makes sense, then you can examine the source of your <code>roc_auc()</code> which attempts to do all this and then fix their code, put in a note that their method needs more documentation and demos for correct usage.</p>
<p>How you split the data is &quot;the Characteristic&quot;.  The Receiver is the model.  Operating means the model was used.  The Area under the curve is total performance over every characteristic.</p>
<p>Suspicious bumps in the AUCROC curve mean your model is finding information gain but only if some set of characteristics are available.  This is supremely useful, because you can eliminate that named criteria from the labeled training set and force the classifier to use another source of data to isolate outcome.  Stop using zipcode to correctly predict patient outcome, because that info betrays something we're not supposed to know, and use something else.</p>
","2023-03-07 00:42:44","0","Answer"
"75657030","75639076","","<p>I think what you may be missing is that ROC AUC <em>requires</em> you have to have probabilities, not just hard class predictions. For example, let's take a look at this dataset:</p>
<pre class=""lang-r prettyprint-override""><code>library(dplyr)
#&gt; 
#&gt; Attaching package: 'dplyr'
#&gt; The following objects are masked from 'package:stats':
#&gt; 
#&gt;     filter, lag
#&gt; The following objects are masked from 'package:base':
#&gt; 
#&gt;     intersect, setdiff, setequal, union
library(yardstick)
#&gt; For binary classification, the first factor level is assumed to be the event.
#&gt; Use the argument `event_level = &quot;second&quot;` to alter this as needed.

data(two_class_example)
glimpse(two_class_example)
#&gt; Rows: 500
#&gt; Columns: 4
#&gt; $ truth     &lt;fct&gt; Class2, Class1, Class2, Class1, Class2, Class1, Class1, Clas…
#&gt; $ Class1    &lt;dbl&gt; 0.0035892426, 0.6786210540, 0.1108935221, 0.7351617031, 0.01…
#&gt; $ Class2    &lt;dbl&gt; 9.964108e-01, 3.213789e-01, 8.891065e-01, 2.648383e-01, 9.83…
#&gt; $ predicted &lt;fct&gt; Class2, Class1, Class2, Class1, Class2, Class1, Class1, Clas…
</code></pre>
<p>Notice that we have here both the <code>truth</code> plus predicted probabilities for <code>Class1</code> and <code>Class2</code>. Those predicted probabilities (well, one of them) are what we use for computing ROC AUC:</p>
<pre><code>roc_auc(two_class_example, truth, Class1)
#&gt; # A tibble: 1 × 3
#&gt;   .metric .estimator .estimate
#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
#&gt; 1 roc_auc binary         0.939
</code></pre>
<p>If all we had was <code>truth</code> and <code>predicted</code>, then we could only compute a metric that uses <a href=""https://yardstick.tidymodels.org/reference/index.html#classification-metrics"" rel=""nofollow noreferrer"">hard class probabilites</a>. One thing I can do is compute the confusion matrix:</p>
<pre class=""lang-r prettyprint-override""><code>conf_mat(two_class_example, truth, predicted)
#&gt;           Truth
#&gt; Prediction Class1 Class2
#&gt;     Class1    227     50
#&gt;     Class2     31    192
</code></pre>
<p><sup>Created on 2023-03-06 with <a href=""https://reprex.tidyverse.org"" rel=""nofollow noreferrer"">reprex v2.0.2</a></sup></p>
","2023-03-07 00:26:20","0","Answer"
"75656012","75654000","","<p>As you are on a Mac silicon (I guess M1, but anyway), you should try to use <code>tensorflow_macos</code> instead of <code>tensorflow</code>. To install it, you can download it from GitHub:</p>
<pre><code>bash -c &quot;$(curl -fsS  https://raw.githubusercontent.com/apple/tensorflow_macos/master/scripts/download_and_install.sh)&quot;
</code></pre>
<p>Or simply use pip (or pip3):</p>
<pre><code>pip install tensorflow-macos
</code></pre>
","2023-03-06 21:27:58","1","Answer"
"75655991","75654000","","<p>Hey try using this command</p>
<pre><code>%pip3 install tensorflow
</code></pre>
<p>or</p>
<pre><code>!pip3 install tensorflow
</code></pre>
<p>Let us know if it worked</p>
","2023-03-06 21:24:29","0","Answer"
"75654000","","Tensorflow.keras doesn't enable to my project","<p>I try to use tensorflow library and it doesn't work. I don't know what to do. BTW. Mac silicon.
Traceback (most recent call last):
File &quot;/Users/belka/PycharmProjects/golubov_laba_1/main.py&quot;, line 2, in 
from tensorflow import keras
ImportError: cannot import name 'keras' from 'tensorflow' (unknown location)</p>
<p>Process finished with exit code 1</p>
<p>I'd tried to uninstall tensor flow and used the apple require to this library</p>
","2023-03-06 17:30:54","-1","Question"
"75653158","75633185","","<p>the same thing happened to me, I changed the versions of the packages. I have the following setting and it works for me: scikit-learn = 1.1.2, scipy = 1.9.1, missingpy = 0.2.0.</p>
","2023-03-06 16:10:26","4","Answer"
"75649038","","Training difference between LightGBM API and Sklearn API","<p>I'm trying to train a LGBClassifier for multiclass task. I tried first working directly with LightGBM API and set the model and training as follows:</p>
<p><strong>LightGBM API</strong></p>
<pre><code>train_data = lgb.Dataset(X_train, (y_train-1))
test_data = lgb.Dataset(X_test, (y_test-1))
params = {}
params['learning_rate'] = 0.3
params['boosting_type'] = 'gbdt'
params['objective'] = 'multiclass'
params['metric'] = 'softmax'
params['max_depth'] = 10
params['num_class'] = 8
params['num_leaves'] = 500

lgb_train = lgb.train(params, train_data, 200)

# AFTER TRAINING THE MODEL

y_pred = lgb_train.predict(X_test)
y_pred_class = [np.argmax(line) for line in y_pred]
y_pred_class = np.asarray(y_pred_class) + 1
</code></pre>
<p>This is how the confussion matrix looks:</p>
<p><a href=""https://i.sstatic.net/oiZ79.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/oiZ79.png"" alt=""enter image description here"" /></a></p>
<p><strong>Sklearn API</strong></p>
<p>Then I tried to move to Sklearn API to be able to use other tools. This is the code I used:</p>
<pre><code>lgb_clf = LGBMClassifier(objective='multiclass',
    boosting_type='gbdt',
    max_depth=10,
    num_leaves=500,
    learning_rate=0.3,
    eval_metric=['accuracy','softmax'],
    num_class=8,
    n_jobs=-1,
    early_stopping_rounds=100,
    num_iterations=500)

clf_train = lgb_clf(X_train, (y_train-1), verbose=1, eval_set=[(X_train, (y_train-1)), (X_test, (y_test-1)))])

# TRAINING:  I can see overfitting is happening

y_pred = clf_train.predict(X_test)
y_pred = [np.argmax(line) for line in y_pred]
y_pred = np.asarray(y_pred) + 1
</code></pre>
<p>And this is the confusion matrix in this case:</p>
<p><a href=""https://i.sstatic.net/BQNWh.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/BQNWh.png"" alt=""enter image description here"" /></a></p>
<p><strong>Notes</strong></p>
<ol>
<li>I need to substract 1 from y_train as my classes start at 1 and LightGBM was complaining about this.</li>
<li>When I try a RandomSearch or a GridSearch I always obtain the same result as the last confusion matrix.</li>
<li>I have check different questions here but none solve this issue.</li>
</ol>
<p><strong>Questions</strong></p>
<ol>
<li>Is there anything that I'm missing out when implementing the model in Sklearn API?</li>
<li>Why do I obtain good results (maybe with overfitting) with LightGBM API?</li>
<li>How can I achieve the same results with the two APIs?</li>
</ol>
<p>Thanks in advance.</p>
<p><strong>UPDATE</strong> It was my mistake. I thought the output in both APIs would be the same but it doesn't seem like that. I just removed the np.argmax() line when predicting with Sklearn API. It seems this API already predict directly the class. Don't remove the question in case someone else is dealing with similar issues.</p>
","2023-03-06 09:24:30","3","Question"
"75648366","75648179","","<pre><code>!git clone https://github.com/facebookresearch/d2go
!python -m pip install ./d2go

...
your code
...
</code></pre>
","2023-03-06 08:03:43","0","Answer"
"75648179","","ModuleNotFoundError: No module named 'torch.ao.pruning'","<p>I want to train my custom dataset using D2Go.</p>
<p>D2Go official Repository Link: <a href=""https://github.com/facebookresearch/d2go"" rel=""nofollow noreferrer"">https://github.com/facebookresearch/d2go</a></p>
<p>But I am getting error. I have tried all possible ways to solve it. Still it shows error. Can anyone suggest me to solve it?</p>
<p>Already install below code as told in repository!</p>
<pre><code>!git clone https://github.com/facebookresearch/d2go
!python -m pip install ./d2go
</code></pre>
<p><code>from d2go.model_zoo import model_zoo</code></p>
<pre><code>Google Colab Output:

ModuleNotFoundError Traceback (most recent call last)
in
----&gt; 1 from d2go.model_zoo import model_zoo

5 frames
/content/d2go/d2go/trainer/fsdp.py in
14 from d2go.trainer.helper import parse_precision_from_string
15 from detectron2.utils.registry import Registry
---&gt; 16 from torch.ao.pruning import fqn_to_module
17 from torch.cuda.amp import GradScaler
18 from torch.distributed.fsdp.fully_sharded_data_parallel import (

ModuleNotFoundError: No module named 'torch.ao.pruning'
</code></pre>
","2023-03-06 07:37:07","0","Question"
"75648027","75282840","","<p>It turns out that you can just use <code>trial.suggest_categorical</code> to achieve your goal:</p>
<pre><code>import optuna
def objective(trial):
        # define two variables:
        A = trial.suggest_categorical('A', [1,2,3])
        B = trial.suggest_categorical('B', [5,6])
        # minimize this toy objective:
        obj = A/B
        return obj
study = optuna.create_study(direction=&quot;minimize&quot;)
study.optimize(objective, n_trials=20)
</code></pre>
","2023-03-06 07:16:23","10","Answer"
"75640068","","AttributeError: 'ArtistList' object has no attribute 'pop'","<pre><code>&gt;&gt;&gt; import jsbgym
&gt;&gt;&gt; import gymnasium as gym
&gt;&gt;&gt; env = gym.make(&quot;JSBSim-HeadingControlTask-Cessna172P-Shaping.STANDARD&quot;, render_mode=&quot;human&quot;)
&gt;&gt;&gt; env.reset()


     JSBSim Flight Dynamics Model v1.1.13 [GitHub build 986/commit a09715f01b9e568ce75ca2635ba0a78ce57f7cdd] Dec  3 2022 12:36:17
            [JSBSim-ML v2.0]

JSBSim startup beginning ...

(array([ 5.00000000e+03,  1.21430643e-17,  1.50920942e-16,  2.02536000e+02,
        4.44089210e-15, -5.32907052e-15,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00, -3.72529030e-09,  1.25629209e-15,  0.00000000e+00,
        2.99000000e+02]), {})
&gt;&gt;&gt; env.render()
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;C:\Users\noahs\AppData\Local\Programs\Python\Python311\Lib\site-packages\gymnasium\wrappers\order_enforcing.py&quot;, line 52, in render
    return self.env.render(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\noahs\AppData\Local\Programs\Python\Python311\Lib\site-packages\gymnasium\wrappers\env_checker.py&quot;, line 53, in render
    return env_render_passive_checker(self.env, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\noahs\AppData\Local\Programs\Python\Python311\Lib\site-packages\gymnasium\utils\passive_env_checker.py&quot;, line 384, in env_render_passive_checker
    result = env.render()
             ^^^^^^^^^^^^
  File &quot;C:\Users\noahs\Coding\AI\RL\JSBGym\jsbgym\environment.py&quot;, line 161, in render
    self.figure_visualiser.plot(self.sim)
  File &quot;C:\Users\noahs\Coding\AI\RL\JSBGym\jsbgym\visualiser.py&quot;, line 64, in plot
    data = subplot.lines.pop()
           ^^^^^^^^^^^^^^^^^
AttributeError: 'ArtistList' object has no attribute 'pop'
</code></pre>
<p>I tried rendering this environment with human <a href=""https://github.com/sryu1/jsbgym"" rel=""nofollow noreferrer"">https://github.com/sryu1/jsbgym</a>
but I keep getting this error. I understand that I can't use pop() with ArtistList but I don't know what is using ArtistList, could someone check my repo and see if there's any solution to that? Thanks :)</p>
","2023-03-05 03:44:32","1","Question"
"75639076","","How do I calculate the Area Under the ROC Curve in practice (using the yardstick package in R)?","<p>I am really struggling to understand why I can't get this working, as it must surely be very simple. I'd really appreciate some insight.</p>
<p>I am using R 4.2.2 on an M1 Macbook Air.</p>
<p>I am a physician and have trained a Gaussian Naive Bayes model that (imperfectly) predicts the likelihood of a patient dying given their response to a certain method of physicial positioning them when their lungs are not working properly.</p>
<p><strong>NB - all of this research is ethically approved, it won't be used in patient treatment, I don't have a statistician on this project.</strong></p>
<p>I will focus on the training dataset in which a column of predictions has been added. This df is called <code>train_pre_post</code>. There are 28 columns, and the ones of interest are <code>outcome</code>, which contains the true outcome of the patient, and <code>prediction</code> containing the predicted outcome. Both of these are factors with two levels. These levels are <code>rip</code> meaning the patient died, and <code>dc</code> meaning they survived until they were discharged. The other columns contain continuous physiological variables (e.g. oxygen levels, blood pressure, etc.).</p>
<p>I am trying to calculate the area under the receiver operating characteristic curve using the yardstick package. The command is <code>roc_auc()</code>. I am struggling with part of this command:</p>
<pre><code>roc_auc(data = train_pre_post, truth = outcome, ?????)
</code></pre>
<p>Where I have typed ????? this refers to my inability to comprehend what to put here. For simple measures of accuracy (such as f_meas(), part of the command involves designating the column containing the truth and the column containing the estimate. When I try to do this in <code>roc_auc()</code>, I get the following error message:</p>
<pre><code>Error in `dplyr::summarise()`:
ℹ In argument: `.estimate = metric_fn(...)`.
Caused by error in `validate_class()`:
! `estimate` should be a numeric but a factor was supplied
</code></pre>
<p>The yardstick documentation states &quot;Binary metrics using class probabilities take a factor truth column, and a single class probability column containing the probabilities of the event of interest.&quot; and despite playing around, I can't make this work and in all honesty I don't understand what this means.</p>
<p>Can anyone shed light on this or point me in the right direction?</p>
","2023-03-04 22:30:03","1","Question"
"75638930","75633662","","<p>I am guessing that the index in <code>CUDA_AVAILABLE_DEVICES</code> and the pytorch indexing don't actually correspond to each other i.e. <code>cuda:0</code> is the 1st gpu from the available devices in the list <code>CUDA_AVAILABLE_DEVICES</code>.</p>
<p>jodag's comment:</p>
<blockquote>
<p>When CUDA_VISIBLE_DEVICES is set to a single integer then pytorch will only see one device and it will be cuda:0 regardless of the value of the environment variable. Devices are always indexed starting at 0 in pytorch so for example if CUDA_VISIBLE_DEVICES is set to 2,5,7 then you should use pytorch device cuda:0, cuda:1 or cuda:2 to refer to devices 2, 5, or 7 respectively.</p>
</blockquote>
","2023-03-04 21:59:07","2","Answer"
"75634218","75633662","","<p>The error you are getting is that you have only one GPU. As torch.cuda.device_count() says you are having only one GPU. However, you are trying to load model from the cuda:3, which isn't available. In other words, you are trying to load the model from the device, and the PyTorch is unable to find that device and throws an error.</p>
<p>Check that your Pytorch have the available cuda resources to where you want to load the model, or otherwise you can update the CUDA_VISIBLE_DEVICES environment variable to match the device index.</p>
","2023-03-04 07:15:09","0","Answer"
"75633662","","How do you load a specific GPU from CUDA_AVAILABLE_DEVICES in PyTorch?","<p>I came up with this code but it's resulting in never ending bugs:</p>
<pre><code>def get_device_via_env_variables(deterministic: bool = False, verbose: bool = True) -&gt; torch.device:
    device: torch.device = torch.device(&quot;cpu&quot;)
    if torch.cuda.is_available():
        if 'CUDA_VISIBLE_DEVICES' not in os.environ:
            device: torch.device = torch.device(&quot;cuda:0&quot;)
        else:
            gpu_idx: list[str] = os.environ['CUDA_VISIBLE_DEVICES'].split(',')
            if len(gpu_idx) == 1:
                gpu_idx: str = gpu_idx[0]
            else:
                # generate random int from 0 to len(gpu_idx) with import statement
                import random
                idx: int = random.randint(0, len(gpu_idx) - 1) if not deterministic else -1
                gpu_idx: str = gpu_idx[idx]
            device: torch.device = torch.device(f&quot;cuda:{gpu_idx}&quot;)
    if verbose:
        print(f'{device=}')
    return device
</code></pre>
<p>I have a suspicion that the <code>gpu_idx</code> and  <code>CUDA_VISIBLE_DEVICES</code> don't actually match...I just want to load the right GPU. How do I do that?</p>
<p>error:</p>
<pre><code>Traceback (most recent call last):aded (0.000 MB deduped)
  File &quot;/lfs/ampere1/0/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_experiment_analysis_sl_vs_maml_performance_comp_distance.py&quot;, line 1368, in &lt;module&gt;
    main_data_analyis()
  File &quot;/lfs/ampere1/0/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_experiment_analysis_sl_vs_maml_performance_comp_distance.py&quot;, line 1163, in main_data_analyis
    args: Namespace = load_args()
  File &quot;/lfs/ampere1/0/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_experiment_analysis_sl_vs_maml_performance_comp_distance.py&quot;, line 1152, in load_args
    args.meta_learner = get_maml_meta_learner(args)
  File &quot;/afs/cs.stanford.edu/u/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/data_analysis/common.py&quot;, line 272, in get_maml_meta_learner
    base_model = load_model_ckpt(args, path_to_checkpoint=args.path_2_init_maml)
  File &quot;/afs/cs.stanford.edu/u/brando9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/mains/common.py&quot;, line 265, in load_model_ckpt
    base_model, _, _ = load_model_optimizer_scheduler_from_ckpt(args, path_to_checkpoint,
  File &quot;/afs/cs.stanford.edu/u/brando9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/mains/common.py&quot;, line 81, in load_model_optimizer_scheduler_from_ckpt
    ckpt: dict = torch.load(path_to_checkpoint, map_location=torch.device('cuda:3'))
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 607, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 882, in _load
    result = unpickler.load()
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 857, in persistent_load
    load_tensor(data_type, size, key, _maybe_decode_ascii(location))
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 846, in load_tensor
    loaded_storages[key] = restore_location(storage, location)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 827, in restore_location
    return default_restore_location(storage, str(map_location))
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 175, in default_restore_location
    result = fn(storage, location)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 151, in _cuda_deserialize
    device = validate_cuda_device(location)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/serialization.py&quot;, line 142, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on CUDA device '
RuntimeError: Attempting to deserialize object on CUDA device 3 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device.
</code></pre>
<p>motivated by the fact that I am trying to use the remainign 40GB from my 5CNN with 256 &amp; 512 filters but results it memory issues</p>
<pre><code>Traceback (most recent call last):
  File &quot;/lfs/ampere1/0/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_experiment_analysis_sl_vs_maml_performance_comp_distance.py&quot;, line 1368, in &lt;module&gt;
    main_data_analyis()
  File &quot;/lfs/ampere1/0/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_experiment_analysis_sl_vs_maml_performance_comp_distance.py&quot;, line 1213, in main_data_analyis
    stats_analysis_with_emphasis_on_effect_size(args, hist=True)
  File &quot;/afs/cs.stanford.edu/u/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/data_analysis/stats_analysis_with_emphasis_on_effect_size.py&quot;, line 74, in stats_analysis_with_emphasis_on_effect_size
    results_usl: dict = get_episodic_accs_losses_all_splits_usl(args, args.mdl_sl, loaders)
  File &quot;/afs/cs.stanford.edu/u/brando9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/data_analysis/common.py&quot;, line 616, in get_episodic_accs_losses_all_splits_usl
    losses, accs = agent.get_lists_accs_losses(data, training)
  File &quot;/afs/cs.stanford.edu/u/brando9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/meta_learners/pretrain_convergence.py&quot;, line 92, in get_lists_accs_losses
    spt_embeddings_t = self.get_embedding(spt_x_t, self.base_model).detach()
  File &quot;/afs/cs.stanford.edu/u/brando9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/meta_learners/pretrain_convergence.py&quot;, line 166, in get_embedding
    return get_embedding(x=x, base_model=base_model)
  File &quot;/afs/cs.stanford.edu/u/brando9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/meta_learners/pretrain_convergence.py&quot;, line 267, in get_embedding
    out = base_model.model.features(x)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/nn/modules/container.py&quot;, line 139, in forward
    input = module(input)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py&quot;, line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File &quot;/lfs/ampere1/0/brando9/miniconda/envs/mds_env_gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py&quot;, line 439, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 174.00 MiB (GPU 0; 79.20 GiB total capacity; 54.31 GiB already allocated; 22.56 MiB free; 54.61 GiB reserved in total by PyTorch)
</code></pre>
<p>I want to use GPU 3 but the last error say GPU 0. What am I doing wrong?</p>
<p>cross: <a href=""https://discuss.pytorch.org/t/how-do-you-load-a-specific-gpu-from-cuda-available-devices-in-pytorch/174044"" rel=""nofollow noreferrer"">https://discuss.pytorch.org/t/how-do-you-load-a-specific-gpu-from-cuda-available-devices-in-pytorch/174044</a></p>
","2023-03-04 04:33:57","0","Question"
"75633185","","ImportError: cannot import name '_check_weights' from 'sklearn.neighbors._base'","<p>I am trying to do Missforest as a method for handling missing values in table data.</p>
<pre><code>import sklearn
print(sklearn.__version__)
-&gt;1.2.1

import sklearn.neighbors._base
import sys
sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base

!pip install missingpy
from missingpy import MissForest
</code></pre>
<p>It was working fine until now, but since yesterday, the following error message has appeared.</p>
<pre><code>ImportError: cannot import name '_check_weights' from 'sklearn.neighbors._base'
</code></pre>
<p>I would like to know how to deal with this error.</p>
","2023-03-04 01:48:43","2","Question"
"75632847","74979359","","<p>I had the same doubt, but I indeed agree with the answer from @Rabin Adhikari.</p>
<p>In the provided implementation, the <code>x</code> that is passed to the <code>forward</code> method is a tensor of shape <code>(batch_size, sequence_length, embedding_dimension)</code>, rather than a flattened version of it (with shape <code>(batch_size, sequence_length * embedding_dimension)</code>). The (same) feed-forward layer applies to the last dimension only (the embedding dimension) for each batch and for each position in the sequence, hence <em>position-wise</em>.</p>
<p>This explains the quote from the paper which is also in the answer below and in your question</p>
<blockquote>
<p>While the linear transformations are the same across different positions, they use different parameters from (encoder) layer to (encoder) layer.</p>
</blockquote>
<p>It is easy to see that feeding the position-wise feed-forward layer with a sequence made of a repetition of the same tokens (represented here by the trivial embedding obtained via <code>torch.ones()</code>) you get the same output embedding for each token.</p>
<pre><code>feed_forward = PositionwiseFeedForward(d_model=5, d_ff=3, dropout=0)
input_embeddings = torch.ones(1, 10, 5)
ff_outputs = feed_forward(input_embeddings)

ff_outputs, ff_outputs.shape
# --&gt; (tensor([[[-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252],
                [-0.5512, -0.3976,  0.4570,  0.5153,  0.4252]]],
                grad_fn=&lt;ViewBackward0&gt;), torch.Size([1, 10, 5]))
</code></pre>
<p>I would also like to report a quote from the <a href=""https://transformersbook.com/"" rel=""noreferrer"">Natural Language Processing with Transformers</a> book</p>
<blockquote>
<p>Note that a feed-forward layer such as <code>nn.Linear</code> is usually applied to a tensor of shape <code>(batch_size, input_dim)</code>, where it acts on each element <em>of the batch independently</em>. This is actually true for any dimension except the last one, <strong>so when we pass a tensor of shape <code>(batch_size, seq_len, hidden_dim)</code> the layer is applied to all token embeddings <em>of the batch and sequence independently</em></strong>.</p>
</blockquote>
<p>Eventually, it is important to observe that this way you obtain <em>a hidden state for each token in the batch</em>, which makes the architecture very flexible.</p>
","2023-03-04 00:11:11","7","Answer"
"75628364","75625359","","<p>I think you could do something like</p>
<pre><code>train_set['Age'] = train_set['Age'].fillna(train_set.groupby([&quot;Sex&quot;,&quot;Pclass&quot;])['Age'].transform('median'))
test_set['Age'] = test_set['Age'].fillna(train_set.groupby([&quot;Sex&quot;,&quot;Pclass&quot;])['Age'].transform('median'))
</code></pre>
","2023-03-03 14:32:46","0","Answer"
"75628050","75626974","","<h1>TL;DR</h1>
<p>You will need to <strong>make a lot of assumption</strong> if you don't have the <code>config.json</code> and the model card doesn't have any documentation</p>
<p>After some guessing, possibly it's this:</p>
<pre><code>from u2net import U2NET
import torch

model = U2NET()

model.load_state_dict(torch.load('full_weights.pth', map_location=torch.device('cpu')))
</code></pre>
<hr />
<h1>In Long</h1>
<p>Looking at the files available in the model card, we see these files:</p>
<ul>
<li>.gitattributes</li>
<li>README.md</li>
<li>full_weights.pth</li>
</ul>
<p>A good guess would be that the <code>.pth</code> file is a PyTorch model binary. Given that, we can try:</p>
<pre><code>import shutil
import requests

import torch


# Download the .pth file locally
url = &quot;https://huggingface.co/Carve/u2net-universal/resolve/main/full_weights.pth&quot;
response = requests.get(url, stream=True)
with open('full_weights.pth', 'wb') as out_file:
    shutil.copyfileobj(response.raw, out_file)

model = torch.load('full_weights.pth', map_location=torch.device('cpu'))
</code></pre>
<p>But what you end up with is NOT a usable model, it's just the model parameters/weights (aka checkpoint file), i.e.</p>
<pre><code>type(model)
</code></pre>
<p>[out]:</p>
<pre><code>collections.OrderedDict
</code></pre>
<p>Looking at the layer names, it looks like a <code>rebnconvin</code> model that points to the <a href=""https://github.com/xuebinqin/U-2-Net"" rel=""nofollow noreferrer"">https://github.com/xuebinqin/U-2-Net</a> code:</p>
<pre><code>model.keys()
</code></pre>
<p>[out]:</p>
<pre><code>odict_keys(['stage1.rebnconvin.conv_s1.weight', 'stage1.rebnconvin.conv_s1.bias', 'stage1.rebnconvin.bn_s1.weight', 'stage1.rebnconvin.bn_s1.bias', 'stage1.rebnconvin.bn_s1.running_mean', 'stage1.rebnconvin.bn_s1.running_var', 'stage1.rebnconv1.conv_s1.weight', 'stage1.rebnconv1.conv_s1.bias', 'stage1.rebnconv1.bn_s1.weight', 'stage1.rebnconv1.bn_s1.bias', 'stage1.rebnconv1.bn_s1.running_mean', 'stage1.rebnconv1.bn_s1.running_var', ...])
</code></pre>
<p><strong>ASSUMING THAT YOU CAN TRUST THE CODE</strong> from the github, you can try installing it with:</p>
<pre><code>! wget https://raw.githubusercontent.com/xuebinqin/U-2-Net/master/model/u2net.py
</code></pre>
<p>And guessing from the layer names and model name, it looks like a U2Net from <a href=""https://arxiv.org/abs/2005.09007v3"" rel=""nofollow noreferrer"">https://arxiv.org/abs/2005.09007v3</a></p>
<p>So you can try:</p>
<pre><code>from u2net import U2NET

model = U2NET()

model.load_state_dict(torch.load('full_weights.pth', map_location=torch.device('cpu')))
</code></pre>
","2023-03-03 14:01:44","5","Answer"
"75626974","","Is it possible to load huggingface model which does not have config.json file?","<p>I am trying to load <a href=""https://huggingface.co/Carve/u2net-universal"" rel=""noreferrer"">this</a> semantic segmentation model from HF using the following code:</p>
<pre><code>from transformers import pipeline

model = pipeline(&quot;image-segmentation&quot;, model=&quot;Carve/u2net-universal&quot;, device=&quot;cpu&quot;)
</code></pre>
<p>But I get the following error:</p>
<pre><code>OSError: tamnvcc/isnet-general-use does not appear to have a file named config.json. Checkout 'https://huggingface.co/tamnvcc/isnet-general-use/main' for available files.
</code></pre>
<p>Is it even possible to load models from HuggingFace without config.json file provided?</p>
<p>I also tried loading the model via:</p>
<pre><code>id2label = {0: &quot;background&quot;, 1: &quot;target&quot;}
label2id = {&quot;background&quot;: 0, &quot;target&quot;: 1}
image_processor = AutoImageProcessor.from_pretrained(&quot;Carve/u2net-universal&quot;)
model = AutoModelForSemanticSegmentation(&quot;Carve/u2net-universal&quot;, id2label=id2label, label2id=label2id)
</code></pre>
<p>But got the same error.</p>
","2023-03-03 12:16:42","10","Question"
"75626081","75625359","","<p>IIUC, what you want is to replace the <code>Age</code> by a formula for each group <code>('Sex', 'Pclass')</code> when the <code>Age</code> is null:</p>
<pre><code>import numpy as np
import pandas as pd

train_df = pd.read_csv('train_df.csv', index_col=0)
test_df = pd.read_csv('test_df.csv', index_col=0)

guess_age = lambda x: int(x.median() / 0.5 + 0.5) * 0.5

train_df['Age'] = train_df['Age'].fillna(train_df.groupby(['Sex', 'Pclass'])['Age']
                                                 .transform(guess_age)).astype(int)

test_df['Age'] = test_df['Age'].fillna(test_df.groupby(['Sex', 'Pclass'])['Age']
                                              .transform(guess_age)).astype(int)
</code></pre>
<p>Before:</p>
<pre><code>&gt;&gt;&gt; train_df['Age'].isna().sum()
177

&gt;&gt;&gt; test_df['Age'].isna().sum()
86
</code></pre>
<p>After:</p>
<pre><code>&gt;&gt;&gt; train_df['Age'].isna().sum()
0

&gt;&gt;&gt; test_df['Age'].isna().sum()
0
</code></pre>
","2023-03-03 10:48:26","2","Answer"
"75625359","","refactor age imputation","<p>How can I refactor the following code to make sure it easier to read and better using a function. Can reproduce code and data frames used using GitHub <a href=""https://github.com/hamidpat/titanic"" rel=""nofollow noreferrer"">https://github.com/hamidpat/titanic</a> posted csv used on my github.</p>
<pre><code>import numpy as np
import pandas as pd


train_df = pd.read_csv(&quot;train_df.csv&quot;)
test_df = pd.read_csv(&quot;test_df.csv.csv&quot;)
combine = [train_df, test_df]


guess_ages = np.zeros((2, 3))
for df in combine:
    for i in range(0, 2):
        for j in range(0, 3):
            guess_df = df[(df['Sex'] == i) &amp; (
                df['Pclass'] == j + 1)]['Age'].dropna()
            age_guess = guess_df.median()
            guess_ages[i, j] = int(age_guess/0.5 + 0.5) * 0.5
    for i in range(0, 2):
        for j in range(0, 3):
            df.loc[(df.Age.isnull()) &amp; (df.Sex == i) &amp; (
                df.Pclass == j + 1), 'Age'] = guess_ages[i, j]

    df.Age = df.Age.astype(int)
</code></pre>
","2023-03-03 09:33:36","0","Question"
"75620412","75609027","","<p>I found that when I replaced the input_shape it works, anyway I tried this yesterday and it did not work so that was the reason why I insert the input_shape. It looks like TensorFlow trolling me all the time :))</p>
<p><code>model_gender_2 = tf.keras.Sequential([tf.keras.layers.Dense(60), tf.keras.layers.Dense(30), tf.keras.layers.Dense(1)])</code></p>
","2023-03-02 20:17:44","0","Answer"
"75615518","74981734","","<p>had the same issue. using shap.plot_summary(..., plot_type=&quot;bar&quot;) works for me -</p>
<pre><code>x = np.array(x_train[sample_indices], dtype=np.float32)
x_tensor = torch.from_numpy(x).to(DEVICE)
e = shap.DeepExplainer(model, x_tensor)

shap_values = e.shap_values(x_tensor)

shap.summary_plot(
    shap_values, features=x_samples, feature_names=x_cols, plot_type=&quot;bar&quot;, max_display=30)
</code></pre>
<p><a href=""https://i.sstatic.net/oJQTk.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/oJQTk.png"" alt=""enter image description here"" /></a></p>
","2023-03-02 12:37:55","1","Answer"
"75615176","75614816","","<p>Yes it is theoretically possible to forecast stock prices with LSTM. But...
The performance of LSTM for stock price prediction can vary depending on the quality and quantity of the data, as well as the specific architecture and parameters of the model.
In real-life it is not that effective in predicting long-term trends or sudden changes in the market because its impossible to factor all possible events that may really affect a price.</p>
<p>You can give it a try using this code:</p>
<p><a href=""https://www.datacamp.com/tutorial/lstm-python-stock-market"" rel=""nofollow noreferrer"">https://www.datacamp.com/tutorial/lstm-python-stock-market</a></p>
","2023-03-02 12:04:20","1","Answer"
"75615074","75614816","","<p>Answering your question - Yes</p>
<blockquote>
<p>Is LSTM suitable for forecasting stocks trend?</p>
</blockquote>
<p>LSTMs can be used for time series forecasting, but if you want to use something more complex and better there are many alternatives including Transformers which tackle many problems encountered in LSTMs such as lack of parallelization ability.</p>
<p>If you want to use some more involved methods I recommend checking out:
<a href=""https://timeseriesai.github.io/tsai/"" rel=""nofollow noreferrer"">https://timeseriesai.github.io/tsai/</a></p>
","2023-03-02 11:54:08","0","Answer"
"75614816","","Is LSTM suitable for forecasting stocks trend?","<p>I'm very beginner in AI and want to find an AI algorithm for forecasting stocks trend, I've seen SLTM but these algorithms use the price of a share for example 1000 days and predicate the next day, I want a predicate based on multiple rules, for example, buyer power or volume or ratio between them, etc...</p>
<p>I've used the LSTM by the price of a share in input.
But as I mentioned I do not want to use time series of prices :
for example, I have some data same to the below:</p>
<p>2.3, 2.1, 2.8,1.05,....,3.5,1.08  ---&gt; +5</p>
<p>1.5, 4.1, 3.8,2.47,....,1.2,2.41  ---&gt; +2</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>2.2, 2.8, 2.1,1.35,....,2.6,1.18  ---&gt; -3</p>
<p>That this data is the situation of a share in stock and have not the price and I want to fit the AI system with these millions of data and then with another sample of like share data forecast the trend of that share!<br />
The important thing for me is figuring out the relation or pattern of inputs and the output of these data.</p>
","2023-03-02 11:28:37","-1","Question"
"75609072","75609027","","<p>Problem is with the function <code>tf.keras.Sequential</code>. It expects a list of layers rather than each layer as an argument. So, the way you're passing the input is wrong. Try doing this:</p>
<pre><code>model_gender_2 = tf.keras.Sequential()
model_gender_2.add(tf.keras.layers.Dense(60, input_shape=(139,))
model_gender_2.add(tf.keras.layers.Dense(30)
model_gender_2.add(tf.keras.layers.Dense(1)
</code></pre>
<p>Or this</p>
<pre><code>model_gender_2 = tf.keras.Sequential([tf.keras.layers.Dense(60, input_shape=139),
                                      tf.keras.layers.Dense(30),
                                      tf.keras.layers.Dense(1)])
</code></pre>
","2023-03-01 21:15:43","0","Answer"
"75609027","","TensorFlow error : TypeError: 'int' object is not iterable - I can not find where is the problem","<p>first I am a greenhorn in ML, so its probably a stupid mistake :)</p>
<p>I downloaded this dataset:
<a href=""https://www.kaggle.com/datasets/muhammadtalharasool/simple-gender-classification"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/muhammadtalharasool/simple-gender-classification</a></p>
<p>Turned to variable gender_2</p>
<p>Use OneHotCode:</p>
<pre><code>gender_one_hot_2 = pd.get_dummies(gender_2)
gender_one_hot_2.head()

gender_one_HOT = gender_one_hot_2.drop(&quot;Unnamed: 9&quot;, axis = 1)
</code></pre>
<p>Normalized the data:</p>
<pre><code>cf = make_column_transformer((MinMaxScaler(), [' Age', ' Height (cm)', ' Weight (kg)']),
                             (OneHotEncoder(handle_unknown= &quot;ignore&quot;),[' Occupation_ Accountant', ' Occupation_ Analyst',
       ' Occupation_ Architect', ' Occupation_ Business Analyst',
       ' Occupation_ Business Consultant', ' Occupation_ CEO',
       ' Occupation_ Doctor', ' Occupation_ Engineer',
       ' Occupation_ Graphic Designer', ' Occupation_ IT Manager',
       ' Occupation_ Lawyer', ' Occupation_ Marketing Specialist',
       ' Occupation_ Nurse', ' Occupation_ Project Manager',
       ' Occupation_ Sales Representative', ' Occupation_ Software Engineer',
       ' Occupation_ Teacher', ' Occupation_ Writer', ' Occupation_Accountant',
       ' Occupation_Analyst', ' Occupation_Architect',
       ' Occupation_Business Analyst', ' Occupation_CEO', ' Occupation_Doctor',
       ' Occupation_Engineer', ' Occupation_Graphic Designer',
       ' Occupation_IT Manager', ' Occupation_Lawyer',
       ' Occupation_Marketing Specialist', ' Occupation_Nurse',
       ' Occupation_Project Manager', ' Occupation_Sales Representative',
       ' Occupation_Software Developer', ' Occupation_Teacher',
       ' Occupation_Writer', &quot; Education Level_ Associate's Degree&quot;,
       &quot; Education Level_ Bachelor's Degree&quot;,
       ' Education Level_ Doctorate Degree',
       &quot; Education Level_ Master's Degree&quot; ,
       &quot; Education Level_Associate's Degree&quot;,
       &quot; Education Level_Bachelor's Degree&quot;,
       ' Education Level_Doctorate Degree', &quot; Education Level_Master's Degree&quot;,
       ' Marital Status_ Divorced', ' Marital Status_ Married',
       ' Marital Status_ Single', ' Marital Status_ Widowed',
       ' Marital Status_Divorced', ' Marital Status_Married',
       ' Marital Status_Single', ' Favorite Color_ Black',
       ' Favorite Color_ Blue', ' Favorite Color_ Green',
       ' Favorite Color_ Grey', ' Favorite Color_ Orange',
       ' Favorite Color_ Pink', ' Favorite Color_ Purple',
       ' Favorite Color_ Red', ' Favorite Color_ Yellow',
       ' Favorite Color_Black', ' Favorite Color_Blue',
       ' Favorite Color_Green', ' Favorite Color_Grey',
       ' Favorite Color_Orange', ' Favorite Color_Pink',
       ' Favorite Color_Purple', ' Favorite Color_Red',
       ' Favorite Color_Yellow'])
)
X = gender_one_HOT.drop(&quot; Income (USD)&quot;, axis = 1)
y = gender_one_HOT[&quot; Income (USD)&quot;]

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)

cf.fit(X_train)

X_train_normal_2 = cf.transform(X_train)
X_test_normal_2 = cf.transform(X_test)
</code></pre>
<p>and then I inserted to the NN:</p>
<pre><code>tf.random.set_seed(42)

model_gender_2 = tf.keras.Sequential(tf.keras.layers.Dense(60 ,input_shape=139),
                                     tf.keras.layers.Dense(30),
                                     tf.keras.layers.Dense(1)
                                     )

model_gender_2.compile(loss = tf.keras.losess.mae,
                       optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),
                       metrics = [&quot;mae&quot;])
model_gender_2.fit(X_train_normal_2, y_train, epochs = 120)


but I got this output: 

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-103-e0b5ab8c49e8&gt; in &lt;module&gt;
      1 tf.random.set_seed(42)
      2 
----&gt; 3 model_gender_2 = tf.keras.Sequential(tf.keras.layers.Dense(60 ,input_shape=139),
      4                                      tf.keras.layers.Dense(30),
      5                                      tf.keras.layers.Dense(1)

3 frames
/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py in __init__(self, trainable, name, dtype, dynamic, **kwargs)
    450                 else:
    451                     batch_size = None
--&gt; 452                 batch_input_shape = (batch_size,) + tuple(kwargs[&quot;input_shape&quot;])
    453             self._batch_input_shape = batch_input_shape
    454 

TypeError: 'int' object is not iterable
</code></pre>
<p>Actualy I can not find the error I tried change the input on the first layer but it did not work:/</p>
<p>I tried inserting different input shapes but it did not work</p>
<p>I tried to change input shape of the first layer to 139 - which should be the right one but still does not work</p>
","2023-03-01 21:09:08","0","Question"
"75593802","75589764","","<p>The types of model trainings mentioned by other answers are if you want to train <em>one big model</em> on all of your data. What you are trying to do is train many small models. To do that, what you should do is group the DataFrame by <code>DeviceID</code> and pass each sub dataset to a PandasUDF for training.</p>
<p><a href=""https://www.databricks.com/blog/2021/04/06/fine-grained-time-series-forecasting-at-scale-with-facebook-prophet-and-apache-spark-updated-for-spark-3.html"" rel=""nofollow noreferrer"">Here</a> is a blog post that describes how to do this at scale. Ignore the part about prophet, you can use any ML model you like that works on pandas DataFrames. Note that Spark parallelizes the training so each dataset is trained on a separate executor.</p>
<p><a href=""https://spark.apache.org/docs/3.0.0/sql-pyspark-pandas-with-arrow.html#pandas-udfs-aka-vectorized-udfs"" rel=""nofollow noreferrer"">Documentation on PandasUDF</a></p>
","2023-02-28 15:06:26","0","Answer"
"75590653","75589764","","<p>Yes, this can achieved in PySpark. Some ML algorithms already work out of the box, i.e., they are already parallelized using different worker nodes. See these algorithms here : <a href=""https://spark.apache.org/docs/latest/ml-classification-regression.html"" rel=""nofollow noreferrer"">https://spark.apache.org/docs/latest/ml-classification-regression.html</a></p>
<p>What you need to do is divide the data based on DeviceID and train them in separate linear models. If you like to parallelize the training for 3 different linear models, open 3 different spark sessions and train them on device specific data.</p>
","2023-02-28 10:19:15","0","Answer"
"75589764","","How to parallelize model training with PySpark","<p>I have a large Spark DataFrame (it doesn't fit in memory) that contains data for multiple devices.</p>
<p>For each device there are multiple rows, and the columns contain features and a target. Here is what it looks like with dummy data:</p>
<pre><code>| DeviceID | Feature 1 | Feature 2 | Target |
|----------|-----------|-----------|--------|
|        A |         1 |         2 |      3 |
|        A |         2 |         4 |      6 |
|        B |         1 |         2 |      3 |
|        B |         2 |         4 |      6 |
|        C |         1 |         2 |      3 |
|        C |         2 |         4 |      6 |
</code></pre>
<p>I want to fit one linear model for each device, and I would like to parallelize this training to speed up computation.</p>
<p>With the data above, I would end up with 3 models: one for device A, one for device B, one for device C.</p>
<p>Can this be achieved with PySpark?</p>
<p>Using joblib Parallel/delayed doesn't work because spark dataframes can't be serialized.</p>
","2023-02-28 08:53:46","0","Question"
"75584625","","Why my script stop when scrapping img from web?","<p>I am currently trying to enrich a dataset for machine learning using a script that allows me to download images from google.</p>
<p>I first browse a dataframe that contains the fields to search on google, with the selenium webdriver I then retrieve the urls of the images to download, and save them in specific folders depending on the field via this function:</p>
<pre><code>def download_image(file_path, url, file_name):
    try:
        response = requests.get(url)
        response.raise_for_status()
        with open(os.path.join(file_path, file_name), 'wb') as file:
            file.write(response.content)
        print(f&quot;Image downloaded successfully to {os.path.join(file_path, file_name)}&quot;)
    except requests.exceptions.HTTPError as http_error:
        print(f&quot;HTTP error occurred: {http_error}&quot;)
    except Exception as error:
        print(f&quot;An error occurred: {error}&quot;) 
</code></pre>
<p>which is called in this loop:</p>
<pre><code>def enhanced_dataset_folder(name:str, tag:str, df):
    DRIVER_PATH = &quot;chromedriver&quot;
    wd = webdriver.Chrome(DRIVER_PATH)
    urls = get_images(tag, wd, 1, 2)
    folder_name = name.split('/')[0]
    props = tag.split(' ')
    test = []
    for i, url in enumerate(urls):
        try:
            img_name = str(i) + &quot;_img&quot;+str(i)+&quot;.jpg&quot;
            download_image(&quot;train/&quot;+folder_name+&quot;/&quot;, url, img_name)
        except Exception as e:
            print('Fail: ', e)
            continue
        else:
            print(&quot;ok&quot;)
            #df.append([folder_name+&quot;/&quot;+img_name,tag,props[0],props[1],props[2]], ignore_index=True)
    wd.quit()
</code></pre>
<p>The google chrome window and the script always stop at the same time, no matter how many photos I get per page.
I have this output, but no error comes out:</p>
<pre><code>Image downloaded successfully to train/1982 Porsche 944/0_img0.jpg
ok
Image downloaded successfully to train/1982 Porsche 944/1_img1.jpg
ok
HTTP error occurred: 403 Client Error: Forbidden. Please comply with the User-Agent policy: https://meta.wikimedia.org/wiki/User-Agent_policy for url: https://upload.wikimedia.org/wikipedia/commons/1/13/1986_944_Turbo.jpg
ok
Image downloaded successfully to train/1996 Ferrari 550 Maranello/0_img0.jpg
ok
Image downloaded successfully to train/1996 Ferrari 550 Maranello/1_img1.jpg
ok
Image downloaded successfully to train/1996 Ferrari 550 Maranello/2_img2.jpg
ok
Image downloaded successfully to train/2001 BMW 3 Series Convertible/0_img0.jpg
ok
</code></pre>
<p>After that I have nothing, even if I let it run for more than 10 minutes.
I know the problem is with the <code>download_image</code> function because when I don't call it the urls are retrieved for each occurrence of the dataframe</p>
","2023-02-27 19:09:17","2","Question"
"75584135","75552168","","<p>I would suggest, the following steps -</p>
<ol>
<li>EDA(Learn about data)</li>
<li>Finding correlations</li>
<li>Removing unnecessary features.</li>
<li>Working on preprocessing the data(Such as Outlier removal, Encoding Data)</li>
<li>Split features and target variables(X and Y)</li>
<li>Train Test Split</li>
<li>Perform scaling(Scaling before train test split will lead to data leakage)</li>
<li>Choose the algorithm, depending on the usecase (TreeBased models doesn't get effected by outliers and different scale of data so you can reduce those steps while selecting these models)</li>
<li>Depending on the usecase select the metrics to judge your model's performance.(Confusion matrix, f1 score, precision, recall, rmse, mse)</li>
</ol>
","2023-02-27 18:18:14","1","Answer"
"75569871","75566575","","<p>I assume the problem lies with your class Dataset, please replace it with following function,</p>
<pre><code>def load_data(test_split, batch_size):
&quot;&quot;&quot;Loads the data&quot;&quot;&quot;
sonar_dataset = SonarDataset('./sonar.all-data')
# Create indices for the split
dataset_size = len(sonar_dataset)
test_size = int(test_split * dataset_size)
train_size = dataset_size - test_size

train_dataset, test_dataset = random_split(sonar_dataset,
                                           [train_size, test_size])

train_loader = DataLoader(
    train_dataset.dataset,
    batch_size=batch_size,
    shuffle=True)
test_loader = DataLoader(
    test_dataset.dataset,
    batch_size=batch_size,
    shuffle=True)

return train_loader, test_loader 
</code></pre>
","2023-02-26 03:38:53","1","Answer"
"75567836","75111871","","<p>just change plt.scatter(X, Y, alpha=0.3) to plt.scatter(X, y, alpha=0.3) and you should have your problem solved.</p>
","2023-02-25 19:20:01","1","Answer"
"75567017","75566575","","<p>The error is coming from <code>model(dataset[&quot;train_dataset&quot;])</code>. That lines takes the DataLoader for the training data and passes it to the model as a Tensor to execute the model on. Instead, to train a model, you need to create an optimization loop that iterates over the DataLoader like this:</p>
<pre><code>dataset = DataSet()
model = NeuralNetwork() # Don't pass the dataset to your models

loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.05)

for X, y in dataset['train_dataset']:
    pred = model(X)
    loss = loss_fn(pred, y)

    # Backpropagation
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if batch % 100 == 0:
        loss, current = loss.item(), (batch + 1) * len(X)
        print(f&quot;loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]&quot;)
</code></pre>
<p>But you probably want to test using your test DataLoader during your training process as well. DataLoaders are iterable so it looks similar the above for the training data. But you have to be careful to turn off the gradients. Look at the below link for more details:</p>
<p><a href=""https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation"" rel=""nofollow noreferrer"">https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation</a></p>
","2023-02-25 17:01:34","1","Answer"
"75566575","","How to use the dataset comes from pytorch random_split()?","<p>I'm new to pyTorch and this is my first project. I need to split the dataset and feed the training dataset to model. <strong>The training dataset must be splitted in to features and labels (which I failed to do that)</strong>.  Here is what I have tried so far, however, I don't know how to feed the dataset obtained from <code>random_split()</code> to model.</p>
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import SGD
import matplotlib.pyplot as plt
import seaborn as sns
from dataset import DataSet


class NeuralNetwork(nn.Module):
    input_dim = 10
    hidden_dim = 4
    output_dim = 1

    def __init__(self, dataset):
        super().__init__()

        self.layers = [
            nn.Linear(self.input_dim, self.hidden_dim),
            nn.Linear(self.hidden_dim, self.output_dim)
        ]
        self.train_dataset = dataset[&quot;train_dataset&quot;]
        self.test_dataset = dataset[&quot;test_dataset&quot;]
        self.layers = nn.ModuleList(self.layers)

    def forward(self, x):
        for layer in self.layers:
            x = nn.functional.rrelu(layer(x))


dataset = DataSet()
model = NeuralNetwork(dataset)
model(dataset[&quot;train_dataset&quot;])
</code></pre>
<p>and this is <code>dataset.py</code></p>
<pre><code>import pandas as pd
import torch
from torch.utils.data import DataLoader


class DataSet:
    divide_rate = 0.8
    file = './pima-indians-diabetes.csv'

    def __init__(self):
        data_set = pd.read_csv(self.file)
        train_size = int(self.divide_rate * len(data_set))
        test_size = len(data_set) - train_size
        self.train_dataset, self.test_dataset = torch.utils.data.random_split(data_set, [train_size, test_size])
        self.train_dataset = torch.utils.data.DataLoader(self.train_dataset, shuffle=True)
        self.test_dataset = torch.utils.data.DataLoader(self.test_dataset, shuffle=True)

    def __getitem__(self, key):
        return getattr(self, key)
</code></pre>
<p>The error is</p>
<blockquote>
<p>TypeError: linear(): argument 'input' (position 1) must be Tensor, not DataLoader</p>
</blockquote>
","2023-02-25 15:44:45","0","Question"
"75556772","75552538","","<p>Comparing model performance is relative to the task you have and the goal of your project. I would recommend allocating time to decide what constitutes as better performance.</p>
<p>Here are some things to consider:</p>
<p><strong>Overall accuracy</strong></p>
<p>Compare MAE/MSE/R-squared across a test set. It sounds like you have already done this - however I am surprised that you said both models have similar RMSE but different R-squared since they are related quantities. I would advise checking there are no bugs in your code OR consider reavaluating what you mean by <em>similar RMSE</em>.
Consider also adding MAPE (Mean Average Percentage Error) to your repertoire since percentages are more intuitively interpreted and compared that things like MAE.</p>
<p><strong>Computational time</strong></p>
<p>Computation resources are often valuable. If you are running models through AWS or GCC then you can likely translate model training, hyperparameter tuning, and model evaluations to $$$. If two models have comparable performance but one is costing you less to run then that is something you should keep in mind. The significance of this depends on how often you plan on training, optimising hyperparameters, feature selection, or function use, and how much you are willing to pay for an increase in accuracy.</p>
<p>Another importance is how fast it takes to get results. If this is being used in an API where human waiting time for the computer to churn out a result is significant, then this is something to consider. Another scenario where time is important is if it's time consuming to train and fine-tune a model when you (or worse, someone else) are wanting results quickly.</p>
<p><strong>Edge / border cases</strong></p>
<p>Are there obscure / unusual cases / atypical that are important which one model can predict over another? These do not have to be obscure but simply occur less frequently in the data sets, and since they are rare they may not contribute significantly to overall accuracy. However, the benefit of being able to cover more cases may significantly improve your use cases.</p>
<p><strong>Variance of accuracy</strong></p>
<p>Similar to edge/border cases. Instead of MAE or overall accuracy, it may be the case that your accuracy for each model output is either <em>good enough</em> or <em>not good enough</em> and that a more meaningful metric is to evaluate the percentage of times your model output is <em>good enough</em>. It may be that one model has a higher overall accuracy, but this is distributed across some scenarios where accuracy is exceptionally high and others where it is low. It may be favourable to have a <em>good enough</em> prediction 100% of the times than an <em>exceptional accuracy</em> most of the time and <em>not good enough</em> some of the time.</p>
<p><strong>Behaviour</strong></p>
<p>Sometimes the behaviour of one model is favourable to another, even though there may be little difference seen in error metrics. The term <em>behaviour</em> here  is subjective, but it can be:</p>
<ol>
<li>Are there unwanted fluctuations in output seen in one model over another?</li>
<li>Do similar inputs give significantly different outputs?</li>
<li>Do you occasionally make wildly inaccurate predictions?</li>
<li>How similar is model behaviour to a human performing the same task?</li>
<li>Does the regression increase/decrease in scenarios you expect it to?</li>
</ol>
<p><strong>Performance on test cases</strong></p>
<p>Oftentimes models are trained in different circumstances to how they are used in production. Having a collection of production use-cases with an idea of what performance you are wanting can help to evaluate your model, especially in circumstances where model performance is subjective.</p>
<p>Which brings me on to what is probably the most important thing to consider:</p>
<p><strong>What is your model actually being used for?</strong></p>
<p>What problem are you actually trying to solve? If your goal is to create a model with less overall MSE then use the one with less MSE. If not then try to write down exactly what the goal is and how you are going to measure it. Consider writing OKRs: <a href=""https://en.wikipedia.org/wiki/OKR"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/OKR</a></p>
<p>I regularly get into this scenario myself but I do consider it a core issue to the purpose of my work if ever I cannot immediately answer the question: has this made a significant and demonstratable improvement?</p>
","2023-02-24 12:50:22","1","Answer"
"75556684","75552538","","<p>R Squared value is the measure of goodness of fit of Regression models and ranges between 0-100%</p>
<p>0% means that the model does not explain the variation of the response variable around its mean and 100% means it explains all the variation
Usually larger the value of R squared, the better the data fits your model.
But there's an important point to remember:</p>
<p>A lower R-squared value is always not bad because there are several areas of study that exist in which you'll find unexplainable variation and the value is bound to be lower but still it can be used to draw some conclusions.</p>
<p>Conclusion- A model with a larger R-squared value does not necessarily mean a good model and the one with the smaller value is always not a bad model. It depends on your field of study and you can use the R-squared value along with the residual plot of your data to understand the goodness of fit by visualizing it.
To learn more you can read <a href=""https://statisticsbyjim.com/regression/interpret-r-squared-regression/"" rel=""nofollow noreferrer"">this</a>.</p>
<p>I hope you find this helpful.
Thanks</p>
","2023-02-24 12:41:07","-1","Answer"
"75556202","75554580","","<p>Based on my understanding, it seems like the question is asking whether the same prediction model can be used for different categories of products within the same company or for similar categories of products across different companies.</p>
<p>Regarding the first part of the question, it is possible to use the same prediction model for different categories of products within the same company, but it might not be as effective as using a model that is specifically tailored to each category. This is because the characteristics and patterns of each category of products might be different, and using a single model might not capture all the nuances of each category.</p>
<p>For the second part of the question, it is more difficult to use the same prediction model for similar categories of products across different companies. This is because different companies might have different characteristics, such as different customer bases, pricing strategies, or product offerings. Additionally, each company might have their own unique data sets, making it challenging to use a single model across different companies.</p>
<p>In terms of applying this to healthcare and beauty products, it is possible to use a single prediction model if the products share similar characteristics or if there is significant overlap between the customer base. However, it might be more effective to use separate models that are tailored to the specific characteristics and patterns of each category. Additionally, as you mentioned, offering credit or other incentives to customers can also help drive sales in both categories.</p>
<p>ps....&quot;Based on my experience, selling healthcare and beauty products together may be more effective for younger individuals who are paying for their own healthcare, rather than for Medicare members.&quot;</p>
","2023-02-24 11:46:21","1","Answer"
"75555797","75552168","","<ol>
<li><p>Data analysis and visualization (swarmplot, boxplot...).</p>
</li>
<li><p>Correlation(sns.heatma())</p>
</li>
<li><p>Check outliers</p>
</li>
<li><p>Preprocessing(MinMaxScaler, StandardScaler).</p>
</li>
<li><p>Split x--y.</p>
</li>
<li><p>Feature_importances_</p>
</li>
<li><p>train_test_split: X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.15, random_state=2)</p>
</li>
<li><p>Choosing an algorithm: log_reg, xgboost, svm...</p>
</li>
<li><p>Check Metrics</p>
<pre><code>  ...............#Example 
  X = df[['age', 'anaemia', 'creatinine_phosphokinase', 
        'ejection_fraction', 'high_blood_pressure', 'platelets',
        'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time', 'diabetes']]
  y = df['DEATH_EVENT']

   from sklearn.model_selection import train_test_split
   from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
   from sklearn import metrics
   X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.15, random_state=2, stratify=y)


   from xgboost import XGBClassifier
   model_XGB = XGBClassifier(earning_rate= 0.01, max_depth = 4, n_estimators = 100)
   model_XGB.fit(X_train, y_train)
   Y_pred_XGB = model_XGB.predict(X_test)

   cmXG = confusion_matrix(y_test, Y_pred_XGB)
</code></pre>
</li>
</ol>
","2023-02-24 11:06:54","0","Answer"
"75554804","75554580","","<p><strong>On the same company:</strong></p>
<p>Assuming that the data for the two categories is similar: yes, but you should either:</p>
<ol>
<li>Train an instance of the model for each category, or;</li>
<li>Combine the data of the two categories for model training and evaluation and consider adding the category as a feature.</li>
</ol>
<p>What I mean by the data of the two categories being similar is that they should have the same data fields / features. For example, if you are forecasting sales then you should know historical sales, inventory, etc. for products in both categories.</p>
<p>I would typically prefer the latter option (2) over the former (1) since your single model would then have effectively trained on more data. The benefit of (1) over (2) is that you can deploy a different for each category for scenarios where the data between those categories is significantly different.</p>
<p><strong>On using the same model for different companies:</strong></p>
<p>This depends on what you mean by same model, the legalities surrounding the data, what you do with your model, and what your agreements are with the companies the data is sourced from. I'm not a legal expert (and you should consider seeking legal advice if in doubt), but I believe commercial use of a model trained on private data owned by a company requires the legal consent of the company.</p>
<p>If by <em>same model</em> you mean the model architecture e.g. a Neural Network with X layers and Y activation functions, then this is fine. If what you mean is can you use a model which is trained on one company's data to forecast another, or whether you can combine company data to train a model (hyperparameter tuning included), then depending on what you are planning on doing with this model you may run into significant legal issues.</p>
","2023-02-24 09:29:48","1","Answer"
"75554580","","Can we use the same Machine Learning model for two categories of product of the same company?","<p>Can we use the same prediction model for two categories of products for example Beauty and Healthcare of the same company? Also, can we use the same prediction model for the Healthcare products of two different companies?</p>
","2023-02-24 09:08:55","-2","Question"
"75552538","","How to compare two different models?","<p>I trained a new regression model and want to compare its performance against the benchmark model. If the models have similar RMSE and MAE but different R-squared values (the benchmark model R2 is much lower). How to understand which one is performing better.</p>
","2023-02-24 04:07:56","1","Question"
"75552168","","What is the correct order in data preprocessing stage for Machine Learning?","<p>I am trying to create some sort of step-by-step guide/cheat sheet for myself on how to correctly go over the data preprocessing stage for Machine Learning.</p>
<p>Let's imagine we have a binary Classification problem.
Would the below strategy work or do I have to change/modify the order of some of the steps and maybe something should be added or removed?</p>
<p><strong>1.</strong> <strong>LOAD DATA</strong></p>
<pre><code>import pandas as pd    

df = pd.read_csv(&quot;data.csv&quot;)
</code></pre>
<p><strong>2.</strong> <strong>SPLIT DATA</strong> - I understand, that to prevent &quot;data leakage&quot;, we <strong>MUST</strong> split data into training (work with it) and testing (pretend it does not exist) sets.</p>
<pre><code>from sklearn.model_selection import train_test_split

# stratify = 'target' if proportion disbalance in data, so training and testing sets will have the same proportion after splitting.
train_df, test_df = train_test_split(df, test_size = 0.33, random_state = 42, stratify = 'target')    
</code></pre>
<p><strong>3.</strong> <strong>EDA ON TRAINING DATA</strong> - Is it correct to look at the training set only or should we do EDA before splitting? If we assume the Test set doesn't exist, then we should not care what is there, right?</p>
<pre><code>train_df.info()
train_df.describe()
# + Plots etc.
</code></pre>
<p><strong>4.</strong> <strong>OUTLIERS ON TRAINING DATA</strong> - If we have to scale the data, the Mean (Average) is very sensitive to outliers, therefore we have to take care of them in the beginning. Also, if we decide to fill Null numerical features with mean, outliers may be a problem in this case.</p>
<pre><code>import matplotlib.pyplot as plt
import seaborn as sns 

# Check distributions
sns.diplot(train_df)    
sns.boxplot(train_df)   
train_df.corr()    # Correlation between all features and label
train_df.corr()[&quot;target&quot;].sort_values()
sns.scatterplot(x = &quot;Column X&quot;, y = 'target', data = train_df)

train_df.describe() # above 75% + 1.5 * (75% - 25%) and below 25% - 1.5 * (75% - 25%)
</code></pre>
<p><strong>5.</strong> <strong>MISSING VALUES ON TRAINING DATA</strong> - We can't have Null values. We either remove or fill in them. This step should be taken care of in the beginning.</p>
<pre><code>train_df.info()
train_df.isnull().sum() # or train_df.isna().sum()
# Show the rows with Null values
train_df[train_df[&quot;Column&quot;].isnull()]      
</code></pre>
<p><strong>6.</strong> <strong>FEATURE ENGINEERING ON TRAINING DATA</strong> - Is this step should be taken care of in the beginning as well? I think so because we can create the feature that might need to be scaled.</p>
<pre><code># If some columns (not target) correlated with each other, we should delete one of them, or make some sort of blending.
train_df.corr()
train_df = train_df.drop(&quot;1 of Correlated X Column&quot;, axis = 1)

# For normally distributed data, the skewness should be about 0. A skewness value &gt; 0 means there is more weight in the left tail of the distribution
# We should try to have normal distribution in the columns
train_df[&quot;Not Skewed Column&quot;] = np.log(train_df[&quot;Skewed Column&quot;] + 1)
train_df[&quot;Not Skewed Column&quot;].hist(figsize = (20,5))
plt.show()
</code></pre>
<p><strong>7.</strong> <strong>CATEGORICAL DATA</strong> - We can't have objects in the data frame.</p>
<pre><code>from sklearn.preprocessing import OneHotEncoder     # Just an example

# Create X and y variables
X_train = train_df.drop('target', axis = 1)
y_train = np.where(train['target'] == 'yes', 1, 0)

# Create the one hot encoder
onehot = OneHotEncoder(handle_unknown = 'ignore')

# Apply one hot encoding to categorical columns 
encoded_columns = onehot.fit_transform(X_train.select_dtypes(include = 'object')).toarray()

X_train = X_train.select_dtypes(exclude = 'object')
X_train[onehot.get_feature_names_out()] = encoded_columns
</code></pre>
<p><strong>8.</strong> <strong>IMBALANCED DATA</strong> - Good to have the same or similar number of observations in the target column.</p>
<pre><code> from imblearn.over_sampling import SMOTE      # Just an example

 # Create the SMOTE class
 sm = SMOTE(random_state = 42)

 # Resample to balance the dataset
 X_train, y_train = sm.fit_resample(X_train, y_train)
</code></pre>
<p><strong>9.</strong> <strong>SCALE DATA</strong> - Should we scale the target column in the Regression task?</p>
<pre><code># Brings mean close to 0 and std to 1. Formula = (x - mean) / std
from sklearn.preprocessing import StandardScaler      # Just an example

scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)    # X_test we don't fit, only transform!
</code></pre>
<p><strong>10.</strong> <strong>PRINCIPAL COMPONENT ANALYSIS (PCA) - REDUCING DIMENSIONALITY</strong> - Should data be scaled before applying PCA?</p>
<pre><code># Example: PCA = 50 (n_components). Let's say Input is 100 X features, after applying PCA, Output will be 50 X features.
# Why don't use PCA all the time? We lose the ability to explain what each value is because they are now in combination with a whole bunch of features. 
# Will not be able to look at feature importance, trees, etc. We use it when we need to. 
# If we are able to train the model with all features, then great. if can't, we can apply PCA, but be ready to lose the ability to explain what is driving the machine learning model.

from sklearn.decomposition import PCA     # Just an example

pca = PCA(n_components = 50)  # Just an Example
scaled_X_train = pca.fit_transform(scaled_X_train)    # X_test we don't fit, only transform!
</code></pre>
<p><strong>11.</strong> <strong>MODEL, FIT, EVALUATE, PREDICT</strong></p>
<pre><code>from sklearn.linear_model import RidgeClassifier          # Just an Example  
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix

model = RidgeClassifier()
model.fit(scaled_X_train, y_train)

# HERE we should create and / or execute transformation function that will take test_df as input and will return scaled_X_test and y_test

y_pred = model.predict(scaled_X_test)

# Evaluate model - Calculate Classification metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
print(f&quot;RidgeClassifier model scores Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}&quot;)

confusion_matrix(y_test, y_pred, labels = [1,0])
</code></pre>
<p><strong>12.</strong> <strong>SAVE MODEL</strong></p>
<pre><code>import joblib       # Just an example

# Save Model
joblib.dump(model, 'best_model.joblib')  
</code></pre>
","2023-02-24 02:41:33","1","Question"
"75541609","75464126","","<p>Thought about this tech challenges for some time. In general it’s AI solvable problem since there are easy features to extract such as unique values, clustering, distribution, etc.</p>
<p>And we want to bake this ability in <a href=""https://columns.ai"" rel=""nofollow noreferrer"">https://columns.ai</a>, obviously we haven’t gotten there yet, the first step we have done though is to collect all columns stats upon a data connection, identify columns that have similar range of unique values and generate a bunch of query templates for users to explore its dataset.</p>
<p>If interested, please take a look, as we keep advancing this part, it will become closer to an AI model to find relevant columns. Cheers!</p>
","2023-02-23 07:13:22","0","Answer"
"75540302","75529760","","<p>Thinks for @Ivan's answer.
According to @Ivan's answer, this is exact solution of my question:</p>
<pre><code>b, c, z, d, = 1, 1, 4, 2
pz = int(z**0.5)
crop_img = x.transpose(-1, -2).reshape(b, c, pz, pz*d, d).transpose(-1, -2).reshape(b, c, pz*d, pz*d)

# and the inverse process
x = crop_img.reshape(b, c, pz, d, pz*d).transpose(-1, -2).reshape(b, c, z, d, d).transpose(-1, -2)
</code></pre>
","2023-02-23 03:28:01","1","Answer"
"75530049","75529760","","<p>This is an operation that can be solved with a combination of <a href=""https://pytorch.org/docs/stable/generated/torch.transpose.html"" rel=""nofollow noreferrer""><code>torch.transpose</code></a> and <a href=""https://pytorch.org/docs/stable/generated/torch.reshape.html"" rel=""nofollow noreferrer""><code>torch.reshape</code></a> operations. Starting from an arrangement tensor:</p>
<pre><code>&gt;&gt;&gt; x = torch.arange(16).view(4,2,2)
</code></pre>
<ol>
<li><p>Start by transposing the tensor such that the dimension that you want to collate on is standing &quot;vertically&quot;, this can be done with <code>x.transpose(dim0=1, dim1=2)</code>. Although, I recommend working with negative dimensions instead:</p>
<pre><code>&gt;&gt;&gt; x.transpose(-1,-2)
tensor([[[ 0,  2],
         [ 1,  3]],

        [[ 4,  6],
         [ 5,  7]],

        [[ 8, 10],
         [ 9, 11]],

        [[12, 14],
         [13, 15]]])
</code></pre>
</li>
<li><p>Then reshape to collate the dimension:</p>
<pre><code>&gt;&gt;&gt; x.transpose(-1,-2).reshape(2,4,2)
tensor([[[ 0,  2],
         [ 1,  3],
         [ 4,  6],
         [ 5,  7]],

        [[ 8, 10],
         [ 9, 11],
         [12, 14],
         [13, 15]]])
</code></pre>
</li>
<li><p>Then flip back to recover the order of the elements from <strong>step 1.</strong>:</p>
<pre><code>&gt;&gt;&gt; x.transpose(-1,-2).reshape(2,4,2).transpose(-1,-2)
tensor([[[ 0,  1,  4,  5],
         [ 2,  3,  6,  7]],

        [[ 8,  9, 12, 13],
         [10, 11, 14, 15]]])
</code></pre>
</li>
<li><p>Finally, reshape to the desired form:</p>
<pre><code>&gt;&gt;&gt; x.transpose(-1,-2).reshape(2,4,2).transpose(-1,-2).reshape(len(x),-1)
tensor([[ 0,  1,  4,  5],
        [ 2,  3,  6,  7],
        [ 8,  9, 12, 13],
        [10, 11, 14, 15]])
</code></pre>
</li>
</ol>
<p>From there you can apply to your needs by changing the dimension sizes and even expanding to higher dimension numbers such as <code>[b, c, z, d, d]</code> as you described. If you understand this simple approach by playing around with this example you will be able to work out any problem similar to this.</p>
","2023-02-22 08:38:40","2","Answer"
"75529760","","How to merge sub-matrices of high-dimensional matrices under the condition of ensuring the relative position of sub-matrices？","<p>If I have a tensort x with shape [z, d, d], which indicates a series image frames just like video data. Let pz=z**0.5 and let x = x.view(pz, pz, d, d]. Then we can get a grid of images with grid size of pz*pz, and each image has a shape of [d, d]. Now, I want get a matrix or tensor with shape of [1, 1, p*d, p*d], and MUST insure all element keep the same inter-position with all original images.</p>
<p>For an example:</p>
<pre><code>    x =    [[[ 0,  1],
             [ 2,  3]],

            [[ 4,  5],
             [ 6,  7]],

            [[ 8,  9],
             [10, 11]],
    
            [[12, 13],
             [14, 15]]]
</code></pre>
<p>which indicates a series images with shape [2,2] and z = 4
I want get a tensor like:</p>
<pre><code>tensor([[ 0,  1,  4,  5],
        [ 2,  3,  6,  7],
        [ 8,  9, 12, 13],
        [10, 11, 14, 15]])
</code></pre>
<p>I can use x = x.view(1, 1, 4, 4) to get one with the same shape,but it likes this:</p>
<pre><code>tensor([[[[ 0,  1,  2,  3],
          [ 4,  5,  6,  7],
          [ 8,  9, 10, 11],
          [12, 13, 14, 15]]]])
</code></pre>
<p>which I don't want.</p>
<p>And more , How about x has more dimension? Just like [b, c, z, d, d]. How to deal with this?</p>
<p>Any suggestion will be helpful.</p>
<p>I have a solution about the three dimention situation.If x.shape = [z, d, d], then the code below will work. But not work for high dimention tensors. Nested loop will be ok, but too heavy.
My solution for three dimention situation:</p>
<pre><code>
    d = 2
    z = 4
    b, c = 1, 1
    x = torch.arange(z*d*d).view(z, d, d)
    # x = torch.tensor([[[ 1,  2],
    #          [ 4,  6]],
    #
    #         [[ 8, 10],
    #          [12, 14]],
    #
    #         [[16, 18],
    #          [20, 22]],
    #
    #         [[24, 26],
    #          [28, 30]],
    #
    #         [[32, 34],
    #          [36, 38]],
    #
    #         [[40, 42],
    #          [44, 46]],
    #
    #         [[48, 50],
    #          [52, 54]],
    #
    #         [[56, 58],
    #          [60, 62]],
    #
    #         [[64, 66],
    #          [68, 70]]])
    # make z-index planes to a grid layout
    grid_side_len = int(z**0.5)
    grid_x = x.view(grid_side_len, grid_side_len, d, d)
    # for all rows of crops , horizontally stack them togather
    plane = []
    for i in range(grid_x.shape[0]):
        cat_crops = torch.hstack([crop for crop in grid_x[i]])
        plane.append(cat_crops)

    plane = torch.vstack([p for p in plane])
    print(&quot;3D crop to 2D crop plane:&quot;)
    print(x)
    print(plane)
    print(plane.shape)


    print(&quot;2D crop plane to 3D crop:&quot;)
    # group all rows
    split = torch.chunk(plane, plane.shape[1]//d, dim=0)
    spat_flatten = torch.cat([torch.cat(torch.chunk(p, p.shape[1]//d, dim=1), dim=0) for p in     split], dim=0)
    crops = [t[None,:,:] for t in torch.chunk(spat_flatten, spat_flatten.shape[0]//d, dim=0)]
    spat_crops = torch.cat(crops, dim=0)
    print(spat_crops)
    print(spat_crops.shape)
</code></pre>
","2023-02-22 08:05:48","1","Question"
"75522398","75521999","","<p>This is a warning generated when <code>predict</code> function in <code>sklearn</code> internally calls <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html#scipy.stats.mode"" rel=""nofollow noreferrer""><code>scipy.stats.mode</code></a>. This was fixed <a href=""https://github.com/scikit-learn/scikit-learn/commit/02a4b342181e5ff0226081691308414e53c3107b#diff-861011cf3c620527b29aa12afb1b31212d7b6782e71f5b8ceca6e84199bf86be"" rel=""nofollow noreferrer"">here</a> - I suggest you update scikit-learn to latest and try.</p>
","2023-02-21 15:14:46","3","Answer"
"75521999","","What to do about future warning when using sklearn.neighbors?","<p>I fear, I have the same problem as in this post:</p>
<p><a href=""https://stackoverflow.com/questions/74877602/getting-a-warning-when-using-sklearn-neighbors-about-keepdims"">getting a warning when using sklearn.neighbors about keepdims</a></p>
<p>I try to use KNN as part of an ensemble classifier, but everytime I get the following warning:</p>
<blockquote>
<p>FutureWarning: Unlike other reduction functions (e.g. <code>skew</code>, <code>kurtosis</code>), the default behavior of <code>mode</code> typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of <code>keepdims</code> will become False, the <code>axis</code> over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set <code>keepdims</code> to True or False to avoid this warning.
mode, _ = stats.mode(_y[neigh_ind, k], axis=1)</p>
</blockquote>
<p>I know that one way to solve this issue is to suppress future warnings, but since this might lead to errors later, I would rather fix it now. Is there a way to do this? I tried simply calling <code>KNeighborsClassifier(keepdim = True)</code> but this syntax was not accepted.</p>
<p>Also when adding
<code>from warnings import simplefilter simplefilter(action='ignore', category=FutureWarning)</code> does not suppress the message for me.</p>
<p>Here is the full code:</p>
<pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
sns.set(style='darkgrid', font_scale=1.4)
from imblearn.over_sampling import SMOTE
import itertools
#import warnings
#warnings.filterwarnings('ignore')
import plotly.express as px
import time

# Sklearn
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score
from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve, roc_curve
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder
from sklearn.feature_selection import mutual_info_classif
from sklearn.decomposition import PCA
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import eli5
from eli5.sklearn import PermutationImportance
from sklearn.utils import resample
from sklearn.metrics import cohen_kappa_score, make_scorer
from sklearn import metrics

# Models
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.naive_bayes import GaussianNB

# Train-validation split
X_train, X_valid, y_train, y_valid = train_test_split(X,y,stratify=y,train_size=0.8,test_size=0.2,random_state=0)


oversample = SMOTE(random_state=0)

X_train_Smot, Y_train_Smot = oversample.fit_resample(X_train, y_train)
# Classifiers
classifiers = {
    &quot;LogisticRegression&quot; : LogisticRegression(random_state=0, solver='lbfgs'),
    &quot;KNN&quot; : KNeighborsClassifier(),
    &quot;SVC&quot; : SVC(random_state=0, probability=True),
    &quot;RandomForest&quot; : RandomForestClassifier(random_state=0),
    &quot;XGBoost&quot; : XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss'), # XGBoost takes too long
    &quot;LGBM&quot; : LGBMClassifier(random_state=0),
    #&quot;CatBoost&quot; : CatBoostClassifier(random_state=0, verbose=False),
    &quot;NaiveBayes&quot;: GaussianNB()
}

# Grids for grid search
LR_grid = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],
           'max_iter': [50, 100, 150]
          }

KNN_grid = {'n_neighbors': [3, 5, 7, 9],
            'p': [1, 2]}

SVC_grid = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],
            'kernel': ['linear', 'rbf'],
            'gamma': ['scale', 'auto']}

RF_grid = {'n_estimators': [50, 100, 150, 200, 250, 300],
        'max_depth': [4, 6, 8, 10, 12]}

boosted_grid = {'n_estimators': [50, 100, 150, 200],
        'max_depth': [4, 8, 12],
        'learning_rate': [0.05, 0.1, 0.15]}

NB_grid={'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-7]}

# Dictionary of all grids
grid = {
    &quot;LogisticRegression&quot; : LR_grid,
    &quot;KNN&quot; : KNN_grid,
    &quot;SVC&quot; : SVC_grid,
    &quot;RandomForest&quot; : RF_grid,
    &quot;XGBoost&quot; : boosted_grid,
    &quot;LGBM&quot; : boosted_grid,
    &quot;CatBoost&quot; : boosted_grid,
    &quot;NaiveBayes&quot;: NB_grid
}
i=0
clf_best_params=classifiers.copy()
valid_scores=pd.DataFrame({'Classifer':classifiers.keys(), 'Validation accuracy': np.zeros(len(classifiers)), 'Training time': np.zeros(len(classifiers))})
for key, classifier in classifiers.items():
    start = time.time()
    clf = GridSearchCV(estimator=classifier, param_grid=grid[key], n_jobs=-1, cv=None)

    # Train and score
    clf.fit(X_train_Smot, Y_train_Smot)
    #valid_scores.iloc[i,1]=clf.score(X_valid, y_valid)
    y_pred = clf.predict(X_valid)
    valid_scores.iloc[i,1]=metrics.cohen_kappa_score(y_pred, y_valid, weights='quadratic')
    # Save trained model
    clf_best_params[key]=clf.best_params_
    
    # Print iteration and training time
    stop = time.time()
    valid_scores.iloc[i,2]=np.round((stop - start)/60, 2)
    
    print('Model:', key)
    print('Training time (mins):', valid_scores.iloc[i,2])
    print('')
    i+=1


</code></pre>
","2023-02-21 14:39:17","1","Question"
"75515320","75476211","","<pre class=""lang-py prettyprint-override""><code>import os

import pandas as pd
from dotenv import load_dotenv
import numpy as np
from sklearn.base import TransformerMixin, BaseEstimator
from sklearn.experimental import enable_iterative_imputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.impute import IterativeImputer
from sklearn.compose import ColumnTransformer
from sklearn.compose import make_column_selector
from sklearn.pipeline import Pipeline

load_dotenv()


sample_data = pd.DataFrame({
    &quot;a&quot;: [4.4, 1.0, None, 3.0, 2.7],
    &quot;a1&quot;: [1, 2, 4, None, 2.7],
    &quot;b&quot;: [&quot;HIGH&quot;, &quot;HIGH&quot;, &quot;LOW&quot;, &quot;HIGH&quot;, &quot;LOW&quot;],
    &quot;c&quot;: [True, False, False, True, False]
})


class VTEAllColImputeTransformer(TransformerMixin, BaseEstimator):
    def __init__(self, non_num_cols=[], num_cols=[]):
        self.non_num_cols = non_num_cols
        self.num_cols = num_cols
        self.encoder = OneHotEncoder(handle_unknown='ignore', drop='first', sparse=False)
        self.num_transformer = IterativeImputer(max_iter=100, random_state=int(os.getenv(&quot;RANDOM_SEED&quot;)))

    def fit(self, X, y=None):
        self.encoder.fit(X[self.non_num_cols])
        res = pd.DataFrame(self.encoder.transform(X[self.non_num_cols]), columns=self.encoder.get_feature_names_out())
        res = pd.concat([res.reset_index(drop=True), X[self.num_cols].reset_index(drop=True)], axis=1)
        print(res)
        self.num_transformer.fit(res)
        return self

    def transform(self, X, y=None):
        res = pd.DataFrame(self.encoder.transform(X[self.non_num_cols]), columns=self.encoder.get_feature_names_out())
        res = pd.concat([res.reset_index(drop=True), X[self.num_cols].reset_index(drop=True)], axis=1)
        res = pd.DataFrame(self.num_transformer.transform(res), columns=self.num_transformer.get_feature_names_out())
        scaler = StandardScaler()
        res[self.num_cols] = scaler.fit_transform(res[self.num_cols])
        return res.to_numpy()


custom_transfomer = Pipeline(steps=[('custom_transformer', AllColImputeTransformer(non_num_cols=[&quot;b&quot;, &quot;c&quot;],
                                                                                      num_cols=[&quot;a&quot;, &quot;a1&quot;]))])
scaler = Pipeline([('scaler', StandardScaler())])

transformers = []
transformers.append(('custom', custom_transfomer, [&quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a1&quot;]))

preprocessor = ColumnTransformer(transformers=transformers)
pre_processing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])
print(pre_processing_pipeline.fit_transform(sample_data))
</code></pre>
","2023-02-21 00:19:31","0","Answer"
"75513712","75505829","","<p>This is a bit of a stab in the dark, performance-wise, but maybe it helps:</p>
<p>If the dataframe has <code>NaN</code>s instead empty strings <code>&quot;&quot;</code> do <code>df = df.fillna(&quot;&quot;)</code> first. Then:</p>
<pre class=""lang-py prettyprint-override""><code>import re

tags = {word: tag for tag in df.columns[:5] for word in set(df[tag]) if word != &quot;&quot;}

def repl(match):
    tag = tags.get(match[0], &quot;Others&quot;)
    return &quot; &quot;.join(f&quot;{part}^{tag}&quot; for part in match[0].split())

def tagging(row):
    pat = &quot;|&quot;.join(sorted(row.iloc[:-1], key=len, reverse=True)) + r&quot;|\w+&quot;
    return re.sub(pat, repl, row.at[&quot;FullAddress&quot;])

df[&quot;FullAdressWithTag&quot;] = df.apply(tagging, axis=1)
</code></pre>
<ul>
<li><p>First make mapping <code>tags</code> of the items in the columns <code>Premise</code>, <code>Thoroughfare</code>, <code>Locality</code>, <code>PostalCode</code> and <code>Country</code> onto the column names, the tags.</p>
</li>
<li><p>Then <code>.apply</code> the <code>tagging</code> function to the dataframe rows:</p>
<ul>
<li>The function packs the items of the tag-columns into a search pattern (a disjunction, sorted by length in reverse, augmented with a part to catch items that are not present in the columns).</li>
<li>Then use the pattern to add the tags with the <code>repl</code> function, which uses the <code>tags</code> mapping to do that. If the there's no key present for the address part then the <code>.get</code> returns <code>Others</code> as tag.</li>
</ul>
</li>
</ul>
<p>Result for the small sample:</p>
<pre class=""lang-none prettyprint-override""><code>+----+---------------------------------------------------------------------+
|    | FullAdressWithTag                                                   |
+====+=====================================================================+
|  0 | Old^Others Thorn^Others,                                            |
|    | Yew^Thoroughfare Tree^Thoroughfare Lane^Thoroughfare,               |
|    | Holmbridge^Locality HD9^PostalCode 2NR^PostalCode,                  |
|    | N^Country Ireland^Country                                           |
+----+---------------------------------------------------------------------+
|  1 | 3^Premise Cysgod^Thoroughfare Y^Thoroughfare Castell^Thoroughfare,  |
|    | Llandudno^Locality Junction^Locality LL31^PostalCode 9LJ^PostalCode |
+----+---------------------------------------------------------------------+
|  2 | 1168^Premise Christchurch^Thoroughfare Road^Thoroughfare,           |
|    | BH7^PostalCode 6DY^PostalCode Bournemouth^Locality                  |
+----+---------------------------------------------------------------------+
</code></pre>
","2023-02-20 20:09:09","0","Answer"
"75508226","75505829","","<p>Here is a long and bulky code that could get your job done:</p>
<pre><code>def getDFwithFullTag(df1):
    cols_to_check = ['Premise', 'Thoroughfare', 'Locality', 'PostalCode', 'Country']
    def checkAddr(row):
        ans = ''
        for st in row['FullAddress'].split(' '):
            flg = False
            for col in cols_to_check:
                if st in row[col].split(' '):
                    if st[-1]==',':
                        ans += st[:-1]+'^'+col+', '
                    else:
                        ans += st+'^'+col+' '
                    flg = True
                    break
            if not flg:
                if st[-1]==',':
                    ans += st[:-1]+'^'+col+', '
                else:
                    ans += st+'^'+col+' '
        return ans
    ftag = []
    for i in range(len(df1)):
        ftag.append(checkAddr(df1.loc[i]))

    df_new = pd.DataFrame(data=df1.FullAddress)
    df_new.insert(1, 'FullAdressWithTag', ftag, True)
    return df_new
</code></pre>
<p>Apart from being large and ugly, this function would take around 20-30 minutes to process 1 million rows. This function takes a dataframe as input and outputs a dataframe of your desired format.</p>
","2023-02-20 10:43:48","0","Answer"
"75505829","","Python pandas: Search from multiple columns that contained strings of another column and map it to the new column","<p>I have a dataframe looks like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Premise</th>
<th>Thoroughfare</th>
<th>Locality</th>
<th>PostalCode</th>
<th>Country</th>
<th>FullAddress</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Yew Tree Lane</td>
<td>Holmbridge</td>
<td>HD9 2NR</td>
<td>N Ireland</td>
<td>Old Thorn, Yew Tree Lane, Holmbridge HD9 2NR, N Ireland</td>
</tr>
<tr>
<td>3</td>
<td>Cysgod Y Castell</td>
<td>Llandudno Junction</td>
<td>LL31 9LJ</td>
<td>Uk</td>
<td>3 Cysgod Y Castell, Llandudno Junction LL31 9LJ</td>
</tr>
<tr>
<td>1168</td>
<td>Christchurch Road</td>
<td>Bournemouth</td>
<td>BH7 6DY</td>
<td>Wales UK</td>
<td>1168 Christchurch Road, BH7 6DY Bournemouth</td>
</tr>
</tbody>
</table>
</div>
<p>And want to create another column or dataframe that looks like this</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>FullAddress</th>
<th>FullAdressWithTag</th>
</tr>
</thead>
<tbody>
<tr>
<td>Old Thorn, Yew Tree Lane, Holmbridge HD9 2NR, N Ireland</td>
<td>Old^Others Thorn^Others, Yew^Thoroughfare Tree^Thoroughfare Lane^Thoroughfare, Holmbridge^Locality HD9^PostalCode 2NR^PostalCode, N^Country Ireland^Country</td>
</tr>
<tr>
<td>3 Cysgod Y Castell, Llandudno Junction LL31 9LJ</td>
<td>3^Premise Cysgod^Thoroughfare Y^Thoroughfare Castell^Thoroughfare, Llandudno^Locality Junction^Locality LL31^PostalCode 9LJ^PostalCode</td>
</tr>
<tr>
<td>1168 Christchurch Road, BH7 6DY Bournemouth</td>
<td>1168^Premise Christchurch^Thoroughfare Road^Thoroughfare, BH7^PostalCode 6DY^PostalCode Bournemouth^Locality</td>
</tr>
</tbody>
</table>
</div>
<p>I am trying to map the <em><strong>FullAddressWithTag</strong></em> columns that based on data that is available on the single column such as Locality, Premise, PostalCode etc. Do note that the pattern of the FullAddress might be vary.</p>
<p>For example, it can be:</p>
<ul>
<li><p>Premise -&gt; Thoroughfare -&gt; Postalcode -&gt; Locality</p>
</li>
<li><p>Premise -&gt; Thoroughfare -&gt; Locality -&gt; PostalCode</p>
</li>
<li><p>Thoroughfare -&gt; Premise -&gt; Postalcode -&gt; Locality</p>
</li>
</ul>
<p>It can be in different position depends on how the FullAddress given. If the element in FullAddress doesnt have a tag, it will tags as &quot;Others&quot;</p>
<p>I have million records for this data to be map with.</p>
","2023-02-20 06:15:55","-1","Question"
"75496179","75476211","","<p>You need to first create pipeline that uses <code>'ColumnTransformer'</code> then  apply one-hot encoding to the categorical columns, followed by an <code>IterativeImputer</code> that uses both the one-hot encoded categorical columns and numerical columns to impute missing values</p>
<pre><code>categorical_transformer = make_pipeline(OneHotEncoder(handle_unknown='ignore'))
numerical_transformer = make_pipeline(VarianceThreshold(), StandardScaler(), IterativeImputer())


preprocessor = make_column_transformer(
    (categorical_transformer, make_column_selector(dtype_include=object)),
    (numerical_transformer, make_column_selector(dtype_include=np.number))
)

pipeline = make_pipeline(preprocessor)

transformed_data = pipeline.fit_transform(sample_data)
</code></pre>
","2023-02-18 20:24:11","-1","Answer"
"75495995","75371176","","<p>I had this issue while running <code>import statsmodels.api as sm</code>. The issue was happening with <code>numpy==1.24.2</code>. Downgrading it to <code>1.23</code> solved the issue for me. I have not tested newer versions tbh, so another one might work as well.</p>
","2023-02-18 19:49:42","7","Answer"
"75489292","75484347","","<p>there is a mismatch in the number of samples between the true labels (Y_test) and the predicted labels (logreg_main_test)</p>
<p>you should make sure that the shape of the test data is the same as the shape of the training data before you use the trained model to make predictions. You can do this by preprocessing the test data in the same way as the training data. Specifically, you should apply the same feature scaling or normalization that you applied to the training data to the test data.</p>
<p>You can try the following below:</p>
<pre><code>scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
</code></pre>
","2023-02-17 21:16:03","0","Answer"
"75488964","75487663","","<p>You could use a one-liner that <code>sample</code>s one of <code>1:3</code> for unique patient IDs and <code>split</code>s <code>df</code> by that.</p>
<pre><code>set.seed(42)
res &lt;- split(df, with(df, ave(id, id, FUN=\(x) sample.int(3, 1, prob=c(.6, .2, .2)))))
</code></pre>
<p><em>Tests:</em></p>
<pre><code>## test proportions (should approx. be [.6, .2, .2])
proportions(sapply(res, \(x) length(unique(x$id)))) |&gt; round(2)
#    1    2    3 
# 0.53 0.25 0.22 

## test uniqueness
stopifnot(length(Reduce(intersect, lapply(res, `[[`, 'id'))) == 0)
</code></pre>
<h2>Update</h2>
<p>To get more stable proportions, we could use fixed group sizes by <code>rep</code>eating <code>1:3</code> by vector <code>p</code>.</p>
<pre><code>len &lt;- length(u &lt;- unique(df$id))
p1 &lt;- c(.2, .2)
rlp &lt;- round(len*p1)
p &lt;- c(len - sum(rlp), rlp)
set.seed(42)
a &lt;- setNames(rep.int(1:3, p), sample(u))

res &lt;- split(df, a[match(df$id, names(a))])  ## this line splits the df

proportions(sapply(res, \(x) length(unique(x$id))))
#   1   2   3 
# 0.6 0.2 0.2 

## test uniqueness
stopifnot(length(Reduce(intersect, lapply(res, `[[`, 'id'))) == 0)
</code></pre>
<hr />
<p><em>Data:</em></p>
<pre><code>set.seed(42)
n &lt;- 200; np &lt;- 100
df &lt;- data.frame(id=paste0('P', as.integer(as.factor(sort(sample.int(np, n, replace=TRUE))))),
                 les=sample(0:1, n, replace=TRUE),
                 pyr=runif(n))
</code></pre>
","2023-02-17 20:24:41","1","Answer"
"75488145","75487663","","<p>Here is a way with package <code>rsample</code>.<br />
First split in <code>test</code> and other data (named <code>train</code> in the code below) keeping all <code>PatientID</code> in the same subsets, then split <code>train</code>.</p>
<pre class=""lang-r prettyprint-override""><code>library(rsample)

set.seed(2023)
g &lt;- group_initial_split(df1, group = PatientID, prop = 0.8)
train &lt;- training(g)
test &lt;- testing(g)
g &lt;- group_initial_split(train, group = PatientID, prop = 3/4)
train &lt;- training(g)
validation &lt;- testing(g)

# check data split proportions
df_list &lt;- list(train = train, validation = validation, test = test)
sapply(df_list, nrow)
#&gt;      train validation       test 
#&gt;        600        199        201

# this shows that all groups belong to one subset only
lapply(df_list, \(x) unique(x[[1]]))
#&gt; $train
#&gt; [1] &quot;P5&quot;  &quot;P9&quot;  &quot;P8&quot;  &quot;P3&quot;  &quot;P10&quot; &quot;P4&quot; 
#&gt; 
#&gt; $validation
#&gt; [1] &quot;P2&quot; &quot;P7&quot;
#&gt; 
#&gt; $test
#&gt; [1] &quot;P1&quot; &quot;P6&quot;
</code></pre>
<p><sup>Created on 2023-02-17 with <a href=""https://reprex.tidyverse.org"" rel=""nofollow noreferrer"">reprex v2.0.2</a></sup></p>
<hr />
<h1>Test data</h1>
<pre class=""lang-r prettyprint-override""><code>set.seed(2023)
p &lt;- sprintf(&quot;P%d&quot;, 1:10)
n &lt;- 1e3
df1 &lt;- data.frame(
  PatientID = sample(p, n, TRUE),
  x = rnorm(n)
)
</code></pre>
<p><sup>Created on 2023-02-17 with <a href=""https://reprex.tidyverse.org"" rel=""nofollow noreferrer"">reprex v2.0.2</a></sup></p>
","2023-02-17 18:39:16","1","Answer"
"75487944","75487663","","<p><em><strong>Edit</strong></em> I misunderstood how you wished to handle PatientIDs. The original answer is at the bottom, however note stratification will aim to put equivalent proportions of each PatientID in each split. You should use the <code>group_</code> splitting function indicated by @Rui Barradas.</p>
<pre class=""lang-r prettyprint-override""><code>library(tidymodels)

set.seed(217)
df_split &lt;- group_initial_split(df, PatientID, prop = 4/5)
df_training &lt;- training(df_split)
df_testing &lt;- testing(df_split)
df_validation &lt;- group_validation_split(df_training, PatientID, prop = 3/4)
</code></pre>
<p><em>Original reply</em>
In the <code>tidymodels</code> framework you can opt to stratify the sampling using your <code>PatientID</code> variable. The resulting resamples will have equivalent proportions.</p>
<p>To create your desired splits you could first split the data 80:20 training:testing, then split the training set 75:25 into training:validation.</p>
<pre class=""lang-r prettyprint-override""><code>library(tidymodels)

set.seed(217)
df_split &lt;- initial_split(df, prop = 4/5, strata = PatientID)
df_training &lt;- training(df_split)
df_testing &lt;- testing(df_split)
df_validation &lt;- validation_split(df_training, prop = 3/4, strata = PatientID)
</code></pre>
","2023-02-17 18:17:15","2","Answer"
"75487663","","Splitting datas in three sets with balanced datas","<p>EDIT : OK so now I have my train, validation and test sets with rows belonging to patients in same groups. But, using a plot test, I see that the original imbalanced data from the original dataset (from the outcome LesionResponse, 1: 70% and 0 : 30%) is not very respected...Indeed, in the training datas, I have a nearly 55/45 repartition and it's not really welcomed for me. How can I do to correct this ?</p>
<pre><code>summary(train$LesionResponse)
#   0   1
# 159 487
summary(validation$LesionResponse)
#  0   1
# 33 170
summary(test$LesionResponse)
#  0   1
# 77 126
</code></pre>
<p>Hi guys,
I have my dataset (here an exemple) and I must build a predictive model for an outcome : &quot;LesionResponse&quot;.
So I have in a first time split my datas in train (60%), validation and test (20% each) sets.
I have a huge problem, many rows of my table belong to same patients...so in order to dodge bias, I must divide my datas and take into account the PatientIDs...
I am here stuck because I don't know how to split my datas in three and keep the rows belonging to same patients together.</p>
<p>Here is my code :</p>
<pre><code>structure(list(PatientID = c(&quot;P1&quot;, &quot;P1&quot;, &quot;P1&quot;, 
&quot;P2&quot;, &quot;P3&quot;, &quot;P3&quot;, &quot;P4&quot;, &quot;P5&quot;, 
&quot;P5&quot;, &quot;P6&quot;), LesionResponse = structure(c(2L, 2L, 1L, 2L, 2L, 2L, 2L, 
    2L, 1L, 2L), .Label = c(&quot;0&quot;, 
    &quot;1&quot;), class = &quot;factor&quot;), pyrad_tum_original_shape_LeastAxisLength = c(19.7842995242803, 
    15.0703960571122, 21.0652247652897, 11.804125918871, 27.3980336338908, 
    17.0584330264122, 4.90406343942677, 4.78480430022189, 6.2170232078547, 
    5.96309532740722, 5.30141540007441), pyrad_tum_original_shape_Sphericity = c(0.652056853392657, 
    0.773719977240238, 0.723869070051882, 0.715122964970338, 
    0.70796498824535, 0.811937882810929, 0.836458991713367, 0.863337931630415, 
    0.851654860256904, 0.746212862162174), pyrad_tum_log.sigma.5.0.mm.3D_firstorder_Skewness = c(0.367453961973625, 
    0.117673346718817, 0.0992025164349288, -0.174029385779302, 
    -0.863570016875989, -0.8482193060411, -0.425424618080682, 
    -0.492420174157913, 0.0105111292451967, 0.249865833210199), pyrad_tum_log.sigma.5.0.mm.3D_glcm_Contrast = c(0.376932105256115, 
    0.54885738172596, 0.267158344601612, 2.90094719958076, 0.322424096161189, 
    0.221356030145403, 1.90012334870722, 0.971638740404501, 0.31547550396399, 
    0.653999340294952), pyrad_tum_wavelet.LHH_glszm_GrayLevelNonUniformityNormalized = c(0.154973213866752, 
    0.176128379241556, 0.171129002059539, 0.218343919352019, 
    0.345985943932352, 0.164905080489496, 0.104536489151874, 
    0.1280276816609, 0.137912385073012, 0.133420904484894), pyrad_tum_wavelet.LHH_glszm_LargeAreaEmphasis = c(27390.2818110851, 
    11327.7931034483, 51566.7948885976, 7261.68702290076, 340383.536555142, 
    22724.7792207792, 45.974358974359, 142.588235294118, 266.744186046512, 
    1073.45205479452), pyrad_tum_wavelet.LHH_glszm_LargeAreaLowGrayLevelEmphasis = c(677.011907073653, 
    275.281153810458, 582.131636238695, 173.747506476692, 6140.73990175018, 
    558.277670638306, 1.81042257642817, 4.55724031114589, 6.51794350173746, 
    19.144924585586), pyrad_tum_wavelet.LHH_glszm_SizeZoneNonUniformityNormalized = c(0.411899490603372, 
    0.339216399209913, 0.425584323452468, 0.355165782879786, 
    0.294934042125209, 0.339208410636982, 0.351742274819198, 
    0.394463667820069, 0.360735532720389, 0.36911240382811)), row.names = c(NA, -10L), class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, 
&quot;data.frame&quot;))
</code></pre>
<p>i was thinking about a loop who would split a <code>unique(PatientID)</code> dataset in three with 60% in the train set, and if there is no balanced outcome in the sets, to do it again and again. I was thinking more of an interval to solve it...
How would you do guys ?</p>
","2023-02-17 17:48:35","2","Question"
"75485874","75411671","","<p>Can you access the model.ini inside of the zip? There is [domains] tag and under the tag is a list of files in domains/ directory which correspond the categorical encoding for each feature.</p>
<p>e.g:</p>
<pre><code>[columns]
AGE
RACE
DPROS
DCAPS
PSA
VOL
GLEASON
CAPSULE

[domains]
7: 2 d000.txt 
</code></pre>
<p>means 7th column (CAPSULE) has 2 categorical variables in d000.txt</p>
<p>or there is a experimental/modelDetails.json file that has categorical values under output.domains. The index in the list correspond to the feature in the output.names list.</p>
<p>e.g output.domains[7] are domains for output.names[7] feature.</p>
","2023-02-17 14:57:21","0","Answer"
"75485309","75464126","","<p>The most common approach I've seen to evaluate the analytical utility of columns is the correlation method. This would tell you if there is a relationship (positive or negative) among specific column pairs. In my experience you'll be able to more easily build analysis outputs when columns are correlated - although, these analyses may not always be the most accurate.</p>
<p>However, before you even do that, like you indicate, you would probably need to narrow down your list of columns using much simpler methods. For example, you could surely eliminate a whole bunch of columns based on datatype and basic count statistics.</p>
<p>Less common analytic data types (ids, blobs, binary, etc) can probably be excluded first, followed by running simple <code>COUNT(Distinct(ColName))</code>, and <code>Count(*) where ColName is null</code> . This will help to eliminating UniqueIDs, Keys, and other similar data types. If all the rows are distinct, this would not be a good field for analysis. Same process for NULLs, if the percentage of nulls is greater than some threshold then you can eliminate those columns as well.</p>
<p>In order to automate it depending on your database, you could create a fairly simple stored procedure or function that loops through all the tables and columns and does a data type, count_distinct and a null percentage analysis on each field.</p>
<p>Once you've narrowed down list of columns, you can consider a <a href=""https://www.geeksforgeeks.org/python-pandas-dataframe-corr/"" rel=""nofollow noreferrer"">.corr() function</a> to run the analysis against all the remaining columns in something like a Python script.
If you wanted to keep everything in the database, Postgres also supports a <code>corr()</code> <a href=""https://www.postgresql.org/docs/9.5/functions-aggregate.html"" rel=""nofollow noreferrer"">aggregate function</a>, but you'll only be able to run this on 2 columns at a time, like this:</p>
<blockquote>
<p><code>SELECT corr(column1,column2) FROM table;</code></p>
</blockquote>
<p>so you'll need to build a procedure that evaluates multiple columns at once.</p>
","2023-02-17 14:06:19","0","Answer"
"75485068","75484347","","<p>The length(number of samples) in your truth labels doesn't match with the number of samples in your predicted labels.<br />
Check the length of your <strong>Y_test</strong> and <strong>logreg_main_test</strong>, it should match if not then either your split is incorrect or you are trying to predict with the train split instead of test split.</p>
","2023-02-17 13:43:45","0","Answer"
"75484347","","Evaluating test dataset","<p>For most competitions, the data is split into a training data and test data. I worked on the training data(spliting it into x_train...) and created a model, i evaluated it and got the respective accuracy score. I used the same model to predict the test dataset that was left out, however, when i tried to evaluate the models performance, i kept getting this error below:
Could anyone explain what am doing wrong? and give ways to remedy it.</p>
<p>The Code:</p>
<pre><code># logistic regression

logreg_main_test = logreg.predict(main_test_scaled) # predict

# evaluate
logreg_score_main_test = accuracy_score(Y_test, logreg_main_test)
f1_val_main_test = f1_score(Y_test, logreg_score_main_test)
recall_val_main_test = recall_score(Y_test, logreg_score_main_test)

# display result
print('Model accuracy:',logreg_score_main_test)
</code></pre>
<p>The output error</p>
<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-51-8265b6fa0a29&gt; in &lt;module&gt;
      4 
      5 # evaluate
----&gt; 6 logreg_score_main_test = accuracy_score(Y_test, logreg_main_test)
      7 f1_val_main_test = f1_score(Y_test, logreg_score_main_test)
      8 recall_val_main_test = recall_score(Y_test, logreg_score_main_test)

2 frames
/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py in check_consistent_length(*arrays)
    330     uniques = np.unique(lengths)
    331     if len(uniques) &gt; 1:
--&gt; 332         raise ValueError(
    333             &quot;Found input variables with inconsistent numbers of samples: %r&quot;
    334             % [int(l) for l in lengths]

ValueError: Found input variables with inconsistent numbers of samples: [4705, 10086]
</code></pre>
","2023-02-17 12:32:52","0","Question"
"75482011","75472472","","<p>When calling the attribute feature_importances_ on an sklearn estimator, you notice that the sum of all makes 100%.</p>
<p>Therefore I would say it makes sense to sum the importance when you regroup features together:</p>
<p>feature_importance(featureA &amp; featureB) = feature_importance(featureA) + feature_importance(featureB)</p>
","2023-02-17 08:47:19","3","Answer"
"75478362","75414991","","<p>This is likely because the notebook instance doesn't have the NeptuneML IAM role parameter set as an environment variable.</p>
<p>Try running <code>export NEPTUNE_ML_ROLE_ARN=&lt;your neptune ml role arn&gt;</code> in the terminal of the notebook instance you're using. Alternatively you can add that  to the .bashrc file on the notebook instance.</p>
","2023-02-16 22:04:31","0","Answer"
"75478202","75420887","","<p>The following code is working for me:</p>
<pre><code>def to_float(inps: str):
    ret = []
    for inp in inps:
        # Removing square braces
        inp = inp[1:-1]
        # Split using comma
        inp = inp.split(',')
        # Convert each string to float
        ret.append(list(map(float, inp)))   
    return ret
</code></pre>
","2023-02-16 21:39:20","0","Answer"
"75477152","75476903","","<p>Have you tried using different train/val splits? It could be something specific to the split you happen to have selected.</p>
","2023-02-16 19:40:05","0","Answer"
"75477109","75476903","","<p>Here is one source related to your problems (<a href=""https://github.com/christianversloot/machine-learning-articles/blob/main/getting-out-of-loss-plateaus-by-adjusting-learning-rates.md"" rel=""nofollow noreferrer"">https://github.com/christianversloot/machine-learning-articles/blob/main/getting-out-of-loss-plateaus-by-adjusting-learning-rates.md</a>). Have a look! May give you some ideas.</p>
","2023-02-16 19:35:51","0","Answer"
"75476903","","Training process stuck in a local minimum for neural network","<p>I'm working on a neural network that's designed to identify patterns in a large dataset, but I'm running into an issue where the training process seems to be stuck in a local minimum. Despite trying a variety of different optimization algorithms and adjusting the learning rate, I can't seem to get the network to converge on a more optimal solution. Here's the code I'm using to train the network:</p>
<pre><code>import numpy as np
import tensorflow as tf

# Load dataset
data = np.load('data.npy')

# Split dataset into training and validation sets
train_data = data[:5000]
val_data = data[5000:]

# Define neural network architecture
model = tf.keras.models.Sequential([
  tf.keras.layers.Dense(512, activation='relu', input_shape=(data.shape[1],)),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train model
history = model.fit(train_data[:, :-1], train_data[:, -1],
                    validation_data=(val_data[:, :-1], val_data[:, -1]),
                    batch_size=32,
                    epochs=100,
                    verbose=1)

</code></pre>
<p>I suspect that there might be an issue with the dataset itself, but I've tried normalizing and standardizing the data, as well as applying various preprocessing techniques, with no luck. Any insights or suggestions would be helpful.</p>
","2023-02-16 19:10:35","0","Question"
"75476211","","Imputation after one hot encoding in scikit-learn","<p>I have a dataset where I have categorical and numerical data. I want to -</p>
<ol>
<li>Apply OneHot encoding for all categorical columns</li>
<li>Use the numerical data + one-hot encoded categorical data to do <code>Multiple Imputation</code> using IterativeImputer.</li>
<li>Integrate it to a pipeline where I have access to <code>fit</code> and <code>transform</code> methods.</li>
</ol>
<p>I can use <code>ColumnTransformer</code> to impute using only numerical columns but I want to use the categorical column too for the imputation.</p>
<p>E.g.</p>
<pre class=""lang-py prettyprint-override""><code>sample_data = pd.DataFrame({
    &quot;a&quot;: [4.4, 1.0, None, 3.0, 2.7],
    &quot;b&quot;: [&quot;HIGH&quot;, &quot;HIGH&quot;, &quot;LOW&quot;, &quot;HIGH&quot;, &quot;LOW&quot;],
    &quot;c&quot;: [True, False, False, True, False]
})
</code></pre>
<p>I want to first encoded columns <code>b,c</code> and then use them along with <code>a</code> to impute the missing value in column <code>a</code>.</p>
<p>Also, I do not have any missing values in the categorical columns.</p>
","2023-02-16 17:57:09","0","Question"
"75472472","","Feature Importances for categorical features after one hot encoding?","<p>We need to encode a categorical feature with multiple categories, the resulting one-hot encoded feature will have importance scores separately for each category. If we want to combine these importances into a single feature importance for the original categorical feature, can we simply add the importances for each one hot encoded feature.</p>
<p>For example, let's say we one hot encode a categorical feature called Department.</p>
<p>Resulting values</p>
<p>Department_0 : 0.03
Department_1 : 0.08
Department_2: 0.12</p>
<p>To combine these into a single feature importance for ‘Department’, can we sum up the values ?</p>
<p>Department : 0.03 + 0.08 + 0.12= 0.23.</p>
<p>Is there any drawback in this approach ? If yes, then what is the best approach ?</p>
","2023-02-16 12:44:05","2","Question"
"75468342","75448991","","<p>Can you try?</p>
<pre><code>public static byte[] ImageToByte(Image image)
{
    using (var stream = new MemoryStream())
    {
        image.Save(stream, System.Drawing.Imaging.ImageFormat.Png);
        return stream.ToArray();
    }
}
</code></pre>
<p>Or</p>
<pre><code>Image image = Image.FromFile(imagePath);

byte[] byteArr = new byte[] { };

using (var ms = new MemoryStream())
{
    image.Save(ms, image.RawFormat);
    byteArr = ms.ToArray();
}
</code></pre>
<p>For Image you will need System.Drawing</p>
","2023-02-16 05:53:28","0","Answer"
"75464192","75224346","","<p>This value of visualizing <code>5-keywords</code> is hard-coded. So, you won't be able to pass as parameter. Check out the code here: <a href=""https://github.com/MaartenGr/BERTopic/blob/1ee8141d65063a37f6ee3fd56b30e3f9e2f43d6e/bertopic/plotting/_topics.py#L66"" rel=""nofollow noreferrer"">https://github.com/MaartenGr/BERTopic/blob/1ee8141d65063a37f6ee3fd56b30e3f9e2f43d6e/bertopic/plotting/_topics.py#L66</a></p>
<p><a href=""https://i.sstatic.net/ktn1w.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/ktn1w.png"" alt=""top-5 words BERTopic visualization"" /></a></p>
<p>If you really want to hack this, you can fork a repository and change the value or pass as parameter for your use. The file tree from original source is something like below:</p>
<pre><code>BERTopic v0.14.0
BERTopic/bertopic/plotting/_topics.py (Line #66)
</code></pre>
","2023-02-15 18:45:19","0","Answer"
"75464126","","How to identify relevant columns in very wide tables using AI and Machine Learning?","<p>I have a complex data model consisting of around hundred tables containing business data. Some tables are very wide, up to four hundred columns. Columns can have various data types - integers, decimals, text, dates etc. I'm looking for a way to identify relevant / important information stored in these tables.</p>
<p>I fully understand that business knowledge is essential to correctly process a data model. What I'm looking for are some strategies to pre-process tables and identify columns that should be taken to later stage where analysts will actually look into it. For example, I could use data profiling and statistics to find and exclude columns that don't have any data at all. Or maybe all records have the same value. This way I could potentially eliminate 30% of fields. However, I'm interested in exploring how AI and Machine Learning techniques could be used to identify important columns, hoping I could identify around 80% of relevant data. I'm aware, that relevant information will depend on the questions I want to ask. But even then, I hope I could narrow the columns to simplify the manual assesment taking place in the next stage.</p>
<p><strong>Could anyone provide some guidance on how to use AI and Machine Learning to identify relevant columns in such wide tables?</strong> What strategies and techniques can be used to pre-process tables and identify columns that should be taken to the next stage?</p>
<p>Any help or guidance would be greatly appreciated. Thank you.</p>
<p>F.</p>
","2023-02-15 18:38:07","-1","Question"
"75448991","","Convert HImage to byte[] as File.ReadAllBytes() does with .png","<pre class=""lang-cs prettyprint-override""><code>HalconDotNet.HOperatorSet.ReadImage(out HObject image, srcPath);
//...
//(graphic stuff)
//...
HalconDotNet.HOperatorSet.WriteImage(imagePart, &quot;png&quot;, 0, tmpImgPath); // skip these steps
Image = File.ReadAllBytes(path)                                        // skip these steps
</code></pre>
<p>This piece of code is executed thousands of times. The last two steps are just there to have a compatibility step in between Halcon and .NET as I dont know how to combine them.</p>
<p>What I need is a way to convert a <code>HImage(HObject)</code> to a <code>byte[]</code>, the same way <code>WriteImage()</code> + <code>File.ReadAllBytes(path)</code> would do. This last bit is important as this piece of code generates inputs for image classification models.</p>
<p>As the models are trained with data loaded from disk with <code>File.ReadAllBytes(path)</code> I'm assuming I need to prepare the data in the same way when using the model. When I read a 100x100 color PNG (solid color) with <code>File.ReadAllBytes()</code> I don't get 100x100x3 bytes, but 342, so I'm assuming the data is still compressed, and further assuming that I need to guarantee similar data when using the model.</p>
<p>This question has some overlap with <a href=""https://stackoverflow.com/questions/51282049/convert-grayscale-himage-mvtec-halcon-library-to-c-sharp-bitmap"">this one</a> but I need a byte[] instead of bitmap and just can't get it to work.</p>
","2023-02-14 14:06:47","0","Question"
"75448148","75447792","","<p>EDIT:</p>
<p>Since then I found a pythonic way for the ranges, without the list comprehension! For this your ends should be bigger by one, as this method will take python ranges, wich does not contain the end of the range.</p>
<pre><code>indices=torch.stack((starts,ends),axis=1)
newtensor=torch.stack([data[slice(idx[0], idx[1])] for idx in indices])
</code></pre>
<p>OLD ANSWER:</p>
<p>You can do this with torch.take. To get your desired output, you need to subtract 1 from your ends indices, as it takes exact indices, not intervals. (Alternatively you can generate ends like that in the first place)</p>
<pre><code>indices=torch.stack((starts,ends-1),axis=1)
newtensor=torch.take(data,indices)
</code></pre>
<hr />
<pre><code>tensor([[0, 1],
        [3, 4],
        [4, 5],
        [1, 2]])
</code></pre>
<p>If you would want to take real intervals
(based on the fact that you named the indices starts and ends), this would be a solution for that:</p>
<pre><code>indices=torch.stack((starts,ends),axis=1)
rangeindices=[torch.range(i[0],i[1]) for i in indices]
tensorindices=torch.stack(rangeindices).type(torch.LongTensor)
newtensor=torch.take(data,tensorindices)
</code></pre>
<hr />
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [4, 5, 6],
        [1, 2, 3]])
</code></pre>
<p>But this would (understandably) result in a different tensor than your expected output.</p>
","2023-02-14 12:55:28","0","Answer"
"75447988","75447792","","<p>If it were a list, <code>zip</code> would solve your problem</p>
<p>Looks like you need:
<a href=""https://pytorch.org/docs/stable/generated/torch.transpose.html"" rel=""nofollow noreferrer"">torch.transpose()</a>.</p>
<p>And use the solution from this answer by @bachr:
<a href=""https://stackoverflow.com/a/60367265/3456886"">https://stackoverflow.com/a/60367265/3456886</a></p>
","2023-02-14 12:40:45","0","Answer"
"75447792","","Slice 1D tensor in PyTorch with tensors of start and end indexes","<p>I am trying to create a 2D tensor of even slices from a 1D tensor in PyTorch. Say we have a 1D data tensor and tensors of indexes as:</p>
<pre><code>&gt;&gt;&gt; data = torch.arange(10)
&gt;&gt;&gt; data
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
&gt;&gt;&gt; starts = torch.tensor([0, 3, 4, 1])
&gt;&gt;&gt; ends = starts + 2
&gt;&gt;&gt; starts
tensor([0, 3, 4, 1])
&gt;&gt;&gt; ends
tensor([2, 5, 6, 3])
</code></pre>
<p>How could I index the <code>data</code> tensor without looping over and slicing with each set of indexes to achieve a result as:</p>
<pre><code>
&gt;&gt;&gt; dataSlices
tensor([[0, 1],
        [3, 4],
        [4, 5],
        [1, 2]])
</code></pre>
<p>My first obvious thought is to just put the <code>starts</code> and <code>ends</code> as you would with individual indexes but it just errors out:</p>
<pre><code>&gt;&gt;&gt; data[starts:ends]
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
TypeError: only integer tensors of a single element can be converted to an index
</code></pre>
<p>I've looked through some parts of the documentation but can't seem to find a way, am I missing something obvious?</p>
","2023-02-14 12:24:44","0","Question"
"75436416","75194136","","<p>I ran into the same issue and I solved it by explicitly passing a dataframe in your last method.</p>
<p>So this:</p>
<pre><code>xgb_model.predict([[47.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   2.,  49.,   2.,  55.,   0.,   0.,
          0.,   1.]])
</code></pre>
<p>Became this:</p>
<pre><code>import pandas as pd

row_to_predict = [47.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
              0.,   0.,   0.,   0.,   0.,   2.,  49.,   2.,  55.,   0.,   0.,
              0.,   1.] 
df = pd.DataFrame(row_to_predict , columns = xgb_model.feature_names_in_)
xgb_model.predict(df)
</code></pre>
","2023-02-13 13:19:45","0","Answer"
"75433441","75387197","","<p>Using python 3.6 with <code>conda install -c conda-forge opencv=3.2.0</code> as described here <a href=""https://stackoverflow.com/questions/44668602/opencv-python-importerror-dll-load-failed-the-specified-module-could-not-be-fo?rq=1"">OpenCV-Python ImportError: DLL load failed: The specified module could not be found</a> solved the issue on my laptop with an RTX A1000. Weird opencv works with python 3.10 on my desktop with an GTX 1070</p>
","2023-02-13 08:26:46","0","Answer"
"75432401","75432346","","<p>Yes, there are ways to normalize data to the range between -1 and 1. One common method is called Min-Max normalization. It works by transforming the data to a new range, such that the minimum value is mapped to -1 and the maximum value is mapped to 1. The formula for this normalization is:</p>
<p>x_norm = (x - x_min) / (x_max - x_min) * 2 - 1</p>
<p>Where x_norm is the normalized value, x is the original value, x_min is the minimum value in the data and x_max is the maximum value in the data.</p>
<p>Another method for normalizing data to the range between -1 and 1 is called Z-score normalization, also known as standard score normalization. This method normalizes the data by subtracting the mean and dividing by the standard deviation. The formula for this normalization is:</p>
<p>x_norm = (x - mean) / standard deviation</p>
<p>Where x_norm is the normalized value, x is the original value, mean is the mean of the data and standard deviation is the standard deviation of the data.</p>
","2023-02-13 06:14:13","0","Answer"
"75432397","75432346","","<p>You can use the <code>min-max scalar</code> or the <code>z-score normalization</code> here is what u can do in sklearn</p>
<p><code>from sklearn.preprocessing import MinMaxScaler</code></p>
<p><code>from sklearn.preprocessing import StandardScaler</code></p>
<p>or hard code it like this</p>
<p><code>x_scaled = (x - min(x)) / (max(x) - min(x)) * 2 - 1</code> -&gt; this one for minmaxscaler</p>
<p><code>x_scaled = (x - mean(x)) / std(x)</code> -&gt; this one for standardscaler</p>
","2023-02-13 06:14:01","1","Answer"
"75432374","75432346","","<p>Consider re-scale the normalized value. e.g. normalize to 0..1, then multiply by 2 and minus 1 to have the value fall into the range of -1..1</p>
","2023-02-13 06:10:43","2","Answer"
"75432366","75432346","","<p>You can use <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler"" rel=""nofollow noreferrer""><code>MinMaxScaler</code></a> from <code>sklearn</code> and specify the range:</p>
<pre><code>from sklearn.preprocessing import MinMaxScaler
import pandas as pd
import numpy as np

scaler = MinMaxScaler(feature_range=(-1, 1))

df = pd.DataFrame({'val': np.random.random(10)})
df['std'] = scaler.fit_transform(df[['val']])
</code></pre>
<p>Output:</p>
<pre><code>&gt;&gt;&gt; df
        val       std
0  0.630673 -0.080580
1  0.842867  0.563090
2  0.662732  0.016669
3  0.433478 -0.678750
4  0.778883  0.369001
5  0.327573 -1.000000  # MIN
6  0.512345 -0.439515
7  0.563789 -0.283465
8  0.986901  1.000000  # MAX
9  0.775790  0.359619
</code></pre>
","2023-02-13 06:09:23","0","Answer"
"75432346","","Normalize -1 ~ 1","<p>there are many ways about normalize skils for ml and dl. It is known to provide only normalization for 0 to 1.
I want to know that is some ways to normalize -1 between 1.</p>
","2023-02-13 06:04:15","1","Question"
"75431641","75356723","","<p>Let suppose I have created the same dataset as yours,</p>
<pre><code>x = tf.random.normal((7000, 900,1))
y = tf.random.normal((7000, 900,1))
z = tf.random.uniform((7000, 1,1), 1, 2, dtype=tf.int32)

#Now converting it to Tf.Dataset object
dataset = tf.data.Dataset.from_tensor_slices(((x,y),z))

func = lambda x , y : (({'input_A' : x[0], 'input_B' : x[1]}), y)
dataset = dataset.map(func)
</code></pre>
<p>After mapping my <code>dataset</code> will look exactly like yours</p>
<pre><code>&lt;MapDataset element_spec=({'input_A': TensorSpec(shape=(900, 1), dtype=tf.float32, name=None), 'input_B': TensorSpec(shape=(900, 1), dtype=tf.float32, name=None)}, TensorSpec(shape=(1, 1), dtype=tf.int32, name=None))&gt;
</code></pre>
<p>Now, I have to remove this last <code>Tensor</code></p>
<pre><code>disjoint_func = lambda x , y :(x)
dataset = dataset.map(disjoint_func)
</code></pre>
<p>Now, the <code>extra Tensor</code> has been removed</p>
<pre><code>&lt;MapDataset element_spec={'input_A': TensorSpec(shape=(900, 1), dtype=tf.float32, name=None), 'input_B': TensorSpec(shape=(900, 1), dtype=tf.float32, name=None)}&gt;
</code></pre>
","2023-02-13 03:16:54","1","Answer"
"75422680","75356723","","<p>I can't tell you where the added tensor comes from but here would be an example how to remove/drop it from your dataset:</p>
<pre><code>import tensorflow as tf
import numpy as np
# creating a sample dataset that's similar to your 'wrong' output
ds = tf.data.Dataset.from_tensor_slices((np.arange(-10, 0),(tf.constant(np.arange(10)), tf.constant(np.arange(10,20)))))
# remove the new 'wrong' tensor
dds = ds.map(lambda x, y: y)
# check new dataset
for i in dds.take(2):
    print(i)
</code></pre>
<p>Keep in mind that this is a workaround and doesn't remove the source that causes the additional tensor</p>
","2023-02-11 19:09:21","1","Answer"
"75421115","75420887","","<p>This will convert your Series of lists into a DataFrame with one float per cell:</p>
<pre><code>pd.DataFrame(df['thermal'].tolist())
</code></pre>
","2023-02-11 15:12:38","1","Answer"
"75420887","","How to convert string array data type to float array data type?","<p>I am working on thermal sensor data. The first three data are as follows. Data is in an array of strings. Please find the data link here drive.google.com/file/d/1EfJOFszf7z1aOosc-PbKSsYcEE8ePjLk/…. Thank you so much for helping.</p>
<pre><code>[25.64177131652832, 25.456825256347656, 24.92892074584961, 24.316755294799805, 23.454368591308594, 22.40850067138672, 21.829116821289062, 21.764848709106445, 21.72584342956543, 24.04592514038086, 24.358749389648438, 24.438608169555664, 24.78814697265625, 24.301586151123047, 24.657527923583984, 24.677270889282227, 24.422500610351562, 24.059892654418945, 23.85132598876953]

[23.502470016479492, 23.628114700317383, 23.68063735961914, 23.141122817993164, 22.970962524414062, 22.815067291259766, 22.713998794555664, 22.732934951782227, 22.681840896606445, 23.653491973876953, 23.332386016845703, 23.260208129882812, 23.49359703063965, 23.29375648498535, 23.734455108642578, 23.88347053527832, 23.9250431060791, 23.524120330810547, 23.196813583374023]

[23.735689163208008, 23.837121963500977, 24.044170379638672, 23.415151596069336, 21.520160675048828, 20.2335205078125, 19.441017150878906, 19.177982330322266, 18.871313095092773, 23.82925796508789, 24.192703247070312, 23.958843231201172, 23.816261291503906, 23.37897300720215, 23.469127655029297, 23.600635528564453, 23.589786529541016, 23.144105911254883, 22.776491165161133]
</code></pre>
<p>How can I convert this data to float-type data for machine learning models? Thank you.</p>
<p>I tried the following:</p>
<pre><code>df[&quot;thermal2&quot;] = pd.to_numeric(df[&quot;thermal&quot;],errors=&quot;coerce&quot;)

0    NaN
1    NaN
2    NaN
     ..
83   NaN
84   NaN

Name: thermal2, Length: 85, dtype: float64
</code></pre>
","2023-02-11 14:33:59","0","Question"
"75419951","75419766","","<p>The problem here is that the <code>to_categorical</code> function creates a one hot encoding of integers 0 to n, not of arbitrary labels.</p>
<p>What you are looking for is probably:</p>
<pre class=""lang-py prettyprint-override""><code>Y_TRAIN = [-1, 1, 1, -1]
one_hot = np.unique(Y_TRAIN, return_inverse=True)[1]
# array([0, 1, 1, 0])
</code></pre>
","2023-02-11 11:42:36","0","Answer"
"75419870","75419766","","<p>You can probably convert the zeros to -1 like this:</p>
<pre><code>Y_TRAIN_One_hot[Y_TRAIN_One_hot == 0] = -1
</code></pre>
","2023-02-11 11:29:57","0","Answer"
"75419766","","One Hot encoding for [-1,1] labels","<p>I have binary labels for a classification problem as -1 and 1. How can I perform one hot encoding for this?</p>
<p>Used following but it only returns [0,1] always.</p>
<p><code>Y_TRAIN_One_hot = keras.utils.np_utils.to_categorical(Y_TRAIN, 2)</code></p>
","2023-02-11 11:11:52","0","Question"
"75416466","75414991","","<p>Your Neptune cluster should have a cluster parameter group assigned to it that has the <code>neptune_ml_iam_role</code> parameter defined.  It is this role that is being used.</p>
","2023-02-10 21:54:36","0","Answer"
"75414991","","ERROR:root:Unable to determine the Neptune ML IAM Role","<p>When trying to run one of the Neptune-ML examples in a notebook instance
when running the line</p>
<pre><code>endpoints=neptune_ml.setup_pretrained_endpoints(s3_bucket_uri, setup_node_classification, setup_node_regression, setup_link_prediction, setup_edge_classification, setup_edge_regression)
</code></pre>
<p>it returns None, and I can see the following error in the logs:</p>
<blockquote>
<p>ERROR:root:Unable to determine the Neptune ML IAM Role.</p>
</blockquote>
<p>I guess this is related to roles and permissions but I cannot find anything in the documentation(I followed the official documentation when doing setup).</p>
<p>Question is: how to solve this issue or how to debug it?</p>
","2023-02-10 18:43:57","0","Question"
"75413681","75411671","","<p>Thank you for your question.</p>
<p>Can you access the stored categorical values here?</p>
<p><a href=""https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/algos/tree/SharedTreeMojoModel.java#L72"" rel=""nofollow noreferrer"">https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/algos/tree/SharedTreeMojoModel.java#L72</a></p>
<p><a href=""https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/algos/tree/SharedTreeMojoReader.java#L34"" rel=""nofollow noreferrer"">https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/algos/tree/SharedTreeMojoReader.java#L34</a></p>
<p><a href=""https://github.com/h2oai/h2o-3/blob/master/h2o-algos/src/main/java/hex/tree/SharedTreeMojoWriter.java#L61"" rel=""nofollow noreferrer"">https://github.com/h2oai/h2o-3/blob/master/h2o-algos/src/main/java/hex/tree/SharedTreeMojoWriter.java#L61</a></p>
<p>The index in the array means the translated categorical value.</p>
<p>The EasyPredictModelWrapper did it this way:</p>
<p><a href=""https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/easy/RowToRawDataConverter.java#L44"" rel=""nofollow noreferrer"">https://github.com/h2oai/h2o-3/blob/master/h2o-genmodel/src/main/java/hex/genmodel/easy/RowToRawDataConverter.java#L44</a></p>
","2023-02-10 16:24:10","0","Answer"
"75411671","","Categorical features encoding in H2O","<p>I train GBM models with H2O and want to use them in my backend (not Java). To do so, I download the MOJOs, convert it to ONNX and run it in my apps.</p>
<p>In order to make inference, I need to know how categorical columns transformed to their one-hot encoded versions. I was able to find it in the POJO:</p>
<pre class=""lang-java prettyprint-override""><code>    static final void fill(String[] sa) {
      sa[0] = &quot;Age&quot;;
      sa[1] = &quot;Fare&quot;;
      sa[2] = &quot;Pclass.1&quot;;
      sa[3] = &quot;Pclass.2&quot;;
      sa[4] = &quot;Pclass.3&quot;;
      sa[5] = &quot;Pclass.missing(NA)&quot;;
      sa[6] = &quot;Sex.female&quot;;
      sa[7] = &quot;Sex.male&quot;;
      sa[8] = &quot;Sex.missing(NA)&quot;;
    }
</code></pre>
<p>So, here is the workflow for non-Java backend as I see it:</p>
<ol>
<li>Encode categorical features with <code>OneHotExplicit</code>.</li>
<li>Train GBM model.</li>
<li>Download MOJO and convert to ONNX.</li>
<li>Download POJO and find feature alignment in the source code.</li>
<li>Implement the inference in your backend.</li>
</ol>
<p>Is it the most straightforward and correct way?</p>
","2023-02-10 13:17:07","0","Question"
"75401323","75094244","","<p>In my case reinstalling sharp didn't help.</p>
<p>The problem is most likely caused by a bug in Numba library. More details: <a href=""https://github.com/numba/numba/issues/8718"" rel=""nofollow noreferrer"">https://github.com/numba/numba/issues/8718</a> and <a href=""https://github.com/numba/numba/issues/8615"" rel=""nofollow noreferrer"">https://github.com/numba/numba/issues/8615</a></p>
<p>It should be fixed in a next release (<code>0.57</code>).</p>
<p>EDIT:
When I reinstalled <code>numba</code> (<code>pip uninstall numba ; pip install numba</code>) the problem has disappeared. I think it might be related to updated packages in my system.</p>
","2023-02-09 16:09:00","2","Answer"
"75398605","75102134","","<p>I converted the input to np.float32 which solved a similar problem for me</p>
","2023-02-09 12:27:52","5","Answer"
"75397378","75396744","","<p>PCA finds the axis of the data with the greatest variance. For this all the inputs must be numerical.</p>
<p>You could take the length of the text string, that would provide a number, but it is unlikely that will provide any useful information. Ultimately, it is up to you to decide what you want from the data and that will inform how to change this. If your text field is categorical one way is to can create dummy variables that split a categorical variable into multiple binary variables. You can do this in Pandas with the get_dummies method.</p>
<p>In my opinion, a better question to ask is why you want to reduce your feature set and if the text is even relevant to your analysis.</p>
","2023-02-09 10:37:53","0","Answer"
"75396840","75396744","","<p>For the text, you can build vectors from text.
List of vectorizers in scikit-learn that work on text can be found here - <a href=""https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text"" rel=""nofollow noreferrer"">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text</a>.</p>
","2023-02-09 09:49:47","0","Answer"
"75396744","","PCA on text data in Python","<p>I want to use <a href=""https://en.wikipedia.org/wiki/Principal_component_analysis"" rel=""nofollow noreferrer"">PCA</a> to reduce our features (columns) in a dataset, but one of the features is a text feature.</p>
<p>For this, our solution was convert text features to numeric, how can we do this?</p>
<p>Or is there another solution to use PCA on text features?</p>
<p>For example, this dataframe:</p>
<p><a href=""https://i.sstatic.net/FFWGM.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/FFWGM.png"" alt=""Enter image description here"" /></a></p>
","2023-02-09 09:41:27","-1","Question"
"75388466","75387197","","<p>This happened to me just this morning, and I fixed it by installing opencv using pip. First, I removed conda's opencv installation. In the environment where it is installed type</p>
<p><code>conda remove opencv</code></p>
<p>Once it is removed, type</p>
<p><code>pip install opencv-python</code></p>
<p>Hope it helps</p>
","2023-02-08 16:00:26","4","Answer"
"75387197","","anaconda ImportError: DLL load failed while importing cv2: The specified module could not be found","<p>I am trying to install opencv on my laptop but I keep getting <code>ImportError: DLL load failed while importing cv2: The specified module could not be found.</code><br />
I tried installing installing with <code>conda install -c conda-forge opencv</code> in an anaconda env.<br />
But I also get the same result if I use my normal python 3.10 interpreter with <code>opencv-python</code> and <code>opencv-contrib-python</code>.<br />
I also tried to compile the module myself but <code>cv2.cp310-win_amd64</code> gives me the same error as well...</p>
<p>Isnt there just an prebuild binary I can use? or should I look for an different ML module?</p>
<p>Yesterday when I came home I tried installing <code>opencv-python</code> on my personal computer. And it worked instantly. I have an GTX 1070 in that pc and an RTX A1000 in the work laptop I need opencv on. So I tought that the cuda cores might not be supported or something.<br />
I found this tutorial <a href=""https://machinelearningprojects.net/build-opencv-with-cuda-and-cudnn/"" rel=""nofollow noreferrer"">https://machinelearningprojects.net/build-opencv-with-cuda-and-cudnn/</a><br />
But after installing the Nvidia SDK, cudnn and compiling opencv from source I still get the same error.<br />
Even with appending the opencv output folder and the cuda sdk bin folder to python's dll_path.</p>
<p>Disabling <code>BUILD_SHARED_LIBS</code> as suggested in here also does nothing....<br />
<a href=""https://forum.opencv.org/t/opencv-w-cuda-build-seems-successful-but-import-cv2-fails/11328/3"" rel=""nofollow noreferrer"">https://forum.opencv.org/t/opencv-w-cuda-build-seems-successful-but-import-cv2-fails/11328/3</a></p>
","2023-02-08 14:25:56","2","Question"
"75378918","75375480","","<p>Finally I figured it out. The <code>ml5.objectDetector('cocossd');</code> function must be marked as await because it takes quite long time to execute. Below is working code:</p>
<pre><code>import { Component, OnInit } from '@angular/core';

import * as p5 from 'p5';

declare let ml5: any;

@Component({
  selector: 'app-new-found',
  templateUrl: './new-found.component.html',
  styleUrls: ['./new-found.component.scss']
})
export class NewFoundComponent implements OnInit {

  objectDetector;
  img;

  constructor(
  ) { }

  async ngOnInit(): Promise&lt;void&gt; {
    this.objectDetector = await ml5.objectDetector('cocossd');

    const sketch = (s) =&gt; {

      s.preload = () =&gt; {
        console.log(ml5);   
        console.log('detector object is loaded', this.objectDetector);
        this.img = s.loadImage('https://i.imgur.com/Mzh4cHR.jpg');
      }

      s.setup = () =&gt; {
        s.createCanvas(700, 700).parent('test-canvas');
        this.objectDetector.detect(this.img, this.gotResult);
        s.image(this.img, 0, 0);
      };

      s.draw = () =&gt; {

      };
    }

    let canvas = new p5(sketch);  
  }

  gotResult(error, results) {

    if (error) {
        console.error(error);
    } else {
        console.log(results);

        //drawResults(results);

    }
}

}
</code></pre>
","2023-02-07 20:59:32","2","Answer"
"75376624","75375480","","<p>It is possible that the library has not fully loaded yet. I would create a polling technique here where you keep checking if the value has been initialized and only then proceed.</p>
<p>This is the code I use for polling that <code>xola</code> script has loaded:</p>
<pre><code>let subscription = interval(1000)
        .pipe(timeout(3 * 60 * 1000))
        .subscribe({
            next: () =&gt; {
                if (this.window.xola) {
                    const xola = this.window.xola();
                    subscription.unsubscribe();
                    this.xolaSubject.next(xola);
                }
            },
            error: (error) =&gt; {
                if (error instanceof TimeoutError) {
                    console.error('Xola took too long to load, check your connection.');
                }
                subscription.unsubscribe();
            },
        });
</code></pre>
","2023-02-07 16:58:28","0","Answer"
"75375480","","ML5.JS objectDetector.detect is not a function","<p>I'm quite new to ml5 and p5 libraries and during implementation to my Angular project I'm receiving this error:</p>
<pre><code>TypeError: this.objectDetector.detect is not a function
</code></pre>
<p>After logging objectDetector object console shows this:</p>
<pre><code>ZoneAwarePromise {__zone_symbol__state: null, __zone_symbol__value: Array(0)}
</code></pre>
<p>p5 drawing working good but combined with ml5 is not working.</p>
<p>Here's my component code:</p>
<pre><code>import { Component, OnInit } from '@angular/core';

import * as p5 from 'p5';

declare let ml5: any;

@Component({
  selector: 'app-new-found',
  templateUrl: './new-found.component.html',
  styleUrls: ['./new-found.component.scss']
})
export class NewFoundComponent implements OnInit {

  objectDetector;
  img;

  constructor(
  ) { }

  ngOnInit(): void {
    const sketch = (s) =&gt; {

      s.preload = () =&gt; {
        this.objectDetector = ml5.objectDetector('cocossd');
        console.log('detector object is loaded', this.objectDetector);
        this.img = s.loadImage('https://i.imgur.com/Mzh4cHR.jpg');
      }

      s.setup = () =&gt; {
        s.createCanvas(700, 700).parent('test-canvas');
        this.objectDetector.detect(this.img, this.gotResult);
        s.image(this.img, 0, 0);
      };

      s.draw = () =&gt; {

      };
    }

    let canvas = new p5(sketch);  
  }

  gotResult(error, results) {

    if (error) {
        console.error(error);
    } else {
        console.log(results);

        //drawResults(results);

    }
}

}
</code></pre>
<p>ml5 library is imported in <code>&lt;HEAD&gt;</code> of my <code>index.html</code> file.</p>
<p>Does someone know how to get rid of this error?</p>
<p>Thank you.</p>
","2023-02-07 15:24:40","1","Question"
"75371176","","module 'numpy' has no attribute 'MachAr'?","<p>I have a question. When I import 'variance_inflation_factor ' from 'statsmodels.stats.outliers_influence', I get ' module 'numpy' has no attribute 'MachAr'' error, what is the reason?</p>
<p>I once executed this code in a project and it worked without any problems, but it gives this error for subsequent projects</p>
","2023-02-07 09:17:47","10","Question"
"75360117","75360007","","<p>You can use <strong>get_dummies</strong> function of pandas for convert row to column based on data.</p>
<p>For that your code will be:</p>
<pre><code>import pandas as pd

df = pd.DataFrame({
    'month': [1, 1, 2, 2, 1],
    'day': [7, 2, 1, 2, 2],
    'week_day': [2, 6, 5, 6, 6],
    'classname_en': [1, 2, 1, 4, 5],
    'origin': [2, 1, 2, 1, 6],
    'destination': [5, 167, 54, 6, 1]
})

response = pd.get_dummies(df, columns=df.columns)
print(response)
</code></pre>
<p><strong>Result :</strong>
<a href=""https://i.sstatic.net/pA8fQ.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/pA8fQ.png"" alt=""enter image description here"" /></a></p>
","2023-02-06 10:31:50","1","Answer"
"75360098","75360007","","<p>To expand @Corraliens answer</p>
<p>It is indeed a way to do it, but since you write for ML purposes, you might introduce a bug.
With the code above you get a matrix with 20 features. Now, say you want to predict on some data which suddenly have a month more than your training data, then your matrix on your prediction data would have 21 features, thus you cannot parse that into your fitted model.</p>
<p>To overcome this you can use <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"" rel=""nofollow noreferrer"">one-hot-encoding</a> from Sklearn. It'll make sure that you always have the same amount of features on &quot;new data&quot; as your training data.</p>
<pre class=""lang-py prettyprint-override""><code>import pandas as pd

df_train = pd.DataFrame({&quot;color&quot;:[&quot;red&quot;,&quot;blue&quot;],&quot;age&quot;:[10,15]})
pd.get_dummies(df_train)

# output
   age  color_blue  color_red
0   10           0          1
1   15           1          0


df_new = pd.DataFrame({&quot;color&quot;:[&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;],&quot;age&quot;:[10,15,20]})
pd.get_dummies(df_new)

#output

   age  color_blue  color_green  color_red
0   10           0            0          1
1   15           1            0          0
2   20           0            1          0
</code></pre>
<p>and as you can see, the order of the color-binary representation has also changed.</p>
<p>If we on the other hand use <code>OneHotEncoder</code> you can ommit all those issues</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.preprocessing import OneHotEncoder

df_train = pd.DataFrame({&quot;color&quot;:[&quot;red&quot;,&quot;blue&quot;],&quot;age&quot;:[10,15]})
ohe = OneHotEncoder(handle_unknown=&quot;ignore&quot;) 

color_ohe_transformed= ohe.fit_transform(df_train[[&quot;color&quot;]]) #creates sparse matrix

ohe_features = ohe.get_feature_names_out() # [color_blue, color_red]

pd.DataFrame(color_ohe_transformed.todense(),columns = ohe_features, dtype=int)

# output
   color_blue  color_red
0           0          1  
1           1          0      


# now transform new data

df_new = pd.DataFrame({&quot;color&quot;:[&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;],&quot;age&quot;:[10,15,20]})

new_data_ohe_transformed = ohe.transform(df_new[[&quot;color&quot;]])
pd.DataFrame(new_data_ohe_transformed .todense(),columns = ohe_features, dtype=int)

#output

  color_blue  color_red
0           0          1
1           1          0
2           0          0
</code></pre>
<p>note in the last row that both <code>blue</code> and <code>red</code> are both zeros since it has <code>color= &quot;green&quot;</code> which was not present in the training data.</p>
<p>Note the <code>todense()</code> function is only used here to illustrate how it works. Ususally you would like to keep it a sparse matrix and use e.g <code>scipy.sparse.hstack</code> to append your other features such as <code>age</code> to it.</p>
","2023-02-06 10:29:54","1","Answer"
"75360049","75360007","","<p>Use <a href=""https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html"" rel=""nofollow noreferrer""><code>pd.get_dummies</code></a>:</p>
<pre><code>out = pd.get_dummies(df, columns=df.columns)
print(out)

# Output
   month_1  month_2  day_1  day_2  day_7  week_day_2  week_day_5  ...  origin_2  origin_6  destination_1  destination_5  destination_6  destination_54  destination_167
0        1        0      0      0      1           1           0  ...         1         0              0              1              0               0                0
1        1        0      0      1      0           0           0  ...         0         0              0              0              0               0                1
2        0        1      1      0      0           0           1  ...         1         0              0              0              0               1                0
3        0        1      0      1      0           0           0  ...         0         0              0              0              1               0                0
4        1        0      0      1      0           0           0  ...         0         1              1              0              0               0                0

[5 rows x 20 columns]
</code></pre>
","2023-02-06 10:23:59","1","Answer"
"75360007","","How to pivot dataframe into ML format","<p>My head is spinning trying to figure out if I have to use pivot_table, melt, or some other function.</p>
<p>I have a DF that looks like this:</p>
<blockquote>
<pre><code>     month  day  week_day  classname_en  origin  destination
0      1     7        2        1            2         5
1      1     2        6        2            1       167
2      2     1        5        1            2        54
3      2     2        6        4            1         6
4      1     2        6        5            6         1
</code></pre>
</blockquote>
<p>But I want to turn it into something like:</p>
<blockquote>
<pre><code>     month_1 month_2 ...classname_en_1 classname_en_2 ... origin_1 origin_2 ...destination_1
0      1       0              1             0                 0         1        0      
1      1       0              0             1                 1         0        0
2      0       1              1             0                 0         1        0
3      0       1              0             0                 1         0        0
4      1       0              0             0                 0         0        1
</code></pre>
</blockquote>
<p>Basically, turn all values into columns and then have binary rows 1 - if the column is present, 0 if none.</p>
<p>IDK if it is at all possible to do with like a single function or not, but would appreciate all and any help!</p>
","2023-02-06 10:20:18","0","Question"
"75356723","","Tensorflow.data.Dataset.rejection_resample modifies my dataset's element_spec","<p>I am trying to use <code>tf.data.Dataset.rejection_resample</code> to balance my dataset, but I am running into an issue in which the method modifies the <code>element_spec</code> of my dataset, making it incompatible with my models.</p>
<p>The original element spec of my dataset is:</p>
<pre class=""lang-py prettyprint-override""><code>({'input_A': TensorSpec(shape=(None, 900, 1), dtype=tf.float64, name=None),
  'input_B': TensorSpec(shape=(None, 900, 1), dtype=tf.float64, name=None)},
 TensorSpec(shape=(None, 1, 1), dtype=tf.int64, name=None))
</code></pre>
<p>This is the element spec after batching.</p>
<p>However, if I run <code>rejection_resample</code> (before batching), the element spec at the end becomes:</p>
<pre class=""lang-py prettyprint-override""><code>(TensorSpec(shape=(None,), dtype=tf.int64, name=None),
 ({'input_A': TensorSpec(shape=(None, 900, 1), dtype=tf.float64, name=None),
   'input_B': TensorSpec(shape=(None, 900, 1), dtype=tf.float64, name=None)},
  TensorSpec(shape=(None, 1, 1), dtype=tf.int64, name=None)))
</code></pre>
<p>So <code>rejection_resample</code> is adding another <code>tf.int64</code> tensor in the beginning of my data, which I can't find out what is it for. My problem is that this breaks compatibility between the input data and my model, since it depends on the original input tuple.</p>
<p>Furthermore, it also causes an inconsistency between the training and validation data. I was expecting to apply <code>rejection_resample</code> only on training data, but if I do that, the training dataset will have the added tensor, while the validation one won't.</p>
<p>So my question is what is this added tensor to the element spec, and if there is any way to <em>drop</em> an element from the dataset after building it. Thank you.</p>
","2023-02-06 01:50:46","1","Question"
"75345792","75333618","","<p>I'm going to use your code, and I'll modify it as little as possible.
I'm also going to use [1, 2, 3] as the list of possible values for lmd, but you can change these values with the ones that you want to try.</p>
<pre><code>max_accuracy = 0
learning_rates = [0.01, 0.02, 0.03, 0.04, 0.05, 0.001, 0.002, 0.003, 0.004, 0.005]
iterations = [1000, 1500, 2000, 2500, 3000]
lmd = [1, 2, 3]

parameters = []
for i in learning_rates:
    for j in iterations:
        for k in lmd:
            parameters.append((i, j, k))
print(&quot;Possible combinations: &quot;, parameters)

for k in range(len(parameters)):
    model = LogisticRegression(learning_rate=parameters[k][0], n_steps=parameters[k][1], n_features=X_train.shape[1], lmd=parameters[k][2])
    model.fit_reg(X_train, y_train, X_valid, y_valid)

Y_pred = model.predict(X_test, thrs=0.5)
</code></pre>
<p>Basically, to add the third hyperparameter, you just add a third list over which you are going to iterate to create your list of hyperparameters, and an additional nested for loop to add all the possible combinations of hyperparameters.
You can do the same with a fourth hyperparameter, and so on.</p>
<p>Good luck!</p>
","2023-02-04 14:35:40","0","Answer"
"75340611","75309099","","<p>The problem is solved ! It's just a format problem, the conversion in numpy format solve it. Thank you !</p>
","2023-02-03 20:13:56","1","Answer"
"75334189","75333618","","<p>We can use below code where the grid_search function takes as input a model, the training data X and y, and a param_grid dictionary, which defines the hyperparameters and their possible values. The function iterates over all possible combinations of hyperparameters, fits the model with each combination, and computes the score. At end function returns the combination with the highest score as the best hyperparameters and best score.</p>
<pre><code>
import itertools
import numpy as np

def grid_search(model, X, y, param_grid):
    best_score = -np.inf
    best_params = {}
    for combination in itertools.product(*param_grid.values()):
        params = dict(zip(param_grid.keys(), combination))
        model.set_params(**params)
        model.fit(X, y)
        score = model.score(X, y)
        if score &gt; best_score:
            best_score = score
            best_params = params
    return best_params, best_score

param_grid = {
    'a': [1, 2, 3],
    'b': [4, 5, 6],
    'c': [7, 8, 9]
}
model = LogisticRegression()
best_params, best_score = grid_search(model, X, y, param_grid)


</code></pre>
","2023-02-03 10:09:09","0","Answer"
"75334135","75334085","","<p>Please check the version of streamlit (update the sklearn version)</p>
<pre><code>ColumnTransformer(transformers=[('col_tnf',OneHotEncoder(sparse=False,drop='first'),0,1,3,8,11])],remainder='passthrough')
</code></pre>
","2023-02-03 10:04:32","0","Answer"
"75334085","","streamlit error in AttributeError: 'OneHotEncoder' object has no attribute '_infrequent_enabled'","<p>Traceback:
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py&quot;, line 565, in _run_script
exec(code, module.<strong>dict</strong>)
File &quot;C:\Users\spand\Desktop\laptop price prediction\app.py&quot;, line 68, in 
st.title(int(np.exp(pipe.predict(query))))
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\pipeline.py&quot;, line 457, in predict
Xt = transform.transform(Xt)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\compose_column_transformer.py&quot;, line 763, in transform
Xs = self._fit_transform(
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\compose_column_transformer.py&quot;, line 621, in _fit_transform
return Parallel(n_jobs=self.n_jobs)(
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py&quot;, line 1085, in <strong>call</strong>
if self.dispatch_one_batch(iterator):
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py&quot;, line 901, in dispatch_one_batch
self._dispatch(tasks)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py&quot;, line 819, in _dispatch
job = self._backend.apply_async(batch, callback=cb)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib_parallel_backends.py&quot;, line 208, in apply_async
result = ImmediateResult(func)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib_parallel_backends.py&quot;, line 597, in <strong>init</strong>
self.results = batch()
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py&quot;, line 288, in <strong>call</strong>
return [func(*args, **kwargs)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py&quot;, line 288, in 
return [func(*args, **kwargs)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\fixes.py&quot;, line 117, in <strong>call</strong>
return self.function(*args, **kwargs)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\pipeline.py&quot;, line 853, in _transform_one
res = transformer.transform(X)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing_encoders.py&quot;, line 888, in transform
self._map_infrequent_categories(X_int, X_mask)
File &quot;C:\Users\spand\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing_encoders.py&quot;, line 726, in _map_infrequent_categories
if not self._infrequent_enabled:</p>
<p>How to overcome this problem no i can't find the reason behind it</p>
","2023-02-03 09:57:50","0","Question"
"75333618","","How to tune more than 2 hyperparameters in Grid Search in Python?","<p>I am applying grid search on Logistic Regression in order to find the combination of parameters that achieves the best accuracy. In this part of code I tuned only two hyperparameters (learning rate and iterations or &quot;n_steps&quot;), but I have some difficulties if I want to tune more than 2 parameters (for example learning_rate, iterations and regularization factor or &quot;lmd&quot;).</p>
<p><strong>Note: I need to do everything from scratch, so I can't use sklearn but only numpy</strong></p>
<p>This is my code where I tuned learning_rate and the number of iterations:</p>
<pre><code>max_accuracy = 0
learning_rates = [0.01, 0.02, 0.03, 0.04, 0.05, 0.001, 0.002, 0.003, 0.004, 0.005]
iterations = [1000, 1500, 2000, 2500, 3000]

parameters = []
for i in learning_rates:
    for j in iterations:
        parameters.append((i, j))
print(&quot;Possible combinations: &quot;, parameters)

for k in range(len(parameters)):
    model = LogisticRegression(learning_rate=parameters[k][0], n_steps=parameters[k][1], n_features=X_train.shape[1], lmd=2)
    model.fit_reg(X_train, y_train, X_valid, y_valid)

    Y_pred = model.predict(X_test, thrs=0.5)
</code></pre>
<p>How do I change the code if I want to tune learning_rate, n_steps and lmd?</p>
","2023-02-03 09:12:52","0","Question"
"75332842","75332257","","<p>In function <code>all_moves_from_board</code> I think it should be</p>
<pre><code>move_list = []
    for i, v in enumerate(board):
        if v == EMPTY_SIGN:
            move_list.append(board[:i] + sign + board[i + 1:])

    return move_list
</code></pre>
<p>You accidentally wrote the first slicing of the board index to 1.
I have not checked whether the code is working as it's intended to or not but now it runs and generates an output:</p>
<pre><code> step 0. Moves: 1
 step 1. Moves: 1
 step 2. Moves: 8
 step 3. Moves: 24
 step 4. Moves: 144
 step 5. Moves: 83
 step 6. Moves: 214
 step 7. Moves: 148
 step 8. Moves: 172
First player wins: 504
Second player wins: 12
Draw: 91
Total: 607
</code></pre>
","2023-02-03 07:48:57","0","Answer"
"75332473","75282840","","<p>There is a module <a href=""https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.GridSampler.html#optuna.samplers.GridSampler.sample_relative"" rel=""nofollow noreferrer""><code>GridSampler</code></a> in optuna that solves this question:</p>
<pre><code>import optuna

def objective(trial):
        # define two variables:
        A = trial.suggest_float('A', 0.001, 0.01)
        B = trial.suggest_int('B', 10, 70)
        # minimize this toy objective:
        obj = A/B
        return obj

def optimization():
        # define custom values to search on:
        search_space = {'A':[0.0015, 0.003, 0.0075], 'B':[11, 23]}
        sampler = optuna.samplers.GridSampler(search_space)
        study = optuna.create_study(study_name=&quot;Optimization over given values&quot;, sampler=sampler)
        study.optimize(objective, n_trials = 6)

if __name__=='__main__':
    optimization()  
</code></pre>
<p>The out put is:</p>
<pre><code>[I 2023-02-03 10:21:01,912] A new study created in memory with name: Optimization over given values
[I 2023-02-03 10:21:01,914] Trial 0 finished with value: 0.0006818181818181818 and parameters: {'A': 0.0075, 'B': 11}. Best is trial 0 with value: 0.0006818181818181818. 
[I 2023-02-03 10:21:01,916] Trial 1 finished with value: 0.00013043478260869567 and parameters: {'A': 0.003, 'B': 23}. Best is trial 1 with value: 0.00013043478260869567.
[I 2023-02-03 10:21:01,917] Trial 2 finished with value: 0.0003260869565217391 and parameters: {'A': 0.0075, 'B': 23}. Best is trial 1 with value: 0.00013043478260869567.
[I 2023-02-03 10:21:01,921] Trial 3 finished with value: 6.521739130434783e-05 and parameters: {'A': 0.0015, 'B': 23}. Best is trial 3 with value: 6.521739130434783e-05. 
[I 2023-02-03 10:21:01,927] Trial 4 finished with value: 0.00013636363636363637 and parameters: {'A': 0.0015, 'B': 11}. Best is trial 3 with value: 6.521739130434783e-05.
[I 2023-02-03 10:21:01,951] Trial 5 finished with value: 0.00027272727272727274 and parameters: {'A': 0.003, 'B': 11}. Best is trial 3 with value: 6.521739130434783e-05.
</code></pre>
","2023-02-03 07:04:25","3","Answer"
"75332421","75332257","","<p>in game_won_by function</p>
<pre><code># board: .O.X....   &lt;- 8 elements
# index: [6, 7, 8] 
# index[2] = 8 
# so, occurred out of range (board[index[2]])
# check board array

if board[index[0]] == board[index[1]] == board[index[2]] != EMPTY_SIGN:
</code></pre>
<p>3 times: board array size: 9<br />
4th: board array size: 8</p>
<p>check why board array size is changed</p>
","2023-02-03 06:58:18","0","Answer"
"75332257","","Error in Heuristics Tic-Tac-Toe Python code - string index out of range","<pre><code>from random import choice
import numpy as np

combo_indices = [
    [0,1,2],
    [3,4,5],
    [6,7,8],
    [0,3,6],
    [1,4,7],
    [2,5,8],
    [0,4,8],
    [2,4,6]
]

EMPTY_SIGN = '.'
AI_SIGN = 'X'
OPPONENT_SIGN = 'O'


def all_moves_from_board(board, sign):
    move_list = []
    for i,v in enumerate(board):
        if v == EMPTY_SIGN:
            move_list.append(board[:1] + sign + board[i+1:])
    return move_list

def game_won_by(board):
    for index in combo_indices:
        if board[index[0]] == board[index[1]] == board[index[2]] != EMPTY_SIGN:
            return board[index[0]]
    return EMPTY_SIGN


def filter_wins(move_list, ai_wins, opponent_wins):
    for board in move_list:
        won_by = game_won_by(board)
        if won_by == AI_SIGN:
            ai_wins.append(board)
            move_list.remove(board)
        elif won_by == OPPONENT_SIGN:
            opponent_wins.append(board)
            move_list.remove(board)    
    
def init_utility_matrix(board):
    return [0 if cell == EMPTY_SIGN else -1 for cell in board]

def generate_add_score(utilities, i , j, k):
    def add_score(points):
        if utilities[i] &gt;= 0:
            utilities[i] += points
        if utilities[j] &gt;= 0:
            utilities[j] += points
        if utilities[k] &gt;= 0:
            utilities[k] += points 
    return add_score

def utility_matrix(board):
    utilities = init_utility_matrix(board)
    for [i,j,k] in combo_indices:
        add_score = generate_add_score(utilities, i, j, k)
        triple = [ board[i], board[j], board[k]]
        if triple.count(EMPTY_SIGN) == 1:
            if triple.count(AI_SIGN) == 2:
                add_score(1000)
            elif triple.count(OPPONENT_SIGN) == 2:
                add_score(100)
        elif triple.count(EMPTY_SIGN) == 2 and triple.count(AI_SIGN) == 1:
            add_score(10)
        elif triple.count(EMPTY_SIGN) == 3:
            add_score(1)
    return utilities


def best_moves_from_board(board, sign):
    move_list =[]
    utilities = utility_matrix(board)
    max_utility = max(utilities)
    for i,v in enumerate(board):
        if utilities[i] == max_utility:   
            move_list.append(board[:i] + sign + board[i+1:])
    return move_list

def all_moves_from_board_list(board_list, sign):
    move_list = []
    get_moves = best_moves_from_board if sign == AI_SIGN else all_moves_from_board
    for board in board_list:
        move_list.extend(get_moves(board, sign))
    return move_list

            
def count_possibilities():
    board = EMPTY_SIGN*9
    move_list = [board]
    ai_wins = []
    opponent_wins = []
    for i in range(9):
        print(' step ' + str(i) + '. Moves: ' + str(len(move_list)))
        sign = AI_SIGN if i%2==0 else OPPONENT_SIGN
        move_list = all_moves_from_board_list(move_list, sign)
        filter_wins(move_list, ai_wins, opponent_wins)
    print('First player wins: ' + str(len(ai_wins)))
    print('Second player wins: ' + str(len(opponent_wins)))
    print('Draw: ' + str(len(move_list)))
    print('Total: ' + str(len(ai_wins) + len(opponent_wins) + len(move_list) ))


count_possibilities()
        
    
    
    
    
    
    
    
    
    
    
</code></pre>
<p>This is my code above...</p>
<p>i am getting this error:-</p>
<pre><code>
IndexError                                Traceback (most recent call last)
Input In \[3\], in \&lt;cell line: 107\&gt;()
103     print('Draw: ' + str(len(move_list)))
104     print('Total: ' + str(len(ai_wins) + len(opponent_wins) + len(move_list) ))
\--\&gt; 107 count_possibilities()

Input In \[3\], in count_possibilities()
98     sign = AI_SIGN if i%2==0 else OPPONENT_SIGN
99     move_list = all_moves_from_board_list(move_list, sign)
\--\&gt; 100     filter_wins(move_list, ai_wins, opponent_wins)
101 print('First player wins: ' + str(len(ai_wins)))
102 print('Second player wins: ' + str(len(opponent_wins)))

Input In \[3\], in filter_wins(move_list, ai_wins, opponent_wins)
34 def filter_wins(move_list, ai_wins, opponent_wins):
35     for board in move_list:
\---\&gt; 36         won_by = game_won_by(board)
37         if won_by == AI_SIGN:
38             ai_wins.append(board)

Input In \[3\], in game_won_by(board)
27 def game_won_by(board):
28     for index in combo_indices:
\---\&gt; 29         if board\[index\[0\]\] == board\[index\[1\]\] == board\[index\[2\]\] != EMPTY_SIGN:
30             return board\[index\[0\]\]
31     return EMPTY_SIGN
</code></pre>
<p>IndexError: string index out of range</p>
<p>while calling the game_won_by function and then checking the if state for indexes 0,1,2 for board iteration it is showing string index out of range...</p>
<p>Please help anyone...</p>
<p>Error resolution :- String index out of range</p>
","2023-02-03 06:33:42","0","Question"
"75325928","75303038","","<p>You want to take advantage of the fact that <a href=""https://docs.scipy.org/doc/scipy/reference/special.html"" rel=""nofollow noreferrer"">scipy</a> has a set of functions which are <a href=""https://pola-rs.github.io/polars-book/user-guide/dsl/numpy.html"" rel=""nofollow noreferrer"">numpy ufuncs</a> as those</p>
<blockquote>
<p>still have fast columnar operation through the NumPy API.</p>
</blockquote>
<p>Specifically you want the <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.pdtr.html#scipy.special.pdtr"" rel=""nofollow noreferrer"">pdtr</a> function.</p>
<p>You then want to use <code>reduce</code> rather than <code>map</code> or <code>apply</code> as those are for generic python functions and aren't going to perform as well.</p>
<p>So if we have...</p>
<pre><code>df = pl.DataFrame({&quot;count&quot;: [9,2,3,4,5], &quot;expected_count&quot;: [7.7, 0.2, 0.7, 1.1, 7.5]})
result = poisson.cdf(df[&quot;count&quot;].to_numpy(), df[&quot;expected_count&quot;].to_numpy())
df = df.with_columns(pl.Series(result).alias(&quot;poission_cdf&quot;))
</code></pre>
<p>then we can add to it with</p>
<pre><code>df=df.with_columns(
    pl.reduce(function=pdtr, exprs=[pl.col('count'),pl.col('expected_count')]).alias(&quot;poicdf&quot;)
)
df

shape: (5, 4)
┌───────┬────────────────┬──────────────┬──────────┐
│ count ┆ expected_count ┆ poission_cdf ┆ poicdf   │
│ ---   ┆ ---            ┆ ---          ┆ ---      │
│ i64   ┆ f64            ┆ f64          ┆ f64      │
╞═══════╪════════════════╪══════════════╪══════════╡
│ 9     ┆ 7.7            ┆ 0.75308      ┆ 0.75308  │
│ 2     ┆ 0.2            ┆ 0.998852     ┆ 0.998852 │
│ 3     ┆ 0.7            ┆ 0.994247     ┆ 0.994247 │
│ 4     ┆ 1.1            ┆ 0.994565     ┆ 0.994565 │
│ 5     ┆ 7.5            ┆ 0.241436     ┆ 0.241436 │
└───────┴────────────────┴──────────────┴──────────┘
</code></pre>
<p>You can see it gives the same answer.</p>
","2023-02-02 16:09:49","1","Answer"
"75325662","75325247","","<p>The update of <code>m</code> and <code>b</code> needs to happen every step but this is not going to be enough. You also need to slightly increase your learning rate, say twice:</p>
<pre><code>import numpy as np
celsius_q = np.array([-40, -10, 0, 8, 15, 22, 38], dtype=float)
fahrenheit_a = np.array([-40, 14, 32, 46, 59, 72, 100], dtype=float)

inputs = celsius_q
output_expected = fahrenheit_a

# y = m * x + b
m_new = m = 100.0
b_new = b = 0.0
m_gradient = 0.0
b_gradient = 0.0
learning_rate = 0.0002
# Forwardpropagation
for i in range(10000):
    m_gradient, b_gradient = 0, 0

    for i in range(len(inputs)):
        m_gradient += (m_new + (b_new * inputs[i] - output_expected[i]))
        b_gradient += inputs[i] * (m_new + (b_new * inputs[i]) - output_expected[i])

    m_new -= learning_rate * m_gradient
    b_new -= learning_rate * b_gradient

print(m_new, b_new)
</code></pre>
<p>Getting:</p>
<pre><code>31.952623523538897 1.7979482813813066
</code></pre>
<p>which is close to the expected 32 and 1.8.</p>
","2023-02-02 15:49:45","1","Answer"
"75325595","75325247","","<p>You should continually update your parameters, in every step.  Something like:</p>
<pre class=""lang-py prettyprint-override""><code>for i in range(10000):
    m_gradient, b_gradient = 0, 0

    for i in range(len(inputs)):
        m_gradient += (m + (b * inputs[i] - output_expected[i]))
        b_gradient += inputs[i] * (m + (b * inputs[i]) - output_expected[i])

    m -= learning_rate * m_gradient 
    b -= learning_rate * b_gradient
</code></pre>
<p>(But I didn't check your math.)</p>
","2023-02-02 15:44:49","1","Answer"
"75325247","","Simple Linear Regression - what am I doing wrong?","<p>I am new to ML and tried to build a Linear Regression Model by myself. Object is to predict the fahrenheit values for celcius values.
This is my code:</p>
<pre><code>celsius_q = np.array([-40, -10, 0, 8, 15, 22, 38], dtype= float)
fahrenheit_a = np.array([-40, 14, 32, 46, 59, 72, 100], dtype = float)

inputs = celsius_q
output_expected = fahrenheit_a

# y = m * x + b
m = 100
b = 0
m_gradient = 0
b_gradient = 0
learning_rate = 0.00001
#Forwardpropagation
for i in range(10000):
    for i in range(len(inputs)):
        m_gradient += (m + (b * inputs[i] - output_expected[i]))
        b_gradient += inputs[i] * (m + (b * inputs[i]) - output_expected[i])

m_new = m - learning_rate * (2/len(inputs)) * m_gradient 
b_new = b - learning_rate * (2/len(inputs)) * b_gradient
    
</code></pre>
<p>The code generates wrong weights for m and b, no matter how much I change the learning_rate and the epochs. The weights for minimal loss function has to be:</p>
<pre><code>b = 1.8
m = 32

</code></pre>
<p>What am I doing wrong?</p>
","2023-02-02 15:18:02","1","Question"
"75322451","75212292","","<p>There is a limit on GCS, it returns only the first 1000 files per request if we want more than 1000 we have pass NextMarker (name of last file) and request again until we get all files. This way we can get all files without missing any.</p>
<p>This issue can be tracked at <a href=""https://github.com/tensorflow/datasets/issues/1938"" rel=""nofollow noreferrer"">#1938</a>.</p>
<p>As a workaround, you can try gsutil command to downlaod the data from GCS as shown below.</p>
<pre><code>!gsutil cp -r &quot;gs://tfds-data/datasets/nsynth/full/2.3.3&quot; &quot;/content/data&quot;
</code></pre>
<p>Install gsutil locally: <a href=""https://cloud.google.com/storage/docs/gsutil_install"" rel=""nofollow noreferrer"">https://cloud.google.com/storage/docs/gsutil_install</a></p>
","2023-02-02 11:23:57","0","Answer"
"75318442","75094244","","<p>As per Hiran's comment in the question, it also worked for me.
install shap again after uninstall it.</p>
<pre><code>pip uninstall shap

pip install shap
</code></pre>
","2023-02-02 03:39:41","1","Answer"
"75318044","75300301","","<p>The issue here was indeed due to the shape of my labels not being the same as logits. Logits were of shape (3) since they contained a float for the probability of each of the three classes that I wanted to predict. Labels were originally of shape (1) since it only contained one int.</p>
<p>To solve this, I used one-hot encoding which turned all labels into a shape of (3) and this solved the problem. Used the keras.utils.to_categorical() function to do so.</p>
<pre><code>sentiment_types = ('negative', 'neutral', 'positive')

train_df['sentiment'] = train_df['sentiment'].astype('category')
test_df['sentiment'] = test_df['sentiment'].astype('category')

# Turning labels from strings to int
train_sentiment_cat = train_df['sentiment'].cat.codes
test_sentiment_cat = test_df['sentiment'].cat.codes

# One-hot encoding 
train_y = to_categorical(train_sentiment_cat)
test_y = to_categorical(test_sentiment_cat)
</code></pre>
","2023-02-02 02:19:19","0","Answer"
"75316939","75273987","","<p><strong>Issue 1</strong></p>
<p><code>GeometryReader</code> makes everything inside shrink to its smallest size.</p>
<p>Add <code>.border(Color.orange)</code> to the <code>ZStack</code> and you will see something like what I have below.</p>
<p><a href=""https://i.sstatic.net/ZuZYH.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/ZuZYH.png"" alt=""enter image description here"" /></a></p>
<p>You can use <code>.frame(maxWidth: .infinity, maxHeight: .infinity)</code> to make the <code>ZStack</code> stretch to take all the available space.</p>
<p><strong>Issue 2</strong></p>
<p><code>position</code> vs <code>offset</code>.</p>
<p><code>offset</code> usually starts at the center then you <code>offset</code> by the specified amount.</p>
<p><code>position</code> is more like <code>origin</code>.</p>
<blockquote>
<p>Positions the center of this view at the specified coordinates in its parent’s coordinate space.</p>
</blockquote>
<p><strong>Issue 3</strong></p>
<p>Adjusting for that center positioning vs top left (0, 0) that is used by origin.</p>
<p><strong>Issue 4</strong></p>
<p>The <code>ZStack</code> needs to be flipped on the X axis.</p>
<p>Below is the full code</p>
<pre><code>import SwiftUI
import Vision
import CoreML
@MainActor
class Detection: ObservableObject {
    //Moved file to assets
    //let imgURL = URL(string: &quot;https://i.imgur.com/EqsxxTc.jpg&quot;)! // Xcode preview generates this: https://i.imgur.com/6IPNQ8b.png
    let imageName: String = &quot;EqsxxTc&quot;
    @Published var objects: [VNRecognizedObjectObservation] = []
    
    func getModel() throws -&gt; VNCoreMLModel {
        //Used model directly instead of loading from URL
        let model = try YOLOv3Tiny(configuration: .init()).model
        
        let mlModel = try VNCoreMLModel(for: model)
        
        return mlModel
    }
    
    func detect() async throws {
        let model = try getModel()
        
        guard let tiff = NSImage(named: imageName)?.tiffRepresentation else {
            // YOLOv3Tiny: https://ml-assets.apple.com/coreml/models/Image/ObjectDetection/YOLOv3Tiny/YOLOv3Tiny.mlmodel
            //fatalError(&quot;Either YOLOv3Tiny.mlmodel is not in project bundle, or image failed to load.&quot;)
            throw AppError.unableToLoadImage
        }
        //Completion handlers are not compatible with async/await you have to convert to a continuation.
        self.objects = try await withCheckedThrowingContinuation { (cont: CheckedContinuation&lt;[VNRecognizedObjectObservation], Error&gt;) in
            
            let request = VNCoreMLRequest(model: model) { (request, error) in
                if let error = error{
                    cont.resume(throwing: error)
                }else{
                    cont.resume(returning: (request.results as? [VNRecognizedObjectObservation]) ?? [])
                }
            }
            do{
                try VNImageRequestHandler(data: tiff).perform([request])
            }catch{
                cont.resume(throwing: error)
            }
        }
    }
    
    func deNormalize(_ rect: CGRect, _ geometry: GeometryProxy) -&gt; CGRect {
        return VNImageRectForNormalizedRect(rect, Int(geometry.size.width), Int(geometry.size.height))
    }
}

struct ContentView: View {
    @StateObject var detection = Detection()
    
    var body: some View {
        Image(detection.imageName)
            .resizable()
            .scaledToFit()
            .overlay {
                GeometryReader { geometry in
                    ZStack {
                        ForEach(detection.objects, id: \.uuid) { object in
                            let rect = detection.deNormalize(object.boundingBox, geometry)
                            Rectangle()
                                .stroke(lineWidth: 2)
                                .foregroundColor(.red)
                                .frame(width: rect.width, height: rect.height)
                            //Changed to position
                            //Adjusting for center vs leading origin
                                .position(x: rect.origin.x + rect.width/2, y: rect.origin.y + rect.height/2)
                        }
                    }
                    //Geometry reader makes the view shrink to its smallest size
                    .frame(maxWidth: .infinity, maxHeight: .infinity)
                    //Flip upside down
                    .rotation3DEffect(.degrees(180), axis: (x: 1, y: 0, z: 0))
                    
                }.border(Color.orange)
            }
        
            .task {
                do{
                    try await self.detection.detect()
                }catch{
                    //Always throw errors to the View so you can tell the user somehow. You don't want crashes or to leave the user waiting for something that has failed.
                    print(error)
                }
            }
    }
}
struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}

enum AppError: LocalizedError{
    case cannotFindFile
    case unableToLoadImage
}
</code></pre>
<p><a href=""https://i.sstatic.net/3N3ae.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/3N3ae.png"" alt=""enter image description here"" /></a></p>
<p>I also changed some other things as you can notice, there are comments in the code.</p>
","2023-02-01 22:37:23","3","Answer"
"75316303","75273987","","<p>Okay so after a long time of troubleshooting, I finally managed to make it work correctly (<strong>while still not understanding the reason for the problem</strong>)...</p>
<p>The problem was this part:</p>
<pre><code>GeometryReader { geometry in
    ZStack {
        ForEach(detection.objects, id: \.uuid) { object in
            let rect = detection.deNormalize(object.boundingBox, geometry)
            Rectangle()
                .stroke(lineWidth: 2)
                .foregroundColor(.red)
                .frame(width: rect.width, height: rect.height)
                .offset(x: rect.origin.x, y: rect.origin.y)
        }
    }
}
</code></pre>
<p>I assumed because many <code>Rectangle()</code>s will overlap, I need a <code>ZStack()</code> to put them over each other, this turned out to be wrong, apparently when using <code>.offset()</code> they can overlap without any issue, so removing the <code>ZStack()</code> completely solved the problem:</p>
<pre><code>GeometryReader { geometry in
    ForEach(detection.objects, id: \.uuid) { object in
        let rect = detection.deNormalize(object.boundingBox, geometry)
        Rectangle()
            .stroke(lineWidth: 2)
            .foregroundColor(.red)
            .frame(width: rect.width, height: rect.height)
            .offset(x: rect.origin.x, y: rect.origin.y)
    }
}
</code></pre>
<p><strong>What I still don't understand, is why moving the <code>ZStack()</code> outside <code>GeometryReader()</code> also solves the problem and why some boxes were in the correct positions while some were not!</strong></p>
<pre><code>ZStack {
    GeometryReader { geometry in
        ForEach(detection.objects, id: \.uuid) { object in
            let rect = detection.deNormalize(object.boundingBox, geometry)
            Rectangle()
                .stroke(lineWidth: 2)
                .foregroundColor(.red)
                .frame(width: rect.width, height: rect.height)
                .offset(x: rect.origin.x, y: rect.origin.y)
        }
    }
}
</code></pre>
","2023-02-01 21:20:14","1","Answer"
"75315389","75315325","","<p>Convert to integer before handing values to numpy:</p>
<pre><code>arr = np.array(list(map(int, preds)))
</code></pre>
","2023-02-01 19:43:01","0","Answer"
"75315349","75315325","","<p>You can easily convert it into a regular Python list of 1s and 0s with <code>[1 if p else 0 for p in preds]</code>, and then pass that to <code>np.array</code> or whatever, e.g.:</p>
<pre><code>import numpy as np
preds = [False, True, False, True,  True,  True,  True,  True,  True,  True,
         True,  True, True,  False, False, True,  True,  True,  True,  False,
         True,  True, False, True,  False, False, True,  False, True,  True,
         True,  True, True,  False, False, False, False, True,  False, False,
         True,  True, True,  True,  False, False, False, False, True,  False,
         True, False, True,  True,  True,  True,  True,  False,  True, False,
         True]
np_preds = np.array([1 if p else 0 for p in preds])
</code></pre>
","2023-02-01 19:39:14","1","Answer"
"75315325","","How to convert a list into an np.array in Python?","<p>I have this type of list named &quot;preds&quot;:</p>
<pre><code>[False  True False  True  True  True  True  True  True  True  True  True
  True False False  True  True  True  True False  True  True False  True
 False False  True False  True  True  True  True  True False False False
 False  True False False  True  True  True  True False False False False
  True False  True False  True  True  True  True  True False  True False
  True]
</code></pre>
<p>It's the prediction i obtained with the logistic regression model. I need to convert it into an array containing 1 if the element in the list is &quot;True&quot; and 0 if the element is &quot;False&quot;. I have already tried using np.array(preds) or np.asarray(preds) but it doesn't work.</p>
<p>Please can somebody help me finding a solution? I am sorry for the stupid question but I am very new to programming. Thanks in advance.</p>
<p>I already tried using the command of the numpy library like np.array(preds) or np.asarray(preds). I need to obtain a new vector with the same number of elements, in which 1 corresponds to True and 0 corresponds to False</p>
","2023-02-01 19:36:09","-1","Question"
"75311287","75303038","","<p>If <code>scipy.stats.poisson.cdf</code> was implemented as a proper <a href=""https://numpy.org/doc/stable/user/basics.ufuncs.html#ufuncs-basics"" rel=""nofollow noreferrer"">numpy universal function</a>, it would be possible to use it directly on polars expressions, but it is not.  Fortunately, Poisson CDF is almost the same as regularized upper incomplete gamma function for which scipy supplies <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.gammaincc.html"" rel=""nofollow noreferrer"">gammaincc</a> which can be used in polars expressions:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; import polars as pl
&gt;&gt;&gt; from scipy.special import gammaincc
&gt;&gt;&gt; df = pl.select(pl.arange(0, 10).alias('k'))
&gt;&gt;&gt; df.with_columns(cdf=gammaincc(pl.col('k') + 1, 4.0))
shape: (10, 2)
┌─────┬──────────┐
│ k   ┆ cdf      │
│ --- ┆ ---      │
│ i64 ┆ f64      │
╞═════╪══════════╡
│ 0   ┆ 0.018316 │
│ 1   ┆ 0.091578 │
│ 2   ┆ 0.238103 │
│ 3   ┆ 0.43347  │
│ ... ┆ ...      │
│ 6   ┆ 0.889326 │
│ 7   ┆ 0.948866 │
│ 8   ┆ 0.978637 │
│ 9   ┆ 0.991868 │
└─────┴──────────┘
</code></pre>
<p>The result is the same as returned by poisson.cdf:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; _.with_columns(cdf2=pl.lit(poisson.cdf(df['k'], 4)))
shape: (10, 3)
┌─────┬──────────┬──────────┐
│ k   ┆ cdf      ┆ cdf2     │
│ --- ┆ ---      ┆ ---      │
│ i64 ┆ f64      ┆ f64      │
╞═════╪══════════╪══════════╡
│ 0   ┆ 0.018316 ┆ 0.018316 │
│ 1   ┆ 0.091578 ┆ 0.091578 │
│ 2   ┆ 0.238103 ┆ 0.238103 │
│ 3   ┆ 0.43347  ┆ 0.43347  │
│ ... ┆ ...      ┆ ...      │
│ 6   ┆ 0.889326 ┆ 0.889326 │
│ 7   ┆ 0.948866 ┆ 0.948866 │
│ 8   ┆ 0.978637 ┆ 0.978637 │
│ 9   ┆ 0.991868 ┆ 0.991868 │
└─────┴──────────┴──────────┘
</code></pre>
","2023-02-01 13:59:47","3","Answer"
"75309099","","Confidence interval AUC with the bootstrap method","<p>today I attempted to make a bootstrap to obtain the interval confidence of various different ML algorithm AUC.</p>
<p>I used my personal medical dataset with 61 features formatted liked this :</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Age</th>
<th>Female</th>
</tr>
</thead>
<tbody>
<tr>
<td>65</td>
<td>1</td>
</tr>
<tr>
<td>45</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>For exemple I used this type of algorithm :</p>
<pre><code>X = data_sevrage.drop(['Echec_sevrage'], axis=1)

y = data_sevrage['Echec_sevrage']

X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25, random_state=0)

lr = LogisticRegression(C=10 ,penalty='l1', solver= 'saga', max_iter=500).fit(X_train,y_train)
score=roc_auc_score(y_test,lr.predict_proba(X_test)[:,1])
precision, recall, thresholds = precision_recall_curve(y_test, lr.predict_proba(X_test)[:,1])
auc_precision_recall = metrics.auc(recall, precision)
y_pred = lr.predict(X_test)
print('ROC AUC score :',score)
print('auc_precision_recall :',auc_precision_recall)
</code></pre>
<p>And finally, when I used the boostrap method to obtain the confidence interval (I take the code from other topic : <a href=""https://stackoverflow.com/questions/52373318/how-to-compare-roc-auc-scores-of-different-binary-classifiers-and-assess-statist"">How to compare ROC AUC scores of different binary classifiers and assess statistical significance in Python?</a>)</p>
<pre><code>def bootstrap_auc(clf, X_train, y_train, X_test, y_test, nsamples=1000):
    auc_values = []
    for b in range(nsamples):
        idx = np.random.randint(X_train.shape[0], size=X_train.shape[0])
        clf.fit(X_train[idx], y_train[idx])
        pred = clf.predict_proba(X_test)[:, 1]
        roc_auc = roc_auc_score(y_test.ravel(), pred.ravel())
        auc_values.append(roc_auc)
    return np.percentile(auc_values, (2.5, 97.5))

bootstrap_auc(lr, X_train, y_train, X_test, y_test, nsamples=1000)
</code></pre>
<p>I have this error :</p>
<blockquote>
<p>&quot;None of [Int64Index([21, 22, 20, 31, 30, 13, 22,  1, 31,  3,  2,  9,  9, 18, 29, 30, 31,\n            31, 16, 11, 23,  7, 19, 10, 14,  5, 10, 25, 30, 24,  8, 20],\n           dtype='int64')] are in the [columns]&quot;</p>
</blockquote>
<p>I use this other method, and i have nearly the same error :</p>
<pre><code> n_bootstraps = 1000
rng_seed = 42  # control reproducibility
bootstrapped_scores = []

rng = np.random.RandomState(rng_seed)
for i in range(n_bootstraps):
    # bootstrap by sampling with replacement on the prediction indices
    indices = rng.randint(0, len(y_pred), len(y_pred))
    if len(np.unique(y_test[indices])) &lt; 2:
        # We need at least one positive and one negative sample for ROC AUC
        # to be defined: reject the sample
        continue

    score = roc_auc_score(y_test[indices], y_pred[indices])
    bootstrapped_scores.append(score)
    print(&quot;Bootstrap #{} ROC area: {:0.3f}&quot;.format(i + 1, score))
</code></pre>
<blockquote>
<p>'[6, 3, 12, 14, 10, 7, 9] not in index'</p>
</blockquote>
<p>Can you help me please ? I tested many solutions but I have this error every time.</p>
<p>Thank you !</p>
<p>Bootstrap method for AUC confidence interval on machine learning algorithm.</p>
","2023-02-01 10:51:08","0","Question"
"75307451","75300301","","<blockquote>
<p>my logits (None, 3) are not the same size as my labels (None, 1)
I made sure that my last layer had an output of 3 and had the activation = 'softmax'
my labels have a dimension of (None, 1) since I mapped each class to a unique integer</p>
</blockquote>
<p>The key concept you are missing is that you need to one-hot encode your labels (after assigning integers to them - see below).</p>
<p>So your model, after the softmax, is spitting out three values: how probable each of your labels is. E.g. it might say A is 0.6, B is 0.1, and C is 0.3. If the correct answer is C, then it needs to see that correct answer as <code>0, 0, 1</code>. It can then say that its prediction for A is <code>0.6 - 0 = +0.6</code> wrong, B is <code>0.1 - 0 = +0.1</code> wrong, and C is <code>0.3 - 1 = -0.7</code> wrong.</p>
<p>Theoretically you can go from a string label directly to a one-hot encoding. But it seems Tensorflow needs the labels to first be encoded as integers, and then that is one-hot encoded.</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding#examples"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding#examples</a> says to use:</p>
<pre><code>tf.keras.layers.CategoryEncoding(num_tokens=3, output_mode=&quot;one_hot&quot;)
</code></pre>
<p>Also see <a href=""https://stackoverflow.com/a/69791457/841830"">https://stackoverflow.com/a/69791457/841830</a> (the higher-voted answer there is from 2019, so applies to TensorFlow v1 I think).  And searching for &quot;tensorflow one-hot encoding&quot; will bring up plenty of tutorials and examples.</p>
","2023-02-01 08:37:32","1","Answer"
"75304406","75252308","","<p>i fix the problem using the answer from this post <a href=""https://stackoverflow.com/a/58477381/19640802"">answer</a>
by joining all the train data column before vectorizing.</p>
<pre><code>df_train = pd.DataFrame(data=x_train)
df_test = pd.DataFrame(data=x_test)

series = pd.Series(df_train['stemmed_tweet'])
corpus = series.apply(lambda series: ' '.join(series))
vectorizer = CountVectorizer(ngram_range=(1,3), lowercase=False)
x_train_tf = vectorizer.fit_transform(corpus).toarray()
x_test_tf = vectorizer.transform(str(df_test.values).split(&quot;\n&quot;)).toarray()
</code></pre>
","2023-02-01 00:09:29","0","Answer"
"75303514","75262200","","<p>After some search I found the difference: ensemble learning involves training multiple classifiers and combining their predictions, while classifier fusion involves combining the predictions of pre-trained classifiers.</p>
","2023-01-31 21:50:06","0","Answer"
"75303247","75303038","","<p>It sounds like you want to use <a href=""https://docs.pola.rs/user-guide/expressions/user-defined-functions/#processing-a-whole-series-with-map_batches"" rel=""nofollow noreferrer""><code>.map_batches()</code></a></p>
<pre class=""lang-py prettyprint-override""><code>df.with_columns(
   pl.struct(&quot;count&quot;, &quot;expected_count&quot;)
     .map_batches(lambda x: 
        poisson.cdf(x.struct.field(&quot;count&quot;), x.struct.field(&quot;expected_count&quot;))
     )
     .alias(&quot;poisson_cdf&quot;)
)
</code></pre>
<pre><code>shape: (5, 3)
┌───────┬────────────────┬─────────────┐
│ count | expected_count | poisson_cdf │
│ ---   | ---            | ---         │
│ i64   | f64            | f64         │
╞═══════╪════════════════╪═════════════╡
│ 9     | 7.7            | 0.75308     │
│ 2     | 0.2            | 0.998852    │
│ 3     | 0.7            | 0.994247    │
│ 4     | 1.1            | 0.994565    │
│ 5     | 7.5            | 0.241436    │
└───────┴────────────────┴─────────────┘
</code></pre>
","2023-01-31 21:17:58","1","Answer"
"75303038","","How to Write Poisson CDF as Python Polars Expression","<p>I have a collection of polars expressions being used to generate features for an ML model. I'd like to add a poission cdf feature to this collection whilst maintaining lazy execution (with benefits of speed, caching etc...). I so far have not found an easy way of achieving this.</p>
<p>I've been able to get the result I'd like outside of the desired lazy expression framework with:</p>
<pre><code>import polars as pl
from scipy.stats import poisson

df = pl.DataFrame({&quot;count&quot;: [9,2,3,4,5], &quot;expected_count&quot;: [7.7, 0.2, 0.7, 1.1, 7.5]})
result = poisson.cdf(df[&quot;count&quot;].to_numpy(), df[&quot;expected_count&quot;].to_numpy())
df = df.with_columns(pl.Series(result).alias(&quot;poisson_cdf&quot;))
</code></pre>
<p>However, in reality I'd like this to look like:</p>
<pre><code>df = pl.DataFrame({&quot;count&quot;: [9,2,3,4,5], &quot;expected_count&quot;: [7.7, 0.2, 0.7, 1.1, 7.5]})
df = df.select(
    [
        ... # bunch of other expressions here
        poisson_cdf()
    ]
)
</code></pre>
<p>where <code>poisson_cdf</code> is some polars expression like:</p>
<pre><code>def poisson_cdf():
    # this is just for illustration, clearly wont work
    return scipy.stats.poisson.cdf(pl.col(&quot;count&quot;), pl.col(&quot;expected_count&quot;)).alias(&quot;poisson_cdf&quot;)
</code></pre>
<p>I also tried using a struct made up of <code>&quot;count&quot;</code> and <code>&quot;expected_count&quot;</code> and apply like advised in the docs when applying custom functions. However, my dataset is several millions of rows in reality - leading to absurd execution time.</p>
<p>Any advice or guidance here would be appreciated. Ideally there exists an expression like this somewhere out there? Thanks in advance!</p>
","2023-01-31 20:55:29","3","Question"
"75302879","75147062","","<blockquote>
<p>Why can't I just select the top len(select_X_train) most important features from model.feature_importances_ and use this subset of the test set for prediction?</p>
</blockquote>
<p>Because choosing the top &quot;len(select_X_train)&quot; features like <code>X_train[:, :len(select_X_train)]</code> (which really should be <code>X_train[:, :select_X_train.shape[1]]</code> since <code>len</code> returns the number of rows) does not give you the top most important features! That's why your model performance was worse.</p>
<p>Why not? Because the features in <code>X_train</code> aren't sorted by importance (from highest to lowest), they're in the order you loaded them in.</p>
<p>How do you get the most important features from the <code>SelectFromModel</code> object? Well, you can use the <code>get_support()</code> method. Look at the case where <code>thresh &lt;= 0.13577053</code> or <code>n=3</code>.</p>
<pre><code>print(selection.get_support())

# Returns the features to choose from the range(X_train.shape[1])
[False  True False False False  True False  True]
</code></pre>
<p>If you take the first &quot;<code>n=select_X_train.shape[1]</code>&quot; features, you take the first <code>n</code> features in your dataset. For <code>X_test</code> that would be</p>
<pre><code>[[102.   30.8  26. ]
 [ 77.   33.3  24. ]
 [124.   35.4  34. ]
 [111.   30.1  23. ]
 [108.   30.8  21. ]]
</code></pre>
<p>To get the correct features, you'd have to do</p>
<pre><code>print(X_test[:5, selection.get_support()]) # prints first 5 rows

[[ 90.   27.2  24. ]
 [181.   35.9  51. ]
 [152.   26.8  43. ]
 [ 93.   28.7  23. ]
 [125.   27.6  49. ]]
</code></pre>
<p>But that's what the <code>transform</code> function does for you. The line</p>
<pre><code>select_X_test = selection.transform(X_test)

print(&quot;Transformed select_X_test&quot;)
print(select_X_test[:5,:])

Transformed select_X_test: 
[[ 90.   27.2  24. ]
 [181.   35.9  51. ]
 [152.   26.8  43. ]
 [ 93.   28.7  23. ]
 [125.   27.6  49. ]]
</code></pre>
<p><code>selection</code> saves the features chosen when <code>SelectFromModel</code> is run on <code>X_train</code> and then selects those features when you apply to <code>X_test</code>. Hence the line</p>
<pre><code>select_X_test = selection.transform(X_test)
</code></pre>
","2023-01-31 20:38:38","1","Answer"
"75300585","75299046","","<p>As has been determined elsewhere, the problem is due to the implementation's <code>RAND_MAX</code> value being too small.</p>
<p>Assuming 32-bit <code>int</code>s, a slightly better PRNG function can be implemented in the code, such as this C implementation of the <code>minstd_rand()</code> function from C++:</p>
<pre><code>#define MINSTD_RAND_MAX 2147483646

// Code assumes `int` is at least 32 bits wide.

static unsigned int minstd_seed = 1;

static void minstd_srand(unsigned int seed)
{
    seed %= 2147483647;
    // zero seed is bad!
    minstd_seed = seed ? seed : 1;
}

static int minstd_rand(void)
{
    minstd_seed = (unsigned long long)minstd_seed * 48271 % 2147483647;
    return (int)minstd_seed;
}
</code></pre>
<p>Another problem is that expressions of the form <code>rand() % m</code> produce a biased result when <code>m</code> does not divide <code>(unsigned int)RAND_MAX + 1</code>. Here is an unbiased function that returns a random integer from 0 to <code>le</code> inclusive, making use of the <code>minstd_rand()</code> function defined earlier:</p>
<pre><code>static int minstd_rand_max(int le)
{
    int r;

    if (le &lt; 0)
    {
        r = le;
    }
    else if (le &gt;= MINSTD_RAND_MAX)
    {
        r = minstd_rand();
    }
    else
    {
        int lt = le + 1;
        int rdiv = MINSTD_RAND_MAX / lt;
        int rmin = MINSTD_RAND_MAX % lt + 1;

        if (rmin == lt)
        {
            rmin = 0;
        }
        do
        {
            r = minstd_rand();
        }
        while (r &lt; rmin);
        r = (r - rmin) / rdiv;
    }
    return r;
}
</code></pre>
<p>(Actually, it does still have a very small bias because <code>minstd_rand()</code> will never return 0.)</p>
<p>For example, replace <code>rand() % 100</code> with <code>minstd_rand_max(99)</code>, and replace <code>rand() % m</code> with <code>minstd_rand_max(m - 1)</code>. Also replace <code>srand(random_seed)</code> with <code>minstd_srand(random_seed)</code>.</p>
<hr />
<p><strong>EDIT 2024-06-11</strong></p>
<p>Since <code>minstd_rand()</code> never returns <code>0</code>, it only returns <code>MINSTD_RAND_MAX</code> (<code>214748646</code>) possible values from <code>1</code> to <code>MINSTD_RAND_MAX</code>, resulting in a small bias from the <code>minstd_rand_max(int le)</code> function.</p>
<p>To solve this problem, renamed and slightly modified versions of the functions are presented below. <code>int my_rand()</code> returns a pseudorandom number from <code>0</code> to <code>MY_RAND_MAX</code> inclusive, where <code>MY_RAND_MAX</code> is <code>214783645</code> (one less than the previous <code>MINSTD_RAND_MAX</code>). <code>void my_srand(unsigned int seed)</code> sets a seed variable <code>my_seed</code> to a value in the range <code>1</code> to <code>MY_RAND_MAX+1</code> inclusive. <code>int my_rand_max(int le)</code> returns an unbiased pseudorandom number in the range <code>0</code> to <code>le</code> inclusive as long as <code>le</code> is in the range <code>0</code> to <code>MY_RAND_MAX</code> inclusive. If <code>le &lt; 0</code> it returns <code>le</code>. If <code>le &gt; MY_RAND_MAX</code> it returns <code>my_rand()</code> (so values from <code>MY_RAND_MAX+1</code> to <code>le</code> inclusive will never be returned).</p>
<pre><code>#define MY_RAND_MAX 2147483645

// Code assumes `int` is at least 32 bits wide.

static unsigned int my_seed = 1;

void my_srand(unsigned int seed)
{
    my_seed = seed % (MY_RAND_MAX + 1) + 1;
}

int my_rand(void)
{
    my_seed = (unsigned long long)my_seed * 48271 % (MY_RAND_MAX + 2);
    return (int)(my_seed - 1);
}

int my_rand_max(int le)
{
    int r;

    if (le &lt; 0)
    {
        r = le;
    }
    else if (le &gt;= MY_RAND_MAX)
    {
        r = my_rand();
    }
    else
    {
        int lt = le + 1;
        int rdiv = MY_RAND_MAX / lt;
        int rmin = MY_RAND_MAX % lt + 1;

        if (rmin == lt)
        {
            rmin = 0;
        }
        do
        {
            r = my_rand();
        }
        while (r &lt; rmin);
        r = (r - rmin) / rdiv;
    }
    return r;
}
</code></pre>
","2023-01-31 17:03:57","1","Answer"
"75300301","","ValueError: 'logits' and 'labels' must have the same shape for NLP sentiment multi-class classifier","<p>I am trying to make a NLP multi-class sentiment classifier where it takes in sentences as input and classifies them into three classes (negative, neutral and positive). However, when training the model, I run into the error where my logits (None, 3) are not the same size as my labels (None, 1) and the model can't begin training.</p>
<p>My model is a multi-class classifier and not a multi-label classifier since it is only predicting one label per object. I made sure that my last layer had an output of 3 and had the activation = 'softmax'. This should be correct from what I have searched online so I think that the problem lies with my labels.</p>
<p>Currently, my labels have a dimension of (None, 1) since I mapped each class to a unique integer and passed this as my test and train y values (which are in the form of  one dimensional numpy array.</p>
<p>Right now I am confused if I have change the dimensions of this array to match the output dimensions and how to go about doing it.</p>
<pre><code>import os
import sys
import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.optimizers import SGD

device_name = tf.test.gpu_device_name()
if len(device_name) &gt; 0:
    print(&quot;Found GPU at: {}&quot;.format(device_name))
else:
    device_name = &quot;/device:CPU:0&quot;
    print(&quot;No GPU, using {}.&quot;.format(device_name))
</code></pre>
<pre><code># Load dataset into a dataframe
train_data_path = &quot;/content/drive/MyDrive/ML Datasets/tweet_sentiment_analysis/train.csv&quot;
test_data_path = &quot;/content/drive/MyDrive/ML Datasets/tweet_sentiment_analysis/test.csv&quot;

train_df = pd.read_csv(train_data_path, encoding='unicode_escape')
test_df = pd.read_csv(test_data_path, encoding='unicode_escape').dropna()
</code></pre>
<pre><code>sentiment_types = ('neutral', 'negative', 'positive')

train_df['sentiment'] = train_df['sentiment'].astype('category')
test_df['sentiment'] = test_df['sentiment'].astype('category')

train_df['sentiment_cat'] = train_df['sentiment'].cat.codes
test_df['sentiment_cat'] = test_df['sentiment'].cat.codes

train_y = np.array(train_df['sentiment_cat'])
test_y = np.array(test_df['sentiment_cat'])
</code></pre>
<pre><code># Function to convert df into a list of strings
def convert_to_list(df, x):
  selected_text_list = []
  labels = []

  for index, row in df.iterrows():
    selected_text_list.append(str(row[x]))
    labels.append(str(row['sentiment']))
  
  return np.array(selected_text_list), np.array(labels)


train_sentences, train_labels = convert_to_list(train_df, 'selected_text')
test_sentences, test_labels = convert_to_list(test_df, 'text')

# Instantiate tokenizer and create word_index
tokenizer = Tokenizer(num_words=1000, oov_token='&lt;oov&gt;')
tokenizer.fit_on_texts(train_sentences)
word_index = tokenizer.word_index

# Convert sentences into a sequence 
train_sequence = tokenizer.texts_to_sequences(train_sentences)
test_sequence = tokenizer.texts_to_sequences(test_sentences)

# Padding sequences 
pad_test_seq = pad_sequences(test_sequence, padding='post')
max_len = pad_test_seq[0].size
pad_train_seq = pad_sequences(train_sequence, padding='post', maxlen=max_len)
</code></pre>
<pre><code>model = tf.keras.Sequential([
    tf.keras.layers.Embedding(10000, 64, input_length=max_len),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

with tf.device(device_name):
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>
<pre><code>num_epochs = 10

with tf.device(device_name):
  history = model.fit(pad_train_seq, train_y, epochs=num_epochs, validation_data=(pad_test_seq, test_y), verbose=2)
</code></pre>
<p>Here is the error:</p>
<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-28-62f3c6445887&gt; in &lt;module&gt;
      2 
      3 with tf.device(device_name):
----&gt; 4   history = model.fit(pad_train_seq, train_y, epochs=num_epochs, validation_data=(pad_test_seq, test_y), verbose=2)

1 frames
/usr/local/lib/python3.8/dist-packages/keras/engine/training.py in tf__train_function(iterator)
     13                 try:
     14                     do_return = True
---&gt; 15                     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
     16                 except:
     17                     do_return = False

ValueError: in user code:

    File &quot;/usr/local/lib/python3.8/dist-packages/keras/engine/training.py&quot;, line 1051, in train_function  *
        return step_function(self, iterator)
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/engine/training.py&quot;, line 1040, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/engine/training.py&quot;, line 1030, in run_step  **
        outputs = model.train_step(data)
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/engine/training.py&quot;, line 890, in train_step
        loss = self.compute_loss(x, y, y_pred, sample_weight)
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/engine/training.py&quot;, line 948, in compute_loss
        return self.compiled_loss(
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py&quot;, line 201, in __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/losses.py&quot;, line 139, in __call__
        losses = call_fn(y_true, y_pred)
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/losses.py&quot;, line 243, in call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/losses.py&quot;, line 1930, in binary_crossentropy
        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),
    File &quot;/usr/local/lib/python3.8/dist-packages/keras/backend.py&quot;, line 5283, in binary_crossentropy
        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)

    ValueError: `logits` and `labels` must have the same shape, received ((None, 3) vs (None, 1)).
</code></pre>
","2023-01-31 16:38:52","1","Question"
"75300294","75299046","","<p>Since <code>RAND_MAX</code> may be <a href=""https://stackoverflow.com/a/75299859/2410359"">too small</a> and array indexing should be done using <code>size_t</code> math, consider a helper function to generate a random index over the entire <code>size_t</code> range.</p>
<pre><code>// idx = rand() % m;
size_t idx = rand_size_t() % (size_t)m;
</code></pre>
<hr />
<p>If stuck with the standard <code>rand()</code>, below is a helper function to extend its range as needed.<br />
It uses the real nifty <a href=""https://stackoverflow.com/a/4589384/2410359""><code>IMAX_BITS(m)</code></a>.</p>
<pre><code>#include &lt;assert.h&gt;
#include &lt;limits.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdlib.h&gt;

// https://stackoverflow.com/a/4589384/2410359
/* Number of bits in inttype_MAX, or in any (1&lt;&lt;k)-1 where 0 &lt;= k &lt; 2040 */
#define IMAX_BITS(m) ((m)/((m)%255+1) / 255%255*8 + 7-86/((m)%255+12))

// Test that RAND_MAX is a power of 2 minus 1
_Static_assert((RAND_MAX &amp; 1) &amp;&amp; ((RAND_MAX/2 + 1) &amp; (RAND_MAX/2)) == 0, &quot;RAND_MAX is not a Mersenne number&quot;);

#define RAND_MAX_WIDTH (IMAX_BITS(RAND_MAX))
#define SIZE_MAX_WIDTH (IMAX_BITS(SIZE_MAX))

size_t rand_size_t(void) {
  size_t index = (size_t) rand();
  for (unsigned i = RAND_MAX_WIDTH; i &lt; SIZE_MAX_WIDTH; i += RAND_MAX_WIDTH) {
      index &lt;&lt;= RAND_MAX_WIDTH;
      index ^= (size_t) rand();
  }
  return index;
}
</code></pre>
<p>Further considerations can replace the <code>rand_size_t() % (size_t)m</code> with a more <a href=""https://stackoverflow.com/q/2509679/2410359"">uniform distribution</a>.</p>
","2023-01-31 16:38:30","2","Answer"
"75299859","75299046","","<p>The issue is here:</p>
<blockquote>
<pre><code>            // Randomly sample an observation
            idx = rand() % m;
</code></pre>
</blockquote>
<p>... in light of the fact that the OP's <code>RAND_MAX</code> is 32767.  This is exacerbated by the fact that all of the class 0 observations are at the end.</p>
<p>All samples will be drawn from the first 32768 observations, and when the total number of observations is greater than that, the proportion of class 0 observations <em>among those that can be sampled</em> is less than 0.25.  At 43691 total observations, there are <strong>no</strong> class 0 observations among those that can be sampled.</p>
<p>As a secondary issue, <code>rand() % m</code> does not yield a wholly uniform distribution if <code>m</code> does not evenly divide <code>RAND_MAX + 1</code>, though the effect of this issue will be much more subtle.</p>
<hr />
<p><strong>Bottom line</strong>: you need a better random number generator.</p>
<p>At minimum, you could consider combining the bits from two calls to <code>rand()</code> to yield an integer with sufficient range, but you might want to consider getting a third-party generator.  There are several available.</p>
","2023-01-31 16:04:18","3","Answer"
"75299175","75299046","","<p>Note: OP reports &quot;m=50,000 observations with n=150 features.&quot;, so perhaps this is not the issue for OP, but I'll leave this answer up for reference when OP tries larger tasks.</p>
<hr />
<p>A potential issue:</p>
<p><strong><code>long</code> overflow</strong></p>
<p><code>m * n * sizeof(double)</code> risks overflow when <code>long</code> is 32-bit and <code>m*n &gt; LONG_MAX</code> (or about 46,341 if <code>m, n</code> are the same).</p>
<p>OP does report</p>
<p>A first step is to perform the multiplication using <code>size_t</code> math where we gain at least 1 more bit in the calculation.</p>
<pre><code>// m * n * sizeof(double)
sizeof(double) * m * n 
</code></pre>
<p>Yet unless OP's <code>size_t</code> is more than 32-bit, we still have trouble.</p>
<p>IAC, I recommend to use <code>size_t</code> for array sizing and indexing.</p>
<hr />
<p>Check allocations for failure too.</p>
","2023-01-31 15:10:46","3","Answer"
"75299046","","Logistic regression code stops working above ~43,500 generated observations","<p>Having some difficulty troubleshooting code I wrote in C to perform a logistic regression. While it seems to work on smaller, semi-randomized datasets, it stops working (e.g. assigning proper probabilities of belonging to class 1) at around the point where I pass 43,500 observations (determined by tweaking the number of observations created. When creating the 150 features used in the code, I do create the first two as a function of the number of observations, so I'm not sure if maybe that's the issue here, though I am using double precision. Maybe there's an overflow somewhere in the code?</p>
<p>The below code should be self-contained; it generates m=50,000 observations with n=150 features. Setting m below 43,500 should return &quot;Percent class 1: 0.250000&quot;, setting to 44,000 or above will return &quot;Percent class 1: 0.000000&quot;, regardless of what max_iter (number of times we sample m observations) is set to.</p>
<p>The first feature is set to 1.0 divided by the total number of observations, if class 0 (first 75% of observations), or the index of the observation divided by the total number of observations otherwise.</p>
<p>The second feature is just index divided by total number of observations.</p>
<p>All other features are random.</p>
<p>The logistic regression is intended to use stochastic gradient descent, randomly selecting an observation index, computing the gradient of the loss with the predicted y using current weights, and updating weights with the gradient and learning rate (eta).</p>
<p>Using the same initialization with Python and NumPy, I still get the proper results, even above 50,000 observations.</p>
<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include &lt;time.h&gt;

// Compute z = w * x + b
double dlc( int n, double *X, double *coef, double intercept )
{
    double y_pred = intercept;
    for (int i = 0; i &lt; n; i++)
    {
        y_pred += X[i] * coef[i];
    }
    return y_pred;
}

// Compute y_hat = 1 / (1 + e^(-z))
double sigmoid( int n, double alpha, double *X, double *coef, double beta, double intercept )
{
    double y_pred;
    y_pred = dlc(n, X, coef, intercept);
    y_pred = 1.0 / (1.0 + exp(-y_pred));

    return y_pred;
}

// Stochastic gradient descent
void sgd( int m, int n, double *X, double *y, double *coef, double *intercept, double eta, int max_iter, int fit_intercept, int random_seed )
{
    double *gradient_coef, *X_i;
    double y_i, y_pred, resid;
    int idx;

    double gradient_intercept = 0.0, alpha = 1.0, beta = 1.0;

    X_i = (double *) malloc (n * sizeof(double));
    gradient_coef = (double *) malloc (n * sizeof(double));

    for ( int i = 0; i &lt; n; i++ )
    {
        coef[i] = 0.0;
        gradient_coef[i] = 0.0;
    }
    *intercept = 0.0;

    srand(random_seed);
    
    for ( int epoch = 0; epoch &lt; max_iter; epoch++ )
    {
        for ( int run = 0; run &lt; m; run++ )
        {
            // Randomly sample an observation
            idx = rand() % m;
            for ( int i = 0; i &lt; n; i++ )
            {
                X_i[i] = X[n*idx+i];
            }
            y_i = y[idx];
            // Compute y_hat
            y_pred = sigmoid( n, alpha, X_i, coef, beta, *intercept );
            resid = -(y_i - y_pred);
            // Compute gradients and adjust weights
            for (int i = 0; i &lt; n; i++)
            {
                gradient_coef[i] = X_i[i] * resid;
                coef[i] -= eta * gradient_coef[i];
            }
            if ( fit_intercept == 1 )
            {
                *intercept -= eta * resid;
            }
        }
    }
}

int main(void)
{
    double *X, *y, *coef, *y_pred;
    double intercept;
    double eta = 0.05;
    double alpha = 1.0, beta = 1.0;
    long m = 50000;
    long n = 150;
    int max_iter = 20;

    long class_0 = (long)(3.0 / 4.0 * (double)m);
    double pct_class_1 = 0.0;

    clock_t test_start;
    clock_t test_end;
    double test_time;

    printf(&quot;Constructing variables...\n&quot;);
    X = (double *) malloc (m * n * sizeof(double));
    y = (double *) malloc (m * sizeof(double));
    y_pred = (double *) malloc (m * sizeof(double));
    coef = (double *) malloc (n * sizeof(double));

    // Initialize classes
    for (int i = 0; i &lt; m; i++)
    {
        if (i &lt; class_0)
        {
            y[i] = 0.0;
        }
        else
        {
            y[i] = 1.0;
        }
    }

    // Initialize observation features
    for (int i = 0; i &lt; m; i++)
    {
        if (i &lt; class_0)
        {
            X[n*i] = 1.0 / (double)m;
        }
        else
        {
            X[n*i] = (double)i / (double)m;
        }
        X[n*i + 1] = (double)i / (double)m;
        for (int j = 2; j &lt; n; j++)
        {
            X[n*i + j] = (double)(rand() % 100) / 100.0;
        }
    }

    // Fit weights
    printf(&quot;Running SGD...\n&quot;);
    test_start = clock();
    sgd( m, n, X, y, coef, &amp;intercept, eta, max_iter, 1, 42 );
    test_end = clock();
    test_time = (double)(test_end - test_start) / CLOCKS_PER_SEC;
    printf(&quot;Time taken: %f\n&quot;, test_time);

    // Compute y_hat and share of observations predicted as class 1
    printf(&quot;Making predictions...\n&quot;);
    for ( int i = 0; i &lt; m; i++ )
    {
        y_pred[i] = sigmoid( n, alpha, &amp;X[i*n], coef, beta, intercept );
    }

    printf(&quot;Printing results...\n&quot;);
    for ( int i = 0; i &lt; m; i++ )
    {
        //printf(&quot;%f\n&quot;, y_pred[i]);
        if (y_pred[i] &gt; 0.5)
        {
            pct_class_1 += 1.0;
        }
        // Troubleshooting print
        if (i &lt; 10 || i &gt; m - 10)
        {
            printf(&quot;%g\n&quot;, y_pred[i]);
        }
    }
    printf(&quot;Percent class 1: %f&quot;, pct_class_1 / (double)m);

    return 0;
}
</code></pre>
<p>For reference, here is my (presumably) equivalent Python code, which returns the correct percent of identified classes at more than 50,000 observations:</p>
<pre><code>import numpy as np
import time

def sigmoid(x):
    return 1 / (1 + np.exp(-x))


class LogisticRegressor:
    def __init__(self, eta, init_runs, fit_intercept=True):
        self.eta = eta
        self.init_runs = init_runs
        self.fit_intercept = fit_intercept
    
    def fit(self, x, y):
        m, n = x.shape
        self.coef = np.zeros((n, 1))
        self.intercept = np.zeros((1, 1))
        
        for epoch in range(self.init_runs):
            for run in range(m):
                idx = np.random.randint(0, m)
                x_i = x[idx:idx+1, :]
                y_i = y[idx]
                y_pred_i = sigmoid(x_i.dot(self.coef) + self.intercept)
                gradient_w = -(x_i.T * (y_i - y_pred_i))
                self.coef -= self.eta * gradient_w
                if self.fit_intercept:
                    gradient_b = -(y_i - y_pred_i)
                    self.intercept -= self.eta * gradient_b
        
    def predict_proba(self, x):
        m, n = x.shape
        y_pred = np.ones((m, 2))
        y_pred[:,1:2] = sigmoid(x.dot(self.coef) + self.intercept)
        y_pred[:,0:1] -= y_pred[:,1:2]
        return y_pred
    
    def predict(self, x):
        return np.round(sigmoid(x.dot(self.coef) + self.intercept))
    

m = 50000
n = 150
class1 = int(3.0 / 4.0 * m)

X = np.random.rand(m, n)
y = np.zeros((m, 1))

for obs in range(m):
    if obs &lt; class1:
        continue
    else:
        y[obs,0] = 1

for obs in range(m):
    if obs &lt; class1:
        X[obs, 0] = 1.0 / float(m)
    else:
        X[obs, 0] = float(obs) / float(m)
    X[obs, 1] = float(obs) / float(m)

logit = LogisticRegressor(0.05, 20)
start_time = time.time()
logit.fit(X, y)
end_time = time.time()
print(round(end_time - start_time, 2))
y_pred = logit.predict(X)
print(&quot;Percent:&quot;, y_pred.sum() / len(y_pred))
</code></pre>
","2023-01-31 15:00:25","2","Question"
"75290165","75147062","","<p>I wanted to recreate the same behavior and did the pipeline as you mentionned.</p>
<p>the pipeline :</p>
<pre><code>import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=&quot;,&quot;)
X = dataset[:,0:8]
Y = dataset[:,8]
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)
model = XGBClassifier()
model.fit(X_train, y_train)
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print(&quot;Accuracy: %.2f%%&quot; % (accuracy * 100.0))
thresholds = sorted(model.feature_importances_, reverse=True)
</code></pre>
<p>after training the first model i used the two methods to extract the features
the first method as below :</p>
<pre><code>for thresh in thresholds:
    # select features using threshold
    selection = SelectFromModel(model, threshold=thresh, prefit=True)
    select_X_train = selection.transform(X_train)
    # train model
    selection_model = XGBClassifier(random_state=7)
    selection_model.fit(select_X_train, y_train)
    # eval model
    select_X_test = selection.transform(X_test)
    predictions = selection_model.predict(select_X_test)
    accuracy = accuracy_score(y_test, predictions)
    print(&quot;Thresh=%.3f, n=%d, Accuracy: %.2f%%&quot; % (thresh, select_X_train.shape[1], accuracy*100.0))
</code></pre>
<p>which gave me the following accuracies : 67.32% =&gt; 71.26% =&gt; 71.26% =&gt; 74.80% =&gt; 74.41% =&gt; 71.26% =&gt;  71.65% =&gt; 74.02%.</p>
<p>after that i test to manually create the train and test set without the SelectFromModel</p>
<pre><code>for thresh in range(8):
    mask_of_the_column_to_use = (model.feature_importances_.argsort() &lt;= thresh)
    data_with_choosen_columns = X_train[:,model.feature_importances_.argsort() &lt;= thresh].copy()
    selection_model = XGBClassifier(random_state=7)
    selection_model.fit(data_with_choosen_columns, y_train)
    # eval model
    select_X_test = X_test[:,model.feature_importances_.argsort() &lt;= thresh].copy()
    predictions = selection_model.predict(select_X_test)
    accuracy = accuracy_score(y_test, predictions)
    print(&quot;Thresh=%.3f, n=%d, Accuracy: %.2f%%&quot; % (thresh, select_X_train.shape[1], accuracy*100.0))
</code></pre>
<p>which gave me the following accuracies : 67.32% =&gt; 64.57% =&gt; 69.69% =&gt; 68.90% =&gt; 69.69% =&gt; 70.47% =&gt; 70.08% =&gt; 74.02%</p>
<p>so there is a small variation in the accuracy. furthermore when we add columns we converge to the same results.</p>
","2023-01-30 21:08:58","1","Answer"
"75288510","75273843","","<p>I succeeded to find the solution. In fact, I was looking to get back the original(since I had 4 columns so I thought I should get these columns back) columns as they were before the OneHotEnoder, which is not generally POSSIBLE. In my case I have ,for each cat_train columns, a different modality(more than one) so the result after a OneHotEncoder must be a more columns than before. So, and based on this, I ve regenerated the code as follow:</p>
<pre><code>feats = df.drop([&quot;Transported&quot;], axis=1)  
target = df[&quot;Transported&quot;]

X_train, X_test, y_train, y_test = train_test_split(feats, target, 
test_size = 0.2, random_state=42)
</code></pre>
<p>Separate numeric columns from categorical columns</p>
<pre><code>import numpy as np
num_train = X_train.select_dtypes(include=[np.number])
cat_train = X_train.select_dtypes(exclude=[np.number])
num_test = X_test.select_dtypes(include=[np.number])
cat_test = X_test.select_dtypes(exclude=[np.number])
</code></pre>
<p>Fill in missing values</p>
<pre><code>num_imp = SimpleImputer(strategy='median')
num_train = num_imp.fit_transform(num_train)
num_test = num_imp.transform(num_test)
cat_imp = SimpleImputer(strategy='most_frequent')
cat_train = cat_imp.fit_transform(cat_train)
cat_test = cat_imp.transform(cat_test)
</code></pre>
<p>Encode categorical variables</p>
<pre><code>cat_enc = OneHotEncoder(handle_unknown='ignore')
cat_train = cat_enc.fit_transform(cat_train)
cat_test = cat_enc.transform(cat_test)
</code></pre>
<p>And Now the magic part; Reconstitute training and test sets</p>
<pre><code>X_train = pd.concat([pd.DataFrame(num_train), 
pd.DataFrame(cat_train.toarray())], axis=1)

X_test = pd.concat([pd.DataFrame(num_test), 
pd.DataFrame(cat_test.toarray())], axis=1)
</code></pre>
<p>the dataframe is now as it should be</p>
<pre><code>X_train.head()

    0   1   2   3   4   5   0   1   2   3   4   5   6   7   8   9
0   28.0    0.0 55.0    0.0 656.0   0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0  0.0
1   17.0    0.0 1195.0  31.0    0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
2   28.0    0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0
3   20.0    0.0 2.0 289.0   976.0   0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
4   36.0    0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0
</code></pre>
","2023-01-30 18:14:31","1","Answer"
"75288338","75222558","","<p>This open issue is being resolved by the MindsDB engineering team, and will be fixed in the next release (24-48hrs).</p>
","2023-01-30 17:57:38","1","Answer"
"75287205","75212292","","<p>If you have problems downloading/extracting the files via tfds.load i strongly recommend to download them locally via:</p>
<p><a href=""https://magenta.tensorflow.org/datasets/nsynth#files"" rel=""nofollow noreferrer"">https://magenta.tensorflow.org/datasets/nsynth#files</a></p>
<p>Here you can choose the package you need and extract them locally yourself.</p>
","2023-01-30 16:19:46","0","Answer"
"75282840","","use trial.suggest_int to pick values from given list in optuna, just like trial.suggest_categorical does","<p>I'm working with optuna for hyperparameter tuning of ML models in Python. While defining the objective function for tuning a Deep Learning model I tried to define a list of choices from which the <code>trail.suggest_int</code> can pick up values from.
<strong>For example</strong> -</p>
<pre><code>'batch_size': trial.suggest_int('batch_size', [16, 32, 64, 128, 256])
</code></pre>
<p>optuna documentation suggest that <code>trial.suggest_int</code> should be in the following format</p>
<pre><code>'some_param': trial.suggest_int('some_param', low, high, step)
</code></pre>
<p>my code looks something like below</p>
<pre><code>def objective(trial):
        DL_param = {
            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),
            'optimizer': trial.suggest_categorical('optimizer', [&quot;Adam&quot;, &quot;RMSprop&quot;, &quot;SGD&quot;]),
            'h_units': trial.suggest_int('h_units', 50, 250, step = 50),
            'alpha': trial.suggest_float('alpha', [0.001,0.01, 0.1, 0.2, 0.3]),
            'batch_size': trial.suggest_int('batch_size', [16, 32, 64, 128, 256]),
        }
        DL_model = build_model(DL_param)
        DL_model.compile(optimizer=DL_param['optimizer'], loss='mean_squared_error')
        DL_model.fit(x_train, y_train, validation_split = 0.3, shuffle = True,
                                  batch_size = DL_param['batch_size'], epochs = 30)
        y_pred_2 = DL_model.predict(x_test)
        return mse(y_test_2, y_pred_2, squared=True)
</code></pre>
<p>I'm facing problem in defining a list for the parameters <code>'alpha'</code> and <code>'batch_size'</code>. Is there a way? something like <code>trial.suggest_categorical</code> can pick strings from the given list like in the above code</p>
<pre><code>'optimizer': trial.suggest_categorical('optimizer', [&quot;Adam&quot;, &quot;RMSprop&quot;, &quot;SGD&quot;])
</code></pre>
<p>Any suggestions are welcome. Thanks in advance.</p>
","2023-01-30 10:06:22","7","Question"
"75278655","75275501","","<p>There can be several reasons why the test accuracy didn't change after using GridSearchCV:</p>
<p>The best parameters found by GridSearchCV might not be optimal for the test data.</p>
<p>The test data may have a different distribution than the training data, leading to low test accuracy.</p>
<p>The models might be overfitting to the training data and not generalizing well to the test data.</p>
<p>The test data size might be small, leading to high variance in test accuracy scores.</p>
<p>The problem itself might be challenging, and a test accuracy of 0.508 might be the best that can be achieved with the current models and data.</p>
<p>It would be useful to have more information about the data, the problem, and the experimental setup to diagnose the issue further.</p>
","2023-01-29 21:53:24","1","Answer"
"75278641","75275501","","<p>Looking at your accuracy, first of all I would say: are you performing a binary classification task? Because if it is the case, your models are almost not better than random on the test set, which may suggest that something is wrong with your training.</p>
<p>Otherwise, <code>GridSearchCV</code>, like <code>RandomSearchCV</code> and other hyperparameters optimization techniques try to find optimal parameters <strong>among a range that you define</strong>. If, after optimization, your optimal parameter has the value of one bound of your range, it may suggest that you need to explore beyond this bound, that is to say set another range on purpose and run the optimization again.</p>
<p>By the way, I don't know the size of your dataset but if it is big I would recommend you to use <code>RandomSearchCV</code> instead of <code>GridSearchCV</code>. As it is not exhaustive, it takes less time and gives results that are (nearly) optimized.</p>
","2023-01-29 21:51:13","2","Answer"
"75278420","75273843","","<p>The first error is because you try to assign the one-hot-encoded data, which has more columns than the original, back to the same original columns.  You need to instead add these dummy columns and delete the original ones.  Anyway, applying <code>fit_transform</code> to both train and test (assuming the repeated <code>train</code> row is a typo) is a bad idea.</p>
<p>The second error appears to be due to the one-hot-encoded data being sparse.  You can specify <code>sparse=False</code> in the <code>OneHotEncoder</code> to fix that, but then probably you'll have the same issue as above.</p>
<p>The best thing to do is to use a <code>ColumnTransformer</code>; it would handle all the concatenation for you.</p>
","2023-01-29 21:11:35","0","Answer"
"75276602","75276506","","<p>if you have pip installed it, there is no way that it will not work. Unless you've installed it to a virtual environment and running your program without it and vice versa. Or you've installed to a different version of python on your system.</p>
","2023-01-29 16:46:12","-1","Answer"
"75276552","75276506","","<p>You need to verify that you are using the same version of python that you did <code>pip install</code> with. In VS Code, you can select the Python version in the upper right corner. Simply type &quot;python --version&quot; into the console to verify the version. You might want to use Anaconda because someone libraries like Tensorflow only fully-support Anaconda.</p>
","2023-01-29 16:39:00","0","Answer"
"75276506","","Why doesn't import gym work; however, the command pip install gym was done and executed","<p>I have went to the terminal and used,&quot;pip install gym&quot;, and it successfully installed gym .  When I go to use the, &quot;import gym,&quot; command, I get an error when running the code at that line.</p>
<pre><code>Exception has occurred: ModuleNotFoundError
No module named 'gym'
</code></pre>
<p>I have looked at other posts and they all say it should work after ruining,&quot;pip install gym.&quot; Although mine successfully installed, it still doesn't work.</p>
","2023-01-29 16:32:41","1","Question"
"75275895","75275501","","<p>I would like to confirm, you mean your training scores improve but you testing scores did not change? If yes, there are a lot of possibility behind this.</p>
<ul>
<li>You might want to reconfigure and add your hyper parameter range for example if using KNN you can increase the number of k or by adding more distance metric calculation</li>
<li>If you want to you can change the hyper parameter optimization technique like randomized search or bayesian search</li>
<li>I don't have any information about your data but sometimes turn on or turn off the shuffle mode when splitting can affect the scores for instance if you have time series data you have not to shuffle the dataset</li>
</ul>
","2023-01-29 15:03:11","1","Answer"
"75275501","","GridSearchCV does not improve my test accuracy","<p>I am making multiple classifier models and the test accuracy for all of them is 0.508.</p>
<p>I find it weird that multiple models have the same accuracy. The models I used are Logistic Regressor,DesicionTreeClassifier, MLPClassifier, RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, XGBClassifier, SVC, and VotingClassifier.</p>
<p>After using GridSearchCV to improve the models, all of their test accuracy scores improved. But the test accuracy scores did not change.</p>
<p>I wish I could say I changed something, but I don't know why the test scores did not change. After using gridsearch, I expected the test scores to improve but it didn't</p>
","2023-01-29 14:04:42","-2","Question"
"75275318","75274978","","<blockquote>
<p>I've applied data augmentation (on the train data).</p>
</blockquote>
<p>What does this mean? What kind of data did you add and how much? You might think I'm nitpicking, but if the distribution of the augmented data is different enough from the original data, then this will indeed cause your model to generalize poorly to the validation set.</p>
<p>Increasing your epochs isn't going to help here, your training loss is already decreasing reasonably. Training your model for longer is a good step if the validation loss is also decreasing nicely, but that's obviously not the case.</p>
<p>Some things I would personally try:</p>
<ol>
<li>Try decreasing the learning rate.</li>
<li>Try training the model without the augmented data and see how the validation loss behaves.</li>
<li>Try splitting the augmented data so that it's also contained in the validation set and see how the model behaves.</li>
</ol>
","2023-01-29 13:37:08","0","Answer"
"75275049","75274978","","<blockquote>
<p>Train part looks good. Validation part has a lot of 'jumps' though. Does it overfit?</p>
</blockquote>
<p>the answer is yes. The so-called 'jumps' in the validation part may indicate that the model is not generalizing well to the validation data and therefore your model might be overfitting.</p>
<blockquote>
<p>Is there any way to fix this and make validation part more stable?</p>
</blockquote>
<p>To fix this you can use the following:</p>
<ul>
<li>Increasing the size of your training set</li>
<li>Regularization techniques</li>
<li>Early stopping</li>
<li>Reduce the complexity of your model</li>
<li>Use different hyperparameters like learning rate</li>
</ul>
","2023-01-29 12:54:46","1","Answer"
"75274978","","Validation loss and accuracy has a lot of 'jumps'","<p>Hello everyone so I made this cnn model.</p>
<p>My data:</p>
<p>Train folder-&gt;30 classes-&gt;800 images each-&gt;24000 all together</p>
<p>Validation folder-&gt;30 classes-&gt;100 images each-&gt;3000 all together</p>
<p>Test folder-&gt;30 classes -&gt; 100 images each -&gt; 3000 all together</p>
<p>-I've applied data augmentation. ( on the train data)</p>
<p>-I got 5 conv layers with filters 32-&gt;64-&gt;128-&gt;128-&gt;128<br />
each with maxpooling and batch normalization</p>
<p>-Added dropout 0.5 after flattening layers</p>
<p>Train part looks good. Validation part has a lot of 'jumps' though. Does it overfit?<br />
Is there any way to fix this and make validation part more stable?</p>
<p>Note: I plann to increase epochs on my final model I'm just experimenting to see what works best since the model takes a lot of time in order to train. So for now I train with 20 epochs.</p>
<p><a href=""https://i.sstatic.net/WXTCE.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/WXTCE.png"" alt=""enter image description here"" /></a></p>
","2023-01-29 12:43:35","2","Question"
"75273987","","Wrong offsets when displaying multiple VNRecognizedObjectObservation boundingBoxes using SwiftUI","<p>I am using Vision to detect objects and after getting <code>[VNRecognizedObjectObservation]</code> I transform the normalized rects before showing them:</p>
<pre><code>let transform = CGAffineTransform(scaleX: 1, y: -1).translatedBy(x: 0, y: -CGFloat(height))
VNImageRectForNormalizedRect(normalizedRect, width, height) // Displayed with SwiftUI, that's why I'm applying transform
    .applying(transform)
</code></pre>
<p>The width and height are from SwiftUI GeometryReader:</p>
<pre><code>Image(...)
    .resizable()
    .scaledToFit()
    .overlay {
        GeometryReader { geometry in // ZStack and ForEach([VNRecognizedObjectObservation], id: \.uuid), then:
            let calculatedRect = calculateRect(boundingBox, geometry)
            Rectangle()
                .frame(width: calculatedRect.width, height: calculatedRect.height)
                .offset(x: calculatedRect.origin.x, y: calculatedRect.origin.y)
        }
    }
</code></pre>
<p>But the problem is many boxes are positioned incorrectly (while some are accurate) even on on square images.</p>
<p>This is not related to model because the same images (using same MLModel) have pretty accurate BBs when I try them in Xcode Model Preview section.</p>
<p><strong>Sample Image in my App:</strong></p>
<p><img src=""https://i.sstatic.net/XGRP4.jpg"" alt=""Sample Image on my App"" /></p>
<p><strong>Sample Image in Xcode Preview:</strong></p>
<p><img src=""https://i.sstatic.net/BU05L.jpg"" alt=""Sample Image in Xcode Preview"" /></p>
<hr />
<h3>Update (Minimal Reproducible Example):</h3>
<p>Having this code inside <code>ContentView.swift</code> as a <code>macOS SwiftUI</code> project while having <a href=""https://ml-assets.apple.com/coreml/models/Image/ObjectDetection/YOLOv3Tiny/YOLOv3Tiny.mlmodel"" rel=""nofollow noreferrer"">YOLOv3Tiny.mlmodel</a> in project bundle will produce the same results.</p>
<pre><code>import SwiftUI
import Vision
import CoreML

class Detection: ObservableObject {
    let imgURL = URL(string: &quot;https://i.imgur.com/EqsxxTc.jpg&quot;)! // Xcode preview generates this: https://i.imgur.com/6IPNQ8b.png
    @Published var objects: [VNRecognizedObjectObservation] = []

    func getModel() -&gt; VNCoreMLModel? {
        if let modelURL = Bundle.main.url(forResource: &quot;YOLOv3Tiny&quot;, withExtension: &quot;mlmodelc&quot;) {
            if let mlModel = try? MLModel(contentsOf: modelURL, configuration: MLModelConfiguration()) {
                return try? VNCoreMLModel(for: mlModel)
            }
        }
        return nil
    }

    func detect() async {
        guard let model = getModel(), let tiff = NSImage(contentsOf: imgURL)?.tiffRepresentation else {
            fatalError(&quot;Either YOLOv3Tiny.mlmodel is not in project bundle, or image failed to load.&quot;)
            // YOLOv3Tiny: https://ml-assets.apple.com/coreml/models/Image/ObjectDetection/YOLOv3Tiny/YOLOv3Tiny.mlmodel
        }
        let request = VNCoreMLRequest(model: model) { (request, error) in
            DispatchQueue.main.async {
                self.objects = (request.results as? [VNRecognizedObjectObservation]) ?? []
            }
        }
        try? VNImageRequestHandler(data: tiff).perform([request])
    }

    func deNormalize(_ rect: CGRect, _ geometry: GeometryProxy) -&gt; CGRect {
        let transform = CGAffineTransform(scaleX: 1, y: -1).translatedBy(x: 0, y: -CGFloat(geometry.size.height))
        return VNImageRectForNormalizedRect(rect, Int(geometry.size.width), Int(geometry.size.height)).applying(transform)
    }
}

struct ContentView: View {
    @StateObject var detection = Detection()

    var body: some View {
        AsyncImage(url: detection.imgURL) { img in
            img.resizable().scaledToFit().overlay {
                GeometryReader { geometry in
                    ZStack {
                        ForEach(detection.objects, id: \.uuid) { object in
                            let rect = detection.deNormalize(object.boundingBox, geometry)
                            Rectangle()
                                .stroke(lineWidth: 2)
                                .foregroundColor(.red)
                                .frame(width: rect.width, height: rect.height)
                                .offset(x: rect.origin.x, y: rect.origin.y)
                        }
                    }
                }
            }
        } placeholder: {
            ProgressView()
        }
        .onAppear {
            Task { await self.detection.detect() }
        }
    }
}
</code></pre>
<p><strong>Edit:</strong> further testing revealed that VN returns correct positions, and my <code>deNormalize()</code> function also return correct positions and size so it has to be related to SwiftUI.</p>
","2023-01-29 09:48:23","5","Question"
"75273843","","Machine Learning: getting a Dataframe after a OneHotEncoder","<p>I have been stacked on how do I convert back the result of a OneHotEnocder to a DataFrame.The Idea that I have separated numeric columns from categorical columns as follows:</p>
<pre><code>feats = df.drop([&quot;Transported&quot;], axis=1)  
target = df[&quot;Transported&quot;]
</code></pre>
<p>​
from sklearn.model_selection import train_test_split</p>
<pre><code> X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2, 
 random_state=42)
</code></pre>
<p>here after doing the split, I needed to separet the num from cat for training set and i did this:</p>
<pre><code>num_train = X_train.select_dtypes(include=['float64', 'int64'])
cat_train = X_train.select_dtypes(include=['object'])
num_test = X_test.select_dtypes(include=['float64', 'int64'])
cat_test = X_test.select_dtypes(include=['object'])
</code></pre>
<p>After this I did the the Simple imputer and it worked.</p>
<pre><code>imputer_median = SimpleImputer(missing_values=np.nan, strategy='median')
imputer_most_frequent = SimpleImputer(missing_values=np.nan, strategy='most_frequent')

num = [&quot;Age&quot;, &quot;RoomService&quot;, &quot;FoodCourt&quot;, &quot;ShoppingMall&quot;,&quot;Spa&quot;,&quot;VRDeck&quot;]
num_train.loc[:,num] = imputer_median.fit_transform(num_train[num])
num_test.loc[:,num] = imputer_median.transform(num_test[num])

cat = [&quot;HomePlanet&quot;, &quot;CryoSleep&quot;, &quot;Destination&quot;,&quot;VIP&quot;]
cat_train.loc[:,cat] = imputer_most_frequent.fit_transform(cat_train[cat])
cat_test.loc[:,cat] = imputer_most_frequent.transform(cat_test[cat])
</code></pre>
<p>and this the head of  the cat_train:</p>
<pre><code>cat_train.head()
     HomePlanet CryoSleep   Destination VIP
2333    Earth   False   TRAPPIST-1e False
2589    Earth   False   TRAPPIST-1e False
8302    Europa  True    55 Cancri e False
8177    Mars    False   TRAPPIST-1e False
 500    Europa  True    55 Cancri e False
</code></pre>
<p>​
But, after this I needed to apply the OneHotEncoder just like this:</p>
<pre><code>from sklearn.preprocessing import OneHotEncoder
oneh = OneHotEncoder( drop='first',sparse=False)

cat_train.loc[:,cat] = oneh.fit_transform(cat_train[cat])
cat_train.loc[:,cat] = oneh.fit_transform(cat_train[cat])
</code></pre>
<p>And I got this error:</p>
<pre><code>shape mismatch: value array of shape (6954,6) could not be broadcast to indexing result 
of shape (6954,4)
</code></pre>
<p>I tried several ways, but everytime I could not succeed to have a DataFrame back after the OneHotEncoder. Please help me out, I am stacked on this and I cannot continue the rest of the work. Thanks in advance</p>
<p>here is the full traceback error:</p>
<pre><code>ValueError                                Traceback (most recent 
call last)
~\AppData\Local\Temp\ipykernel_16200\2252764984.py in &lt;module&gt;
  3 oneh = OneHotEncoder( drop='first',sparse=False)
  4 
----&gt; 5 cat_train.loc[:,cat] = oneh.fit_transform(cat_train[cat])
  6 cat_train.loc[:,cat] = oneh.fit_transform(cat_train[cat])

~\anaconda3\lib\site-packages\pandas\core\indexing.py in 
__setitem__(self, key, value)
714 
715         iloc = self if self.name == &quot;iloc&quot; else self.obj.iloc
--&gt; 716         iloc._setitem_with_indexer(indexer, value, 
self.name)
717 
718     def _validate_key(self, key, axis: int):

~\anaconda3\lib\site-packages\pandas\core\indexing.py in 
_setitem_with_indexer(self, indexer, value, name)
</code></pre>
<p>1691             self._setitem_with_indexer_split_path(indexer,
value, name)
1692         else:
-&gt; 1693             self._setitem_single_block(indexer, value,
name)
1694
1695     def _setitem_with_indexer_split_path(self, indexer, value,
name: str):</p>
<pre><code>~\anaconda3\lib\site-packages\pandas\core\indexing.py in 
_setitem_single_block(self, indexer, value, name)
1941 
1942         # actually do the set
-&gt; 1943         self.obj._mgr = 
self.obj._mgr.setitem(indexer=indexer, value=value)
 1944         self.obj._maybe_update_cacher(clear=True, 
inplace=True)
 1945 

~\anaconda3\lib\site-packages\pandas\core\internals\managers.py in 
setitem(self, indexer, value)
335         For SingleBlockManager, this backs s[indexer] = value
336         &quot;&quot;&quot;
--&gt; 337         return self.apply(&quot;setitem&quot;, indexer=indexer, 
value=value)
338 
339     def putmask(self, mask, new, align: bool = True):

~\anaconda3\lib\site-packages\pandas\core\internals\managers.py in 
apply(self, f, align_keys, ignore_failures, **kwargs)
302                     applied = b.apply(f, **kwargs)
303                 else:
--&gt; 304                     applied = getattr(b, f)(**kwargs)
305             except (TypeError, NotImplementedError):
306                 if not ignore_failures:

~\anaconda3\lib\site-packages\pandas\core\internals\blocks.py in 
setitem(self, indexer, value)
957         else:
958             value = setitem_datetimelike_compat(values, 
len(values[indexer]), value)
--&gt; 959             values[indexer] = value
960 
961         return self

ValueError: shape mismatch: value array of shape (6954,6) could not 
be broadcast to indexing result of shape (6954,4)
</code></pre>
<p>I tried this time the next move:</p>
<pre><code>from sklearn.preprocessing import OneHotEncoder
oneh = OneHotEncoder(handle_unknown='ignore')

cat_train.loc[:,cat] = oneh.fit_transform(cat_train[cat])
cat_test.loc[:,cat] = oneh.transform(cat_test)
</code></pre>
<p>and I got this dataframe, but this is not what I am looking for:</p>
<pre><code>HomePlanet  CryoSleep   Destination VIP
2333    (0, 0)\t1.0\n (0, 3)\t1.0\n (0, 7)\t1.0\n ...   (0, 
0)\t1.0\n (0, 3)\t1.0\n (0, 7)\t1.0\n ...   (0, 0)\t1.0\n (0, 
3)\t1.0\n (0, 7)\t1.0\n ... (0, 0)\t1.0\n (0, 3)\t1.0\n (0, 
7)\t1.0\n ...
2589    (0, 0)\t1.0\n (0, 3)\t1.0\n (0, 7)\t1.0\n ...   (0, 
0)\t1.0\n (0, 3)\t1.0\n (0, 7)\t1.0\n ...   (0, 0)\t1.0\n (0, 
3)\t1.0\n (0, 7)\t1.0\n ... (0, 0)\t1.0\n (0, 3)\t1.0\n (0, 
7)\t1.0\n ...
</code></pre>
<p>I also used Columntransformer; but It's not getting me back the dataframe I want to(i mean the dataframe with the original columns used before the onehotencoder (look above the cat_train)) this is the steps I did:</p>
<pre><code>from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
ct = ColumnTransformer(
    transformers=[(&quot;OneHotEncoder&quot;, OneHotEncoder(drop='first', 
sparse=False), cat)],
    remainder='passthrough'
)

cat_train = ct.fit_transform(cat_train)
cat_test = ct.transform(cat_test)

cat_train = pd.DataFrame(cat_train, columns=ct.get_feature_names())
cat_test = pd.DataFrame(cat_test, columns=ct.get_feature_names())

cat_train
</code></pre>
<p>and the cat_train.head() I got is :</p>
<pre><code>OneHotEncoder__x0_Europa    OneHotEncoder__x0_Mars  OneHotEncoder__x1_True  OneHotEncoder__x2_PSO J318.5-22 OneHotEncoder__x2_TRAPPIST-1e   OneHotEncoder__x3_True
</code></pre>
<p>0   0.0 0.0 0.0 0.0 1.0 0.0
1   0.0 0.0 0.0 0.0 1.0 0.0
2   1.0 0.0 1.0 0.0 0.0</p>
<p>this is weird because next I need to concatenat the cat_train with num_train and also for the test, and I done this , alot of NAN values will appears, wherease I already imputed all the nan values before. Any Idea?</p>
","2023-01-29 09:24:34","1","Question"
"75273543","75189681","","<p>TSNE is a great way for visualization but it is not good for getting reduced feature space. And even if you are able to do dimensionality reduction effectively (i.e. using PCA with n=3), and you are able to get new features F1, F2 and F3 : It is not easy to find which original features contributed to differentiation between different clusters.</p>
<p>Hi, I agree with @MotaBtw that Silhouette is a good way to measure the feature importances. But I will try to explain the same according to your use case.
By definition, Silhouette score will try to evaluate a clustering run by calculating the difference between mean inter cluster distance and mean intra cluster distance. The more this difference, the better the clustering run.
<a href=""https://i.sstatic.net/2ysvC.png"" rel=""nofollow noreferrer"">See this detailed image</a></p>
<p>We can use the same logic a little differently, where we want to find the contribution of each feature on the silhouette score. The more the contribution of a feature, the important it is.</p>
<p>Created a working algo, and added the code in a github repo, since it was a little lengthy to be added here:
<a href=""https://github.com/vsablok123/silhouette_feature_importance/"" rel=""nofollow noreferrer"">https://github.com/vsablok123/silhouette_feature_importance/</a></p>
<pre><code>def silhouette_feature_importance(X, labels):
&quot;&quot;&quot;
The Silhouette Coefficient is calculated using the mean intra-cluster
distance (a) and the mean nearest-cluster distance (b) for each sample.
The Silhouette Coefficient for a sample is ``(b - a) / max(a, b)``.
To clarrify, b is the distance between a sample and the nearest cluster
that b is not a part of.
The feature importance is inferred by looking at the features which contribute the most
to the silhouette coefficient.
Parameters
----------
X : array [n_samples_a, n_features]
    Feature array.
labels : array, shape = [n_samples]
         label values for each sample
Returns
-------
silhouette : array, shape = [n_features]
    Feature importance for each feature

&quot;&quot;&quot;
n = labels.shape[0]
A = np.array([_intra_cluster_distance(X, labels,i)
              for i in range(n)])
B = np.array([_nearest_cluster_distance(X, labels, i)
              for i in range(n)])
print(f&quot;A shape = {A.shape}&quot;)
print(f&quot;B shape = {B.shape}&quot;)
sil_samples = abs(B - A)
# nan values are for clusters of size 1, and should be 0
return np.mean(np.nan_to_num(sil_samples), axis=0)
</code></pre>
<p><strong>Steps to take for your usecase:</strong></p>
<ol>
<li>Find the highly correlated features before you run clustering on 'scores' and remove them.</li>
<li>Run clustering using any algorithm, but the clustering should be optimized. For e.g. In case of Kmeans, we should find the ideal n_clusters using the elbow method.</li>
<li>Now, pass the clustering output to the silhouette_feature_importance algo to get the top features.</li>
</ol>
<p>Let me know if there is issue in understanding the code.</p>
","2023-01-29 08:27:23","2","Answer"
"75272986","75272187","","<p>Not sure what your underlying data look like, but the error message <code>bool object has no attribute 'any'</code>, suggests something wrong with the way your <code>y</code> object is formatted.  Here's a minimal working example:</p>
<pre><code>import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

N = 100
x = np.random.choice(range(3), size=N)
df = pd.DataFrame({
    'x': x,
    'y1': 3 * x + np.random.normal(size=N),
    'y2': -0.2 * x + np.random.normal(scale=0.2, size=N),
    'y3': -x + 12 + np.random.normal(scale=0.3, size=N)})
print(df.head())

X = df.pop('x').to_numpy().reshape(-1, 1)
reg = LinearRegression().fit(X, df)

preds = reg.predict(X)
print(preds[:5])
print('coefs:', reg.coef_)
print('intercepts:', reg.intercept_)
</code></pre>
","2023-01-29 06:24:04","0","Answer"
"75272664","75272187","","<p>I am not sure about the data that you are using but try reshaping your &quot;x_train&quot; by using x_train.reshape(-1,1) and then fitting this reshaped data to your linear regression.</p>
","2023-01-29 04:48:06","0","Answer"
"75272187","","Python: Predicting vector from a scalar","<p>I am working on a problem where I have to predict a vector <em>y</em> from a scalar <em>x</em>. I am currently using linear regression to create a baseline model. But it does not seem to handle the multi-dimesional output.</p>
<p>I am using the following the code:</p>
<pre><code>from sklearn.linear_model import LinearRegression
lm = LinearRegression()

lm.fit(x_train, y_train)
</code></pre>
<p>In this case, x_train is a column vector of shape <em>(1,m)</em> and y_train is a vector of vectors of shape <em>(m,)</em>.</p>
<p>The error message produced can be seen <a href=""https://i.sstatic.net/3bBJR.png"" rel=""nofollow noreferrer"">here</a>.</p>
<p>I think it has to do something with multi-output parameter. Is there any way to work around this?</p>
","2023-01-29 02:04:07","-1","Question"
"75270011","75252308","","<p>I cannot solve it precisely because I don't have your data, but here are a few observations which should help:</p>
<ul>
<li>apparently <code>x_train_tf</code> has only 7 rows? it's not enough for training a model and it's not 80% of 4401, as you're supposed to obtain from <code>train_test_split</code>.</li>
<li>Note that <code>y_train</code> has 3520 rows = 4401 * 80%, the correct number of rows.</li>
</ul>
<p>I suspect that the line <code>x_train_tf = vectorizer.fit_transform(str(x_train).split('\n')).toarray()</code> is not doing what you think it does. Try to decompose the <code>str(x_train).split('\n')</code> part.</p>
","2023-01-28 18:41:29","0","Answer"
"75262606","75262200","","<p>If I'm not really mistaken, both are the same.
It's common to read <em>fusion</em> as the act of creating an ensemble from a bunch of classifiers - that is the case for the paper you linked.</p>
","2023-01-27 19:34:54","1","Answer"
"75262200","","Ensemble Learning and Fusion","<p><strong>Question - What is the difference (or are they the same) between ensemble learning and classifier fusion?</strong></p>
<p>As I understood, ensemble learning is averaging models when making the final prediction, whereas classifier fusion is also the same in meaning. However, when I'm searching for references on ensemble learning, I don't find any mention of the term 'fusion' in some literature. Besides, some references use these two terms (e.g., <a href=""https://ieeexplore.ieee.org/document/8695622"" rel=""nofollow noreferrer"">https://ieeexplore.ieee.org/document/8695622</a>). Any suggestion/resource is appreciated to my question.</p>
","2023-01-27 18:47:52","-1","Question"
"75259774","","Pytorch mat1 and mat2 must have the same dtype mlp","<p>So i am trying to do a function that trains an mlp using PyTorch.
My code is as follows :</p>
<pre class=""lang-py prettyprint-override""><code>def mlp_gradient_descent(x,y , model , eta = 1e-6 , nb_iter = 30000)  : 

    loss_descent = []
    dtype = torch.float
    device = torch.device(&quot;cpu&quot;)
    x = torch.from_numpy(x)
    y = torch.from_numpy(y)

    params = model.parameters()

    learning_rate = eta
    for t in range(nb_iter):
        y_pred = model(x)
        loss = (y_pred - y).pow(2).sum()
        print(loss)
        if t % 100 == 99:
            print(t, loss.item())
            loss_descent.append([t, loss.item()])
        loss.backward()
        with torch.no_grad():
            for param in params : 
                param -= learning_rat*param.grad
            for param in params : 
                param = None 
</code></pre>
<p>and i m having this error :</p>
<pre class=""lang-markdown prettyprint-override""><code>mat1 and mat2 must have the same dtype
</code></pre>
<p>Note that : The problem comes from the model(x) and x and y are numpy arrays.</p>
<p>Thank you all.
And have a great day.</p>
","2023-01-27 14:54:14","2","Question"
"75257911","75244523","","<p>As mentionned by @nadji mansouri, I would use SIFT technique as it suits your need. But I want just to correct something, CNN is also a thing in this case. This being said, I wouldn't tackle the problem as a classification problem, but rather using Distance Metric Learning, i.e, training a model to generate embeddings that are similar in the space when the inputs are similar, and distant otherwise. But to do this you need a large representative dataset.</p>
<p>In short, I suggest starting with SIFT, using OpenCV, or open source implementations on GitHub, playing around with the parameters and see what fits your case best, and then see if it's really necessary to switch to a neural network, and in this case tackling the problem as a metric learning task, maybe with something like <strong>siamese networks</strong>.</p>
<p><strong>Some definitions:</strong></p>
<p><em><strong>Metric learning</strong></em> is an approach based directly on a distance metric that aims to establish similarity or dissimilarity between data (images in your case). <em><strong>Deep Metric Learning</strong></em> on the other hand uses Neural Networks to automatically learn discriminative features from the data and then compute the metric. <a href=""https://towardsdatascience.com/the-why-and-the-how-of-deep-metric-learning-e70e16e199c0"" rel=""nofollow noreferrer"">source</a>.</p>
<p><em><strong>The Scale-Invariant Feature Transform (SIFT)</strong></em> is a method used in computer vision to detect and describe local features in images. The algorithm is invariant to image scale and rotation, and robust to changes in illumination and affine distortion. SIFT features are represented by local image gradients, which are calculated at various scales and orientations, and are used to identify keypoints in an image. These keypoints and their associated descriptor vectors can then be used for tasks such as image matching, object recognition, and structure from motion. <a href=""https://en.wikipedia.org/wiki/Scale-invariant_feature_transform"" rel=""nofollow noreferrer"">source, with modification</a>.</p>
","2023-01-27 12:10:16","0","Answer"
"75257629","75257564","","<p>You can store the accuracy scores in a list, and then use that list to calculate the mean accuracy at the end</p>
<pre><code>import numpy as np
 n = 10
accuracies = np.zeros(n)
for i in range(n):
    predictions = test_df[['histor', 'philosoph', 'cook', 'roman', 'bibl']].apply(lambda x: baseline.predict(*x), axis=1)
    accuracy = accuracy_score(y_true, predictions)
    accuracies[i] = accuracy
    print(&quot;Run &quot;, i+1, &quot; Accuracy: &quot;, accuracy)

mean_accuracy = np.mean(accuracies)
print(&quot;Mean Accuracy: &quot;, mean_accuracy)
</code></pre>
<p>or</p>
<pre><code>n = 10
accuracies = []
for i in range(n):
    predictions = test_df[['histor', 'philosoph', 'cook', 'roman', 'bibl']].apply(lambda x: baseline.predict(*x), axis=1)
    accuracy = accuracy_score(y_true, predictions)
    accuracies.append(accuracy)
    print(&quot;Run &quot;, i+1, &quot; Accuracy: &quot;, accuracy)

mean_accuracy = sum(accuracies) / n
print(&quot;Mean Accuracy: &quot;, mean_accuracy)
</code></pre>
","2023-01-27 11:41:24","0","Answer"
"75257618","75257564","","<p>I would use sklearns cross_val_score for this:</p>
<pre><code>from sklearn.model_selection import cross_val_score
X = test_df[['histor', 'philosoph', 'cook', 'roman', 'bibl']]
y = test_df[&quot;label&quot;].values
cross_val_score(baseline, X, y, cv=10)
</code></pre>
","2023-01-27 11:40:02","5","Answer"
"75257564","","How to loop and .apply a lambda function on a DataFrame?","<p>I'm building a ML model. I would like to run the prediction bit a few times and then calculate the mean of the accuracy scores.</p>
<p>My code looks like this:</p>
<pre><code>predictions = test_df[['histor', 'philosoph', 'cook', 'roman', 'bibl']].apply(lambda x: baseline.predict(*x), axis=1)

y_true = test_df[&quot;label&quot;].values

print(&quot;Accuracy: &quot;, accuracy_score(y_true, predictions))
</code></pre>
<p>Is there a way to loop the predictions? The desired results would be: let's say n=10. Predictions are run 10 times, I get all the accuracies printed for each run and also the mean of all of them at the end.</p>
<p>Hope this makes sense.</p>
","2023-01-27 11:34:43","0","Question"
"75252308","","why smote raise ""Found input variables with inconsistent numbers of samples""?","<p>I try to classify emotion from tweet with dataset of 4401 tweet, when i use smaller sample of data (around 15 tweet) everything just work fine, but when i use the full dataset it raise the error of</p>
<pre><code>Found input variables with inconsistent numbers of samples: [7, 3520]
</code></pre>
<p>the error happen when i try to oversampling the data using smote after transforming the data using countvectorizer.</p>
<p><strong>This is the code where the error raise</strong></p>
<pre><code># N-gram Feature and Term Frequency
vectorizer = CountVectorizer(ngram_range=(1,3))
x_train_tf = vectorizer.fit_transform(str(x_train).split('\n')).toarray()
x_test_tf = vectorizer.transform(str(x_test).split('\n')).toarray()
df_output = pd.DataFrame(data =x_train_tf, columns = vectorizer.get_feature_names_out())
display(df_output)
# the print shape is (7 rows × 250 columns)

smote = SMOTE(random_state=42, k_neighbors=5)
x_smote, y_smote = smote.fit_resample(x_train_tf, y_train)
print(&quot;Total Train Data SMOTE : &quot;,x_smote.shape), print(&quot;Total Train Label SMOTE : &quot;,y_smote)
</code></pre>
<p>i did not understand why this is happening so some explanation could really help.
i already tried to solve it using answers from other similiar question but nothing have worked.</p>
<p><strong>This is the full code</strong></p>
<pre><code>import nltk
import re
#nltk.download()
import string
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
from nltk import everygrams
from collections import Counter
from sklearn import preprocessing
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from imblearn.over_sampling import SMOTE
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix

dataset = pd.read_csv(&quot;G:/TA/Program/dataset/Twitter_Emotion_Dataset.csv&quot;, encoding='latin-1')
# Preprocessing
dataset['case_folding_tweet'] = dataset['tweet'].str.casefold()
dataset['only_alphabet_tweet'] = [re.sub('[^a-zA-Z]+\s*', ' ', s) for s in dataset['case_folding_tweet']]
dataset['data_cleaning_tweet'] = dataset['only_alphabet_tweet'].str.replace(r'\b\w{1}\b','').str.replace(r'\s+', ' ')

slangword_dictionary = (&quot;G:/TA/Program/dataset/kamus_singkatan.csv&quot;)

deslang = {}
list_slangword = open(slangword_dictionary).readlines()
for line in list_slangword:
    slang, unslang = line.strip().split(';')
    deslang[slang] = unslang
deslang[slang] = {r&quot;\b{}\b&quot;.format(k): v for k, v in deslang.items()}

dataset['data_cleaning_tweet'] = dataset['data_cleaning_tweet'].replace(deslang[slang], regex=True)
dataset['convert_slang_tweet'] = dataset['data_cleaning_tweet']

replace_dictionary = {'tidak ': 'tidak', 'bukan ': 'bukan', 'jangan ': 'jangan', 'belum ': 'belum'}
dataset['convert_negation_tweet'] = dataset['convert_slang_tweet'].replace(replace_dictionary, regex=True)
dataset['tokenization_tweet'] = dataset['convert_negation_tweet'].apply(word_tokenize) 
list_stopwords = set(stopwords.words(&quot;indonesian&quot;))
list_stopwords.add('username')
list_stopwords.add('url')
dataset['stopword_removal_tweet'] = dataset['tokenization_tweet'].apply(lambda x: [item for item in x if item not in list_stopwords])

factory = StemmerFactory()
stemmer = factory.create_stemmer()
dataset['stemmed_tweet'] = dataset['stopword_removal_tweet'].apply(lambda x: [stemmer.stem(y) for y in x]) 

# Split data
x = dataset[&quot;stemmed_tweet&quot;].values
y = dataset[&quot;label&quot;].values
x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state= 42)

# Get N-gram and TF
vectorizer = CountVectorizer(ngram_range=(1,3))
x_train_tf = vectorizer.fit_transform(str(x_train).split('\n')).toarray()
x_test_tf = vectorizer.transform(str(x_test).split('\n')).toarray()

# Oversampling
smote = SMOTE(random_state=42, k_neighbors=5)
x_smote, y_smote = smote.fit_resample(x_train_tf, y_train)

print(&quot;Total Train Data SMOTE : &quot;,x_smote.shape), print(&quot;Total Train Label SMOTE : &quot;,y_smote)

gnb_classifier = GaussianNB()
gnb_classifier.fit(x_smote, y_smote)
print(gnb_classifier)
y_pred = gnb_classifier.predict(x_test_tf)
print(&quot;Emotion Predicted :&quot;, y_pred)
</code></pre>
<p><a href=""https://drive.google.com/file/d/15JAhVWTSU0oS3zQXdEBT89KOV6dr9Zns/view?usp=share_link"" rel=""nofollow noreferrer"">Link to the dataset</a></p>
","2023-01-26 22:30:45","2","Question"
"75246298","75235422","","<p>Fundamentally, you're training your model with a dense dataset (19/19 feature values), and are now wondering if you're allowed to make predictions with a sparse dataset (4/19 feature values).</p>
<blockquote>
<p>Does xgboost supports such a feature?</p>
</blockquote>
<p>Yes, it is technically possible with XGBoost, because XGBoost will treat the absent 15/19 feature values as missing. It will not be possible with some other ML framework (such as Scikit-Learn) that do not work with sparse input by default.</p>
<p>Alternatively, you can make your XGBoost model explicitly &quot;missing-value-proof&quot; by assembling a pipeline which contains feature imputation step(s).</p>
<blockquote>
<p>I tried just to fill x_input's other dimensions to None, but that yields to terrible prediction results.</p>
</blockquote>
<p>You should represent missing values as <code>float(&quot;NaN&quot;)</code> (not as <code>None</code>).</p>
","2023-01-26 12:43:13","1","Answer"
"75245926","75146595","","<p>Tried installing <code>!pip install pypiwin32</code> in Jupyter notebook, it works like a charm.</p>
<p>But didn't worked in colab.</p>
","2023-01-26 12:07:56","0","Answer"
"75245317","75189681","","<p>Just as food for thought: How about you cluster the t-SNE dimensions into the seen clusters (e.g. 5 clusters). Afterwards you merge that information to the original dataframe containing the original variables and try to train a simple classification algorithm (e.g. catboost to keep it simple and reasonably well performing). Target of the classification algorithm would be to predict the clusters.</p>
<p>Lastly, you can then use explainable AI approaches, like <a href=""https://shap.readthedocs.io/en/latest/"" rel=""nofollow noreferrer"">shapley values</a> or <a href=""https://github.com/marcotcr/anchor"" rel=""nofollow noreferrer"">anchors</a> to explain the decisions of your model.</p>
<p>Given that your model reaches reasonable performance, it would give you a list of drivers that relate to certain clusters.</p>
<p>If you need help with the code, let me know. Hope that helps.</p>
","2023-01-26 11:10:21","0","Answer"
"75244635","75244523","","<p>i don't think that CNN can help you in your problemes, take a look at the SIFT Technique <a href=""https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/#:%7E:text=SIFT%20helps%20locate%20the%20local,detection%2C%20scene%20detection%2C%20etc"" rel=""nofollow noreferrer"">see this for more détails</a>.it is used for image matching and i think it's better in your cas. if your not looking to get in to much detailes the opencv is a python (and c++ i think) library that has image matching function that are easy to use <a href=""https://www.askpython.com/python-modules/feature-matching-in-images-opencv"" rel=""nofollow noreferrer"">more détails</a> .</p>
","2023-01-26 10:05:13","1","Answer"
"75244523","","Python compare images of, piece of, clothing (identification)","<p>As an example I have two pictures with a particular type of clothing of a certain brand.
I can download a lot of different images of this same piece, and color, of clothing</p>
<p><a href=""https://i.sstatic.net/6AoUC.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/6AoUC.jpg"" alt=""enter image description here"" /></a><a href=""https://i.sstatic.net/Erx5N.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Erx5N.jpg"" alt=""enter image description here"" /></a></p>
<p>I want to create a model which can recognize the item based on a picture.
I tried to do it using this example:
<a href=""https://www.tensorflow.org/tutorials/keras/classification"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/keras/classification</a>.
This can recognize the type of clothing (eg shirt or shoe or trousers, etc) But not a specific item and color.
My goal is to have a model that can tell me that the person on my first picture is wearing the item of my second picture.
As mentioned I can upload a few variations of this same item to train my model, if that would be the best approach.</p>
<p>I also tried to use <a href=""https://pillow.readthedocs.io"" rel=""nofollow noreferrer"">https://pillow.readthedocs.io</a>
This can do something with color recognition but does not solve my initial goal.</p>
","2023-01-26 09:53:21","1","Question"
"75244138","75222558","","<p>I have this same issue. There's an <a href=""https://github.com/mindsdb/mindsdb/issues/4345"" rel=""nofollow noreferrer"">open issue</a> on their Github page. Right now deleting the model in MongoDB Compass works.</p>
","2023-01-26 09:13:40","1","Answer"
"75241778","75235422","","<p>If I understand your question correctly, you are trying to train a model with 19 features, but then feed it only 1 feature to make a prediction.</p>
<p>That's not going to be possible. When you train a model, you are assuming that your data points are drawn from a probability distribution <code>P(X,Y)</code>, where Y is your label and X is your features. If you try to change the dimensionality of X, it'll no longer belong to that distribution (at least intuitively, I am not a mathematician so, I cannot come up with a proof for this).</p>
<p>For instance, let's assume your data lies on a 3D cube. That means that you need three coordinate axes to represent a point on it. You cannot place a point using 2 dimensions without assuming the value of the remaining dimension.</p>
<p>You can assume the values of the features you try to drop, but they may not represent the data you originally trained on.</p>
","2023-01-26 02:22:50","1","Answer"
"75239670","75237257","","<p>Note that because the model in your question includes a nonlinearity after the linear layer, the model will not learn an identity transform between the input and output. In the specific case of the relu nonlinearity, the model <em>could</em> learn an identity transform if all of the input values were positive, but in general this won't be the case.</p>
<p>I find it a little easier to imagine the issue if we had an even smaller model consisting of <code>Linear --&gt; Sigmoid --&gt; Linear</code>. In such a case, the input will be mapped through the first matrix transform and then &quot;squashed&quot; into the space [0, 1] as the &quot;hidden&quot; layer representation. The next (&quot;output&quot;) layer would need to take this squashed view of the input and come up with some way of &quot;unsquashing&quot; it back into the original. But with an affine output layer, it's not possible to do this, so the model will have to learn some other, non-identity, transforms for the two matrices.</p>
<p>There are some neat visualizations of this concept on <a href=""https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/"" rel=""nofollow noreferrer"">Chris Olah's blog</a> that are well worth a look.</p>
","2023-01-25 20:46:13","-1","Answer"
"75237576","75237257","","<p>As well stated by wikipedia:</p>
<blockquote>
<p>An autoencoder is a type of artificial neural network used to learn
efficient codings of unlabeled data. The
encoding is validated and refined by attempting to regenerate the
input from the encoding.</p>
</blockquote>
<p>In other words, the idea of the autoencoder is to learn an identity. This identity-function <strong>will be learned only for particular inputs</strong> (i.e. without anomalies). From this, the following points derive:</p>
<ol>
<li>Input will have same dimensions as output</li>
<li>Autoencoders are (generally) built to learn the essential features of the input</li>
</ol>
<p>Because of point (1), you have that autoencoder will have a series of layers (e.g. a series of <code>nn.Linear()</code> or <code>nn.Conv()</code>).
Because of point (2), you generally have an Encoder which compresses the information (as your code-snippet, you start from 28x28 to the ending 10) and a Decoder that decompress the information (10 -&gt; 28x28). Generally the latent space dimensionality (10) is much smaller than the input (28x28) across several implementation of this theoretical architecture. Now that the end-goal of the Encoder part is clear, you may appreciate that <strong>the compression may produce additional data during the compression itself</strong> (<code>nn.Linear(28*28, 512)</code>), which will disappear when the series of layers will give the final output (10).</p>
","2023-01-25 17:16:39","1","Answer"
"75237257","","What is the purpose of having the same input and output in PyTorch nn.Linear function?","<p>I think this is a comprehension issue, but I would appreciate any help.
I'm trying to learn how to use PyTorch for autoencoding. In the nn.Linear function, there are two specified parameters,
<code>nn.Linear(input_size, hidden_size)</code></p>
<p>When reshaping a tensor to its minimum meaningful representation, as one would in autoencoding, it makes sense that the hidden_size would be smaller. However, in the PyTorch tutorial there is a line specifying identical input_size and hidden_size:</p>
<pre><code>class NeuralNetwork(nn.Module):
def __init__(self):
    super(NeuralNetwork, self).__init__()
    self.flatten = nn.Flatten()
    self.linear_relu_stack = nn.Sequential(
        nn.Linear(28*28, 512),
        nn.ReLU(),
        nn.Linear(512, 512),
        nn.ReLU(),
        nn.Linear(512, 10),
    )
</code></pre>
<p>I guess my question is, what is the purpose of having the same input and hidden size? Wouldn't this just return an identical tensor?</p>
<p>I suspect that this just a requirement after calling the nn.ReLU() activation function.</p>
","2023-01-25 16:48:46","1","Question"
"75235422","","XGBoost XGBRegressor predict with different dimensions than fit","<p>I am using <a href=""https://xgboost.XGBRegressor"" rel=""nofollow noreferrer"">the xgboost XGBRegressor</a> to train on a data of 20 input dimensions:</p>
<pre><code>    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=20)
    model.fit(trainX, trainy, verbose=False)
</code></pre>
<p><code>trainX</code> is 2000 x 19, and <code>trainy</code> is 2000 x 1.</p>
<p>In another word, I am using the 19 dimensions of <code>trainX</code> to predict the 20th dimension (the one dimension of <code>trainy</code>) as the training.</p>
<p>When I am making a prediction:</p>
<pre><code>yhat = model.predict(x_input)
</code></pre>
<p><code>x_input</code> has to be 19 dimensions.
I am wondering if there is a way to keep using the 19 dimensions to train prediction the 20th dimension. But during the prediction, <code>x_input</code> has only 4 dimensions to predict the 20th dimension. It is kinda of a transfer learning to different input dimension.</p>
<p>Does xgboost supports such a feature? I tried just to fill <code>x_input</code>'s other dimensions to <code>None</code>, but that yields to terrible prediction results.</p>
","2023-01-25 14:27:31","0","Question"
"75227125","75168665","","<p>I was facing the same error today, after using the collate function, the above error was solved,</p>
<pre><code>def collate_fn(batch):
    return {
        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),
        'labels': torch.tensor([x['labels'] for x in batch])
    }
</code></pre>
","2023-01-24 20:46:35","0","Answer"
"75226886","75226495","","<ol>
<li><p>If you use a virtual environment, ensure the correct environment is activated.</p>
</li>
<li><p>Also, you might need to use pip3 instead of pip, as in <code>pip3 install tqdm</code>.</p>
</li>
<li><p>Finally, check if you have multiple versions of python installed. For <a href=""https://stackoverflow.com/questions/53312590/how-can-i-check-all-the-installed-python-versions-on-windows"">Windows</a>/<a href=""https://stackoverflow.com/questions/14117945/too-many-different-python-versions-on-my-system-and-causing-problems"">Mac</a>/<a href=""https://stackoverflow.com/questions/2547554/multiple-python-versions-on-the-same-machine"">Linux</a>. If you have multiple versions of python. Delete unused versions.</p>
</li>
</ol>
","2023-01-24 20:21:16","-1","Answer"
"75226555","75226495","","<p>Here are some options I can advise:</p>
<ol>
<li>Check that you have <code>tdqm</code> with pip show <code>tdqm</code></li>
<li>Check that you're using the correct virtual environment.</li>
<li>You can try uninstall and then reinstall it again.</li>
</ol>
","2023-01-24 19:48:16","-1","Answer"
"75226495","","how can I fix ModuleNotFoundError: No module named 'tqdm' after installation 'tqdm'","<p>I have installed <code>tqdm</code> using <code>pip install tqdm</code></p>
<p>but I still got an error that <code>ModuleNotFoundError: No module named 'tqdm'</code>,
how can I fix this?</p>
<p>my code looks like this <code>from tqdm import tqdm</code></p>
","2023-01-24 19:43:22","1","Question"
"75224346","","Visualise topics from BERTopic","<p>I am using <code>TOPIC_MODEL.visualize_topics()</code> for visualising my topics on the graph.
This is the example:</p>
<p><a href=""https://i.sstatic.net/E3Dym.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/E3Dym.png"" alt=""enter image description here"" /></a></p>
<p>My question is, how to see more than 5 words when I hover over blob topics on the graph?</p>
","2023-01-24 16:21:54","0","Question"
"75222558","","Error when deleting MindsDB model from MongoDB","<p>I have a MindsDB model named <code>hrd</code> and I intended to delete the model by running the below command as per the documentation.</p>
<pre><code>db.models.deleteOne({name: &quot;hrd&quot;}) 
</code></pre>
<p>While  running the command and I got hit with the below error.</p>
<pre><code>MongoServerError 'unsupported operand type(s) for &gt;&gt;: 'NoneType' and 'int'
</code></pre>
<p>How can I delete specific models from a MongoDB database integration in MindsDB?</p>
","2023-01-24 13:58:42","2","Question"
"75214753","75208167","","<p>The <code>mglearn</code> package seems to rely on deprecated and removed features of its dependencies.  Hopefully the authors will upgrade their package, or at least better specify its dependencies.  You can read about the several problems users are having on the <a href=""https://github.com/amueller/introduction_to_ml_with_python/issues"" rel=""nofollow noreferrer"">project issues webpage</a>.</p>
<p>To successfully import <code>mglearn</code>, here's what I did.</p>
<p>In a dedicated directory I created a virtual environment with:</p>
<pre class=""lang-bash prettyprint-override""><code>python -m venv _venv
</code></pre>
<p>... and then activated it:</p>
<pre class=""lang-bash prettyprint-override""><code>. _venv/bin/activate
</code></pre>
<p>I then upgraded/installed the packages that at least allow <code>import mglearn</code> to complete without throwing an error.</p>
<pre class=""lang-bash prettyprint-override""><code>python -m pip install --upgrade --upgrade-strategy eager pip setuptools ipython mglearn &quot;scikit-learn==1.0.2&quot; &quot;joblib&lt;0.12&quot;
</code></pre>
<p>If you need to install more packages, using <code>--upgrade-strategy eager</code> for those packages may not be the best choice. YMMV.</p>
<p>There is probably a <code>conda</code> equivalent of the above procedure, but I'm not familiar with it.</p>
<p>As you use the <code>mglearn</code> features, it's possible there may be further dependency problems that need to be resolved.  Good luck!</p>
","2023-01-23 20:32:31","4","Answer"
"75212292","","How can I load the nsynth dataset on a normal local machine in tensorflow?","<p>I've been attempting to load the NSynth dataset for use in tensorflow on my local machine. Google Collab is very powerful, but can't really be used to write full python applications to my knowledge.</p>
<p>However, when using the normal command</p>
<pre class=""lang-py prettyprint-override""><code>ds = tfds.load('nsynth', split='train', shuffle_files=False, download=True,
                data_dir=&quot;data&quot;)
</code></pre>
<p>The data downloads fine, but the script ends silently unexpectedly, seemingly due to lack of disk space, despite there's over 250GB available before running the script, and the dataset isn't larger than this.</p>
<p>I'm not certain disk space is the issue, as the script fails silently after 30 minutes or so, and there is no verbose option for the load function.</p>
<p>How can I load it locally without freeing up more space?</p>
","2023-01-23 16:22:54","1","Question"
"75212273","75206523","","<p>We have to use a for loop in any programming language and we will get only max 3 hits in inner hits. We have to access the json file and load it in Python for example and then use for loop and we can have upto 3 hits.by this process we can access upto 3 inner hits in a same file.
the code:-
we can fetch em in this way
for i in range(some_value):</p>
<pre><code>try:



    uniq_id = data[&quot;hits&quot;][&quot;hits&quot;][i][&quot;_id&quot;]
    start = data[&quot;hits&quot;][&quot;hits&quot;][i][&quot;inner_hits&quot;][&quot;key&quot;][&quot;hits&quot;][&quot;hits&quot;][0][&quot;fields&quot;][&quot;key.start&quot;][0]
    check = data[&quot;hits&quot;][&quot;hits&quot;][i][&quot;inner_hits&quot;][&quot;key&quot;][&quot;hits&quot;][&quot;total&quot;][&quot;value&quot;]
</code></pre>
","2023-01-23 16:21:13","0","Answer"
"75208167","","Any idea how to deal with mglearn import error?","<p>I am a new data science bootcamp student. Recently I bought a book &quot;Introduction to Machine Learning with Pyhton&quot;. However the book heavily uses mglearn library. When I want to import the library I am having an error. (You can see from below.) I can not demonstrate the examples provided from the book. Is there any way to tackle this issue?</p>
<p>Many thanks in advance!.</p>
<pre><code>ImportError                               Traceback (most recent call last)
Cell In [3], line 1
----&gt; 1 import mglearn

File c:\Users\murad\AppData\Local\Programs\Python\Python310\lib\site-packages\mglearn\__init__.py:1
----&gt; 1 from . import plots
      2 from . import tools
      3 from .plots import cm3, cm2

File c:\Users\murad\AppData\Local\Programs\Python\Python310\lib\site-packages\mglearn\plots.py:5
      3 from .plot_animal_tree import plot_animal_tree
      4 from .plot_rbf_svm_parameters import plot_svm
----&gt; 5 from .plot_knn_regression import plot_knn_regression
      6 from .plot_knn_classification import plot_knn_classification
      7 from .plot_2d_separator import plot_2d_classification, plot_2d_separator

File c:\Users\murad\AppData\Local\Programs\Python\Python310\lib\site-packages\mglearn\plot_knn_regression.py:7
      4 from sklearn.neighbors import KNeighborsRegressor
      5 from sklearn.metrics import euclidean_distances
----&gt; 7 from .datasets import make_wave
      8 from .plot_helpers import cm3
     11 def plot_knn_regression(n_neighbors=1):

File c:\Users\murad\AppData\Local\Programs\Python\Python310\lib\site-packages\mglearn\datasets.py:5
      3 import os
      4 from scipy import signal
----&gt; 5 from sklearn.datasets import load_boston
      6 from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures
      7 from .make_blobs import make_blobs

File c:\Users\murad\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\datasets\__init__.py:156, in __getattr__(name)
    105 if name == &quot;load_boston&quot;:
    106     msg = textwrap.dedent(
    107         &quot;&quot;&quot;
    108         `load_boston` has been removed from scikit-learn since version 1.2.
   (...)
    154         &quot;&quot;&quot;
    155     )
--&gt; 156     raise ImportError(msg)
    157 try:
    158     return globals()[name]

ImportError: 
`load_boston` has been removed from scikit-learn since version 1.2.

The Boston housing prices dataset has an ethical problem: as
investigated in [1], the authors of this dataset engineered a
non-invertible variable &quot;B&quot; assuming that racial self-segregation had a
positive impact on house prices [2]. Furthermore the goal of the
research that led to the creation of this dataset was to study the
impact of air quality but it did not give adequate demonstration of the
validity of this assumption.

The scikit-learn maintainers therefore strongly discourage the use of
...
[2] Harrison Jr, David, and Daniel L. Rubinfeld.
&quot;Hedonic housing prices and the demand for clean air.&quot;
Journal of environmental economics and management 5.1 (1978): 81-102.
&lt;https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air&gt;
</code></pre>
<p>I tried to find an answer from online but I could not find anything.</p>
","2023-01-23 10:26:04","1","Question"
"75206581","75206523","","<p>If you are using kibana sql, you will search any occurence in each elasticsearch doc. If you search by &quot;<em>brother</em>&quot; you will get 1 occurence from each doc contains the word &quot;brother&quot;. If you have 3 docs and once has 3 times the word you are searching for and the other 2 have the word once each, you will get 3 hits.</p>
","2023-01-23 07:19:23","0","Answer"
"75206523","","while searching in elasticsearch,if we search for a word ""brother"" which is present more than once in array of json","<p>then if we write a nested query to get brother then will we get the both occurences present in the array or json or only single occurence?</p>
<p>for example
if we are querying to get the word &quot;brother&quot; and its present more than twice in the array of json
will it show only one occurence of brother or multiple occurences?
hence we are handling multiple files we need the file id in which the word is present and if single word is present in a file more than once is it possible to get the word in that single file more than once?</p>
<p>i tried to get the single file id more than once because the single file contained the word more than once in multiple jsons but im getting the file id only once ...</p>
","2023-01-23 07:11:15","0","Question"
"75194136","","XGBoost classifier shows: training data did not have the following fields","<p>I was training a model on thyroid disease detection, it was a multiclass classification problem.
So I used XGBoost classifier. I performed <code>train_test_split</code> and then I passed <code>X_train</code> and <code>y_train</code> to xgb (for model training). The model was successfully made.
But when I tried to predict the values by passing <code>X_test</code> data it is showing error:</p>
<blockquote>
<p>training data did not have the following fields: age, sex, on_thyroxine, query_on_thyroxine, on_antithyroid_medication, sick, pregnant, thyroid_surgery, I131_treatment, query_hypothyroid, query_hyperthyroid, lithium, goitre, tumor, hypopituitary, psych, T3, TT4, T4U, FTI, referral_source_SVHC, referral_source_SVHD, referral_source_SVI, referral_source_other</p>
</blockquote>
<p>So I checked <code>X_train</code> dataframe but it has all the required columns(fields).</p>
<pre class=""lang-py prettyprint-override""><code>X_train,X_test,y_train,y_test=train_test_split(x_sampled,y_sampled,train_size=0.75, random_state = 70)

def xgboost(train_x,train_y):
    
     xgb = XGBClassifier()

     # initializing with different combination of parameters
     param_grid_xgboost = {'tree_method': ['auto'],
                  &quot;n_estimators&quot;: [10, 20, 30,50, 70, 100, 120],
                  'booster' : ['dart', 'gbtree', 'gblinear'],
                  &quot;max_depth&quot;: range(2, 4, 1), 
                  'objective': ['binary:logistics'],
                  'alpha' : (1e-4,10),
                  'colsample_bytree' : (.1, .5),
                  'subsample' : (.1, 1)
              
        
             }
    
     # object for Grid Search cv
     grid= GridSearchCV(xgb, param_grid_xgboost, verbose=3,cv=5)
    
     # finding the best parameters
     grid.fit(train_x, train_y)

     # getting best parameters
     booster = grid.best_params_['booster']
     tree_method = grid.best_params_['tree_method']
     n_estimators = grid.best_params_['n_estimators']
     max_depth = grid.best_params_['max_depth']
     objective = grid.best_params_['objective']
     alpha = grid.best_params_['alpha']
     colsample_bytree = grid.best_params_['colsample_bytree']
     subsample = grid.best_params_['colsample_bytree']
   
     # creating a new model with the best parameters
     xgb = XGBClassifier(booster=booster, tree_method=tree_method, n_estimators=n_estimators,
                                max_depth=max_depth, objective=objective, alpha=alpha,
                                colsample_bytree=colsample_bytree, subsample=subsample)
    
     # training the mew model
     xgb.fit(train_x, train_y)
     print('Best parameters for XGBoost: {}'.format (grid.best_params_))


     return xgb

xgb_classifier = xgboost(X_train,y_train) #the model was trained successfully
xgb_classifier.score(X_test, y_test) # i got score of 0.9456896. i ploted classification matrix, it was good.

pickle.dump(xgb_classifier, open('xgb_model_thyroid_1.pickle', 'wb'))
xgb_model = pickle.load(open('xgb_model_thyroid_1.pickle', 'rb'))

#but when i tried to predict it is showing error
xgb_model.predict([[47.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   2.,  49.,   2.,  55.,   0.,   0.,
          0.,   1.]])
</code></pre>
<p>Please tell me what to do, what I've done wrong?</p>
","2023-01-21 14:41:04","1","Question"
"75192942","75192505","","<p>the first point is that without nonlinearities, such as the ReLU function, in a neural network, the network is limited to performing linear combinations of the input. In other words, the network can only learn linear relationships between the input and output. This means that the network can't approximate complex functions that are not linear, such as polynomials or non-linear equations.</p>
<p>Consider a simple example where the task is to classify a 2D data point as belonging to one of two classes based on its coordinates (x, y). A linear classifier, such as a single-layer perceptron, can only draw a straight line to separate the two classes. However, if the data points are not linearly separable, a linear classifier will not be able to classify them accurately. A nonlinear classifier, such as a multi-layer perceptron with a nonlinear activation function, can draw a curved decision boundary and separate the two classes more accurately.</p>
<p>ReLU function increases the complexity of the neural network by introducing non-linearity, which allows the network to learn more complex representations of the data. The ReLU function is defined as f(x) = max(0, x), which sets all negative values to zero. By setting all negative values to zero, the ReLU function creates multiple linear regions in the network, which allows the network to represent more complex functions.</p>
<p>For example, suppose you have a neural network with two layers, where the first layer has a linear activation function and the second layer has a ReLU activation function. The first layer can only perform a linear transformation on the input, while the second layer can perform a non-linear transformation. By having a non-linear function in the second layer, the network can learn more complex representations of the data.</p>
<p>In the case of your experiment, it's normal that the performance did not change much when you removed the ReLU function, because the dataset and the problem you were trying to solve might not be complex enough to require a ReLU function. In other words, a linear model might be sufficient for that problem, but for more complex problems, ReLU can be a critical component to achieve good performance.</p>
<p>It's also important to note that ReLU is not the only function to introduce non-linearity and other non-linear activation functions such as sigmoid and tanh could be used as well. The choice of activation function depends on the problem and dataset you are working with.</p>
","2023-01-21 11:22:42","4","Answer"
"75192607","75192505","","<p>Neural networks are inspired by the structure of brain. Neurons in the brain transmit information between different areas of the brain by using electrical impulses and chemical signals. Some signals are strong and some are not. Neurons with weak signals are not activated.</p>
<p>Neural networks work in the same fashion. Some input features have weak and some have strong signals. These depend on the features. If they are weak, the related neurons aren't activated and don't transmit the information forward. We know that some features or inputs aren't crucial players in contributing to the label. For the same reason, we don't bother with feature engineering in neural networks. The model takes care of it. Thus, activation functions help here and tell the model which neurons and how much information they should transmit.</p>
","2023-01-21 10:24:17","0","Answer"
"75192505","","Why ReLU function after every layer in CNN?","<p>I am taking intro to ML on Coursera offered by Duke, which I recommend if you are interested in ML. The instructors of this course explained that <strong>&quot;We typically include nonlinearities between layers of a neural network.There's a number of reasons to do so.For one, without anything nonlinear between them, successive linear transforms (fully connected layers) collapse into a single linear transform, which means the model isn't any more expressive than a single layer. On the other hand, intermediate nonlinearities prevent this collapse, allowing neural networks to approximate more complex functions.&quot;</strong> I am curious that, if I apply ReLU, aren't we losing information since ReLU is transforming every negative value to 0? Then how is this transformation more expressive than that without ReLU?</p>
<p>In Multilayer Perceptron, I tried to run MLP on MNIST dataset without a ReLU transformation, and it seems that the performance didn't change much (92% with ReLU and 90% without ReLU). But still, I am curious why this tranformation gives us more information rather than lose information.</p>
","2023-01-21 10:02:23","3","Question"
"75190328","","Calculate AUC by different segments in python","<p>I have a dataset which contains <strong>id, datetime, model features, ground truth labels</strong> and the <strong>predicted probability</strong>.</p>
<pre><code>id     datetime   feature1   feature2   feature3   ...      label      probability
001   2023-01-01   a1          b3          c1      ...     Rejected       0.98
002   2023-01-04   a2          b1          c1      ...     Approved       0.28
003   2023-01-04   a1          b2          c1      ...     Rejected       0.81
004   2023-01-08   a2          b3          c2      ...     Rejected       0.97
005   2023-01-09   a2          b1          c1      ...     Approved       0.06
006   2023-01-09   a2          b2          c2      ...     Approved       0.06
007   2023-01-10   a1          b1          c2      ...     Approved       0.13
008   2023-01-11   a2          b2          c1      ...     Approved       0.18
009   2023-01-12   a2          b1          c1      ...     Approved       0.16
010   2023-01-12   a1          b1          c2      ...     Rejected       0.96
011   2023-01-09   a2          b3          c2      ...     Approved       0.16
...
</code></pre>
<p>I want to know what is the AUC of each segment under different features. How can I manipulate the dataset to get results?</p>
<p>What I have done is to use the groupby method on date to get the monthly AUC for all features together.</p>
<pre><code>def group_auc(x, col_tar, col_scr):
    from sklearn import metrics
    return metrics.roc_auc_score(x[col_tar], x[col_scr])
def map_y(x):
    if x == 'Rejected':
        return 1
    elif x == 'Approved':
        return 0
    return x
## example
y_name = 'label'
df[y_name] = df[y_name].apply(map_y)
# Remove NA rows
df = df.dropna(subset = [y_name])
df['Month_Year'] = df['datetime'].dt.to_period('M')
group_data_monthly = df.groupby('Month_Year').apply(group_auc, y_name, 'probability').reset_index().rename(columns={0:'AUC'})
</code></pre>
<p>My expected output will be like,</p>
<pre><code>datetime     features   value     AUC
2023-01-01   feature1    a1      0.98
2023-01-01   feature1    a2      ...
2023-01-01   feature1    a3      ...
2023-01-01   feature2    b1      ...
2023-01-01   feature2    b2      ...
2023-01-01   feature2    b3      ...
2023-01-01   feature3    c1      ...
2023-01-01   feature3    c2      ...
2023-01-04   feature1    a1      ...
2023-01-04   feature1    a2      ...
2023-01-04   feature1    a3      ...
2023-01-04   feature2    b1      ...
...
</code></pre>
<p>I have also tried to use <code>stack</code> method to transpose the dataframe, but the script failed due to the huge size of the dataframe.</p>
","2023-01-20 23:55:13","0","Question"
"75189681","","After performing t-SNE dimentionality reduction, use k-means and check what features contribute the most in each individual cluster","<p>The following plot displays the t-SNE plot. I can show it here but unfortunately, I can't show you the labels. There are 4 different labels:</p>
<p><a href=""https://i.sstatic.net/ztBgI.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/ztBgI.png"" alt=""enter image description here"" /></a></p>
<p>The plot was created using a data frame called <code>scores</code>, which contains approximately 1100 patient samples and 25 features represented by its columns. The labels for the plot were sourced from a separate data frame called <code>metadata</code>. The following code was used to generate the plot, utilizing the information from both <code>scores</code> and <code>metadata</code> data frames.</p>
<pre><code>tsneres &lt;- Rtsne(scores, dims = 2, perplexity = 6)
tsneres$Y = as.data.frame(tsneres$Y)
ggplot(tsneres$Y, aes(x = V1, y = V2, color = metadata$labels)) + 
  geom_point()
</code></pre>
<h3>My mission:</h3>
<p>I want to analyze the t-SNE plot and identify which features, or columns from the &quot;scores&quot; matrix, are most prevalent in each cluster. Specifically, I want to understand which features are most helpful in distinguishing between the different clusters present in the plot. Is it possible to use an alternative algorithm, such as PCA, that preserves the distances between data points in order to accomplish this task? perhaps it's even a better choice than t-SNE?</p>
<p>This is an example of <code>scores</code>, this is not the real data, but it's similar:</p>
<pre><code>structure(list(Feature1 = c(0.1, 0.3, -0.2, -0.12, 0.17, -0.4, 
-0.21, -0.19, -0.69, 0.69), Feature2 = c(0.22, 0.42, 0.1, -0.83, 
0.75, -0.34, -0.25, -0.78, -0.68, 0.55), Feature3 = c(0.73, -0.2, 
0.8, -0.48, 0.56, -0.21, -0.26, -0.78, -0.67, 0.4), Feature4 = c(0.34, 
0.5, 0.9, -0.27, 0.64, -0.11, -0.41, -0.82, -0.4, -0.23), Feature5 = c(0.45, 
0.33, 0.9, 0.73, 0.65, -0.1, -0.28, -0.78, -0.633, 0.32)), class = &quot;data.frame&quot;, row.names = c(&quot;Patient_A&quot;, 
&quot;Patient_B&quot;, &quot;Patient_C&quot;, &quot;Patient_D&quot;, &quot;Patient_E&quot;, &quot;Patient_F&quot;, 
&quot;Patient_G&quot;, &quot;Patient_H&quot;, &quot;Patient_I&quot;, &quot;Patient_J&quot;))
</code></pre>
<h2>EDIT - PYTHON</h2>
<p>I got to the same point python. I tried PCA at first but it produced very bad plots. So I first reduced dimensions using t-SNE, which produced much better results and clustered the data using k-means. I still got the same question as before, just now I don't mind using R or python.</p>
<p>This is the new plot:</p>
<p><a href=""https://i.sstatic.net/Iq3ed.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Iq3ed.png"" alt=""enter image description here"" /></a></p>
<p>And this is the code:</p>
<pre><code>from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, perplexity=30, learning_rate=200)
tsne_result = tsne.fit_transform(scores)

#create a dict to map the labels to colors
label_color_dict = {'label1':'blue', 'label2':'red', 'label3':'yellow', 'label4':'green'}

#create a list of colors based on the 'labels' column in metadata
colors = [label_color_dict[label] for label in metadata[['labels']]

plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=colors, s=50)
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], c='red', marker='o')

# Add labels to the cluster centers
for i, center in enumerate(cluster_centers,1):
    plt.annotate(f&quot;Cluster {i}&quot;, (center[0], center[1]), 
                 textcoords=&quot;offset points&quot;, 
                 xytext=(0,10), ha='center', fontsize=20)
</code></pre>
","2023-01-20 21:56:15","5","Question"
"75180938","75168936","","<p>I have created a private endpoint for the storage account in the same subnet of the workspace and it started working.</p>
<p>Still thinking about why with Service Endpoint it's not working. Is there any configurations I am missing.</p>
","2023-01-20 07:28:05","0","Answer"
"75170668","75168936","","<p><em><strong>I tried to reproduce the same in my environment and got below results:</strong></em></p>
<p>I have one storage account in which I enabled <strong>Networking</strong> settings as below:</p>
<p><img src=""https://i.sstatic.net/Ijl85.png"" alt=""enter image description here"" /></p>
<p>When I tried to upload data from Azure Machine Learning Studio, I got <strong>same error</strong> as you like below:</p>
<p><img src=""https://i.sstatic.net/N2WTQ.png"" alt=""enter image description here"" /></p>
<p>To <strong>resolve</strong> the error, make sure to add your <strong>client IP address</strong> under storage account's Firewall settings like below:</p>
<p><img src=""https://i.sstatic.net/RogmK.png"" alt=""enter image description here"" /></p>
<p>Now, I tried to upload data again from Azure Machine Learning Studio and got <strong>results</strong> like below:</p>
<p><img src=""https://i.sstatic.net/JcDM6.png"" alt=""enter image description here"" /></p>
<p>When I selected <strong>Next</strong>, it took me to <strong><code>Review</code></strong> tab like below:</p>
<p><img src=""https://i.sstatic.net/NyODZ.png"" alt=""enter image description here"" /></p>
<p>After clicking on <strong>Create</strong>, data asset is created successfully with below details:</p>
<p><img src=""https://i.sstatic.net/kikzZ.png"" alt=""enter image description here"" /></p>
<p>To confirm that, I checked the same in Portal where <strong><code>test.txt</code></strong> file uploaded to storage account successfully like below:</p>
<p><img src=""https://i.sstatic.net/vyAuO.png"" alt=""enter image description here"" /></p>
<p>In your case, make sure to add your <strong>client IP address</strong> under storage account's firewall settings. If the error still persists, try with <strong><code>Storage Blob Data Contributor</code></strong> role.</p>
<p><strong>Reference:</strong></p>
<p><a href=""https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-connect-data-ui?tabs=credential#storage-access-and-permissions"" rel=""nofollow noreferrer"">Connect to data storage with the studio UI - Azure Machine Learning | Microsoft Learn</a></p>
","2023-01-19 10:13:21","2","Answer"
"75168936","","Azure ML Workspace is not able to upload data in for workspace linked storage account which is behind VNet","<p>I am trying to setup an Azure ML workspace with Storage Accound behind the Vnet but when trying to upload an sata from Data tab I am getting below error.</p>
<p><a href=""https://i.sstatic.net/AF3Lk.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/AF3Lk.png"" alt=""enter image description here"" /></a></p>
<p>I have all the necessary setting as describe in the below article but still no luck</p>
<p><a href=""https://learn.microsoft.com/en-us/azure/machine-learning/how-to-secure-workspace-vnet?tabs=se%2Ccli#secure-the-workspace-with-private-endpoint"" rel=""nofollow noreferrer"">https://learn.microsoft.com/en-us/azure/machine-learning/how-to-secure-workspace-vnet?tabs=se%2Ccli#secure-the-workspace-with-private-endpoint</a></p>
<p>Things did to make Storage Accessible to ML workspace</p>
<ol>
<li>Enabled Azure.Storage Service Endpoint from Vnet</li>
<li>Done this setting on Storage <a href=""https://i.sstatic.net/wUV7A.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/wUV7A.png"" alt=""enter image description here"" /></a></li>
<li>Both the ML Workspace and Storage are in same subnet</li>
<li>Assigned &quot;Storage Blob Data Reader&quot; permission for Worspace</li>
<li>Accessing this ML Workspace from Virtual machine created on same subnet.</li>
</ol>
<p>Can anyone suggest is there anything missing ?</p>
","2023-01-19 07:29:14","0","Question"
"75168665","","""Unsupported number of image dimensions"" while using image_utils from Transformers","<p>I'm trying to follow this HuggingFace tutorial <a href=""https://huggingface.co/blog/fine-tune-vit"" rel=""nofollow noreferrer"">https://huggingface.co/blog/fine-tune-vit</a></p>
<p>Using their &quot;beans&quot; dataset everything works, but if I use my own dataset with my own images, I'm hitting &quot;Unsupported number of image dimensions&quot;. I'm wondering if anyone here would have pointers for how to debug this.</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/tmp/ipykernel_2042949/883871373.py in &lt;module&gt;
----&gt; 1 train_results = trainer.train()
      2 trainer.save_model()
      3 trainer.log_metrics(&quot;train&quot;, train_results.metrics)
      4 trainer.save_metrics(&quot;train&quot;, train_results.metrics)
      5 trainer.save_state()

~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py in train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)
   1532             self._inner_training_loop, self._train_batch_size, args.auto_find_batch_size
   1533         )
-&gt; 1534         return inner_training_loop(
   1535             args=args,
   1536             resume_from_checkpoint=resume_from_checkpoint,

~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py in _inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)
   1754 
   1755             step = -1
-&gt; 1756             for step, inputs in enumerate(epoch_iterator):
   1757 
   1758                 # Skip past any already trained steps if resuming training

~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py in __next__(self)
    626                 # TODO(https://github.com/pytorch/pytorch/issues/76750)
...
--&gt; 119         raise ValueError(f&quot;Unsupported number of image dimensions: {image.ndim}&quot;)
    120 
    121     if image.shape[first_dim] in (1, 3):

ValueError: Unsupported number of image dimensions: 2
</code></pre>
<p><a href=""https://github.com/huggingface/transformers/blob/main/src/transformers/image_utils.py"" rel=""nofollow noreferrer"">https://github.com/huggingface/transformers/blob/main/src/transformers/image_utils.py</a></p>
<p>I tried looking at the shape of my data and theirs and it's the same.</p>
<pre><code>$ prepared_ds['train'][0:2]['pixel_values'].shape
torch.Size([2, 3, 224, 224])
</code></pre>
<p>I followed the stack trace and found that the error was in the <code>infer_channel_dimension_format</code> function, so I wrote this filth to find the problematic image:</p>
<pre><code>from transformers.image_utils import infer_channel_dimension_format
try:
    for i, img in enumerate(prepared_ds[&quot;train&quot;]):
        infer_channel_dimension_format(img[&quot;pixel_values&quot;])
except ValueError as ve:
    print(i+1)
</code></pre>
<p>When I inspected that image, I saw that its not RGB like the others.</p>
<pre><code>$ ds[&quot;train&quot;][8]
{'image': &lt;PIL.JpegImagePlugin.JpegImageFile image mode=L size=390x540&gt;,
 'image_file_path': '/data/alamy/img/00000/000001069.jpg',
 'labels': 0}
</code></pre>
<p>So the solution for me was to add a <code>convert('RGB')</code> to my transform:</p>
<pre><code>def transform(example_batch):
    # Take a list of PIL images and turn them to pixel values
    inputs = feature_extractor([x.convert(&quot;RGB&quot;) for x in example_batch['image']], return_tensors='pt')

    # Don't forget to include the labels!
    inputs['labels'] = example_batch['labels']
    return inputs
</code></pre>
<p>I will try to find some time to come back here and clean this up with a fully reproducible example. (Sorry)</p>
","2023-01-19 06:53:46","3","Question"
"75160529","75158273","","<p>I found a solution at least for my case: despite the fact that I uninstalled <code>umap-learn</code> , there was still a umap folder in the package directory ( c:\python310\lib\site-packages ). I manually deleted the umap folder and later I just installed the bertopic. It works now!</p>
","2023-01-18 14:11:07","0","Answer"
"75158273","","Problem in importing UMAP while importing bertopic","<p>So everything worked fine with my code and then suddenly the hdbscan was not working anymore, than I re-instaled all packages and now I have a problem with umap.</p>
<p>I did what was suggested here and in other foruns and uninstalled and re-installed both <code>umap-learn</code> and <code>bertopic</code> . I can import umap as <code>import umap</code> or <code>import umap.umap_ as UMAP</code> , the problem is when I import bertopic. I tried:</p>
<pre><code>import bertopic
</code></pre>
<p>and</p>
<pre><code>import umap.umap_ as UMAP
import bertopic
</code></pre>
<p>and</p>
<pre><code>import umap
import bertopic
</code></pre>
<p>and</p>
<pre><code>import umap
from bertopic import BERTopic
</code></pre>
<p>and finally:</p>
<pre><code>import umap.umap_ as UMAP
from bertopic import BERTopic
</code></pre>
<p>In all situations, the problem occurs when I'm importing bertopic: <code>ImportError: cannot import name 'UMAP' from 'umap' (unknown location)</code> .  I also reboot the machine a several times.  I don't think that issue is related to the environment, because I have been using the same environment before when the same code was working: Python 3.10.7 and Visual Code Studio 1.74.3 . The bertopic is version  0.13.0 and umap-learn version 0.5.3</p>
","2023-01-18 11:06:19","1","Question"
"75148255","75146595","","<ul>
<li>Are you running it actually on Windows? If no, it pyiwin32 only is supported for Windows</li>
<li>Try using <code>pip install --no-cache-dir pyiwin32</code></li>
</ul>
","2023-01-17 14:54:44","1","Answer"
"75147062","","Difference between running XGBoost on top X most important features and using the transform method","<p>recently I've been working on a XGBoost model, and using it for feature selection based on the feature importance scores (<a href=""https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/"" rel=""nofollow noreferrer"">https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/</a>)</p>
<p>This technique builds models iteratively based on the most important features:</p>
<ol>
<li>First building a model based on all features and giving each feature an importance score.</li>
<li>Then building models iteratively: building a model based on the most important feature, then on the 2 most important features, then on the 3 most important features and so on).</li>
</ol>
<p>The code of building of the models iteratively (taken from the link attached at the top):</p>
<pre><code># load data
dataset = loadtxt('pima-indians-diabetes.csv', delimiter=&quot;,&quot;)
# split data into X and y
X = dataset[:,0:8]
Y = dataset[:,8]
# split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)
# fit model on all training data
model = MyXGBClassifier()
model.fit(X_train, y_train)
# make predictions for test data and evaluate
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print(&quot;Accuracy: %.2f%%&quot; % (accuracy * 100.0))
# Fit model using each importance as a threshold
thresholds = sort(model.feature_importances_, reverse=True)
for thresh in thresholds:
 # select features using threshold
 selection = SelectFromModel(model, threshold=thresh, prefit=True)
 select_X_train = selection.transform(X_train)
 # train model
 selection_model = XGBClassifier()
 selection_model.fit(select_X_train, y_train)
 # eval model
 select_X_test = selection.transform(X_test)
 predictions = selection_model.predict(select_X_test)
 accuracy = accuracy_score(y_test, predictions)
 print(&quot;Thresh=%.3f, n=%d, Accuracy: %.2f%%&quot; % (thresh, select_X_train.shape[1], accuracy*100.0))
</code></pre>
<p>My question is - why do I need this line in order to select the model features from the test set:</p>
<pre><code>select_X_test = selection.transform(X_test)
</code></pre>
<p>Why can't I just select the top len(select_X_train) most important features from model.feature_importances_ and use this subset of the test set for prediction?
When I tried doing so I got a low performing model that labeled almost every instance as true, but when I used selection.transform(X_test) I got a model with a way better performance (~70% precision and recall).</p>
<p>Thanks in advance!</p>
","2023-01-17 13:21:21","2","Question"
"75146595","","Unable to install pypiwin32 library","<p>Tried to install the <code>pip install pypiwin32</code> in Google Colab for reading outlook emails. But the installation keeps on getting failed.</p>
<p><a href=""https://i.sstatic.net/wIXxI.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/wIXxI.png"" alt=""enter image description here"" /></a></p>
<p>Tried by downgrading the python version to 3.9 as well, but didn't worked.</p>
<p>Any suggestions for fixing the issue?</p>
","2023-01-17 12:43:03","-1","Question"
"75137078","75136455","","<pre class=""lang-py prettyprint-override""><code>X_test[&quot;column&quot;] = X_test[&quot;column&quot;].replace({&quot;O&quot;: &quot;0&quot;, &quot;b&quot;: &quot;6&quot;}, regex=True)
</code></pre>
","2023-01-16 16:30:35","0","Answer"
"75136527","75136455","","<p>Try this:</p>
<pre><code>X_test['column_name'] = X_test['column_name'].str.replace('O', '0')
X_test['column_name'] = X_test['column_name'].str.replace('b', '6')
</code></pre>
","2023-01-16 15:42:53","1","Answer"
"75136455","","How to replace a character in a text in a dataframe","<p>I have a pandas dataframe X_test that contains one column &quot;review&quot;.
I want to check reviews and replace two characters as below:
O ==&gt; 0 and b ==&gt; 6
The replace method replaces just one character.
Any idea, please?</p>
","2023-01-16 15:36:40","-1","Question"
"75115787","75115715","","<p>There are other ways to normalize images. Standardization is the most common way (subtract the mean and divide by the standard deviation).</p>
<p>Using numpy...</p>
<pre><code>image = (image - np.mean(image)) / np.std(image)
</code></pre>
<p>As I mentioned in a clarifying comment, you want the normalization method to match how the NN training set.</p>
","2023-01-14 04:28:18","0","Answer"
"75115715","","What is the right way to normalize satellite images to feed into a Nerual network?","<p>I am trying to feed small patches of satellite image data (landsat-8 Surface Reflectance Bands) into neural networks for my project. However the downloaded image values range from 1 to 65535.</p>
<p>So I tried dividing images by 65535(max value) but plotting them shows all black/brown image like this!</p>
<p><a href=""https://i.sstatic.net/tFCvD.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/tFCvD.png"" alt=""rgb image normalized by max possible value"" /></a></p>
<p>But most of the images do not have values near 65535</p>
<p>Without any normalization the image looks all white.</p>
<p><a href=""https://i.sstatic.net/cLlSm.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/cLlSm.png"" alt=""Un-Normalized rgb image plotted with matplotlib imshow"" /></a></p>
<p>Dividing the image with 30k looks like this.</p>
<p><a href=""https://i.sstatic.net/ocrUB.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/ocrUB.png"" alt=""enter image description here"" /></a></p>
<p>If the images are too dark or too light my network may not perform as intended.</p>
<p>Is dividing the image with max value possible (65535) the only solution or are there any other ways to normalize images especially for satellite data?</p>
","2023-01-14 04:08:10","-1","Question"
"75114900","75114602","","<h2>Model capacity</h2>
<p>The model is too simple (just two convolutional layers) to process these images with complex structures. The two convolutional layers may be able to recognize simple structures like lines and nothing else more complicated.</p>
<p>The model does not have the capacity to model more complicated structures, such as teeth and different parts of the skull, to decide about the overbite. It simply does not understand the image. Compare the size of your model to models such as the ResNet. You will see that it is significantly larger.</p>
<h2>Data</h2>
<p>As you said, your dataset is relatively small. Even if you use a model with sufficient capacity to understand the images, your dataset might be insufficient for the model to generalize and instead will overfit your data. You recognize this by watching the metric for your training and validation data: the training score will keep increasing, while the validation score will not. That is called overfitting.</p>
<h2>Practical standpoint</h2>
<p>I would suggest that you use a pre-trained model. These models were trained on massive datasets with millions of images, so their ability to generalize is pretty high. You download the model and finetune it on your dataset.
See <a href=""https://www.tensorflow.org/tutorials/images/transfer_learning#create_the_base_model_from_the_pre-trained_convnets"" rel=""nofollow noreferrer"">the Tensorflow tutorial</a> on how to use a pre-trained model and fine-tune it.</p>
<p>Starting with a pre-trained model is always better than starting from scratch. Only in case of poor results would I move on to training a custom model.</p>
<h2>Conclusion</h2>
<p>I believe the dataset size is sufficient if you use a pre-trained model and fine-tune it. But if you have more data available, I would consider using it. The model will give you better results.</p>
","2023-01-13 22:08:48","2","Answer"
"75114827","75114602","","<p>There might be many other reasons why the model could perform the it is performing but as for your first question, we can probably say that your model is performing poorly because it is unable to learn all the complexities of multiple classes due to the amount of data which is being provided to it. For a multi class classifier it would be better if you add more data so that it could learn learn the added complexity.</p>
<p>When you make a binary classifier it's easier for the model to learn distinguishing features from one another the same cannot be said for a multi class classifier.</p>
<p>The number of images you have for data might not be large enough for a multi classification model. The model could be overfitting on the train dataset which is why you get such bad accuracy on your validation dataset. Moreover the solution is not just to keep on adding images in the dataset but to balance out your dataset, having little to no imbalance in your dataset might give your model some space to improve.</p>
<p>The model architecture is quite small and not suitable for a multi class classifier. The more data you pore into your model the larger the architecture would be required to capture further complex features from the dataset specially in a multi classification model.</p>
","2023-01-13 21:59:26","1","Answer"
"75114602","","Poor model performances when doing multi-class classification","<h1>Context</h1>
<p>I have a dataset of medical X-Rays (<a href=""https://thumbs.dreamstime.com/z/x-ray-human-head-skull-side-view-cranium-medical-analysis-xray-mri-ct-diagnostic-scan-photo-ray-human-head-skull-side-view-239898982.jpg"" rel=""nofollow noreferrer"">example</a>). I want to train a model to recognize an <a href=""https://d1l9wtg77iuzz5.cloudfront.net/assets/5501/248215/original.svg?1542210077"" rel=""nofollow noreferrer"">overbite</a>. The potential values can be:</p>
<ul>
<li>Normal</li>
<li>1-2mm</li>
<li>2-4mm</li>
<li>[ ... ]</li>
<li>8mm+</li>
</ul>
<h2>Test Results</h2>
<p>I've built a CNN to process the images. My problem is that the validation accuracy is extremely low when comparing multiple classes of images. I tried different combinations of things and here are the results:</p>
<pre><code>| Image       | Val Accuracy |
| ----------- | ------------ |
| A -&gt; B      | 56%          |
| B -&gt; C      | 33%          |
| A -&gt; C      | 75%          |
| A -&gt; B -&gt; C | 17%          |
</code></pre>
<p>When I compare images 1-1 against each other, the ML seems to train better than when otherwise. Why is that the case? In total I have:</p>
<ul>
<li>1368 images of A</li>
<li>1651 images of B</li>
<li>449 images of C</li>
</ul>
<p>(I realize 3.5K images is not a lot of data but I'm trying to figure out the fundamentals of a good model first before downloading and training on more data. My DB only has 17K images)</p>
<h2>Code</h2>
<p>I have a custom input pipeline and generate a <code>tf.data.Dataset</code>.</p>
<pre><code>print(train_ds)
==&gt; &lt;ParallelMapDataset element_spec=(TensorSpec(shape=(512, 512, 1), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.uint8, name=None))&gt;
</code></pre>
<p>Here is the CNN architecture:</p>
<pre><code>input_shape = (None, IMG_SIZE, IMG_SIZE, color_channels)
num_classes = len(class_names)

# Pre-processing layers
RESIZED_IMG = 256
resize_and_rescale = tf.keras.Sequential([
  layers.Resizing(RESIZED_IMG, RESIZED_IMG),
  layers.Rescaling(1./255)
])

medium = 0.2
micro = 0.10
data_augmentation = tf.keras.Sequential([
  layers.RandomContrast(medium),
  layers.RandomBrightness(medium),
  layers.RandomRotation(micro, fill_mode=&quot;constant&quot;),
  layers.RandomTranslation(micro, micro, fill_mode=&quot;constant&quot;),
  layers.RandomZoom(micro, fill_mode=&quot;constant&quot;),
])

# Hidden layers
model = Sequential([
  data_augmentation,
  resize_and_rescale,

  Conv2D(16, 3, padding='same', activation='relu'),
  Conv2D(24, 5, padding='same', activation='relu'),
  MaxPooling2D(),

  Flatten(),
  Dense(128, activation='relu'),
  Dense(num_classes, activation='softmax'), 
])

# Build
model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'])

model.build(input_shape)
model.summary()

# Start training
epochs = 15
early_stopping_monitor = tf.keras.callbacks.EarlyStopping(
    monitor='val_accuracy',
    restore_best_weights=True,
    patience=7
)
mcp_save = tf.keras.callbacks.ModelCheckpoint(
    '.mdl_wts.hdf5', 
    save_best_only=True, 
    monitor='val_accuracy'
)

history = model.fit(
  batch_train_ds,
  validation_data=batch_val_ds,
  epochs=epochs,
  class_weight=class_weights,
  callbacks=[early_stopping_monitor, mcp_save]
)
</code></pre>
<p>The only thing I've changed in between my runs is which images are loaded in my input pipeline and then recorded their accuracy. I have intentionally kept the CNN small because I don't have a lot of data.</p>
<h2>Questions</h2>
<ul>
<li>Why does my model perform worse when training on more classes?</li>
<li>Do I have the wrong data and the images do not have enough conclusive information?</li>
<li>Is my image count too low in order to train a decent ML model?</li>
<li>Is my CNN not deep enough for multi-class classification?</li>
</ul>
","2023-01-13 21:25:34","1","Question"
"75111991","75111871","","<p>I believe the problem may be in the way you are passing the &quot;X&quot; and &quot;Y&quot; values to the &quot;scatter&quot; and &quot;plot&quot; methods in matplotlib. Sklearn's LinearRegression model expects the input data to be in the form of 2D arrays, whereas the DataFrame you pass only contains 1 column.</p>
<p>Have you tried converting X and Y into 2D arrays using the DataFrame's values attribute and passing this to the adjustment and prediction methods</p>
<pre><code>X = DataFrame(data, columns=['production_budget_usd']).values
Y = DataFrame(data, columns=['worldwide_gross_usd']).values

regression = LinearRegression()
regression.fit(X, Y)

plt.figure(figsize=(10,6))
plt.scatter(X, Y, alpha=0.3)
plt.plot(X, regression.predict(X), color= 'red', linewidth=3)
</code></pre>
<p>One question, is the data file &quot;cost_revenue.csv&quot; loaded correctly, and does it contain the expected data?</p>
","2023-01-13 16:34:45","0","Answer"
"75111871","","Linear Regression & Machine Learning Error","<p>Good day devs,</p>
<p>I am currently working on Linear Regression with Machine Learning.</p>
<p>The module sklearn.linear_model method Linear_regresion works just fine but throws an error when I try plotting the graph with matplotlib.pyplot plot() method.</p>
<p>You can find my code below:</p>
<pre><code>
import pandas
from pandas import DataFrame
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression

data = pandas.read_csv('cost_revenue.csv')

data.describe()

#The CSV file contains 5034 entries. 

X = DataFrame(data, columns=['production_budget_usd'])

Y = DataFrame(data, columns=['worldwide_gross_usd'])

plt.figure(figsize=(10,6))
plt.scatter(X, Y, alpha=0.3)

plt.title('Film Cost vs Global Revenue')
plt.xlabel('Production Budget $')
plt.ylabel('Worldwide Gross $')

plt.ylim(0, 3000000000)
plt.xlim(0, 450000000)
plt.show()

#This plots a scatterplot and works just fine.

regression = LinearRegression()
regression.fit(X, Y)

plt.figure(figsize=(10,6))
plt.scatter(X, y, alpha=0.3)
plt.plot(X, regression.predict(X), color= 'red', linewidth=3)

plt.title('Film Cost vs Global Revenue')
plt.xlabel('Production budget $')
plt.ylabel('worldwide gross $')
plt.ylim(0,3000000000)
plt.xlim(0,450000000)
plt.show()

#This is the part pf the code where it throws an exception

</code></pre>
<p>It is suppose to draw a linear regression line on the graph but it throws 3 errors which. I haven’t been able to debug and I will appreciate any possible help.</p>
<p>The errors are:
Typeerror
Keyerror
InvalidIndexerror</p>
<p>Debugging from top to bottom</p>
","2023-01-13 16:23:22","0","Question"
"75111711","75110547","","<p>Tensorflow has two types of seeds the global and the operational - this is also why you need to pass two numbers to <code>stateless_truncated_normal</code> as <em>xdurch0</em> describes in his answer. Tensorflow combines these two seeds to generate a new one.</p>
<pre><code>tf.random.truncated_normal(shape=[2],seed=1234) # global seed #1 &amp; operational 1234 -&gt; Seed A
tf.random.truncated_normal(shape=[2],seed=1234) # global seed #2 &amp; operational 1234 -&gt; Seed B
</code></pre>
<p>There are multiple ways to tackle your problem. Set the global seed as well beforehand twice.
Work inside <code>@tf.functions</code> these kindof reset the global seed and have their own operational counters.
Or use <code>stateless_truncated_normal</code> as written in the other answer.</p>
<p>As already linked, in the <a href=""https://www.tensorflow.org/api_docs/python/tf/random/set_seed"" rel=""nofollow noreferrer"">documentation</a> it is described as well.</p>
","2023-01-13 16:08:27","2","Answer"
"75111596","75110547","","<p>This seems to be intentional, see the docs <a href=""https://www.tensorflow.org/api_docs/python/tf/random/set_seed"" rel=""nofollow noreferrer"">here</a>. Specifically the &quot;Examples&quot; section.</p>
<p>What you need is <code>stateless_truncated_normal</code>:</p>
<pre><code>print(tf.random.stateless_truncated_normal(shape=[2],seed=[1234, 1]))
print(tf.random.stateless_truncated_normal(shape=[2],seed=[1234, 1]))
</code></pre>
<p>Gives me</p>
<pre><code>tf.Tensor([1.0721238  0.10303579], shape=(2,), dtype=float32)
tf.Tensor([1.0721238  0.10303579], shape=(2,), dtype=float32)
</code></pre>
<p>Note: The seed needs to be two numbers here, I honestly don't know why (the docs don't say).</p>
","2023-01-13 16:00:02","2","Answer"
"75110547","","Tensorflow's random.truncated_normal returns different results with the same seed","<p>The following lines are supposed to get the same result:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
print(tf.random.truncated_normal(shape=[2],seed=1234))
print(tf.random.truncated_normal(shape=[2],seed=1234))
</code></pre>
<p>But I got:</p>
<pre class=""lang-py prettyprint-override""><code>tf.Tensor([-0.12297685 -0.76935077], shape=(2,), dtype=tf.float32)
tf.Tensor([0.37034193 1.3367208 ], shape=(2,), dtype=tf.float32)
</code></pre>
<p>Why?</p>
","2023-01-13 14:29:34","3","Question"
"75102134","","mat1 and mat2 must have the same dtype","<p>I'm trying to build a neural network to predict per-capita-income for counties in US based on the education level of their citizens.
X and y have the same dtype (I have checked this) but I'm getting an error.
Here is my data:</p>
<pre><code>   county_FIPS state          county  per_capita_personal_income_2019  \
0        51013    VA   Arlington, VA                            97629   

   per_capita_personal_income_2020  per_capita_personal_income_2021  \
0                           100687                           107603    

   associate_degree_numbers_2016_2020  bachelor_degree_numbers_2016_2020  \
0                               19573                             132394   
 
</code></pre>
<p>And here is my network</p>
<pre><code>import torch
import pandas as pd
df = pd.read_csv(&quot;./input/US counties - education vs per capita personal income - results-20221227-213216.csv&quot;)
X = torch.tensor(df[[&quot;bachelor_degree_numbers_2016_2020&quot;, &quot;associate_degree_numbers_2016_2020&quot;]].values)
y = torch.tensor(df[&quot;per_capita_personal_income_2020&quot;].values)

X.dtype
torch.int64

y.dtype
torch.int64

import torch.nn as nn
class BaseNet(nn.Module):
    def __init__(self, in_dim, hidden_dim, out_dim):
        super(BaseNet, self).__init__()
        self.classifier = nn.Sequential(
        nn.Linear(in_dim, hidden_dim, bias=True), 
        nn.ReLU(), 
        nn.Linear(feature_dim, out_dim, bias=True))
        
    def forward(self, x): 
        return self.classifier(x)

from torch import optim
import matplotlib.pyplot as plt
in_dim, hidden_dim, out_dim = 2, 20, 1
lr = 1e-3
epochs = 40
loss_fn = nn.CrossEntropyLoss()
classifier = BaseNet(in_dim, hidden_dim, out_dim)
optimizer = optim.SGD(classifier.parameters(), lr=lr)

def train(classifier, optimizer, epochs, loss_fn):
    classifier.train()
    losses = []
    for epoch in range(epochs):
        out = classifier(X)
        loss = loss_fn(out, y)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        losses.append(loss/len(X))
        print(&quot;Epoch {} train loss: {}&quot;.format(epoch+1, loss/len(X)))
    
    plt.plot([i for i in range(1, epochs + 1)])
    plt.xlabel(&quot;Epoch&quot;)
    plt.ylabel(&quot;Training Loss&quot;)
    plt.show()

train(classifier, optimizer, epochs, loss_fn)
</code></pre>
<p>Here is the full stack trace of the error that I am getting when I try to train the network:</p>
<pre><code>---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Input In [77], in &lt;cell line: 39&gt;()
     36     plt.ylabel(&quot;Training Loss&quot;)
     37     plt.show()
---&gt; 39 train(classifier, optimizer, epochs, loss_fn)

Input In [77], in train(classifier, optimizer, epochs, loss_fn)
     24 losses = []
     25 for epoch in range(epochs):
---&gt; 26     out = classifier(X)
     27     loss = loss_fn(out, y)
     28     loss.backward()

File ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194, in Module._call_impl(self, *input, **kwargs)
   1190 # If we don't have any hooks, we want to skip the rest of the logic in
   1191 # this function, and just call forward.
   1192 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1193         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1194     return forward_call(*input, **kwargs)
   1195 # Do not call functions when jit is used
   1196 full_backward_hooks, non_full_backward_hooks = [], []

Input In [77], in BaseNet.forward(self, x)
     10 def forward(self, x): 
---&gt; 11     return self.classifier(x)

File ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194, in Module._call_impl(self, *input, **kwargs)
   1190 # If we don't have any hooks, we want to skip the rest of the logic in
   1191 # this function, and just call forward.
   1192 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1193         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1194     return forward_call(*input, **kwargs)
   1195 # Do not call functions when jit is used
   1196 full_backward_hooks, non_full_backward_hooks = [], []

File ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:204, in Sequential.forward(self, input)
    202 def forward(self, input):
    203     for module in self:
--&gt; 204         input = module(input)
    205     return input

File ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194, in Module._call_impl(self, *input, **kwargs)
   1190 # If we don't have any hooks, we want to skip the rest of the logic in
   1191 # this function, and just call forward.
   1192 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1193         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1194     return forward_call(*input, **kwargs)
   1195 # Do not call functions when jit is used
   1196 full_backward_hooks, non_full_backward_hooks = [], []

File ~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114, in Linear.forward(self, input)
    113 def forward(self, input: Tensor) -&gt; Tensor:
--&gt; 114     return F.linear(input, self.weight, self.bias)

RuntimeError: mat1 and mat2 must have the same dtype
</code></pre>
<h1>Updates</h1>
<p>I have tried casting X and y to float tensors but this comes up with the following error: <code>expected scalar type Long but found Float</code>. If someone who knows PyTorch could try running this notebook for themselves that would be a great help. I'm struggling to get off the ground with Kaggle and ML.</p>
","2023-01-12 20:45:51","9","Question"
"75100062","75086268","","<p>The simplest one is the best one!</p>
<p>I found that the normal StandardScaler is the best answer to my question.
StandardScaler(with_mean=False,with_std=False) that means mean=0 and var=1.
These values is fix for train set, test set and input data. so it's OK!</p>
","2023-01-12 17:19:32","0","Answer"
"75094244","","shap : SystemError: initialization of _internal failed without raising an exception","<p>I am tryring to use shap to get feature importance, but it fails at import:</p>
<pre><code>import shap
</code></pre>
<p>Error:</p>
<pre><code>---------------------------------------------------------------------------
SystemError                               Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_11012\3923049429.py in &lt;module&gt;
----&gt; 1 import shap
      2 svc_linear = SVC(C=1.2, probability=True)
      3 svc_linear.fit(X_train, Y_train)
      4 explainer = shap.KernelExplainer(svc_linear.predict_proba, X_train)
      5 shap_values = explainer.shap_values(X_test)

~\Anaconda3\lib\site-packages\shap\__init__.py in &lt;module&gt;
     10     warnings.warn(&quot;As of version 0.29.0 shap only supports Python 3 (not 2)!&quot;)
     11 
---&gt; 12 from ._explanation import Explanation, Cohorts
     13 
     14 # explainers

~\Anaconda3\lib\site-packages\shap\_explanation.py in &lt;module&gt;
     10 from slicer import Slicer, Alias, Obj
     11 # from ._order import Order
---&gt; 12 from .utils._general import OpChain
     13 from .utils._exceptions import DimensionError
     14 

~\Anaconda3\lib\site-packages\shap\utils\__init__.py in &lt;module&gt;
----&gt; 1 from ._clustering import hclust_ordering, partition_tree, partition_tree_shuffle, delta_minimization_order, hclust
      2 from ._general import approximate_interactions, potential_interactions, sample, safe_isinstance, assert_import, record_import_error
      3 from ._general import shapley_coefficients, convert_name, format_value, ordinal_str, OpChain, suppress_stderr
      4 from ._show_progress import show_progress
      5 from ._masked_model import MaskedModel, make_masks

~\Anaconda3\lib\site-packages\shap\utils\_clustering.py in &lt;module&gt;
      2 import scipy as sp
      3 from scipy.spatial.distance import pdist
----&gt; 4 from numba import jit
      5 import sklearn
      6 import warnings

~\Anaconda3\lib\site-packages\numba\__init__.py in &lt;module&gt;
     40 
     41 # Re-export vectorize decorators and the thread layer querying function
---&gt; 42 from numba.np.ufunc import (vectorize, guvectorize, threading_layer,
     43                             get_num_threads, set_num_threads)
     44 

~\Anaconda3\lib\site-packages\numba\np\ufunc\__init__.py in &lt;module&gt;
      1 # -*- coding: utf-8 -*-
      2 
----&gt; 3 from numba.np.ufunc.decorators import Vectorize, GUVectorize, vectorize, guvectorize
      4 from numba.np.ufunc._internal import PyUFunc_None, PyUFunc_Zero, PyUFunc_One
      5 from numba.np.ufunc import _internal, array_exprs

~\Anaconda3\lib\site-packages\numba\np\ufunc\decorators.py in &lt;module&gt;
      1 import inspect
      2 
----&gt; 3 from numba.np.ufunc import _internal
      4 from numba.np.ufunc.parallel import ParallelUFuncBuilder, ParallelGUFuncBuilder
      5 

SystemError: initialization of _internal failed without raising an exception
</code></pre>
<p>How to resolve this?</p>
<p>python version : 3.9.13</p>
<p>shap version :  0.40.0</p>
","2023-01-12 09:39:28","3","Question"
"75090336","75089762","","<p>&quot;RuleFit learns a sparse linear model with the original features and also a number of new features that are decision rules. These new features capture interactions between the original features. RuleFit automatically generates these features from decision trees. Each path through a tree can be transformed into a decision rule by combining the split decisions into a rule.&quot; (<a href=""https://christophm.github.io/interpretable-ml-book/rulefit.html"" rel=""nofollow noreferrer"">reference</a>)</p>
<p>Also, from this <a href=""https://hacarus.com/ai-lab/20211208-rulefit/"" rel=""nofollow noreferrer"">example</a> we understand that rf.get_rules() will return the rules created from initial attributes and created attributes, but not the predictions.</p>
<p>I am therefore assuming the prediction results come from your GradientBoostingClassifier's <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier.predict"" rel=""nofollow noreferrer"">predict</a> method. If that is the case, then the most natural thing to do is to indeed select a threshold above which you consider if a sample is predicted as a 0 or 1. Here is a possible example:</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)
reg = GradientBoostingClassifier()
reg.fit(X_train, y_train)
y_pred = reg.predict(X_test)
thresh = 0.5
y_pred = np.array([y_pred &gt; thresh])
</code></pre>
<p>Notice that the threshold may not be 0.5, depending on what you are aiming for.
For more about this, I encourage you to look for the <a href=""https://medium.com/@sarath13/area-under-the-roc-curve-explained-d056854d3815"" rel=""nofollow noreferrer"">Area Under the Curve</a> metric.</p>
<p>I hope this helped!</p>
","2023-01-12 00:20:28","0","Answer"
"75089762","","I am using RuleFit for binary classification; how do I interpret the rules?","<p>I am using RuleFit with a GradientBoostingClassifier to generate rules for a binary classification problem (health-dataset on Kaggle).  When I print out the rules with RuleFit.get_rules(), it shows rule, type, coef, support, and importance.  But it doesn’t show which class (0 or 1) is the target of the rule.  For example: does exang &lt;= 0.5 describe a 0 or 1 class?</p>
<p>Summary: how do I know which target class a given rule is describing?</p>
","2023-01-11 22:42:33","-1","Question"
"75086941","75086268","","<pre><code>from sklearn.preprocessing import StandardScaler
import numpy as np

# Your training data
X_train = ...

# Your test data
X_test = ...

# Concatenate the training and test data
X_all = np.concatenate((X_train, X_test))

# Initialize the scaler
scaler = StandardScaler()

# Fit the scaler on the combined data set
scaler.fit(X_all)

# Transform the training data
X_train_scaled = scaler.transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)
</code></pre>
<p>If you want to use input data instead of traning set you could include this:</p>
<pre><code>scaler = StandardScaler(with_mean=True, with_std=True, mean=mean_all, 
scale=var_all)
input_data = #input data
input_data_scaled = scaler.transform(input_data)
</code></pre>
","2023-01-11 17:33:31","1","Answer"
"75086268","","custom mean and var for standard_scaler","<p>How we can use <code>custom mean</code> and <code>var</code> in <code>standard_scaler</code>? I need to calculate mean and var for all data in the dataset (train set+test set) and then use these values to standardize the train set and test set (and later input data) separately. How can I do this?</p>
<p>I couldn't find any example of it.</p>
","2023-01-11 16:34:54","0","Question"
"75085523","75085236","","<p>You are comparing the predicted labels for the train set with the labels for the test set, which are of different sizes, hence the error.</p>
<p>Replace</p>
<pre class=""lang-py prettyprint-override""><code>y_pred = logReg.predict(X_train)
</code></pre>
<p>with</p>
<pre class=""lang-py prettyprint-override""><code>y_pred = logReg.predict(X_test)
</code></pre>
","2023-01-11 15:37:51","2","Answer"
"75085236","","""Found input variables with inconsistent numbers of samples"" Have I done something wrong during the train_test_split?","<p>I am trying to logistic Regression Model, and run some test but I keep getting this error. Not really sure what I have done differently to everyone else</p>
<pre><code>from sklearn import preprocessing
X = df.iloc[:,:len(df.columns)-1]
y = df.iloc[:,len(df.columns)-1]ere
</code></pre>
<p>This is how I am separating  my columns</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
</code></pre>
<p>TTS</p>
<pre><code>logReg = LogisticRegression(n_jobs=-1)
logReg.fit(X_train, y_train)
</code></pre>
<pre><code>y_pred = logReg.predict(X_train)
</code></pre>
<pre><code>mae = mean_absolute_error(y_test, y_pred)
print(&quot;MAE:&quot; , mae)
</code></pre>
<pre><code>ValueError                                Traceback (most recent call last)
Cell In [112], line 1
----&gt; 1 mae = mean_absolute_error(y_test, y_pred)
      2 print(&quot;MAE:&quot; , mae)

File ~\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:196, in mean_absolute_error(y_true, y_pred, sample_weight, multioutput)
    141 def mean_absolute_error(
    142     y_true, y_pred, *, sample_weight=None, multioutput=&quot;uniform_average&quot;
    143 ):
    144     &quot;&quot;&quot;Mean absolute error regression loss.
    145 
    146     Read more in the :ref:`User Guide &lt;mean_absolute_error&gt;`.
   (...)
    194     0.85...
    195     &quot;&quot;&quot;
--&gt; 196     y_type, y_true, y_pred, multioutput = _check_reg_targets(
    197         y_true, y_pred, multioutput
    198     )
    199     check_consistent_length(y_true, y_pred, sample_weight)
    200     output_errors = np.average(np.abs(y_pred - y_true), weights=sample_weight, axis=0)

File ~\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:100, in _check_reg_targets(y_true, y_pred, multioutput, dtype)
     66 def _check_reg_targets(y_true, y_pred, multioutput, dtype=&quot;numeric&quot;):
     67     &quot;&quot;&quot;Check that y_true and y_pred belong to the same regression task.
     68 
     69     Parameters
   (...)
     98         correct keyword.
     99     &quot;&quot;&quot;
--&gt; 100     check_consistent_length(y_true, y_pred)
    101     y_true = check_array(y_true, ensure_2d=False, dtype=dtype)
    102     y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)

File ~\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py:387, in check_consistent_length(*arrays)
    385 uniques = np.unique(lengths)
    386 if len(uniques) &gt; 1:
--&gt; 387     raise ValueError(
    388         &quot;Found input variables with inconsistent numbers of samples: %r&quot;
    389         % [int(l) for l in lengths]
    390     )

ValueError: Found input variables with inconsistent numbers of samples: [25404, 101612]
</code></pre>
<p>I thought it was the way I split the columns but that doesn't seem to be the issue
It works when the test size is 50/50 but no other test size works</p>
","2023-01-11 15:15:49","2","Question"
"75080653","75080557","","<p>You could either</p>
<p><code>size = y_test.shape[0]</code></p>
<p>Which will give first element of the tuple, which is size.
Or you could get it directly using <code>size</code> attribute or the <code>len()</code> method.</p>
<pre><code>size = y_test.size
#or
size = len(y_test)
</code></pre>
","2023-01-11 09:15:07","7","Answer"
"75080616","75080557","","<p><code>y_test.shape</code> gives you a tuple.
So you can do <code>print(y_test.shape)[0]</code> to get the first element in the there which is the size of the Series.</p>
<p><code>shape</code> gives you a tuple because it comes from dataframes which give you the shape of the frame in (rows, columns).</p>
","2023-01-11 09:11:38","3","Answer"
"75080579","75080557","","<p>Use <code>len</code> or <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.size.html"" rel=""nofollow noreferrer""><code>Series.size</code></a>:</p>
<pre><code>y_test = pd.Series(range(20))

print(len(y_test))
20

print(y_test.size)
20
</code></pre>
","2023-01-11 09:08:10","1","Answer"
"75080557","","How can i get the size of a pandas Series?","<p>I have a pandas series test set y_test. I want to get its size for statistics.</p>
<p>Using this code :</p>
<pre><code>print(y_test.shape)

</code></pre>
<p>I get</p>
<pre><code>(31054,)
</code></pre>
<p>I want to get 31054</p>
","2023-01-11 09:05:58","1","Question"
"75074944","75063379","","<p>The Code that Ran for me is below, it will take some tweeks to get everything learning in the way that I want, but at least its running :)</p>
<pre><code>import gym
from gym import Env
import numpy as np
from gym.spaces import Discrete, Box, Dict
import random

Myarray = np.Myarray = [[3, 2]]
# Myarray = [[1][2 ]]
x1 = y1 = x2 = y2 = angle = 1


# create a custom class
class ShowerEnv(Env):
    def __init__(self, size=5):
        self.size = size
        high = np.array([[600, 600, 600, 600, 360]])
        low = np.array([[-1, -1, -1, -1, -360]])
        self.state = np.zeros((1, 5), dtype=np.float32)
        self.x1, self.y1, self.x2, self.y2, self.angle = 1, 1, 1, 1, 1
        self.action_space = Discrete(3)
        self.observation_space = gym.spaces.Box(low, high, dtype=np.float32, shape=(1, 5))
        self.shower_length = 60  # duration of  temperature

    def step(self, shower_action):
        x1 = y1 = x2 = y2 = angle = 1
        self.shower_length -= 1
        # this line sends a protobuf command to the car program and gets a response ie the true enviroment
        result = client.ChangeCoarse( shower_action - 1, True)#( shower_action - 1, True)
        self.state = np.array([result.X, result.Y, result.DesX, result.DesY, result.BearingToDest])

        if (result.ResetML == True):
            self.reset()
       # x1 = y1 = x2 = y2 = angle = 1
      #  self.state = np.array([x1, y1, x2, y2, angle])

        # this should set the reward and gets it from protobuf
        reward =    result.BearingToDest
       # reward = 1  # just put in to make the code run
        if self.shower_length &lt;= 0:
            done = True
        else:
            done = False
        info = ()
        info = {}

        return self.state, reward, done, info

    def render(self):
        pass

    def reset(self):
        result = client.ChangeResetDest()
        self.shower_length = 60000
        self.state = np.array([result.X, result.Y, result.DesX, result.DesY, result.BearingToDest])
        print(&quot;Resetting ML&quot;)
        return self.state


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam

env = ShowerEnv()
states = env.observation_space.shape
actions =  env.action_space.n


def build_model(states, actions):
    model = Sequential()
    model.add(Dense(units=24, activation='relu', input_shape=states))
    model.add(Dense(units=24, activation='relu'))
    model.add(Dense(actions, activation='linear'))
    model.add(Flatten())
    return model


# model =build_model(states,actions)
# model.compile(optimizer=Adam(learning_rate=1e-3), metrics=['mae'])
# del model
#print(model.summary())
from rl.agents import DQNAgent
from rl.policy import BoltzmannQPolicy
from rl.memory import SequentialMemory
import grpc
import Message_pb2_grpc as pb2_grpc, Message_pb2 as pb2


class UnaryClient(object):
    &quot;&quot;&quot;
     Client for gRPC functionality
     &quot;&quot;&quot;

    def __init__(self):
        self.host = 'localhost'
        self.server_port = 50052

        # instantiate a channel
        self.channel = grpc.insecure_channel(
            '{}:{}'.format(self.host, self.server_port))

        # bind the client and the server
        self.stub = pb2_grpc.UnaryStub(self.channel)

    def ChangeCoarse(self, val, TF):
        &quot;&quot;&quot;
        Client function to call the rpc for GetServerResponse
        &quot;&quot;&quot;
        message = pb2.MessageTo(MoveBoat=True, MoveBoatStep=TF, BoatDelta=val)
        # (message=&quot;message&quot;, Val=9, MoveBoat=True,MoveBoatStep=True, SailAngle=4, BoatAngle=5.79878, SailDelta=0, BoatDelta=-1)
        #     print(f'{message}')

        return self.stub.GetServerResponse(message)

    def ChangeSail(self, val, TF):
        &quot;&quot;&quot;
        Client function to call the rpc for GetServerResponse
        &quot;&quot;&quot;
        message = pb2.MessageTo(MoveBoat=True, MoveBoatStep=TF, SailDelta=val)
        # print(f'{message}')
        return self.stub.GetServerResponse(message)

    def ChangeWindDirection(self, val, TF):
        &quot;&quot;&quot;
        Client function to call the rpc for GetServerResponse
        &quot;&quot;&quot;
        message = pb2.MessageTo(MoveBoat=True, MoveBoatStep=TF, WindDelta=val)
        #   print(f'{message}')
        return self.stub.GetServerResponse(message)

    def ChangeResetDest(self):
        &quot;&quot;&quot;
        Client function to call the rpc for GetServerResponse
        &quot;&quot;&quot;
        message = pb2.MessageTo(MoveBoat=True, ResetTarget=True)
        # (message=&quot;message&quot;, Val=9, MoveBoat=True,MoveBoatStep=True, SailAngle=4, BoatAngle=5.79878, SailDelta=0, BoatDelta=-1)
        #     print(f'{message}')
        return self.stub.GetServerResponse(message)


client = UnaryClient()
result = client.ChangeCoarse(90, True)


# if result.
def build_agent(model, actions):
    policy = BoltzmannQPolicy()
    memory = SequentialMemory(limit=900000, window_length=1)
    dqn = DQNAgent(model=model, memory=memory, policy=policy, nb_actions=actions, nb_steps_warmup=100,
                   target_model_update=1e-2)
    return dqn


dqn = build_agent(build_model(states, actions), actions)
dqn.compile(optimizer=Adam(learning_rate=1e-5), metrics=['mae'])
dqn.fit(env, nb_steps=1000000, visualize=False, verbose=1)
</code></pre>
","2023-01-10 19:30:49","0","Answer"
"75065225","75063379","","<p>First, just to make sure, the state you return in <em>reset</em> should look something like:</p>
<pre><code>self.state = np.array([x1, y1, x2, y2, angle])
</code></pre>
<p>I don't see the <em>step</em> function in your code, but I assume you also modified it to return <em>self.state</em>?</p>
<p>Also, your action space is the same as the observation space, it is not normal is it? Given what you said, there are 3 actions so it should be:</p>
<pre><code>self.action_space = Discrete(3)
</code></pre>
<p>Without the full code, it is not really possible to find the cause of your problem. Could you show it?</p>
<p>I also noticed a minus sign which I find strange (although it seems unrelated to your main problem):</p>
<pre><code>high = -np.array([ 5,  5,  5,  5,  5])
       ^
      HERE
</code></pre>
","2023-01-10 03:40:10","0","Answer"
"75063379","","Im having problems adding observation space to a custom Gym enviroment","<p>I am using <a href=""https://www.section.io/engineering-education/building-a-reinforcement-learning-environment-using-openai-gym/"" rel=""nofollow noreferrer"">this code</a>. I have modified it to work with a car <strong>(0 Left, 1 Straight, 2 Right)</strong>.</p>
<p>I would like to add some observations, such as <strong>Destination (XY), Car Location (XY) bearing (angle), distance_to_destination and bearing_of_destination</strong>, in the hope that the car can find its way to the destination.</p>
<p>I have spent most of the days trying to get this to work, however failed, and failed in many different ways. The crux of the problem seams to be getting the input shape to match.</p>
<p>I think the closest that I have got is this:</p>
<pre class=""lang-py prettyprint-override""><code>def __init__(self):
    low = np.array([-5, -5, -5, -5, -5])
    high = -np.array([ 5,  5,  5,  5,  5])
    self.observation_space = gym.spaces.Box(low, high, dtype=np.float32)
    self.action_space = gym.spaces.Box(low, high, dtype=np.float32)

def reset(self):
    self.state = Myarray# \[\[1,2\], \[1,2\],\[1,2\],\[1,2\],\[1,2\]\]#result.BearingToDest
    self.shower_length = 60000
    return  self.state

def build_model(states, actions):
    model = Sequential()
    model.add(Dense(units=24, activation='relu', input_shape=\[ 2\]))
    model.add(Dense(units=24, activation='relu'))
    model.add(Dense(actions, activation='linear'))
    return model
</code></pre>
<p>When I run it and the model loads, the error message is :</p>
<pre><code>ValueError: Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (1, 1, 1, 2)

**Training for 1000000 steps ...
Resetting ML
Interval 1 (0 steps performed)**
</code></pre>
","2023-01-09 21:59:10","0","Question"
"75048298","75048117","","<p>You can just concatenate your prefix with the desired column:</p>
<pre class=""lang-py prettyprint-override""><code>df['review'] = 'xxx' + df['review']
</code></pre>
","2023-01-08 13:55:21","0","Answer"
"75048286","75048117","","<p>That's the expected behavior- <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.add_prefix.html"" rel=""nofollow noreferrer""><code>.add_prefix</code></a> adds prefix to the <em>labels</em> (row labels if it's a series like <code>correct_X_test['review']</code>or<code>Modified_X_test</code>, column labels if it's a DataFrame like <code>correct_X_test</code>).</p>
<p>You could try something like</p>
<pre class=""lang-py prettyprint-override""><code>correct_X_test[&quot;review_prefixed&quot;] = [f' xxxx {r}' for r in list(correct_X_test[&quot;review&quot;])]
</code></pre>
<p>And then <code>correct_X_test</code> will have an added column with prefixed <code>review</code>s.</p>
","2023-01-08 13:54:09","0","Answer"
"75048117","","add a prefix to all lines of a dataframe's column","<p>I have a pandas dataframe 'correct_X_test' as mentioned :</p>
<pre><code>index                                             review
2       38448  روايه سخيفه جدا. مش عارفه العيب منى ولا منها. ...
3       85548  أحمد مراد يتطور أسلوبه من رواية إلى أخرى.يحاول...
4      127165  كثيرا ما هربت من أنوثتي وكثيرا ما هربت منك لأن...
7       72234  ع عكس معظم الناس معجبنيش أوي. عجبني جداااا بعض...
8      150053  أحببت هذا الجزء أكثر .ذلك أن عرض الدكتور المسي...
...       ...                                                ...
31048   81162  الاسود يليق بك. لا اعرف كيف اصنفها. روايه روما...
31049  102431  تجتاحنى حالة من الهدوء النفسى عقب قراءة هذا ال...
31051  140999  اه ، كم لهذا الكتاب وقع في قلبي. قرأته بالوقت ...
31052  128882  تريد القيام برحله حول العالم برغم مكوثك بمكانك...
31053   85422  بالرغم من أنك قد تكون قرأت الكثير من الكتب الت...

[23005 rows x 2 columns]
</code></pre>
<p>I want to add a prefix to the review columns.
Using this code the prefix is added to the index instead of the text as below:</p>
<pre><code>Modified_X_test = correct_X_test[&quot;review&quot;].add_prefix(' xxxx ')
print(Modified_X_test)
</code></pre>
<pre><code>xxxx 2        روايه سخيفه جدا. مش عارفه العيب منى ولا منها. ...
 xxxx 3        أحمد مراد يتطور أسلوبه من رواية إلى أخرى.يحاول...
 xxxx 4        كثيرا ما هربت من أنوثتي وكثيرا ما هربت منك لأن...
 xxxx 7        ع عكس معظم الناس معجبنيش أوي. عجبني جداااا بعض...
 xxxx 8        أحببت هذا الجزء أكثر .ذلك أن عرض الدكتور المسي...
                                     ...                        
 xxxx 31048    الاسود يليق بك. لا اعرف كيف اصنفها. روايه روما...
 xxxx 31049    تجتاحنى حالة من الهدوء النفسى عقب قراءة هذا ال...
 xxxx 31051    اه ، كم لهذا الكتاب وقع في قلبي. قرأته بالوقت ...
 xxxx 31052    تريد القيام برحله حول العالم برغم مكوثك بمكانك...
 xxxx 31053    بالرغم من أنك قد تكون قرأت الكثير من الكتب الت...
Name: review, Length: 23005, dtype: object
</code></pre>
<p>Could you help me, please?
Thanks a lot,</p>
","2023-01-08 13:26:06","0","Question"
"75042383","75042333","","<p>Pandas typically represents invalid timestamps with <code>NaT</code> (Not a Time). You can use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html"" rel=""nofollow noreferrer""><code>pd.to_datetime</code></a> with <code>errors=&quot;coerce&quot;</code>:</p>
<pre><code>import pandas as pd

series = pd.Series([&quot;2023-01-07 12:34:56&quot;, &quot;error&quot;])
out = pd.to_datetime(series, format=&quot;%Y-%m-%d %H:%M:%S&quot;, errors=&quot;coerce&quot;)
</code></pre>
<p>output:</p>
<pre><code>0   2023-01-07 12:34:56
1                   NaT
dtype: datetime64[ns]
</code></pre>
","2023-01-07 17:28:43","2","Answer"
"75042351","75042333","","<p>Create a function with try except, like this:</p>
<pre><code>def to_timestamp(x):
    try:
        return datetime.datetime.strptime(x, &quot;%Y-%m-%d %H:%M:%S&quot;).timestamp()
    except:
        return None

series = series.apply(to_timestamp)
</code></pre>
","2023-01-07 17:24:32","0","Answer"
"75042333","","How to convert Pandas Series to Timestamp when not every value is convertible?","<p><strong>Context</strong></p>
<p>I have a <code>Pandas</code> <code>Series</code> containing <code>Dates</code> in a <code>String</code> format <em>(e.g. 2017-12-19 09:35:00)</em>. My goal is to convert this <code>Series</code> into <code>Timestamps</code> <em>(Time in Seconds since 1970)</em>.</p>
<p>The difficulty is, that some <code>Values</code> in this <code>Series</code> are corrupt and cannot be converted to a <code>Timestamp</code>. In that case, they should be converted to <code>None</code>.</p>
<hr />
<p><strong>Code</strong></p>
<pre class=""lang-py prettyprint-override""><code>import datetime

series = series.apply(lambda x: datetime.datetime.strptime(x, &quot;%Y-%m-%d %H:%M:%S&quot;).timestamp())
</code></pre>
<hr />
<p><strong>Question</strong></p>
<blockquote>
<p>The code above would work when all <code>Values</code> are in the correct format, however there is corrupt data.</p>
</blockquote>
<ul>
<li>How can I achieve my goal while converting all not-convertible data to <code>None</code>?</li>
</ul>
","2023-01-07 17:22:13","0","Question"
"75036830","75026592","","<p>My guess is that one the rationales behind the enhancement of <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.set_config.html#sklearn.set_config"" rel=""nofollow noreferrer""><code>set_config()</code></a> by means of the parameter <code>transform_output</code> was indeed to enable also <em>custom transformers</em> to output pandas DataFrames.</p>
<p>By looking at the <a href=""https://github.com/scikit-learn/scikit-learn/blob/2e481f114169396660f0051eee1bcf6bcddfd556/sklearn/utils/_set_output.py#L150"" rel=""nofollow noreferrer"">underlying code</a>, I've found one hack that allows <em>custom transformers</em> to output pandas DataFrames without the need to <em><strong>explicitly</strong></em> set the global configuration; it is sufficient to implement a dummy <code>.get_feature_names_out()</code> method. However, this works just because in this way the global configuration is <em>automatically</em> set.
Indeed, <a href=""https://github.com/scikit-learn/scikit-learn/blob/2e481f114169396660f0051eee1bcf6bcddfd556/sklearn/utils/_set_output.py#L157"" rel=""nofollow noreferrer""><code>_auto_wrap_is_configured()</code></a> returns <em>True</em> if <code>.get_feature_names_out()</code> is available and, if so, <code>full_pipeline</code> reverts to calling <a href=""https://github.com/scikit-learn/scikit-learn/blob/2e481f114169396660f0051eee1bcf6bcddfd556/sklearn/utils/_set_output.py#L200"" rel=""nofollow noreferrer"">this <code>.set_output()</code>
method</a> rather than getting to <a href=""https://github.com/scikit-learn/scikit-learn/blob/98cf537f5c538fdbc9d27b851cf03ce7611b8a48/sklearn/utils/_set_output.py#L237"" rel=""nofollow noreferrer"">this <code>._safe_set_output()</code> method</a>, where the first sets the global configuration with <code>transform=&quot;pandas&quot;</code> automatically, while the second would output the <a href=""https://github.com/scikit-learn/scikit-learn/blob/2e481f114169396660f0051eee1bcf6bcddfd556/sklearn/utils/_set_output.py#L264"" rel=""nofollow noreferrer"">ValueError</a> that you're getting.</p>
<p>Here's a working example:</p>
<pre><code>from sklearn.compose import ColumnTransformer
from sklearn.pipeline import make_pipeline
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np
import pandas as pd

df = pd.DataFrame({'column_1': [np.nan, 1.34, 10.98, 3.34, 5.32], 'column_2': [9.78, 20.34, 43.54, 1.98, 7.85]})

class StandardScalerCustom(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        self.mean = np.mean(X, axis=0)
        self.std = np.std(X, axis=0)
        return self

    def transform(self, X):
        return (X - self.mean) / self.std

    def get_feature_names_out(self):
        pass

impute_pipe = make_pipeline(SimpleImputer())
scale_pipe = make_pipeline(StandardScalerCustom())

full_pipeline = ColumnTransformer([
    (&quot;imputer&quot;, impute_pipe, ['column_1']),
    (&quot;scaler&quot;, scale_pipe, ['column_2'])
])

full_pipeline.set_output(transform=&quot;pandas&quot;)
full_pipeline.fit_transform(df)
</code></pre>
","2023-01-06 22:54:19","4","Answer"
"75031148","75026436","","<p>Here is an example without <code>tf.py_function</code>, as requested by @KyleFHartzenberg:</p>
<pre><code>import tensorflow as tf

# 0 = negative
# 1 = positive
documents = [['topology freaking sucks man, what a waste of time!', 0], ['wow bro you a NLP fan? Tell me more I want to know', 1], 
['you know, I will eventually die',0], ['the secret to happiness is to only be depresssed',0], 
['what is the floor without feet', 1], ['regicide is permissable only in historical situations',1],
['I do not like delivering wehat based products for I am allergic to wheat', 0], 
['Why does he ring the large bell every hour?',0],
['Wisdom comes not from experience but from knowing',1], 
['Little is known of the inner workings of the feline mind', 1]]

VOCAB_SIZE = 500 # max amount of vocabulary amongst all documents
MAX_SEQUENCE_LENGTH = 50 # maximum amount of words/tokens that will be considered in each document
# output mode 'int' will assign unique integer per token, so in our example below, 'topology' is assigned the value
# 19. Notice that these integers are randomly assigned and essentially acts as a hashmap
int_vectorize_layer = tf.keras.layers.TextVectorization(
    max_tokens=VOCAB_SIZE,
    output_mode='int',
    output_sequence_length = MAX_SEQUENCE_LENGTH,
)

def int_vectorize_text(sentence, label):
  return int_vectorize_layer(sentence), label


def generate_data(sentences, labels):
  for s, l in zip(sentences,labels):
    yield s, l

train_docs = documents[:8]
val_docs = documents[8:]

train_sentences = [d[0] for d in train_docs]
train_labels = [d[1] for d in train_docs]

val_sentences = [d[0] for d in val_docs]
val_labels = [d[1] for d in val_docs]

train_sentences_tensor = tf.convert_to_tensor(train_sentences)
train_labels_tensor = tf.convert_to_tensor(train_labels)

train_dataset = tf.data.Dataset.from_generator(
    generate_data, output_signature=(
         tf.TensorSpec(shape=(), dtype=tf.string),
         tf.TensorSpec(shape=(), dtype=tf.int32)), args=(train_sentences_tensor, train_labels_tensor))

# adapt layer using training sentences
int_vectorize_layer.adapt(train_dataset.map(lambda x, y: x))
int_train_df = train_dataset.map(int_vectorize_text)

for x, y in int_train_df:
  print(x, y)
  break
</code></pre>
<pre><code>tf.Tensor(
[19 42 22 34  7 10 17 29 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0], shape=(50,), dtype=int64) tf.Tensor(0, shape=(), dtype=int32)
</code></pre>
","2023-01-06 12:49:23","2","Answer"
"75030447","75026436","","<p>After reviewing @AloneTogether's clean and more appropriate solution, it appears your issue is stemming from <code>train_dataset</code> and <code>val_dataset</code> definitions. The documentation for the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">tf.data.Dataset.from_generator</a> function recommends that one</p>
<blockquote>
<p>... use the <code>output_signature</code> argument. In this case the output will be assumed to consist of objects with the classes, shapes and types defined by <code>tf.TypeSpec</code> objects from <code>output_signature</code> argument</p>
</blockquote>
<p>As you didn't use the <code>output_signature</code> argument, it defaulted to using the deprecated way which uses either the <code>output_types</code> argument alone, or together with <code>output_shapes</code>. In your case, <code>output_types</code> was set to <code>(tf.string, tf.int32)</code> but because you left the <code>output_shapes</code> argument empty, it defaulted to &quot;unknown&quot;.</p>
<p>Later when you go to <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">map</a> the <code>int_vectorize_text</code> function, it attempts to check if the input shape rank is greater than 1, however, it receives &quot;shape=&lt;unknown&gt;&quot; which is of type <code>NoneType</code> and so the TypeError manifests when comparing with type <code>int</code>.</p>
<p>Knowing all this, you can simply add <code>((), ())</code> as the output shape in your <code>from_generator</code> function call after the output type <code>(tf.string, tf.int32)</code>. Hence, replace these lines:</p>
<pre class=""lang-py prettyprint-override""><code>train_dataset = tf.data.Dataset.from_generator(
    generate_data, (tf.string, tf.int32), args=(train_sentences_tensor, train_labels_tensor))

val_dataset = tf.data.Dataset.from_generator(
    generate_data, (tf.string, tf.int32), args=(val_sentences_tensor, val_labels_tensor))
</code></pre>
<p>With:</p>
<pre class=""lang-py prettyprint-override""><code>train_dataset = tf.data.Dataset.from_generator(
    generate_data, output_types=(tf.string, tf.int32), output_shapes=((), ()), args=(train_sentences_tensor, train_labels_tensor))

val_dataset = tf.data.Dataset.from_generator(
    generate_data, output_types=(tf.string, tf.int32), output_shapes=((), ()), args=(val_sentences_tensor, val_labels_tensor))
</code></pre>
<p>Or, the TensorFlow recommended way as @AloneTogether demonstrated:</p>
<pre class=""lang-py prettyprint-override""><code>train_dataset = tf.data.Dataset.from_generator(
    generate_data, output_signature=(
         tf.TensorSpec(shape=(), dtype=tf.string),
         tf.TensorSpec(shape=(), dtype=tf.int32)), args=(train_sentences_tensor, train_labels_tensor))

val_dataset = tf.data.Dataset.from_generator(
    generate_data, output_signature=(
         tf.TensorSpec(shape=(), dtype=tf.string),
         tf.TensorSpec(shape=(), dtype=tf.int32)), args=(val_sentences_tensor, val_labels_tensor))
</code></pre>
<p>I've removed my original solution as I don't believe in propagating code that is suboptimal. Full credit to @AloneTogether for showing how it's supposed to be done. My intent with this edit is to hopefully explain the error and why it occurred so that you and future readers have a better understanding.</p>
","2023-01-06 11:38:30","2","Answer"
"75026592","","How to create pandas output for custom transformers?","<p>There are a lot of changes in scikit-learn 1.2.0 where it supports pandas output for all of the transformers but how can I use it in a custom transformer?</p>
<p><strong>In [1]:</strong> Here is my custom transformer which is a standard scaler: <br></p>
<pre><code>from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np

class StandardScalerCustom(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        self.mean = np.mean(X, axis=0)
        self.std = np.std(X, axis=0)
        return self

    def transform(self, X):
        return (X - self.mean) / self.std
</code></pre>
<p><strong>In [2]:</strong> Created a specific <code>scale</code> pipeline</p>
<pre><code>scale_pipe = make_pipeline(StandardScalerCustom())
</code></pre>
<p><strong>In [3]:</strong> Added in a full pipeline where it may get mixed with scalers, imputers, encoders etc.</p>
<pre><code>full_pipeline = ColumnTransformer([
    (&quot;imputer&quot;, impute_pipe, ['column_1'])
    (&quot;scaler&quot;, scale_pipe, ['column_2'])
])

# From documentation
full_pipeline.set_output(transform=&quot;pandas&quot;)
</code></pre>
<p>Got this error: <br></p>
<p><strong>ValueError</strong>: Unable to configure output for StandardScalerCustom() because <code>set_output</code> is not available.</p>
<hr />
<p>There is a solution and it can be:
<code>set_config(transform_output=&quot;pandas&quot;)</code> <br></p>
<p>But in <strong>case-to-case basis</strong>, how can I create a function in StandardScalerCustom() class that can fix the error above?</p>
","2023-01-06 03:14:45","11","Question"
"75026436","","Constructing Tensorflow Dataset and applying TextVectorization layer using map method","<p>I'm attempting to construct input to an embedding layer for an NLP model. However, I am having problems with converting raw text data to the numerical input required by the embedding layer.</p>
<p>Here is some example data to illustrate what I wish to feed to the NLP model:</p>
<pre><code># 0 = negative
# 1 = positive
documents = [['topology freaking sucks man, what a waste of time!', 0], ['wow bro you a NLP fan? Tell me more I want to know', 1], 
['you know, I will eventually die',0], ['the secret to happiness is to only be depresssed',0], 
['what is the floor without feet', 1], ['regicide is permissable only in historical situations',1],
['I do not like delivering wehat based products for I am allergic to wheat', 0], 
['Why does he ring the large bell every hour?',0],
['Wisdom comes not from experience but from knowing',1], 
['Little is known of the inner workings of the feline mind', 1]]
</code></pre>
<p>Each document contains one sentence and one label. This data format was inspired by the tutorial prompt I am working on:</p>
<blockquote>
<p>Your Task
Your task in this lesson is to design a small document classification problem with 10 documents of one sentence each and associated labels of positive and negative outcomes and to train a network with word embedding on these data.</p>
</blockquote>
<p>I utilize the TextVectorization function from the keras library:</p>
<pre><code># create preprocessing layer
VOCAB_SIZE = 500 # max amount of vocabulary amongst all documents
MAX_SEQUENCE_LENGTH = 50 # maximum amount of words/tokens that will be considered in each document
# output mode 'int' will assign unique integer per token, so in our example below, 'topology' is assigned the value
# 19. Notice that these integers are randomly assigned and essentially acts as a hashmap
int_vectorize_layer = TextVectorization(
    max_tokens=VOCAB_SIZE,
    output_mode='int',
    output_sequence_length = MAX_SEQUENCE_LENGTH
)
</code></pre>
<p>The issue now becomes applying this vectorized layer to the raw data <code>documents</code>. Here is the following code I have to convert the raw data into a tensorflow <code>Dataset</code> object:</p>
<pre><code># Applies adapted layer to tensorflow dataset
def int_vectorize_text(sentence, label):
  sentence = tf.expand_dims(sentence, -1)
  sentence = tf.squeeze(sentence, axis=-1)
  return int_vectorize_layer(sentence), label


# passes raw data as a generator to the Dataset from_generator constructor
def generate_data(sentences, labels):
  for s, l in zip(sentences,labels):
    yield s, l

# split raw data between training and validation set
train_docs = documents[:8]
val_docs = documents[8:]

# separate sentences and labels
train_sentences = [d[0] for d in train_docs]
train_labels = [d[1] for d in train_docs]

val_sentences = [d[0] for d in val_docs]
val_labels = [d[1] for d in val_docs]

# convert to tensors
train_sentences_tensor = tf.convert_to_tensor(train_sentences)
train_labels_tensor = tf.convert_to_tensor(train_labels)

val_sentences_tensor = tf.convert_to_tensor(val_sentences)
val_labels_tensor = tf.convert_to_tensor(val_labels)

# build tensorflow Dataset using the above generator function on the newly constructed tensor objects
train_dataset = tf.data.Dataset.from_generator(
    generate_data, (tf.string, tf.int32), args=(train_sentences_tensor, train_labels_tensor))
val_dataset = tf.data.Dataset.from_generator(
    generate_data, (tf.string, tf.int32), args=(val_sentences_tensor, val_labels_tensor))

# adapt layer using training sentences
int_vectorize_layer.adapt(train_sentences)

# now here is where the error occurs
int_train_df = train_dataset.map(int_vectorize_text) # ERROR
int_val_df = val_dataset.map(int_vectorize_text)
</code></pre>
<p>As you can see, an error occurs when we attempt to map the <code>int_vectorize_text</code> to the tensorflow dataset. Specifically, I get the following error:</p>
<pre><code>TypeError                                 Traceback (most recent call last)
/home/akagi/Documents/Projects/MLMastery NLP Tutorial/Lesson 5 - Learned Embedding.ipynb Cell 7 in &lt;cell line: 21&gt;()
     19 # Use the map method to apply the int_vectorize_text function to each element of the dataset
     20 int_vectorize_layer.adapt(train_sentences)
---&gt; 21 int_train_df = train_dataset.map(int_vectorize_text)
     22 int_val_df = val_dataset.map(int_vectorize_text)

File ~/Documents/Projects/.venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2294, in DatasetV2.map(self, map_func, num_parallel_calls, deterministic, name)
   2291   if deterministic is not None and not DEBUG_MODE:
   2292     warnings.warn(&quot;The `deterministic` argument has no effect unless the &quot;
   2293                   &quot;`num_parallel_calls` argument is specified.&quot;)
-&gt; 2294   return MapDataset(self, map_func, preserve_cardinality=True, name=name)
   2295 else:
   2296   return ParallelMapDataset(
   2297       self,
   2298       map_func,
   (...)
   2301       preserve_cardinality=True,
   2302       name=name)

File ~/Documents/Projects/.venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5499, in MapDataset.__init__(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)
   5497 self._use_inter_op_parallelism = use_inter_op_parallelism
   5498 self._preserve_cardinality = preserve_cardinality
-&gt; 5499 self._map_func = structured_function.StructuredFunctionWrapper(
...
    '&gt;' not supported between instances of 'NoneType' and 'int'
    
    Call arguments received by layer 'text_vectorization' (type TextVectorization):
      • inputs=tf.Tensor(shape=&lt;unknown&gt;, dtype=string)
</code></pre>
<p>Which seems to imply that a <code>NoneType</code> is being passed. However, I checked the construction of <code>train_dataset</code> and it appears to be correct. Here is what it looks like:</p>
<pre><code>(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'topology freaking sucks man, what a waste of time!'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;)
(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'wow bro you a NLP fan? Tell me more I want to know'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'you know, I will eventually die'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;)
(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'the secret to happiness is to only be depresssed'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;)
(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'what is the floor without feet'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'regicide is permissable only in historical situations'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'I do not like delivering wehat based products for I am allergic to wheat'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;)
(&lt;tf.Tensor: shape=(), dtype=string, numpy=b'Why does he ring the large bell every hour?'&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;)
</code></pre>
<p>Furthermore, if I apply <code>int_vectorize_text</code> manually in a loop like so:</p>
<pre><code>for x in train_dataset:
    print(int_vectorize_text(x[0], x[1]))
</code></pre>
<p>No error occurs and I get the desired output. What is going on here?</p>
","2023-01-06 02:43:49","2","Question"
"75023660","75023029","","<p>Here's a generic way to get the result you've specified, irrespective of the number of epochs or the number or labels of rows and columns:</p>
<pre class=""lang-py prettyprint-override""><code>df2 = df.stack().apply(pd.Series)
df2.index = ['_'.join(reversed(x)) for x in df2.index]
df2 = df2.T.assign(epochs=range(1, len(df2.columns) + 1)).set_index('epochs').reset_index()
</code></pre>
<p>Output:</p>
<pre><code>   epochs  train_auc  test_auc  train_logloss  test_logloss
0       1      0.432     0.456          0.123         0.321
1       2      0.543     0.567          0.234         0.432
2       3      0.523     0.678          0.345         0.543
</code></pre>
<p>Explanation:</p>
<ul>
<li>Use <code>stack()</code> to convert the input dataframe to a series (of lists) with a multiindex that matches the desired column sequence in the question</li>
<li>Use <code>apply(pd.Series)</code> to convert the series of lists to a dataframe with each list converted to a row and with column count equal to the uniform length of the list values in the input series (in other words, equal to the number of epochs)</li>
<li>Create the desired column labels from the latest multiindex rows transformed using <code>join()</code> with <code>_</code> as a separator, then use <code>T</code> to transpose the dataframe so these index labels (which are the desired column labels) become column labels</li>
<li>Use <code>assign()</code> to add a column named <code>epochs</code> enumerating the epochs beginning with <code>1</code></li>
<li>Use <code>set_index()</code> followed by <code>reset_index()</code> to make <code>epochs</code> the leftmost column.</li>
</ul>
","2023-01-05 19:50:51","1","Answer"
"75023233","75023029","","<p>Try this:</p>
<pre><code>df = pd.DataFrame({'train': {'auc': [0.432,       0.543,       0.523],
  'logloss': [0.123,       0.234,       0.345]},
 'test': {'auc': [0.456,       0.567,       0.678],
  'logloss': [0.321,       0.432,       0.543]}})

de=df.explode(['train', 'test'])
df_out = de.set_index(de.groupby(level=0).cumcount()+1, append=True).unstack(0)
df_out.columns = df_out.columns.map('_'.join)
df_out = df_out.reset_index().rename(columns={'index':'epochs'})
print(df_out)
</code></pre>
<p>Output:</p>
<pre><code>   epochs train_auc train_logloss test_auc test_logloss
0       1     0.432         0.123    0.456        0.321
1       2     0.543         0.234    0.567        0.432
2       3     0.523         0.345    0.678        0.543
</code></pre>
","2023-01-05 19:01:16","1","Answer"
"75023029","","Transforming a dataframe of dict of dict specific format","<p>I have this <code>df</code> dataset:</p>
<pre><code>df = pd.DataFrame({'train': {'auc': [0.432,       0.543,       0.523],
  'logloss': [0.123,       0.234,       0.345]},
 'test': {'auc': [0.456,       0.567,       0.678],
  'logloss': [0.321,       0.432,       0.543]}})
</code></pre>
<p><a href=""https://i.sstatic.net/U9pDj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/U9pDj.png"" alt=""enter image description here"" /></a></p>
<p>Where I'm trying to transform it into this:</p>
<p><a href=""https://i.sstatic.net/J6F4x.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/J6F4x.png"" alt=""enter image description here"" /></a></p>
<p>And also considering that:</p>
<ul>
<li><code>epochs</code> always have the same order for every cell, but instead of only 3 epochs, it could reach 1.000 or 10.000.</li>
<li>The column names and axis could change. For example another day the data could have <code>f1</code> instead of <code>logloss</code>, or <code>val</code> instead of <code>train</code>. But no matter the names, in <code>df</code> each row will always be a metric name, and each column will always be a dataset name.</li>
<li>The number of columns and rows in <code>df</code> could change too. There are some models with 5 datasets, and 7 metrics for example (which would give a <code>df</code> with 5 columns and 7 rows)</li>
<li>The columname of the output table should be <code>datasetname_metricname</code></li>
</ul>
<p>So I'm trying to build some generic code transformation where at the same time avoiding brute force transformations. Just if it's helpful, the <code>df</code> source is:</p>
<pre><code>df = pd.DataFrame(model_xgb.evals_result())
df.columns = ['train', 'test'] # This is the line that can change (and the metrics inside `model_xgb`)
</code></pre>
<p>Where <code>model_xgb = xgboost.XGBClassifier(..)</code>, but after using <code>model_xgb.fit(..)</code></p>
","2023-01-05 18:43:43","0","Question"
"75013141","75012589","","<p>Modified Code that worked:</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code># Read images and annotations
image_dir = r""C:/Users/X3/pharmaceutical-drugs-and-vitamins-synthetic-images/ImageClassesCombinedWithCOCOAnnotations/images_raw""
images = [os.path.join(image_dir, x) for x in os.listdir(image_dir)]

# Create a list of the file names of the images in the image_dir directory, without the full paths
image_filenames = [x for x in os.listdir(image_dir)]

# Create a list of the annotation paths that correspond to the images in the images list
annotations = []
for image_filename in image_filenames:
    annotation_filename = image_filename[:-3] + ""txt""
    annotation_path = os.path.join('C:/Users/X3/text_files', annotation_filename)
    annotations.append(annotation_path)

# Sort the images and annotations lists
images.sort()
annotations.sort()

# Split the dataset into train-valid-test splits 
train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)
val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)</code></pre>
</div>
</div>
</p>
","2023-01-05 01:57:20","0","Answer"
"75012610","75012589","","<p>This error is saying you have 10001 <code>images</code> and 0 <code>annotations</code>.</p>
<p>Make sure you're finding the correct files in the line</p>
<pre><code>annotations = [os.path.join('C:/Users/X3/1/text_files', x) for x in os.listdir('C:/Users/X3/1/text_files') if x[-3] == &quot;txt&quot;]
</code></pre>
","2023-01-05 00:08:12","0","Answer"
"75012589","","ValueError: Found input variables with inconsistent numbers of samples: [10001, 0]","<p>I was trying to split data with sklearn and I keep getting this error? This is the full documentation of what I am trying to do: <a href=""https://www.kaggle.com/code/vencerlanz09/pharmaceutical-drugs-classification-using-yolov5#%E2%9C%82%EF%B8%8FSplitting-the-Dataset"" rel=""nofollow noreferrer"">https://www.kaggle.com/code/vencerlanz09/pharmaceutical-drugs-classification-using-yolov5#%E2%9C%82%EF%B8%8FSplitting-the-Dataset</a></p>
<pre class=""lang-py prettyprint-override""><code># Read images and annotations
image_dir = r&quot;C:/Users/X3/pharmaceutical-drugs-and-vitamins-synthetic-images/ImageClassesCombinedWithCOCOAnnotations/images_raw&quot;
images = [os.path.join(image_dir, x) for x in os.listdir(image_dir)]
annotations = [os.path.join('C:/Users/X3/1/text_files', x) for x in os.listdir('C:/Users/X3/1/text_files') if x[-3] == &quot;txt&quot;]

images.sort()
annotations.sort()

# Split the dataset into train-valid-test splits 
train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)
val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)
</code></pre>
<p>**
The error I am getting is:**</p>
<pre class=""lang-py prettyprint-override""><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_6292\1715792042.py in &lt;module&gt;
      8 
      9 # Split the dataset into train-valid-test splits
---&gt; 10 train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 1.0, random_state = 1)
     11 val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)

~\anaconda3\lib\site-packages\sklearn\model_selection\_split.py in train_test_split(test_size, train_size, random_state, shuffle, stratify, *arrays)
   2415         raise ValueError(&quot;At least one array required as input&quot;)
   2416 
-&gt; 2417     arrays = indexable(*arrays)
   2418 
   2419     n_samples = _num_samples(arrays[0])

~\anaconda3\lib\site-packages\sklearn\utils\validation.py in indexable(*iterables)
    376 
    377     result = [_make_indexable(X) for X in iterables]
--&gt; 378     check_consistent_length(*result)
    379     return result
    380 

~\anaconda3\lib\site-packages\sklearn\utils\validation.py in check_consistent_length(*arrays)
    330     uniques = np.unique(lengths)
    331     if len(uniques) &gt; 1:
--&gt; 332         raise ValueError(
    333             &quot;Found input variables with inconsistent numbers of samples: %r&quot;
    334             % [int(l) for l in lengths]

ValueError: Found input variables with inconsistent numbers of samples: [10001, 0]
</code></pre>
","2023-01-05 00:04:36","-1","Question"
"75011843","","Displaying two SHAP beeswarm plots side by side in the same figure using matplotlib","<p>I wonder how to place two independent SHAP beeswarm plots into the same figure but in different axes. I am using matplotlib version <code>3.4.2</code>, shap version <code>0.39.0</code>, and Python <code>3.8.2</code>. I am trying using a single figure and two axes but realize that the beeswarm method does not handle the axis as parameter (error: <code>TypeError: beeswarm() got an unexpected keyword argument 'ax'</code>).</p>
<p>I am aware of this related <a href=""https://stackoverflow.com/questions/70696896/how-to-add-already-created-figures-to-a-subplot-figure"">question</a>, but this is different since I am using SHAP API. Any recommendation is welcome. Thanks in advance.</p>
<pre><code>from matplotlib import pyplot as plt
import shap

fig, axes = plt.subplots(1, 2, figsize=(35, 7), gridspec_kw = {&quot;wspace&quot;:1.0}) 

shap.plots.beeswarm(explainer_a(X_test_a), max_display=10, ax=axes[0])
shap.plots.beeswarm(explainer_b(X_test_b), max_display=10, ax=axes[1])

plt.show()
</code></pre>
","2023-01-04 22:05:01","1","Question"
"75006235","75005117","","<p>It's mission impossible. If fridge work without interference, then graph always looks the same. The change can be caused, for example, by opening a door, a breakdown, a major change in external conditions. But you cannot predict such events. Instead, you can try to warn about the possibility of problems in the near future, for example, based on a constant increase in average temperature. This situation may indicate a leak in the cooling system.
By the way, have you considered logging the temperature every 3 seconds? This is usually unjustified, because it is physically impossible for the temperature to change to a measurable degree in such an interval. Our team usually sets the login interval to 30 or 60 seconds in such cases. Sometimes even more. Depending on the size of the chamber, the way the air is circulated, the ratio of volume to power of the refrigeration unit, etc.</p>
","2023-01-04 13:32:32","-1","Answer"
"75005601","75005117","","<p>When the goal is to forecast rising temperatures, you can forecast the lower and upper peaks, i.e., their hight and distances. Assuming (simplified model) that the temperature change in between is linear we can, model each complete peak starting from a first lower peak of the temperature curve to the next upper peak down to next lower peak. So a complete peak can be seen as triangle which we easily integrate (calculate its area + the area of the rectangle below of it). The estimation can now be done by a integrating a number of complete peaks we have already measured. By repeating this procedure, we can do now a linear regression on the average temperatures and alert when the slope is above a defined threshold.</p>
<p>As this only tackles a certain kind of errors, one can do the same for the average distances between the upper peaks and the also for the lower peaks. I.e., take the times between them for a certain periode, fit a curve (linear regression can possibly be sufficient) and alert when the slope of the curve is indicating too long distances.</p>
","2023-01-04 12:42:23","0","Answer"
"75005117","","Model for predicting temperature data of fridge","<p>I set up a sensor which measures temperature data every 3 seconds. I collected the data for 3 days and have 60.000 rows in my csv export. Now I would like to forecast the next few days. When looking at the data you can already see a &quot;seasonality&quot; which displays the fridges heating and cooling cycle so I guess it shouldn't be too difficult to predict. I am not really sure if my data is too granular and if I should do some kind of undersampling. I thought about using a seasonal ARIMA model but I am having difficulties with picking parameters. As the seasonality in the data is pretty obious is there maybe a model that fits better? Please bear with me I'm pretty new to machine learning.</p>
<p><a href=""https://i.sstatic.net/kYYvj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/kYYvj.png"" alt=""enter image description here"" /></a></p>
","2023-01-04 11:58:56","2","Question"
"74997406","74994886","","<p>(Alternate answer for people reading the Second Edition).</p>
<p>I think this was an error which was corrected in the 2nd Edition of Aurélien Géron's &quot;<em>Hands-On Machine Learning with Scikit-Learn, Keras &amp; TensorFlow</em>.&quot;</p>
<p>The 2nd Edition describes Grid Search with cross validation on p. 76 of Chapter 2, writing:</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.model_selection import GridSearchCV

param_grid = [
  {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},
  {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},
]

forest_reg = RandomForestRegressor()

grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)

grid_search.fit(housing_prepared, housing_labels)
</code></pre>
<p>Since the <code>bootstrap=True</code> is the default, the updated <code>param_grid</code> does not have this issue:</p>
<pre><code>{'max_features': 2, 'n_estimators': 3}
{'max_features': 2, 'n_estimators': 10}
...
{'bootstrap': False, 'max_features': 4, 'n_estimators': 3}
{'bootstrap': False, 'max_features': 4, 'n_estimators': 10}
</code></pre>
","2023-01-03 18:38:41","0","Answer"
"74997254","74995705","","<p>This question is best suited for stack exchange as it is not a specific coding question.</p>
<p>Window size is the duration of observations that you ask an algorithm to consider when learning a time series. For example, if you need to predict tomorrow's temperature, and you use a window of 5 days, then the algorithm will divide your entire time series into segments of 6 days (5 training days and 1 prediction days) and try to learn how to use only 5 days of data to predict next 1 day based on the historic records.</p>
<p><strong>Advantage of short window:</strong>
You get more samples out of the time series so that your estimation of short term effects are more reliable (100 days historic time series will provide you around 95 samples if you are using a 5 day window - so the model is more certain about what the influence of the past 5 days has on next day temperature)</p>
<p><strong>Advantage of long window</strong>
long windows allow you to better learn seasonal and trend effects (think about events that happen yearly, monthly...etc). If your window is small - say 5 days, your model will not learn any seasonal effect that occurs monthly. However, if your window is 60 days, then every sample of data that you feed to the model would have at least 2 occurrences of the monthly seasonal effect, and this would enable your model to learn such seasonality.</p>
<p>The downside of long window is the number of samples decreases. Assuming an 100 day time series, 60 day window will only yield 40 samples of data. This would mean every parameter of your model is now fitted on much smaller sample of data and may be reduce the reliability of the model.</p>
","2023-01-03 18:23:40","5","Answer"
"74997020","74994886","","<p>Yes, this grid contains duplicates.</p>
<p>You can check by enumerating them:</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.model_selection import ParameterGrid

param_grid = [
    {&quot;preprocessing__geo__n_clusters&quot;: [5, 8, 10],
     &quot;random_forest__max_features&quot;: [4, 6, 8]},
    {&quot;preprocessing__geo__n_clusters&quot;: [10, 15],
     &quot;random_forest__max_features&quot;: [6, 8, 10]},
]

for params in ParameterGrid(param_grid=param_grid):
    print(params)
</code></pre>
<pre><code>{'preprocessing__geo__n_clusters': 5, 'random_forest__max_features': 4}
...
{'preprocessing__geo__n_clusters': 10, 'random_forest__max_features': 6}
{'preprocessing__geo__n_clusters': 10, 'random_forest__max_features': 8}
{'preprocessing__geo__n_clusters': 10, 'random_forest__max_features': 6}
{'preprocessing__geo__n_clusters': 10, 'random_forest__max_features': 8}
...
{'preprocessing__geo__n_clusters': 15, 'random_forest__max_features': 10}
</code></pre>
","2023-01-03 18:00:20","1","Answer"
"74996588","74995705","","<p>&quot;<strong>window size</strong>&quot; typically refers to the number of time periods that are used to calculate a statistic or model.</p>
<p>Advantages and Disadvantages of various window sizes relate to the <strong>balance</strong> between:</p>
<ul>
<li><code>the sensitivity to changes in the data</code> vs <code>susceptibility to noise &amp; outliers</code></li>
</ul>
<p>If you have ever dealt with moving average indicators on the stock market, you will understand that each window size has a purpose, and these different window sizes are often used in combination to get a more holistic view/understanding. eg. <code>MA20</code> vs <code>MA50</code> vs <code>MA100</code>. Each of these indicators are using a different window size to calculate the moving average of the stock of interest.</p>
<p><a href=""https://i.sstatic.net/aZYO4.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/aZYO4.png"" alt=""Stock Market"" /></a></p>
<h3>Image Source: Yahoo Finance</h3>
","2023-01-03 17:18:37","1","Answer"
"74995705","","What is window_size in time-series and What are the advantages and disadvantages of having small and large window_size?","<p>I am quite beginner in machine learning. I have tried a lot to understand this concept but I am unable to understand it on google. I need to understand this concept in easy way.</p>
<p>Please explain this question in easy words and much detail.</p>
","2023-01-03 15:59:37","1","Question"
"74994886","","I think there are repetitive combinations, no?","<p>I am reading the book Hands-on Machine Learning by Aurélien Géron, and in the second chapter at page 142 he wrote the following code about hyperparameter tuning combinations:</p>
<pre class=""lang-py prettyprint-override""><code>param_grid = [
  {'preprocessing__geo__n_clusters': [5, 8, 10],
   'random_forest__max_features': [4, 6, 8]},
  {'preprocessing__geo__n_clusters': [10, 15],
   'random_forest__max_features': [6, 8, 10]},
]
</code></pre>
<p>I think there are repetitive combinations, or am I missing something?</p>
","2023-01-03 14:44:00","0","Question"
"74987414","74984624","","<p>Testing multiple architectures / hyperparameters to find the best model is a task for <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"" rel=""nofollow noreferrer""><code>GridSearchCV</code></a>.</p>
<p>Here's an example testing the four architectures in the question:</p>
<pre class=""lang-py prettyprint-override""><code>from sklearn.datasets import make_classification
from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPClassifier

X, y = make_classification(n_samples=10_000)

# Initialize MLPClassifier with some parameters
clf = MLPClassifier(max_iter=300, alpha=1e-4, solver=&quot;sgd&quot;, tol=1e-4, learning_rate_init=.1)

# Search over `hidden_layer_sizes`
search = GridSearchCV(clf, param_grid={'hidden_layer_sizes': [(10,), (50,), (10,10,), (50,50,)]}, n_jobs=-1, verbose=3)
search.fit(X, y)

print(search.best_params_)
</code></pre>
<p>Which shows us that the best cross-validation performance <code>hidden_layer_sizes=(10, 10,)</code></p>
<pre><code>{'hidden_layer_sizes': (10, 10)}
</code></pre>
","2023-01-02 22:03:12","1","Answer"
"74986907","74986170","","<p>Without optimization or any warranty: Normalization and correctly applied gradient descent formula leads you to something like</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np


def gradient_descent(x_train, y_train, w=np.ones(3), b=float(0), learning_rate=0.001):
    predictions = x_train @ w + b
    error = predictions - y_train
    w = w - learning_rate * error @ x_train
    b = b - learning_rate * sum(error)
    return w, b


def train():
    # data with last column being the target
    data = np.array(
        [
            [5612.0, 1015.0, 472.0, 1283.0],
            [7650.0, 1129.0, 463.0, 1901.0],
            [720.0, 333.0, 117.0, 174.0],
            [1501.0, 515.0, 226.0, 337.0],
            [1454.0, 624.0, 262.0, 326.0],
        ]
    )
    norm_offset = np.mean(data[:])
    norm_factor = 1 / np.std(data[:])
    data_normalized = (data - norm_offset) * norm_factor
    x_train = data_normalized[:, :-1]
    y_train = data_normalized[:, -1]

    # start values
    w = np.ones(x_train.shape[1])
    b = float(0)

    # train
    for i in range(10_000):
        w, b = gradient_descent(x_train, y_train, w, b)
        # o = offset, f = factor, w'/b' normalized parameters, w/b original parameters
        #   y' = w' * x' + b'
        #   f * (y - o) = w' * f * (x - o) + b'
        #   y = w' * (x - o) + b' / f + o
        #   y = w' * x - o * sum(w') + b' / f + o
        #   =&gt; w = w', b = b' / f + o - o * sum(w')
        b_orig = b / norm_factor + norm_offset - sum(w) * norm_offset
        ssr = np.sum((data[:, :3] @ w + b_orig - data[:, 3]) ** 2)
        print(i, ':', w, b_orig, ssr)


if __name__ == &quot;__main__&quot;:
    train()
</code></pre>
<pre><code>...
9999 : [0.13503938 0.69644619 0.75400302] -386.71116671360414 71015.11748640954
</code></pre>
","2023-01-02 20:45:26","1","Answer"
"74986467","74986170","","<p>As suggested in the comments: feature scaling is a good idea (scikit-learn includes <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"" rel=""nofollow noreferrer""><code>SimpleScaler</code></a>, but it's pretty straightforward to subtract the mean of each column and divide by the standard deviation as well).</p>
<p>Also: the error term appears to be backwards, the residual is usually <code>prediction - true</code>.</p>
<pre class=""lang-py prettyprint-override""><code>error = prediction - y[i]
</code></pre>
","2023-01-02 19:48:07","2","Answer"
"74986170","","Getting infinity values from gradient descent","<p>I'm trying to implement a multivariable linear regression with gradient descent but when I try this:</p>
<pre><code># Starting values
w = np.ones(3) # The number of features is 3
b = float(0)

def gradient_descent():
  global w
  global b

  learning_rate = 0.0001

  for i in range(x_train.shape[0]):
    prediction = np.dot(x_train[i], w) + b
    error = x_train[i] - prediction
    for j in range(w.shape[0]):
      w[j] = w[j] - (error * x_train[i][j] * learning_rate)
    b = b - (error * learning_rate)

def train():
  for i in range(10_000):
    gradient_descent()
    print(i, ':', w, b)

train()
</code></pre>
<p>the output is</p>
<pre><code>0 : [inf inf inf] inf
1 : [inf inf inf] inf
2 : [inf inf inf] inf
3 : [inf inf inf] inf
4 : [inf inf inf] inf
5 : [inf inf inf] inf
6 : [inf inf inf] inf
....
</code></pre>
<p>so what I did wrong?
I tried to decrease the learning rate but nothing changed</p>
<p>data sample:</p>
<pre><code>total_rooms,population,households,bedrooms(target)
5612.0,1015.0,472.0,1283.0
7650.0,1129.0,463.0,1901.0
720.0,333.0,117.0,174.0
1501.0,515.0,226.0,337.0
1454.0,624.0,262.0,326.0
</code></pre>
<p>which total_rooms, population and households is x_train with shape (17000, 3)
and bedrooms is y_train with shape (17000, 1)</p>
<p>when I try to scale the data using <code>sklearn.preprocessing.StandardScaler</code> before splitting the data</p>
<pre><code>from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
train_data = scaler.fit_transform(train_data)
x_train = train_data[:, :3]
y_train = train_data[:, -1]
</code></pre>
<p>I get <code>nan</code> instead of <code>inf</code>!</p>
<p>note: The data works fine with scaling or not with <code>sklearn.linear_model.LinearRegression</code></p>
","2023-01-02 19:08:55","1","Question"
"74986028","74984624","","<p>MLPClassifier(hidden_layer_sizes=<strong>hl_parameters['hidden_layer_sizes']</strong>, max_iter=300, alpha=1e-4, solver='sgd', tol=1e-4, learning_rate_init=.1, verbose=True, random_state=ID)</p>
<p>that field is an issue...you are providing a list of tuples as input for hidden_layer_sizes. MLPClassifier can only take tuple for hidden_layer_sizes.</p>
<p>if you need 3 hidden layers with 10, 50 and 50 neurons, just put (10,50,50) for hidden layer sizes. If you are testing different configurations, you can make a list of tuples and loop through the different combinations one at a time instead of putting the full list.</p>
","2023-01-02 18:50:26","1","Answer"
"74984624","","How can I pass a combination of architectures to a MLPClassifier?","<p>I need to create a <code>MLPClassifier</code> with <code>hidden_layer_sizes</code>, that is a tuple specifying the number of neurons in the hidden layers.</p>
<p>For example: <code>(10,)</code> means that there is only 1 hidden layer with 10 neurons. <code>(10, 50,)</code> means that there are 2 hidden layers, the first with 10 neurons, the second with 50 neurons and so on. I want to test each of them in sequence.</p>
<p>I have passed this dictionary:</p>
<pre><code>hl_parameters = {'hidden_layer_sizes': [(10,), (50,), (10,10,), (50,50,)]}
</code></pre>
<p>And defined <code>MLPClassifier</code> like this:</p>
<pre><code>mlp_cv = MLPClassifier(hidden_layer_sizes=hl_parameters['hidden_layer_sizes'], max_iter=300,       alpha=1e-4, solver='sgd', tol=1e-4, learning_rate_init=.1, verbose=True, random_state=ID)
mlp_cv.fit(X_train, y_train)
</code></pre>
<p>But when I fit the model, I got this error:</p>
<pre><code>TypeError                                    

    Traceback (most recent call last)
Input In [65], in &lt;cell line: 9&gt;()
      8 mlp_cv = MLPClassifier(hidden_layer_sizes=hl_parameters['hidden_layer_sizes'], max_iter=300, alpha=1e-4, solver='sgd', tol=1e-4, learning_rate_init=.1, verbose=True, random_state=ID)
----&gt; 9 mlp_cv.fit(X_train, y_train)

File ~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:752, in BaseMultilayerPerceptron.fit(self, X, y)
    735 def fit(self, X, y):
    736     &quot;&quot;&quot;Fit the model to data matrix X and target(s) y.
    737 
    738     Parameters
   (...)
    750         Returns a trained MLP model.
    751     &quot;&quot;&quot;
--&gt; 752     return self._fit(X, y, incremental=False)

File ~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:385, in BaseMultilayerPerceptron._fit(self, X, y, incremental)
    383 # Validate input parameters.
    384 self._validate_hyperparameters()
--&gt; 385 if np.any(np.array(hidden_layer_sizes) &lt;= 0):
    386     raise ValueError(
    387         &quot;hidden_layer_sizes must be &gt; 0, got %s.&quot; % hidden_layer_sizes
    388     )
    389 first_pass = not hasattr(self, &quot;coefs_&quot;) or (
    390     not self.warm_start and not incremental
    391 )

TypeError: '&lt;=' not supported between instances of 'tuple' and 'int'
</code></pre>
<p>I cannot find a solution. How do I solve this?</p>
","2023-01-02 16:09:12","2","Question"
"74984222","74979359","","<p>The weights are shared for a layer. After self-attention, all the transformed vectors are assumed to be in the same vector space. So, the same type of transformation can be applied to each of those vectors. This intuition is also used in some other tasks like sequence labelling where each token share the same classification head. This reduces the parameters of the network and forces the self-attention to do the heavy lifting.</p>
<p>Quoting from the link you provided,</p>
<blockquote>
<p>While the linear transformations are the same across different positions, they use different parameters from layer to layer.</p>
</blockquote>
<p>The <code>x</code> passed in the <code>forward</code> function is a single word vector <code>z_i</code>, not a list.</p>
","2023-01-02 15:30:12","2","Answer"
"74981734","","Why is shap.plots.bar() not working for me?","<p>I computed several shap values for my Neural Net and wanted to plot them as a bar plot that only shows the top 10 most important features as bars and sums up the importance of the rest in another bar.</p>
<p>As far as I understood, this should be possible using <code>shap.plots.bar()</code>.</p>
<p>However, whenever I try to run the code, I get the following error:</p>
<pre><code>AssertionError: You must pass an Explanation object, Cohorts object, or dictionary to bar plot!
</code></pre>
<p>Next thing I did, was to try using <code>shap.summary_plot( ..., plot_type=&quot;bar&quot;)</code> since that is another way of displaying shap values in a bar chart. This indeed worked for me, however this does not sum up features in one bar.</p>
<p>So my question is, what did I do wrong while using <code>shap.plots.bar()</code> or what can I do to get <code>shap.summary_plot( ..., plot_type=&quot;bar&quot;)</code> to sum up features in one bar?</p>
<p>Here is my code:</p>
<pre><code>explainer = shap.KernelExplainer(model=agent.policy.predict, data=state_df, link=&quot;identity&quot;)
shap_values = explainer.shap_values(X = state_df.iloc[0:35,:])

shap.summary_plot(shap_values = shap_values[0],features = state_df.iloc[0:35,:], plot_type=&quot;bar&quot;)
shap.plots.bar(shap_values[0], max_display=10)
</code></pre>
<p>Note that my background data set has 35 samples and that I have 160 inputs and 8 outputs, so the shape of my inputs <code>state_df</code> is <code>(35, 160)</code> and of my outputs <code>action_df</code> is <code>(35, 8)</code>. Also whithin that code I am trying to display the shap values for the first output which is why I am using <code>shap_values[0]</code>.</p>
<p>Hope someone can help :)</p>
","2023-01-02 11:15:22","2","Question"
"74979543","74979359","","<p>It is indeed just a single feedforward network rather than a separate one for each position. I don’t know why the paper says “position-wise”. As you said, there’s nothing really position-wise here.</p>
","2023-01-02 06:34:06","1","Answer"
"74979359","","How is position wise feed forward neural network implemented for transformers?","<p>I am having hard time understanding position wise feed forward neural network in transformers architecture.</p>
<p><a href=""https://i.sstatic.net/HfjMB.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/HfjMB.png"" alt=""enter image description here"" /></a></p>
<p>Lets take example as Machine translation task, where inputs are sentences. From the figure I understand that for each word, different feed forward neural network is used to the output of self attention sub-layer. The feed forward layer apply similar Linear transformations but actual weights and biases for each transformations are different because they are two different feed forward neural network.</p>
<p>refering to <a href=""https://nlp.seas.harvard.edu/2018/04/03/attention.html"" rel=""noreferrer"">Link</a>, Here is the class for <code>PositionWiseFeedForward</code> neural network</p>
<pre><code>class PositionwiseFeedForward(nn.Module):
    &quot;Implements FFN equation.&quot;
    def __init__(self, d_model, d_ff, dropout=0.1):
        super(PositionwiseFeedForward, self).__init__()
        self.w_1 = nn.Linear(d_model, d_ff)
        self.w_2 = nn.Linear(d_ff, d_model)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        return self.w_2(self.dropout(F.relu(self.w_1(x))))
</code></pre>
<p>My question is:</p>
<p>I don't see anything position-wise about this. This is simple fully connected neural network with two layers. assuming  <code>x</code> to be list of embedding of each word in a sentence, each word in a sentence is transformed by above layer using same set of weight and biases.(correct me if i am wrong)</p>
<p>I was expecting to find something like passing each word embedding to separate <code>Linear</code> layer which will have different weight and biases to achieve something similar to what is shown in the picture.</p>
","2023-01-02 05:59:25","8","Question"