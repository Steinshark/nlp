40 Super? More like 4080, wow, Super Paint Job. In 4K gaming, we found next to no difference across our entire suite of games between our two top-end cards. In fact, our Super card performed a bit worse in Cyberpunk compared to our non-Super, despite having more cores and higher on-paper clock speeds. Now, that doesn't mean the Super is a worse card overall. We've just released a video demonstrating that modern processors can have measurable difference from one to the next. All it means is power limits are a bit, and this whole launch shenanigans could have been an email. So rather than waste your time trickling out LTT review videos every couple of weeks with, ooh, one more line on the graph, we combined everything into one Super video. Between the price cuts and the new cards though, the GPU market has officially been shaken up a lot here. $1 for frame, the 4080 Super presents virtually the same value as the beloved 3080 at its original MSRP. And while the other Super refresh cards don't get lower prices, they're at least more Winter Soldier Super than Nick Fury Super. Finally, the 4070 gets a price cut down to $550, which makes it actually still kind of a bad value. We're not gonna spend too much time on 1080p gaming because even the weakest card in this kind of price tier delivers an excellent 1080p ultra experience. It is impressive to see the 3080 sinking so low on our charts though. And the 4070 Super is really impressive, beating out even the 3090, despite retailing for less than the historically low pricing on that card. If you're an eSports player, the good news is any card on this chart will do you well. But the bad news is the word Super can mean basically anything from a sizable performance increase to meh. So what exactly did they change with these cards? Let's go through it after this message from our sponsor. Build Redux, psst, hey, do you like gaming? The folks over at Build Redux do as well. And their mission is to help you build the gaming rig of your dreams. Pick your parts and let them take care of the rest. Check out Build Redux at the link below to learn more. The 4070 Super uses the same 8104 silicon that's found on its non-Super and Ti cousins. Man, these names. But it comes with 20% increases in its functional units, or FUs for short, just about across the board. And it got an especially big bump in level two cache. It, however, got no increase to its memory interface width or its 12 gigabytes of VRAM, a move that seems entirely designed to ensure that this otherwise actually pretty solid value card won't last for the rest of this generation of console games, many of which already perform best with 16 gigs of VRAM or more. So if that's a concern, you'll have to look to the 4070 Ti Super. It now shares the same 8103 silicon as the 4080 family, but it's clear that this move is less about providing more value and more about NVIDIA offloading some 8103 chips that weren't up to snuff. As for the 4080 Super, the modest increase in FUs seems to offer a small benefit sometimes, but other times it's clear that NVIDIA's power limit for this card is doing exactly what it's intended to do, limit its power. You'll see what I mean at 1440p. The 4070 Ti Super is another major disappointment here. Despite the shift to the bigger die, we don't really see a major increase in performance, at least not like we saw on the 4070 Super. And even at its new lower price, the 4080 Super doesn't seem to offer a great value proposition over AMD's 7900 XT or NVIDIA's own 4070 Ti Super, which now retail for 750 and 800 US dollars respectively. It offers only a single digit performance uplift for what are in both cases, double digit price bumps. A couple of bright spots for NVIDIA though are they took the lead in F123, a game series that has heavily favored AMD in the past, and the 4070 Super just kind of in general, that is an offer that is kind of hard to refuse, at least in the context of NVIDIA's other 40 series cards. Say it with me guys, this is the card NVIDIA should have released a year ago. Looking at games like Cyberpunk, the step up from the non-Super is pretty darn big. And yeah, it's $100 more than the 7800 XT, but the 4070 Super outperforms it consistently by about 5% and is compatible with NVIDIA's fancy pants AI features, like their new automatic SDR to HDR video playback tomfoolery and DLSS with frame gen. We're gonna get to frame gen in a bit, but first let's move on to 4K raster gaming. In Dota 2 at 4K, every single Super GPU will be able to produce as many frames as you can possibly output with DisplayPort 1.4a. AMD's DP2 Cloud GPUs on the other hand, may end up being the go-to for high refresh rate 4K e-athletes, even if it comes at the cost of some performance in other games. The 4080 Super pulls pretty far ahead of the 7900 XT and Red Dead Redemption 2 and Atomic Heart. As for the 4070 Ti Super, it has fully caught up to the 7900 XT and extends its lead over the 4070 Super to about 20%. A point where it's $800 price tag could almost be justifiable. And the 4070 Super begins falling behind the 3090. It appears to be being held back by that 12 gigs of video memory that we complained about before. If you were hoping that this refresh then would push the prospect of 4K ultra gaming to a lower price bracket, I'm sorry, but that just isn't the case and it appears to be by design. So with Nvidia's cards having names that are too long and traditional raster gaming performance that is at best competitive with AMD, the question becomes, are Nvidia's other features worth the price premium? Let's take a quick detour into productivity and find out. Now featuring, I'm so sorry, you must be so tired of hearing about it, AI benchmarks. The Procyon benchmark is testing the speed of inference of various AI models on this hardware. Things like upscaling and object recognition or generating images like with stable diffusion. Like it'll see pixels and infer that those pixels form a stop sign. And naturally we see Nvidia dominate here, but this isn't just some architectural failure on AMD's part. A big part of it is software. CUDA has been around for a long time now and basically every AI program is accelerated by Nvidia's CUDA cores. Whereas AMD is stuck in direct NL hell in this test and just can't keep up. So we're gonna be working to build out an AI suite that is more representative as time goes on. Of note, this is the first instance where we see an actual increase in performance from the 4080 refresh, excuse me, 4080 Super. If AI is a major part of your workflow, then you can be thankful that you're now getting even better AI performance for less money at the very high end. Similarly in Blender, AMD is hamstrung by lacking software support and we see Nvidia dominate the rendering race even without taking advantage of their optics rendering. However, that uplift that we saw in AI workloads on the 4080 Super has all but evaporated. Let's talk about how Nvidia's AI horsepower affects gaming now then with DLSS and FrameGen. As we've seen in the past, an increase in AI cores doesn't correlate to improved performance from DLSS and FrameGen. You turn them on and they work or you don't turn them on and they don't work. You get roughly a 60% increase in FPS from enabling DLSS with FrameGen regardless of which card you're using. That is assuming it's green, which dramatically increases performance with what has become a pretty small difference in visual fidelity. The increase in latency is measurable, but outside of professional gamers and enthusiasts, I think it's kind of reached the point where it's like, well, why wouldn't I turn this on? As for AMD, you might've noticed that even though they finally launched their driver level FrameGeneration, we didn't include it in our results. We wanted to be as apples to apples as possible. And in theory, it's really cool. You just turn it on in the adrenaline control panel and it boosts your FPS in any DirectX 11 or DirectX 12 game. Though like with Nvidia, they do say you need decent performance already for it to work its best with AMD recommending 60 FPS. The problem is that we were not able to get consistent outputs such that we would be confident putting them on our graphs. So we've got some screen capture here for you guys to give you some idea of what you might expect in terms of a performance uplift. But I think it's gonna have to wait for a future video to see how their fluid motion frames compare to Nvidia when it comes to image quality and latency. Another place, speaking of latency, where AMD has lagged behind Nvidia has been ray tracing, which doesn't change at all. The introduction of these performance bumps and the new SKUs will all but force AMD to discount pretty much their entire current gen lineup, at least if they wanna appeal to ray tracing enthusiast gamers. Post price cut, the 4080 now competes directly with the 7900XTX with slightly better raster and much better ray tracing performance alongside other Nvidia walled off features. And the story is the same when it comes to power consumption. Even with the bump to total power consumption, Nvidia's new cards handily outclass AMD in overall efficiency. And if you were worried that the power bump would result in thermal problems, maybe on the 4080 Super for example, you can rest easy knowing that thermals on all of these cards were very much in check. So you can rest easy and comfortably in our new collection of pajamas. We have onesies and lounge pants now available at lttstore.com. Now, is anyone else getting a sense of deja vu by now? If you are, it's probably cause you're pretty smart and observant. Nvidia is pulling from the exact same playbook as they did with the 20 series. Seriously, stop me if this sounds familiar. You release a generation of cards that is perceived as not offering a very good value. And in fact, not offering much in the way of a performance improvement over the last gen. Then you do a mid cycle super refresh so that you can say, yeah, we know this one was kind of a downer, but we're listening. Well, that may have been a very long four and a half years ago, but I haven't forgotten Nvidia. And how is it that you thought that this was worth dragging out over a month plus long series of launch events? Did anyone else notice that they gave nothing to the gamers who already had the least this generation? What about people who have less than 500 US dollars to spend on a gaming accessory? Nvidia is basically yielding that customer to Sony or Microsoft. So I hate to say it, but unless Intel Arc Battle Mage swoops in to save us, APUs might be the future that we have to look forward to for budget PC gaming. As for the future of this video, it's the segue to our sponsor. Ground News. No one likes to admit it, but we all kind of live in our own bubbles, thanks in no small part to internet platforms that feed us more and more stuff that they think we'll like, including news. But Ground News wants to change how we engage with news by helping us break free from algorithms, see through media bias, and better understand where we get our information from. To do this, their team processes nearly 60,000 news articles from over 50,000 different news sources each day, merging coverage of the same events to give you a clearer picture of just what the heck is going on out there. Every story comes with this little bar that breaks down the political leanings of the outlets that are reporting on it. For example, here's a recent story about OpenAI no longer banning the use of chat GPT for military purposes. Outlets from one side of the spectrum reported on it, while it looks like the other side didn't really find it that newsworthy. And if you wonder why, Ground News can help you dig more into those outlets to have a look at what topics they cover, which ones they don't, and why that might be. It's time we had a smarter way to read the news. So go to ground.news.linus, or click the link below, and you'll get 40% off their unlimited access Vantage plan today. If you guys enjoyed this video, why don't you check out the one I alluded to earlier, where we analyzed the difference between a dozen different identical AMD CPUs and showed how they don't always perform quite the same.