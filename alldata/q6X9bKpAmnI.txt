a little bit about me so my name is Alon wolf I started learning C++ in high school because I wanted to make video games um before that all I knew about C++ was that there was a popup I needed to click on whenever I installed a new game um today I am working as a senior soft engineer at metronic um where I work we make robots for spine surgeries so I get to do what I love I also helping to improve patients lives in my spare time I write a technical blog and participate in game James and I also enjoy experimenting and trying new new things in C++ um okay so in this talk we are going to take a deep dive into the world of compile time Parcels but we will also cover other aspects of the C++ language so I hope you will find it useful even if compil tank parsing isn't your cup of tea about the structure of this talk first we are going to cover expressiveness in C++ and how we can write more expressive code then we are going to take take a look at open source compile time libraries for each Library we will look at its API design and some implementation details finally we will see how we can use compile time parsers um uh to implement reflection features and show how we can use them to implement some examples such as creating functions types and three data structures okay so what is a parcel for our purpose a parcel is something that takes an input uh like a text or tokens and returns a value or a parsing error for example in a compiler the text is converted by a tokenizer into a tokens uh which are then passed to the parser to create the syntax tree or in a web browser we can uh use text we can use a Json parser to convert text into a JavaScript object so there are many ways to create parsers one common way is by using parcer combinators a parcer combinator can create a new parer by combining existing one so for example if we have a function that we call Par string that takes the input string and the current parsing position and returns a string or an error and we have another similar function called parse int that takes the same arguments and returns an integer or an error we can combine them to create a new parsing function that um that returns a string or an INT uh by first calling the par string with the parameters and if it fails calling the the parse int function um because all the function have the exact same input arguments we can simplify this pseudo syntax and remove the function arguments another way to create parsers is with parer generators so a parser generator can create a parer from a grammar definition some popular paring algorithms that are using paral generators are ll1 lr1 LR and many others here you you can see an example of a grammar definition that uses the ebnf syntax so in the final line of this example we can see that an assignment is defined as an identifier followed by colon equals followed by a number or identifier or a string okay now let's talk about expressiveness in C++ what do we mean when we say expressive code we mean a code that communicates its purpose for example um what it does how it should be used or why it was was written and it relies on two things the syntax of the programming language and the naming convention in this talk we will focus on the syntax part as the language evolves we get new syntax that we can use to write more expressive code here we have two examples that create a an a vector with four integers um the C++ example the C++ 11 example is more expressive because it has less boiler plate it doesn't need to create a c style array or use size off both of which burdens the people who need to work with this code another way we can make our code more more expressive is with Opera overloading we can use operators to we can use operator overloading uh to write uh operators that call a costum function for specific types um so in this example by using the the division operator our code can be written from left to right and without parenthesis also the division operator is a good choice for path concatenation because it is a common way to represent paths in many operating systems so domain specific language or DSL is a language that is designed to solve problems in a specific domain so after we learn the syntax of the DSL we can use it to more easily solve problem in that specific domain some examples of d csls include SQL CSS um Regular expressions and makes that we use to R make files here we can see an example of an SQL parer that uses the Boost Spirit Library boost spirit is a library for writing gr time parsers and it has a DSL um in this example we first Define text as all characters that aren't opening angle brackets then we Define we Define node as either XML or text then we defined start tag end tag and finally we Define our XML parel as a struct tag followed by a list of node followed by a matching end tag this is all valid C++ and as you can see we can make it look like a completely different language but there are still limitations um the syntax must be valid C++ because it needs to be passed and compiled by the C++ compiler so if we take a look at a small part of of code from the previous Slide the Syntax for list of node is starred followed by node let's assume we want a different Syntax for DSL what if we wanted to write node star instead well in this case we will get a compilation error because in C++ the unar star operator must be on the left side of the expression okay now let's do a quick recap of everything so far with a filter transform example so here we have a an input Vector of cats and we want to get all the cats um over the age of 42 and we want to get just the ID and name of them so we use iterators to iterate over the vector we check if the age is bigger than 42 and if so we place a tupl with the ID and name we can use modern C++ syntax to replace the iterators with a range based for Loop to make our code more expressive but this is 2023 and we have ranges now we can use the overloaded pipe operator to chain multiple operation and now our code literally says filter transform but what if we wanted to write it in SQL syntax so we can do it by using a parser first we create a parser then we use the parser to parse the SQL syntax into a function finally we call the function and we are done right well not exactly because there are some differences first we have the runtime overhead of creating the parser and parsing the string into a function then we also um have the runtime overhead that a result type must be type erased for example by using a vector of St any this is because it depends on the the the parsing function is the output of the parel which is only known at run time so at compile time we don't know what type we get we can solve all three problems by Shifting the parsing to compile time now we don't have the runtime overhead of creating the parser parsing the string into a function and we also know at compile time the output of our of our function that we passed so we know the the type of the result finally we can wrap the parsing logic with a string literal operator um this is the Syntax for it for those who are haven't seen it um and now our filter transfor code is a single line of SQL like syntax okay so let's generalize what we've just seen in this example we we used compile time parser to convert SQL syntax into a function or more specifically a Lambda but the general case for compile time parsers is that we can use them to convert any costume syntax into any compile time value is something like this even possible well spoiler alert the answer is yes and by the end of this talk you will know how but we need to to start from the beginning which in my case was a Google search so I asked hey did anyone try to do this crazy thing in C++ and the result was of course there is already a boost liary for it which leads us to the first library of this talk boost meta parse is a compile time parsing Library by Abel sovich everything in this Library uses C++ 98 except from the for the creation of the compile time input string so in C++ 98 we have to write each character as a separate template parameter while in C++ 11 we can use the Boost metap part string macro with a string literal for compile time computation the library uses template structs which are also known as meta functions a typical parser in boost meta pars is a struct that has an inner apply meta function which takes the input string and the current parsing position and Returns the parsing result with some additional information so let's talk about the syntax of meta functions um the syntax and techniques needed are pretty horrendous and this is not me saying it's from the official C++ core guidelines about template meta programming while you may say that pretty horrendous is a bit harsh having to express everything in terms of template structs instead of if branches for loops and other basic syntax element is definitely not something that we would like to do in the slide you can see part of a calculator pars implementation that uses the Boost meta pars library with template meta programming and judge the syntax for yourself okay let's go over some features of boost meta parse you can use it to parse a string into a compile time meta function or a runtime regular function the difference between them is whether the paring result is a meta function or also we can call it template struct um for compile time function or for rtime function it's a struct that overloads the call Operator another feature of boost meta pars is that you can use it to write meta function in HK like syntax which you might prefer over The Meta programming syntax in this slide The Meta uncore h a is a compile time map um the import call um adds a new meta function to the map the defined call creates a new meta function from a hcal like syntax and add it to the map each call Returns the new modified map so we can nicely change them together in the end we can get the new uh meta functions from the map to use them in a regular C++ code we can also use boost metap pars um to create a parcel for grammar rules for each rule we need to define a the syntax rules that it contains and an optional semantic action to take okay now for some implementation detail let's see how the Boost metap par string macro Works what I want you to take from this is not the inner working of the macro and how it is and the complete implementation but more to see how difficult it was to create a compile time string using C++ 11 so the macro expends to something like this a call to make string with the length of the string followed by many calls to S Str at with the input string and the running index St Str is a Conex per function that takes a string and an index and Returns the character at that index or zero if the index is past the length of the string um so after evaluation our call to make string look something like this the length of the string followed by a characters of the string and then a lot of trailing zeros in C++ 11 Conex per function were limited to a single return statement so this is pretty much the limit of what was possible the make string function recursively concatenates the string until it reaches the original length um so it removes the trailing zeros and we are left with the original um string as a compile time string um look how much effort and tricks were necessary to create a c a compile time string in C++ 11 something that we can now do with just a few lines of code and with that I think we can move to C++ 17 so Lexi is a compile time parsing Library by Jonathan Mueller that uses C++ 17 it has a DSL for writing parsel combinators and it's supports unic code string um and compiling and parsing at run time or compile time we can create a parcel by defining a struct that has a rule and a value the rule defines how to match the input string and it can be implemented as parser combinators the value specifies how to store the parsing result con exper has become a lot more powerful in C++ 17 so now we can use a an immediately invoked Conex per Lambda to Define our rule Conex per value and inside the Conex per Lambda we can write code with the same syntax that we use to write regular C++ runtime code Lexi has an online playground um that includes many examples on the left window you write the parsel on the right window you write the input string and the window below shows how how the parser matches the input string and constructs the result result everything is interactive um much like a compiler explorer that we all know and love and it is a great tool for learning how to use Lexi and um and prototyping with parsers as I mentioned before Lexi can pass at runtime or compile time uh in terms of runtime performance uh here you can see a Json passsing Benchmark and as you can see Lexi is on par with other popular Json libraries so we get a library that can pass run time and compile time without sacrificing performance okay this is how a typical parser in Lexi looks like we have an outer struct with um with an inner par Conex per parse function similar to the outer struct with the inner apply meta function in boost meta pars but this time we have between them another template struct called indirect that takes a next parer template parameter um the parse function can invoke the next parser with additional or modified arguments this design decision solves the problem of dealing with different return type such as optional Tuple or variant the results are simply passed H to the next parser when we call it so um let's see how a sequence parser combinator is implemented in in Lexi so what is a sequence parer combinator it takes two parsers P1 and P2 and creates a new parser where P1 must be followed by P2 um in Lexi a sequence parser is easily implemented um by defining an alas that rewies the next parser template parameter so during par parsing P1 will invoke P2 which will then invoke the next parcel okay we've seen two um compil time parsing libraries let's now it's time for something different City or compile time regular expression is a library for um compile time regular Expressions um and it was created by hanova the library can perform regex operations like matching searching and capturing at run time or compile time and it also supports unic code strings um we can create a regular expression by using the CT literal operator or by passing the regex pattern as a string literal as an on type template parameter one limitation of the library is that the regex pattern must be known at compile time but it is already a common practice to have the regex part of the code for example if we want to pass a date format okay now let's talk about performance so the construction of the regex from the regex pattern string happens at compile time so there is zero runtime overhead and Performing matching and other operations can be done at run time and compile time as you can see from this benchmark Mar CT is much faster than St regex and have similar performance to boost regex so let's see how the CT literal operator works we have a struct that that we will use um to to represent our compile time string that we will call fix string and it it has a Conex per Constructor that takes a fixed size array um and copy it and store it in itself when we call the literal operator it will construct a fixed string from the string literal um and then inside the C literal operator it will pass the the fix string into the regx object and return it look how much easier it is to create a compile Z string compared to the um boost metap par string macro okay in order to pass the string to a CT uses ll1 parser the one paring algorithm takes the input string internally it has a stack that it pushes and Pops values from and it also has a parsing table that represents the the grammar rules and is used to determine which action the algorithm should take next the stack of the ll1 parser is implemented as empty struct and Performing operation on the stack such as pushing and popping values is done with overloaded functions the ll1 uh parsing table of the regx gber is also implemented as empty struct and overloaded functions I think this is a very elegant design decision that show how such a complex system can be implemented from these two basic building blocks so the parsing Loop takes the input string the coring parsing the corrent parsing position and the stack first it will call the overloaded rule function of the grammar which essentially performs lookup into the part in table and then it will it will decide what to do next based on the action so we can return an error or success or recurse to the next iteration with modified parameters okay after we have seen how ll1 paring works we can move to a different library but this one uses the lr1 algorithm so compile time parcel generator or ctpg was created by P winter and use a C++ 17 as the name suggests we can use this library to to generate parsers from lr1 grammar um you can use this library with your own costume lexer or let it generate one for you okay in order to generate a gramar we first need to define the terminals and non- terminals that will be used in the grammar we we can Define operator Pro precedence for example so that multiplication will be evaluated before substraction and we can also Al Define associativity so that if we have a chain of subtractions they will be evaluated from left to right um the the library also allows us to define a terminal with a regex pattern as you can see here this will match a number okay we can combine our Terminals and non- terminals to define the grammar rules and generate the parcel the rules are created with an expressive dsls and we can create recursive rules because all the non terminals have already been defined okay now I can't possibly cover the entirety of lr1 parser in a single slide and it is a big topic that deserves a talk of his own but I would like to highlight one implementation detail that is used in ctpg so here is a quick overview of how lr1 parsing Works um first uh the lr1 parcel generator uh takes the grammar rules to create items set that represents every state that can be reached during parsing it then computes the parsing tables which will be used to transition between States during parsing here you can see an image that represents the um the item sets and the transitions uh for a grammar and in many runtime implementations they are often implemented by using a set or a map but how can we do it at compile time because we don't have Conex per set or a Conex per map in C++ so how does ctpg do it well a CTP an lr1 item is defined as a struct that has three data members one that that uh that contains the index of the rule the next contains the current position inside the rule and the last contains the next terminal that can follow it this is the one in the lr1 for the look ahead ctpg computes the maximum value for each member in the lr1 item so here we have the number of rues the maximum number of positions and the the number of terminals in the grammar then it multiplies them all together to to compute the address space of all possible lr1 items um and so an item set is implemented as just a bit set um of the address space for all the items finally it defines functions to convert back and forth between an lr1 item and an index so that adding removing and finding items in the item sets are just basic bits at operations um it shows that some problems of compile time code can become a lot simpler if we can find an upper limit and use a fixed size container now let's move to C++ 23 okay so macro rules is a library created by Maxim Maxim pnik and it it uses C++ uh 23 um we can use it to create a DSL with rusts macro rules style syntax it is more of an experimental proof of concept than a full library before we take a look at the library here is a quick overview of rust's macros rust have two types of macros procedural macros and declarative macros procedural macros or a proc macro is just a function that takes a token stream and Returns the token stream of the new uh generated code uh we can call a pro macro directly or pass it to another Macro for for example to the derive macro which will invoke each one of the macros in parenthesis with the tokens of the struct below it this Library isn't about Pro macros but at this point you can already have an idea about how they can be implemented in C++ de declarative macros use the macro rule syntax which contains two parts the first part specifies how to match an input pattern and the second um specifies how how to transform it into an a um in this example uh the the macro rule V will match a a list of Expressions separated by commas and it will generate a temporary Vector generate a push call for each of the expressions and return the temporary Vector let's see how we can do something similar in C++ by using the macro rules Library first we declare a stct called sum that inherits from macro rules uh pattern um and so to specify which syntax we match so in this example we will match the word sum followed by a list of arguments then we need to define a transform function that will take the context of our matching result and return the the output from the context we can get a list of arguments pass them to stud apply and use use um fold expression to calculate the sum and return it we can invoke the new sum macro rule by calling apply rules with the name of the struct and the text that we want to match internally the library uses a compil time parcer to create a template that represents the as you can also write the template directly instead of using the macro rules macro um but I think the syntax above is more expressive and easier to work with okay so identifier in micro rules are only used for lookup and equality comparison so they are converted into 32bit hash values because it's easier and more efficient to pass them around than a variable size string if we look at the implementation of apply rules we can see that it is a pre-processor macro which converts the text to string literal and passes it to a function that that does the matching and transformation here are some things to to keep in mind we're using a pre-processor macro to convert text into a string literal um the first thing is that comments won't be included as part of the string literal so you get support for comments for free um in every editor that I tested syntax silting kept working inside the macro and the last thing to keep in mind that if you have multiple white spaces they will be reduced into a single white space so keep that in mind if you are thinking about um having a syntax that relies on one space on white space for your DSL like in Python for example okay here we have the final um compile time paring library for this stock this is a very lightweight one that I wrote from uh for for myself and it and we will use it to implement some examples um it has a DSL similar to Lexi and boost spirit for writing parer combinators um and the and it returns fixed size containers so if we have um the binary or operator return a variate parcel or an or parcel so it will pass an INT or a double and it return a variant of it um the bit shift right operator is a sequence parser so here we have in that must be followed by a se but by a comma and then by a double and it will return a tuple um the star operator is a list parer as we've seen before and it will return a fixed SI a fixed capacity vector and finally we can use the bit shift equal operator to pass the output into a Lambda okay we can use C++ 23 to expected to represent the parse result um which can be a value or a parsing error a parser in a in this library is just a wrapper around the stateless Lambda that takes a parsing context by reference and Returns the parsing result the parsing context is a struct that contains the input string and the current parsing position we can Define concept that checked if a type is an instantiation of the parcel template um it is implemented by calling the parcel Constructor with a concept argument and checking if they have the same type we want to have different implementation for the sequence parsel combinator depending if we want to combine uh two parsers or we want to append the parser into an existing sequence this is done by using Contex Concepts uh the concept for sequence parser checks if the type is a parser and also if the inner uh function of the parser is the sequence parsing function um therefore it is more um more specific than the regular parsel concept because it includes the parsing concept and also another uh concept uh because it is more special I the call to bit shift right operator will will reach the correct overload function and we will not have an ambiguity error one limitation of compile time paring is that the input string must be know at compile time so now I have a question for you which uh string must which H string is used in every C++ application and was always been known at compile time yes yes exactly it is the source code because it is the input to the compiler so it must be known um so now so which leads us to reflection and we will see some interesting ways that compile time Parcels can be integrated with reflection but first here is a quick overview of the state of reflection in C++ so C++ has many introspection features but having reflection as part of the language is still far away um here are some uh libraries that you can use right now if you want to get reflection uh working in C++ a common approach of reflection libraries is to use a macro to generate the reflection metadata for example in rare CPP in the rare CPP Library you can use the reflect macro inside the class to reflect all the data members or right out of it to reflect just the public ones we can use compile time parser to generate the reflection metadata um here we have macros that uses the same text twice once uh it passes it as is as source code and another it converts it into a string literal and passes it into a compil Time parcel um while it is not available approach to try and parse the entire C++ sytax uh at compile time um it is possible to write parsers that parse just part of the Syntax for example the attributes of a struct in the code here the macro generates a Conex per function that Returns the attributes of thect we can Define two separate macro macros that will call compil time parcel one will pass the attributes and and another will pass all the data members then we can create a new macro which will which we will call theive that we will in will invoke each one of the macros in parenthesis with the string literal of the source code and pass it to them and this this is one way to implement thrust derive macro and create a similar system to procedural macros in C++ but a more interesting use case is when we leverage reflection to empower compile time parsers for the sake of fitting the code in slides the word identifiers were shored to ident um here we have a static member function called resolve identifier that Maps an identifier to a pointer to data member it uses function overloads as as lookup table and and it computes 32bit hash values of the string literal similar to what we've seen in the macro rules Library we can wrap it in a repeating macro to generate a resolve identifier function for each one of the data members then we can create a function to get a data member by an identifier it will first call the static resolve identif identifier function of the struct with the with the current identifier to get a pointer to the data member and then use the pointer to data member to get the actual data member from the object and so we can use it to to get a data member of an object by an identifier string okay now let's see how we can integrate reflection with compil and parcel to implement a syntax that returns aned data member it will be a starting point that we will build upon later the syntax is a list of identifiers separated by Dot and okay now we need a fun and so um and this is how a parser look like it just pares a list of identifiers that is separated by dots and the output is a fixed size Vector um with 32bit hash values for each of the identifiers now we need a function to get the nested data member from an object this is an approach that I sometime use when writing compile time code I first write it as a as a pseudo code like runtime code um just to get the the basic logic going so first we create a result Vector that points to the input object then we iterate over data member and call get member to get the N the next nested data member and store it in the result finally we return the result which will be the most nested data member that we want to get um in order to make this code work we need to make some changes First We Take our um compile time argument and move it into a non-type template parameter so in this case we we move the members from being an argument into a non-type template parameter the next step is to replace loops with recursion or a fold expression in this case we replace the loop over the members with a recursive Lambda which we can easily write in in C++ 23 by using the recursive this so if you can see in the beginning of the Lambda we have this Auto ref ref self which refers to this Lambda so when we call self it's a recursive call finally the last step to make it work is to replace a branches with um if Con xare in this case we only have one branch that checks if we need to exit the recursive Lambda so we just instead of if write if con exper and now we have our function works um finally we can wrap the code to pass the um the input string into the list of members and then call our get nested function that we just implemented inside a string literal operator so that we can have this nice and expressive syntax okay now let's look at the generated assembly um do you see it wait okay so here we have two functions F1 and F2 one of them uses the regular C++ syntax and another uses our new syntax that we used with compiled and parel as you can see it has generated a lot of code what you will not find of in in this code is any of the parsing logic or the input string all of this is just the implementation of the get nested function the reason there is so much the the compiler generated so much code here is because I compile it with o zero optimization so it's essentially emits the code s is without any optimization let's increase it to 01 and it removed all of the boiler plate we are left with the exact same implementation for the regular C++ syntax and the comp time paring syntax so it is a zero runtime overhead abstraction okay let's let's extend the syntax and add two new operators the colon operator will perform a rage base for Loop and the pipe operator will call the function with the current value first we need to create parcel that supports the extended syntax so the the pipe parser will match a pipe followed by an identifier and it will return a pipe struct that will hold the the um the 32-bit identifier of the um function that we need to call and the iterate parser will just match a colum and we will return an empty struct finally our new extended parser will be a a list parser that will that each variant can be either a pipe an iterate or a list of members to get the nested member function so now we need to implement the implementation function for our new extended syntax um so we use a recursive Lambda similar to how to what we did in the previous example um and for each iteration we check the the value in the current variant if we have a list of members then we call the get nested um function um with the current value and pass it to the next recursion if we need to perform a range based for Loop then we perform a range based for Loop and pass each element to the next Call of the recursive Lambda and finally if we need to call a function then we can get the identifier from the pipe struct and what do we do now um we need some way to call a function based on an an identifier well it can be done by using the same technique to use to get an a data member but this time we use a free function called resolve identifier that will map an identifier to a function in this case we map the square literal to the square function and we can wrap it in a macro to reduce boiler plate so now we call resolve identifier um to get the functions that we need to call and we get the function and we call it and we are done right um well actually no because the lookup for resolve identifier will be based on the scope of the implementation function and not not where the syntax is used for example if the resolve identifier is defined inside of a namespace it will not be found when we will try to call the resolve identifier in the implementation function we can move the call to resolve identifier from the implementation function into where we use the syntax and pass it to the implementation function as a Lambda and now it will find the square function we can refunct the Lambda that calls resolve identifier into a macro which we will call scope because our scope is just a Lambda we can also create one that Maps an identifier to a local variable in this case if we will if it will pass an identifier of the X of the string X um we can return the X local variable okay now let's compare our new extended syntax to the regular C++ syntax okay so once again we have two functions one called F1 and FS2 each one uses um the different syntax um here on the left you can see F1 and let me scroll down on the right so you can see F2 and they have the exact um instructions so once again even with the extended syntax this is um zero uh overhead upst all right um also about the syntax um so our new costume syntax is linear so it can be read from left to right um and we can also chain function calls with the pipe operator so overall we have created a more expressive Syntax for this very specific kind of problems okay now I have a question for you can anyone tell me if this code compiles well the answer is no but can anyone tell me why this code doesn't compile what well so this code doesn't compile because the int uh data member inside of C is private so if you try to compile it you will get an error C is not a valid type for template for non- type template parameter because it is not structural in C++ 20 the definition of structural type was modified to include context per variables of Class Type but uh they must have the these two following properties old based class and non static data members must be public and non-mutable so all direct data member must be public and also all uh all types of the base classes and nonstatic data members must be structural so the entire composition tree must be uh public so if you have even one nested non-public data member you cannot use it as a non- type template parameter St duple and variant are not structural types because they have private data members so I had to write my own basic version of them so that they can be used as a non- type template parameter um it took less effort and code that I expected thanks to deducing this okay so we saw how we can use compil time parsers to create functions now let's use them to create types we will create structs from this types script like syntax so our parser will mention opening curly brackets followed by a list of data members where each data member is two identifier separated by colon and then H closing corly brackets our output will be a list of data members where each data member is two um identifier hashes for the name of the data member and the type of the data member we can use this type wrapper class to pass around the type as a value then Creator resolve identifier function that Maps an identifier to a type wrapper and that way we will be able to get a type by an identifier we will use this struct member type to implement a single data member of our final struct it takes an identifier and type rapper as template parameters um it declares a it defines a getter function to get the data member by a by the identifier and it also holds the the data members that we want then we can combine multiple struct members into a single struct by inheriting from all of them this is how the functions that creates the structs look like it takes the input string and the scope that will be used for to map identifier we first pass the input string to get the members and then we create an index sequence for the members and expand it into parameter pack we use a fold expression to create a struct member for each identifier pair so the first one is the identifier of the data member and we can pass it s is the second one is the type of the data member and we use the scope Lambda to convert it from an identifier to a typ wrapper um finally we we can um return the the stru the combined stru type as a type wrapper from our expand function and this is an example of how our new syntax look like inside the stct macro the text is converted into a string literal and passed to the create struct function so far the uh the parsers and syntax have all been linear but it is very common to parse threes for a final example we will see how we can use compile time parsers to create three data structures and our Target syntax will be Json first we Define aliases for array object and string all of them will use a fixed capacity Vector we Define a VAR as a variant of all the Json data types notice that object array and string are all pointers inside the variant so they are held as pointer and not the actual value when we create three data structures and run time we usually use pointers from a parent to a node H from a parent node to each children nodes are often dynamically allocated and should be preferably stored as smart pointers here we have an example of code that creates a Json at run time if we try to make the Json variable cons xer we will get a compilation error because it refers to dynamically allocated value you can use dynamic allocations in Conex per functions um but they must be deallocated and can't be stored inside the Contex per variable we can solve this problem by using a compile time allocator here we have a basic compile time allocator that contains a tel of fixed capacity vectors one for each type the add method stores a value in one of the fixed Vex and Returns the two and Returns the reference that holds it now we can replace the calls to new with calls to allocate or ADD and store the Json in a Conex per variable we pass the allocator along with our input string to the Json parser um to and store the result as the root of the Json value below you can see an example of how to create um here you can see that the allocator and the root are stored in the same uh struct because they must live together and here you can see an example of how we can um create a compile time Json from a string uh the size of our Jenson variable is very big because it contains the compile time allocator so how it will affect the um the binary size so if it is only used at compile time it will not be included in the binary output if you do need to use it in run time then it must be included in the binary output uh in this case there are some ways to reduce its size one way is to first run a lightweight parser to to find what capacity is needed and then just allocate based on the capacity that is necessary another way is to copy from a from the um big capacity allocator into a smaller one based on the size that is actually used when we use compil time parser the first thing to ask is um do you need spe domain specific language or a general purpose language compil time parsers are best suited for domain specific languages uh so if you need a a general purpose language I recommend using regular C++ um the second thing that you need to ask is can your desired syntax be expressed with C++ operators if so then use operator overloading um so um the last thing to consider is how your uh domain specific language needs to interact with C++ so the best examples and use cases for compiled and parsers are self-contained syntaxes like regex or inam they don't refer to any outside variable and so they are um the easiest to use and Implement um if you do need to access outside variables in C++ then you can either have explicit access by using an an import table like how boost metap pars is interacts with the hcal environment or you can use um if you need a or if you need a score based lookup you can use a reflection with the resolve identifier mechanism that we have just seen so which compile time Library should you choose if you're using C++ version before C++ 17 then your only option is to use boost meta pars if you're using C++ 17 and above then it depends if you how you prefer to wrate your Parcels if you prefer to create them by using parcel combinators use Lexi if you prefer to um generate them from an lr1 grammar use ctpg and if regular Expressions uh suit your use case then use CT and for if you would like to try more experimental things with C++ 23 then you have the option of trying the macro rules library to see how rust macro rules can be implemented in C++ or use ycp to see like the complete implementation of the examples that we've seen here and how reflection can be be used with compile time parcel okay so about um compile time error how bad are they so here we have two passing errors the first one is because I forgot to add a semic color and in the end of uh Main and it is the kind of passing eror that I would like to get this is from GCC the second one is because I used uh the CT with a string literal and provided invalid reg syntax um from there on message we can see that it from the second o message we can see that it failed to in a static assert which validates the regx syntax and that there is a problem at position four of the string while it provides enough information to understand what is the problem ideally we would like to get errors like the one above and I'm not just piing on the CT library from what I tested um this Library um consistently provided better compil time messages compared to other libraries there are um so about compile time printing there are ways to print arbitrary strings in C++ 20 to produce better better error messages and warnings um here you can see a link of how Victorio Romeo used it to implement a compile time model and I have a librar that I used compile time printing to generate coded compile time um for more information checks the link over here so how better the compile times I'm guessing this is something you are all wondering um we will soon see some Benchmark results but keep in mind that they can drastically change depending on some things like the complexity of the syntax that you are trying to pass the parsing algorithm used and how well it is optimized um it can change between compiler and compiler versions and it will also depend on hardware and other things so to get accurate results you should run a benchmark for your own use case but anyway I still ran some benchmarks um that can give you a rough estimate of what kind of numbers you should expect so I used msvc to compile in debug and release the examples we saw in the previous uh slide um which used my very unoptimized compile time parsel combinator Library so the numbers that you see here are in seconds and are the average of five runs I didn't include the variance because it was very small at the top uh row of the table um you can see how long it takes to rebuild the entire project and on the bottom row you can see how long it takes to build the project without any of the compile time parsing uh code so around 1.5 seconds difference I generated another Benchmark that compiles 1,000 structs by either using regular C++ syntax or by using the typescript like like syntax um I would like to clarify that you shouldn't use compile time passers to implement structs as they are better used for things that can't be easily expressed in regular C++ syntax uh so parsing 1,000 regular structs end around 100 to 200 milliseconds over the Baseline and it's good to know that compilers are very well optimized for this task um with the costume syntax uh uh the compile time parser adds another 14 seconds which average to around um 14 milliseconds per stract one tip when writing compile time code is to try to make it similar to runtime code it will be easier to understand and um and they will use the same syntax unlike with uh meta functions and template meta programming uh debugging can be a lot easier because you can just remove the Conex per keyword set break points and see what is going on in there um you can share the same code between compile time and run time so you don't have to write a different implementation for each and it can lead to fter faster compile times and lower memory usage for example I wrote a different parcel that uh that passes a Json into a template three and it took over 1 minute and 4 gabt of ram instead of 1.5 seconds um and I have experienced the same behavior when creating a large template race with other compilers so I recommend trying to avoid this when possible compile time parel are not something use they have been available in C++ in C++ 11 or arguably C++ 98 their viability depends on the difficulty of writing and using compile time code and on compilation speed both have significantly improved over the years through language features discovery of new techniques compiler improvements and faster hardware and we can assume that they will continue to improve in the future for example in C++ 23 we get the if ER the if contal keyword which checks if a function is executed at run time or compile time and we can use it to have a different implementation for the for the environment it executes in and as far as I know um in C++ 26 uh we should have support for user generated error messages in static assert so we can generate better error messages for compile time passsing errors eventually we will reach the point where we will have a DSL for every domain and they will all interact seamlessly through C++ also recently there have been many talks about successor languages like um carbon and cpp2 um something that I thought out is that I mean in the future when compiled and passing will be a lot better maybe the next iteration will be just a compil Time parser inside the C++ language um I have not tested anything about this approach but I would like to get your feedback about it or we will all be replaced by a I I mean this is also a possibility so I don't know um but my personal hope is that in a few years there will be another talk about compile time parsers and it will show some of the codes that you've seen here from C++ 17 20 or 23 and it will say look how difficult it was to do something that we can easily write in a few line to days anyway thank you very much um be before we get into the question I would like to to say some words um so um I'm I usually don't like talking about it but I would like just to raise some awareness so I'm from Israel um my country is currently at War many of my friends who are also software Engineers um are either mourning their their loved ones who have been brutally murdered or left their family because they were called to self in the Army so if if you know someone in Israel um please support them help them say some kind words I'm sure they will appreciate it anyway um if you have any question you can ask them now or later um so for the ycp library I think um there was um you used the greater greater and greater greater equals operators so I've used Mega Parc in hcal I don't know if you're familiar with Parc or Mega Parc I'm not familiar with them they are um monatic paring uh parther combinator libraries and um so greater greater and greater greater equals in hasc they are the monatic um bind operators um so I was curious whether that played any role in so if if this is just a coincidence or yeah um so it was the the greater greater equal followed by Lambda was inspired by um by the monadic bind operator of ascol um the greater greator is used in many um other libraries and I think it is inspired by like cin how you use cin to read the input so I think because I mean it is used like also in Lexi and boost spirit and I also other libraries so I I'm not sure if I think it is more inspired by like by the C++ streams than hcll but yeah the greater greater equals is is is inspired by the hcll bind nice for catching that okay thanks yeah in boost Spirit uh there's also greater greater used but uh it's not really monatic so it's like trying to be a little bit monatic I think from the syntax but thanks for to thank you um okay so uh uh just one thing I think I like the very talk very much but uh for the measurements of compile time in there is like this tool which is really nice to see it's called f time trace of a clang which gives you like breakdown you know how much time it took like let's say parsing source files the optimization parts so it's really neat to if you like profiling the uh performance of your uh compilation time it's really neat Tool uh to look into that like to see where compiler took time in the you in generating things uh yeah thanks for letting me know I'll I'll check it out okay so uh thank you very much everyone