so we're going back quite a way in internet history i mean not quite right back to the beginning but we're going back to around 18 1986 and around about 1986 was an event that we call congestion collapse is how this has gone down in internet history and the internet was was really starting to take off there was tens of thousands of machines it wasn't any more just a research project and people were using it to transfer files exchange news it was quite it was getting it was getting quite popular but around about 1986 the bandwidth dropped away really significantly the bandwidth then wasn't huge anyway so we've got to set some expectations they were hoping to get 32 kilobits a second you couldn't have a phone call at 32 kilowatts could you not a real good quality one not not a it might you sound a little bit darlicky but two different institutions both of them in berkeley in california found their bandwidth that dropped as low as 40 bits per second it's a thousand times less than they're expected more or less and 40 bits per second what can you do with that in one second you can send five characters it's pretty poor right it's the only time that i can think of that the internet has been significantly degraded since its starting days has been significantly degraded for a long period of time and what came out of that was um refinements to one of the basic internet protocols that are still useful today there's a classic paper that comes out of this in particular two researchers van jacobson and michael carrolls wanted to try and fix this problem and they were part of a wider community of people trying to fix this problem and they were extremely successful and the paper they wrote about it congestion avoidance and control which was published in 1988 is i i would say that's that's the most influential paper about the internet for my money anyway so i'd like to talk today about some of the things that were in that paper and how it fixed the internet when the internet was broken to do that we are we're going to need a little bit of background about the transport layer okay so this is how we make sure that packets go from one computer to another and we can make choices about how reliable we want that to be so let me draw a basic setup let's say all right so we'll draw a laptop here's one person obviously uh we're talking about 1987 they almost certainly weren't using laptops but uh so let's imagine here's our setup we've got two computers they want to send some packets to each other fundamental to this is the transport layer and in particular today i want to talk about transport control protocol because if you want to send data you want it to be reliable yeah you want all of the video that i send you to get to you no missing data let's imagine we've broken our data into some packets and we're sending them along here one core problem is that that underlying layer might lose packets it's not reliable so what we have is transmission control protocol tcp and tcp's job is to sit at these end hosts and make sure that they can reliably get these packets now there's some little tricks that were already in place so tcp was already there and in place in 1986 and it was doing its job of making sure these packets were reliable so well actually here's a question for you sean you're you're tasked with this and you'll say here's computer a here's computer b we're sending these packets from a to b how are you going to make sure that those packets are delivered one thing i would say is they've got to be numbered in some way right so that you kind of know if number one arrives great spot on yeah so very very good so we need a header at the front and we're going to put in a number we'll call it the seq the sequence number so uh let's say these are a little way down the stream so that's number three and that's number four note for the pedants out there i know that sequence numbers are really bites but just to make it easy i'm going to give them integer numbers like three and four just to make my life easy rather than writing down a big long stream about is it is it going to be kind of kind of an act here you've got there you've got the exact thing you must have heard it before well i think we've talked about the fact that this is kind of a guaranteed thing isn't it so it's guarantee or the idea is tcp guarantees the packets get there is that right that's it that's it so that's a mechanism we're using is this ack so these they're coming back the other way now this is probably for a lot of your views this is you know uh you probably know this already but so axe for acknowledgement isn't it so acknowledgement for acknowledgement and the little blue bit at the front is just my way of indicating that it's a header so we've got the acknowledgements coming back the other way so we've got packets one two three and four have been sent and we and we've got three and four sticking out and acknowledgements coming back the other way and if we notice we don't have an acknowledgement we know something's gone astray we know that some packet has been missed yeah and this sequence number and acknowledgements that's the basis of our reliability yeah so if we notice oh i sent out packet three that was some time ago and i haven't seen acknowledgement three we know we've got to resend it so now we've got reliability there's another question now and the question is how fast should we send them okay is this how long do you wait for an act before you send it again you know uh oh that's that's a different issue that's an important issue but it's a different issue that's that's why we call the timeout issue and that is actually very very important to congestion control and we'll get to that in a moment but yeah so there is this issue of the time timeout so we send off our packet we set up we set a little timer and we say oh i haven't seen that packet for 400 milliseconds it must be lost and we send it again let's imagine we did that let's take a basic assuming imagine we just do that we send a packet and we wait for an acknowledgement send a packet wait for acknowledgement that works great but it's really slow especially if those sites are distant so if i'm sending something to america or china i send a packet away from the knowledge and send a packet wait for an acknowledgement it's just going to be unmanageably slow what i need to do is be able to do what i'm doing here i'm sending several packets at once you see we can see there must be at least four packets here and we use the phrase in flight yeah that the acknowledgement hasn't yet got back to this originating computer so the question is how many packets should i send out before i wait for an acknowledgement to get back can i can i say a really kind of like sneaky kind of snakeish answer which is doesn't it depend on the bandwidth well that's kind of where we're going absolutely and that that is where we're going on it but in those days actually it didn't in those days the networks was relatively simple and it had been built up by people just trying to get packets from one lab to another now obviously by 1986 we've got lots of things in europe we've got a lot of things in north america so things are going longer distances but initially initially their main concern was is the number of packets we're going to send too quick for the receiving computer let's add in a new thing into our diagram we're going to add in a little buffer here the receive buffer i've got our cv for receive so the first thing they did was what we call flow control beautifully simple idea the receiving computer says it says in effect it says i have room for 10 packets or i have room for 100 packets yeah and it adds that message into all the acknowledgements so we can have here what we call the receive window so we've got a little indicator in the packet saying how much room it's got left so now the sender knows if i don't want to overwhelm that computer i'm only going to send a packet so i'm going to send three packets oh it's currently full i can't send any more packets so if this receiving computer is slower we're going to be fine because the sending computer knows to hold on a bit the internet had worked since the 60s with this kind of only this flow control in place um well it was arpa originally but by 1986 the problem that you're mentioning comes to the fore that actually the problem isn't with this receive buffer here the problem is congestion and that is the congestion collapse that we'd like to talk about here because what i've omitted from this diagram is that these computers aren't wired directly together there's the big cloud of the internet in between them i don't know why we always draw as a cloud in these diagrams but we do that it's marketing bump isn't it we know that just a load of computers and lots of wires is what that should be and the odds uh radio signal here yeah some confusing hodgepodge of things isn't here but also are many many more pairs of uh laptops well not quite yeah servers let me try and draw a server then you're trying to draw something servers always look like a 1980s pc don't they that's that's the law and there are they're all sending their data as well so now what we've got is a situation that wasn't handled by this concept of flow control what we're now going to need is congestion control we need some method of working out when working out how quickly we can send these packets to the real problem that this paper solves is the fact that we've got to account for all of this crossing traffic which is going to be highly variable people are going to be switching their computers on making new connections so the core problem we've got to solve is we don't really know the bandwidth we've got now let's go back to this flow control and it works with something we call a window it's the amount of package you're allowed to have in flight so remember this concept of the in flight packet it's the packet like these one two three and four here that we've sent but we've not yet got our acknowledgement back so we know that those packets are out there in the network somewhere they've not yet we've not yet declared them dead because they've timed out and we don't yet know that they've got home because we've not got their acknowledgement so we say our window size is the number of packets that are out there somewhere in the wild circulating at the in the internet one of the major insights in van jacobson and mike carroll's paper is that we want this uh the number of packets out there from all of these pairs of interaction computers to reach some kind of equilibrium yeah so we kind of fill our network up and up and up and up and then if it starts to overflow if we start to lose packets we're gonna back off and send more slowly that seems obvious but they weren't doing it back then so the the concept they came up with is what we call now the congestion window and it's the kind of budget of traffic you're allowed to have out there that's accounting for congestion so the trick we're going to use to do that is we're going to try and probe to work out how much bandwidth we there is so now let's emphasize that all of our packets that we're sending are being kind of pinched here yeah that they're competing with the other traffic and then we've still got our acknowledgements going back in the other direction and the question we want to ask is if we draw a graph here of time and here is c w and d our congestion window and this is we're going to say it's a number of packets really again actually in actuality it's a number of bytes that you're allowed out there but let's just for simplicity pretend that that window size is 10 packets if we set that too large we're going to be sending too much data the network's going to start to overflow if we set it too small we are inefficient we could be going faster we could be getting more out of the network yeah so here's the trick they used well one of the tricks the paper is full of tricks and i would encourage anybody to go and read the whole update because it's lovely they do not only do they do the practical engineering that fixes the problem not only do they show you the code which is often real simple that fix this problem they also show you some of the mathematics behind it that is why they're convinced it will theoretically work so the first thing we're going to do is if we get these acknowledgments back if we send out our window size worth of packets and we get back a window size worth of actually get them all back we sell network didn't have congestion so we're going to let's say we start here and we get back one flight of packets we're going to just increase our window size by enough for one maximum sized packet and we're just going to keep doing that so if we if we get them back successfully we increase it by one get them back successfully we increased by one keep doing that and remember everybody else so remember there's lots and lots of other people doing that competing for our our bottleneck here and if we all keep doing that eventually we hit congestion eventually overflow yeah now we get we get we get a timeout or we get a packet dropped because what happens when those routers overflow they've got too many packets their buffers are full they're just gonna have to drop something so the packet does not get back in time maybe it's been dropped or maybe the packets just stuck in a queue and been delayed way though it hits the timeout that's been dropped what do we do now the ccp algorithm just cuts this window in half that's not a very good half but so it backs off really really aggressively yeah now it's sending half as fast but when it gets to getting traffic back again it keeps on going up and up and up again and then again at some point it's going to hit suggestion bam back down by half again we call it additive increase multiplicative decrease and that is the core insight which uh enabled them to escape from this congestion collapse you might be wondering why i've left a little gap here one thing we want to do is we want to get going really really quickly it's crucial that we get that traffic ramped up as fast as we can to to get near our bandwidth limit so another trick that's in this paper is what we call slow start and what this means is at the beginning of the connection when you're not really sure about the bandwidth you probe very aggressively so instead of saying i have room for one packet i have room for two packets i have room three packets initially you increase exponentially so right at the start of the connection you send one packet then two then four so your window size doubles every time so the graph then looks like this in this initial period zooming up like that and then moving into its linear phase there's lots and lots and lots of other little tricks in there so uh if we detect congestion and we know that there's a lot of congestion because we haven't seen any packets at all for a while we'll slam this right down to the ground and start back from zero because we think there's severe congestion um but yeah i would encourage any of your your viewers to to take a look at that original paper it's an absolute classic so what happens is uh when you first create a file create file in there and make my files green just represent as a box and i call that version one at this point git doesn't know anything about that because you haven't told it about it so to get get to know about it all you have to do is i think mike's going to demonstrate this in a second is that log4j is like milk it's like water it's everywhere