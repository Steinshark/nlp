service to Elixir I recently rewrote a server a service that was on AWS API Gateway and Lambda in Elixir and apparently that intrigued some people so I decided to do a small write-up you know why you know why you want to guess why it's because it involves Elixir okay it has nothing else to do with serverless or anything people just want that Elixir juice in their life at all times every time always this post is going to be about our motivations for the move and what replacement implementation looks like this post is not a critique of node.js Lambda or serverless movement but a word of caution about how pricey it can become if your services end up going web scale mongodatabase trademarked uh we started with the original service was designed to collect an event stream from various web browsers collecting different client metrics and ingest them into a greater ETL extract transform load I love a good extracts transform load system we had previously been using a third-party logging solution that was getting expensive and we did not provide ways to extend or interact uh with the data we stored in a way we needed to here's a very generalized diagram of our original system all right all right all right all right all right akinesis stream okay I like that word you know it reminds me of Kinesis the keyboard I use hashtag add hashtag use code private gen for 15 off actually it's Prime 360 if we're gonna be real it's Prime it's not even prime imagine it's actually Prime 360. that was a great ad by the way didn't even plan the ad but it totally works links links in the description all right anyways so they have API Gateway kanisa stream Json schema validation Lambda all sorts of crazy magic okay this looks like every single project dude basic AF okay I love this article this article is so good API Gateway we bound our API client endpoint directly to a Kinesis stream using velocity templates so that the downstream Lambda function could take the advantage of Lambda Kinesis functionality and can currently be invoked to process batches of HTTP posts we knew that the service would be handling lots of HTTP requests at a time and did not want to run into throttling issues with Lambda so processing it off a queue in batches was a solid choice okay I mean batching is always a good plan Kinesis our Kinesis stream has varied in size a bit but if I recall correctly its highest throughput was 60 to 80 shards to avoid getting right provisioned throughput exceeded that's a lot of shards our Lambda was in charge of pulling patches off the queue validating that the data made sense collecting metrics on our metrics collects metrics on our metrics classic yo doggy-like metrics and ship off the results to a whole other Land of Magic to just dispatch notifications store replicas of data in S3 for posterity and compliance manage log slash event retention and ingest events into gigantic elasticsearch 3 cluster or cluster three all right to Summarize each post adds an event to the Kinesis stream a Lambda pulls off about n events at a time for processing everything is hunky-dory for now this is a great this is actually a great introduction they gave us the meat they gave it to us raw and we got none of the Annoying Parts all right the system worked fantastically for well over a year it scaled very easily required zero attention this is good I mean this is a good argument for why relying on other people's infrastructure is such a great argument is because you don't have to do to it when you build it it just works it's fantastic absolutely in there more teams and projects on the company begin to interface with it and then beautiful daddy basis coming in hot let's go then it got expensive why we needed a change API Gateway alone costs about 3.5 dollars per million HTTP requests that's awesome I can run my side projects on it for free I can build stuff in it rather quickly and get things done but when at scale so does the bill all right let's see our services our service didn't quite grow exponentially in use but it did hockey stick it went from free to a few hundred dollars to around twelve thousand dollars just for API Gateway no Kinesis no Lambda just API Gateway we are doing about five million requests per hour you tell me it only cost 350 per million uh I can't believe I did not recognize tree fitty like it was right there tree fitty was right there and you're telling me I didn't even see it uh 12 600 that's a lot of three fitties yeah again there is no lambdas doing business logic yet that's just cash to get the events in that spent is sustainable but obviously a waste and we knew that we were going to be adding additional load to the system in the near future currently we are processing up to 12 million events per hour let's do a math if we stayed on API Gateway and Lambda all right we're up to thirty thousand thirty thousand glad we dodged that one there's 30 days in a month classic 30 days in a month uh bleeding uh let's see from bleeding cash to let it crash that's an erling joke okay I don't get it so a lot of people ask me why not go this is a great question dude I love this question I've only written a few CLI twoes and created a few PR's and go I am not nor do I pretend to be a go Guru we had a system running at a high scale and I couldn't risk building it in something I didn't know how to write efficient efficiently and operate that's one of the Beauties about go you pretty much always write it pretty efficiently uh aside I did build the prototype in Rust for a uh for fun one weekend but it felt irresponsible to deploy it with the given I had absolutely zero rust experience dude this is such a great take you know we all love these bespoke artisanal languages but man is that hilarious why not node it was already written in node actually most of the code consuming parts were written in terraform to deploy it all and velocity templates to do some in-flight request manipulation to in uh ingest into Kinesis the node Lambda was rather simple it pulled off batches validated them and send them on their way down to the second Kinesis stream if I was going to set up my own Express server or whatever and then it would only be replacing API Gateway portion and my goal is to replace the Gateway and the Lambda in one operation uh get the preliminary Kinesis stream out uh out of there this Lambda was originally processing batches and shipping off batches now the functional function handling individual requests would also need to handle the batching we did not want to hit Kinesis with a single record at a time okay I don't know what Kinesis is what is kinesis I've heard the word Kinesis like 18 times I don't really work with Amazon what is the Kinesis is what is it what's the thing what does it do someone tell me it's a AWS Kafka or a Kafka alternative oh okay oh okay the keyboard maker the Amazon Q okay is that the SNS sqs stuff is that like the proper name behind it yeah no okay that's different I've only used sqs and SNS right stuff and only very little of it sqs is a separate product okay it's a big data streams oh okay yeah I've never really yeah I mean I played with Kafka at Netflix I've never played with it anywhere else we have our own internal Kafka stuff and mantis and Raven Raven on top of mantis on top of Kafka there's a lot of there's a lot of abstractions there okay it's a lot there's a lot of things anyways to get the preliminary cat uh oh we already talked about this so if I let's see so if I built it in node I would let's see I would rather have to I would either have to hack up some Global variable to save my stage in or uh in or depend on some external data store like redis to memcached or memcache why not Cobalt no one asked me that it's a valuable question to be asked but why Elixir this system has to be up when the rest of the world falls apart this tool is used for debugging issues in client software that runs on a lot of high traffic websites it also has to be absolutely fast our client library is for sending lots of information per page load in a lot of customers apps we can't go slowing down our customers user experience at the same time we decided since we are running our own HTTP interface now that we should give feedback 400 bad requests if the data is invalid to the developer Pro request instead of making them look at what the reporting tool down the line keep the user's experience good make the developers experience better okay it's cool and I enjoy writing and reading it honestly one of the most valid reasons uh I can take I mean again this is the truest form of DX I can take advantage of language features to reduce the need for external dependencies like redis or memcache okay that's cool too actually letting it crash like all software projects I shipped this to production I forgot everything right from the first time or hold on like all software projects I ship this for to production and got everything right the first time and it worked fantastically everyone patted me on the back and said good job we've shared egregious high fives and people actually carried me out of the office on a chair over their heads yep JK I screwed this bad boy up a few times and pretty sure I set a server on fire somewhere in the AWS region my first attempt handling the HTTP request is the easy part but I had the batch up data to ship off to Kinesis one way to use aw Kinesis HTTP API but they also have a Kinesis agent that I've run on Plenty of servers so I figured I would use Elixir built-in logger module and run a sidecar container with Kinesis agent configured to ship my logs dead simple nice well that blue uh that blue let's see well that blue to bits quickly The Elixir standard logger mentions Alternatives between sync and async modes to uh remain performant when required but also applies back pressure when under stress there's no way I'm gonna do that that pretty much sounds like everything I've ever done in my lifetime literally every single time I think that's not gonna happen that happens I don't recall the exceptions offhand because this was the quickest I've ever shut down a multivariate test or rolled back code but I drove the logger straight into the ground request times rocketed skyrocketed many memory went off the rails and I started seeing all sorts of errors or all sorts of crashes in the logger process steam started coming out of everything and I swear I saw a sprocket fly off I kind of backed away slowly from that approach my second attempt I wanted to make sure I circumvented any back pressure I needed to keep the request super fast so I replaced the logger module with a simple write to a file that Kinesis agent would read from writing files in Elixir also happens through a process but you can open up a raw access to a file okay I like it I like it here's a little bit of code a little style for a little style oh my goodness style forage storage file a little file storage a behavior event stream storage new line okay I don't know what any of this means because this isn't that fake ass language Elixir which I what am I looking at I don't even know what I'm looking at what is this what is that I don't know what that is seems fake write file log file message whatever that means raw dog me independent okay they are attribute yeah sure they are okay sure they are Elixir Champion sure they are I'm using a behavior an interface in other languages for storing data this allows me uh to have a nice easily inspectable implementation of the store in my test Suite oh that's nice yeah good job traits are great uh this actually worked amazing request times dropped so low I thought it wasn't working then Ram went crazy things are obviously a skew when a web server is using 10 gigabytes of RAM this wasn't elixir's fault it wasn't Kinesis faults either anyone know what it was I mentioned a sidecar container Above This is running in uh in kubernetes and three containers Elixir Kinesis log rotate are sharing a volume that volume behind the scenes is running with temp FS which is an in-memory file system I could change it to disk space but then I realized my goals was to lower dependencies and now I was sitting on a container full of them uh was log rotates deleting files before Kinesis agent parsed them I don't know I hope not I know this is getting real this is getting real this explanation is thorough oh my goodness just I mean this is why I don't see for the near future devops being anything but a growing career path is because there's so much required in all of this you know what I mean like the amount of stuff required to know understand and be fast at is insane I think devops is the only thing that rivals like the front end ecosystem for just the amount of insanity that there is like the amount of things you have to come up with and do is really fun but I will say that in like the devopsy backend stuff it's so much more fun you know you're building these tests you're trying to run you're splitting traffic saying it doesn't live do you do Shadow traffic do you like inspect like it just feels for me it just feels more fun but some people really do love the front end I don't know it's not for me it just feels more fun all right all those dollar sucking Bezos from Mr Bezos made me forget uh that time honored software principle keep its uh keep it simple or keep it simple me the solution was a few gen servers for people not uh from the erlang or Elixir World gen servers are a tool for implementing a client server relationship that allows for storing State and processing work asynchronously with a simple API it's built into the language and a fair amount of language features are built on top of it here's an oversimplified diagram of my supervision Tree application oh it's very bright event stream Q event stream server event stream worker okay server supports async and sync calls from HTTP request to place an event async responds fast with the 201 sync responds with any validation error this allows developers working on the integration to ask for errors when they are debugging but run efficiently when they are releasing code to clients Q holds batches of work Kinesis supports up to 500 items at a time up to five megabytes in size this queue gets pummeled by requests and internally it stores a set of batches when the count or size is exceeded it a synchronously sends a batch to the worker this gen server traps exits oh my goodness this gen server traps traps X it's wow too many s's I can never read too many s's in a row this gen server traps exits and also dispatches events to the workers when it receives an exit worker makes a call to Kinesis put record via a library called xaws if any event failed to write they are placed back into the queue to be reprocessed I mean it sounds simple it sounds simple on paper how emotionally damaging was it though can we all at least come to recognize that the amount of emotional damage that went on in this probably was a bit higher than we'd like to we would like to admit with this approach I have one binary to ship to no external dependencies okay that's good that's actually really awesome this has been working fantastic response times are sub second and resource utilization is almost constant here's a graph of CPU versus Ram during our high traffic time well done this is great very consistent love it love to see it and our numbers well Rock on Rock on the CPU usage per Elixir node ranges between 0.6 to 1.8 under heavy uh load Ram stays pretty consistent in the 100 to 150 range although I currently over provision it just in case how does this compare cost wise it's a lot cheaper for us a mind that we already have an Ops Team and we already have a kubernetes cluster running kubernetes cluster running our additional costs are the fractions of ec2 ec2 instances that Elixir nodes are consuming I could argue that it's free since they are running on leftover compute but for comparison with numbers above I'll calculate the cost I'll use CPU since that is what our this service is mostly constrained fine yeah that makes sense our general kubernetes instance group is running on t2.2xls that is 44 cents per hour and have eight virtual CPUs each so that makes about point or makes about 5 cents yeah yeah five cents per CPU per hour okay we're currently running three to five elixir nodes using between 0.5 to 2 CPUs each on the lower end 59 on the higher end 397 dollars they went from what would be thirty some thousand dollars now to 500 some dollars on the high end well remember it's not 12K 12K was the old numbers it went up to 30k with where they're at now and that's just for API Gateway remember they replaced API Gateway plus the Lambda service so that assuming the land of service isn't zero it's something right let's just assume it's not zero uh we haven't had an Elixir node using above 1.8 CPUs and on average we're running four nodes at a total of 1.1 CPUs okay so 174 dollars so should everyone go and rewrite their server uh serverless servers in Elixir roll out kubernetes uh get a nose piercing absolutely not it does a good part of this entire system still runs on uh in Lambda although it will be moving into Elixir over time to make it easier to reason about and develop on locally what everybody should do is think about where your service is going and can you afford those costs when you get there if you don't have a team of Ops people and you aren't familiar with server full stuff spending 30k a month on HTTP requests might be cheaper than an Ops Team absolutely this is a great call out you gotta make you got it you gotta decide what swords you're going to fall on but if you're already at 30 000 and you're planning on doubling or tripling you got to start thinking about the future right at what point do you change course and when do you know to change course right it's it's really about trying to predict the future but if you have the team you know how or will once you hit the scale there's a lot of room for savings by running your own infrastructure update I was asked on The Elixir Forum about the loss tolerance I'll go into that a bit more in detail here footnotes a downside oh it'll go into here it's some other article if you follow the link you can find the link uh footnotes a downside to this approach was developers using this async service uh we return to 201s and we're unable to tell them at the time if the data they sent was valid and ingestible yeah I was wondering about that because they do a 201 first and then they do like a another reporting they would have to use some additional tooling to see if their events made it to where they were supposed to go okay the system uh uses itself to monitor different aspects of itself like ratios of malformed events throughput and workflow step counters okay interesting uh it's the compiler that builds itself uh the back half of the system is still in Lambda and node.js but the invocations are tiny compare uh in comparison to what was being invoked by the lambdas exposed to the user interactions yeah because the batching happened here so it's 1 50th right so that means 12 million becomes what hundreds of thousands uh 2000 events was our sweet spot for real-time rendering of graphs oh okay you may be thinking that sounds like that can be replaced with the Kinesis fire hose transform function it could be I wasn't aware of or didn't exist at the time our system was originally designed and now that we need to get off the API Gateway it doesn't matter it is a rad feature though my wordplay is out of this world I actually agree with this entire thing including 0.6 I actually was thinking this entire time this guy is an inspiration as to how to make jokes for technical content this is this is such a good article this is such a good article hyper media please uh this is a good article okay okay okay okay hold on there you go the article uh that's a really good art the article is really really good I complete I just love this stuff because you know I I'm a bit of a contrarian sometimes for the sake of being a contrarian and I know that's not good to be a contrarian for the sake of contrarian but when everybody tells me how amazing serverless is and that there's no downsides ever and everything's great and everything's fantastic there's some part of it that feels it it feels like I'm being lied to and I feel like I have to Simply go against the grain completely just because I don't believe people you know what I mean like how many times have you been in a meeting and someone States like oh this thing does this and you're like no it doesn't it does not whatever you're like oh dude we've had people be like oh Jason json's cheap and you're like no it's not Json is like half of what your server does it's not it's amazing uh for node which is harder to have long-running Services yeah you know that it's very funny you say those kind of things because what that says to me is that note is fundamentally sucky if it's hard to have a long-running service it's not node's fault it's JavaScript JavaScript it's just so easy to make mistakes it's so easy to do the wrong thing in I'm not convinced it is fantastic I just simply am not I'm just I'm convinced I don't like that statement you should you should you should be able to write a program that lives for a long time I don't know it's just strange to me anyways I'm just very uh I will always be very very uh contrarian even potentially contrarian to a fault just because I want to go against the grain I don't believe when people say things are fantastic because I've never seen something be fantastic so this article is awesome it just shows that there is more Nuance to that conversation it's not as cheap or as free as people make it but if you don't have the team or the experience sometimes it's worth having a fake engineer who's worth four hundred thousand dollars a year on your team because it takes care of everything for you you know what I mean the name is the primagen