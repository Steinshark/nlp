my name is Matthias I'm with Apex AI where I mainly develop middleware and platform in the context of real-time systems and this is with C plus and the whole talk will deal with with real-time problems I will not be using a fancy new C plus features but I still think anyone can can really benefit and I hope I can convince you that it will be helpful I'm in in all kinds of C plus projects yeah it's it's mainly about real-time asset but this is coupled with safety when we want to have strong safety guarantees and sometimes this is also the reason why we cannot use The Cutting Edge C plus plus features because yeah automotive and Robotics industry for production is moving slow I would like to sometimes lose more of them but yeah and it's also about performance what we will be doing should not affect the performance of whatever we want to be doing much so it's kind of an augmentation of existing code with that being said um let's let's start so we want to keep track of deadlines and time critical systems I will explain what I what I mean with this in more detail so the agenda looks like follow like follows first we will yeah try to understand or talk about the problem itself what we mean with all of these and before we come to designing and Implement and looking at important implementation details that's also what I like most yeah um coming up or using C plus plus to come up with an interesting or hopefully interesting solution to a to an important problem so that's kind of yeah yeah and C plus is great for that it offers performance is it's very very powerful but we know this so then we we move on to implementation before we finally look at how we can or this apply to our existing projects so that's kind of kind of the plan and yeah talk about much about this you suggests go on so that we are we try to be all on the same page what are real-time systems so consider that we that this could be very simple example consider that we have some camera or other sensor it doesn't actually matter um and have to process whatever data we get and make a decision based on this processing and let's say those kind of data comes in with 25 frames per second then we have 40 milliseconds to make the decision or we have to ignore frames that's kind of simple and this is all already a deadline or what I would call here a deadline and it's a timing constraint on your application and yeah time critical system and real-time system I use these terms interchangeably so it's a real-time system as soon as we have such a constraint we can consider the real-time system and the problem is in general yeah if you have incorrect results of course there was missbroken and the results are useless but if you have correct results but they are very late in this context they're also useless because we might not make the correct decision then or not as a decision at all which could be catastrophic in the context of controlling a car or an industrial robot or something like this so real-time correctness depends not only on the correctness of the argument itself but also on meeting timing constraints or deadlines put it another way so I I already sketch what a deadline is it's kind of we have a time until the function must have completed or it can also be part of a function it can be more fine-grained and usually if you consider time we consider the wall clock because that's actual physical time not like CPU time it's not it can be interesting of course but it's not what we mean with time measurements and as soon as we have a real-time system we have these kind of deadlines that can be hard that can be soft which just means hard headlines if we if you do not meet them it's a system failure and we cannot go on we have to terminate or recover the whole system somewhat soft deadlines are a bit yeah easier to handle think of having a video player and not being able to process some frame in time it may distort your image but the result is not catastrophic so that is a soft deadline most applications fall somewhere in between I would say and this the problems are increased by by the fact that these systems on Modern Hardware we have multiple cores multiple systems and multiple multiple threats and so on so we need an operating system with a fair scheduling or a real-time operating system basically and now we move on to the notion of progress the notion of progress is just okay function has in the most simple sense it means the function has to return in finite time well you could say that this kind of a requirement of any algorithm maybe not blocking ones like mutex waiting for something but it would be cool if it unlocks due to some other reason because otherwise the system is probably also broken but with deadlines you you have you have to return in a concrete time span and yeah that's more strict you that's all you could say we need to make progress in some time and the reasons why we may not make progress is just that yeah we have a deadlock but in use this is usually a programming error the system is kind of starving which is the effect might may be similar but a bit of a different problem or more specifically if you do not get your threat priorities right you may run into priority Invasion version but which is also the same kind of starvation we need to consider all of these and all of these can be reasons that we do not meet deadlines okay that's kind of the setting so what would we do if we want to build a real-time system in C plus yeah usually we we do what we always do we try to understand what the system has to be doing and in addition identify deadlines and ideally if we separate the deadline or the the time coding code from the non-trigger code because it makes it easier to reason about it and then we have to think about these kind of problems with priority inversion and whatnot yeah and usually the the main ideas are just limiting data sharing limiting context switches consider log free programming programming which is not always the Silver Bullet but it's worth considering and of course be careful with sweat priorities so now let's think about can we guarantee deadlines or why can we not guarantee that threat lines are met at compile time because we cannot the reason is it depends on on various cases like Hardware but also data we only have at time of running the algorithm so at one time so otherwise we have to have very precise worst case um yeah worst case bounce and they are not easy to come by and practice so uh anyway this problem is informed if you can if you want to do this at compile time in compile time it's impossible because you could prove something like you would need to solve something like the Harding problem it's it's kind of in this board park so we disregard this we cannot solve this at compile time but we can and this is a goal of this exercise we can we can solve this at one time yeah and what we want to do at minimum is something that looks like this right it's it's simple um I have some kind of time critical function and I want to say and it should be easily understandable and and visible in the code I want to say okay I expect that this part of the code makes progress in a certain amount of time and to make it nice to look at and concise we want to use Chrono little words right because it's just nice notation I like Corner a little bit okay so that's that's kind of it the semantics are I think pretty clear yeah as I said this is the expectation of course you may not agree with with my naming here and I'm also not super happy about it because naming functions is hard right but it does not quite matter at this point right um yeah we can easily change this later it's not and it states what it's supposed to do in my opinion okay let's not not worry about the naming but it will be consistent throughout the remainder of the talk so that's a basic thing we want to accomplish and of course we have to implement it behind these kind of yeah down my course right oh my course evil evil but we use them in a nice way we we will not really dive into it but it could also be functions there's the reason why why it's macros but we could do away with it can't come to this later okay it's a bare minimum we want to achieve but now I already said that we have to consider multi-swelling in some way so consider that your code could be running in different threads so we need to add something more like a macro that tells us or some functionality that tells us please go into it start the monitoring whatever that is supposed to mean right okay and also it would be nice to to identify our deadline sections with with some checkpoint ID or something right and that is what the but in this specific example the 73s and now the semantics is just a bit augmented and now we we will be doing this for multiple threads under the hood it should all be happening automatically right that's kind of the idea and lightweight lightweight is also some consideration later okay in the most simplest way of doing it how could this work right assume we can get from some magical function now a timestamp could be Chrono now for the considered corner now for the time being but it's actually maybe a bit more complicated than that if we come to that and what we just do and that's somewhat zero C plus plus code on the right side right but what we just do is we have to remember what deadline are we at you have to well we have to not actually remember the start you just have to remember the deadline we have to compute the deadline you have to say Okay the deadline is start plus whatever you you say in this case 100 milliseconds of course time unit is also flexible and whatnot and at the end we have to compare the end time to our deadline and if it's exceeded we have to report a violation that's kind of roughly how it will work except that it's not enough because consider that your sweat does not make progress then we would never report anything and we would maybe crash if it would be a car and without having noticed and there are other things like what time type are we using and so on and so forth so as I said what happens is the threat doesn't make progress of course and the reason can be as initially sketched it's in deadlock well it's in Starvation or it just takes so long with this particular input for whatever reason we need to safeguard against it and we do this by running a background foot we have to run some additional mechanism in the background all of this has to be happening automatically and with little overhead I cannot stress this enough to ensure there's the background set will need to have a high priority of course because otherwise we have the same problem but I think we there's no real way around this so basic messages we cannot only use the thread itself to monitor this it would be too easy and yeah could only use this if we know we miss it by only a little and the deadline and we never run into Deadlocks or something like this and then it might be enough but in general you cannot give this guarantee I would say okay yeah I hope you have now identified the problem and I have convinced you that it might be worth considering especially for real-time systems but I think it's also useful for General C plus code if you're interested in your timing of your applications and stuff so now we have to think about yeah more about a specification and how we what we have to do to to solve it in an efficient way okay that's by the way how the main API will look like uh some of this we have already seen But functionality wise what would I Sometimes some some of this is just a reiteration what we want is we want to detect the deadline violations in multiple threads we have to consider that the threats are deadlocking and so we need to safeguard against it we we have to think about well we have to be able to identify the deadline somehow especially if we run into a violation I have to tell you where the violation happened yeah and ideally we have to react in some custom way which which we can just register a Handler or something and then yeah tell what should happen when the deadline is exceeded of course it would be nice if all of this can be if there isn't really sure our system is good because ideally we compile It All We optimize it all out and we say okay I'm I do not care it I want the last bit of performance and we can optimize it out and it also presents us this opportunity to um if you want to with additional overhead we can gather some kind of statistics and this is also useful to to come up with your deadlines or what is possible on your target Hardware in the first place so that's where we had it at and ideally it should not be hard to use interfaces it's hard to use this probably a bad interface and we just need some some stuff from the sdl and self-written custom code not much more a third party dependencies are also always or can be a problem for for certain projects so that's nice to avoid them okay I already mentioned that performance is kind of a thing so because we do not want it to interfere with the normal computation too much and again this means reducing data sharing and we will see that the log the data there's a happy path sorry will be log free and the path that is not log free will it will have very low contention there will be locks but they are not used often or not contended often and also in real-time systems it's often the case that we do not want exceptions yeah that's a whole nother topic or a reduce or avoid dynamic memory allocation so so some kind of note heavy on yeah node based containers like map which allocate frequently are right out or you have to write them yourselves yeah we have to write them ourselves and yeah what we also do not want is our checking mechanism kind of producing priority inversion that would be kind of bad because otherwise it would be bad it's our system originally has no priority inversion but if we introduce this kind of checks we suddenly have them kind of defeats the purpose I would say so it should be in some way non-blocking and from my experience at least we should consider this early in design because otherwise you make decisions you have to have to revert it from from scratch and you yeah you have to rewrite it again if you have some restrictions but minor ones yeah um let's let's limit the number of threads of course the deadlines cannot be arbitrarily large because it cannot represent um arbitrarily large deadlines right and also we need to ensure the priority of the background thread and for now maybe you have wondered about another case what would happen if you do not immediately um say this it's working like it's working like parenthesis right um but if you do not close the parenthesis with the confirm because but start a new opening parenthesis is expect progress this should also work but we ignore this for now the yeah I will sketch later how this will will work I think we get the idea but the basic idea is to just ignore it for simplification so moving on to some yeah I would say that's kind of uml C plus plus pseudo code almost C plus plus to get a rough idea how this works and actually it's super simple you I would say we have some management code which will be a Singleton which is which I call just a threat monitor for a lack of better word and each thread has a thread State and the thread state and it's a one-to-one correspondence right well more precisely each monitor advert has some such a thread State some of threats we may not care about has an old switch state um and the threat States they have they have to store the deadlines the ID of the checkpoint or deadline ID and it's also useful to know the thread ID and just monitoring mechanisms just knows which threats are currently monitored or not this is those registering API and also runs some background thread is responsible to run this background thread which has to access the thread state in a leading way and actually also in a writing way on a very specific circumstances as we will see but mainly it will just read from them and this is lightweight yeah but we come to that now that's kind of kind of the picture that's also on versus of note is that we use thread local to just establish this one-to-one correspondence between thread State and threat actually it's a pointer here but it could be the actual object I chose for some reason not to do it um yeah that's that's a technical detail but it establishes in an easy way that each thread may have it's uh its web state and adjust the pointer here is one one reason is for example you may not want it for every thread state for every thread and then you have for each just an empty well null pointer but not the whole object but the object is lightweight so it would not matter that much okay I hope he gets a picture if not from this and from from that drawing set money for the top part is the same it starts this monitoring thread this will periodically monitor the deadlines and for each thread we have some constellation like this there's an active deadline I chose to to say this 100 milliseconds that is kind of relative to to some zero starting point but it's actually considered a Time point it's not super exact here but I think you get the picture so this is what the thread store and the monitoring thread just periodically looks at this in in some way we will see in the details later okay and can then look whether the deadline was exceeded and all of this will not be very synchronization between between threads that's kind of the the system design I find it convincing or I I I would think it works but but the devil is in the detail of course and so we have to look at some we have to zoom in into actually in the important part of the implementation first of all we have to think about how we represent our deadlines and fundamentally deadlines are just time points and we have something for time points if we wanted to we have Chrono and yeah time points but time points is all there are only durations in some way relatively measured to some people and usually this report is something like yeah within with the system clock it's often first of January in 1970 or it could also be the system starting the boot up time and other ways are conceivable yes that's that's kind of how it works and we can think of durations as just yeah if you're familiar with this corner just number of ticks um which represent a Time unit and we can just consider this nanoseconds for the time being but of course it can be easily changed for implementation reasons we we will see that we have an additional constraint our representation should be small so because we want to use it in an atomic and that is yeah our main mechanism will be log free so if it would be too large and we've and we would write Atomic or something around it it would under the hood potentially create something like a mutex which is more heavy weight and introduces introduces other problems we can avoid and if you can avoid them why not avoiding so for the time being we assume also that we our time type helps the threat is readable actually um if not sorry about that [Music] um the time type is some 64-bit unsigned integer unsigned is kind of important but become clear soon I hope and we have again our our magic functions that gives us gives us a timestamp I avoid here specifying that it's Chrono because Chrono may not have well or some function of the time point because it may not have the full capabilities that that we need or actually we will see that it has but it's just missing a small piece and I was wondering why but that's probably a good reason for it okay we have to have be able to add and subtract or something like these these times and we consider nanosecond ticks and if we do that we are prepared for for almost 300 years so let's forget about overflow for now and move on okay now that we have established how we represent our time we have to consider um what we do when we we check the deadlines I think we have already already already seen this but yeah it's it's a bit more detail right now because now we have established the types in the thread State particularly the deadline it's now time T remember unsigned integer 64-bit for the time being and what we also consider for now is that zero is an invalid deadline that's it's good enough for now and mostly okay and we start with an invalid deadline but now what are our expect for Progress function macro whatever we want to Define it to the the column is of course not real code but but everything Below in a way is yeah it's it's it's it's the same I already showed but now I specify that I do this for the current sled by invoking the if you have this variable threat state or TS here which um yeah points us to a threat State and we can now set the deadline in the search date and the ID actually I have to think about this it should be the other way around but yeah the order of setting it it might otherwise come to a to an interesting ways I just see this now okay and when it is said we consider the deadline valid otherwise with zero it's invalid yeah I think I already mentioned that we we try to use threat interaction and sweat local is one tool to do that but of course um the the 0.2 object may be known elsewhere so yeah and it is in fact so now for the counterpart the confirmed progress It's also just more yeah I zoom in more compared to the original version what we do is first we look at the thread state we exchange the current deadline to zero which is necessary to to invalidate it for everyone else looking at the deadline and who else will be looking at the deadline it will be the threat that monitors it in the background so the reason for this is just to avoid that we get multiple reports or something um if the deadline is violated and if it is valid it means and then we have to check whether whether it's actually violated as a check for now is written down here it's just what we already had and if it violated we report the violation and we pass the threat state to this violation reporting and it hopefully had has enough information from this could pass additional information but it has enough information to to do useful things it can be actually a bit extended like providing the amount of time we violated the deadline by but yeah that's easy to add later okay and validation is just for and to to avoid multiple um multiple reports so I mentioned the background sweat that is running what is the background set doing and I want to convince you that that it's not interacting in an inefficient way with uh with the rest of the world basically of course it has to access the Swatch State we have already seen it in the design diagram and yeah you have to consider it's maybe we have two threads and they could invoke all of the operations here sometimes concurrently and what I like to do is I draw some kind of metrics like this where I think about what happens if those interact concurrently what is is the thread one cause register thread and the other also calls with just a threat how are they concurrently interfering and the answer is in this case okay they are um this is protected by a critical section protected by a mutex so that is not log free but on the other hand this registration happens infrequently so I do not care much actually it's not worth the hassle to make it lock free actually will probably cost you more and make up everything more complicated same thing but while the background thread is doing its checks it's yeah excluding registration or and will deal with this registration but this is a small price to pay the important part is um the threads thread one and thread two with those expect confirm will not interfere with each other at all so it's no interference and this is monitoring sweats interference will be log free so and that is why um if you can if you can do that then the happy path is log free and also the the monitoring threat we will see it will do a complex change operation in case of deadline violation compare exchange operations are more closely than Atomic reads or or something but this also only happens in the bad case and you should not be violating your deadlines left and right if you do something is already warm probably encode it would look somewhat like this right the monitoring threat for each thread state would do something like looks almost the same like this was what confirmed us but it it loads the current deadline but does not invalidate it like by by exchanging it to zero it just reads it the memory order here can be optimized but I usually do this later on and checks whether it's valid and if so whether it's violated and if so then it tries to invalidate it by using compare exchange to zero and if this succeeded it reports the violation if it does not succeed it just means in the meantime concurrently the other thread was whether the sweatpants monitored was actually also running into confirm exchanging it to zero and yeah and Reporting the violation and so we don't have to this all only holds if we ignore a wrap around which is fair to do with these counters and times we have in mind I'm just saying that and of course all this will be done for all monitor threats that's why we have this Czech slats routine which is just doing it for us rights and you can think of it running periodically in the background and there you also have to make a design choice you can run it periodically all the time in a some kind of polling mode or you can consider waking it up with some kind of notification when actually deadlines are to be processed but you will all immediately run into the problem that you have to think about how to notify and you would usually say Okay condition variable and that is right but this is a heavier mechanism and it's also usually not log free and you may introduce contact switches I have actually seen projects where use of the condition variables kind of yeah severely degraded performance so but I think the the the actual the learning from this is well there's optimization potential to to do some kind of hybrid approach between polling and notification what we cannot do is some kind of or not easily do is having some kind of priority queue of all deadlines because I do not know how to implement in an efficient way a log free priority queue it's kind of a challenge I can tell you because yeah analog no problem but I want to avoid logs and so and it's not needed so you pay in some way and you have to consider in way which way you want to be paying and like this is the easiest way and I think it works well enough okay now that we have seen that I hope you all have the picture how it will work if not hopefully this will cleared up time is Flowing from top to bottom and we have two threads and we have our monitoring thread and the first word says Okay I want in 15 milliseconds that whatever is now coming there's a function f in particular will be completed so it sets a deadline of 15 milliseconds it's but the monitoring threat we can consider that is has currently checked has not seen the deadline so it checks nothing for now and and then time moves on I only sketched the or Draw the to the relevant times here time moves on and we see that thread one is late and it will be detected well the confirm is only uh comes at at 40 milliseconds so the monitoring threat will detect it first with a violation of plus five and when it's finally completed we see that the actual violation will be 25 milliseconds in the meantime thread 2 has also started it's um it's yeah it's computation of function G but it has a much larger deadline which yeah if it's 50 milliseconds and from time Point 20 to yeah then we have time until 70. so that's the deadline and this is actually not exceeded in this example so it is confirmed nothing happens it was checked in the meantime the check does not say anything it does not nothing bad happens and now the other threat again starts its deadline having cyclical systems like this is very common in in robotics but also elsewhere I would say and now it also will violate the deadline but the difference now is that the threat itself detects it because the monitoring threat will check a bit too late so but it's again the same plus five violation but it's now detected by the site itself so in any case the important point is whatever we do the violation will be detected and the delay with which we detected is about it's about the the frequency with which we monitor that's not the whole tools because the checking itself takes also a bit of time and so on but yeah it cannot be it may not have not been do not detect anything at all so that's kind of the point and in practice it will be fast enough so now it's a basic functionality we have two top two important topics to consider NASA deadlines may actually be the more important one but we start with what I would call overflow tolerance it's kind of maybe a bit exotic but you will see I um yeah until now as I just said okay we have some magical function that gives us a Time point and please I want it to be somehow and you in 64. how can we achieve this well the code is here we take the chronostatic clock which is probably aesthetic clock or a monotonic clock is the right choice because we are measuring intervals that's also important so I would not take the system clock because it can change um in Coe well also in practice and yeah we measure in nanoseconds and so on and what we now do is yeah but probably can be considered bad practice in a way we undermine all this Corner type safety but it's not that bad because no one except ourselves the implementers know this so it's not not really public API so I guess it's all right but it still has some problems if you look up if you look up a specification of Chrono for the steady clock it does not tell you whether it will give you a signed or an unsigned representation type that's the web t count will give you a ft and it's left unspecified to my knowledge whether this is signed or unsigned but in all implementations I have seen which is about three um it was signed and the point is signed overflow is undefined while unsigned overflow is not so even if we cast it like this and pretend it's unsigned we may run into problems when we actually get the time point from from the Chrono clock um we could remedy this by by having some alternative way to get it why I'm why am I talking about this why why do I want to have an unsigned type because it makes things nicer if you have an unsigned time we can accomplish several things we do not have to care about the epoch in theory our system can run forever consider we sometimes some someday want to launch some kind of math Expedition and it needs to go on and on and yeah then it's go on and then it works forever or for a very long time if it's powered of course and nothing else bad happens and also in in safety critical context there may be some guys that ask you how can you ensure that this does not go wrong and then you can say I would like like we will see we can do this and for me more yeah practical perspective it means we can maybe use a smaller integer type and that means if we want to apply atomics we can squeeze in more data in our atomics because usually you have eight bytes and now you can squeeze in more information in your atomics and this can allow you to optimize your algorithms more yeah to make this work of course the clock must support overflow the violation checks we will see will be more a little more complex but nothing to worry about yeah yeah and you just have to think about time like a cycle right the time is now a cycle of of lengths here in this case 2 to the 64. how about the violation check now look like uh it would look like yeah we could think about like this we compute the data now and check whether the data is greater than zero between this I just use T for yeah to refer to it but now directly of course this is of course incorrect because it does not really help you because um and Einstein is of course always greater or equal to zero so yeah it's not it's not correct but we can correct it and because if we can just cast it to to answer to sign to the corresponding sign type and if we do this then it works at least for for small deadlines smaller than this m half and to be to be precise because of because of how tools complement behave I would leave this as an exercise it's not I'm just telling the messages measure you have to be careful with measuring time okay now you may say it's only a theoretical problem and you may be right um it depends on your application context but the point is we can Source this and if we need to solve it it's not complicated to solve and yeah it does not really cost us much if we have this clock and Corner steady clock may not cut it for this but if the underlying clock actually works with unsigned as and it's kind of a real-time counter it's not much of an issue to to make it work if you want to just have to yeah provide the interface at Chrono now where the customer can could guarantee the yeah an untimed return value that's about that's for for overflow and now nested deadlines how do we solve this I hope I have to speed up a bit I think but the idea is not just have a single deadline on for our third state but a stack you have a stack of deadlines and if you have the stack of deadlines then we [Music] um yeah we can we have to check the topmost deadline that's kind of the idea not there's not much more to it you have a stack of deadlines but then the stack has to be some nice has to have some nice properties it must be log free in a very particular way it needs to be log free for Consumer producer only for for the setting thread and the monitoring thread needs to read from it and yeah that's kind of the challenge is to come up with the lock research thread for for this I did this um it's not super complicated because it's very hand tailored for the problem and it's also an efficient stack with intrusive you may you may have heard about this intrusive data structures are very efficient in memory management there's boost intrusive you may look it up um yeah we use similar techniques to to avoid memory allocation it basically means that the elements we push on the stack have awareness that they they belong in a stack they they know their their next pointer if it's implemented as a list yeah unfortunately I have to skip the details but you can hopefully imagine how it works if you now have this confirmed progress you have a threat state and you pop it and if you're in time nothing bad happens yeah that's that's about it if on the other hand the monitoring threat detects it it will not pop sir uh topmost deadline in this case 17 milliseconds it will invalidate it which is indicated here by by yeah marking it at red okay that's how it works um yeah now final section by the way how much time have I left okay let me let me let me wrap this up okay we have we already have a picture how this works um we have an application and we can monitor it like this I think it's not super surprising right it looks like like this you can just monitor it and why do I use macros I use macros because it allows me to to track also the source location I could not do this without Marcos I think there's an experimental um Source location but it's not even in C plus 20. 15. okay great great because I was worried well actually I was super valued because I then I can relax I I take a take a drink exactly my my talk is also on the deadline deadlines are everywhere else so you should be concerned um exactly so I will slow down a bit um yeah this could be your code you run it in a loop right and you can yeah nothing nothing super surprising you have further now for now you have to do this may be ugly yeah I want to start this threat monitoring this can of course be abstracted away if you want to we can have our monitor a monitored threat abstraction we may even combine it with with J threads and it's even joining automatically in the destructor and whatnot so of course this can be can be abstracted no problem at all and we could also yeah you could also be concerned about I have to confirm this progress this is error prone this is like mutex lock and unlock um we have lock cards for this in the mutex world actually this can be generalized to scope guards and this particular scorecard could do this for us on the other hand this has a drawback that we are now limited to to Scopes yeah that may not be applicable so I would make it optional API right okay and I think um why did I make it macros because most coding style conventions makes us stand out they allow me to capitalize it and whatnot it's not at oddsmith with with most coding style conventions and yeah this makes it easy to find it in the code to grab for for it and same with it was the same for for certain error handling strategies but where but this is more related to that I usually cannot use exceptions in my production code due to real-time limitations okay so I and this works together with this and those macro things stand out okay what can we also do we can integrate this in our test framework personally I use Google test also used catch two for a little bit not tried it with it but for Google test I would say it does not interfere yeah it does not scream at you that oh that's totally different it looks nice with Google search I would say because now yeah we could have some kind of atomic variable we're indicating whether we have actually a violation and set it in the Handler and just check it in the test and if you think this is still too much boilerplate you could combine this confirm progress and expect faults into one somehow test specific macro no problem so I would say yeah is this easy to include it in addition to to Google test it's header only it could be also made pre-compiled which was of course better for compile time it's not using genetics it's a it's a yeah it's a it's a user site so there's no need to make it header only but it makes it of course easier to to include of course you have to be careful with timing tests and that is no exception because if you run timing tests you have to be aware that there may be taking longer well it depends on your your platform you have to have good control about your platform you are earning it on I've seen multiple times things like that the CI actually is doing a lot of other things it's loaded and then test fails sporadically you have to have dedicated hardware for your timing tests and they yeah it should not be loaded and it should be a similar Hardware you will intend to deploy the things on because yeah otherwise that's probably no point but this is timing test in general which can just integrate it yeah otherwise we would solve the problem again and why it's doing it already but what you can also do is if you are interested what your code is actually about variants and stuff in runtime the mean runtime of a certain section it's of course easy to integrate this I did this only experimentally in a very very clumsy and inefficient way with some mutex and whatnot because I've write to some map in a protected way but at this point I did not care too much but of course it it changes your runtime characteristics a bit but this can be done also with less interference by using more local maps and aggregating at the end and so on and so forth and your output could look look like this now you at the end you get some statistics you can invite it to a file whatever and this is actually generated from code where I generated to the the timing it's drawn from some kind of distribution and if I repeat this it looks accurate or it looks good enough because yeah it um it estimates in a way my the deviation that I that I that I gave of the uniform distribution and then what other one is uniform no one is one is normally distributed and one is uniform doesn't quite matter you see probably where this is going so you can and and from this you can get a feel that what your system is actually doing okay of course this introduces overhead and so we should um not have this in production code okay last last topic what does this all cost us and the answer is unless I did some mistake in Google Benchmark not much it was also the target if I scale up the nesting or the number of deadlines it scales linearly that's good and it does not cost much to begin with it was it's about 100 nanoseconds I think the main part of this is actually taking the timestamp or at least a lot and some of the atomics are of course also not that cheap for comparison mutex log unlock cycle and this is of course an unusual scenario right you'll not no no code in between and this is on this machine and but yeah music is an order of magnitude lower about on the on this machine um but what I find more noteworthy or interesting is how does it scale with the number of threads I have if I have now a number of threats increase the number of threats that do are doing this in parallel then I see that I still stay roughly with non-violation I stay roughly in the same ballpark it's still about 100 milliseconds actually this measurement for the latest version I think I brought it down to 280 nanoseconds but maybe it may also have been a little luck but it's the order that matters and the scaling for me at least in this part um so and this confirms our design intention our design intention was that multiple threads do not cause it to interfere we do not see it going up and that's that's logical because the threats itself do not interfere with each other only with the monitoring threat which is one thread nothing more and so if I scale this up yeah at some point it should scale up because of swapping between threat context that's not visible here but of course the metal measurement could have been wrong I need to confirm and it gets a bit a little bit worse if you have actually violation where it then satellites it scales up I think it scales up to the 12th cores I have here and then accelerates all right um yeah but but the message is yeah the message is it's gay it's good I would say but be careful in micro benchmarks the caches are hot that's not probably not the real characteristic on your system you have to in the end you have to measure there but it I would say it has a little overhead that is kind of the important message all right what did we do we have now some kind of let's call it a framework um to monitor these deadlines that is easy to integrate I hope you have accomplished all the goals we set out to do yeah to achieve what I also like is the code is the source of Truth in the in the development especially in in production systems you often have some kind of requirement system where you say okay this code must not you have timing requirements it says so in some kind of requirement database that's all well and good but then you ask myself okay where in the code do you ensure that this is the case and now I could connect these and say okay I do it right here of course the mechanism could be wrong but the algorithm could also be wrong so that that is always a problem you at least can argue why it works so in the but but I care more about that the code is a source of truth instead of some requirement somewhere yeah I already mentioned it has low overhead as it's macros but we could also accomplish this otherwise we can easily disable it yeah we have the statistic mode I think we succeeded yeah what are the key takeaways in my opinion well as for data sharing the best sharing the best way of sharing is no sharing don't teach this to your children but in the case of sweats I would say it's true if you cannot avoid sharing then try to to limit it in some way and log3 is one way small critical sections are one way but it's also okay to block four rare operations meaning using mutexes finally or time measurement yeah it's it's a it's it's trickier if you think about it there's also devil is in the details again but you should use a monotonic clock and with unsigned timestamps you could run forever and we could replace the corner stuff with if we have some real-time content and some systems have this Maybe closer to the hardware get some ticks from from some Hardware counter which should be accurate of course and we have not talked too much about this but this is about the stack it's handcrafted particularly for the problem that's not unusual for log3 structures to make um yeah hand tail light to the problem then you can optimize it for this problem and the optimizations are usually try to avoid allocations by pre-allocating as much as you can and so on and use special structure of your problem um yeah more general purpose stick I've not tried it actually with a general purpose stick probably would not have the IPI I need yeah last but not least you could think of extensions we could monitor different processes but then we would need to exchange information between processes and that can be done in an efficient way actually for example with some powerful shared memory middleware which it happens to I'm co-developing um but there are probably other ways as well but you will pay for it and so it's not the default use case and it's not implemented yet but yeah it might be it may be important so we have one process at monopolitor's different other processes or the threats and different other processes it may be might be your use case it it is in certain distributed robotics applications the monitoring threat can be made more efficient um I already talked about this and the statistics mode yeah it's kind of yeah it's an afterthought currently but um yeah I did not worry about it much and also still some not so critical parts are still using St sdl structures that use dynamic memory but they are easily replaced with fixed size alternatives you cannot yeah but the key parts are not using um anything that shows or dynamically allocates okay to to sum it up where can all this be found Okay so this is this is very much work in progress and can be found on this GitHub page if you are more interested in all this real-time counting the the site I mentioned here has a very good and better explanation than I could do in this could give in this short amount of time um yes the luxury stack has uses similar techniques and the log free buffer implementation uh it could be worse versus to to to watch the previous talk of mine but also what I find very enlightening was a talk from from federal where he carefully weights up calls and cons of log free programming it's not a silver bullet you have to be aware of this and and I think here it's worth it I made a slight effort to compare it to a mutex based version and the log 3 version came up on top but yeah maybe this was maybe a bit sloppy so I would not count on it I still think it's here it's there ended to to use this techniques and yeah of course the book of Anthony who happens to give I think a parallel talk um yeah Google test you probably all know and some of the real-time mechanisms can for example the containers I mentioned to make this non-allocating could be also taken from from our uh yeah middleware if you're interested I'm always open for suggestions for improvements contact me yeah um I probably will extend it after after we're doing Christmas I think yeah now I've lied to you a little bit you hope you spotted it or maybe you spotted it when I talked about the invalid deadline the invalid deadlines but I'm yeah think about it a bit yeah but otherwise thanks for your attention some questions thank you uh so the question I guess is what if the thread the monitoring thread gets a lower priority and without the monitoring threat gets a low priority and doesn't check the deadlines for a long time and then it uh basically there is no limit on how many deadlines it can limit it can it can miss if uh something let's say violates the deadline by 20 milliseconds it doesn't matter what was the Precision we set for monitoring threat if it gets suspended for longer even if even even if it wants to wake up more often you mean the the background sweat yes yeah for sure that's a problem but um thinking about it um what is the best that we can do I do not know whether we can really do anything better and for real-time systems we have threat priorities to play around and if the system is not loaded we have certain guarantees that they are scheduled but of course we could use some kind of journaling in order to remember the uh like when we started the deadline so that eventually when we read the journal we know that well it was started at some point even even without checking out the real time yes we could could write this down but then we would check this after after this after the running of the system you mean yeah it would be more like the statistics mode which also can track the number of violations and um the amount of violation and so on I think this is this is what the statistics mode could provide because it works regardless of the thread scheduling but because but but but of course if no threat you care about is scheduled at all then you have a problem but I do not see how this ever can be avoided it cannot also be you can also not do this from another process you can argue the same way right it's kind of yeah well but it's still realistic that well something gets overloaded for let's say a second uh because I don't know we run out of memory or on killer doesn't come at the right time uh there can be realistic time spans which go over let's say 40 milliseconds that you mentioned thank you I have no no better answer than than I gave so at some point you have to have some give maximum concessions here I think hi um yeah thanks for the for the talk um it's not a question it's more of a suggestion so you were talking about like uh using a priority queue if you were willing to take the constraints of say like you have some Maximum deadline and you were willing to quantize your time units so let's say you quantize your time units to milliseconds and you said right I'm only going to have a window of 1024 milliseconds yeah that's my maximum deadline is going to be a minute about a second then you could use a circular buffer yeah so it might be an option so you write your you know so then you would use the current time as a lookup as an index into this circular buffer and that would tell you if anything is supposed to be expiring at the moment you want to solve the problem that you otherwise have unnecessarily wake UPS where you check nothing or you are not even close or you would be able to check you'd be able to know exactly what is supposed to be expiring at the moment and you would only have to check one thing then I'm looking at at what to check here yeah yeah you are right but it's okay that's not not that simple with real if you want to have a real priority queue I have problems to um modify it without using a mutex maybe yeah so if you're going to have like if you have multiple things expiring in the same time slot then you would have to have some way of representing those as but this is actually the pro a problem I'm usually interested in this kind of algorithmic uh yeah minor sort of interesting problem to me and I'm actually intend to tackle it but I can from the top of my head I cannot see how it how this would play out and and then you have to measure how it how it works but you are right um I'm still always already considering having a lot thanks so for you for those of you thinking about what it's about it's a deadline invalidation right the zero deadline is is an actual deadline and you have to think about especially if you want to consider overflow but it's solvable either you use the lower most bit kind of work it out for yourself or you use some kind of double counter I cannot sketch this due to a lack of time we can discuss this afterwards actually it currently is implemented a solution too um yeah that's that's it foreign