this episode is brought to you by brilliant one of the rarest occurrences in technology today is that of the unchanged the standards and specifications of information exchange that form the internet in particular has been in a constant state of evolution since its inception however one 35 year old image format has become an oddity taking a completely different path as the internet developed the graphic interchange format or jif has remained technologically stagnant for over three decades predating the modern internet and yet still remaining popular today thanks to a dramatic social evolution of its use [Music] gif was introduced in 1987 by compuserve america's first major commercial online service provider compuserve had first started offering dial-up online information services to consumers in 1979 and by the early 1980s advances in modem speeds processing power and the introduction of their compuserve b file transfer protocol had now allowed for the exchange of graphics on their platform this also opened the door to copy serve's eventual transition to a gui based interface at the time access to most online information services were billed by time and for graphics to be exchanged cost effectively and within a practical transfer time the service required a method to reduce the memory requirements of informationally dense graphical data compuserve software engineer steve wilheit was tasked with leading the team to solve this problem the mainstream availability of color computer graphics in the early 1980s was a relatively new development at the time and due to memory costs and the limitations of memory access methods to reduce the number of bits that represented a pixel were needed in the vast majority of color graphic systems an additive color space based on the rgb model is used in this model it colors defined by chromaticity coordinates of the red green and blue additive primaries in modern graphic architecture eight bits are typically used to quantify each chromaticity coordinate with 24 bits in total representing 16.7 million possible colors per pixel storing 24 bits of data per pixel even at the lowest usable pixel densities would easily overwhelm if not exceed the memory capacity of most systems of the time because of this the concept of a palette or color lookup table was introduced a palette is a data structure that contains an indexable lookup table of chromaticity coordinates in this mechanism each pixel of the image data is defined by a palette table index where its colored data can be found the number of color definitions within this table determine how many simultaneous colors can be used within the image and inherently how many bits are needed to define each pixel a 2-bit per pixel image for example can reference 4 color definitions within a palette while a 16-bit per pixel image can reference a little over 65 000 unique color definitions wild's team opted to use a variable bit depth palette scheme for the gif specification allowing for as little as 2 bits and up to a maximum of 8 bits per pixel for palette colored referencing this allowed low color count and monochrome images to significantly reduce their memory requirements by limiting the palette size this bit depth versatility proved to be efficient however as graphic hardware expanded in capability the 8-bit per pixel format would become the most popular variant used while efficiently consolidating color definitions significantly reduces the memory footprint of an image the bulk of reducing its storage and transmission size would come from image compression all forms of image compression operate on the premise that most images contain regions of color patterns that are repeated throughout them these patterns can be reused within an image using a symbolic definition that requires far less information than what is required to define the region's colors directly the more repetitive the information contained within an image the more compressible it becomes it's even possible to increase the compressibility of an image by removing information in selective amounts that increases the image's repetitiveness yet fool our eyes this technique is known as lossy compression as it alters the original image data in the compression process while lossy compression can dramatically reduce memory requirements the technique was far too processor intensive for consumer computer hardware of the time and its lossiness made it unusable for functional graphics such as in the case of graphical user interfaces lossless image compression that did not change the image data was chosen for the gif format as the available techniques were relatively simple and could operate easily on existing hardware it also best matched the intended application of sharp edged line art based graphics that used a limited number of colors such as logos and gui elements at the time most early image formats that used compression relied on a simple technique known as run length encoding or rle this lossless technique stored image data as a color definition paired with a count this allowed long runs of similar pixels to be compressed into one data element and it proved to be most efficient on image data that contained simple graphics such as with icons in line drawings however run length and coding would have the opposite effect on images that lack long runs of color because of the overhead of the counting mechanism more memory is required than the original image in such cases making the technique unusable for more complex images wilheid had concluded that run length encoding was not an effective solution and looked towards a new class of data compression algorithms developed in the late 1970s by jacob ziv and abraham limpell collectively referred to as lz-77 and lz-78 the latter would be further developed in 1983 by terry welch into a faster variant known as the lampel ziv welch or lzw method lzw compression works by using a dictionary to index a series of symbol sequences that are found within a given set of data this dictionary also contains every possible individual symbol used within the data and from this the compressed output is created entirely from dictionary index references that can represent both single symbols and recurring symbol sequences reducing the overall memory required to store the original data a key characteristic of lzw is that the dictionary is neither stored or transmitted but rather developed within the algorithm as the source data is encoded or compressed data decoded in the encoding process an initial code width size is established for the encoded data because a lzw code word is a dictionary index reference its chosen bit width determines the dictionary size before encoding the dictionaries initialized with the values of every individual symbol used within the source data an 8-bit based data source for example would require the first 256 dictionary indexes to be mapped to each possible 8-bit word value this inherently also requires the code width size to be larger than the bit width size of the source data typically a 12-bit wide code word is considered the largest practical size for the process the algorithm begins with first reading the first value from the source data stream and placing it in an index buffer the algorithm's loop point begins with the next value from the source data stream being read and temporarily appended to the contents of the index buffer this temporary value sequence is now searched for within the dictionary if it's found this temporary value sequence now becomes the contents of the index buffer if the temporary value sequence isn't found within the dictionary it is added to the dictionary at the next available index slot the contents of the index buffer is then found within the dictionary and its index is sent as a code word to the output code stream the index buffer is then set to the value that was read from the source data stream from here if more data is available in the source data stream the algorithm returns to its loop point if there's no data left to encode the contents of the remaining index buffers found within the dictionary and its index code word sent to the output code stream completing the final encoding decoding in lzw code stream is equally as simple to implement a dictionary table matched to the bit width specification of the encoded data is first initialized in a manner similar to the encoding process because the encoding process always starts with a single value the first code word read from the input code stream always references a single value within the dictionary which is subsequently sent to the decoded output data stream at this point the decoding algorithm loop begins with the reading of the next code word from the input codeword stream the code is then checked against the dictionary to determine if it's mapped to a value sequence if one is found or the code word represents a single value the referenced values are sent to the decoded output data stream the previously decoded codewords value sequence is then combined with the first value of the current codeword's value sequence and added to the next available index slot in the dictionary if the red code word isn't defined in the dictionary then the previously decoded codeword's value sequence is then combined with the first value of its value sequence and the resultant combination is both added to the next available index slot in the dictionary and outputted to the output data stream in the gif specification the efficiency of lcw compression is further enhanced by the use of flexible code sizes in a gif file two additional code words are defined for signaling a reset of the working dictionary and the end of the image data this requires the bit width of a code word to be at minimum one bit larger than that of the image data a gif file can use dictionaries as large as 12 bits in depth however using 12 bits for every code word especially at the beginning of the encoding process wastes coding bits by allowing the bit width of a code word to vary unused bits can be eliminated this is accomplished by starting the encoding process with the assumption that the bit width of a code word will be one bit larger than the image data's bit depth this is the minimum needed to index every possible value of the image data plus the control codes within the encoding loop as the dictionary grows beyond the limits of the current codeword capacity another bit is added to the code word bit width to accommodate this expansion this is done until a maximum width of 12 bits is reached and the dictionary is full at which point a clear code is used to reset the dictionary resetting the encoding for the remaining data when the codes are decoded the same bit width expansion rule must be followed to match the encoding process the starting code word bit width used by the encoder is defined within the image data of the jiffa the gif specification was not only exceptionally memory efficient for its time but it also possessed the capability of encapsulating multiple images within a single file wilight's team had originally envisioned the format to be structured as a single canvas in which each image contained within the file would be attached to a logical image montage within the format structure the canvas size is defined globally along with an optional global color palette each image is contained within a segment block that defines its size location on the canvas an optional local color palette and the lcw encoded image data along with its starting code word bit width size each image can either use its own local color palette or the global color palette allowing for the use of far more simultaneous colors than a single 8-bit palette would allow the lcw encoded data within the image blocks are packaged into linked data sub-blocks of 256 bytes or less this allows for decoding to begin before the contents of the entire file is available beyond image data the standard also contains a mechanism known as an extension block extension blocks are a memory structure that allow for the addition of features in future versions of the gif specification these blocks look similar in structure to image data containing a definition element followed by linked data sub-blocks extension blocks have no direct overlap with image data blocks and it was possible to produce an image without them allowing for backwards compatibility of the format as it evolved the original version of the gif specification 87a was introduced by compuserve on june 15th 1987. it was such a success on their platform that two years later an enhanced version would be released call 89a several new features would be incorporated as extension blocks including the ability to store application specific metadata support for text caption overlays and embedded comments while most of these enhancements would see little use one feature in particular the graphic control extension would transform the image format by adding support for transparency and animation capabilities the graphic control extension allowed for the designation of one of the palette references as a transparent background color effectively making that pixel invisible this permitted images like logos and interface graphics to be easily overlaid over existing on-screen graphics the graphic control extension also took advantage of the format's ability to store multiple images with the introduction of basic animation through the inclusion of a delay time value and a disposal method bit field the delay time specified a screen hold time in hundredths of a second for the image block that immediately followed the graphic control extension block this was used in conjunction with the disposal method bit field which specified how the image was removed after the delay in 1995 full animation loops would be solidified as part of gif files with the introduction of netscape's gif application extension block this extension added the ability to control the animation loops and the popularity of its use grew directly from its support by netscape navigator 2.0 the first commercial web browser upon its release compuserve had provided conversion utilities for ibm's macintosh twos atari st's amigas commodore 64's and apple ii gs's this encouraged the rapid adoption of the format and with netscape support ultimately led to it becoming the dominant image standard of the early internet however despite its success give had a fatal flaw that would become the downfall of the format the lzw algorithm that powered the format was under patent since 1983 and had its ownership transferred to a company called unisys corp in 1986. compuserve had been unaware of the patent until 1993 when unisys would affirm its ownership and enter into a licensing agreement with compuserve by december of 1994 unisys announced they would be charging a 0.45 royalty on software that used the algorithm including several formats such as tiff and pdf but most notable jif while unisys only targeted large companies to buy licenses developers still felt that the patent was a threat this would directly lead to the development of the portable network graphics format in 1995. ping was intended as a replacement for gif that avoided lzw compression altogether it had the advantage of offering better compression and color capacity over jif as well as true transparency support though it took till the turn of the century for it to supersede gif's dominance on the internet by 2004 unisys patent would expire globally though by then gif images were largely phased out especially since other file formats were more effective when it came to static images the advent of browser scripting and streaming video also largely replaced its functional motion graphic capabilities however there was one void that no other technology had fulfilled even long after gifs fading from the internet the short efficient continuous soundless loops of animated gifs could convey nuanced emotions in ways that no other format could several projects have even quantified the emotions felt from large pools of animated gifs with some of the more popular animations being unmatched in their accuracy of emotional intent unlike most other technologies gif created its own need instead of fulfilling an existing one by the 2010s jeff had re-emerged on the internet as the de facto format for emotional queuing its newfound popularity would be fueled by several search engines such as giphy and tenor that explicitly tied them to emotional intent gifts are also protected from copyright claims by fair use doctrine which protects copying material for limited and transformative purposes in may 2015 facebook began to support animated gifs with most other messaging services including mobile-based platforms following suit within a year by 2019 search engine giphy had estimated that over 10 billion gifs are served up daily the clever image format designed to transmit simple graphics over slow modem speeds in the 1980s has now transformed itself into a contemporary cultural icon [Music] the lcw algorithm found within gif is one of a handful of compression techniques that directly shaped how we share information from simple and efficient data encoding methods to the massive and bewildering systems that power search engines algorithms run our world with brilliant building and understanding of the structure and processes of algorithm design has never been easier brilliant is my go-to tool for diving head first into learning a new concept it's a website and app built off the principle of active problem solving because to truly learn something it takes more than just watching it you have to experience it with this in mind brilliant has been tirelessly revamping their courses to introduce even more interactivity and with their recently updated algorithm fundamentals course you can expect intuitive and interactive examples that allow you to make sense of these abstract concepts with brilliant you learn in depth and at your own pace it's not about memorizing or regurgitating facts you simply pick a course you're interested in and get started if you feel stuck or make a mistake an explanation is always available to help you through the learning process if you'd like to try out brilliant and start learning stem for free click the link in the description below or visit brilliant.org forward slash new mind and the first 200 of you will get 20 off and annual premium subscription you