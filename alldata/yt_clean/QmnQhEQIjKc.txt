Al Jazeera Podcasts. Today, blowing the whistle on Facebook and Instagram when it comes to Palestine. I think my conscience doesn't allow me to sleep without trying to do something about it. How alleged censorship at parent company Meta might be shaping our perception of the war in Gaza. I'm Malika Bilal, and this is The Take. Meta is today's modern-day town square, and it is clear that Meta is censoring Palestine. Saima Akhter is a former Meta employee. She was there for three years She talked to us outside of Meta's New York offices, Meta retains far too much unchecked power in controlling public perception by deciding what is and isn't allowed to be shared and deciding who is and isn't allowed a platform Saima says she herself experienced this censorship, especially in the months following October 7. Any time she or her colleagues posted about Palestine on internal platforms, the posts were deleted. I had a colleague who upon hearing that one of our colleagues in Gaza and offered condolences to him in our Muslim ERG, employee resource group, and the post was taken down. When I posted about having watermelon cupcakes at the Muslim booth at our community fair, and I was told I cannot have watermelon cupcakes Saima says when she posted news articles about public concerns about the censorship of Palestine on Facebook and Instagram, I couldn't sleep while I was working there. I just -- it was just sleepless nights where I felt the weight and the burden of what Meta was doing on our platforms. So in December, I helped write a letter that was addressed to Meta leaders. The letter, circulated and signed by 450 employees in a single day, including allegations of censorship and an unsafe environment for Palestinian employees. Meta responded by deactivating my system access, putting me under investigation for two months, and they deleted the letter and even went into to delete any copies of the letter, Saima was suspended but was eventually allowed to come back, where she continued her Palestine advocacy. She was ultimately fired in June, when the company found out she'd made a copy of another document employees were working on about bias and discrimination related to Palestine at Meta. She's one of a number of current and former employees for a new AJ+ documentary called Inside Meta's Palestine Censorship. We put these claims made by Saima and other employees to the company, and a Meta spokesperson replied saying, 'Our goal is to foster a company culture around mutual respect and inclusivity where everyone can do their best work.' My name is Dena Takruri. I'm a senior presenter at AJ+. I host the documentary show Direct From. Well Dina, it's really good to have you on The Take. Since October 7, we have heard many users publicly accusing Meta of suppressing pro-Palestine content, and that is from shadow bans to blocked accounts to more. But your documentary shows that those complaints were coming from inside Meta as well. So you talked to Saima as well as a number of other former and current Meta employees for this documentary. What did they tell you about what they saw happening? Similar to the users that have all witnessed this shadow this was something that was really pronounced inside of Meta. You know, and I just want to point out before that even, it's not just something that users experience this has been well-documented by Human Rights Human Rights Watch came out with a report in December of 2023 calling Meta's censorship of Palestine content "systemic and global." So for employees within Meta, they're getting, you know, tons of messages from people they know being like, what's happening? My posts are getting taken down. I can't go live anymore on Instagram. Things are being censored, things are being shadow banned. Instagram is taking down my stories. That post was removed. Shadow bans. This is censorship at its finest. So can you give me some examples of what people were saying was happening? Sure. You know, our documentary starts out with a conversation I had. It was an exclusive interview with a former software engineer at Meta who's Palestinian American. We call him Omar to protect his identity, One of the things that he was tasked to do by Meta in October of 2023 was to assess the quality of integrity filters as they related to Israel, Gaza and Ukraine. So his job was to look into things. In late 2023, so in December, about two months or more into this genocide, he was looking into these severe issues impacting many users from Palestine whose accounts were being suppressed, A bunch of accounts were basically disappearing from search. Their content wasn't showing up in recommendations. We just got a lot of reports, both internally and externally. And in looking into this, young photojournalist out of Gaza who had at that point amassed more than 17 million followers. Perhaps your audience is familiar with Motaz Azaiza. I'm at the gate of Gaza City. Behind me, He found that many of his posts were being marked for containing sexual activity or nudity, which was flagged internally as pornographic. These were posts depicting the devastation in Gaza. In some cases, they were destroyed buildings. In other cases, they were images of injured or dead children. This deeply affected Omar. Some of them were difficult to look at, Marking images and videos of injured and dead children as pornographic, you know, I find deeply offensive. He followed the typical protocol But as he was doing so, he noticed that You know, he noticed that tickets were being opened and marked 'mitigated,' 'resolved' and 'closed' with the same timestamp, indicating that people were dismissing issues It struck me as very odd. Unprofessional. I've never seen that in any company that I worked at. And in addition to that, he was receiving messages outside of the chat from people saying like, hey, stop looking into this, or hey, like, Omar said there were thousands of such cases What eventually happens is that Omar gets, pulled into a meeting by an employment investigator, basically HR, And the question basically came to: Do you have a personal He's never met the guy. He's never communicated with him. He's never messaged him. He's not from Gaza. There's no way. And at this point, Motaz was on the cover of magazines and stuff. He felt that that was a racist question just because they're both Palestinian. He eventually complains to HR and shortly after is fired. They fired him just a few days before his stocks And, you know, just before he was due to be paid out for his performance review, Meta declined to comment directly on Omar's case, spokesperson had said that Omar violated data access policies, and those are rules on how employees can use company data. The implication there was that he was looking into Marcus Azaiza's account But we interviewed Motaz and asked him point blank, Have you ever talked to this guy? He said no. They fired him just because he was doing his job. It's their way. It's a war against our existence. So Omar was fired. As we heard earlier from Saima, she was also fired. How reflective are stories like theirs of the company's approach to dealing with those who've raised concerns within Meta about how pro-Palestine posts are dealt with or those who've been advocating for Palestine? What did you find? I think they're pretty reflective. There's definitely this sense among people the company put a target on their back. In some cases, employees are terminated, like Saima and like Omar. In other cases, they are, you know, punished in certain ways. Like, for example, Meta workers have this internal platform called Workplace, which you can basically think of as corporate Facebook. And the company has gotten very strict They have a policy they unrolled in 2022 which is called CEE, that stands for Community Engagement Expectations. The goal is to stop disruptive conversations in the workplace But what ended up happening is that it is so over-enforced that if anyone just tried to post condolences for their colleagues who lost relatives in Gaza, we were shown dozens of these posts. if they tried to post innocuous things about Palestinian culture or dance or olive trees, those posts would be taken down. So not only are these posts being removed, CEE violations could result in your performance reviews being affected and bonus payouts And yet, one of the points you raised earlier and what he was seeing in his actual job, he wasn't seeing that same kind of censorship with posts related to, say, the war in Ukraine, Russia's involvement, any of that. Yeah, absolutely. We definitely uncovered a glaring double standard and how Meta adjusts its policies during other global events. So Meta employs something that it calls a newsworthiness allowance, which means it'll, you know, change its policies if if they deem it important to the public interest. So when Russia invaded Ukraine in 2022, Meta relaxed some of its policies to post, to protect their free speech. So that even resulted in, you know, them being allowed to call for violence against Russia or death to Vladimir Putin. And in one case, temporarily, they delisted a Ukrainian neo-Nazi group from their list of banned accounts because they were seen to be, you know, freedom fighters Now, do you think, Malika, that when it came to Palestine or let's say Hamas or the Israeli invasion of Gaza, Definitely not. No. In fact, in some cases, After October 7, after the Hamas-led attacks on Israel, Meta cranked up its automated content filters But they applied the strictest filters, specifically out of Palestine, so they made it even harder for Palestinians to post. So who is influencing Meta's policies on Israel and Palestine? That's after the break. So I know that you put these allegations to Meta of targeting employees for their pro-Palestine advocacy, of over-enforcing these policies when it comes to content about or from Palestine, of double standards in general. What did they say? How did they respond? For the most part, the responses that we got from When it came to allegations made by Saima and others that, you know, they couldn't speak out freely. They repeated, "Our goal is to foster a company culture of mutual respect and inclusivity." When we asked them about Omar's case, they declined to comment, presumably because it's pending litigation. What we found most interesting is what they did not comment on. So one of the things we raised to them were really hurt by the fact that after October 7, senior leadership sent their condolences to Israeli employees and made that clear and posted about it internally and publicly. But when it came to Palestinian employees, many of whom lost multiple family members in the war on Gaza, there was no such messaging When we raised that to them, that they failed to fully acknowledge the grief of their Palestinian employees, Oh, wow. And this is something too, Malika, that really affected the morale of so many of the Meta workers that we spoke to. I mean, they were witnessing their colleagues just falling apart, losing multiple family members in Gaza. And even if you just wanted to post internally sympathy or condolences, you were not allowed to. And, you know, as for example, we talked to Ramzi, who's a Palestinian American data analyst. It's been really difficult. I've been challenged, like, depressed and anxious, like, debating, like, what is this company I've come to? And he told me that 'Tomorrow is my last day at Meta, I just can't take it anymore.' Dina, we've talked about the experiences of employees inside Meta, where these policies And what did you find? We found that there are a lot of senior leaders in Meta who have ties to Israel or Israeli causes. So, I spoke to a tech expert named Paul Biggar who really helped map this out for me. He told me that one of the most senior guys at Meta is somebody named Guy Rosen. Guy Rosen is the company's chief information security officer. And prior to that, he was the vice president content moderation tools. But before all of that, he served in the Israeli military's elite Unit 8200. That's the secretive cyber intelligence group Unit 8200's operators are always watching, but at a distance from those they target, from the consequences of the work they do. But surveillance and intimidation of Palestinians is often more personal. In our own analysis of LinkedIn data, we found dozens of other current Meta employees who once served in Unit 8200 as well, and even more who had previously worked at Meta So that's just the military side. We also found Meta employees Jordana Cutler is the company's public policy director for Israel and the Jewish diaspora. That's a position, by the way, Jordana Cutler was previously an advisor to Israeli Before that, she worked at the Israeli embassy in Washington, DC. And she gave an interview, in 2020, I believe, to an Israeli outlet. Inside the company, part of my job is to be a representative voice of the government for their concerns. I have an opportunity to really influence And, you know, there are other senior figures with Israeli ties that we detail in the documentary. But the one last thing I would point out called the Israeli Cyber Unit that was established in 2015. The Israeli Cyber Unit's goal is to petition to remove content that they say incites violence or promotes terrorism. And in many cases, these companies comply and remove an overwhelming majority of that content. And most of the requests do, in fact, go to Meta. And I think that's concerning that social media companies are moderating their content And the implications of that, I think, are troubling. You detailed some of the names that are in leadership positions, and I'm wondering how far up this goes. What about Mark Zuckerberg? What we discovered about Mark Zuckerberg he gave a donation of $125,000 to ZAKA. ZAKA is the Israeli search and rescue organization that was responsible for perpetuating the infamous beheaded baby fraud. We also, you know, when we want to talk about the faces of the company, Sheryl Sandberg, longtime former COO, she's no longer at the company, but she was on the board of Meta. She recently affronted a documentary that claims that there was a mass campaign of sexual assault on Israeli women on October 7. This is a claim that continues to have little evidence behind it, but it definitely has been used to drum up support for and justify Israel's assault on Gaza. And what someone like Paul Biggar, the tech expert you know, the influence of Sheryl Sandberg throughout the company in terms of who's employed, Why is what happens at a place like Meta important for the public to know about? Because at first glance, it can seem like a niche concern for people, But are there consequences to what's happening behind the scenes at a company like Meta that impact policy or public perception Yeah, I think it's very important is the primary method through And when we're talking about Gaza specifically, since the war started, has banned foreign journalists So, you know, people are depending on journalists, and others to be the eyes and ears and to uncover the truth Meta is the biggest social media company in the world, so it has a real impact on how people understand what's happening. I think the stakes are really high, Gaza is being suppressed and censored, that's contributing to the cover up of this genocide. When a video or when images get taken down that reduces the visibility, it reduces outrage. It prevents people from fully being able to mobilize, So I think the implications are incredibly serious and alarming. And that's The Take. Have any of your Palestine-related posts been censored on Facebook or Instagram? Let us know in the comments below. Also, if you want to catch more episodes like this, That's where you'll find all of our recent content, And while you're at it, hit that subscribe button See you tomorrow.