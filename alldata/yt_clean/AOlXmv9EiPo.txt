It's hard to believe that just over 5-years-ago, looking to hodge-podge a fix together, such that to plummet. High TDP Intel chips paired with that created the worst Macs in decades--but Apple silicon was a revelation to form factor. Not only did they *keep* things literal identical MacBook Air chassis just but we don't even need a fan. Oh, and by at all but it lasts 50% longer than before. The redesign of the MacBook Pro and M2 MacBook keyboard-sporting laptops of yore bringing speakers, keyboards, and more. Meanwhile, the M1 too small for this master-class in efficiency. computer lineup is not just Apple's best ever, *any* company. But be warned, because changes continue being true into the future. Let's to the almost physics-defying standards the M1 real competition is just months away I've talked a lot about why Apple silicon but there were really three main drivers behind significantly more modern (ISAs) instruction set of x86--nerdy crap like weakly-ordered memory registers for parallelizable code, etc., (2) video engines, Neural Engine, matrix coprocessor, vastly more capably than a general-compute from hardware to kernel to OS to application All of the work had to be paved for M1. but they've been iterative--and Apple is now else is: transistor density. M1 launched and 2000s when transistor density and node process names today like "5nm" don't really mean and hardly any of those features precisely measure the M1--not to even mention the M1 Max--was a an 5nm chip to date, but one of the largest Arm to get a faster chip like M2? There's really consumption of the transistors so you can add the transistor size the same but increase the greater heat and power drain, or, (3) keep the the voltage to push up the chip's clock-speed M2 did a combination of options 1 and 2. They which netted both a 7% performance improvement and then to speed things up even more, they from 16 billion to 20 billion. But this "not really the full story" napkin math, and the than M1--running hotter and drawing more energy that's not theoretical: we proved back when the difficult to keep cool and experienced more due to those thermals. So why wasn't this more per watt increased as well--not just total package car. The car runs hotter and consumes more fuel however, because it's so fast and efficient, it car, reducing the total time it is running at while yes, the M2 consumed more total energy get tasks done more quickly--reducing time spent consumption per task relative to M1. Sounds When M3 launched on TSMC's N3E 3nm process, expectations from pundits were high. I mean, doing transistor density--HUGE performance gains! But jump than we did from M1 to M2--and those on the lesson - using napkins for calculations can be as TSMC's 3nm node uses transistors that are closer to 3.5. Okayyy, but even that would the logic density comes close at 1.7x. all. And chips--even magical ones--contain there's only about a 1.3x shrink. The era of to the next are over. The shrinks themselves are is orders of magnitude more expensive than the cost on these N3E chips is greater--not lesser--than that would not yield the same expect from Apple. More transistors on a We've spent several minutes getting really that normal people don't care about--and the vast majority of Apple's products. Sure, expected and the jump from M3 to M4 will likely heretical for a minute? That's OK! The silicon Look, Qualcomm invited me out to San Diego reference design laptops (which basically for the Snapdragon X Elite SoC. You we bought Microsoft's Arm-based Windows chip (which was just a rebranded Snapdragon low-performance Windows laptops. No offense to sucked. Its performance under ideal conditions come by because so much of the Windows experience following the original release of Windows RT. has every single native app for Windows made of 3rd party apps have too--including big ones--like and OpenGL are said to work through mapping huge efforts to ensure a smooth transition--they this than anyone and they hope to be compared to So, what is the Snapdragon X Elite? Well, they card. It is a bespoke laptop chip--not based on with a 12 high-performance core CPU, Adreno the on-board sensing hub houses an additional ISP, be paired with up to 64GB of LPDDR5 memory, over PCIe. The specs suggest Qualcomm is not it consistently placed itself in between Apple is still certainly going to have the but this doesn't aim to compete with those. While extra performance boost, its reference-design Now do I think that Qualcomm's going to come out 3-years? Not really, no. But they're hungry, alluded to the fact that using heavy-duty GPUs the future--something Apple has zero and everybody else, they're really leaning into hardware for maximum efficiency and speed. the Snapdragon X Elite embodies given its massive power-hungry beasts. Layer in the fact that this and that higher-performance chips are on the So what's Apple to do? Rush TSMC to the next more consumptive chips in the name of speed? competency. Apple Silicon has always been about but physics are a cruel mistress and many already pushing up against boundaries that didn't Apple silicon laptops are dead silent and this YouTube channel on a 14" M3 Max MacBook the time--not just when exporting. And even with out even close to the time the 16" MacBook throttle to the point that it's no faster than slower than an M1 Max Mac Studio--something that My point here is that for years, Apple had computer makers. The silicon was never when that formula got flipped on its head and be braggadocios about their computer's speed. But others are catching up--so lets sit the silicon hardware design. As I see it, the entire the Air has a lower-quality display and worse Air is cheaper than the 16" Pro, but I mean size, footprint, weight, and feature-set than advantage of the form-factor provided by Apple a laptop even thinner, smaller, and lighter than impossible today--nearly a decade after its hamstrung by a crappy low-TDP Intel chip and lousy how many people own--heck--a base M1 MacBook Air chip? I'd venture to say MOST--and if your silicon On the other end of the spectrum, why not bit on the hefty-side--the style that gamers and A chip that just absolutely screams when but while maintaining the excellent idle cores. It could be the first "gaming" laptop What I'm getting at is this - when it was a bold, risky move. It paid off massively. greatest computers ever. But it also feels like and I think its time they stop sitting on the rest of the industry catches up. What do but most importantly--and as always--stay snazzy.