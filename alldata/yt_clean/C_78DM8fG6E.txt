We started OpenAI seven years ago because we felt like something and we wanted to help steer it It's honestly just really amazing to see how far this whole field And it's really gratifying to hear who are using the technology for so many wonderful things. We hear from people who are excited, we hear from people who are concerned, we hear from people who feel And honestly, that's how we feel. Above all, it feels like we're entering where we as a world that will be so important And I believe that we can So today, I want to show you and some of the underlying So the first thing I'm going to show you is what it's like to build rather than building it for a human. So we have a new DALL-E model, and we are exposing it as an app And you can do things like ask, you know, suggest a nice post-TED meal (Laughter) Now you get all of the, sort of, and taking care of the details for you And here we go, it's not just but a very, very detailed spread. So let's see what we're going to get. But ChatGPT doesn't just generate sorry, it doesn't generate text, And that is something of what it can do on your behalf And I'll point out, This is all generated So I actually don't even know This looks wonderful. (Applause) I'm getting hungry just looking at it. Now we've extended ChatGPT for example, memory. You can say &quot;save this for later.&quot; And the interesting thing is they're very inspectable. So you get this little pop up here And by the way, this is coming to you, all And you can look under the hood was write a prompt And so you sort of have how the machine is using these tools, which allows us to provide Now it's saved for later, and let me show you and to integrate You can say, "Now make a shopping list I was suggesting earlier." And make it a little tricky for the AI. &quot;And tweet it out for all (Laughter) So if you do make this wonderful, I definitely want to know how it tastes. But you can see that ChatGPT without me having to tell it explicitly And this, I think, shows a new way Like, we are so used to thinking of, we click between them, and usually it's a great as long as you kind of know Yes, I would like you to. Yes, please. Always good to be polite. (Laughter) And by having this unified the AI is able to sort of take away So you don't have to be the one who spells out every single of what's supposed to happen. And as I said, this is a live demo, so sometimes the unexpected But let's take a look at the Instacart And you can see we sent a list Here's everything you need. And the thing that's really interesting is that the traditional UI If you look at this, you still can click through it And that's something that I think shows that they're not going away, It's just we have a new, And now we have a tweet which is also a very important thing. We can click "run," and there we are, we're able to change the work And so after this talk, And there we go. Cool. Thank you, everyone. (Applause) So we'll cut back to the slides. Now, the important thing it's not just about building these tools. It's about teaching Like, what do we even want it to do when we ask these very And to do this, we use an old idea. If you go back to Alan Turing's 1950 paper you'll never program an answer to this. Instead, you can learn it. You could build a machine, and then teach it through feedback. Have a human teacher who provides as it tries things out and does things And this is exactly how we train ChatGPT. It's a two-step process. First, we produce what Turing through an unsupervised learning process. We just show it the whole world, and say, "Predict what comes next And this process imbues it For example, if you're shown the only way to actually to say what comes next, that green nine up there, is to actually solve the math problem. But we actually have to do which is to teach the AI And for this, we provide feedback. We have the AI try out multiple things, and then a human rates them, says And this reinforces not just the specific but very importantly, the whole process And this allows it to generalize. It allows it to teach, and apply it in scenarios that it hasn't received feedback. Now, sometimes the things are not what you'd expect. For example, when we first showed they said, &quot;Wow, this is so great, We're going to be able to teach Only one problem, it doesn't If there's some bad math in there, it will happily pretend that one plus one So we had to collect some feedback data. Sal Khan himself was very kind and offered 20 hours of his own time alongside our team. And over the course of a couple of months &quot;Hey, you really should in this specific kind of scenario.&quot; And we've actually made lots and lots And when you push that actually is kind of like sending up "Here's an area of weakness And so when you do that, that's one way that we really and make sure we're building something Now, providing high-quality If you think about asking a kid if all you're doing you don't know if you're just teaching This is a nice DALL-E-generated And the same sort As we move to harder tasks, we will have to scale our ability But for this, the AI itself It's happy to help us provide and to scale our ability to supervise And let me show you what I mean. For example, you can ask GPT-4 of how much time passed on unsupervised learning and learning from human feedback. And the model says two months passed. But is it true? Like, these models although they're getting better But we can actually use And it can actually check its own work. You can say, fact-check this for me. Now, in this case, I've actually This one is a browsing tool where the model can issue search queries And it actually writes out It says, I'm just going to search for this It then it finds the publication date It then is issuing another search query. It's going to click into the blog post. And all of this you could do, It's not a thing It's much more fun to be in this manager's position triple-check the work. And out come citations so you can actually go and very easily verify any piece And it actually turns out Two months and one week, that was correct. (Applause) And we'll cut back to the side. And so thing that's so interesting to me is that it's this many-step collaboration Because a human, using is doing it in order to produce data for another AI to become And I think this really shows that we should expect to be where we have humans and delicately designed and how we want We make sure that the humans are providing the feedback, and the machines are operating and trustworthy. And together we're able to actually create And I think that over time, we will be able to solve And to give you a sense I think we're going to be able of how we interact with computers. For example, think about spreadsheets. They've been around in some form since, I don't think they've really And here is a specific spreadsheet for the past 30 years. There's about 167,000 of them. And you can see there the data right here. But let me show you the ChatGPT take So we can give ChatGPT this one a Python interpreter, so it's able to run code, And so you can just and ask questions about it. And very helpfully, you know, it knows &quot;Oh, this is CSV,&quot; &quot;I'll parse it for you.&quot; The only information here the column names like you saw And from that it's able to infer Like, that semantic information It has to sort of, put together "Oh yeah, arXiv is a site and therefore that's what these things are and so therefore it's a number like all of that, that's work and the AI is happy to help with it. Now I don't even know what I want to ask. So fortunately, you can ask the machine, &quot;Can you make some exploratory graphs?&quot; And once again, this is a super high-level But I don't even know what I want. And the AI kind of has to infer And so it comes up So a histogram of the number time series of papers per year, All of that, I think, And the great thing is, Here we go, a nice bell curve. You see that three It's going to then make this nice plot Something crazy Looks like we were on an exponential What could be going on there? By the way, all this And then we'll see word cloud. So you can see all these wonderful things But I'm pretty unhappy It makes this year look really bad. Of course, the problem is So I'm going to push back on the machine. [Waitttt that's not fair!!! 2023 isn't over. What percentage of papers in 2022 So April 13 was the cut-off Can you use that to make So we'll see, this is (Laughter) So you know, again, I feel like there was more I wanted I really wanted it to notice this thing, maybe it's a little bit to have sort of, inferred magically But I inject my intent, I provide this additional piece And under the hood, the AI is just writing code again, it's very possible. And now, it does the correct projection. (Applause) If you noticed, it even updates the title. I didn't ask for that, Now we'll cut back to the slide again. This slide shows a parable A vision of how we may end up A person brought and the veterinarian made a bad call And the dog would not In the meanwhile, like, the full medical records, to GPT-4, which said, &quot;I am not a vet, here are some hypotheses.&quot; He brought that information who used it to save the dog's life. Now, these systems, they're not perfect. You cannot overly rely on them. But this story, I think, shows that a human with a medical professional and with ChatGPT was able to achieve an outcome I think this is something think about as we consider into our world. And one thing I believe really deeply, is that getting AI right is going And that's for deciding that's for setting the rules of the road, for what an AI will and won't do. And if there's one thing it's that this technology Just different from anything And so we all have to become literate. And that's, honestly, one Together, I believe that we can of ensuring that artificial benefits all of humanity. Thank you. (Applause) (Applause ends) Chris Anderson: Greg. Wow. I mean ... I suspect that within every mind out here there's a feeling of reeling. Like, I suspect that a very large you look at that and you think, pretty much every single thing Like, there's just Am I right? Who thinks that they're having to rethink Yeah, I mean, it's amazing, but it's also really scary. So let's talk, Greg, let's talk. I mean, I guess how the hell have you done this? (Laughter) OpenAI has a few hundred employees. Google has thousands of employees Why is it you who's come up that shocked the world? Greg Brockman: I mean, the truth is, we're all building on shoulders If you look at the compute progress, the algorithmic progress, all of those are really industry-wide. But I think within OpenAI, we made a lot of very deliberate And the first one was just And that we just thought What is it going to take We tried a lot of things that didn't work, And I think that the most important thing who are very different from each other CA: Can we have the water, I think we're going to need it, But isn't there something also that you saw something that meant that if you continue that something GB: Yes. And I think that, I mean, honestly, I think the story there I think that high level, deep learning, like we always knew that was was a deep learning lab, I think that in the early days, We tried a lot of things, and one person was working to predict the next character and he got a result where -- you expect, you know, the model where the nouns and verbs are. But he actually got a state-of-the-art This model could tell you I mean, today we are just like, But this was the first time this sort of semantics that emerged And there we knew, you've got to see where it goes. CA: So I think this helps explain the riddle that baffles because these things are described And yet, what we're seeing it just feels impossible that that Just the stuff you showed us just now. And the key idea of emergence suddenly different things emerge. It happens all the time, ant colonies, when you bring enough of them together, you get these ant colonies that show Or a city where a few houses together, But as you grow the number of houses, things emerge, like suburbs Give me one moment for you that just blew your mind that you just did not see coming. GB: Yeah, well, so you can try this in ChatGPT, CA: 40-digit? GB: 40-digit numbers, which means it's really learned And the really interesting if you have it add like a 40-digit number it'll often get it wrong. And so you can see that it's really but it hasn't fully generalized, right? It's like you can't memorize that's more atoms So it had to have learned but that it hasn't really Oh, I can sort of generalize this of arbitrary lengths. CA: So what's happened here is that you've allowed it to scale up and look at an incredible And it is learning things that you didn't know that it was GB Well, yeah, and it's more nuanced, too. So one science that we're starting is predicting some of these And to do that actually, one of the things I think is sort of engineering quality. Like, we had to rebuild our entire stack. When you think about building a rocket, every tolerance has to be incredibly tiny. Same is true in machine learning. You have to get every single piece and then you can start There are all these incredibly They tell you something deeply If you look at our GPT-4 blog post, you can see all of these curves in there. And now we're starting So we were able to predict, for example, We basically look at some models that are 10,000 times And so there's something about this even though it's still early days. CA: So here is, one of the big fears then, that arises from this. If it's fundamental that as you scale up, things emerge that you can maybe predict but it's capable of surprising you. Why isn't there just a huge risk GB: Well, I think all of these and scale and timing. And I think one thing people miss, too, is sort of the integration with the world sort of, very powerful thing too. And so that's one of the reasons to deploy incrementally. And so I think that what we kind of see a lot of what I focus on is providing Today, the tasks that we do, It's very easy to look at that math machine, seven was the correct answer. But even summarizing a book, Like, how do you know You have to read the whole book. No one wants to do that. (Laughter) And so I think that the important thing And that we say, OK, we have to supervise this task properly. We have to build up that they're able to actually And I think we're going to have to produce more reliable ways of scaling this, sort of like making the machine CA: So we're going to hear there are critics who say that, you know, there's no real the system is going to always -- we're never going to know that it doesn't have Is it your belief, Greg, but that the expansion of the scale that you talked about is basically of actually getting to things with a high degree of confidence. Can you be sure of that? GB: Yeah, well, I think that the OpenAI, I believe that is where we're headed. And I think that the OpenAI approach let reality hit you in the face, right? It's like this field is the field of all these experts saying People have been saying neural nets They haven't been right yet. They might be right or something like that is what you need. But I think that our approach you've got to push to the limits to really see it in action, because that tells you then, oh, here's And we just haven't exhausted CA: I mean, it's quite that the right way to do this and then harness all this, you know, instead of just your team giving feedback, the world is now giving feedback. But ... If, you know, bad things it is out there. So, you know, the original story when you were founded as a nonprofit, well you were there as the great doing their unknown, And you were going to build models somehow held them accountable and was capable of slowing Or at least that's kind of what I heard. And yet, what's happened, That your release of GPT, sent such shockwaves that now Google and Meta and so forth And some of their criticisms have been, you are forcing us to put this out here You know, how do you, like, make the case that what you have done GB: Yeah, we think about these Like, seriously all the time. And I don't think we're always But one thing I think from the very beginning, about how to build actually have it benefit all of humanity, like, how are you And that default plan of being, you get this super powerful thing, and then you figure out the safety of it and you hope you got it right. I don't know how to execute that plan. Maybe someone else does. But for me, that was always terrifying, And so I think that this is the only other path that I see, which is that you do let And I think you do give people You do have, before these before they are super powerful, to see them in action. And we've seen it from GPT-3, right? GPT-3, we really were afraid that the number one thing was generate misinformation, Instead, the number one thing (Laughter) CA: So Viagra spam is bad, Here's a thought experiment for you. Suppose you're sitting in a room, there's a box on the table. You believe that in that box there's a very strong chance that's going to give beautiful gifts But there's actually also a one percent that says: "Pandora." And there's a chance that this actually could unleash Do you open that box? GB: Well, so, absolutely not. I think you don't do it that way. And honestly, like, I'll tell you a story which is that shortly I remember I was in Puerto Rico I'm sitting in the hotel room just all these people having a good time. And you think about it for a moment, if you could choose for basically to be five years away or 500 years away, which would you pick, right? On the one hand you're like, it's better to have it be five years away. But if it gets to be 500 years away which do you pick? And you know, I just I was like, of course My brother was in the military at the time and like, he puts his life on the line than any of us typing things in computers and developing this And so, yeah, I'm really sold But I don't think that's quite Like, if you look at the whole I really mean it when I say or even just almost like a human-development- And the more that you sort of, that are there, right, we're still making faster computers, we're still improving the algorithms, And if you don't put them together, which means that if someone does, or the moment that someone does manage then you suddenly have no one's had any time to adjust, who knows what kind And so I think is like, even you think about development think about nuclear weapons, people talk about being sort of, change in what humans could do. But I actually think it's been quite smooth over time. And so the history, I think, has been, you've got and you've got to figure out for each moment that you're increasing it. CA: So what I'm hearing is that you ... the model you want us to have is that we have birthed that may have superpowers that take humanity to a whole new place. It is our collective responsibility for this child to collectively teach it to be wise Is that basically the model? GB: I think it's true. And I think it's also important We've got to take each step And I think it's incredibly that we all do get literate figure out how to provide the feedback, decide what we want from it. And my hope is that that will but it's so good we're honestly because we wouldn't otherwise CA: Greg Brockman, thank you so much (Applause)