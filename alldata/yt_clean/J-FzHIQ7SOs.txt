Hi, I'm Jeff. I lead AI Research and Health at Google. I joined Google more than 20 years ago, when we were all wedged above what's now a T-Mobile store I've seen a lot of computing and in the last decade, we've seen AI But we're still doing it That's what I want But first, let's talk So in the last decade, in how AI can help computers see, understand speech better than ever before. Things that we couldn't do If you think about computer vision alone, just in the last 10 years, computers have effectively 10 years ago, they couldn't see, You can imagine this has had on what we can do with computers. So let's look at a couple enabled by these capabilities. We can better predict flooding, using machine learning. We can translate over 100 languages and better predict and diagnose disease, where everyone gets So let's look at two key components that underlie the progress The first is neural networks, a breakthrough approach to solving that has really shone But they're not a new idea. And the second is computational power. It actually takes a lot to make neural networks and in the last 15 years, and that's partly what's enabled But at the same time, and that's what I want at the end of the talk. First, a bit of a history lesson. So for decades, almost since the very people have wanted that could see, understand language, The earliest approaches people were trying to hand-code that you need to accomplish and it just turned out But in the last 15 years, unexpectedly advanced all these different neural networks. So neural networks are not a new idea. They're kind of loosely based on some of the properties And many of the ideas have been around since the 1960s and 70s. A neural network is what it sounds like, a series of interconnected that loosely emulate the properties An individual neuron has a set of inputs, each with an associated weight, and the output of a neuron is a function of those inputs So pretty simple, and lots and lots of these work together So how do we actually learn It turns out the learning process consists of repeatedly making to the weight values, strengthening the influence weakening the influence of others. By driving the overall system these systems can be trained like translate detect what kind all kinds of complicated things. I first got interested in neural networks when I took a class on them At that time, neural networks showed but they really couldn't scale to do But I was super excited. (Laughter) I felt maybe we just needed And the University of Minnesota I thought, &quot;With more compute power, boy, we could really make So I decided to do a senior thesis the idea of using processors in a computer to all work toward the same task, that of training neural networks. 32 processors, wow, we've got to be able But I was wrong. Turns out we needed about a million times as we had in 1990 before we could actually get But starting around 2005, thanks to the computing progress we actually started to have and researchers in a few universities in using neural networks for a wide I and a few others at Google and we decided to start a project One system that we trained, we trained with 10 million from YouTube videos. The system developed the capability to recognize all kinds And it being YouTube, of course, it developed the ability YouTube is full of cats. (Laughter) But what made that so remarkable is that the system was never told So using just patterns in data, the system honed in on the concept All of this occurred at the beginning of using neural networks at Google and elsewhere. Many of the things you use every day, things like better speech improved understanding for better search quality, better understanding of geographic and so on. Around that time, we also got excited about how we could to the kinds of computations Neural network computations The first is they're very tolerant Couple of significant digits, And the second is that all the of different sequences So if you can build a computer that is really good at low-precision but can't do much else, that's going to be great even though you can't use it And if you build such things, This is the first one we built, TPU v1. &quot;TPU&quot; stands for Tensor Processing Unit. These have been used for many years for translation, in the DeepMind AlphaGo matches, so Lee Sedol and Ke Jie but they were competing And we've built a bunch that are even better and more exciting. But despite all these successes, I think we're still doing and I'll tell you about three and how we'll fix them. The first is that most are trained to do one thing, You train it for a particular task but it's a pretty heavyweight activity. You need to curate a data set, you need to decide for this problem, you need to initialize the weights apply lots of computation And at the end, if you're lucky, that is really good But if you do this over and over, you end up with thousands each perhaps very capable, but separate for all the different But think about how people learn. In the last year, many of us I've been honing my gardening skills, experimenting with vertical To do that, I didn't need to relearn I was able to know how to pour water, that plants need sun, and leverage that Computers can work If you train a neural it's effectively like forgetting every time you try to do something new. That's crazy, right? So instead, I think we can multitask models that can do Each part of that model would specialize And then, if we have a model and the thousand and first we can leverage in the related kinds of things so that we can more quickly be able just like you, if you're confronted you quickly identify that are going to be helpful Second problem is that most deal with only a single with images, or text or speech, but not all of these all at once. But think about how you You're continuously using all your senses to learn from, react to, figure out what actions Makes a lot more sense to do that, and we can build models in the same way. We can build models that take in text, images, speech, but then fuse them together, so that regardless of whether the model sees a video of a leopard the same response the concept of a leopard can deal with different even nonhuman inputs, 3D clouds of points, The third problem There's a single model, the model is fully activated for every example whether that's a really simple This, too, is unlike Different parts of our brains and we're continuously calling that are relevant for the task at hand. For example, nervously watching back up towards your car, the part of your brain that thinks is probably inactive. (Laughter) AI models can work the same way. Instead of a dense model, we can have one So for particular different tasks, During training, the model can also learn to continuously identify what parts in order to accomplish a new task. The advantage of this is we can have but it's very efficient, because we're only calling for any given task. So fixing these three things, I think, will lead to a more powerful AI system: instead of thousands of separate models, train a handful of general-purpose models that can do thousands Instead of dealing with single modalities, deal with all modalities, and be able to fuse them together. And instead of dense models, where we call upon the relevant We've been building a system and we've been calling So the idea is this model thousands or millions of different tasks, and then, we can incrementally and it can deal and then incrementally learn and call upon the relevant for different examples or tasks. And we're pretty excited about this, we think this is going in how we build AI systems. But I also wanted We clearly need to make sure benefits everyone. These kinds of models raise about how do we build them with fairness, interpretability, privacy and security, for all users in mind. For example, if we're going on thousands or millions of tasks, we'll need to be able to train them And we need to make sure that data and is representative of different all around the world. And data concerns are only We have a lot of work to do here. So in 2018, Google published by which we think about developing And these have helped guide us how we use AI in our products. And I think it's a really helpful for how to think about these deep about how we should We continue to update these Many of these kinds of principles super important area. Moving from single-purpose systems to these kinds of general-purpose that have a deeper will really enable us to tackle some of the greatest problems For example, we'll be able to diagnose more disease; we'll be able to engineer better medicines by infusing these models we'll be able to advance by providing more individualized tutoring to help people learn we'll be able to tackle like climate change, and perhaps engineering So really, all of these kinds of systems are going to be requiring of people all over the world. So connecting AI in order to make progress. So I've seen a lot and how computing, over the past decades, has really helped millions of people And AI today has the potential We truly live in exciting times. Thank you. (Applause) Chris Anderson: Thank you so much. I want to follow up on a couple things. This is what I heard. Most people's traditional picture of AI is that computers recognize and with a bit of machine learning, they can get really good at that, What you're saying is those patterns are no longer the atoms that it's much richer-layered concepts that can include all manners that go to make up a leopard, for example. So what could that lead to? Give me an example what do you picture happening in the world in the next five or 10 years Jeff Dean: I think is how do you generalize you already know how to do to new tasks, as easily and effortlessly as possible. And the current approach of training means you need lots of data because you're effectively trying about the world But if you can build these systems that already are infused with how to do then you can effectively with relatively few examples. So I think that's the real hope, that you could then have a system of something you care about, and it learns to do that new task. CA: You can do a form that is based on remarkably JD: Yeah, as opposed to needing to figure everything in the world out. CA: Aren't there kind of terrifying possible, from that? JD: I think it depends It's very clear that AI or if you apply it in ways it can be a negative consequence. So I think that's why it's important by which you look at potential uses of AI and really are careful and thoughtful CA: One of the things is that, if AI is so good at learning it's going to carry forward aspects of the world as it is And there's obviously been recently at Google. Some of those principles you've been challenged that you're not Not really interested to hear but ... are you really committed? How do we know that you are Is that just PR, or is that real, JD: No, that is absolutely real. Like, we have literally hundreds of people working on many of these because many of those in their own right. How do you take data from the real world, that is the world as it is, and how do you then use that and adapt the data bit of the scene or augment the data with additional data so that it can better reflect not the values that it sees in the world? CA: But you work for Google, Google is funding the research. How do we know that the main values are for the world, and not, for example, to maximize When you know everything you're going to know so much about the little wriggly, In your group, are there rules church-state wall &quot;You must do it for this purpose,&quot; so that you can inspire to do this for the world, for all of us. JD: Yeah, our research group with a number of groups across Google, including the Ads group, so we do have some collaboration, that we publish openly. We've published more in different topics, about fairness, interpretability things that are super important, and we need to advance in order to continue to make progress to make sure these models CA: It feels like we're at a time about the power of the big tech companies, and it's almost, if there was ever that this is being done that is actually key to Google's future, as well as all of ours. JD: Indeed. CA: It's very good to hear you Thank you so much for coming here to TED. JD: Thank you. (Applause)