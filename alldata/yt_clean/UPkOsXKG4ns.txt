Intro with a traditional RabbitMQ messaging broker. RabbitMQ Streams, which is more closely aligned use cases. RabbitMQ Streams is a relatively new As always, we'll focus on the four golden signals. second metric. We'll also track the latency for send and receive a message. Next, we'll including CPU usage relative to the VM limit disk operations, as Kafka uses an append-only log And finally, we'll measure the average CPU usage of all clients that send and receive To run these tests, I use AWS. I deploy the and use an EKS cluster with a bunch of Graviton test was a bit expensive. That's how much compute Test Design test design, and then we'll quickly cover Kafka message types used to send and receive messages which is significantly smaller than sending the load on the messaging broker and improves both messages in your gRPC and service-to-service For this test, I have a Device RPC message address, firmware, and the timestamp find the source code in my public GitHub repo. device using this message type on the producer the device. Then, I send that device to both a message is received, I retrieve the timestamp the latency of each message. This way, I don't measure latency. Instead, I measure it from the which I believe is quite accurate. client's source code can be improved, feel 1st Test this test, we're comparing Kafka with traditional Right from the start, you can notice that the is almost half the time it takes for Kafka. This your use case, but in general, RabbitMQ tends to you can see the number of messages per You'll also notice that Kafka's needs to write every single message you can see Kafka actively writing to the disk, Another point to keep in mind is that, in general, Kafka producers and consumers use about When Kafka's CPU usage hits around 50%, increase significantly. I'd say that after degrade. This is important to keep in mind if At around 15,000 messages per reaches 100%, and it starts to degrade At around 33,000 messages per second, RabbitMQ's producers and consumers begin to this is the maximum number of messages As you can see, Kafka reached 100% CPU to process all the messages. While its it keeps working. Now, let's push At this point, I'll focus only on Kafka manages to reach around 230,000 start to interfere with my Prometheus monitoring. Now, let me now open each graph First, we have the messages-per-second default settings, Kafka is capable of Next, let's look at latency. RabbitMQ failed performance before both systems started to and that's likely the main reason you'd choose and delivers better latency performance. Kafka can Next is disk operations. By the way, I used fast local SSDs on the EC2 Now, let's look at CPU usage. it doesn't fail immediately when it hits stores all its data in memory, it fails Next is the client's average CPU usage. Finally, let's look at memory usage. You can see and started to fail. Now for the second test, we'll compare the latency is much higher from the start. which utilizes a new binary protocol developed you'll also notice that RabbitMQ is writing data for RabbitMQ in the first part of the test was By around 12,000 messages per second, latency began to rise. Surprisingly, which I think is due to the high latency By around 100,000 messages per second, RabbitMQ also reached 100% CPU usage At around 135,000 messages per Now, let me slowly increase the process more messages than in the first test. I was able to increase the number of clients, and Kafka held up until 272,000 messages per Alright, let me go ahead and open each First, we have the messages RabbitMQ performed much better than in but it was much slower overall. Next, we have latency. From this graph, it's latency and should only be used in batch data Next, we have disk write operations per second. Then we have CPU usage for Next is the clients' average CPU usage. And finally, the memory usage. Based on the first test, you have a choice: go with RabbitMQ if you need low or if you need throughput, resilience, and Now, based on the second test, I think Apache and if someone watching this can improve RabbitMQ I have a playlist with similar interesting. Thank you for watching,