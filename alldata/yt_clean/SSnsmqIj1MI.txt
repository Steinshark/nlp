This is a demo of long context an experimental feature We'll walk through some example prompts which comes out to over 800,000 tokens. We extracted the code and put it together into this txt file AI Studio over here. We asked the model to find three examples The model looked across and picked out these three. One one about poses, and one about morph All good choices based on our prompt. In this test, the model took around 60 seconds But keep in mind that latency times as this is an experimental feature Next, we asked, "what controls As you can see and it explained that the animations Next, we wanted to see if it could so we asked, "Show me some code to add a slider Use that kind of GUI the other demos have." This is what it looked like before and here's the modified version. It's the same scene, but it added slow down, It used this GUI library the other demos have, set a new parameter and wired it up to the mixer in the scene. Like all generative models, responses There's actually not an INIT function in this demo like However, the code it gave us Next, we tried a multimodal input of one of the demos. We didn't tell it anything we could find the code As you can see, the model was able to look through the hundreds of demos Next, we asked the model "how can I modify the code The model was able to zero in on one called generate height, and showed us it clearly explained how the change you can see that the terrain is indeed We tried one more code modification task using this 3D We asked, "I'm looking at the text geometry How can I change the text to say, 'goldfish' look really shiny and metallic?" You can see the model identified and showed the precise lines in it Further down, it explained these material and how to change them You can see that it definitely pulled off the task and the text looks a lot shinier now. These are just a couple examples of up to 1 million This is a demo of long context an experimental feature We'll walk through some example which comes out to over 800,000 tokens. We extracted the code and put it together into this text file, We extracted the code and put it together into this text file, over here. We asked the model to find three examples animation. The model looked across and picked out these three one What about poses? And what about morph All good choices based on our prompt. In this test, the model took about 60 seconds But keep in mind that latency times as this is an experimental feature Next, we asked what controls the animations And you can see here and it explained that the animations Next, we wanted to see if we could So we asked, to control the speed of the animation The other demos have. This is what it looked like before on And here's the modified version. It's the same scene, up, slow down It used this goofy library. The other demos have set a new parameter and wired it up to the mixer in the scene. Next, we try to multi-modal input of one of the demos. We didn't tell it anything where we could find the code As you can see, the model was able and find the one that matched the image. Next, we asked the model How can I modify the code The model was able to zero in on one function called generate height, Below the code, over here in the updated version. You can see that the terrain is indeed We tried one more code modification task using this 3D We asked, I'm looking at the text geometry How can I change the text to say, goldfish look really shiny? Metallic. You can see the model identified and showed the precise lines in it Further down, it ness and roughness and how to change them You can see the model identified and showed the precise lines in it Further down, it explained nice and roughness and how to change Like all generative models, responses We did feel like it could have maybe reuse see that it definitely pulled off the task These are just a couple examples of up to 1 million This is a demo of long context an experimental feature We'll walk through some example prompts which comes out to over 800,000 tokens. We extracted the code and put it together in this text file Studio over here. We asked the model to find three examples The model looked across hundreds What about blending skeletal animations? What about poses? And what about morph All good choices based on our approach. In this test, to respond to each of these prompts. But keep in mind that latency times this is an experimental feature Okay. Next, we asked what controls As you can see here, and it explained that the animations model. Next, we wanted to see So we asked. Next, we wanted to see So we asked, Show me some code the speed of the animation and use that This is what it looked like before on And here's the modified version. It's the same scene, up, slow down, It used this goofy library. The other demos have set a parameter and wired it up to the mixer in the scene. Next, we try to multi-modal input of one of the demos. We didn't tell it anything about the Next we try to multi-modal input by giving We didn't tell it anything and just asked where we could find As you can see, the model was able to look through the hundreds of demos Next, we asked the model How can I modify the code The model was able to zero in on one called generate height, and showed us It clearly explained how the change works You can see that the terrain is indeed We tried one more code modification task using this 3D text. We tried one more code modification task using this 3D texture demo over here. We tried one more code modification I'm looking at the text geometry demo How can I change the text to say, goldfish look really shiny and metallic? You can see the model identified and showed the precise lines in it Further down, it explained these material and how to change them Like alternative models, responses We did feel like it could have maybe reuse but you can see that it definitely looks much shinier now. These are just a couple examples of up to 1 million These are just a couple examples with a context window of up 1.5 Pro. This is a demo of long context experimental feature We'll walk through some example prompts example code, We extracted the code and put it together into this text file Studio over here. We asked them all to find three examples The model looked across hundreds About blending skeletal animations. What about poses? And what about morph All good choices based on our prompt. In this test, the model took about. In this test, to respond to each of these prompts. But keep in mind that latency times as this is an experimental feature In this test, to respond to each of these prompts. But keep it in this test. The model took around 60 seconds But keep in mind that latency times as this is an experimental feature Next, we asked what controls the animations Next, we asked what controls As you can see here, and it explained that the animations And you can see and it explained that the animations And you can see here and it explained that the animations Next, we wanted to see if we could So we asked, Show me some code to add a slider and use that to kind of go Have. Next, we wanted to see if you could So we asked, to control the speed of the animation The other demos have this is what it looked like before on the original three JS site, It's the same scene, up, slow down, It uses this. It used this goofy library. The other demos have set a parameter and wired it up to the mixer in the scene. Next, we try to multi-modal input of one of the demos. We didn't tell it anything where we could find the code As you can see, As you can see, the model was able to look through the hundreds of demos Next, we asked the model How can I modify the code The model was able to zero in on one called generate height, Below, the code clearly explained how the change works You can see that the the model was able to zero in on one particular function and showed us the exact line It clearly explained how the change works You can see the terrain is indeed flatter, We tried one more code modification We asked. I'm looking at the Tex Geometry demo How could I change the text to say, look really shiny and metallic? You can see the model identified and showed the precise lines in it Further down, it ness and roughness and how to change them Like all generative models, responses We did feel like it could have maybe reuse but you can see that it definitely looks much shinier now. Like all generative models, responses We did feel like it could have maybe reuse see that it definitely pulled off the task These are just a couple examples of up to 1 million These are just a couple examples window of the 1 million