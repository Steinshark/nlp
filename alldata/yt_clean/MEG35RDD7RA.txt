ANNOUNCER: The following program YASER ABU-MOSTAFA: Welcome back. Last time, we introduced And if you have an application in your learning is the right technique for criteria that you should check. You should ask yourself: is with that we can learn? And we realize that this condition can be even if we don't know mathematically The example we gave was the There is clearly a pattern-- if someone been in a residence for so long, has is somewhat correlated to And therefore, we know that the pattern that we don't know exactly The second item is that we cannot pin the example I just gave. And this is why we resort The third one is that we have data In the case of the credit application, records of previous customers, and we application when they applied, and we their credit behavior. So we have data that are going to enable application to their eventual credit going to learn from. Now, if you look at the three criteria, you can do without, and one that What do I mean? Let's say that you don't Well, if you don't have a pattern, And the only problem is That doesn't sound very encouraging. But the idea here is that, when we develop realize that you can apply the technique is a pattern or not. And you are going to determine whether So you are not going to be fooled and system to your customer, and the There is something you can actually learned or not. So if there's no pattern, there is no The other one, also, Let's say that we can pin the Well, in that case, machine learning It will still work. It may not be the optimal technique. If you can outright program it, and bother generate examples, and try to But machine learning is It is going to learn, and it is It may not be the best system in this The third one, I'm afraid You have to have data. Machine learning is about And if you don't have data, there is So this is basically the picture about Now, we went on to focus on one type, And in the case of supervised learning, The target function we That is our standard notation. And this corresponds, for example, x is your application, and f of x is not, for the bank. So if you look at the target function, function is that it's unknown. This is a property that we And obviously, unknown is a very generous you don't have to worry about what It could be anything, and you will learn There's still a question But it's a good assumption to have, or because then you know that you don't generated the examples. You only worry about the system that you Now, you are going to be given data. And the reason it's called supervised given the input x's, as You're also given the output-- the target outputs. So in spite of the fact that the target it is known on the data This is the data that you are going to are going to use to figure out So in the case of supervised learning, explicitly. In the other cases, you have less talked about it-- like unsupervised anything, and reinforcement learning, which is just a reward or punishment may or may not be the target. Finally, you have the solution tools. These are the things that you're going problem, and they are called the learning They are the learning algorithm And the learning algorithm will the final hypothesis, the one that you we give the symbol g for that. And hopefully g approximates f, which remains unknown. And g is picked from a hypothesis set, a member of the hypothesis So h is a generic hypothesis. The one you happen to pick, Now, we looked at an example First, the learning model-- the function, thresholded. That happens to be the hypothesis set. And then, there is an algorithm that hypothesis to report And the hypothesis in this case is Different hypotheses in the in different lines. Some of them are good and some of them correctly the examples which And we found that there's a very simple hypothesis, while the algorithm is still hypothesis. And once you have all the points guaranteed in the case of the perceptron data was linearly separable then you will get there, and that will Now, we ended the lecture on sort of encouragement about learning, can we actually learn? So we said Unknown function is an attractive But can we learn an unknown And then we realized that if you look at Why is it impossible? Because I'm going to give you a finite the value of the function on this set. Good. Now, I'm going to ask you what is How in the world are you going to tell function is genuinely unknown? Couldn't it assume any value it wants? Yes, it can. I can give you 1000 points, a million still the function can behave So it doesn't look like the statement learning, and therefore we have And what we are going to do about it Now, the lecture is called And I am going to address this question beginning to end. This is the only topic Now, if you want an outline-- it's really a logical flow. But if you want to cluster we are going to start with simple probabilistic situation. It doesn't seem to relate to learning. But it will capture the idea-- can we say something outside the So we're going to answer it in a way mathematics is very friendly. And then after that, I'm going to be situation to learning as we stated. It will take two stages. First, I will just translate the relates to learning, and then we will real learning. That's the last one. And then after we do that, and we think a serious dilemma that we have. And we will find a solution to that indeed, learning is feasible So let's start with the experiment Consider the following situation. You have a bin, and the The marbles are either red or green. That's what it looks like. And we are going to do an experiment And the experiment is to pick some marbles. Let's formalize what the probability There is a probability of picking So now you think of mu as the Now, the bin is really just a visual experiment. You can think of this abstractly two outcomes, red or green. Probability of red is mu, one point to another. If you want to stick to the bin, you can of marbles and the fraction Or maybe it has a finite number of marbles, but replace them. But the idea now is that every time you of picking a red marble is mu. That's the rule. Now, there's a probability of And what might that be? That must be 1 minus mu. So that's the setup. Now, the value of mu is unknown to us. So in spite of the fact that you can there's less red than green, and all of that. You don't have that advantage in real. The bin is opaque-- it's sitting there, So now that I declare mu is unknown, where this is going. Unknown is a famous word from last lecture, what we have. Now, we pick N marbles independently. Capital N. And I'm using the same number of data points in So the sample will look like this. And it will have some It's a probabilistic situation. And we are going to call the fraction this now is a probabilistic mu is an unknown constant If you pick a sample, someone else picks frequency in sample from And we are going to call it nu. Now, interestingly enough, nu also So it says nu equals fraction So that's where it lies. Here is nu! For some reason that I don't understand, in the figures. So I decided maybe the app is actually It doesn't like things in sample. It only likes things that are real. So it knows that nu is not important. It's not an indication. We are really interested in So it kept the mu, but actually At least that's what we are going to Now, this is the bin. So now, the next step is to ask ourselves machine learning. Does nu, which is the sample frequency, which is the actual frequency in the bin The short answer-- this is to remind you what it is. The short answer is no. Why? Because the sample can be mostly green, Anybody doubts that? The thing could have 90% red, of them happen to be green. This is possible, correct? So if I ask you what is actually mu, you You don't know anything about the Well, that's the short answer. The long answer is yes. Not because no and yes, but We have to really discuss a lot So why is it yes? Because if you know a little bit about sample is big enough, the sample disappearing quantity here-- that Think of a presidential poll. There are maybe 100 million or more of 3000 people. You have 3000 marbles, so to speak. And you look at the result in the million will vote. How the heck did you know that? So now the statistics come in. That's where the probability And the main distinction between possible versus probable. In science and in engineering, you go absolutely certain, but It opens a world of possibilities, possibilities that it opens. So now we know that, from tell me something about mu. The sample frequency tells me So what does it exactly say? Now we go into a mathematical In words, it says: in a big sample, should be close to mu, So now, the symbols that go with Large N, our parameter N. And how do we say that We say that they are within epsilon. That is our criterion. Now, with this in mind, we are The formula that I'm going to show stay with us for the I would like you to pay attention. And I'm going to build it gradually. We are going to say that the probability So we're going to say that it's less right-hand side will be Now if I am claiming that the must be that that thing is a bad event. I don't want it to happen. So we have a probability of something What is a bad event in the context It is that nu does not They are not within epsilon And if you look at it, here you have that's the difference That happens to be bigger So that's bad, because that tells us tolerance epsilon. We don't want that to happen. And we would like the probability be as small as possible. Well, how small can we guarantee it? Good news. It's e to the minus N. It's a negative exponential. That is great, because negative So if you get a bigger sample, this probability. So the probability of something bad can claims that, indeed, nu will be wrong for a very minute But that's the good news. Now the bad news-- ouch! Epsilon is our tolerance. If you're a very tolerant I just want nu and mu to be That's not very much to ask. Now, the price you pay for that is not epsilon, but epsilon squared. So that becomes 0.01. 0.01 will dampen N significantly, and negative exponential. And if you are more stringent and to be close to mu. I am not fooling around here. So I am going to pick epsilon Good for you. 10 to the minus 6? Pay the price for it. You go here, and now that's That will completely kill any So the exponent now will So this probability will be around That's not yet the final answer. So now, you know that the probability Congratulations! You knew that already. Well, this is almost the formula, What we need is fairly trivial. We just put 2 here, and 2 there. Now, between you and me, I prefer better, without the 2's. However, the formula with the 2's has the So we have to settle for that. Now that inequality is called It is the main inequality we are going You can look for the proof. It's a basic proof in mathematics. It's not that difficult, but And we are going to use it all the way-- that will get us to prove something If the buzzword 'VC dimension' means this after a lot of derivation. So this is the building block that Now, if you want to translate the we have been talking about is that statement: mu equals nu. That would be the ultimate. I look at the in-sample frequency, that's That's the real frequency out there. But that's not the case. We actually are making the statement making the statement-- we are making a PAC statement. And that stands for: this statement is Probably because of this. This is small, so the probability Approximately because of this. We are not saying that mu equals nu. We are saying that they are And that theme will remain So we put the glorified Hoeffding's a viewgraph analyzing what it means. In case you forgot what nu and So mu is the frequency within the bin. This is the unknown quantity And nu is the disappearing quantity the sample you have. So what about the Hoeffding Well, one attraction of this every N, positive integer, and every Pick any tolerance you want, and want, this is true. It's not an asymptotic result. It's a result that holds for That's a very attractive proposition an exponential in it. Now, Hoeffding Inequality belongs to which are called the Laws So this is one law of large numbers, there are tons of them. This happens to be one of the asymptotic, and happens to have Now, one observation here is that if you computing this probability. This probability patently mu appears explicitly in it, and distribution of nu. Nu is the sample, in N That's a very simple binomial You can find the probability that the value of mu. So the probability that this quantity, the probability itself However, we are not interested We just want to bound it. And in this case, we are As you see, the right-hand side And that gives us a great tool, because that, we already declared, is unknown. mu is unknown. It would be a vicious cycle if I go but I don't know what mu is. Now you know uniformly, regardless of between 0 and 1, and this will still sample frequency from That's a good advantage. Now, the other point is that there is inequality. What is the trade-off? The trade-off is between In a typical situation, if we think of N given to you-- the amount of data-- in of the bin, N is usually dictated. Someone comes and gives you a certain Epsilon is your taste in tolerance. You are very tolerant. You That will be very easy to satisfy. And if you are very stringent, you can Now, because they get multiplied here, than N you need in order to compensate of probability bound. And that makes a lot of sense. If you have more examples, you are more together, even closer and as you get larger N. So this makes sense. Finally, it's a subtle point, but We are making the statement that nu And this implies that mu is What is this? The logic here is a little bit subtle. Obviously, the statement is a tautology, a logical point, here. When you run the experiment, mu is an unknown. It's a constant. The only random fellow in this That is what the probability You generate different samples, and This is the probabilistic thing. This is a happy constant sitting Now, the way you are using the here, from nu. That is not the cause and effect The cause and effect is that mu affects But we are using it the Lucky for us, the form of the Therefore, instead of saying that nu be the accurate logical statement-- mu close to it. We, instead of that, say that I know be close to nu. That's the logic we are using. Now, I think we understand what the bin mathematical condition that What I'd like to do, I'd like to connect that to the In the case of a bin, the unknown a number, mu. Just unknown. What is the frequency inside the bin. In the learning situation that we had, decipher is a full-fledged function. It has a domain, X, that could be Y could be anything. It could be binary, like It could be something else. That's a huge amount of information. The bin has only one number. This one, if you want to specify it, So how am I going to be able to relate simplistic? The way we are going to do it Think of the bin as your input space That's the correspondence. So every marble here is a point x. That is a credit card applicant. So if you look closely at the gray residence, and whatnot. You can't see it here because Now the bin has all the points is really the space. That's the correspondence in our mind. Now we would like to give So here are the colors. There are green marbles, and they learning problem. What do they correspond to? They correspond to your hypothesis So what does that mean? There is a target function You have a hypothesis. The hypothesis is a full function, You can compare the hypothesis to the And they either agree or disagree. If they agree, please color in the input space-- Color it green. Now, I'm not saying that you know which are not, because you don't know I'm just telling you the mapping that an unknown mu. So both of them are unknown, correspondence that maps it. And now you go, and there And, you guessed it. You color the thing red if your So now I am collapsing the entire disagreement between your hypothesis how you get to color the bin. Because of that, you have a mapping for red, according to this rule. Now, this will add a component to did not have before. There is a probability associated There is a probability of independently, and all of that. When we talked about the learning I will just give you a sample set, So let's see what is the addition we statement of the learning problem to And the new ingredient is important, It's not like we have the luxury So we go back to the learning Do you remember this one? Let me remind you. Here is your target function, And I promised you last time that it will be fulfilled. We are not going to touch this box. We're just going to add another box And the target function generates These are the only things that It picks a hypothesis from the final hypothesis, which hopefully That's the game. So what is the addition In the bin analogy, this Now the input space So I need to apply this probability to are being generated. I am going to introduce a probability input space. Now the points in the input space-- Euclidean space-- are not just generic points now. There is a probability of picking And that is captured by the probability, capital P. Now the interesting thing is that I'm be anything. I just want a probability. So invoke any probability you want, and I am not going to restrict the That's number one. So this is not as bad as it looks. Number two, I don't even Of course, the probability choice will of getting a green marble or a red different marbles changed, so it But the good news with the Hoeffding is independently of mu. So I can get away with not only any P, I'll still be able to make the So this is a very benign addition And it will give us very high feasibility of learning. So what do you do with You use the probability to generate the x_1 up to x_N are assumed to be independently. That's the only assumption If you make that assumption, But the good news is, as we did not compromise about You don't need to make assumptions about you want to learn, which is good news. And the addition is almost technical. That there is a probability somewhere, If I know that, then I can make Obviously, you can make that statement is valid, and we can discuss that assumption is not valid. So, OK. Happy ending. We are done, and we now have Are we done? Well, not quite. Why are we not done? Because the analogy I gave hypothesis in mind. I told you that the red and green marbles and the target function. So when you tell me what h is, All of these colors. This is green not because it's anything inherent about It's because of the agreement between hypothesis, h. That's fine, but what is the problem? The problem is that I know that You're probably saying, yeah, I don't see the problem yet. Now here is the problem. What we have actually discussed is The situation as I describe it-- you have a single bin and you have red corresponds to the following. A bank comes to my office. We would like a formula And we have data. So instead of actually taking the data, one, like the perceptron learning corresponds to what I just described. You guys want a linear formula? OK. I guess the salary should Let's say 2. The outstanding debt is negative, so And years in residence are important, So let's give them a 0.1. And let's pick a threshold you not to lose money. Let's pick a threshold of 0.5. Sitting down, improvising an h. Now, after I fix the h, I ask you for I picked is good or bad. That I can do with the bin, because If I miraculously agree with everything definitely declare victory But what are the chances that this I have no control over whether I will The whole idea of learning is that I'm find a hypothesis that In this case, I just dictated And I was able to tell you for sure But I have no control of what news You can come to my office. I improvise this. I go to the data. And I tell you, I have It generalizes perfectly, and That's what I have, because when So that's not what we are looking for. What we are looking for is So how do we do that? No guarantee that nu will be small. And we need to choose the hypothesis That's the game. And in that case, you are going to go for by every hypothesis, and then you pick that gives you the least error. So now, that doesn't look It worked with one bin. Maybe I can have more than one bin, to more than one hypothesis. It looks plausible. So let's do that. We will just take multiple bins. So here is the first bin. Now you can see that So that hypothesis is terrible. And the sample reflects But we are going to have other bins, So this bin corresponds And since we are going to have other h_1 in preparation The next guy comes in, And you have another mu_2. This one looks like a good hypothesis, And it's important to look If you look at the top red point here the same point in the input space. It just was colored red here Why did that happen? Because the target function disagrees happens to agree with this h. That's what got this the color green. And when you pick a sample, the sample because the colors depend And these are different hypotheses. That looks simple enough. So let's continue. And we can have M of them. I am going to consider a finite number easy for this lecture. And we're going to go more sophisticated theory of generalization. So now I have this. This is good. I have samples, and the samples And I can do the learning, and the these samples looking And when you find a good sample, you and you say that it must be that the corresponding bin happens to be So that is an abstraction of learning. That was easy enough. Now, because this is going to stay with the notation that will survive with us So here is the notation. We realize that both mu, which and nu, which happens to be in this case, the sample frequency of So I'd like to give a notation The first thing, I am going to call mu and nu So nu, which is the frequency in the That is a standard definition for what If you perform well in-sample, it means that I give you is small. And because it is called in-sample, I think this is worth blowing up, This is our standard notation for Now, we go and get the other one, And that is called out-of-sample. So if you are in this field, I guess performance. That's the lesson. Out-of-sample means something And if you perform out-of-sample, on you must have really learned. That's the standard for it, With this in mind, we realize that we which we need. So we are going to make the notation a little E_in and E_out-- calling them E_in of h, and E_out of h. Why is that? Well, the in-sample performance-- you approximating the target function That's what E_in is. So obviously, it depends So it's E_in of h. Someone else picks another h, they will Similarly E_out, the corresponding So now, what used to be What used to be mu, inside Now, the Hoeffding Inequality, by now, said that. So all I'm going to do is just And now it looks a little bit exactly the same thing. The probability that your in-sample sample performance by more than your equal to a number that And you can go back and forth. There's nu and mu, or you can go here So we're settled on the notation now. Now, let's go for the multiple These are the multiple We have the hypotheses h_1 up to h_M, And if you see 1, 2, M, again, the symbol that the app doesn't like. But thank God we switched something will appear. Yeah! So right now, that's what we have. Every bin has an out-of-sample sample is: Out. Of. Sample. So this is a sample. What's in it is in-sample. What is not in it is out-of-sample. And the out-of-sample depends on And obviously, these quantities will be these quantities will be different of your hypothesis. So we solved the problem. It's not verification. It's real learning. I'm going to scan these. So that's pretty good. Are we done already? Not so fast. [LAUGHING] What's wrong? Let me tell you what's wrong. The Hoeffding Inequality, that we have and all of that, doesn't apply What? You told us mathematics, and you go Are you just pulling tricks on us? What is the deal here? And you even can complain. We sat for 40 minutes now going from the learning diagram, mapping it to that the main tool we developed Why doesn't it apply, and what Let me start by saying why it doesn't can do about it. Now, everybody has a coin. I hope the online audience I'd like to ask you to take let's say, five times. And record what happens. And when you at home flip the if you happen to get all five heads in got all five heads. If you get anything else, We just want to know if someone Everybody is done flipping the coin. Because you have been so generous and [LAUGHTER] Now, did anybody get five heads? All five heads? Congratulations, sir. You have a biased coin, right? We just argued that in-sample have this Hoeffding thing, and therefore must be that this coin We know better. So in the online audience, MODERATOR: Yeah, in the online audience, PROFESSOR: There are lots of Are they really biased coins? No. What is the deal here? Let's look at it. Here, with the audience here, I didn't because it's a live broadcast. So I said five will work. For the analytical example, Let's say you have a fair coin, You have a fair coin. And you toss it 10 times. What is the probability that you Pretty easy. One half, times one half, you about 1 in 1000. No chance that you will get it-- not no chance, but very little chance. Now, the second question is the one we If you toss 1000 fair coins-- it wasn't Maybe out there is 1000. What is the probability that some Not difficult at all to compute. And when you get the answer, the answer likely than not. So now it means that the 10 heads in the real probability. That is the game we are playing. Can I look at the sample and infer No. In this case, you will get 10 Why did this happen? This happened because Eventually what will happen is-- Hoeffding applies to any one of them. But there is a probability, let's will be off here. Another half a percent that If you do it often enough, and you are are disjoint, you will end up with something bad will happen, somewhere. That's the key. So let's translate this into Here are your coins. And how do they correspond Well, it's a binary experiment, whether or a green marble, or you are flipping It's a binary situation. So there's a direct correspondence. Just get the probability of heads being a red marble, corresponding to them. So because the coins are fair, actually all the bins in this case That's really bad news The hypothesis is completely random. Half the time it agrees with Half the time it disagrees. No information at all. Now you apply the learning paradigm we generate a sample from I get this, I look at it, It has some reds. I want really a clean hypothesis all green. You move on. And, OK. This one-- even, I don't know. This is even worse. You go on and on and on. And eventually, lo and behold, Bingo. I have the perfect hypothesis. I am going to report this to my financial forecasting, we are going make a lot of money. And you start thinking about the car you Well, is it bingo? No, it isn't. And that is the problem. So now, we have to find something multiple bins properly. Hoeffding Inequality-- if you have one The guarantee gets terribly diluted as how the dilution goes. So here is a simple solution. This is a mathematical slide. There is absolutely nothing This is the quantity we've This is the probability But in this case, you realize Remember, g was our final hypothesis. So this corresponds to a process where one according to a criterion, that minimizing the error there, and one that you chose. And you would like to make a statement chose-- the in-sample error-- happens to So you'd like the probability of the tolerance to be, again, small. All we need to do is find a Hoeffding now this fellow is loaded. It's not just a fixed hypothesis It actually corresponds to a large random samples in order to pick one. So clearly the assumptions of Hoeffding to a single bin. This probability is less probability of the following. I have M hypotheses-- capital M hypotheses. h_1, h_2, h_3, h_M. That's my entire learning model. That's the hypothesis set that I have, If you look at what is the probability pick is bad? Well, this will be less than first hypothesis is bad, or the second hypothesis is bad. That is obvious. g is one of them. If it's bad, one of them is bad. So less than or equal to that. This is called the union It's a very loose bound, in general, consider the overlap. Remember when I told you that the half half a percent here-- if you are very unlucky and these are The non-overlapping is the worst-case used by the union bound. So you get this. And the good news about this is that I The union bound is coming up. So I put the OR's. And then I use the union bound to say that this the individual probabilities. So the half a percent plus half a percent this will be an upper bound The probability that one of them goes gets all heads, and I add the makes it a respectable probability. So this event here is implied. Therefore, I have the implication because because of the union bound, where I have just need to add the probabilities. Now, all of this-- again, we make really not simplistic as in trivially We just don't want to make any applicability of our result. So we took the worst case. It cannot get worse than that. If you look at this, now Because each term here is I didn't choose anything. Every one of them has a hypothesis Every one of them is a bin. So if I look at a term by itself, same way it applied before. So this is a mathematical I'm not looking at the I reduced the bigger experiment Each of them corresponds to a simple So I can substitute for each of Hoeffding gives me. So what is the bound that That's the one. For every one of them, each of equal to this quantity. One by one. All of them are obviously the same. So each of them is smaller Each of them is smaller than this quantity. Now I can be confident that the which is the probability that being close to the out-of-sample error-- than my tolerance, the bad event. Under the genuine learning scenario-- you and you look deliberately for a sample green as possible, and And you want an assurance that corresponding bin will genuinely That is what is captured That is still bounded by something, which is good. But it has an added factor that will be I have M of them. Now, this is the bad event. I'd like the probability to be small. I don't like to magnify the right-hand of something bad happening. Now, with M, you realize that if you use 10 hypotheses, this If you use a million hypotheses, we There is no guarantee, because now the to be a respectable probability, which the statement that the probability is less than 10. [LAUGHING] Yeah, thank you very much. We have to take a graduate Now you see what the problem is. And the problem is extremely In that Q&amp;A session after the last discussion the assertion that if you chances are you will memorize in-sample, really generalize well out-of-sample, parameters to work with. There are so many ways to look at that If you have a very sophisticated model-- That's later to come. That's what the theory of But if you pick a very sophisticated link between the in-sample So you look at here. [LAUGHING], I didn't mean it this you what it is. At least you know it's So this fellow is supposed The in-sample is supposed to The more sophisticated the model you track the out-of-sample. Because the probability of them and bigger. And that is exactly the Now, surprise. The next one is for the Q&amp;A. We will go to the questions and answers. We are now in the Q&amp;A session. And if anybody wants to ask a question, microphone and ask, and we can start there are any. MODERATOR: The first question is what happens when gives you something trivial, PROFESSOR: Well, it means that you have, the amount of data you have, generalization, or-- which is somewhat equivalent-- that your tolerance is too stringent. The situation is not Let's say that you'd like to take And let's say that you ask How can you interpret the result? Nothing. You need a certain amount of respondents right-hand side to start Other than that, it's It's very likely that what you have seen anything out-of-sample. MODERATOR: So in the case the question is would each set PROFESSOR: The perceptron and, as a matter of fact, every that we're going to encounter, the happens to be infinite. We were just talking about the because it's bigger than 1. If you take verbatim apply what I said, then you less than infinity. That's very important. However, this is our first step. There will be another step, where we deal And we are going to be able to describe that happens to be finite, and that are going to use in the counterpart That's why there is mathematics Obviously, the perceptron has an infinite you have real space, and here is your continuously as you want. Even just by doing this, you already without even exploring further. MODERATOR: OK, Could you go over again in slide 6, of vice versa. PROFESSOR: Six. It's a subtle point, and it's common statistics. What do you do in statistics? What is the cause and effect for The probability results in a sample. So if I know the probability, I can likelihood that you'll get one Now, what you do in statistics You already have the sample, and you are gave rise to it. So you are using the effect to the other way around. So the same situation here. The bin is the cause. The frequency in the sample I can definitely tell you what the based on the bin. The utility, in terms of learning, and infer the bin. So I infer the cause based There's absolutely nothing I just wanted to make the point clear, Inequality, which you can see here, You should always remember that nu is and causes the probability to happen, When we use it to predict that the sample, we are really taking nu as sample we've got. And then we are trying to interpret And I'm just saying that, in this case, form that the difference between them, epsilon, then if you look at this as will be approximately the same, And you can say, nu is here, and I be the same. That's the whole idea. It's a logical thing rather MODERATOR: OK. Another conceptual question that is model corresponds to And some people are asking-- they thought each h was a model. PROFESSOR: OK. Each h is a hypothesis. A particular function, one of them you be equal to g, and this is the g that guess as an approximation for f. The model is the hypotheses that you're choose one. So that's the hypothesis And again, but there is I'm using the number of hypotheses as intuitive argument that I gave you. It's not clear at all that the pure number It's not clear that anything that has complexity. Maybe the complexity has to do with hypotheses. And that's a very interesting point. And that will be discussed at some hypotheses versus the complexity of hypotheses. This will be a topic that we will MODERATOR: Some people are So how do you pick g? PROFESSOR: OK. We have one way of picking g-- that which is the perceptron So your hypothesis set is H. Script H. It has a bunch of h's, which are the And you pick g by applying the PLA, playing around with this boundary, classifies the inputs correctly, and the one you end up with So g is just a matter of notation, the final hypothesis. How you pick g depends on what hypothesis set you use. So it depends on the learning model, MODERATOR: OK. This is a popular question. So it says: how would you extend the is a valid range of responses PROFESSOR: It can be done. One of the things that I mentioned probability here, is uniform. Now, let's say that you are not talking Instead of taking the frequency of error you take the expected value sample average of it. And they will be close to each other, modification is needed to be here. And basically, the set of laws of large has a bunch of members that actually sample average, rather than just the sample average. If you take your function as being 1, that will give you the sample as the the expected value. So it's not a different animal. It's just a special case that And in the other case, one of the things your variable. So it will affect the bounds. Here, I'm choosing epsilon in general, is very limited. Let's say that the probability times 1 minus mu. It goes from a certain value So it can be absorbed. It's bounded above and below. And this is the reason why the be uniformly done. If you have something that has variance then that will play a role in your this will be valid. So the short answer is: it can be done. There is a technical modification, and modification, that needs to be taken into the variable I'm talking about. MODERATOR: OK. There's also a common confusion. Why are there are multiple bins? PROFESSOR: OK. The bin was only our conceptual feasible in a probabilistic sense. When we used a single bin, we had it looked like we actually captured looked closer and we realized that, if apply the Hoeffding Inequality directly working with-- if you want to put it in is that my hypothesis set And that corresponds to the bin. So now I am picking it-- which is my only choice. I don't have everything else. And all I'm doing now is verifying that correspond to the out-of-sample the plain-vanilla Hoeffding. Now, if you have actual learning, hypothesis. And we realize that the bin changes with a marble is red or green depends on disagrees with your target function. Different hypotheses will Therefore, you need multiple bins to is the only situation that admits that I'm going to explore the hypotheses, and pick the one that performs best, will generalize well out-of-sample. MODERATOR: OK. Another confusion. Can you resolve the relationship so I'm not clear exactly what-- PROFESSOR: We applied the-- there are a bunch of components situation, so let me get the-- It's a big diagram, and it So one big space or set is X, and look at here. This is hypothesis set H. It's a set. OK, fine. And also, if you look here, the target in this case, X is also a set. The only invocation of probability that the benefit of the probabilistic a probability distribution on X. H, which is down there, is left There is no question of When we talk about the Bayesian fact, there will be a question of here in order to make the whole But that is not the approach that is we discuss that specific Question. STUDENT: What do we do when there will satisfy my criteria? Like, in perceptron, for example. I could have several hyperplanes which So how do I pick the best-- PROFESSOR: Correct. Usually, with a pre-specified you'll end up with something. So the algorithm will But your remark now is that, given that there are many solutions error, there is really no distinction sample performance. I'm using the same hypothesis set, And the in-sample error is the same. So my prediction for the out-of-sample distinction between them. The good news is that the learning it will give you one specific, But even within the ones that achieve that we'll talk about later on when we that prefers one particular solution generalization. Not clear at all given what I said as an appetizer, there's something MODERATOR: OK. A question is does the inequality even if g is not optimal? PROFESSOR: What about the g? MODERATOR: Does it hold for any PROFESSOR: Yeah. So the whole idea-- once you write the symbol g, you hypothesis. Because by definition, g is the final allowed to pick any h from the Therefore, when I say g, don't Look at the entire learning process that set of hypotheses, according to the rule, and went through and ended up with one, and now we call this g. So the answer is patently Patently yes, just by the notation MODERATOR: Also, some confusion. With the perceptron algorithm there's a confusion that, at each PROFESSOR: Correct. But these are hidden processes for us. As far as analysis I mentioned, the algorithm does something magic, and In the course of doing that, it will hypotheses. So the abstraction of having just the them and picking the one that happens In reality, these guys happen in hypothesis to another by And in the course of doing that, algorithm, you are moving from But I'm not accounting for that, because hypothesis yet. When you find the final hypothesis, On the other hand, because I use the scenario, the generalization bound visited or you didn't visit. Because what I did to get the bound, of sample, is that I consider that all the in-sample to out-of-sample, closely And that obviously guarantees that with will be fine. But obviously, it could be an overkill. And among the positive side effects intermediate values have not that we look at it or consider it, MODERATOR: A question They say that they don't understand shows that learning is feasible. PROFESSOR: OK. Hoeffding shows that verification The presidential poll makes sense. That, if you have a sample and you have how the question is answered in the believe that the answer in the general close to the answer you got in-sample. So that's the verification. In order to move from verification to that statement, simultaneously on you had the modified Hoeffding which is this one that has the red M in it. This is no longer the plain-vanilla We'll still call it Hoeffding. But it basically deals with a situation guys simultaneously, and you want to behaving well. Under those conditions, this is the give, and the probability, obviously, So the probability that bad thing possibilities is bigger than the you have one of them. And this is the case where you added up mentioned before. MODERATOR: Can it be said that the population in a-- PROFESSOR: The bin corresponds population before coloring. So remember the gray bin-- I have it somewhere. We had a viewgraph where the So this is my way of saying this call it X. And this is indeed the input space in Now, we start coloring it according So now there's more in the process But indeed, the bin can correspond to will correspond to the people you polled the presidential thing. MODERATOR: Is there a relation between p-values in statistics? PROFESSOR: Yes. The area where we are trying to say that an estimate on the sample, the The estimate is close to The probability that you will deviate-- And the p-value in statistics And there are other laws of large I don't want to venture I basically picked from that jungle of formula that will get me home when generalization. And I want to focus on it. I want to understand it-- this specific keep modifying it until we get to the And, obviously, if you get curious about different manifestations of in-sample probabilities of error, that is a very ground to study. But it is not a core subject The subject is only borrowing to get what it wants. So that ends the questions here? Let's call it a day, and