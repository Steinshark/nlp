People have a perception of what AI and robotics What do I call you? Do you have a name? Yes, Samantha. Where did you get that name from? I gave it to myself actually. We've seen happy robots, sad robots, complex I understand what I'm made of, how I'm coated, feel. The first 50 years of AI were dominated by The idea was that you program an AI system can obey these rules and logically interpret If you did the rules just right, you can do From the very first days when people created to think about how to create intelligent machines phenomenon, so forth. The task they sent it, to stack blocks, was We have things like a machine that could first We had a machine that would beat the world rule-based AI. I would say the next big milestone started systems to machine learning-based systems. With machine learning, all the intelligence data. Unlike rule-based systems, machine learning Telling the difference between a cat and a but it's very difficult to articulate the It turns out, it's the same thing for a computer. If you try to do that with rules, it doesn't possible. When you teach a computer you give them examples of pictures of dogs. They learn how to do it pretty well and even One of the first big high-profile game show about a decade ago. Hello, 17,973 and a two-day total of 77,147. Just recently, AlphaGo winning the world championship AlphaGo's won again, three straight wins. Three straight wins, has won the match in We see this rapid acceleration, this exponential exponentially growing data, but they're also For example, when it comes to driverless cars, at driving, but a driverless car can have because it can learn from all other cars. In a strange way, the more driverless cars of them gets. We've seen increasingly how challenges that out to be solvable using machine learning. If I look forward, there's still milestones Machines that generate things, generate images, There are art pieces that win art competitions generate engineering designs, everything from now that outperform what humans can design. How are we different from the computer? What else do we have- It's not human. That's what I said. Right. People don't have buttons and a computer does. What is on your shirt? Uh ... Will AI ever be sentient? To me, the answer is yes. When the AI systems begin to take that incredible begin to have self-awareness, they begin to It's not going to be one day your computer a very gradual process. I want to be more like a human. It's the purpose I was designed for. People always ask, will robots reach human-level The answer is that there's no reason to think possible. Machines will keep learning, they'll get there, There's a lot of people who worry about AI scenarios around AI. I do think we have to worry about it. I don't think it's inherent that as we create always have the same goals in mind that we We just don't know what's going to happen than that of a human brain. I think that the development of full artificial race. I think AI will evolve to be different. It doesn't experience the world the way we Well, I take it from your tone, you're challenging Maybe because you're curious how I work? We'll know things we don't know, we'll know going to be like a different species. Now that you're all properly creeped out, The first one is the Director of the AI Mind Her AI research includes a two-year project Please welcome Susan Schneider. Our next panelist is the Chief AI Scientist Please join me in welcoming Yann Lecun. Also joining us is a professor of cognitive His research focuses on consciousness and Please welcome Peter Tse. Finally, we have a professor doing physics the positive use of technology as the president Please welcome the ridiculously handsome Max ... There's been some major paradigm shifts We had rules-based AI and we've shifted to Part of the major reason we've been able to Yann literally is one of the people that made Yann, just what is rule-based AI versus machine Well, actually the idea of machines that can Turing was talking about it in the 40s and were built in the 50s essentially. The Perceptron was a machine capable of recognizing It was actually an analog computer, so there 60s. It kind of died out a little bit at the end The way machine learning works, and you saw want to train your machine to recognize, let's images, you collect thousands of examples picture of a car, and if it doesn't say car, This is a car.&quot; Then, the machine adjusts its internal parameters you show the same picture the output will That's called supervised running. You feed the machine with the correct answer The problem with this is that it requires examples for the machines to do this properly. There's a lot of tasks you can do this way. You can train machines to recognize speech. You can train them to recognize images. You can train them to translate language. It's not perfect, but it's useful. You can train them to classify a piece of All of the applications that you see today of running, supervised running. That means it only works with things where How are those machines built? There's several ways to build learning machines, like this. The stuff that has become really popular in networks, which we now call deep learning brain a little bit, of constructing a machine that are very similar to the neurons in the changing the efficacy of the connections between They're like coefficients you can change essentially. With this kind of method, it's called deep into many layers essentially. It's as simple as that. It's not deep because there's a deep understanding With that, we can do amazing things like what train a machine to not just recognize objects, pose of a human body and translate language I think there's going to be a lot of applications limited. It's trained for relatively narrow applications. There's a second type of learning called reinforcement Reinforcement learning is a process by which and error. It tries something and then you tell it whether If you tell it it did good, it reinforces it de-emphasizes that behavior. That works really well for games, but it requires So, you can have machines start learning to millions of games against themselves and then But, if you were to use this to train a machine millions of hours and it would have to run out how not to do that. We seem to be able to learn how to drive with without ever crashing for most of us. We don't know how to do this with machines. That's the challenge of the next few years bit later. We have an ability to learn by just observing of background knowledge about the world just Just the fact that objects don't float in The fact that when an object is hidden behind That's called object permanence. This notion of gravity that objects fall, the air to a baby below six months, they're They think that's how the world works. It doesn't violate their model of the world. After eight months, if you show that to a They say, &quot;What's going on?&quot; I mean, they don't say what's going on, but That means, in the meantime, they've built like intuitive physics. That occurs also with animals like apes. Your dog has a model of the world. Your cat has a model of the world. When this model of the world is violated, in any case, we pay attention because you so here's a baby orangutan here being shown An object is being removed from the cup and baby orangutan [crosstalk 00:18:06]. They're rolling on the floor laughing. Obviously, his model of the world was violated. The object had to be in the cup and it wasn't This is funny.&quot; How do we get machines to learn models of That's what we don't know how to do. We aren't going to have truly intelligent Before we even get into the even more mind future, let's just talk about the next 10 Peter, when we talk about the distinction and the stuff that maybe humans can do and Well, I think that artificial narrow intelligence It's in every aspect of our lives now. I think we're going to continue in that direction. That alone is going to change our lives in our lives. We don't expect there to be general airplanes. We don't want them to do anything but fly We don't ask them to watch our children or The question then is, down the line, beyond can watch our children and fly and mow the Well, do we really want that? I think the next 10 years is really all about more powerful. The real hurdle is going to be the mental of the past five years and recognizing objects you provide lots of labels as in the ImageNet But I would argue that a lot of what we regard of what's invisible and cannot be easily labeled. So for example, the contents of other people's The backs of objects, the shapes of things, Our conscious experience is the ultimate model in the world right now in our bodies in that what's going on, causation, other minds, and That's going to be tricky to get to, this I think it's going to be very tricky for AI of information as informative short of full-blown them realized in our own experience, our subjective I think there's a long way to go. Yeah, you keep hearing about new areas of First, it was gaming and other things, driving us wrong. One area that AI has started to move into with computers, art and creativity. Hod Lipson, who was actually in that first artist, very sassy artist. This AI has actually created something that It's sassy. Right? Not so bad. We actually have a video of this being made How do we feel about this? Earlier we were talking about this and I guess creativity because it's just a copy, but then on the painting.&quot; My concern is that there's just not enough the future I wouldn't be surprised if we did machines. Ouch. Yeah. Sorry, Hod. AI has eclipsed humans. It takes a while but when it gets good at Suddenly it is officially better than chess Is it going to suddenly just be putting Mozart to human-written music anymore?&quot; No, I think it's going to help us be more It's going to be an amplification of our intelligence At the root of art, there is generally the Art is really about either evoking or communicating there is no point. If you put a machine that doesn't have emotion not communicate one. I like living nearby here because I'm walking I'm a huge jazz fan. Jazz is really about real-time communication It's like it's open door to the soul of the I don't see the point of having a machine to be... You're saying even if an AI could be programmed the deal, and knows exactly how the best jazz emotion, there's actually going to be, just audience knows that it's manipulating it. Objectively, it might not be missing, because that's actually produced by a human, but my will be different because they will know it It might take many decades, perhaps centuries by machine will change, but, eventually ...I in fact, a Nobel prize-winning economist called communication of emotion may take a while He said, &quot;Yeah, but eventually they'll at we won't be able to tell the difference.&quot; That's a very good point. I cringe a little bit when someone asks, &quot;Oh, Because you were joking earlier about how as soon as the machine figures out how to If you take the point of view that intelligence creativity is also just a certain kind of that we do with our brains, but then the question creative but simply are we smart enough to eventually. I have a lot of friends I respect who are be creative or even as intelligent as us because mysterious that can only exist in biological But, as a physicist, I consider that attitude I think it's arrogant to say that you can of meat. I'm made of exactly the same kind of electrons I eat and as my laptop. It's all about how the patterns in which the all about information processing the way I That makes sense. In the end, it's just the elementary particles Can I return for a moment to the creativity? Because I would argue that something like yet the real thing. I'm not saying it's impossible. We are existence proof that physical systems The kind of creativity I find to be most impressive our understanding of something like space way or take music and create a whole new form Now, these convolutional neural networks as given lots of examples of Mozart and then they then going to create a new form? I suspect the answer is no, that we're going deep unsupervised learning which is what babies Part of that, I think, is going to be moving person, face, to the verbs of the mind. Very central to human cognition is mental If you look at some of the first instances mind blowing. 30,000 years ago in a cave that is now near a human body, which took an operation of downloading it together, and then going and making it Now, modern examples would be lying in bed, thinking about how to fly and then he said, We can just pull the whole thing forward with Then, going and building it and making an Mental operations, this dynamic almost syntactic memory, is something that's very central to and I think is very different from this 'as learning with thousands of examples. True originality might be harder. Although, maybe humans are also ... We're Maybe it will be released of the burden, of originality. Maybe once it gets there, it could be super in every way. We have such a good way to show you that AI in some ways. It has to do with a movie called Sunspring that was fed thousands of screenplays. They said, &quot;Now, take all of that and write The AI did its best and they actually got the AI did. So, I'll let you judge for yourself, but ... Turn All right, you can't tell me that. Yeah, I was coming to that thing because you I don't know. I don't know what you're talking about. That's right. So, what are you doing? I don't want to be honest with you. You don't have to be a doctor. I am not sure. I don't know what you're talking about. I want to see you too. What do you mean? I'm sure you wouldn't even touch me. I don't know what you're talking about. Principle is completely constructed of the It's all about you to be true. You didn't even watch the movie with the rest I don't know. I don't care. I know it's a consequence. Whatever you need to know about the presence the floor. I don't know. I need you to explain to me what you say. What do you mean? Because I don't know what you're talking about. That? That was all the time. Would have been a good time. It's a little uneven right now. This is, again, the present right now and the next few years. What I want to move into now, which is really Max, what is artificial general intelligence now? Yeah, if we can have this picture up here, I like to think about this question in terms the elevation represents how hard it is for sea level represents what AI can do today. The sea level is obviously rising so there's the task landscape. The obvious take away from this is you should which will soon be disrupted by automation. The much bigger question that you're going Will it eventually submerge all land matching This is the definition of artificial general This has been the Holy Grail of AI research Right, it's so hard to understand because something that's generally intelligent on It's going to be something different than That is so mindboggling that we can't apply be something like that.&quot; It's going to be very hard for us to even Yann, you talk about that it's ... You almost Well, not only don't we have the technology so we don't know what principles the intelligent will be based on. Now, we like to think of ourselves as being We're actually very specialized as well. We're more general than, of course, all the very specialized. There's only certain things we do well and AlphaGo has proved in the recent years is We're really bad at Go. The stupid machine can beat us by a very, We're not very good at exploring trees, for that much memory. There's a lot of tasks like this that ... We're to another. This algorithm that runs on your GPS is much There are things like this that we're not We know how to do them somehow, but our brains Now, the thing is, you were talking about human intelligence. It will be very different from human intelligence is very easy to fall into which is to assume will have all the side effects if you want, They will not. For example, there is the traditional Terminator will become super intelligent and then they us all.There's a lot of people who have been inevitable and blah, blah, blah, or at least Now, the thing is, even in the human species, with intelligence. It's true. That is true. It's not like the people who are in leadership In fact, there is an evolutionary argument you want to be the chief. Because if you are smart to survive on your help you, but if you are stupid, you need The desire to take over is not correlated It's correlated with testosterone probably. Yeah. Tim, if I may just add a little bit to what I completely agree with you, Yann, of course, not something that we should worry about, bit more why, nonetheless, artificial general get there. First of all, it's important to remember that If you had artificial general intelligence replace your 40,000 engineers by 40,000 AIs to take breaks. Before too long, you could be incredibly rich of real power in the physical world. In that sense, it gives great power. Then, you can ask the question even if the break out and take over, do we want whatever AGI to unelected be able to take power over be shared more broadly? That's one example of why it's such a big A second example of why AGI, I think, would agree with you, Yann, that we humans are very often that I'm very dumb, there's so much special about human intelligence in the grand Because in the evolution of Earth, we have able to develop technology that might be able If we have machines, which can do everything to be used to develop ever better machines. It's still better and that can enable AI to bit smarter than us, but way smarter. That leads to this whole controversial discussion and so on that's also very controversial. Those are the two reasons why I feel that I agree with what you said. Let's also bring in, I think it's an elephant human level of beyond intelligent computers, Of all the different debates in AI that are most. You have people all over the place. Let's just define consciousness so we can Susan, what is consciousness to you? Well, it's the felt quality of experience. Right now, it feels like something from the Every moment of your waking life and even the world. Consciousness needs to be distinguished from A lot of people run them together at first To have a conscious is entirely different That's just what it is to be alert and alive. When you see the rich hues of a sunset, when you're having conscious experience. I completely agree that consciousness is a It's nothing else than that, but it's very representations over which mental operators The key operator, I think is attention, especially You might have locked-in syndrome and you radio or the TV, so you'd even then have a of your consciousness. Consciousness is for something. It's for these planning areas to have a world. In one sense, it's a veridical hallucination, not saying what's not there or it's saying It allows us to act in this world. That's only half of consciousness. The other half of consciousness is imagination. If I were to buzz you, probably about half about this or that, but we spend about half or our own creation. In this domain, we have total freedom. We can do anything and then we can go and Consciousness is for something and it takes The photons in the world hit your retina at at time zero. There's a lot of processing that goes on in then you experience a full-blown world that Yeah, I share the definition that you both When I drive down the street, I'm experiencing but does the self-driving car experience anything? That's a question I think we honestly don't I love how controversial this is. If you look up the word consciousness in the few years back, it says nothing of interest Even when I asked a lot of science colleagues, When I ask them why, I notice that they form each other about why it's B.S. Half of them say it's B.S. because, of course, You have to be made of meat to be conscious. Then, the other half says, &quot;Of course, this are just the same thing.&quot; In other words, anything that acts as if it To be contrarian, to most of my colleagues, between because I know that most of the information of, the heartbeat regulation and the vast Actually, when I look up and be like, &quot;Oh, information processing happens. What I'm aware of is just this CEO part of of the computation. Not only do I think it's not a B.S. question, long it's a B.S. question have actually been science question. 'Cause usually if you have a great science it's because people just dismissed it rather I think we need to do the hard work on this. If you're a physician in the emergency room in, wouldn't it be great to have a consciousness is in a coma and there's one home or whether If you have a helper robot, wouldn't you want guilty about switching it off? Or, whether it's just like a zombie so you to be happy about what you said? I'd like to know when we do these things. The question of consciousness is probably in the 18th century or 17th century or even how the eye works and that the image on the They were baffled by the fact that we see How is it that we don't see upside down because It was a big mystery. Now that we know what information processing absolutely no sense. The whole statement makes no sense. I think there are things about consciousness question, but there's a lot of contrarian at any moment not totally seriously because The fact, for example, that consciousness So, any intelligent entity will have to be sort of model of itself. That's, according to some definition, that There's another one that I like which I connect well, which is consciousness is actually a We can only focus our attention on one thing our brain is limited hardware. We have our prefrontal cortex that has to and cannot do multiple things at the same We have to have a process in our brain that configure our prefrontal cortex to solve the We interpret this as consciousness, but it's brain is so small, that if our brain was ten at the same time and maybe we wouldn't have Maybe we will have ten simultaneous consciousnesses. Is there a plural for consciousness? Is it consciousnesses? Consciousnesses. Let's go with that. Okay. It's not a collective word, is it? Yeah. I thought- I think we just don't know enough really to Let's start with Peter and then we'll go to All right, so bringing it back a little bit I think that why did consciousness evolve? Well, it's for something. It's for the frontal areas to be able to plan. You want to get the best representation of Now, in order to do that you need to take a disambiguated representation of the world Let's say I have a white-haired cat. It looks white to me because I want to recover that it's a white-haired cat. Now it runs under a shadow or a blue light. Well, the light actually reflecting off of my retina, but I want to discount that and I see it as a white cat that happens to be I want to recover it's intrinsically true It's the best representation of what's intrinsically Again, what got built into this quasi-hallucination the physical world, stories like causation Go to any party, next time you're at a party, and you say, &quot;I can turn the lights off,&quot; The person turns the lights off. Everyone's like, &quot;Wow, how did you do that?&quot; Because we are perceiving causation. We're also perceiving other minds. It's built into the construction. My guess is, that this is going to be very or general intelligence 'cause it's so central I understand what it's like for you to feel a broken heart because I once did. This is very central. I don't see how a system that has never felt about pain. Susan. That's interesting. I guess my general comment here, to go back related to consciousness and we could have We can only entertain maybe seven variables have trouble remembering phone numbers. Maybe consciousness is something we got that Now, if that's true though, suppose we do intelligent synthetic beings that are smarter conscious? Just because they look like, say, Hanson Robotics be conscious. Think about it. Do they need to have these limited capacity For example, a superintelligence could be Its computronium, its computational resources What would be novel to it requiring slow, Why would it be like us in any kind of meaningful What I want to suggest is that we pull apart as an empirical matter. If we want to figure out machine consciousness, whether that type of system has conscious it looks human it feels something. Yeah, I want to applaud you there for distinguishing consciousness, which are way too often conflated I think many people, for example, will say are going to become conscious and then suddenly in bad Hollywood movies.&quot; Somehow, it's the consciousness that you should That, I think, is a total red herring. Although I agree that consciousness is super view- Yeah, of course. ... in terms of whether you should worry or missile chasing after you is conscious or You only care about what it does and it's with some incredibly intelligent machine even In other words, consciousness isn't something That's not going to make any particular difference enormous moral difference. When I have colleagues who tell me that they because it's just philosophical B.S., I ask morality if you refuse to talk about consciousness What's wrong with torture if it's just, oh, this way rather than that way? It's all about the negativity of the subjective If we want to be moral people, we want to future, not just a bunch of zombies. This is a Nick Bostrom example. If there's a trillion simulations you're running trillion, then you're like, &quot;Okay, I got what The inflows, let's shut them all off.&quot; If they're not conscious, it's like closing There's nothing wrong with that. If those things are conscious, you just created human species. It's pretty relevant. It matters. Not if you have a backup. The reason why we care about each other is There is value to every human particularly person It's possible that we'll have the same we trained. We have a lot invested in that household robot, or dogs. We won't want that robot to get destroyed robot will go away. But, if we have a backup, it's okay to smash If you have an identical twin, can I just No, there is all kinds of interesting questions a physicist here. We invent a Star Trek style transporter. You get dematerialized. You get destroyed. You get killed and you get reconstructed at You experience death. This is a metaphor really for what is it that when an intelligent machine with its conscious As long as there's no pain involved, which As long as you have a backup or you can get But, if there's suffering- ... no information loss. If there's suffering then that's a different Yep. That's right. Then, consciousness does ... Okay, so now I ask the question, can machines You see, again, Star Trek Commander Data has emotions or not 'cause somehow you have intelligent I don't personally believe that it is possible machines without them having emotions. Emotion is part of intelligence. Now, we're going to have self-driving cars but it's because they're not going to be, they're not going to be autonomous intelligence. They're just designed to drive your car. If you're talking about autonomous intelligence, they do. They have some intrinsic drive that makes things, justify their lives maybe, but no You can't have a machine like this without ] Peter. Yeah, so I think it's a very interesting point the generation of artificial general intelligence. If you look at the evolution of animals, we of the emotions and the desires because they states within consciousness and they're often How would this get started? Well, you could imagine a fish that only responded It's stimulus present, it does this. If it sees a barracuda, it flees.Then, imagine memory. Now, when the barracuda peers behind a piece I know it's going that way. I'm going to go that way.&quot; The representation of the invisible became, The need for working memory is very central, Then, these teleological states that force really having these teleological states, these not garden paths, but desert paths. A garden path is when you know locally this is best and then you end up in the jaws of A desert path would be well locally I have but at the end of it, I might have a mate This is a big revolution that afforded us of input. Central to that also is the formation of mental physical and emotional as well as social. Actually, one of the big progress, a very the last years, is deep learning systems that Turing machines, things like that. Those are models that actually have a separate storing memory, short-term memory. Similar to we actually have a particular module sort of plays that role more or less of storing I think a very interesting place to look for systems will be not computers, but evolution's I think the most interesting one is the octopus the chordates, and we're sort of the culmination processing plus syntax. Then, some arthropods like praying mantises, neurons. The octopus has 500 million, comparable to If we want to understand computational principles this animal because there might be only so Convergent evolution found that there's only You need some sort of membrane. In the chordates, the bats did this and the but they all have in common flapping and membranes. There's only so many ways to build a wing. There might be only so many ways to build Some people have argued, for example, that completely or very analogous to our hippocampus Well, convergent evolution has brought us Precambrian. It was probably a little flatworm way, way That's really interesting because to go back if we could discover through thinking of both us like the octopus if there are universal anticipate the shape of superintelligence. Because after this panel, I have to confess, super intelligence Our basic behaviors, as humans, are driven The base of our brain, that's where human That's what drives a lot of our basic behaviors. Then our brain on top of this makes our behavior intelligent, actions, but our basic drives That's what computes whether we are happy us happy or not. It drives all of our behavior. We need this for intelligent machines. The fact that an intelligent machine will to have this kind of hardwired piece in its The big question is, how do you build it in with human values? It's going to be probably very difficult to We're going to be able to hardwire some very safe. For example, if you have a knife in your hand, around, sort of very basic things like this. There's probably thousands of rules like this What we're going to have to do is train those evil, behave in society and not injure people. Yeah, I hear people say it's the artificial intelligence once it's way better than we It's the last invention we'll ever make because that we think are hard ... It's like a monkey in and they look at the instructions and in That all these things, poverty, climate change, that is that level of intelligent. It's this utopia that we could be in if we So, you wouldn't have to invent anything in you. The other scenario is that it's ... I don't evil robots, that's anthropomorphizing.. It's the last invention we'll ever face then The stakes are monumentally high and this We only have a few minutes left. I really want to hear what you guys have to middle of a thriller movie in the climax of slowly in our minds so we don't see that what's choose-your-own-ending. How can we nudge this in the right direction? Yeah. If you're taking a big step back and looking here we are, we figured out how to replace That was the industrial revolution. Now, we're figuring out how to replace our Eventually, that's going to be AGI superintelligence. So, how can we make it good? I think Yann mentioned that the key challenge aligned with ours, it doesn't have to be a entities because we all did that when we were It worked out for us because their goals were How can we ensure that this will happen with Well, AI safety research is the answer. We're investing billions of dollars now into to invest money in developing the wisdom needed For example, applicable to what you said, make machines understand our goals, adopt smarter. All of those are really tough. If you tell your future self-driving Uber you get there covered in vomit and chased This isn't what I asked for.&quot; And, it goes, &quot;that's exactly what you asked Then, you appreciate how hard it is to make Raise your hand if you have kids. Then, you know how big the difference is between adopting your goals, doing what you want. Also, who's the parent deciding what the goals Well, in this case- ISIS thinks it's doing good. It does Yeah. We put a lot of effort into raising our kids. We need to put even more effort into raising machines that are more powerful than us. I actually disagree with this. Well, okay. Let's go down the line here. Some of the changes that will have to happen cultural side, the transformation of our cultures. For example, any technology can be used for A hammer can kill somebody or build a house. An airplane can transport people or bomb people. This is also true of AI, but the ethical systems sufficient to deal with this. 2,000 years ago there was ten bad things you sleep with his wife and don't steal his stuff,&quot; Commandment number 853,211, thou shalt not fireflies into tomato, no glow-in-the-dark Thou shalt not raise embryos for their dopaminergic Technology has driven ... There's now infinitely to come up with a new ethical framework for these infinitely many cases. I would say a first step would be thinking life and especially human life, but also life That which is harmful to life is not good. That way we can confront lots of things and but what should we do. I think we're in a fortunate situation actually will increase the chances of superintelligence actually has its first baby step doing something like better cybersecurity research so we don't Let's do those things better 'cause I think things like that now and who's going to trust We're going to get very non-powerful AGI before Our first AGI will have the autonomy and the Okay. I considered it a major success in my career fast, we have a machine that has the same a cat. The cat has 700 million neurons. We don't have the technology for this already. We don't have the science for it. Once we figure out the design of an intelligent, of a cat or a rat. It's not going to take over the world. With this, we can experiment to figure out behave in society and not kill everything Let me just point out that ... The thing that ... I'm sorry. Go ahead. Oh, no. Go ahead. Okay, thanks. Coming out of neuroscience, we just have really know the answer to yet. Science says it's all about what we don't One of these is what's the neural basis of Another is what is the neural code? The kind of neural networks that Yann has neural code involving changing weights. In recent years, something people have thought, the puzzle, but maybe there's other parts It's not simply about what's connected with is what underlies connectomics ... Rather of different connections, it's more like a sudden switches. This piece of track can be part of an epi-connectivity between Boston and San Francisco depending Maybe the neural code is actually a very dynamic changes. That's one direction. More recently, some people have argued, and that memories and information, in general, actually inside the cell. There's some really incredible work done by at UCLA, that I think has convincingly shown accessing the information, but the actual Glanzman says it's patterns of methylation Now, that's really radical. He's the only one saying that but if it's We have so far to go in understanding the of neural nets as understood in the brain in real brain science. My guess is once we crack the neural code, the cracking of the genetic code. All right, Susan. Very interesting. I want to hear it ... We have a couple minutes Susan, how do we make it good in the future? Well, we could have an AI that becomes AGI Whether it be based on the neural code in it could very quickly change its own architecture. Then, I wonder, how we'll be able to stay We have to hit the ground running on AI safety. I wholeheartedly agree with Max. I also wanted to add something which has not we need to think about this idea of merging Elon Musk has recently suggested that in order and to deal with the threat of super intelligence, I think that as a culture, we need to start looks like the Jetsons where they're unenhanced equipment. The AI will change us as well. I just want to leave you with that thought. I like that thought. Thank you. Thank you.