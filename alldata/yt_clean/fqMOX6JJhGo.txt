Hello and welcome to the Docker for beginners your instructor for this course. I'm a DevOps an interactive hands on online learning platform. for over 13 years and have helped hundreds of interactive way. In this course, you will learn animation illustration, and some fun analogies will show you how to install and get started with labs that you can access right in your browser. let's look at the objectives of this course. containers are, what Docker is, and why you might how to run a Docker container how to build your and how to use Docker compose what Docker registry then look at some of these concepts in depth. And the hood. We look at Docker for Windows and Mac container orchestration tools like Docker, swarm, labs. First of all, to complete this course, you set it up if you wish to, if you wish to have your as part of this course, we provide real labs that anytime and as many times as you want. The labs host and an accompanying quiz portal. The quiz the environment and gathering information. Or you Docker container. The quiz portal then validates lecture in this course is accompanied by makes learning Docker a fun activity. So I hope us begin. We're going to start by looking at and what it can do for you. Let me start by of my previous projects, I had this requirement including various different technologies, like as MongoDB, and a messaging system like Redis, a lot of issues developing this application stack their compatibility with the underlying OS was an services were compatible with the version of OS when certain version of the services were not and look at different OS that was compatible with to check the compatibility between the services We've had issues where one service requires one service requires another version, the architecture upgrade to newer versions of these components, or changed, we had to go through the same process components, and the underlying infrastructure. referred to ask the matrix from hell. Next, every really difficult to set up a new environment, of instructions and run hundreds of commands to sure they were using the right operating system, And each developer had to set all that up development tests and production environments. One the others may be comfortable using another one. that we were building would run the same way in our life in developing better Building and So I needed something that could help us with the us to modify or change these components without underlying operating systems as required. And I was able to run each component in a and its own libraries, all on the same VM or containers. We just had to build the Docker now get started with a simple Docker run command. system they're on. All they needed to do was systems. So what are containers, containers they can have their own processes or services, just like washing machines, except they all share means in a bit. But it's also important to note have existed for about 10 years now and some of like CFS, etc. Docker utilizes Aleksey containers. they are very low level and that is where Docker functionalities making it really easy for end let us revisit some basic concepts of operating like Ubuntu, Fedora, Susi or CentOS, they all of software. The OS kernel is responsible for the OS kernel remains the same, which is Linux. In these operating systems different. This software compilers, file managers, developer tools, etc. So OSS and some custom software that differentiate that Docker containers share the underlying the kernel? Let's say we have a system with an can run any flavor of OS on top of it, as long case, Linux. If the underlying OS is Ubuntu, distribution like Debian Fedora Susi or CentOS software that we just talked about in the different. And Docker utilizes the underlying OSS above. So what is an OS that do not share the able to run a Windows based container on a Docker Docker on a Windows Server. Now it is when I say there. That's not true. And they install Docker see it's possible. Well, when you install Docker you're not really running a Linux container on virtual machine under the hoods. So it's really Windows. We discuss more about this on the Docker you might ask, isn't that a disadvantage then not answer is no. Because unlike hypervisors, different operating systems and kernels on the to package and containerize applications and as many times as you want. So that brings us and containers, something that we tend to do As you can see on the right, in case of Docker, and then the OS and then Docker installed on run with libraries and dependencies alone. hypervisor like ESX on the hardware, and then each virtual machine has its own oil inside it. The overhead causes higher utilization of virtual operating systems and kernels running. The as each VM is heavy, and is usually in gigabytes and are usually in megabytes in size. This allows matter of seconds, whereas VMs as we know, takes entire operating system. It's also important more resources are shared between the containers from each other. Since VMs, don't rely on the types of applications built on different services same hypervisor. So those are some differences an either container or virtual machine situation. have large environments with 1000s of application you will often see containers provisioned on advantages of both technologies, we can use the or decommission Docker hosts, as required, at the easily provision applications and quickly scale we will not be provisioning that many virtual we provisioned a virtual machine for each machine for hundreds or 1000s of containers. So versions of applications readily available as of containerized and available in a public Docker For example, you can find images of most common and tools. Once you identify the images you need, an application is as easy as running a Docker run running a Docker run Ansible command will run an run an instance of MongoDB Redis and node j s multiple instances of the web service, simply a load balancer of some kind in the front. simply destroy that instance and launch anyone. such cases that we will look at later during on the commands. We'll get to that in a bit. let's understand the difference between the just like a VM template that you might have worked create one or more containers. Containers are have their own environments and set of processes. been dockerized already, in case you cannot find image and push it to Docker Hub repository, making traditionally, developers developed applications, manage it in production environments. They do as information about how the host must be set up, and how the dependencies are to be configured the application on their own, they struggle they work with the developers to resolve it. hand in hand to transform the guide into a Docker file is then used to create an image for their with Docker installed on it, and is guaranteed team can now simply use the image to deploy the when the developer built it, and operations are same way when deployed in production. And that's to the DevOps culture. Well, that's it for now. get started with Docker. We'll now see how to get the Community Edition and the Enterprise Edition. products. The Enterprise Edition is the certified enterprise add ons like the image management image and orchestrating container runtimes. But of more about container orchestration later in this we will go ahead with the Community Edition. Mac, Windows, or on cloud platforms like AWS, or at how to install and get started with Docker on you have two options, either install a Linux VM platform. And then follow along with the upcoming started with Docker. The second option is Docker desktop for Windows, which are native want the check out the Docker for Mac and the and then head back here. Once you're all and we will take a look at how to install Docker to install and get started with Docker. First machine or laptop that has a supported operating Doc's dot Docker comm and click on Get Docker. Edition page. That is the free version that we're type. I choose Linux In my case, and then select prerequisites and requirements. Your Ubuntu system like this called cosmic bionic or sannio. In my Etsy release file. Next uninstaller any older that there's none on my host. So I'll just copy are no older version that exists on my system. The the software. Now there are two ways to go about first updating the repository using the apt get packages, and then adding Dockers official GPG going to go that route. There is an easier way. find the instructions to install Docker using the the entire installation process and works on to download a copy of the script and then run the Docker automatically. Give it a few minutes to now successful. Let us now check the version have installed version 19.0 3.1. We will now run as expected. For this, head over to Docker Hub at most popular Docker images like nginx MongoDB, fun image called we'll say we'll say is Dockers application that trains a cow saying something. In run command given here. Remember to add sudo On running this command, Docker pulls the image runs it. And we have our avail, saying, hello. of this course, you don't really need to set up on labs that you will get access to but if you feel free to do so. We now look at some of the you will go through a hands on quiz where you will by looking at Docker run command. The Docker run running the Docker run nginx command will run an host if it already exists. If the image is not and pull the image down. But this is only done the same image will be reduced. The docker some basic information about them. Such as use to run the containers, the current status automatically gets a random ID and Name created summit. To see all containers running or not running as well as previously stopped or exited port fields shown in this output later in this commands. To stop a running container use the the container ID or the container name in the run the docker ps command to get it on success. docker ps again will show no running containers. container silly summit and that it is now an exit want this container lying around consuming space? Docker rm command to remove a stopped or exited we're good. Run the docker ps command again to what about the nginx image that was downloaded? At get rid of that image? But first, how do we see a images command to see a list of available images nginx Redis, Ubuntu and Alpine. We will talk about images. To remove an image that you no longer you must ensure that no containers are running the image. You must stop and delete all dependent ran the Docker run command earlier, it downloaded What if we simply want to download the image and we don't want to wait for it to download. Use the not run the container. So in this case, the image and stores it on our host. Let's look at container from an Ubuntu image. When you run the Ubuntu image and exits immediately. If you were to container running. If you list all containers, that the new container you ran is in an exit containers are not meant to host an operating task or process such as to host an instance of a or simply to carry some kind of computation the container exits a container only lives as web service inside the container is stopped, or you run a container from an Ubuntu image, it image of an operating system that is used as the process or application running in it by default. the case with Ubuntu, you could instruct Docker For example, a sleep command with a duration it runs the sleep command and goes into sleep for and the container stops. What we just saw was but what if we would like to execute a command the docker ps command, I can see that there is and sleeps 400 seconds. Let's say I would like to container. I could use the Docker exec command to case to print the contents of the Etsy hosts file. head over to the practice exercises. I'm now going application. The repository name is cloud slash listens on port 8080. When you run a Docker run in an attached mode, meaning you will be attached container. And you will see the output of the to do anything else on this console other than stops. It won't respond to your inputs. press the the application hosted on the container exits and run the Docker container in the detached mode the Docker container in the background mode, and container will continue to run in the backend, container. Now if you would like to attach back to command and specify the name or ID of the Docker ID of a container in any Docker command, you can just so it is different from the other container Now don't worry about accessing the UI of the web upcoming lectures. For now let's just understand with the Docker COI. So let's take a look at how Let me now walk you through the hands on lab associated with this course are available at code labs. This link is also given in the description links given there to access the labs associated remember to choose the right lab for your lecture. recommend to use Google Chrome while working with a terminal on the left and a quiz portal on the challenges to solve. Follow the quiz and try and given to you. Each scenario consists of anywhere Within 30 minutes to an hour. At the top, you have time for your lab below that is the question. look for hints in the head section, you may skip right corner. But remember that you will not be have skipped. If the quiz portal gets stuck for top to open the quiz portal in a separate window. running Docker, you can run any Docker command You will typically be running commands to solve around and experiment with this environment. But the quiz so that your work does not interfere with through a few questions. There are two types of exploratory multiple choice questions where you're environment and select the right answer. This is then asked to perform tasks like run a container, etc. Here, the first question asks us to find the host. Run the Docker version command in Then select the appropriate option from the given where it asks you to run a container using the click on hence and it will show you a hint. We Redis command, wait for the container to run. Once now successfully completed the task. Similarly, lab exercise is completed. Remember to leave a to note. These are publicly accessible labs that out during a peak hour, please wait for some time private or confidential data on these systems. purposes only and is only alive for an hour, after But you may start over and access these labs as I will also post solutions to these lab quizzes. those. That's it for now, head over to the first We will now look at some of the other Docker run through a hands on quiz where you will practice could use the Docker run Redis command to run a the latest version of Redis, which happens to be run another version of Redis like for example, version separated by a colon. This is called a photo zero version of Redis and runs that. Also, first command, Docker will consider the default to the latest version of that software, which So as a user, how do you find information about hub.com look up an image and you will find all the the software can have multiple short and long tags the version 5.0 dot five also has the latest tag prompt application that when run asked for my name if If I were to Docker eyes this application it wouldn't wait for the prompt. It just prints standard out. That is because by default, the input. Even though you're attached to its console, doesn't have a terminal to read inputs from it to provide your input, you must map the standard the dash I parameter. The dash I parameter is it prints the expected output. But there is when we run the app, at first, it asked us for our even though it seems to have accepted my input. terminal and we have not attest to the containers The dash T stands for a pseudo terminal. So with to the terminal, as well as in an interactive mode or port publishing on containers. Let's go back to in a Docker container on my Docker host. Remember called Docker host or Docker engine. When we run able to see that the server is running. But how see, my application is listening on port 5000. So But what IP do I use to access it from a web is to use the IP of the Docker container. Every in this case it is 172 dot 17 dot 0.2. Remember within the Docker host. So if you open a browser colon forward slash forward slash 172 dot 17 dot this is an internal IP users outside of the Docker we could use the IP of the Docker host, which you must have mapped the port inside the Docker For example, if I want the users to access my I could map Port 80 of local host to Port 5000 on in my run command like this. And so the user can colon slash slash 190 2.1 68 dot 1.5 colon 80. And routed to Port 5000 inside the Docker container. application and map them to different ports on applications on different ports. For example, in runs a database on my host and listens on the or another instance of MySQL on another port 8306. and map them to as many ports as you want. And Docker host more than once. We will discuss more in the network lecture later on. Let's now look For example, let's say you were to run a MySQL the data files are stored in location slash four the Docker container has its own isolated file the kernel. tainer let's assume you dump a lot were to delete the MySQL container and remove with all the data inside it gets blown away, like to persist data, you would want to map a host to a directory inside the container. In this data dir and map that to var lib MySQL inside and specifying the directory on the Docker host, Docker container. This way when Docker container directory to a folder inside the Docker container. external volume at slash RPT slash data directory. container. The docker ps command is good enough their names and IDs. But if you'd like to see use the Docker inspect command and provide the of a container in a JSON format, such as the state Remember to use it when you're required to find the logs of a container we run in the background. the dash D parameter and it ran the container which happens to be the contents written to the logs command and specify the container ID or how to work with the challenges and practice a simple web application written in Python. This that displays a web page with a background color. you will see a line that sets the background if you decide to change the color in the future, is a best practice to move such information out of variable called app color. The next time you run add color to a desired value. And the application packaged into a Docker image, you will then by the name of the image. However, if you wish to he would now use the Docker run commands dash the container. To deploy multiple containers with multiple times and set a different value for the the environment variable set on a container that's inspect the properties of a running container. of Environment Variables set on the container. environment variables in Docker. Hello, and lecture, we're going to see how to create your create your own image? It could either be because want to use as part of your application on Docker application you're developing will be dockerized I'm going to containerize an application a simple flask framework. First we need to understand we are creating an image for How the application If you want to deploy the application manually, order. I'm creating an image for a simple web I would start with an operating system like the abt command, then install dependencies using using the PIP command, then copy over the source and then finally, run the web server using the create a Docker file using this. Here's a your own image. First, create a Docker file named setting up your application in it, such as source code from and to and what the entry build your image using the Docker build command as a tag name for the image. This will create an on the public Docker Hub registry, run the Docker just created. In this case, the name of the image the image name, which is my custom app. Now Docker file is a text file written in a specific instruction and arguments format. For example, caps is an instruction. In this case from run, of these instruct Docker to perform a specific right is an argument to those instructions. The should be for this container. Every Docker image or another image that was created before based operating systems on Docker Hub. It's important from instruction. The run instruction instructs images. So at this point, Docker runs the abt get and installs required dependencies on the image. local system onto the Docker image. In this the current folder, and I'll be copying it over Docker image. And finally, entry point allows the image is run as a container. When Docker architecture. Each line of instruction creates changes from the previous layer. For example, the second instruction that creates a second layer the third instruction creates a third layer with that copies the source code over and the final Since each layer only stores the changes from as well. If you look at the base Ubuntu image, it are installed is around 300 Mb and the remaining you run the Docker history command followed by the you can see the various steps involved and the cast. So the layered architecture helps you in case it fails. Or if you were to add new steps all over again. All the layers built out cached by for example, in this case, step three failed, and it will reuse the previous layers from layers. The same is true if you were to add rebuilding your image is faster. And you don't image each time. This is helpful, especially when may change more frequently, only the layers above saw a number of products containerized such as etc. But that's just not it. You can containerize like browsers or utilities, like curl etc. Basically, you can containerize everything is going to run applications. Nobody is going to they're just going to run it using Docker. And easily without having to clean up too much. In and entry points in Docker. Let's start with a container from an Ubuntu image. When you run the Ubuntu image and exits immediately. If you were to container running. If you list all containers, that the new container you ran is in an exited containers are not meant to host an operating task or process, such as to host an instance of a simply to carry out some kind of computation container exits a container only lives as long as inside the container is stopped or crashes, the is run within the container. If you look at the you will see an instruction called CMD, which will be run within the container when it starts. the MySQL image. It is the MySQL D command. What a plain Ubuntu Operating System. Let us look at it uses bash as the default command. Now bash is server. It is a shell that listens for inputs exits. When we ran the Ubuntu container earlier, and launch the bash program. By default, Docker it is run. And so the bash program does not find that was started when the container was created, do you specify a different command to start the the Docker run command. And that way it overrides In this case, I run the Docker run Ubuntu command This way when the container starts, it runs the exits. But how do you make that change permanent? command when it starts. You will then create specify a new command. There are different ways of as a In a shell form, or in a JSON array format JSON array format, the first element in the array program did not specify the command and parameters should be separate elements in the list. So I now and name it as a boon to sleeper. I could now get the same results. It always sleeps for five the number of seconds it sleeps? Currently, it is One option is to run the Docker run command with sleep 10. And so the command that will be run very good. The name of the image, Ubuntu sleeper so we shouldn't have to specify the sleep command like this Docker run Ubuntu sleeper 10, we container should sleep and sleep command should entry point instruction comes into play. The entry As in, you can specify the program that will be specify on the command line, in this case, 10 command that will be run when the container starts two. In case of the CMD instruction, the command Whereas in case of entry point, the command line case, what if I run the open to sleeper image then the command at startup will be just sleep and So how do you configure a default value for the line, that's where you would use both entry point the command instruction will be appended to command would be sleep five, if you didn't specify then that will override the command instruction. specify the entry point and command instructions really want to modify the entry point during command? Well, in that case, you can override it command. The final command at startup would then and I will see you in the next. We now look at it creates three networks automatically. Bridge container gets attached to if you would like to specify the network information using the network at each of these networks. The bridge network is the host all containers attached to this network usually in the range 172 dot 17 series. The internal IP if required. To access any of these of these containers to port on the Docker host, the containers externally is to associate the any network isolation between the Docker host and a web server on port 5000. In a web app container, externally without requiring any port mapping This will also mean that unlike before, you will the same host on the same port, as the ports network. With the non network, the containers have any access to the external network, or other we just saw the default burst network where the associated to this default network will be able to isolate the containers within the Docker host, for network 172 and the second two containers on a Docker only creates one internal bridge network, the command Docker network, create and specify subnet for that network followed by the custom command to list all networks. So how do we see the existing container? Run the Docker inspect command find a section on network settings. There you can to its internal IP address, MAC address, and other their names. For example, in this case, I have a on the same node. How can I get my web server to thing I could do is to use the internal IP address is 172 dot 70 dot 0.3. But that is not very ideal will get the same IP when the system reboots. The All containers in a Docker host can resolve each a built in DNS server that helps the containers Note that the built in DNS server always runs at implement networking? What's the technology behind the host? Docker uses network namespaces that It then uses virtual Ethernet pairs to connect about it for now. More about these are advanced on Docker on code cloud. That's all for now. practice test and practice working with networking Hello and welcome to this lecture and we are lecture we're going to talk about Docker storage and how Docker stores data and how it manages how Docker stores data on the local file system. this folder structure at var lib Docker. You have image volumes, etc. This is where Docker stores files related to images and containers running on containers are stored under the containers folder. the image folder. Any volumes created by the folder. Well, don't worry about that for now. We just understand where Docker stores its files, store the files of an image and a container? Dockers layered architecture. Let's quickly recap it builds these in a layered architecture. Each a new layer in the Docker image with just the the first layer is a base Ubuntu Operating System, second layer, which installs all the Add packages. layer, which with the Python packages, followed over and then finally the fifth layer that each layer only stores the changes from the well. If you look at the base, a boon to image it that are installed is around 300 Mb, and then the advantages of this layered architecture, let's has a different Docker file. But it's very similar image as Ubuntu uses the same Python and flask to create a different application. And so the Docker build command to build a new image for both the applications are the same, Docker is not it reuses the same three layers it built and only creates the last two layers with the Docker builds images faster and efficiently saves update your application code. Whenever you update this case, Docker simply reuses all the previous application image by updating the latest source and updates. Let's rearrange the layers bottom up have the base Ubuntu layer, then the packages, of the application, and then the entry point. All build command to form the final Docker image. So build is complete, you cannot modify the contents can only modify them by initiating a new build. using the Docker run command, Docker creates a a new writable layer on top of the image layer. by the container, such as log files written by the container, or just any file modified by the user is only as long as the container is alive. When of the changes stored in it are also destroyed. all containers created using this image. If I were create a new file called temp dot txt, it will read and write. We just said that the files in the anything in those layers. Let's take an example of the image, the code is part of the image layer What if I wish to modify the source code to say be shared between multiple containers created from this file inside the container. Now, I can still file, Docker automatically creates a copy of the modifying a different version of the file in the be done on this copy of the file in the readwrite image layer being read only just means that the image itself. So the image will remain the same the Docker build command. What happens when we stored in the container layer also gets deleted, file we created will also get removed. So what if were working with a database, and we would like we could add a persistent volume to the container. volume create command. So when I run the Docker it creates a folder called Data underscore volume when I run the Docker container using the Docker the Docker containers rewrite layer using the run dash v then specify my newly created volume my container, which is the default location MySQL and then the image name MySQL. This will we created into var lib MySQL folder inside the is in fact stored on the volume created on the the data is still active. Now what if you didn't volume before the Docker run command. For example, instance of MySQL container with the volume data yet, Docker will automatically create a volume to the container. You should be able to see all lib Docker volumes folder. This is called volume Docker under the var lib Docker volumes folder. location for example, let's say we have some slash data. And we would like to store database Docker volumes folder. In that case, we will run But in this case, we will provide the complete is for slash data forward slash MySQL and so it the container. This is called bind mounting. So and a bind mount volume mount mount a volume a directory from any location on the Docker host. dash V is an old style. The new way is to use dash way as it is more verbose. So you have to specify example, the previous command can be written with source and target options. The type in this host and target is the location on my container. operations, maintaining the layered architecture, layers to enable, copy and write etc. It's the to enable layered architecture. Some of the common Overlay and overlay to the selection of the being used, for example, with a boon to the storage driver is not available on other operating device mapper may be a better option. Docker automatically based on the operating system. The performance and stability characteristics. So you application, and your organization. If you would please refer to the links in the that is all from the Docker architecture concepts. this lecture on Docker compose. Going forward, we so it is important that you are comfortable with first learned how to run a Docker container using complex application running multiple services, a Docker compose, we could create a configuration and put together the different services and the file. Then we could simply run a Docker compose stack is easier to implement, run and maintain compose configuration file. However, this is all Docker host. And for now, don't worry about the file in a bit and see how to put it together. put together. Let us look at a better example. that everyone uses to demonstrate Docker. It's by Docker to demonstrate the various features Docker. So let's first get familiarized with the same application in different sections through application which provides an interface for a user The application consists of various components developed in Python, to provide the user with a cat and the dog. When you make a selection, who are new to Redis Redis, in this case serves as by the worker which is an application written in and updates the persistent database, which is simply has a table with a number of votes for it increments the number of votes for cats as the vote is displayed in a web interface, which is resulting application rates the count of votes to the user. So that is the architecture and stack. As you can see, this sample application is different development tools, and multiple no js, dotnet, etc. This sample application will entire application stack consisting of diverse swarm services and stacks for a minute and see on a single Docker engine using first Docker run that all images of applications are already Let's start with the data layer. First, we run Redis. By running the Docker run Redis command, container in the background. And we will also name important. Why is that important? Hold that we will deploy the Postgres SQL database by time too, we will add the dash D option to run DB for database. Next, we will start with the app for voting interface by running an instance and name the instance vote. Since this is a web 80. We will publish that port to 5000 on the host we will deploy the result web application we deploy a container using the results stash the host. This way, we can access the web UI we deploy the worker by running an instance of we can see that all the instances are running on not seem to work. The problem is that we have but we haven't actually linked them together. As use this particular Redis instance, there could told the worker and the resulting app to use this how do we do that? That is where we use links. to link two containers together. For example, the service. When the web server starts, as you can looks for a Redis service running on host Redis. by the name Redis. To make the voting app aware running the voting app container to link it to the the Docker run command and specifying the name case is Redis followed by a colon and the name which is also Redis. In this case, remember that it the first time so we could use its name while it creates an entry into the EDC host file on the host name Redis with the internal IP of the the result app to communicate with the database by name dB. As you can see, in this source code of to a Postgres database on host dB. Finally, the Redis as well as the Postgres database. So we link to link the Redis and the other link to link is deprecated and the support may be removed in in some time Advanced and newer concepts in ways of achieving what we just did here with you learn the concept from the very basics. Once it is easy to generate a Docker compose file from names, we will use the same name we used in the create a key with each of them. Then under each the image and the value is the name of the image are the other options used. We published ports. containers. So we create a property called ports publish under that. Finally, we are left with create a property under it called links and Note that you could also specify the name of the target target name, and it will create a link with DB colon DB is similar to simply specifying dB, Now that we're all done with our Docker compose the Docker compose up command to bring up the example of the sample voting application, we of the five different components. Two of them available on Docker Hub. There are official images are our own application, it is not necessary the Docker registry. If we would like to instruct trying to pull an image, we can replace the image of a directory, which contains the application build the Docker image. In this example, for the folder named vote which contains all application the Docker compose up command, it will first and then use those images to run containers using build option to build the two other services at different versions of Docker compose file. This files in different formats at different places evolved over time, and now supports a lot more this is the trimmed down version of the Docker the original version of Docker compose file known For example, if you wanted to deploy containers on network, there was no way of specifying say you have a dependency or startup order of some come up first and only then I should the voting specify that in the version one of the Docker two. With version two and up, the format of the specify your stack information directly as you section. So create a property called services services underneath that. You will still use the application stack. But how does Docker compose free to use version one or version two depending know what format you're using. For version two compose file you're intending to use by specifying version, colon two. Another difference is with attaches all the containers, it runs to the enable communication between the containers as automatically creates a dedicated bridged network containers to that new network. All containers are other's service name. So you basically don't need you can simply get rid of all the links you file from version one to version two. And finally, If you wish to specify a startup order. For dependent on the Redis service. So you need to and only then the voting web application must to the voting application and indicate that it which is the latest as of today. version three meaning it has a version specification at the top your services just like in version two, make sure version three comes with support for Docker swarm, that were removed and added. To see details on using the link in the reference page. Following detail later, when we discuss about Docker compose. Getting back to our application. So far, default bridge network. Let us say we modify the from the different sources. For example, we would the applications internal traffic. So we create users, and a back end network dedicated for the user facing applications which are the voting and all the components to an internal back end note that I have actually stripped out there's still there, but they're just not shown to use networks is to define the networks we are front end and back end. So create a new property the services in the Docker compose file and add under each service, create a network's property be attached to. In case of Redis and dB. It's end applications such as the voting app and the a front end and back end network. You must also to the back end network. I have just omitted that you have seen Docker compose files, head over some Docker compose files. That's it for this We will now look at Docker registry. So what is they will rain from the Docker registry, which stored. It's a central repository of all Docker We run the Docker run nginx command to run closer look at that image name. Now the name is image pulled from? This name follows Dockers image repository name. When you say nginx, it's actually user or account name. So if you don't provide an is the same as the given name, which in this case Hub account name or if it is an organization, were to create your own account and create then you would use a similar pattern. Now, where we have not specified the location where these on Dockers default registry, Docker Hub, the DNS all the images are stored. Whenever you create a it to the registry and every time anyone deploys There are many other popular registries as well. where a lot of Kubernetes related images are end tests on the cluster. These are all publicly and access. When you have applications built in public. hosting an internal private registry may such as AWS, Azure, or GCP, provide a private them. on any of these solutions via Docker Hub, or you may choose to make a repository private, of credentials from Dockers perspective. To run a you first log into your private registry using Once successful, run the application using private if you did not log into the private registry, it found. So remember to always log in before pulling cloud providers like AWS or GCP provide a private But what if you're running your application on you deploy your own private registry within your application, and of course, is available as a and it exposes the API on port 5000. Now that you on this Docker host, how do you push your own to tag the image with the private registry URL same Docker host, I can use local host semi colon my image to my local private registry using the the Docker registry information in it. From there network using either localhost if you're on the host, if I'm accessing from another host in my head over to the practice test and practice Welcome to this lecture on Docker engine. at Dockers architecture, how it actually runs works under the hood. Docker engine as we have Docker installed on it. When you install Docker different components. The Docker daemon, the REST is a background process that manages Docker and networks. The Docker REST API server is the daemon and provide instructions, you could create CLA is nothing but the command line interface actions such as running a container stopping the REST API to interact with the Docker daemon. not necessarily be on the same host. It could be work with a remote Docker engine. Simply use the the remote Docker engine address and a port based on nginx on a remote Docker host, run the 2375 run ngi nx. Now let's try and understand how how does it work under the hood, Docker uses network, inter process communication, mounds their own namespace thereby providing isolation the namespace isolation technique. process ID it starts with just one process with a process off all the other processes in the system. we have a handful of processes running. This can running processes. The process IDs are unique ID. Now if we were to create a container, which is system, the child system needs to think that it its own set of processes originating from a root there is no hard isolation between the containers inside the container are in fact processes running cannot have the same process ID of one. This is ID namespaces. Each process can have multiple when the processes start in the container, it's base Linux system. And it gets the next available they also get another process ID starting with P visible inside the container. So the container so it is an independent system. So how does that a host? Let's say I were to run an nga next server runs and nginx service. If we were to list all the the next service running with a process ID of one. the container namespace. If we list the services but with a different process ID that indicates host but separated into their own containers using Docker host as well as the containers share the much of the resources are dedicated to the host and share the resources between the containers. much of a resource a container can use. And of the resources on the underlying host. But there a container can use. Docker uses thi groups or resources allocated to each container. This can to the Docker run command. Providing a value of not take up more than 50% of the host CPU at any value of 100 M to the dash dash memory option use to 100 megabytes. If you're interested in I posted in the reference page. That's it for now about other advanced topics on Docker storage and this course, we learned that containers share the have a Windows container running on Linux hosts going through this lecture, as it's very important with it. So what are the options available available. The first one is Docker on Windows Docker desktop for Windows option. We will look at option. Docker toolbox. This was the original have a Windows laptop and no access to any Linux Docker, you don't have access to a Linux system in I did was to install a virtualization software VMware Workstation and deploy a Linux VM on it the Linux VM and then play around with it. This really have anything much to do with Windows, or run Windows based Docker containers. You Windows either. You're just working with Docker on however, provides us with a set of tools to make The Docker toolbox contains a set of tools like Docker compose and a user interface called by simply downloading and running the Docker deploy a lightweight VM called boot to Docker, you are all set to start with Docker easily what about requirements, you must ensure that or higher and that the virtualization Docker toolbox is legacy version for older for the newer Docker for Windows option. The desktop for Windows. In the previous option, on Windows and then a Linux system and then Docker we take out Oracle VirtualBox and use the native called Microsoft Hyper V. During the installation automatically create a Linux system underneath. V instead of Oracle VirtualBox and have Docker on Hyper V. This option is only supported for and on Windows Server 2016. Because both support by default. Now here's the most important with Dockers support for Windows. It is strictly into Linux Docker images. We're not talking or Windows containers. Both the options we just Windows host. With Windows Server 2016, Microsoft first time. You can now package applications containers and run them on a Windows Docker host Docker desktop for Windows, the default option would like to run Windows containers, then you switch to using Windows containers. In early Now you could create Windows based images and like how you would run Linux containers on a containerize your applications and share them there are two types of containers in Windows. The works exactly like Linux containers where the OS system to allow better security boundary between versions and configurations to coexist. The V isolation. With Hyper V isolation each container guaranteeing complete kernel isolation between the the Linux world, you had a number of base images Alpine etc. If you remember that, that is what you the windows world, we have two options the Windows headless deployment option for Windows Server operating system. You can think of this like the though is not as light weight as you might are supported on Windows Server 2016 Nano Edition. Remember on Windows 10 professional isolated containers. Meaning as we just discussed, optimized virtual machine. Well, that's it about point out one important fact. We saw two ways of Hyper V. But remember, VirtualBox and Hyper So if you started off with Docker toolbox with remember you cannot have both solutions at the on Docker documentation page on how to migrate Thank you and I will see you the next lecture. We to Docker on Windows. There are two options to or Docker desktop for Mac option. Let's look at original support for Docker on Mac. It is Docker Windows It has nothing to do with Mac applications runs Linux containers on a Mac OS. Docker toolbox Docker engine, Docker machine, Docker compose, download and install the Docker toolbox lightweight VM called boot to Docker, which has os 10.8 or newer. The second option is the newer desktop for Mac, we take out Oracle VirtualBox during the installation process for Docker for system underneath. But this time it is created on Docker running on that system. This requires Mac hardware must be 2010 or newer. Finally, remember container on Mac. As of this recording, there are with Docker on Mac for now. We will now try to far in this course, we have seen that with Docker, with a simple Docker run command. In this case, Docker run node j s command. But that's just one what happens when the number of users increase, load, you deploy additional instance of your multiple times. So that's something you have to the load and performance of your application and that, you have to keep a close watch on the health you should be able to detect that and run the instance of that application. What about the crashes and is inaccessible? The containers hosted do in order to solve these issues, you will need state performance and health of the containers and But when you have large applications deployed not a practical approach. So you can build your issues. To some extent. container orchestration that consists of a set of tools and scripts environment. Typically, a container orchestration can host containers. That way, even if one fails, others. A container orchestration solution of instances of your application with a single we will look at the command itself in a bit. Some scale up the number of instances when users when the demand decreases. Some solutions can even to support the user load, and not just clustering also provide support for advanced networking as well as load balancing user requests across sharing storage between the house as well as within the cluster. There are multiple container has Docker swarm Kubernetes from Google and mezzos set up and get started. It lacks some of the complex production grade applications. mezzos on get started, but supports many advanced features. is a bit difficult to set up and get started but and has support for many different vendors. service providers like GCP, Azure and AWS and projects on GitHub and upcoming lectures. We will We will now get a quick introduction to Docker cover and requires its own course. But we will details so you can get a brief idea on what it is. Docker machines together into a single cluster. services or your application instances into balancing across different systems and hardware hosts or multiple hosts with Docker installed on manager or the master or the swarm manager as it you're done with that, run the Docker swarm in initialize the swarm manager. The output will also copy the command and run it on the worker nodes the workers are also referred to as nodes. And them on the swarm cluster. So let's get into an instance of my web server, I run the Docker run to run. This creates a new container instance of we have learned how to create a swarm cluster, how of my web server. Now one way to do this would node. But that's not ideal as I might have to log there could be hundreds of nodes that will have the state of each instance myself. And if myself. So it's going to be an impossible task. in. Docker swarm orchestrator does all of this for but we haven't seen orchestration in action. the Docker a service. Docker services are one or that runs across the saw the nodes in the swarm a Docker service to run multiple instances of my swarm cluster. For this, I run the Docker service, image name there, which is my web server in this number of instances of my web server I would like replicas, and I get three instances of my web nodes. Remember, the Docker service command worker node. The Docker service create command is options passed, such as the dash e environment the network option to attach container to introduction to Docker swarm, there is a lot more overlay networks, etc. As I mentioned, it requires In the next lecture, we will look at Kubernetes at to basic Kubernetes concepts. Again Kubernetes at least five, but we will try to get a brief able to run a single instance of an application command, which is great. running an application using the Kubernetes COI, known as cube control, with a single command Kubernetes can scale it up even configured to do this automatically so that up and down. based on user load Kubernetes can in a rolling upgrade fashion, one at a time it can help you roll back these images with a features of your application. By only upgrading testing methods. The Kubernetes open architecture and storage vendors. Any network or storage brand Kubernetes supports a variety of authentication service providers have native support for Docker and Kubernetes Kubernetes uses Docker containers. Well, it need not be Docker all the well, such as rocket, or a crier. But let's take Kubernetes cluster consists of a set of nodes, let or virtual on which a Kubernetes the Kubernetes worker machine. And that is where containers will on which the application is running fails? Well, to have more than one nodes. A cluster is a set of fails, you have your application still accessible who is responsible for managing this cluster? the cluster stored? How are the nodes monitored? the failed nodes to another worker node, that's with the Kubernetes control plane components in the cluster and is responsible for the actual When you install Kubernetes on a system, you're an API server and actually server, a cubelet a bunch of controllers and the scheduler. The API users management devices command line interfaces Kubernetes cluster. Next is the Etsy d a key value value store used by Kubernetes to store all data when you have multiple nodes and multiple that information on all the nodes in the cluster implementing a locks within the cluster to ensure scheduler is responsible for distributing work for newly created containers and assigns them orchestration, they're responsible for noticing goes down. The controllers makes decisions the container runtime is the underlying software it happens to be Docker. And finally, cubelet is The agent is responsible for making sure that the And finally, we also need to learn a little bit as the cube command line tool or the cube control control tool is the Kubernetes CLA, which is used cluster to get cluster related information to get other things. The Cube control run command is The Cube control cluster info command is used to control get nodes command is used to list all the instances of your application across hundreds command like this. Well, that's all we have for architecture. We currently have three courses on the absolute beginner to a certified expert. So we're at the end of this beginner's course experience. If so please leave a comment you will love my other courses hosted on my site Kubernetes advanced courses on Kubernetes courses for automation tools like Ansible visit code cloud@www.cloud.com. Well, thank you so