Hey, I'm Andy from deep lizard. And in this course, we're going to learn how in Python and integrated with TensorFlow. Throughout the course, each lesson will focus the full implementation in code using the We'll be starting with the absolute basics data, and then we'll move on to building and And some of these networks will be built from state of the art models for which we'll fine Now let's discuss the prerequisites needed From a knowledge standpoint, we'll give brief that we are going to work with before we go But if you're an absolute beginner to deep the deep learning fundamentals scores on the Or if you're super eager to jump into the course and the deep learning fundamentals will give you all the knowledge you need to concepts for which then you can come back And this course, in regard to coding prerequisites, Python experience or all that's needed. On peoples.com. You can also find the deep learning learning So you can see where this Kerris course falls Now let's discuss the Course Resources. So aside from the videos here on YouTube, available on peoples are calm. And actually each episode has its own corresponding and test your own knowledge. And you can actually contribute your own quiz And you can see how to do that on the corresponding Additionally, all of the code resources used including updates and bug fixes when needed. Download access to code files used in this lizard hive mind. So you can check out more about that on tables Alright, so now that we know what this course along with the prerequisites needed to get about Kerris itself. Kerris was developed with a focus on enabling So this allows us to go from idea to implementation Aside from this benefit, users often wonder to learn or in general, which neural network Our general advice is to not commit yourself that one forever, we recommend to learn multiple And the idea is that once you have a fundamental then the minor syntactical and implementation shouldn't really be that hard to catch on already, especially for job prospects. Knowing more than one neural network API will and contrast the differences between API's that certain API's may be better for certain Being able to demonstrate this will make you Now, we previously touched on the fact that So let's discuss that more. Now. Historically, Kerris was a high level neural against one of three separate lower level And those lower level API's were TensorFlow Later, though, Kerris became fully integrated a separate library that you can choose to that we discussed previously. So it's important to understand that cares API. But in this course, we are going to be focusing API without necessarily making much use of Now, before we can start working with cares, and installed onto our machines. And because Kerris is fully integrated with TensorFlow Kerris will come completely packaged So the installation procedure is as simple command line, you might just want to check website to make sure that your specific system to install. Alright, so we have one last talking point the coding. And that is about GPU support. So the first important thing to note is that if you're running your machine only on a CPU, doing in the course. If however, you do want to run your code on After you get through the setup process for we have a full guide on how to get the GPU Comm. So if you are interested in doing that, then But actually, I recommend just going through set up with a GPU. And like I said, the all the code will work a CPU. But then after the fact, after you go through in order to work with the GPU if you have in place from earlier, run it on the GPU, and see the kind of efficiency and speed ups Alright, so that's it for the Kerris introduction. Now we're finally ready to jump in to the Be sure to check out the blog and other resources as well as the dibbles at hive mind where rewards. Thanks for contributing to collective intelligence. Now, let's move on to the next episode. Hey, I may be from deep lizard. In this episode, we'll learn how to prepare use to train our very first artificial neural To train any neural network and a supervised samples along with the corresponding labels When referring to the word samples, we're set, where each data point in the set is referred If we were to train a model to do sentiment for example, then the labels that correspond or negative. Or say that we were training an artificial or dogs, well, then that would mean that each cat or dog. Note that in deep learning, you may also hear And you may hear labels referred to as targets When preparing a data set, we first need to be used. In our example, we'll be using our data set So once we understand this, then we can understand for us to be able to pass the data to the The first type of neural network that we'll from the cares API. And we'll discuss more details about the sequential But for now, we just need to understand what so that we can prepare our dataset accordingly. The sequential model receives data during on it. And again, we're going to go into more details But for now, let's check out what type of So if we look at the fit documentation here, two parameters that the fit function expects So x is our input data, our samples, in other data to be in a NumPy array, a TensorFlow set or a karass generator. So if you're not familiar with all of these example, we are going to organize our data So the first option here in the documentation, the Y parameter that is expected by the fit corresponding labels for our samples. So the target data. Now the requirement for why is that it is we just discussed for x, but y needs to be So we can't have our samples contained in y Our target data or our labels for those So the format of x and y, both need to match. And we're going to be putting both of those Alright, so now we know the data format that But there's another reason that we may want And that is to put it in a format that will to learn from. And we can do that with data normalization and deep learning will vary greatly depending So to start out, we are going to work with our model. And later, we'll get exposure to working with Alright, so now we're ready to prepare and So we are in our Jupyter Notebook. And the first step is to import all the packages random and some modules from scikit learn. Next, we will create two list one called train lists will hold the corresponding samples Now about this data set, we are going to be set. And so for this task, we're actually going Later, we'll work with more practical examples creating the data, but instead downloading But for now, we're going to create this data neural network. So as a motivation for this kind of dummy us an idea of what this data is all about. So let's suppose that an experimental drug 13 to 100. In a clinical trial, this trial had 2100 participants the age of 65. And half were 65 years or older. And the conclusions from this trial was that older population, so 65 or older, the 95% And around 95% of patients who were under Okay, so this is a very simplistic data set. And so that is the background story. Now in this cell, here, we're going to go data set. So what this is, is this first for loop is of younger individuals who did experience who did not experience side effects. So within this first for loop, we are first rather between 13 and 64. And that is constituting as a younger individual under 65 years of age. And we are going to then append this number And then we append a one to the train labels Now a one is representing the fact that a And a zero would represent a patient who did So then similarly, we jumped down to the next And we are generating a random integer between And we are doing that Remember, this is in So it's only running 50 times. So this is kind of the outlier group, these side effects. So we then take that sample appended to the corresponding train labels list. Since these patients were the older patients So then if we jumped down to the next for the same code here, except for this is the And this for loop, we're running this for experience side effects, as well as the 95% effects. So generating a random number between 13 and representing the age of the younger population label of zero. Since these individuals did not experience train labels list. Similarly, we do the same thing for the older Except for since the majority of these guys a one to the train The labels list. So just to summarize, we have the samples from 13 to 100. And then we have the train labels list that these individuals with the ages 13 to 100. The labels correspond to whether or not these So a samples list containing ages, a labels side effects, or no side effects. And just to get a visualization of the samples, in our list. And we see that these are just all integers, And then correspondingly, if we run our train there, then we can see this list contains Alright, so now the next step is to take these So we have our data generated. Now we need to process it to be in the format and we discussed the fact that we are going the fit function. So our next step is to go ahead and do that train labels list and making that now a NumPy Similarly, doing the same thing with the train And then we use the shuffle function to shuffle respective to each other so that we can get process. Okay, so now the data is in the NumPy array But as mentioned earlier, there's another on the data. And that is to either normalize or standardize the training of the neural network might become And so that's what we're doing in this cell. Now we are using this min max scalar object to one, which we'll then use in this next scale of 13 to 100, down to a scale of zero doing here is just a formality because the D data by default. Since our data is one dimensional, we have it to the fit transform function. So now if we print out the elements in our what we're calling our new scaled samples, the individual elements are no longer integers But instead, we have these values ranging So at this point, we have generated some raw array format that our model will expect. And then rescale the data to be on a scale we'll use this data to train our first artificial and other resources available for this episode hive mind where you can gain access to exclusive Thanks for contributing to collective intelligence. Now, let's move on to the next episode. Hey, I'm Andy from Blizzard. And this episode will demonstrate how to create model from the keras API integrated within In the last episode, we generated data from And now we'll create an artificial neural Alright, so first things first, we need to we'll be making use of to build our first And that includes everything that you see and categorical cross and vitry. categorical cross entropy, rather, those two not when we build it. But we're going ahead and bringing all the And then next, if you are running this code will allow you to make sure that TensorFlow as enable memory growth. And there's a few lines on the blog where and why you might want to do this. But if you are running a GPU then go ahead So next, this is the The actual model that And that is kind of the most simplest type TensorFlow. And a sequential model can be described as So if you look at how we're creating the model So we are initializing the model as an instance And we are passing in a list of layers here. Now, it's important to note that this first actually the second layer overall. So this is the first hidden layer. And that's because the input layer, we're input data is what creates the input layer So the way that the model knows what type input data, rather, is through this input dense layer. So through this, the model understands the And then therefore it accepts that shape, to the first hidden layer, which is this dense this dense layer that we want it to have 16 These units are also otherwise known as nodes And the choice of 16 here is actually pretty This model overall is very simple. And with the arbitrary choice of nodes here, a simple model, at least, that won't do a the simplicity of the data itself. So we understand that we're passing in, or hidden layer, we are specifying the input the input data to expect and then we are stating to follow this dense layer. Now, this input shape parameter is only specified So after that, we have one more hidden, dense This time, we are arbitrarily setting the 32. And again, we're following the layer by the And then lastly, we specify our last output layer. This is another dense layer, this time with to the two possible output classes. Either a patient did experience side effects, And we're following this output layer with to give us probabilities for each output class. So between whether or not a patient experience probability for each class, letting us know patient. And just in case, it's not clear, this dense layer or a fully connected layer, probably neural networks. Now in case you need any refresher on fully or anything else that we've discussed up to is covered in the deep learning fundamentals your memory on any of these topics here. Alright, so now we'll run this cell to create And now we can use model dot summary to print the model we just created. So looking here, we can just see the visual just created in the cell above. All right, so now we have just finished creating and intuitive sequential model type. In the next episode, we will see how we can train this network. Be sure to check out the blog and other resources as well as the tables at hive mind where you Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. In this episode, we'll see how to train an API integrated with TensorFlow. In previous episodes, we went through steps neural network. So now we'll bring these two together to actually and processed. Alright, so picking up where we were last you still have all of your imports included we were before. So first we have after building our model, And this just prepares the model for training. So it gets everything in order that's needed So first, we are specifying to the compile and we're choosing to use the very common And next we specify the type of loss that going to use sparse categorical cross in but entropy. And then lastly, we specify what metrics we So this is just for the model performance, by and we are specifying this list, which way to be able to evaluate model performance. So if we run this cell, alright, so the model And training occurs whenever we call this Now recall earlier in the course, we actually function, so that we knew how to process our So to fit the first parameter that we're specifying is currently stored in this scaled at train data, or our labels are labels are currently So we are specifying that here. Next, we specify our batch size that we want So this is how many samples are included in network at one time. So we're setting this to 10. And the number of epochs that we want to run, So that means that the model is going to process 30 times before completing the total training Next, we're specifying this shuffle, shuffle Now, by default, this is already set to true, to show or to make you aware of the fact that we pass it to the network, which is a good of the dataset to be kind of erased before model is not necessarily learning anything So this is true by default. So we don't necessarily have to specify that And actually, we'll see something about that regarding validation data, but we'll see that The last parameter that we specify here is us to see output from whenever we run this So we can either set it to 01, or two, two messages. So we are setting that here so that we can So now let's run this cell so that training All right, so training has just stopped. And we have run for 30 epochs. And if we look at the progress of the model, our loss value is currently point six, eight So no better than chance. But pretty quickly looking at the accuracy, all the way until we get to our last a POC, And our loss has also steadily decreased from two seven. So as you can see this model train very quickly, to run. And within 30 epochs, we are already at a Now although this is a very simple model, we can see that without much effort at all, in a relatively quick manner of time as well. In subsequent episodes, we'll demonstrate as more complex data. But for now, hopefully this example served it is to get started with Kerris. Be sure to check out the blog and other resources As well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. In this episode, we'll demonstrate how we validation set on the fly during training. Before we demonstrate how to build a validation exactly a validation set is. So whenever we train a model, our hope is from the training output, that we have low But we don't ever train a model just for the model and hopefully be able to use it in some to during the training process. And although this new data is data that the the model will be good enough to be able to accurate predictions for it, we can actually is generalizing by introducing a validation a validation set. Before training begins, we can choose to take it into a separate set labeled as validation And then during the training process, the and then we'll validate on the separated validation So what do we mean by validating? Well, essentially, if we have the addition the model will be learning the features of But in addition, in each epoch, after the process, it will take what it's learned from on the data in the validation set, using only though. So then during the training process, when loss, not only will we be seeing that accuracy also see that computed on the validation set. It's important to understand though, that on the training data. It's not taking the validation set into account The validation set is just for us to be able on data that it was not exposed to during In other words, it allows us to see how general on data that is not included in the training So knowing this information will allow us overfitting problem. So overfitting occurs when the model has learned really well, but it's unable to generalize So if while training, we see that the model set, but less than good results for the validation overfitting problem, and then take the steps If you'd like to see the overfitting problem for that in the deep learning fundamentals Alright, so now let's discuss how we can create model, there's actually two ways that we can a sequential model. And the first way is to have a completely set. And then to pass that validation set to the data parameter. And so we can just set that equal to the structure And there's a write up in the corresponding about the format that that data needs to be But we're going to actually only focus on set. This step actually saves us a step because creation process, the validation set, instead, Alright, so we're back in our Jupyter Notebook And we're here on the model dot fit function. And recall, this is what we use last time Now, I've already edited this cell to include And what validation split does is it does of the training set into a validation set. So we just set this to a number between zero So just a fractional number to tell Kerris out into the validation set. So here I'm splitting out 10% of the training So it's important to note that whenever we held out of the training set. So the training samples that we remove from longer contained within the training data So using this approach, the validation set the fit function. Now, there's one other thing worth mentioning And remember last time, I discussed this shuffle And I said that by default, the training set So this shuffle equals true is already set But I was just bringing it up to let you know So that is a good thing, we want the training But whenever we call validation split in this set is shuffled, meaning that if we created sick patients first and then the non sick to split off the last 10% of the training to take the last 10% of the training data. And therefore it could just take all of the set and not get any of the first group. So I wanted to mention that because although fit function, if you haven't already shuffled then you also use the validation split parameter, set is going to be the last X percent of your and may yield some strange results because when really, it's only the training set has been taken out. So just keep that in mind the way that we Before this episode, we actually shuffled to the fit function. So in the future, whenever you're working your data is also shuffled beforehand, especially split parameter to create a validation set. Alright, so now we'll run this cell one more But this time, not only will we see loss and also see these metrics for the validation Alright, so the model has just finished running And now we see both the loss and accuracy loss and validation accuracy on the right So we can see, let's just look at the accuracy They're both starting at around the same 50% rate. So we just scroll all the way to our last accuracy are pretty similar with only 1% difference And yet the loss values are similar as well. So we can see in this example that our model pretty well or just as well rather on the So our model is generalizing well. If however, we saw that the opposite case seriously lagging behind our training accuracy, and we would need to take steps to address Alright, so we've now seen how to train the make use of both training and validation sets. In the next episode, we're going to see how data set. To use the model for inference. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. In this episode, we'll see how we can use on data from a test set using TensorFlow keras As we touched on previously, whenever we train that model and use it on new data that it the model is able to generalize well. And give us good results on this new data. So as a simple example, suppose that we trained cats or dogs. And so during the training process, of course, from a website with 1000s of images of cats So the hope is later that if we wanted to, And we could have people from all over the have our model, tell them with high accuracy, dog. So I don't know why anyone would actually The hope is that even though the images that have their own cats and dogs, even though that the model was originally trained on. Hopefully, the models able to generalize well about dog and cat features, that it can predict a cat, for example, we call this process inference. So the model takes what it learned during infer things about data that it hasn't seen In practice, we might hold out a subset of test set. Typically, after the model has been trained for inference purposes against the test set, to make sure that the model is generalizing So at this point, the model that we've been been trained and validated. And given the metrics that we saw during the the model is probably going to do a pretty In order to conclude that though, we first So we're going to do that now. And then after we create the test set, then Alright, so we are back in our Jupyter Notebook. And now we're going to go through the process And actually, if you just glance at this code of setting up the the samples and labels list clinical trial that we discussed in a previous data and putting it into a NumPy array format, the data to be on a scale from zero to one, So actually, that is the same exact process we're working with our tests, labels, and labels and train samples. So we're not going to go line by line through If you need a refresher, go check out the process for the training set. The important thing to take from this process, and processed in the same format as the training So we'll just go ahead and run the cells to data. And now, we are going to use our model to So to obtain predictions from our model, we in the last couple of episodes. So we are calling model dot predict. And we are first passing in this parameter test samples. So that is what we created in just the line be on a scale from zero to one. So this is the data that we want our model Then we specify the batch size, and we are is the exact same batch size that we use for as well. And then the last parameter we're specifying equal to zero, because during predicting there we actually care about seeing or that is going So we're setting that equal to zero to get Alright, so then if we run this, so then our set. And if we want to have a visualization of looks like for each sample, we can print them So looking at these predictions, the way that within our test set. So for each sample in our tests that we are The patient not experiencing a side effect, So for the first sample in our test set, this is assigning a 92% probability to this patient, around 8% probability of the patient experiencing So recall that we said, no side effect experience was labeled as a one. So that is how we know that this particular because it's in the zeroeth index. And this specific probability maps to having So if we're interested in seeing only the the test set, then we can run this cell here, the index of the prediction with the highest And if we print that out, then we can see than the previous output. So we can see for the first sample that the one. And just to confirm, if we go back up here, the higher probability of a label of zero, And the second sample has a higher probability a side effect. So from these prediction results, we're able But we're not able to make much sense of them predictions, because we didn't supply the same way that we do during training. This is the nature of inference. A lot of times inference is occurring once So we don't necessarily have correct labels If we do have corresponding labels for our because we are the ones who generated the results by plotting them to a confusion matrix. And that'll give us an overall idea at how test data. We'll see exactly how that's done in the next Be sure to check out the blog and other resources as well as the tables at hive mind where you Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. In this episode, we'll demonstrate how to results from a neural network during inference. In the last episode, we showed how we could contained in a test set. Although we have the labels for this test inference, and so we don't get any type of on the test set. Using a confusion matrix, we can visually data. Let's jump right into the code to see exactly We'll be using scikit Learn to create our So the first thing we need to do is import use of next week create our confusion matrix from scikit learn. And we pass in our test labels as the true And we pass in our predictions as the predictions recall this rounded predictions variable, These were created in the last episode. So rounded predictions recall was when we most probable predictions. So now our predictions are in this format. And then our labels are zeros and ones that side effects or not. So next we have this plot confusion matrix And this is directly copied from socket learns There's a link to the site on the corresponding But this is just a function that socket learn notebook, the confusion matrix, which is going to see. So we just run this cell to define that function. And now we create this list that has the labels In matrix, so we want, the labels have no Those are the corresponding labels for our confusion matrix function that we just brought And to that we are going to pass in our confusion And the classes for the confusion matrix which defined just right above. And lastly, just the title that is going to matrix. So if we run this, then we actually get the Alright, so we have our predicted labels on So the way we can read this is that we look patient had no side effects 10 times when So that's incorrect predictions. On the flip side, though, the model predicted that the patient indeed had no side effects. So the this is the correct predictions. And actually, generally reading the confusion right diagonal, these squares here and blue predictions. So we can see total that the model predicted So 396 correct predictions out of a total So all these numbers added up equal 420 396 So that gives us about a 94% accuracy rate we were seeing for our validation, accuracy So as you can see, a confusion matrix is a how well our model is doing edits predictions, further to see for which classes it might and other resources available for this episode hive mind where you can gain access to exclusive Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. And this episode will demonstrate the multiple model. We have a few different options when it comes model. And these all work a little bit differently So we're going to go through all of the options. Now. We've been working with a single model over And we're going to continue working with that Now, I've printed out a summary of that model been working with. But just make sure that in your Jupyter Notebook because we're going to now show how we can Alright, so the first way to save a model So to save, we pass in a path for which we name or the file name that we want to save So this h5 file is going to be where the model And this code here is just a condition that saved to disk first, then save it because over and over again, on my machine if it's So that's what this this condition is about. But this model dot save function is the first Now when we save using this way, it saves to be able to recreate it with the same number etc. It also saves the weights of the model. So if the models already been trained, then for are going to be in place within this saved It also saves the training configuration. So things like our loss and our optimizer and the state of the optimizer is also saved. So that allows us if we are training the model, then we can later load that model again and the state of the optimizer will be in that So this is the most comprehensive option when everything, the architecture, the learnable where it left off with training. So if we want to load a model later that we first import this load model function from And then we create a variable. In this case, I'm calling it a new model, pointing to where our saved model is on disk. So then, if we run that, and then look at it is an exact replica in terms of its architecture previously saved to disk. Also, we can look at the weights of the new of time to be able to compare them directly. But this is showing you that you can inspect that the weights are actually the same as If you were to have taken a look at those We can also look at the optimizer just to explicitly for our new model, because we are use the atom optimizer that we set a while Alright, so that's it for the first saving And again, that is the most comprehensive particular model. The next option that we'll look at is using So we call model.to. json, if we only need to save the architecture So we don't want to set its weights or the the model architecture by saving it to a JSON So I'm using this example here, creating a to model.to. json. And remember, model is our original model this point. So we call to JSON. And now if we print out this JSON string, about the model architecture. So it's a sequential model. And then it's got the layers organized, with about those specific layers from our original Now, if at a later point, we want to create then if we save it to a JSON string, then from TensorFlow Kerris dot models. And now we're creating a new variable called And we are loading in the JSON string using So now we have this new model, which I'm just And if we look at the summary of that, then the summary of the original model. So we have a new model in place now, but we So you would have to retrain it to update And we would need to compile it to get an that defined, this only creates the model Before moving on to our third option, I just go through this same exact process, but using So the function to create a gamble string And then the function to load a YAML string of model from JSON. Alright, so our next option to save a model model. So if you only need to save the weights, and any of the training configurations, like the models weights by using the Save weights function. So to do that, we just call model dot save And this looks exactly the same as when we a path on disk to where to save our model five extension. So I'm calling this my model weights dot h And again, we have this condition here where already been saved to disk, otherwise, I'm again. Now, the thing with this is that when we save at a later time, then we don't have a model model itself. We only save the weights. So to be able to bring in our weights to a a second model at that point with the same And then we could load the weights. And so that's what we're doing in this cell. I'm defining this model called model two. And it is the exact same model from an architecture So if we run this, then at that point, we model. And the shape of these weights is going to architecture is essentially. So we couldn't have a model with five layers weights in because there wouldn't be a direct should be loaded. So that's why we have the same exact architecture So to load our weights, we call load weights. And we point to the place on disk where our And then we can call get weights on our new populated with weights from our original model. Alright, so now you know all the ways that model. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now, let's move on to the next episode. Hey, I may be from people's or, in this episode, and processing steps needed to train our first Our goal over the next few episodes will be network that can classify images as cats or get and prepare our data set for which we'll We're going to work with the data set from And you can find a link to download the dataset on people's are.com. So we're mostly going to organize our data But there's a couple of manual steps that So after you've downloaded the data set from And if we look inside, then this is the contents test folder along with the sample submission So we actually are not going to be working So you can delete the test that as well as with this train zip. So we want to extract the high level cats, the train zip. So because that takes a while I went ahead So now I have just this train directory because the CSV file. So now I have this extracted train folder. And I go in here and I have a nested train As you can see, I'm already in train once. Now I'm in train again. And in here we have all of these images of Okay, so that is the way that the data will The first step, or the next step that we need of these images. And we're going to Ctrl x or cut all of these So we don't want this nested directory structure. Instead, we're going to place them directly Alright, now all of our images have been copied So this nested train directory that the images So we can just go ahead and delete this one. Alright, so now our directory structure is we have a train directory. And then we have all of the images within Both of cats and dogs. The last step is to just move the dogs versus to be in the place on disk where you're going So for me, I am in relative to my Jupyter and I have placed dogs versus cats here. Alright, so that's it for the manual labor the data, and then later process the data Alright, so we're now here within our Jupyter And First things first, we need to import of and all of the packages here are not just data. But actually, these are all of the packages several episodes as we're working with cn Alright, so we'll get that taken care of. And now, just this cell here is making sure to identify it correctly, and we are an enabling If you're not using a GPU, then no worries, to follow this course with a CPU only. Alright, so now we're going to pick back up So assuming that we've gone through the first we're now going to organize the data and to to our training validation and test sets. So this group here is going to first change And then it's going to check to make sure to make does not already exist. And if it doesn't, it's going to proceed with So the first thing that it's doing as long in place, is making the following directories. So we already have a train directory. So it's going to make a nested dog and cat And then additionally is going to make a valid and a test directory, which also contains Now, this particular data set contains 25,000 And that is pretty much overkill for the tasks In the upcoming episodes, we're actually only you're free to work with all the data if you'd But it would take a lot longer to train our if we were using the entire set of it. So we are going to be working with a subset set 200 in our validation set, and 100 in to be split evenly among cats and dogs. So that's exactly what this block of code It's going into the images that are in our moving 500 cat images into our train cat directory And then similarly doing the same thing for for cat and dogs and then our test set, both differing regarding the amounts that I stated And we're able to understand which images of the files. So if you saw earlier, the cat images actually the dog images had the word dog in the file So that's how we're able to select dog images Alright, so after this script runs, we can directory structure and make sure it is what So we have our dogs vs cat directory within So if we enter, then we have test train and Inside test, we have cat that has cat images, If we back out and go to train, we can see And if we go into valid we can see similarly. And you can select one of the folders and files exist within the directory to make sure put in from our script and that we didn't So if we go back to the dogs vs cats the root these cat and dog images leftover. These were the remaining 23,000 or so that our train valid and test directories. So you're free to make use of these in any to another location. All of what we'll be working with are in these Alright, so at this point, we have obtained Now it's time to move on to processing the So if we scroll down, first, we are just creating our train valid and test paths. So this is just pointing to the location on Now recall earlier in the course, we talked we need to put the data into a format that And we know that when we train a karass sequential we call the fit function. So we are going to put our images and do the And we're doing that in this cell here. We're creating these train valid and test generator dot flow from directory, which is Basically, it's going to create batches of reside. And these batches of data will be able to fit function. So now let's look exactly at how we are defining So let's focus just on train batches for now. So we're setting train batches equal to image But first to image data generator, we are setting that equal to tf Kerris dot applications So I'm just going to tell you for now that some type of pre processing on the images we'll be using. And we're processing them in such a way that model known as VGG 16, we're processing our that get passed to this VGG 16 model our process. And we're going to talk about more about this So don't let it confuse you now just know to occur on our images. And we'll talk more about it in a future episode necessarily very important for us right at at least. So besides that, when we call flow from directory, data and specifying how we want this data So we are setting directory equal to train on disk where our training set was under the And then we're setting target size equal to So this is the height and width that we want So if you're working with an image data set want to scale them up or scale them down, And this will resize all images in your data passing them to our network. Now we are specifying our classes, which are of our data set. So cat or dog, and we are setting our batch We do the exact same thing for the validation And the test set. Everything is the exact same for both of them, disk as being specified here under the directory And then the only other difference is here We are specifying this shuffle equals false Now, this is because whenever we use our test to predict on images of cats and dogs after we're going to want to look at our prediction in a previous video for a separate data set. And in order to do that, we need to be able set. So that's why we set shuffle equals false For both validation and training sets, we Alright, so we run this and we get the output And that is corresponding to our train batches which corresponds to valid valid batches, corresponding to our test batches. So that is the output that you want to see That's letting you know that it found the and dog classes that you have specified here. So if you are not getting this at this point, you're pointing to the wrong place on disk. You just need to make sure that it's able Right and here we are just verifying that Now Next, we are going to just grab a single from our train batches. And remember, our batch size is 10. So this should be 10 images along with the Next, we're introducing this function plot images from our train batches that we just And this function is directly from tensor So check the link in the corresponding blog To see, to be able to get to the tensor flows So we will define this function here. Alright, so now we're just going to use this batches here. And we're going to print the corresponding So if we scroll down, we can see this is what So this might be a little bit different than looks like the color data has been a little And that's due to the pre processing function such a way that in the same type of way that 16 model. So like I said, we're going to discuss in is doing technically, as well as why we're But for now, just know that it's skewing the So we can still make out the fact that this And this looks like a cat. This is the dog, dog, dog, dog cat. Yeah, so we can still kind of generally make is skewed. But don't worry too much about the technical For right now, just know that this is what model. And here are the corresponding labels for So we have these one hot encoded vectors that So a one zero represents a cat, and a zero, Okay, so I guess I was wrong earlier with This one is a cat, because as we can see, And if you don't know what I mean by one hot video for that in the deep learning fundamentals But yeah, we can see that 01 is the vector So this one is a dog. And the next two are dogs as well, this one Now, just a quick note about everything that we do not have the corresponding labels for So in the examples that we've done so far, labels for our test set. But in practice, a lot of times you may not And in fact, if we were to have used the downloaded then we would see that that test directory cat or dog. So in this case, we do have the test labels them from the original training set from kaggle But if you don't have access to the test labels, test data accordingly, then check the blog section there that demonstrates what you need video if you do not have access to the labels Alright, so now we have obtained our image accordingly for our convolutional neural network. So now in the next episode, we are going to our first CNN. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. And this episode will demonstrate how to build it on images of cats and dogs using tensor We'll be continuing to work with the cat and episode. So make sure you still have all of that in in in the last episode as well as we'll be For the next several videos of working with making use of the Kerris sequential model. And recall, we introduced this model in an just plain simple numerical data. But we'll continue to work with this model So the first layer to this model that we pass So this is just our standard convolutional And to this layer, we're arbitrarily setting So this first convolutional layer will have three. So the choice of 32 is pretty arbitrary, but common choice for image data. Now, this first column to D layer will be And we are specifying padding equals Same And this just means that our images will have the dimensionality of the images aren't reduced So lastly, for our first layer only, we specify And recall we touched on this parameter previously, an implicit input layer for our model. This comp 2d is actually our first hidden data itself. And so we just need to tell the model the is going to be 224. By 224. Recall, we saw that we were setting that target Whenever we created our valid test and train our images to be of this height and width. And then this three here is regarding the Since these. Since these images are an RGB format, we have input shape. So then we follow our first convolutional setting our pool size to two by two and our And if you are familiar with Max pooling, dimensions in half. So if you need to know more about max pooling, padding here for zero padding, activation to check those episodes out and the corresponding or.com. So after this max pooling layer, we're then looks pretty much exactly the same as the the input shape parameter, since we only specify specifying the filters to be 64 here instead So 64 is again, an arbitrary choice, I just But the general rule of increasing functions is common practice, we then follow this second layer identical to the first one, then we tensor before passing it to our dense output to cat and dog. And our output layer is being followed by as you know, is going to give us probabilities Alright, so if we run this, we can then check And this is what we have exactly what we built, learnable parameters and the output shape So these are things that are also covered as well, if you want to check out more information So now that our model is built, we can prepare which again, we have already used in a previous data. But as you will see here, it looks pretty optimizer equal to the atom optimizer with And we are using categorical cross entropy. And we are looking at the accuracy as our Just a quick note before moving on. We are using categorical cross entropy. But since we have just two outputs from our to instead use binary cross entropy. And if we did that, then we would need to model instead of two And then rather than activation function, we would need to follow And both of these approaches using categorical have here, or using binary cross entropy loss equally well, they're totally equivalent, cross entropy, and using softmax on the app, layer, or just a common approach for when So I like to continue using that approach, it's general. And it's the case that we're going to use so I just like to stick with using the same outputs. Alright, so after compiling our model, we we should be very familiar with up to this So to the fit function, we are first specifying batches. And then we specify our validation data, which Recall, this is a different way of creating episode, we're not using validation split set separately ourselves before fitting the So we are specifying that separated set here are setting our epochs equal to 10. So we're only going to train for 10 runs this two so that we can see the most verbose output And one other thing to mention is that you as we have in the past, but we are not specifying And that's because when data is stored as itself actually contains the corresponding So we do not need to specify them separately, contained within the generator itself. So let's go ahead and run this now. Alright, so the model just finished training. So let's check out the results. Before we do just if you get this warning, be a bug within TensorFlow that's supposed is what I read. So you can just safely ignore this warning, But if we scroll down and look at these results, accuracy on our training set has reached 100%. So that is great. But our validation accuracy is here at 69%. So not so great, we definitely see that we So if this was a model that we really cared be able to deploy to production, then in this doing and combat this overfitting problem But what we are going to do is that we'll use a pre trained model to perform really And that'll get us exposed to the concept Before we do that, though, we are going to up to inference at predicting on images in Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I may be from deep lizard. And this episode will demonstrate how to use to predict on image data using tensor flows Last time, we built and trained our first saw that the training results were great with set. However, it lagged behind by quite a good set. So that tells us that the model wasn't generalizing But nonetheless, we are going to use our model images in our test set. Given the less than decent results that we Our expectation is that the model is not going probably going to perform at around the same But this is still going to give us exposure the Kerris sequential API. Alright, so we are back in Jupyter Notebook the code in place from the last couple of use of both our model that we built last time, prepared the data sets. So the first thing we're going to do is get And then we're going to plot that batch, we're then we're going to print out the corresponding And we're using before we do that just a reminder, in the last couple of episodes. Alright, so if we scroll down, we have our Recall, we had the discussion about why the of the color being skewed last time, but we have kind of distorted color we have, these And by looking at the corresponding label all labeled with the one hot encoded vector cat. So if you're wondering why we have all cats here, that is because we're call whenever we did not want it to be shuffled. And that was so that we could do the following. If we come to our next cell, and we run test has all of the corresponding labels for each So given that we have access to the ns shuffled want to shuffle the test set directly, because mapping from the uncoupled labels to the test And if we were to shuffle the test data set, be able to have the correct mapping between So we care about having the correct mapping, from the model, we're going to want to plot And so we want the corresponding labels that Alright, so next, we're actually going to model dot predict just as we have an earlier And to x, we are specifying our test batches, verbose to be zero to get no output whenever So here, we are just printing out the arounded So the way that we can read this is first, a single sample. So if we just look at the first one, this the test set. So this one, wherever there is a one with the output class that had the highest probability So in this case, we see that the zeroeth index So we can just say that the label that the a zero, because we see that there is a one And if we look at the first element, or if for our first test sample, it is indeed zero. So we can eyeball that and see that the model here, because that's the first 123456 and Okay, so But then, whenever we see that the highest probability, that means that the, a one, and so that corresponds to dog. So it's hard for us to kind of draw an overall this test set, just eyeballing the results But if we scroll down, then we know that we can use to make visualizing these results of this course already. So we are going to do that. Now we're going to create a confusion matrix scikit learn which we've already been introduced test batches classes. Recall that we just touched on that a few And for our predictive labels, we are passing getting the we're actually passing in the We're actually using arg max to pass in the was from our predictions list. So this is something that we've already covered So if we run that, we're now going to bring discussed is directly from psychic Lauren's blog for this episode on people's are calm. This is just going to allow us to plot our And now if we look at the class indices, we So we just need to look at that so that we plot labels for our confusion matrix. And next we call plot confusion matrix and as the labels for the confusion matrix and So let's check that out. Alright, so from what we learned about how we know that we can just look at this diagonal to see what the model predicted correctly. So not that great, the model is definitely So like I said, if this was a model that we definitely want to combat that overfitting But for now, we are going to move on to a art model called VGG 16. In the next episode, so that we can see how of cats and dogs. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from be blizzard. And this episode will demonstrate how we can using tensor flows keras API. The pre train model that we'll be working And this is the model that won the 2014 image In the image net competition, multiple teams that best classifies images within the image And the image net library is made up of 1000s using Kerris will import this VGG 16 model, of the 1000 categories for which it was originally cat and dog. Note, however, that cats and dogs were included VGG 16 was trained on. And because of this, we won't have to do much from 1000 classes to just the two cat and So the overall fine tuning that we'll do will in later episodes, though, we'll do more involved what a model has learned on an original data data set that we'll be using later. To understand fine tuning and transfer learning episode for fine tuning in the deep learning we actually start building our model, let's that is done. Now recall we are here in our Jupyter Notebook. This is from last time when we plotted a batch And a few episodes ago, we discussed the fact of the VGG 16 pre processing function that Well, now we're going to discuss what exactly So as we can see, we can still make out the just the data the color data itself that appears So if we look at the paper that the authors architecture section, let's blow this up a pre processing we do is subtract the mean on the training set from each pixel. So what does that mean? That means that they computed the mean red And then once I had that mean value across that mean value from the red value, the red And then they did the same thing for the green So they found the green picks the Mean Green And then for each sample in the training set, value from it. So and same thing for the blue, of course. So that's what they did for the pre processing. So given that, that's how VGG 16 was originally That means now whenever new data is passed in the same exact way as the original training So Kerris already has functions built in for that pre processing in place that matches So that's why we were calling that model whenever so that we could go ahead and get those images original training set was processed, when Alright, so that is what that color distortion So now let's jump back into the code. Now that we know what that's about, we have Now, Let's now get back to actually building So the first thing that we need to do is download And when you call this for the first time, it's going to be downloading the model from But after this, subsequent calls to this function download a copy on your machine. Alright, so the model has been downloaded And we can see that this model is much more this point. So total, there are almost 140 million parameters And on disk, it is over 500 megabytes. So it is quite large. Now recall I said that this VGG 16 model originally classes. so here we can see our output layer of the So our objective is going to simply be to two output classes corresponding to cat and the fine tuning process that we'll get to So now, we're actually going to just skip These are just for me to be able to make sure But it is not relevant for any code here. It's just checking that the trainable parameters. And non trainable parameters are what I expect But this is not of concern at the moment for So if we scroll down here, we're now going Alright, now before we run this code, we're model this is. So this is returning a model called model. So this is actually a model from the Kerris We have been previously working with sequential So we are in a later episode going to discuss complicated and more sophisticated than the For now, since we're not ready to bring in convert the original VGG 16 model into a sequential And we're going to do that by creating a new equal to an instance of sequential object. And we are going to then loop through every Except for the last output layer, we're leaving layer and then add each layer into our new So now we'll look at a summary of our new And by looking at this summary, if you take this summary, what you will notice is that layer has been not included in this new model. So this layer here we have this fully connected shape of 4096. here if we scroll Back up, So the predictions layer has not been included, loop, we went all the way up to the second of VGG 16. Alright, so now let's scroll back down. And we're now going to iterate over all of And we are going to set each of these layers to false. And what this is going to do is going to freeze biases from all the layers in the model so Whenever we go through the training process learned the features of cats and dogs and have to go through more training again it So that's why we are freezing the weights layer to this model. So remember, we removed the previous output output classes rather. And now we are going to add our own output cat and dog. So we add that now since we have set all of can see that actually only our last output layer in the entire model. And like I said before, that's because we the features of cats and dogs during its original So we only need to retrain this output layer So now if we look at a new summary of our same, except for now we have this new dense two classes, instead of 1000. From the original VGG 16 model, we can also parameters, and those are all within our output As I said that our output layer is our only So before actually, all of our layers were If we go take a look at our original VGG 16 parameters, all of which are trainable, none So if we didn't freeze those layers, then training process for our cat and dog images. So just to scroll back down again and check We can see that now we still have quite a 134 million, but only 8000 of which are trainable. The rest are non trainable. In the next episode, we'll see how we can cats and dogs. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Mandy from Blizzard. In this episode, we'll demonstrate how to built last time on our own data set of cats Alright, so we're jumping straight into the But of course, be sure that you already have be building on the code that we have already So, we are using our model here to first compile This model is the sequential model that we 16 model containing all the same layers with we have modified to output only two possible So, we are compiling this model using the with the learning rate of 0.0001 and a the entropy just like we have before and we are model performance. So, there is nothing new here with this call It is pretty much exactly the same as what Now we are going to train the model using data set which we have stored in train batches. We are passing in our validation set Which And we are only going to run this model for And we are setting the verbosity level to output from the model during training. So let's see what happens. Alright, so training has just finished, and So just after five epochs on our training on our training data of 99%. And validation accuracy, right on par at 98%. So that's just after five epochs. And if we look at the first epoch, even our accuracy of 85%, just starting out, and a So this isn't totally surprising, because how VGG 16 had already been trained on images So it had already learned those features. Now, the flight training that we're doing 16 to output only cat or dog at classes. And so it's really not surprising that it's its first epoch, and even an even considerably accuracy. Now we're called the previous CNN that we convolutional neural network, that model actually 100% accuracy after a small amount of epochs Where we saw it lagging though was with the So it had a validation accuracy of around Here we see that we are at 98%. So the main recognizable difference between model is how well this model generalizes to whereas the model we built from scratch did included in the training set. In the next episode, we're going to use this cat and dog images in our test set. And given the accuracy that we are seeing to see some really good results on our test Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. In this episode, we'll use our fine tuned in our test set. All right, we are jumping right back into Again, making sure that all the code is in as we will be building on the code that has So first things first is that we are going our test set. So to do that we call model dot predict which Recall that this model here is our fine tuned And to predict we are passing our test set And we are setting our verbosity level to output from our predictions. Now recall Previously, we talked about how and dog image data set. And that is because we want to be able to so that we can then pass in the uncheck old the shuffled labels that correspond to the to have those in a one to one mapping, where labels for the unsettled data samples, we matrix. So this is the same story as we saw whenever a few episodes back, we did the same process, And so now we are plotting this confusion So this is actually the exact same line that episodes back when we plotted it on this same from scratch. And just a reminder from last time recall test batches. So that we could get the correct order of for our confusion matrix. So we are again doing the same thing here. And now we are calling the psychic learn plot earlier in your notebook from a previous episode. And to plot confusion matrix we are passing just above as well as a general title for So now, let's check out the plot so that we So this is what the third or fourth time that so far, so you should be pretty normalized So recall, the quick and easy way is to look this diagonal, and we can get a quick overview So the model correctly predicted a dog for And it correctly predicted a cat 47 times So we can see that one time it predicted a And three times it predicted a dog when images So overall, the model incorrectly predicted Correct. Or let's see 96 correct predictions out of So that gives us an accuracy rate on our test Not surprising given what we saw in the last our model had on the validation set. So overall, this fine tuned VGG 16 model does had not seen during training a lot better from scratch. Now recall that we previously discussed that to this model was pretty minimal since cat training set for the original VGG 16 model. But in upcoming episodes, we are going to than what we saw here for VGG 16. As we will be fine tuning another well known new data set that was not included in the So stay tuned for that. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. And this episode we'll introduce mobile nets neural networks that are much smaller and popular models that are really well known. neural nets are a class of small, low power, like classification, detection, and other And because of their small size, these models the name mobile nets. So I have some stats taken down here. So just to give a quick comparison, in regards that we've worked with in the past few episodes So pretty large, generally speaking, the size is only about 17 megabytes. So that's a pretty huge difference, especially run on a mobile app, for example, this vast or weights and biases contained in the model. So for example, let's see VGG 16, as we saw So a lot. And the 17 megabytes mobile net that we talked has only about 4.2 million parameters. So that is much much smaller on a relative Aside from the size on disk being a consideration other larger models. We also need to consider the memory as well. So the more parameters that a model has The also. So while mobile nets are faster and smaller like VGG 16, there is a catch or a trade off, So, mobile nets are not as accurate as some but don't let that discourage you. While it is true that mobile nets aren't as VGG 16, for example, the trade off is actually reduction in accuracy. And in the corresponding blog for this episode, depth to this relatively small accuracy difference. If you'd like to check that out further, let's code with Kerris. Alright, so we are in our Jupyter Notebook. And the first thing we need to do is import use of which these are not only for this video, be covering mobilenet. And as mentioned earlier in this course, a But if you're running a GPU, then you want This is the same cell that we've seen a couple we are just making sure that TensorFlow can it is setting the memory growth to true if So again, don't worry, if you don't have a But if you do, then run this cell, similar we were working with it in previous episodes, net here. So we call TF dot cares applications dot mobile we call it is going to download mobile net So you need an internet connection. But subsequent calls to this are just going on disk and loading it into memory here. So we are going to do that now and assign Now mobile net was originally trained on the So in a few minutes, we will be passing some They are not images from the image net library, And we're just going to get an idea about But first, in order to be able to pass these to do a little bit of processing first. So I've created this function called prepare And what it does is it takes a file name, image path, which is pointing to the location that we're going to use to get predictions So we have this image path defined to where by using the image path, and appending, the So say if I pass in image, one dot png here, one PNG here, pass that to load image, and Now, this load image function is from the So what we are doing here is we are just taking 224 by 224, because that is the size of images take this image and transfer it to be in a of this image, because that's going to put And then finally, we pass this new processed that application stop mobile net, that pre So this is a similar function to what we saw VGG 16, it had its own pre process input. Now mobile net has its own pre process input way that mobile net expects, so it's not the Actually, it's just scaling all the RGB pixel to 255, to be on a scale from minus one to So that's what this function is doing. So overall, this entire function is just resizing with expanded dimensions and then mobile net, image. Okay, so that's kind of a mouthful, but that's them to mobile net. Alright, so we will just Define that function. And now we are going to display our first net samples directory that I told you, I just And we're going to plot that to our Jupyter And what do you know, it's a lizard. So that is our first image. Now, we are going to pass this image to our above that we just finished talking about. So we're going to pass that to the function we are going to pass the pre processed image model, we're going to do that by calling predict videos, when we've called predict on models the prediction for this particular image, to this image net utils dot decode predictions So this is a function from cares, that is from the 1000 possible image net classes. And it's going to tell us the top five that So let's run that and then print out those And maybe you can have a better idea of what So we run this, and we have our output. So these are the top five in order results is predicting for this image. So it's assigning a 58% probability to this probability to green lizard 13% to a gamma. And then we have some small percentages here So it turns out, if you're not aware, and this, because everyone should know this. But this is an American chameleon. And I don't know I've always called these But I looked it up. And they're also known as American chameleon. So mobilenet got it right. So yeah, it assigned at 58% probability that Next was green lizard. So I'd say that that is still really good I don't know if green lizard is supposed to But and then a gamma, which is also a similar So between these top three classes that it between the three of these, I would say mobile So let's move on to number two. Alright, so now we are going to plot our second And this is a cup of well, I originally thought it a cup of cappuccino. So let's say I'm not sure I'm not a coffee and cappuccinos. This looks like it has some cream in it. So hey, now we're going to go through the image where we are passing that image passing so that they undergoes all of the pre processing, image to the predict function for our mobile Then finally, we are going to get the top model relative in regards to the imagenet So let's see. All right, so according to mobile net, this So I don't know. But it predicts 99% probability of espresso particular image. And I'd say that that is pretty reasonable. So let me know in the comments, what do you I don't know if mobile or if image net had So if it didn't, then I'd say that this is But you can see that the other the other four But they are reasonable. I mean, the second one is cup, third eggnog, Fifth, wooden spoon gets a little bit weird, going on here. But these are all under 1%. So they're pretty negligible. I would say mobilenet did a pretty great job this image. All right, we have one more sample image. So let's bring that in. And this is a strawberry or multiple strawberries So same thing we are pre processing the strawberry Then we are getting a prediction For a mobile that top five results for the most probable And we see that mobile net with 99.999% probability so very well, and the rest are well, well But they are all fruits. So interesting. Another really good prediction from mobile So even with the small reduction in accuracy this episode, you can probably tell from just is maybe not even noticeable when you're just through. So in upcoming episodes, we're actually going work on a custom data set. And this custom data set is not one that was it's going to be a brand new data set, we're done in the past. So stay tuned for that. Be sure to check out the blog and other resources calm, as well as the deep lizard hive mind and rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Mandy from deep lizard. And this episode, we'll be preparing and processing mobilenet using tensor flows keras API. Previously, we saw how well VGG 16 was able and dogs. But we noted that VGG 16 was actually already a lot of fine tuning at all to get it to perform Now, with mobile net, we'll be going through But this time, we'll be working with a data original image net library for which mobile This new data set that we'll be working with there are 10 classes total for this dataset, contains images of the particular sign for This data set is available on kaggle as grayscale as RGB images. And for our particular task, we'll be using So check out the corresponding blog for this for where you can download the data set yourself. So after downloading the data set, the next And this will be a very similar procedure earlier in the course. So once we have the download, this is what It is a zipped folder called sign language And the first thing we want to do is extract And when we do that, we can navigate inside And inside here we have all of the classes. And each of these directories has the corresponding So the what we want to do is we want to grab And we are going to Ctrl x or cut these directories. And we're going to navigate back to the root all of the directories zero through nine in And then we're going to get rid of everything So now, one last thing. So I'm just going to delete this master. I don't necessarily like that. So we have sign language digits data set. And directly within we have our nested directories has our training data inside then the last set directory to where you're going to be So for me that is relative to my Jupyter Notebook, cares directory, I have a data directory and here. Now everything else that will do to organize in code. So we are in our Jupyter Notebook. Make sure that you do have the imports that we'll be making use of those Now, this is many images are in each class. So across the classes zero through nine, the in each class. And then here I have just an explanation of point. Now the rest of the organization, we will So this script is going to organize the data So recall right now, we just have all the of zero through nine. But the data is not broken up yet into the So to do that, we are first changing directory And then we are checking to make sure that setup is not already in place on disk. And if it's not, then we make a train valid digits dataset. So next we are then iterating over all of dataset directory. So recall, those are directories labeled zero So that's what we're doing in this for loop That's going from directory zero to nine, our train directory. And after that, we're then making two new directory for whatever place we're at in the So if we are on run number zero, then we are and a directory called zero within test. And if we are on run number one, then we will and one within test. So we do this whole process of moving each directory empty, within valid and test. So at this point, let's suppose that we are So in this range, here we are following add So here on this line, what we are doing is slash zero directory. Because up here we created or we moved the And now we're going to sample 30 random samples so we're calling these valid samples, because move into our validation set. And we do that next. So for each of the 30 samples that we collected we're now going to be moving them from the the validation set in Class Zero. And then we do similarly the same thing for samples from the train slash zero directory. And then we move those five samples from that directory. So we just ran through that loop using the But that's going to happen for each class And just in case you have any issue with visualizing language, digits dataset, now let's check So recall we previously had classes zero through route folder. Now we have train valid and test directories. And within train, we moved the original zero And then once that was done, then we sampled them into the valid directory classes. And then similarly, we did the same thing And then once we look in here, we can see zero, we see that it has five samples for If we go check out the valid directories, that here 30. So every valid directory has 30 samples, and uniform samples because remember, we saw that anywhere from 204 to 209, I think. So the number of images within each class slightly by maybe one or two images. But the number of images in the classes for uniform since we did that programmatically So checking this dataset out on disk, we can for which we structured our cat and dog image just dealing with 10 classes instead of two. And when we downloaded our data, it was in than the cat and dog data that we previously Alright, so we have obtained the data, we've Now the last step is to pre process the data. So we do that first by starting out by defining live on disk. So we supply those paths here. And now we are setting up our directory iterators, point. Given this is the same format that we processed cnn from scratch, and we use the fine tuned So let's focus on this first variable train First, we are calling image data generator see here. But we'll scroll into a minute to image data function, which in this case is the mobile Recall, we saw that already in the last episode. And there we discussed how this pre processes data to be rather than on a scale from zero one to one. So then on image data generator, we call flow here. And we set the directory equal to train path, our training data resides on disk, we are recall just resizes any training data to be width of 224, since that is the image size our batch size equal to 10. So we've got the same deal for valid batches. And for test batches as well, everything exactly show where the validation and test sets live And we are familiar now that we specify shuffle we can later appropriately plot our prediction So we run this cell, and we have output that So that corresponds to our training set 300 and 50 images belonging to 10 classes for So I have this cell with several assertions we find, or that we have right here is what So if you are not getting this, then it's location on disk. So a lot of times if you're pointing to the zero images belonging to 10 classes. So you just need to check your path to where Alright, so now our data set has been processed. We're now ready to move on to building and data set. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Mandy from Blizzard. In this episode, we'll go through the process set. Alright, so we are jumping right back into So make sure your code is in place from then now. So first thing we're going to do is we are in the first mobile net episode by calling dot mobile net, remember, if this is your need an internet connection to download it Now, let's just take a look at the model that So by calling model dot summary, we have this lovely layers included in mobile net. So this is just to get a general idea of the So the fine tuning process now is going to up to the sixth to last layer. So if we scroll up and look at our output So we are going to get all of the layers up going to be included. So all of these layers are what we are going new fine tune model. And we are not going to include the last five And this is just a choice that I came to after the number of layers that you choose to include a model is going to come through experimentation So for for us, we are getting everything from And we are going to keep that in our new fine So let's scroll down. So we're doing that by calling mobile dot and output, then we are going to create a And we're going to set this equal to a dense So this is going to be our output layer. That's why it's called output and 10 units zero through nine. And this, as per usual is going to be followed a probability distribution among those 10 Now, this looks a little strange. So we're calling this and then we're like So what's this about? Well, the mobile net model is actually a functional So this is from the functional API from Kerris, So we kind of touched on this a little bit saw that VGG 16 was also indeed a functional But when we fine tuned it, we iterated over model at that point, because we weren't ready So here, we are going to continue working So that's why we are basically taking all And whenever we create this output layer, in x here, that is the way that the functional output layer, pass all of the previous layers last layer and mobile net. And then we can create the model using these model, which is indeed a functional model equals mobile dot input. So this is taking the input from the original So at this point, output is all of the mobile plus this dense output layer. Alright, so let's run these two cells to create Alright, so our new models now been created. So the next thing we're going to do is we're So through some experimentation on my own, for the last 23 layers, this appears to yield So 23 is not a magic number here, play with results. But basically, what we're doing here is we're and by default, they are all trainable. So we're saying that we want only the last All the layers except for the last one, a And just so that You understand, relatively original mobile net model. And so we're saying that we don't want to 23 layers in our new model that we built just Recall, this is much more than we earlier we only train the output layer. So let's go ahead and run that now. And now let's look at a summary of our new So here, if we just glance it looks basically summary. But we will see here that now now our model which recall before was the sixth the last that layer and everything above it. So all the layers below the global average original mobile net summary are now gone. And instead of an output layer with 1000 classes, from the or corresponding to the 10 potential language digits dataset. If we compare the total parameters, and how parameters, in this model with the original a difference there as well. Alright, so now this model has been built, So the code here is nothing new. We are compiling the model in the same exact our little bit of luck, 0.0001 learning rate, and accuracy as our metric. So this, we have probably seen 2 million times So that's exactly the same. Additionally, we have exactly the same fit model. So we're passing in our train batches as our as our validation data. And we are running this for 10 epochs. Actually, we're going to go ahead and run I had 10 here just to save time earlier from epochs. And we are going to set verbose equal to two Now, let's see what happens. All right, so our model just finished training So let's check out the results. And if you see this output, and you're wondering then we get or the first epoch took 90 seconds, a few later, it's because I realized that being plugged in. So once we plug the laptop in, it beefed up So let's scroll down and look basically just So we are at 100% accuracy on our training So that is pretty freakin great considering not having images that were included in the So these are pretty good results. A little bit overfitting here since our validation So if we wanted to fix that, then we could issue. But if we look earlier at the earlier epochs, on our first epoch, our training accuracy so that is not bad for a starting point. And we quickly get to 100% on our training So that's great. But you can see that, at that point, we're So we have a decent amount of overfitting And then, as we progress through the training and less of a problem. And you can see that we actually at this point, have run here, we've not even stalled out It's not stalled out in terms of decreasing Our validation accuracy has not stalled out more epochs on this data will eradicate the Otherwise, you can do some tuning yourself different structure of fine tuning on the So freeze Morrow. Less than the last 23 layers for during the And if you come up with something that yields comments and let us know. So we have one last thing we want to do with is use it on our test set. So we are familiar, you know the drill with it several times. So we are now going to get predictions from And then we are going to plot those predictions So we are first going to get our true labels We're then going to gain predictions from passing in our test set stored in test batches we do not want to see any output from the And now we are creating our confusion matrix. Using socket learns confusion matrix that labels equal to the test labels that we defined labels to the arg max of our predictions across And now we are going to check out our class they are what we think they are. And they are of course, classes labeled zero So we define our labels for our confusion And then we call our plot confusion matrix and that we have used 17,000 Times up to this our confusion matrix for what to plot, we correspond to our confusion matrix, and giving of confusion matrix, because hey, that's what So let's plot this. Oh, no. So plot confusion matrix is not defined? Well, it definitely is just somewhere in this go. Nope, here we are. Alright, so here's where plot confusion matrix Let's bring that in. Now it is defined and run back here. So looking from the top left to the bottom to have done pretty well. So we have 10 classes total, with five samples And we see that we have mostly we have all that most of the time the model predicted So for example, for a nine, five times out a nine when it actually was for an eight. However, only four out of five times did the the times the model, let's see, predicted But in total, we've got 12345 incorrect predictions So that gives us a 90% accuracy rate on our given the accuracy that we saw right above So hopefully this series on a mobile net has tune models for custom data set and use transfer To use the information that a model gained new task in the future. Be sure to check out the blog and other resources as well as the deep lizard hive mind where rewards. Thanks for contributing to collective intelligence. Now let's move on to the next episode. Hey, I'm Andy from deep lizard. And in this episode, we're going to learn using tensor flows. keras API. Data augmentation occurs when we create a data. We're going to explain the idea a little bit But if you want a more thorough explanation, episode in the deep learning fundamentals For the example that will demonstrate in just image data. And so for image data specifically, data augmentation either horizontally or vertically. It could include rotating the image, it could so on. One of the major reasons we want to use data to more data. So a lot of times that not having access to And we can run into problems like overfitting So that is a major reason to use data augmentation data to our training set can in turn reduce Alright, so now let's jump into the code to Alright, so the first thing that we need to that we will be making use of for this data Next, we have this plot images function, which is directly from tensor flows website. And it just allows us to apply images to our So check out the corresponding blog for this so that you can go copy this function yourself. Alright, so next we have this variable called And recall, we've actually worked with image we create our train at test and valid batches and with this, though, we are using image Here, we are creating this generator that like rotation, range, width, shift range, channels of drains in horizontal flip. So these are all options that allow us to So you need to check the documentation on units for these parameters, because they're So for example, rotation range here, I believe Whereas like this width, shift range is measured So these are all ways that we can augment So this is going to be rotating the image the width of the image by 10%, the height Zooming in shifting the color channels, flipping So just all different ways that we can augment So there are other options to just be sure if you want to see those options. But for now, these are the ones that we'll So we store that in our Jen variable. Next, we are going to choose a random image in the course under the dogs versus cats dataset, we are going to choose a random image from And then we're going to set this image path So we're just going to set this to point to we have this assertion here just to make sure proceed with the remaining code. Now we're just going to plot this image to And I'm not sure what this is going to be So that is a cute looking. I don't know. Beagle, Beagle, basset hound mix, I don't So this is the random dog that was selected Now we are creating this new variable called And to our image data generator that we created function and passing our image in to flow. And this is going to generate a batch of augmented So next, we are defining this og images variable, augmented images created by og etre here. Lastly, we are going to plot these images above. All right, so let's zoom in a bit. All right, we can see now that first let's that is the original image. Now we can look and see that given those things that we defined earlier, whenever we defined that has now been done to All of these images kind of what's happening here. So for example, this particular image looks can see that the head of the dog is being And this image, or let's see which way was facing to the right. So yeah, so this image here has been flipped, And this image appears to be shifted down And so some of these, like this one looks So we can get an idea just by looking at the have been done to them. And we can see how this could be very helpful for example, say that we have a bunch of images all facing to the left. And we want to deploy our model to to be some dogs. But the types of images that will be accepted to the right as well. Well, maybe our model totally implodes on the right. So through data augmentation, given the fact or right, we could augment all of our dog also face in the right direction, as well a more dynamic data set. Now, there is a note in the corresponding giving just the brief instruction for how save the images after you augment them, and So check that out if you're interested in set. Rather than just plot the images here and By the way, we are currently in Vietnam filming If you didn't know we also have a vlog channel little bit more about ourselves. So check that out at beetles or vlog on YouTube. Also, be sure to check out the corresponding available on the blizzard.com. And check out the people's hive mind where rewards. Thanks for contributing to collective intelligence. I'll see you next time.