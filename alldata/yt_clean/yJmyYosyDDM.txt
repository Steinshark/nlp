Intro we'll compare the performance of Deno v2 versus we'll focus on the four golden signals. In the side using the p99 percentile. Throughput for second, and we'll generate enough load to find the we'll measure service saturation, or we'll measure CPU usage of each application as well as memory usage. Additionally, since they are all CPU-bound, we need to measure throttling your service, you can expect Finally, we'll measure errors or availability applications means the ratio of successful The second test will more or less simulate a receives a POST request with a JSON payload, it for the object, and save it to the relational For this test, I internally instrumented to measure each function call that saves I used Node Exporter to monitor the database exporter to track the number of active connections For all my tests, I use a production-ready instances with 2 CPUs to run the applications, and i3en.xlarge instances to run Postgres, Test Design I create an EKS cluster in AWS and provision applications, and the second is used to deploy applications mostly use a single thread, there mode and implement that in each application, gets to a single CPU and scale horizontally. To deploy the clients, I use a Kubernetes Job generate load. I start with 20 truly independent of virtual clients, reaching around For the second test, I provision an EC2 optimize Postgres for the hardware. it saves the item to Postgres. We collect the pods and Node Exporter from Postgres. I collect connection count metrics, and Source Code I basically used the same code base, just copied in Bun, I used Bun.serve, and the Deno project is only difference is that I initialized it with Deno in terms of portability, it's great. If you'd improvements for each app, and I'll test In the Dockerfile, you can see the to compile each project. For example, I didn't find much documentation except for the Docker images with the new For Node.js, I installed all the production for the final stage. Alright, let's go ahead and run the first test. and Bun, you would notice similar behavior. I've updated Bun to the latest version and surprisingly, Deno shows even lower CPU usage for Node.js is also the highest, so and Bun is the most efficient in terms of CPU new Zig programming language, while Deno is have another test comparing Rust and Zig On the right-hand side, we have and you can see the usage on the graph. starts to lose its latency advantage compared This is something to keep in mind if you're using at this point if you need low latency. in latency. Typical latency per request is the client timeout to 100 milliseconds. When a you'll see that spike in the availability graph. no longer keep up with the other applications, and from the graph for the remainder of the test and that Kubernetes starts throttling Node.js, and By around 36,000 requests per second, latency and eventually surpasses it. and you can see Bun remains quite stable at this By around 60,000 requests per second, Deno begins well. Kubernetes also starts throttling it. point for the Bun application. Bun starts to fail. Deno managed to reach around reached 50,000 requests per second. graph for the entire test duration. First, we have requests per second. Node.js started to degrade. around 60,000 requests per second, and Next, we have latency measured from the client latency, followed by Deno, and Bun has the lowest. test. It looks like Deno can produce much Then we have CPU usage. Bun is followed by Deno, and lastly, Node.js. stable, while Node.js and Deno Then we have the availability graph. Node.js has the lowest availability. Let's Finally, we have CPU throttling. first, followed by Deno, and lastly Bun. application where latency is very important, you if latency is not as critical, and the as an internal application doing some kind 2nd Test - PostgreSQL run the second test with Postgres. using the p90 percentile to reduce the in Bun. This is the second time I've seen spikes. I ran this test multiple times, and before dropping the tables and all the data. I noticed you can see higher database latency along with was cleaning up data, and once it finished, the Bun and Node.js, and 2 milliseconds for Deno. to the database, but based on this graph, it seems the JSON payload or generates UUIDs. This is not CPU usage. My main takeaway from this test is better than Node.js and Deno in this real-world using the exact same code base for both Bun and code but rather something internal to Bun. Deno is the slowest application in this test, with It appears that most of the latency in Deno is the client-side latency for the entire request is in this test compared to the other applications. per second, Kubernetes started throttling At around 6,200 requests per second, Bun was also applications handle roughly the same number is the bottleneck. For the next tests, I'll Now, let's take a look at the entire test. Next is client latency. Let's focus on latency the left-hand side, the latency spikes were internal database cleanup. From this graph, off with Bun, and I hope they can fix it. while Deno has the highest. You can see that most of Deno's latency comes have much lower database latency--almost five times be causing such a drastic difference. Then we have the memory usage graph. I also tracked the connection pool size. I set and deployed 2 instances, resulting in 80 like Deno is using a single connection while the That's pretty much it for this test. I have interesting. Thank you for watching,