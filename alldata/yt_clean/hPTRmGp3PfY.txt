And then we have generative AI And it's not that intelligent. It is playing this giant game a mad libs looking for common patterns. And sometimes it gets it right things that are phenomenally stupid Defamation comes from that. It's it gives an illusion of being intelligent, It can't reason about its own answers. There's a new model that can do that so I would say it's intelligence is being able to adaptively solve then it's not intelligent. My name is Ken. Brad. And I'm a long time supporter of the We're supporting tonight's program Square Partners, and are delighted, Gary Marcus and Rachael Myrow. Before we begin, just a few reminders. We do have the C-Span, actually, So more than usual, please If you have any questions with little, card and they'll be brought up here. And a number of those will be selected Please feel free. You can type in your question And for those of you here in person, thank you, first of all, There will be free books available after the program We also have a wine reception, A lot of things to talk about, and have a glass of wine The book is called Taming Silicon Valley. I just found out in the green room So probably a speed record for actual, Gary is a leading voice, He is a cognitive scientist in human language As a successful entrepreneur, and geometric AI, Through significant work and research, many of the contemporary AI limitations. His fascinating new book, Taming AI Works for Us, explains and what a comprehensive Spoiler alert Moderating tonight's She's a senior editor at KQED Silicon moderator at the Commonwealth Club. Please join me in who. by, reading a list here from page 70, at risks of generative AI. Let's just read it out. Disinformation, market manipulation, accidental misinformation. Defamation. Nonsense. Deepfakes. Accelerating crime. Cybersecurity and bioweapons. Bias and discrimination. Privacy and data leaks. Intellect. Property taken without consent. Overreliance on unreliable systems. And last So if any any of you missed because you. I did write this in two months, right. I did actually write about AI accounting that I might have missed some. I think the one thing it's already there, I would have been able to add is either science or nature And what the authors showed English, as opposed to standard English, And that's actually covered in bias, you know, even more vividly. And of course, like all of the things already So, you know, of our election We were talking in the green room AI has been around for a few years it's still like a game of Mad Libs I'm wondering. If you had the great line Yes, Mad Libs, but more expensive. I wish I had written well. So explain for the audience here, to read the book. It's it's a rip roaring read. You'll you'll get through it It's very, very, what's the word? Well written, Explain the problem intelligence I mean, that's but I would say that the AI we have right now, it's We have some narrow It actually works doesn't lead to any of the doesn't risks It's perfectly fine. But nobody expects it And then we have generative AI And it's not that intelligent. It is playing this giant game a mad libs looking for common patterns. And sometimes it gets it right things that are phenomenally stupid Defamation comes from that. It's it gives an illusion of being intelligent, It can't reason about its own answers. There's a new model that can do that I would say it's intelligence is being able to adaptively solve novel problems in reliable ways, If you want to say a chess and have a definition, Well, okay, then we have some of that. So it's partly definitional, I mean, it's certainly not AI. Especially if you don't know When you're looking at an answer. There's an old saying in the military And the thing about chat bots And then if they get it wrong, If you tell them they got it wrong and they got it right, Everything they say is authoritative. But I said on 60 minutes actually was And it just all comes across But that doesn't make it true. So, among the, the, that we've observed in the last few years, at least no more copyright For the companies models, books I love these lines you wrote. Don't let them steal your content. Don't let them destroy the arts. The great data heist has to stop, The first word in data should be consent. But Gary, to hire our own lawyers, Well, I mean, one of the things I suggest all consider boycotting generative So going back to that list of 12, So I'm glad you read the list. If you go back to the list of 12 like these are consequences, You can think of like power plants that Generative AI companies are belching They're ripping off artists. They're causing, It might cause much worse problems because the only solution they have to is to make the models even bigger, Escalating the energy problems, you can think like you might not want to have a cup of coffee If the labor is exploited well, it's exploiting artists. It's probably going to exploit you whatever you do, because their end game Whatever your job is. Use journalist I have a whole stash so the So we could say, look, I make a bet, I make one that we trust that won't rip off people's data. You know, it's most of what they do with better systems You know, it ought to be possible that don't use so much energy, use Right. So we could just demand better. We could say we will boycott this stuff That's really why I wrote the book. The end is to get the government's The companies aren't going We have to get involved. If we are, we could actually force the companies Well, you've just hit my sweet spot. It's a full employment act for Rachel, Covering regulation or the lack thereof Why don't we start with federal? Riddle me this. Senate hearing after congressional hearing after Senate hearings and, you know, very dramatic testimony And yet new legislation of any president, Democrat or Republican. That's right. That's you know, I wrote the book And a lot of the rage because I did I testified in the Senate And when I testified, all of the senators seemed to recognize how urgent it was, they all seemed to recognize They realized that section And so I left the room thinking, well, I've been part of this historic thing. They're going to go You could argue about what And a lot of the book is about that. But people in the room seem very rational and well motivated. And then nothing happened, right? There were a few people in the room but Schumer put nothing forward, The president didn't have any opportunity and I realized at some point And that's really why I wrote the book. And it it should be said that we're a long ways when elderly lawmakers don't have staffers, young staffers who understand And there are. Lots of very bright staffers in town. I met tons of them after my testimony. And, you know, I had a lot of closed door with Senator, the House and Senate, There are people that care. There are people don't, But the ultimate politics of it You know, there's a lot of money There's a lot of lobbying. And so you can have, you know, some keen staffers or every new article and archive But that still doesn't translate into that is actually voted on by the full That goes to the House, Like there's a long way from Well-motivate to actually getting anything passed. And I mean, that's another reason I think the public has to say, We can't sit on this. Look how badly you did on social media I've spoken to a lot of state and in Sacramento who are very mindful of, really two major failures Because in addition to social media, And I wasn't the first one The ad surveillance economy, everywhere, trying to sell stuff to you and sell your information onto others But but let's just play devil's And let me ask you, who legislation. It's a sausage making process It takes a lot of deliberation you know, back and forth before you finally land something. And Jared is just moving too fast. This this train is running at high speed. And, you know, let's not have lawmakers or regulators get in the way of the goose. That's laying all these golden eggs, There's a lot to unpack there. One of the things to unpack there is that the Silicon Valley wants that there is a lot of money, but that doesn't actually bear scrutiny, So about $100 billion, or let's say, almost $100 Cumulative profit has been $5 billion. So, so far, generative AI has been And they've got everybody convinced But it's not clear how. Well some people are making Well, the people that are making in secondary sales. I probably in this town, what that is, there are venture and they make a lot of money. And then their pension funds that may, you know, put who put their money in, who Because in the long run, you can't really So the early investors can, But people who get left holding the bag, So that's the first thing, is the premise is maybe not right. I'd say, remind me the question. They get sidetracked on the, there are some people who say Step aside, just let this thing happen. Right. So, I think there's a mistake in assuming somehow, some lobbyists in California, including companies like that zero regulation is a rational way In fact, other industries There's a strong, challenge You don't want regulatory capture where the big companies write the rules, But think about, for example, airlines If there were no regulations, Instead, it's incredibly safe So we have multiple layers of regulation, industry to be reliable enough I got on five planes and I felt like my life What they want for air is no regulation. We already have that list. There may be more At some point some massive cyber attack And people have fought regulation may actually find themselves in trouble 1047 and things go wrong, You brought up 1047 but but you know. Whereof I speak, literally. Yes. So so we'll get into that But I do want to say, you know, but warning, about the potential catastrophic And, well. He did that at the. Urging lawmakers. Yeah. Did that the Senate after I made him do it, Tell us that story. Yeah. So, Senator Blumenthal, who convened the meeting, asked, Sam, Is it employment? And Sam proceeded to say, well, if they're new jobs. And he didn't answer the question And I had been told in advance, like, was my moment because I wanted to have Sam And so I said, Senator Blumenthal. Sam didn't actually answer the question And then Sam I could do serious harm to civilization. So that's a little anecdote there. Well, Brava. But, you know, this explains for me, that Altman was trying to talk up Well, by scaring us first. If there is some of that, I think that when Altman talks about the worries, the the sort of potentially serious harms is actually coming So one is he is trying to hype up and he's always trying to do that. He had an essay today where he's like, Don't you worry about all the problems We will solve them. And that's just an empty promise. I mean, you think about it and over and over again, like hallucinations have been. I predicted those in 2001. They've continued for 23 years. We don't actually have a solution. So he likes to just wave them away So some of it's hype and some of it is, as Oppenheimer. He knows that He doesn't want to, you know, be that guy And he wants to say, well, So there's a mix of the kind which looms strong And in some cases, those align So Sam Altman is isn't the only one about the potential catastrophic effects of these large language models, but, Well, let's just unpack that little. Yeah. Okay. It's actually. Yeah. Which is there are certainly catastrophic I think the risks of today's current generative AI, are probably not like the doomsday stuff AI is not going to take over the world, So for example, Well, let's just pass for a second. So these things often You just cannot count on them. So there AI, presumably generative AI, to make decisions about nuclear weapons Most rational bill died, didn't get through. So it is legal to use generative AI, to make nuclear weapons decisions. Maybe somebody will do that. That could lead to catastrophe, no doubt. So people often They're like, well, the more intelligent But there's really like one is raw intelligence and the other is empowerment. Like, what do you let the system do And it's stupid, that's a problem. If you have a naive, self-interested president with control of nuclear weapons, So catastrophe even if they're not smart enough to be, the Terminator and take over the world At the very least, where people who are not that, bright or have malevolent, intent are are taught terrible suffering for lots of people in I'm not glad that that's happening, malevolent, because I think that's really cuts to the heart of it. Right now, the fear is not runaway. Runaway It's malevolent bad actors misusing AI for misinformation If they manipulate the market, and things like that. So the worry right now Actors. So back to Sacramento and, a bill 1047 Senate Bill 1047 by State Senator Scott We're still waiting to find out if He has till the end of this month and. Clocks are ticking. Everybody is expecting that Absolutely. And I can understand why Newsom would And he's going for him. Whatever. Whatever happens, he's going. To be he's going to be blamed. So. So, it's so interesting. I mean, you have all of these these, we we want to protect against potential We have all these, that are working hard or try to make sure that doesn't happen, Don't enshrine that in the law. Don't make us liable in with a law. What's your read of that? of course, the generative AI companies Of course, they're going to say We're going to stop innovating. It's garbage. One of the reasons you signed the laws is that the generative They're going to keep innovating. You know, there's some paperwork, really screw up with some liability But it's not going to stop anybody. What do you make of AI laws I haven't followed all of them. I believe there was a deepfake passed signed in the last week. Sounds good, You know, just another thought I think of it with one saying it was originally written to have a what was called And the idea was in the technology crafting regulations, but that got written out during Yes, it like defanged. I mean, it really did. Yeah. But there's still one more thing. It's just that it's it's the state you know, can be a tough customer whoever is in that position decides to go but it is just now And yet the industry keeps describing as potentially catastrophic But it's not I mean, it'd be like the cigaret companies saying, you know, in North Carolina, It's just not true. So back to devil's advocate question. Silicon Valley has overpromised before And somehow we've all survived. Silicon Valley is privatized profits And somehow we've all survived. Why not let this? But I mean, quality of life So I think, for example, from social media Like, I just I cry I mean, the, the level of, of hostility is just horrible. It's much worse than it was before. Or look at the data It's gone up so much in the last decade. So we're all still here. But I think there are ways in Another, scary thing, actually, that I might have wanted to add, is that, large language models a study showing that they can, actually teach people false beliefs. That sorry, implant false memories There's a recent study large language models implanting We could easily wind up in a world where we're basically controlled by 3 So, yes, we still live, but we become Like that would be a huge loss. You could say, you know, in 1984, But you don't want to live in 1984. Well, but I get back to the thought that perhaps overpromising has happened and that as it becomes manifestly obvious, that, you know, things will change. And maybe it's industry specific. Maybe, you know, first about not so driverless cars. Maybe we change our attitude Could an argument be made that, you know, these guys will trip Well, I mean, they're going to lose And, you know, in that sense, Some some investors will lose money. I think I do worry about the pension funds you know, the individual investors, But so if it will be But, Like, okay, some people are going to lose I'm really worried about the kind of I'm worried about There could be a one way ticket in the United States Those kinds of things might be might have very serious consequences. So the cost of the high, the direct cost of the hype is simply The indirect consequences to a bunch of companies that can have a very negative influence We're helping them to distribute these I don't know that they can make any money. I mean, if matter is giving away the stuff But now that it's out there, for example, countries can easily use the stuff So that's So I'm more worried about what the tools are doing I mean, let the economic chips fall but I want to know what kind of society if we give so much power to companies essentially anything that we think in scale way not everybody will know. But, well, I've sort of put it together. OpenAI is losing money, right? The last $5 billion, they're under The initial anticipation was that a lot of people would use this stuff in business, So what I see signs of them doing They want to collect essentially They were working with Microsoft I assume they were working with Microsoft on this product that was going to take That got shut down But they were interested in that. They're interested in getting your email And then they just made a big investment Like I put all that together. It looks to me like OpenAI is the most What they're really going to do because there's no other way Oh, and by the way, formerly of the NSA, on their board. So, like, Oh, boy. Yeah, I imagine some of you And at the very least, you know. If, if, if for one night you can't sleep and you tell your friends about this we might fight all of this. And the whole point of the book is that and the only way we're going to get out of this so well. Let me challenge you on that. You know, like we've already talked We've talked about, perhaps salutary but limited efforts perhaps salutary which, you know, is ahead of our country And coming up with the, that is a gigantic economic But again, it's limited impact. What what is your average I think we should think about boycotts to to their congresspeople. Three is they should be saying, hey, we have a federal election, And so we have Senate elections. We have national action. Where do these people stand? Let's make them make commitments make this part of the election. You know, at the last debate Kamala Harris mentioned, We should say, hey, about the way that early decisions And if we just stand people who don't vote If we don't stand up, then the default is going to be essentially That's going to be culturally enshrined with social media, I've often felt, though, really in power in Washington DC, between administrations and here on the ticket in November, what is not on the menu? It's a serious, commitment to tackle, Right? A serious commitment Yeah. I mean, both both Trump and Harris in an effort from Silicon Valley's elite. And that is the default. Again, if we don't speak up, that's And power of the climate change Almost nothing happened until people And now not enough is happening. But something is happening. We need to get angry and loud. So for the benefit of people give us the upshot on generative I mean, I soft sell sold that in a way, I would say we know that it's already bad. You know, you a lot of questions about I would be vague. I don't know if you remember the old film and they use the phrase bad, you know, It sort of used to be catastrophic. So it's already bad that the big worry I have is. So there's some It could get better because we could figure out Right which is intellectually sterile, But in principle, we could do better. On the other hand, it's like the only idea in Silicon Valley because they all know the system Sam Altman said. GPT four sucks. That's a quote from him. So the only idea that they have maybe 100 times bigger or a thousand times That's why he wanted $7 trillion. It's because he thinks is to use massively more energy, That would be really bad for the climate Oh. Well, let's talk about something. Sorry. Let me just insert. Yeah, Microsoft, I guess, just made a deal where they're turning Three Mile Island that gives you some So let's talk next about model collapse. I hope this isn't horrifying, maybe it should horrify. So define it for people. Model collapse is the idea on their own outputs, You can think of snake eating its own tail partly reduces because they do And so they kind of drift away So that's what model collapses. And it's not it's not good. Nobody again, nobody has, good enough quantitative data But it's it's clearly already a problem. And of course, there doesn't like a general solution No, there isn't one. I actually got annoyed when everybody made pictures of American founding fathers I was like that. That is awful and historically wrong, but there's been so much bias Why was nobody upset about that? It's a huge problem. Nobody has a solution. So I thought I might ask The New York Times and the, Associated Press are two really taking very different approaches to, potentially existential threats One the New York Times is suing, AP cut a deal, figuring, well, you know, Yeah. What would you tell other newsrooms, say, about meeting what appears to be this game changing? Wait and I think the times will win, But yes, definitely, people are playing I think ultimately it's to use the copyrighted materials, or without some kind of licensing, But whether we get there I was going to have you read something, I'll give your voice a break Let's hear and how far it has fallen mission is to look at their own mission Here is a tweet from OpenAI. Introducing OpenAI. OpenAI is a nonprofit Our goal is to advance that is most likely to benefit humanity unconstrained Since our research is free we can better focus Who wouldn't want to work for a company with that massive You right. When I posted it on Twitter and I'm mindful that we need to be family Speaking of, be anyone, remember this? Investor and researcher Mona Hamdi replied by striking out every word So the tweet looks like something. Can you just hold up the picture There is is on the right So so it's mostly blacked out. It looks like one of those, you sometimes get with a FOIA request, instead of open AI, it just reads AI. And then introducing AI. AI is a profit artificial intelligence Our goal is digital intelligence in most So I don't know if you have anything else I'll just add one thing, which is not everybody knows They still get some, you know, they've been requested to ask the, the the California attorney general has received a letter from a group called why do they still have nonprofit status, then what should be the consequences, to dissolve and give some portion So that's that's still pending So there's a, story how I Could Ruin Documentary Film And I wanted to get your, reaction, The two things we always struggle with, are not enough money and not enough time, AI comes in and seemingly offers solutions to both those existential issues, I think the question that we always need And you know, she's speaking in terms of looking at documentary film as our collective history. So if suddenly we don't know what percentage is accurate, is true, is an accurate representation of history, I'm going to go out on a limb is not, GPT sport. GPT does not know how to tell truth. It knows how to make stuff up. That sounds plausible. I give, you know, Like it saying that I have a pet chicken named Henrietta applying it to documentary film because the things that makes up sound plausible, And of course, people are going to start deepfakes to, like, And I think the audiences are going and that's going to undermine Now, this particular organization the issue has issued, guidelines. And they're saying, We've already seen, you know, applications where it might make sense. But the key is to watermark everything, you know, to within an inch of its life. And so just so that everybody knows I do think, is to watermark anything Of course, we have lots of old footage So one of the problems with watermarking but what do you do And then you have problems like we don't We can do it in videos you can hide things watermarking is technology we should use It's part of the solution. So I've played around with ChatGPT. I'll admit that here and now among a friendly audience, you know, getting better at telling me There are some kind of Band-Aids But inherently, the way they work is they explode all the information into lots of little bits, and then they statistically reconstruct those bits and they don't really know So you have to put external tools We call that the attribution problem. Nobody really has a solution. So for example, in some work with the artist Reed South, and we showed with the visual image systems, show me a picture of Italian plumber, and out would come, Mario from Nintendo. The system can't tell you that. It's just not built to be able to do that. I did want to close with, something I think this was an excerpt from the book, Not too long ago, about lies, Perhaps Adrian LaFrance said it best you wrote in an article in The Atlantic of Authoritarianism, Techno the new technocrats claim but in fact they're leading The world that silicon Valley elites of reckless social engineering They promise community. But so division claim to champion truth, in concepts but surveil us relentlessly. Fabulous passage It's sad. That's one of the best passages in But there you go. No, it's a really great, You're you're not alone in crying out like Cassandra and saying, you know, there are a lot of people out there Yeah, actually, on Twitter, people There's an old, rhetorical move, your opposition by kind of making So for various reasons, partly and so forth on Twitter, kind of portrayed who's worried about this stuff, And other people, for example, Adrian, have been far more articulate So, I mean, in fact, there's lots of excellent research Hannah, So, you know, it's a fun fiction to say, oh, Gary Marcus is the Antichrist, and he's just a hater And another rhetorical move Where is really I hate generative I want to say I'm not saying boycott I'm saying boycott this stuff that sucks But you know, people An ad hominem attack is the easiest way. Yeah, yeah. There's actually a piece. Yeah, in AI spectrum. There's an interview with me last week, with all of that ad hominem Why are you doing this? Because I think so much is at stake. You know, two little kids AI positive world point, like, I'm not going to do this I'm losing my voice now. But this is the moment where we're going to make these decisions. One person asks. We as educated adults are doing What are your thoughts on I wish I had a fuller answer. I mean, I think let's start There's no point in having prohibition I think schools should do is to teach kids to think critically about AI, How can they use it? How not. To? A little while ago, college professors should assign let the students use ChatGPT to figure out how they could write a better essay You know, make it a teachable moment says, I used the Marcus method. This was the best free press I ever got, They use the market. 63 out of 63 students This is went completely viral Every student found information, Then learn something. They learn how to use this technology and, I think teenagers need to do that. They they need to be taught. And perhaps they also need And they probably need People have to view this stuff There might be a future if we really had the Star Trek computer, I don't think we would have It wouldn't make them. That wouldn't be a valuable skill. But as long as we're in this interregnum AI and it's widely distributed, This person asks, as a college student, generative AI is something I see How do you recommend college students I mean, I think the last question The second piece of it is if you become dependent on it, you're not actually going to understand You're not really going to learn anything. So, I mean, I would use it sparingly. If I work on knowledge students. Like if your point and you use it, I'm not sure how much So I've been, as I mentioned earlier, Sometimes I'll of when a dual search for some specific information, And I'll try it in ChatGPT and And it's just interesting You know, what's highlighted, Yeah. We use the talk more, and getting students a web search and like, what is the quality of the source what is the word for? It makes opaque the sourcing. And so it's actually harder to judge because it spits it all out as if it were an encyclopedia, It's problematic. There are tools like perplexity but it's harder, of evaluating the answer as opposed to I think, you know, just in terms of like Right. You have to know a fair bit to know whether the article you're looking You know who sells it that. Yeah. If I can take a shot at a well-known he, he, put out something attack on Trump, with explosives And his source was something Like this And it was such a big thing. Like if there had actually been, and exposed to probably a bunch of media Nobody else was reporting on it. This is like a complete failure, But it was a complete failure to do source credible outlet, amplify it to, without spending five minutes to see whether this, And at this point so many generations, but those of us who are middle aged cast a jaundiced eye on what's called Like they must be wrong, however. Which, by the way, Yeah, exactly right. It's, so this person, you're before you've almost But now how do you respond to a question Do you think over the next ten, 20, to make life longer, healthier, happier, And how much more likely? In the long term, I think that I will surely make like, life longer. Whether it makes it because of the dynamics So, for example, totalitarian state to be very unhappy. So the happiness is not assured. I'm sure I will hope medicine, whether we get tangible you can think of the war on cancer. People are often like Ray Nixon We've made some progress, but we still haven't People sort of thought it was like So that was, you know, many decades ago, most of the remaining medical problems because we have so many proteins that you still need to do long term So, like, you know, we're not going to It's very, I will play a role probably, but certainly adding 20% But these are very hard problems. But I also think with medicine, right, for error Right. If a chat bot for some company, gets your order wrong or doesn't you know you're irritated, If if an error is made in the practice of medicine, Yeah. I mean, I do think that in some domains and then improvements So medical error is a huge, huge problem So it's certainly possible to do better. I don't think we're as close but it will happen. Same with driverless cars. Like they're not very good right now, I know you can use them in San Francisco, The vast majority of places in the world, And in most places in the world They might be here because they have You don't have such But the time come Human drivers are so bad in some ways. You know, there's room to do better. Self-regulation might not work, and government, where do we look Doesn't sound like it's OpenAI AI that we may learn and sure, standardize good practices. Another suggestion, I mean, I don't think we should be looking I mean, the big companies are always going I think they're probably true that But, you know, you can read my book. I have 11 different policy proposals, I'm actually giving away, by the way, So I have no financial vested interest, I think you can look at the area I act. I think you can look that people are doing in the field. I mean, would you go to the cigaret companies to say, Isn't there also risk from stagnating that it could leave us unprepared to confront humanity, a disaster I mean, first of all, I think that the notion that anybody is going to stagnate The amount of money being invested going to be deterred because they have to If they're doing $1 billion training run, It's a rumor that Silicon Valley But there is no world in which people You even have companies the leader of the company says this stuff but I'm racing as fast as possible. So if the thought that he might actually in three years is not enough to slow him million in paperwork for his company It's not it's So, I think it's silly to think I think the real problem is So if you think about it, What we've seen since GPT for came out or something like that, all building at the same scale, and having the same kind of problems the definition of insanity over and over again, This is what the field is doing now. Is, you know, $5,000 billion investment That's not the way to make progress. So this stagnation, it's because there's You know, as you say that though, I think of Silicon Valley technologies where everybody pivots at the same time you know, that are delivering information I guarantee it. You know, everyone just does it at the same time or decides to drop it You know, venture capital, venture But the reality is you get 2% of the money And so it's in your interest to have a plausible sales pitch, If you take 2% on a $250 million investment, you've made You don't really care And so I don't think venture capitalists of fostering innovation right now. And you might think, I'd actually like to see venture The potential risk of AI in military use feels like it would make the government How is that not enough? Never mind I mean, the government is very interested I guess I don't fully understand And then, you know, the government talks They're if nothing else, If generative AI is not good enough for corporate use, is there a different, better solution that could win versus GPT three? Wouldn't a trustworthy I think absolutely, but There is a chapter in the book you have a problem that generative and money from the room. And so it's hard for people And if you let's say and employees are expecting $5 million You can't do anything with two employees. I guess I wonder as you're talking, what you think the likely timeline is. It sounds like you're talking If not, response finally, from government. When do you know, just for those of us when do you anticipate I think the So, I mean, like, look at NFTs. I mean, if you had asked me, I forget what the timing is on the NFTs But at some point I was looking at them. I'm like, this is insane. But how much longer is I always think of Wily Coyote like he's over the cliff, So that's what's going on here, is the economics just don't make sense, especially since meta Like nobody has a moat. Nobody can say, I can build a product Now OpenAI has oh one, other DeepMind had a similar paper Like, none of this stuff is in an enduring And so the economics But, you know, for a little while, because other my guess is Nvidia will not stay at its current level, So like, you know, at what point do you stop buying So it depends on psychology. I wrote an article a year ago called What Not that many people paid attention, picked up the piece. Now somebody is writing a piece like that If enough people write pieces like that, sort of like a self-fulfilling prophecy, So that could happen any time. I wouldn't be surprised to see it happen this year, but it is. Irrationality So in recent years, a popular argument, is something akin to Apple ma China. You've got to let us do whatever we're going to do Otherwise, China will take the lead. If you really believe that, the people who run meta, right? Because meta just handed it So like, whatever value that argument at least this generation of AI let's come back to the notion of a dress This one is there for the taking. And China does take. One of the strangest things I ever saw Yann LeCun, who likes to brag, He said they recognize me on the streets what is that city. And the other city is Shanghai. Of course, he's because he's given this software away And so, you know, they love him there. I'm not sure that's what we in would like to have happen, So let me talk about I don't think, as you can tell, I think it will be better. I, I think we have learned some lessons One of those lessons is we really should think about open source. And, you know, what are the consequences Maybe ChatGPT will lead to real destruction, maybe it won't, Do we really want to hand this out? We have to think carefully about that. Another thing that we've learned maybe we can get away with that this time But but maybe they're not catastrophic. Maybe they're just really bad, you know? But maybe the next technology if we can't get a bill through California If you caused $500 million in damage, So I think we should be even if this is not the final technology Wherever you come down. Different military conflicts We see quite a few countries Russia, Iran, Israel, you know, playing with AI as a you know, as they pick targets, execute on strategies, you know, how long do you think, before those strategies come home to roost? Well, one of them already is coming home So in 2016, Russia spent $1 million a month That's a statistic in the Mueller report. Now they can do the same work and so can other countries Right. And so that is happening right now. There's been some reports already from the federal government Russia is using these tools for So some of that I guess that leaves which is, you did and, and, you know, making sure it was, so that as many people as possible Is there something, your, manuscript that that has evolved and you wish, gosh darn it, or I wish I could dial back the clock And there are and there aren't. I mean, like, I wish I had that covert racism study There's certainly some things people Gary Marcus, that substack.com, and I try I'll tell you a story, though, fear and greatest hope was that the book So, you know, submitted And then I had some months thinking, step up to the plate, put something out, Nobody would need the book. The book would look stupid right here. I am saying Congress has done its job. What a waste. No need to read that book. And so, you know, personally, I want people to read the book But also like as a human being, I figured, you know, it would be great Excuse me. But alas, here we are. We still need the book. Our thanks to Gary Marcus, Silicon Valley The Jackson Square Partners Foundation Broad Family If you would like to help continue in making virtual and in-person visit Commonwealth club.org/events. I'm Rachael Myrow, thank you. And thank you for joining us. On. The new.