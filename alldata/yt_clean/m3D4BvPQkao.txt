DaVinci Resolve 19 is out in public beta and we have a few great additions to Fusion. So we have color managed view LUTs finally, we have referenced Fusion compositions, we have additions to the USD toolset, we have better point tracking and a few other things that I tested thoroughly over the last few days. I went into everything that is either in Fusion or is somehow related to professional VFX workflows to really check where I might use those features. And here I want to report back to you and give you a thorough overview of everything Fusion and VFX related. Let's dive in. First things first, color management. I've been waiting for this since Fusion got integrated in DaVinci Resolve. We had different approaches over time to make Fusion match the viewer in the edit page and in the color page. And it was always a mess and there were always exceptions to the exceptions of where it's working and whatever. Now Fusion viewers are fully color managed for DaVinci Resolve color management. So if you use Resolve color management, you get the exact same image in the edit page as in Fusion. I've tried it with SDR. I've tried it with HDR. I've set it to DaVinci white gamut. And in all cases, it just simply worked. No more workarounds. Just turn it on, forget it. Great. Unfortunately, when I switch color management to ACES, which I personally would like to do more than DaVinci Resolve color management, unfortunately it is still inconsistent. So it seems like it's still managing the viewers when switching to ACES. And it does a slightly different form before, but it seems to be using Resolve color management with ACES spaces rather than the ACES transforms. I think that is a bit inconsistent and I wish the ACES transforms were also in the view lot available for manual transforms. So we do have that for Resolve color management, but for ACES there are still some steps missing. I just hope that's planned for one of the next releases now that we got Resolve color management covered. However, if you are doing manual workflows, then you might also appreciate that the OCIO toolset was brought up to date. So OCIO 2.3 is now supported, which also supports an OCIO view lot, which also supports ICC color profiles if you use that. So if you are in professional VFX workflows and you have your set up with open color IO, at least you are up to date with the toolset there. Reference fusion compositions. That's one of the headline features that I was really excited about when I first saw it, but the more I played with it, the more I backed off a little bit and felt it may not be exactly what I need. So reference fusion comps, the way it works, when you have any media clip in the timeline, you can, instead of just jumping into fusion or creating a fusion composition, you can instead create a reference composition that brings you a fusion composition, which lives in the media pool and is linked back into all the places where you use it in the timeline. So you have like one master and if you change that, it gets changed everywhere where you link to this reference composition in the timeline. This might be useful for overlays. I've played around here with a very basic glitch effect. And if I really want to use that in different places, I have one place where I can change the settings for that glitch effect and it gets automatically updated everywhere in the timeline where I use that effect. Now for those type of overlays, I think it's great. Blackmagic Design demonstrated it with a like logo animation overlay. You can do that. However, if it's something that doesn't interact with the image, then usually I would just put it in a compound clip and put that on top because that is also kind of linked to the media pool. So a compound clip can also be used like a regular clip in many places and you have one place where you can update it. So I don't really need it for overlays. I only need it for pieces that interact with the clip itself. However, if I have something that works on individual clips or even like text plus or individual elements, usually I need some level of customization for the individual clips. So in compositing, for example, I might have the same camera angle repeatedly. So I might need almost exactly the same comp many, many times. However, I probably have different tracking data animations I may have to change. Likewise, in motion graphics, you may have the same lower third template every single time, but you certainly want different texts in every lower third. So what you really want is more something similar to let's say a shared note in the color page or think about instancing in the fusion page. You need something where you have linked almost everything, but you can choose to not link certain elements. Unfortunately, that will not work with the referenced composition either so far. Nonetheless, give it a try and let me know if you have some really good place in your workflow for this. DaVinci Resolve render OFX plugin. If you have DaVinci Resolve Studio and you use other VFX authoring or compositing applications instead that do support OFX, then you can now make use of DaVinci Resolve's Renderer OFX plugin. That plugin allows you to render color page stills in other software. Here I've done a quick test with a simple curve and the color warper masked by an animated power window. So you see this effect has some spatial attributes. I could not share this effect with a LUT file. It's not possible. However, I can export a still and load it again here in Fusion Studio. And you see, I get the exact same look, including the animated power window in Fusion Studio. So if you're using with other OFX capable software, that might be quite nice if you want to work under a look developed in the color page and work with it somewhere else. This is vastly more powerful than any LUT export CDL export or whatever else you might try so you can really establish looks in the color page or start grading in the color page and make it accessible in other OFX capable applications. The only downside you do need to have the studio license on the same workstation where you run that OFX effect. If you're into motion graphics, we have some small but useful additions to the text plus tools. So on-screen controls we had previously in Fusion to insert text or to move characters around. They are now also available from the edit page. And in addition, we have some improvements for character, word and line based transforms. So you can see pivot points for characters and words now in the edit page. And you have an offset control, which is particularly useful if you start to animate it. So if you bring in a follower or modifier, for example, you can start to animate that offset on character line or word level position. We have more updates on Universal Scene Description. When it comes to Universal Scene Description, USD, I'm super happy about any update that Blackmagic Design adds because it shows some interest and some commitment into pushing Fusion really towards 3D capabilities, towards professional use, right? It's not just a title engine for Resolve. It is a professional compositing application and USD is where the industry is and where it's going. And these are up to date 3D capabilities, which are more and more replacing Fusion's somewhat dated original 3D system. Where are we now with USD in version 19? Well, if you have Dust, Smoke, etc., simulations, and you can get volumetric data, you can import it right in Fusion. I've loaded some examples here, so that seems to work well. We can also now create our own shaders in Fusion with USD. So remember USD started with version 18.5 with some basic support. Then in 18.6, we got material support to import material X shaders. Now we can create them by ourselves. And you see here, we have all the common material properties and I can use any number of common textures. To create a material from scratch, I bring in the shader node, add a U texture node to load a texture from file, a U texture transform in case I need to remap the texture coordinates in some way. And finally, I just connect it to the shader where I automatically get to choose the correct input of all the texture options. Specifically for a normal map, I also need to use a U normal. Here you see I'm loading some photo scan PBR materials that I got from Polyhaven and I loaded it into this little test scene where I used the text 3D together with HDR lighting. And this gives me this little scene. I have much better shading options than I had with Fusion's traditional 3D system. While USD is superior in many ways, it's still behind in some aspects. Think of camera tracking projections, masks in 3D space, exporting geometry from Fusion, those kinds of tasks, Fusion particles, of course, those kinds of tasks you still have to do through the traditional system. However, with the improvements we see and Blackmagic Design's commitment to bring USD forward in Fusion, I think we are really moving in the right direction and it might more and more replace 3D system from before. And then I hope that sooner or later we might get a real ray tracing render engine which people have speculated and wished for for over a decade. And I think with USD and Blackmagic Design's support for it, it's becoming much, much more likely that that might happen sometime soon. So let's hope for the best in this area. Shape tools. We have multiple enhancements across the Shape Tool set. If you're excited about motion graphics, we have an additional S Text node that works almost exactly like the 2D Text Plus tool. You have the same parameters, you have the same option to use modifiers and so on, but rather than an image, you output into the Shape Tool system and can manipulate it from there. There's Boolean, you can use it to intersect or merge shapes. So previously that forced you to replace the style of the shape. Now it doesn't, so you can maintain your colors. So that's a good addition. We do have an S B Spline. So in addition to the S Polygon, which sneaked in in one of the recent dot releases, we now also have B Splines. Speaking of polygons and B Splines and outlines in general, whenever you have an outline, you can now invert the direction of the line animation just by using negative numbers previously that produced some strange artifacts. Now it's working so you can move clockwise and counterclockwise. And another improvement you see right here in the S Duplicate. We had that node before. Now we can attach a polyline to duplicate across a path that gives additional options to draw or move or animate along a path. This behavior is not just in the S duplicate, but actually it's now in all the duplicate nodes. You find it in the regular duplicate for 2D images with alpha channel. You find it in the duplicate 3D if you want to duplicate 3D geometry. And there's also a U duplicate now for USD workflows. The new multi poly tool is something equivalent to the multi merge, but for polygons, if you have complex Roto, you usually separate polygons into smaller pieces that have independent movement and that are simpler to manipulate. So typically that leads to a lot of polygons that start filling up your node graph. And now you can bundle them up all in one tool, which is nice because it keeps your node graph cleaner. It can also help you with your viewer space. So you can close your node graph while rotoscoping, just use the polyline until you're done with the rotoscoping. That can help. In addition, you can animate the activation status of polylines. That's something that's nice. So when breaking apart movement into many shapes, we often don't need all the shapes, the entire duration of the shot. So typically I might animate the level slider or I have to deactivate them in some other way. here and just click the checkbox and the polygon is turned off on that frame. We have some added layout presets if you want your node graph in a different place. So now there's a left view and mid view preset. Actually we had them before, but now there's a distinction between the regular one and a vertical one, depending on whether your default node layout should be horizontal or vertical. Ultra noise reduction, the regular noise reduction from the color page and the corresponding Resolve FX effect has gotten an additional option for spatial noise reduction, which is an AI based ultra noise reduction mode. This one looks very simple. You have an analyze button, which automatically determines the noise and that's pretty much it and visual results immediately look great. Now I'm generally a bit skeptical about artificial intelligence when it comes to noise reduction because AI tends to make stuff up in order to create pleasing results. However, in many technical VFX workflows, we need noise reduction not to make a pleasing noise free appearance, but to get a noise free, technically clean and accurate image that we use for tracking, keying, whatever it is. And we might not use it later for the final appearance. So sometimes you use the noisy image to put it back in, or you might add the noise back on top after your compositing on top of the final comp. So since AI can tends to make stuff up, it's not always something I thought of. However, I gave it a shot and just compared to see what's going on. You see immediately the ultra noise reduction looks cleaner and sharper. That's what you would expect if the AI is giving an improvement and it certainly does. However, if I look at the noise alone, if I compute the difference and I've brought up the gain a bit here to illustrate it better, you see that the ultra noise reduction has artifacts and it doesn't really have less artifacts than the other one. It also doesn't really have more. It just seems to be different in different areas of the frame. I'm not yet 100% sure where this will fit in and how often I will use this. I think generally I will still start with temporal noise reduction most of the time at a minimum amount of spatial noise reduction. And I might give this ultra NR a try if I have some really tough noise to deal with. Nonetheless, I also have neat video, which works in Fusion Studio where this does not work. So I might not rely on it that heavily. Nonetheless, it's always great to have more options. And of course for colorists, this is certainly great. Just visually the results do look better. Just a short note on this. During my beta testing, I had some artifacts in the ultra noise reduction in Fusion. So the results I'm showing you here, I actually produced them from the color page. I do think there might still be a small bulk. I've reported it, but the effect should be available from Fusion and should work the same way. A big thing for Fusion is the Intelli track, which is now available in all areas of Resolve, including Fairlight, where you can track people to match sounds and space and so on. So in Fusion, the Intelli track is the new default in the point tracker. And it's an AI based tracker, which you just put on something you want to track and that's it. fiddling around with search radius and so on. To test it properly, I used this video here, which has really poor resolution and some compression artifacts, which makes tracking harder. And I tracked some rocks here in the foreground that move across some very similar rocks in the background, which gives options for the tracker to confuse the tracking point. And as you see here on this relatively tough example, I'm able to track the rock in the foreground without problems at all. Just one click track. It works. And if I use the traditional tracker workflow, you see it is jumping around a bit. And here you see the two tracks side by side, the red one from the Intelli track. This one is clean and smooth and looks good. The traditional track in green has lots of places where the tracking pattern jumped around and couldn't hold on to the feature. Only time will tell if I find any problems in the future where perhaps Intelli track fails and the traditional tracker works fine. We'll see if I find such scenarios at some point, but I suspect that for most cases, the Intelli tracker will be my new default. A little but important enhancement to the planar tracker, the planar transform node now has an option scale to source, which allows you to apply a track onto an image of different dimensions. Let's say you have a large frame that you track and a small element like a logo that you want to position on top. Previously, you first had to make the frame dimensions match so that the tracking data, the movement that the planar transform produces matches the size of the dimensions of the frame. Now we have this option here to automatically match the source. And as you see, it works just fine. It's clicked by default. So no longer worrying about the frame size when doing planar transforms. That's all the points that I've mentioned. There are always those general performance and stability improvements and a few minor things that were touched here and there. Some improvement to the multi-merge, something about, you know, resetting parameters with animation curves, you know, some minor fixes. The magic mask got faster and I tried it and I can confirm it does feel even faster than before. Yeah. stuff in the other pages. So if you are playing around with it, let us know what are the most exciting things from your perspective. Keep in mind, this is an early beta version. So if you are right now on a tight production schedule, maybe you want to wait with upgrading. But one thing this time, the upgrade does not require a database upgrade. So you should be able to move back to 18.6 or so if you need to step back. Nonetheless, I would always recommend backups. And if you are not sure that if you have them configured or not, now might be a good time before an upgrade to make sure that you can step back. All right. Let me know what you find and what do you find most exciting and see you again very soon for new tutorials. Cheers.