Well, good afternoon everyone. Got to love the buzz Welcome to the MaRS Discovery District, this wonderful complex for this very special co-hosted by the University of Toronto. My name is Meric Gertler and it's my great privilege of the University of Toronto. Before we begin, I want on which the University For thousands of years, it of the Huron-Wendat, the Seneca, and the Mississaugas of the Credit. Today, this meeting to many Indigenous people and we are very grateful to work and to gather on this land. Well, I'm truly delighted to this discussion university professor Emeritus known to many as the and Fei-Fei Li the in Computer Science at where she's Co-Director of I want to thank Radical Ventures and the other event partners to create this rare and Thanks in large part to of Professor Hinton and his colleagues, the University of Toronto of the academic AI community for decades. Deep learning is one of propelling the AI boom, and many of its key by Professor Hinton and This tradition of excellence, this long tradition Our faculty, students and graduates, together with partners and at universities around the world are advancing machine learning Later this fall, our and partners will begin of the beautiful new Schwartz just across the street. You may have noticed a at the corner with the for early next year. This facility will accelerate by creating Canada's largest university based innovation hub, made possible by a from Heather Reisman and Gerry Schwartz. The innovation campus for AI thought leadership, hosting both the Schwartz for Technology and Society, led by Professor Gillian Hadfield and the Vector Institute. It is already clear that and machine learning and value creation across the economy. They're also transforming research in fields like drug discovery, and the search for advanced materials. Of course, at the same time, there are growing concerns over the role that AI will play in So today's conversation clearly addresses a timely and important topic, and I am so pleased that on this momentous occasion. So without further ado, let me now introduce today's Jordan is managing partner and co-founder of Radical Ventures, a leading venture capital firm supporting AI-based and around the world. Earlier he co-founded Layer 6 AI and served as Co-CEO by TD Bank Group, which he Jordan serves as a Director for Advanced Research, and he was among the founders a concept that he dreamed up with Tomi Poutanen, Geoff Hinton, Ed Clark, and a few others. So distinguished guests, please join me in welcoming Jordan Jacobs. (audience applauding) - Come on up. Thanks very much, Meric. I wanted to start by who've helped to make this possible today, University of Toronto and Meric, Melanie Woodin, Dean of Arts and Science, and a number of partners that So this is the first in of founder AI masterclasses This is the third year we've done it, and today's the first one of this year. We do it in person and online. So we've got thousands of So if you decide you maybe head outside. We do that in partnership and thank them very much for their participation and support with the Alberta Machine and with Stanford AI, thanks to Fei-Fei. So thank you all of you for We're hoping that this is gonna be a really interesting discussion. This is the first time who I like to think of as but this is the first time they're doing this publicly together. So it's, I think, gonna be a really interesting conversation. Let me quickly do some deeper explanations of their background. Geoff is often called the Godfather of Artificial Intelligence. He's won the touring award. He is a Professor Emeritus co-founder of the Vector Institute, also mentored in a lot of the people who have gone on to be including at the big companies and many of the top research So when we say godfather, it really is, there are many kinds of children who are leading the world in AI and that all comes back to Toronto. Fei-Fei is the founding Director for Human-Centered AI, Professor at Stanford. She's an elected member of Engineering in the US, the National Academy of Medicine in the American Academy During a sabbatical from she stepped in for a role as as Chief Scientist of There's many, many other things but she also has an who have gone on to be And really importantly, and so for those of you Fei-Fei has a book coming It is called, it's coming it's called &quot;The Worlds I See, Curiosity, Exploration, and I've read it, it's fantastic. You should all go out and buy it. I'll read you the back 'cause it's much better than So here's Geoff's description. &quot;Fei-Fei Li was the first to truly understand the power of big data, and her work opened the She delivers an urgent, clear-eyed account of the awesome potential and danger of the AI technology And her call for action and is desperately needed at this So I urge you all to go and read it as soon as it comes out. With that, thanks Fei-Fei - Thank you, Jordan. (audience applauding) - Okay, so I think it's to say that without these two people, the modern age of AI does not exist, certainly not in the way So let's go back to what I AlexNet ImageNet, maybe Geoff, do you want to take us that moment which is 11 years ago now? - Okay, so in 2012, two of my won a competition, a public competition, and showed that deep neural networks could do much better than Now, this wouldn't have been possible without a big data set that Up to that point, there of labeled images, and Fei-Fei was responsible And I'd like to start by asking Fei-Fei whether there were any problems in putting together that data set? (audience laughing) - Well, thank you Geoff, and thank you University Toronto for this, it's really fun to be here. So yes, the data set that is called ImageNet. And I began building it 2007 and spent the next three years pretty much with my graduate students building it. And you asked me was there where do I even begin? (Fei-Fei laughing) Even at the conception of this project I was told that it really was a bad idea. I was a young Assistant Professor. I remember it was my first year actually as a Assistant Professor at Princeton and for example, a very respected mentor of mine in the field, if you know the academic jargon, these are the people who will be writing my tenure evaluations, actually told me really out of their good heart that please don't do what this plan is back in 2007. - So that would've been Jitendra right? (audience laughing) - The advice was that, &quot;You might have trouble And then I also tried to and nobody in machine learning or AI wanted to even go close to this project, and of course no funding. (audience laughing) - Just describe ImageNet to us for the people who are not - Yeah, so ImageNet was and the reason I conceived One is that, and Geoff, I think we I was trained as a scientist, to me, doing science is And in the field of AI, for me, object recognition, the ability for computers to recognize there's or there's a chair is has to be a North star And I feel that we need in this problem. So I want to define that North Star problem, that was one aspect of ImageNet. Second aspect of ImageNet was recognizing that machine learning was a little bit at that time, that we were making without the kind of data to Of course, in our jargon, it's really the And I recognize that we and rethink about machine learning from a data driven point of view. So I wanted to go crazy and make a data set that in terms of its quantity and So ImageNet after three of internet images that's totaled 15 million images across 22,000 concepts, object category concepts. And that was the data set - Just for comparison, at the same time in Toronto we were making a data set called CIFAR-10 that had 10 different and it was a lot of work, with general generously paid for by CIDAR at five cents an image. - And so you turn the data just walk us through a little bit of what that meant, and then we'll kind of - Right. So we made the data set in 2009. We barely made it into a poster And no one paid attention. So it was a little desperate at that time. And I believe this is the way to go. And we open sourced it, but even with open source, it wasn't really picking up. So my students and I thought, well let's get a little more Let's create a competition to invite the worldwide research community to participate in this through ImageNet. So we made a ImageNet competition and the first feedback we got from our friends and And at that time you can not let alone memory. So we actually created a smaller data set called the ImageNet challenge data set, which is only 1 million images across 1000 categories and that was unleashed in 2010, I think. You guys noticed it in 2011, right? - Yes. - And so in my lab we already working quite well for speech recognition. And then Ilya Sutskever said, &quot;What we've got really ought to be able to win the ImageNet competition.&quot; And he tried to convince And I said, well, you know, And he tried to convince and Alex wasn't really interested. So Ilya actually to put it in just the - You shrunk the size of the images. - Yes. - He shrunk the images a bit. - Yeah, I remember. - And got it pre-processed and then Alex eventually agreed to do it. Meanwhile, in Yann Yann was desperately and postdocs to work on this data set. 'Cause he said, &quot;The first person to apply convolutional nets to And none of his students were interested. They were all busy doing other things. And so Alex and Ilya got on with it, and we discovered by running on the previous that we were doing much better And so we knew we were gonna And then there was this political problem, which is we thought if we win this competition, the Computer Vision people, Jitendra in particular will say, well that just shows it's So we had to get them that if we won the competition, we'd proved that neural networks worked. So actually called up Jitendra and we talked about data And my objective was to that if we could do ImageNet, then neural nets really worked. And after some discussion and him telling me to do other data sets, we eventually agreed, okay, then we'd have shown neural nets work. Jitendra remembers it and he was the one who told us to do it, but it was actually a And we did it and it was amazing. We got just over half the error rate of the standard techniques. And the standard techniques by very good researchers. - I remember standard the previous year is with sparsification. - That was, so you guys submitted I think it was late And I remember either or getting an email late who was running this because we hold the test data we were running on the server side. The goal is that we have so that we select the winners, and then by, I think it was that Computer Vision Fields ICCV 2012 was happening We already booked a workshop, annual workshop at the conference. We will be announcing the winner, it's the third year. So a couple of weeks before Because it was the third year and frankly the previous two years results didn't excite me, and I was a nursing mother at that time. So I decided not to go to the third year, so I didn't book any tickets. I'm just like, too far from me. And then the results came in, that evening, phone call or email, I really don't remember, came in. And I remember saying to now I have to get a ticket to Italy. Because I knew that was a especially with a which I learned as a graduate student, as a classic algorithm. And of course by that time there was only middle seats economy class flying from San Francisco to Florence with a one stop layover. So it was a grueling - I'm sorry. (audience laughing) Yeah, but you didn't come. - No (audience laughing) Well, it was a grueling trip. - But did you know that - Yes, I did actually. - You did, and you still didn't come. But you sent Alex. - Alex, yes. - Who ignored all your advice? - Who ignored my email for multiple times, 'cause I was like, Alex, this is so cool, please do this visualization, He ignored me. But Yann LeCun came and it was because, for those of you who have attended these academic conference workshops tend to book these smaller rooms. We booked a very small room, probably just the middle section here. And I remember Yann had to because it was really packed, and Alex eventually showed up 'cause I was really nervous that he wasn't even gonna show up. But as you predicted at that workshop ImageNet was being attacked. At that workshop there were this is a bad dataset. - In the room? - In the room . - During the presentation? - But not Jitendra, 'cause Jitendra has already - Yeah, I don't think I don't remember. But I remember it was such because as a machine learning researcher, I knew history was in the making, yet ImageNet was being attacked. It was just a very strange, it was exciting moment. And then I had to hop in the middle seat to get back to San Francisco because then the next morning. - So you mentioned a few people that I want to come back to later. So Ilya who's founder and and Yann LeCun who subsequently went on to be head of AI at Facebook now Meta, and there's a number of other But before we go forward and kind of see what let's just go back for a little bit. Both of you started in this with kind of a very specific goal in mind that is an individual and and you had to persevere that you just described, but kind of throughout your careers. Can you just go back, give us a background to why did you want to get - I did psychology as an undergraduate. I didn't do very well at it. And I decided they were how the mind worked unless they figured out And so I wanted to figure and I wanted to have an So you can think of as building a bridge. There's experimental data and things you can learn and there's things that will things that will recognize objects. And they were very different. And I think of it as you between the data and the competence, the ability to do the task. And I always saw myself as starting at the end but trying to make them more but still work. Other people tried to stay with things justified by empirical data, and try and have theories that might work. But we're trying to build that bridge and not many people were Terry Sejnowski was from the other end, and so we got along very well. A lot of people doing, trying to do computer vision, just wanted something that worked, they didn't care about the brain. And a lot of people who wanted to understand how but didn't want to think much about the nature of the computations. And I still see it as we by getting people who know about the data and people who know about So my aim was always to make but do vision in the - Okay, so we're gonna come back to that 'cause I want to ask you about the most recent developments and how you think that Fei-Fei, so Geoff just to on where you started, by mid to late '80, you along that route, funding and the way the approach kind of goes like this, but I'd say mostly like this- - It went up and down. - Fei-Fei you started your Like can you walk us through a little bit of how you came to AI? - Yeah, so I started my life in China, and when I was 15-year-old, my parents and I came to So I became a new immigrant and where I started was first English as second language classes, 'cause I didn't speak the language, and just working in laundries, and restaurants and and so on. But I had a passion for physics. I don't know how it got into my head. And I wanted to go to Princeton because all I know was Einstein was there, and I got into Princeton, he wasn't there by the - You're not that old. But there was a statue of him. And the one thing I learned in physics, beyond all the math and all that is really the audacity to like the smallest particles or the boundary of space time And along the way I discover brain as a third year Roger Yeah, you might have opinions, but at least I've read those books. - It was probably better that you didn't. (audience laughing) - Well it at least got And by the time I was graduating I wanted to ask the most And to me the absolute most of my generation that was So I went to Caltech to get a dual, pretty much a dual PhD in neuroscience with Christof Koch, and in AI with Pietro Perona. So I so echo Geoff, what because that five years allow me to work on computational neuroscience and look at how the mind works, as well as to work on and try to build that computer program that can mimic the human brain. So that's my journey, - Okay, so your journeys - By the way, I met Geoff when I was a graduate student. I used to go visit Pietro's lab. - Yeah. - In fact he actually offered me a job at Caltech when I was 17. - You would've been my advisor. - No, I would not, not when I was 17. - Oh, okay. - Okay, so we intersected at ImageNet, I mean in the field everyone knows that ImageNet is this big bang moment and subsequent to that first and basically start buying and to get them into the companies. I think they were the first ones to realize the potential of this. I would like to talk but kind of fast forwarding, I think it's only now since ChatGPT that the rest of the world is catching up to the power of AI. Because finally you can play with it. You can experience it, in the boardroom they can talk about it, and then go home, and then the 10-year-old kid has just written a dinosaur essay for fifth grade with ChatGPT. So that kind of transcendent experience of everyone being able to play with it, I think has been a huge shift. But in the period in there is kind of this inside the big tech companies, and everyone else is not really Can can you just talk us Because you experienced a kind of a ground zero post ImageNet. - It's difficult for us of everybody else not 'cause we realized what was going on. So a lot of the universities you'd have thought would were very slow in picking up on it. So MIT for example, and Berkeley, I remember going even talking in Berkeley in I think 2013 when already AI was being very successful in Computer Vision. And afterwards a graduate and he said, &quot;I've been and this is the first talk I've heard about neural networks. They're really interesting.&quot; - Well, they should have gone to Stanford. - Probably, probably. But the same with MIT, they were rigidly against And the ImageNet moment and now they're big But it's hard to imagine now, but around 2010 or 2011 there was the Computer Vision people, very good Computer Vision people who were really adamantly They were so against it that, for example, one of the main journals, - PAM? Had a policy not to referee papers on neural nets at one point. Just send them back, don't referee them, it's a waste of time, And Yann LaCun sent a where he had a neural net that at doing segmentation of pedestrians than the state of the art. And it was rejected. And it was one of the was one of the referees said, &quot;This tells us nothing about vision.&quot; 'Cause they had this view of which is you study the nature you formulate an algorithm you figure out how to and then you publish a paper. In fact, it doesn't work to it - I have to defend my - Not everybody. - So there are people who are- - But most of them were And then something remarkable happened after the ImageNet competition, which is, they all changed within about a year. All the people who have of neural nets started doing neural nets, much to our chagrin, and some of them did it better than us. So this (indistinct) made a better neural net very quickly. But they behaved like which is that the strong Because of ImageNet we that it wasn't and then they changed. So that was very comforting. - And just to carry it forward, so what you're trying to show, you're trying to label these 15 million images accurately, you've got them all so you can measure it. The error rate when you did it dropped from 26% the year before, I think to 16% or so. - Yep. - Okay. And then it subsequently keeps- - 15.32. (audience laughing) - I knew you'd remember. - Geoff doesn't forget. And then in subsequent years people are using more powerful neural nets and it continues to drop to the point where it surpasses- - 2015. So there's a Canadian, very smart Canadian his name is Andrej Karpathy. And he got bored one summer and said, &quot;I want to measure how humans do.&quot; So you should go read his blog. So he had all these like human doing image that test parties, he had to bribe them with pizza I think. with my students in the lab. And they got to a accuracy Was it five or 3.5? - Three. 3.5 I think. - So humans basically make mistakes about 3% of the time? And then I think 2016, I - Yeah. is that year's winning algorithm passed the human performance. - And then ultimately you because it was so much - We had to retire 'cause - Okay, alright. It's a different reason. - A bad reason. - Instantly that student started life at the University of Toronto. - Where he went to your lab, and then he went to be - Okay, first of all, he came to Stanford to be a PhD student. And yesterday night we were talking, actually there was a in the middle of this. And then he became part of - But then he went to Tesla. - And then he thought better of it. - He's back. But I do want to answer your - Well there's a couple of - Right. - Right. - So the transformer paper is paper written inside Google, another Canadian is a who's now the CEO and who I think was a 20-year-old when co-authored the paper. So there's a tradition of Canadians being involved But Geoff, you were at Google was there an awareness inside Google of how important this would be? - I don't think there was, but it took me several years to realize how important it was. And at Google people didn't realize how important it was until BERT so BERT used transformers, and BERT then became a lot better at a lot of natural language for a lot of different tasks. And that's when people realized - So 2017 the transformer I also joined Google, and I think you and I actually met on my first week. - I think most of 2017 and 2018 was neuro-architecture search. - I think that was Google's bet. - Yep. of GPUs being used. So it was a different bet. - So just to explain that essentially means this, you get yourself a whole lot of GPUs, and you just try lots of to see which works best It's basically automated evolution for neural net architectures. - It's like hyper parameter to new. - Yeah. - And it led to some- - Quite big improvements. - But nothing like transformers. And transformers were a huge improvement for natural language - Neural architecture search - Yeah. - So I'll tell you our So we were doing our I think we saw a pre-read of the paper and we were in the middle of a fundraising and a bunch of acquisition And I mean, not just me, but my partner told me and Maksims Volkovs who came And we thought this is the we should sell the company, start a venture fund and that are gonna be using transformers. So we figured it would take five years to get adopted beyond Google. And then from that moment forward, it would be 10 years for all the software in the world to get replaced or embedded with this technology. We made that decision before ChatGPT came out. So I'm glad to see we but I have to give who I thought I understood but they were able to explain it fully. - I should just correct you, I don't think Tomi ever studied with me. He wanted to come study with me, but a colleague in my department told him if he came to work with me, that would be the end of his career and he should go do something else. - So he took the classes, and this is my partner was doing a master's at U of T, and he wanted to go study with And his girlfriend, now wife's father, who was a engineering neural nets are a dead end.&quot; So instead he took the classes but wrote his thesis in cryptocurrency. (audience laughing) Okay, so- - Are you still gonna Because I think there's - Yeah, so go ahead. - So I do think there's overlooked this 10 years and ChatGPT. Most of the world sees or we see it as a tech 10 years, in the big tech there's things brewing. I mean it took sequence but things are brewing. But I do think for me personally and for the world, it's between tech to society. I actually think personally, to a humanist in this 10 years. Because having joined in the middle of the transformer papers, I begin to see the societal It was post AlphaGo moment and very quickly we got It was where bias it was creeping out, there was privacy issues. And then we're starting of disinformation and misinformation. And then we're starting to see the talks of job within a small circle, not within in a big public discourse. It was when I grew personally anxious, I feel, you know 2018- Oh, oh, it was also right So that huge implication of but it's algorithm driven that's when I had to of staying at Google or And I knew the only to Stanford was starting this to really, really understand the human side of this technology. So I think this is a even though it's kind of not but this technology is the rest of our lives. And of course 2022, it's all shown under the daylight how profound this is. - There's an interesting footnote to what happened during which is ultimately you and but before that there was that had the opportunity to Do you want us, I've heard this story but I don't think it's Maybe do you want to share - Okay, so the technology for the ImageNet, we developed it in 2009 for for doing the acoustic modeling, So you can take the sound wave and you can make a thing which just tells you at each time how much energy that is at each frequency. So you're probably used And what you'd like to do and make guesses about which part of which phonamium is being expressed by the middle frame of the spectrogram. And two students, George Dahl and another student who I shared with Gerald Penn called Abdo, he had a longer name, who was a speech expert, Over the summer of 2009, they made a model that was better than what 30 years of speech research had been able to produce, and big, big teams working And the model was slightly better, not as big as the ImageNet And that model was then by George went to Microsoft and Abdo went to IBM, and those big speech groups And I had a third student who'd been working on something else, called Navdeep, Navdeep Jaitly. And he wanted to take to a big company, but he wanted to stay in Canada for complicated visa reasons. And so we got in touch and we said we've got this new way of doing speech recognition and it works better than and we'd like a student to and show you how to use it, and then you can have the in your cell phone. And they said after some discussions, a fairly senior gap Blackberry said, &quot;We are not interested.&quot; So our attempt to give it And so then Navdeep took it to Google, and Google were the first So in 2012, around the same time as we won the ImageNet competition, George and Abdo's speech the acoustic model was in, there was a lot of work and making it have low latency and so on, that came out in the Android. And there was a moment when as good as Siri at speech recognition and that was a neural net. And I think for the people that was another ingredient. They saw it get this but they also saw that it for speech recognition was So I think that combination it does vision, clearly - We won't say anymore about Blackberry. It was a shame that I think we might have if that happened. (audience laughing) - Alright, we'll leave that one there. (audience laughing) I thought it was a story, but I thought it was important to know some of what went why this technology didn't stay in Canada even though it was offered for free. Okay, so let's advance forward. We now have post transformers, Google is starting to use this and develop it in a OpenAI, where your former been a founder of OpenAI with Greg Brockman and a few others. Ilya is the chief scientist, and Andrej your student as a co-founder. So they are working to basically take turns, well initially the idea artificial general intelligence, ultimately the transformer they start to adopt at and they start to make they're not really sharing publicly in what they're able to do and a number of other things. They had efforts going on Pieter Abbeel ended up a company we subsequently But so the language part of it advances, and advances and advances. People outside OpenAI don't really know to the extent what's going on. And then ChatGPT comes out So 10 months ago. caught the attention of some of us. I think actually, I think my colleague Percy Liang, I remember he came to me and say, &quot;Fei-Fei I have a whole of how important this technology is.&quot; So to the credit of Percy, he immediately asked HAI to And I don't know if this Stanford is the university foundation models, and some people call it But going beyond language, we We created the center of research for foundation model before, So definitely before ChatGPT. what a foundation model is just for those who are not familiar. - That's actually a great question. Foundation model, some people feel it has to have transformer in it. I don't know if you use- a very big huge amount of data. - Very large, pretrained And I think one of the of a foundation model of multiple tasks. You're not training it for So in NLP, machine translation but the kind of foundation model like GPT is able to do is able to do conversation, summarization, and blah blah blah. So that's a foundation model and we're seeing that We're seeing a vision, in So we created that. But you're right, the - 10 months ago. - October 30th. - November. - One other very important which is for a long time the general opinion was if you give 'em enough training data, they can do complicated things, but they need an awful They need to see thousands of cats. And people are much more That is they can learn to do And people don't say that so much anymore because what they were what an MIT undergraduate can learn to do on the limited amount of data with what a neural net that can learn to do on a - Yeah, that's an unfair comparison. a fair comparison, you take a foundation that's been trained on and then you give it and you ask how much data does it need to learn this completely new task? And that's called few shot learning 'cause it doesn't take much. And then you discover these things are statistically efficient. That is, they compare in how much data they need So the old kind of innatist idea that we come with lots and that makes us far you just learn everything from data. People have pretty much because you take a foundation model that had no innate knowledge and then you give it a new task, it learns pretty efficiently. It doesn't need huge amounts of data. - You know, my PhD is but it's very interesting, even in Beijing framework but it's only in the neuro network kind of pre-training really - Right. - Okay, so this basically the world experiences it, although for some of us it feels like- - Much longer. - Because you suddenly you have this, you had this big bang that that I think for a long time no one really saw the results of it, suddenly, I mean my comparison would be there's planets that are formed, and stars that are visible, and everyone can experience the results of what and then transformed, etc. So the world suddenly what I think feels to a Something that they can and gives them back a feedback in whatever way they're asking for it. Whether they're putting in text prompts and asking for an image to be created, or video, or texts, and asking for more texts to come back and answer things that you and getting those unexpected answers. So it feels a little bit like magic. My personal view is that, we've always moved the goal line in AI. AI is always the thing it's always the magic. And as soon as we get there then we say that's not AI at all, or there's people around that We move the the goal line. In this case what was your I know part of your and decided to do different things, but when you first saw - Well, like Fei-Fei said, GPT-2 made a big impression on us all. And then there was a steady progression, also I'd seen things and GPT-3.5 that were So that in itself didn't It was more PaLM made an 'cause PaLM could explain and I'd always just use that as a, we'll know that it really gets it when it can explain why a joke is funny. And PaLM could do that. Not for every joke but for a lot of jokes. - And so- are quite good now at but they're terrible at telling jokes, and there's a reason which is they generate text one word at a time. So if you ask them to tell a joke, what they do is they're So they're gonna try and tell So they say, a priest and and that sounds a bit like and they keep going telling stuff that sounds like the beginning of a joke. But then they get to the point where they need the punchline. And of course they haven't thought ahead, they haven't thought what's They're just trying to make it sound like they lead into a joke, and then they give you a 'cause they have to come So although they can explain jokes 'cause they get to see the whole joke before they say anything, they can't tell jokes, but we'll fix that. - Okay, so I was going to ask you if comedian is a job of the future or not. You think soon? - Probably not. - All right. - So what was your reaction to it? And again, you've seen things behind the scenes along the way. - A couple of reaction. My first reaction is of the power of data, and I was still old by the power of data. That was a technical reaction. I was like, darn it, I should No, but maybe not, but that was really- - Funding is the problem. Yeah, so that was first. Second, when I saw the with ChatGBT, not just the GPT-2 technology moment, I generally thought, thank goodness we've for the past four years. Thank goodness we have built a bridge with the policy makers, with the civil society. We have not done enough, but thank goodness that that We were participating it, we were leading some part of it. For example, we as a we're leading a critical that is still going - [Geoff] Not right now actually. - Senate, Senate, it's by camera, so at least it's moving the senate because we predicted the societal moment for this tech. We don't know when it would come, but we knew it would come, and it was just a sense I feel that this is the moment we really have to rise to, not only our passion as technologist, but responsibility as humanists. - And so you both, I think the common reaction we have to think about both but also the negative consequences of it. - So for me, there was and didn't realize until very late, and what got me much more was like Fei-Fei said, the power of data. These big chatbots have seen thousands of times more data than any And the reason they can do that is 'cause you can make thousands of copies of the same model, and each copy can look at a and they can get a gradient from that of how to change their parameters, and they can then share So every copy can benefit from what all the other and we can't do that. If suppose you had 10,000 people and they went out and they and after they've each read one book, all of them know what's in all the books. We could get to be very smart that way, and that's what these things are doing and so it makes them far superior to us. There's some schooling that but not in the way. But education's just hopeless, I mean hardly worth paying for. (audience laughing) - Except University of (audience laughing) - I've tried to explain to friends that Geoff has a very and if you spend enough time But I'll leave it to you to decide whether that was sarcastic. - So the way we exchange this is something of a simplification, but I produce a sentence and you figure out what you so you might have said that, that is if you trust me. We can do that with these models too. If you want one neural net architecture to know what another architecture knows, which is a completely you can't just give it the weights. So you get one to mimic that's called distillation and that's how we learn from each other. But it's very inefficient, it's limited by the which is a few hundred bits. Whereas if you have these models, these digital agents which each of them looks at and then they share the gradients, they're sharing a trillion numbers. So you are comparing an that's in trillions of numbers with something that's hundreds of bits. They're just much, much - So I guess Geoff that- So I agree with you at but it sounded like for you that's the moment that got - That's the moment I - Yeah, I'm less negative than you. I'll explain later, but I think that's where we- let's talk about that. Explain why you are optimistic and let's understand why - I'm pessimistic 'cause the (audience laughing) - I thought I was a pessimist too. We have this conversation. So I don't know if I should I think I'm- Look when you came to a now speaking a single bit of there's something very I think technology, our human relationship with than an academia typically would predict, 'cause we come to academia we want to make a discovery, we want to build a piece of technology, but we tend to be purist. But when the technology and reach the societal level, it is inevitably messily And this is where maybe is my sense of humanity. I believe in humanity. I believe in the, not only but also of collective will, the arc of history is dicey sometimes. But if we do the right thing, we have a chance, we of creating a future that's better. So what I really feel is not delusional optimism at this point, is actually a sense of And one thing Geoff, I think, I really hope you do feel positive is you look at the students in my class I teach a 600 undergrad class every spring on introduction of deep This generation compared to even five years ago is so different. They walk into our class not only wanting to learn gen AI, they want to talk about ethics, they want to talk about policy, they want to understand privacy and bias. And I think that really is where I see that the humanity rising to the occasion. And I think it's fragile. I mean look at what's going on it's very fragile, but I think if we recognize - So I see the same thing. - Oh good. undergraduates anymore, but I see it in sort of - Yeah. University of Toronto for example, two of the most brilliant young professors went off to anthropic Roger Grosse is coming back again, I hope. And AI, for example, is now - Yes. a huge shift now, and I think that will help solve this problem, but I can encourage these - Thank you. - To work on these ideas and they really are working on 'em now, they're taking it seriously. - Yeah, as long as we put like many of you, I'm looking onto this problem, this is where my hope comes from. - So Geoff, you left Google in large part to be able to go and in the way that you wanted to. And basically - that's not really true, that's the media story and it sounds good. I left Google 'cause I was old and tired and wanted to retire and watch Netflix. (audience laughing) And I happened to have the to say some things I'd been and not have to worry about how Google would respond. So it's more like that. we'll come back to the - I was going to say. - But in the meantime, but you did go out, and start speaking pretty significantly- - Yes. I think you've both spoken in the last eight months from presidents and prime ministers, right through congress, parliament, etc. Geoff can you explain what you were trying to and whether you think - Yeah, so people talk about AI risk, but there's a whole So there's a risk that and not create as many jobs. And so we'll have a whole And we need to worry hard about that because the increasing productivity AI is going to cause is not going to get shared with the people who lose the jobs. Rich people are going to get richer and poor people are going to get poorer. And even if you have basic income, that's not going to solve the of many people want to have a job to feel they're doing something important, including academics. And so that's one problem. Then there's a problem of fake news, which is a quite different problem. Then there's a problem of battle robots, that's a quite different problem again. All the big defense departments want to make battle robots, and nobody's going to stop them and it's going to be horrible. And maybe eventually after we've had some we'll get something like like we did with chemical weapons. It wasn't until after they were used that people could do something about it. Then there's the existential risk. And the existential risk And the existential risk is because we've developed a that decides to take control, and if it gets to be much smarter than us. So there's a lot of hypotheses here. It's a time of huge uncertainty. You shouldn't take anything So if we make something because these digital intelligences so can learn much more, we will inevitably get those smart things to create sub goals. So if you want 'em to do something in order to do that they'll figure out, well, you have to do something else first. Like if you want to go to Europe, you have to get to the airport. That's a sub goal. So they will make sub-goals and there's a very obvious sub-goal, which is if you want to get If you get more control, it's going to be easier to do things. And so anything that has the ability to create sub-goals will create the sub-goal And if things much more want to get control, they will, we won't be able to stop them. So we somehow have to figure out how we stop them ever And there's some hope. These things didn't evolve, they're not nasty competitive things. They're however we make So with a digital intelligence, you just store the weight somewhere and you can always run it So they really, we've actually discovered The only problem is it's not for us, we are mortal. But these other things are immortal. And that might make them much nicer 'cause they're not worried about dying and they don't have to sort of- - Like Greek gods. - Well, they're very like Greek gods, and I have to say something This is Elon Musk's belief that, yes, we are the kind of bootloader for digital intelligence. We are this relatively that is just smart enough and that's going to be a much And Elon Musk thinks it'll keep us around 'cause the world will be more interesting with people in it than without. Which seems like a very thin thread to hang your future from. But it relates to what Fei-Fei is said, it's very like the Greek god's model, that the gods have people - Okay, can I comment on that? - Yes. (audience laughing) - Nothing you said was controversial. - Yeah, no, not at all. So I want to bucket your four concerns, economy, labor, disinformation and then the extinction Greek gods- - (indistinct) discrimination and bias. - Okay, so I want to bucket The Greek god extinction everything else I would call catastrophic. - [Geoff] Yeah, merely catastrophic. - Catastrophic danger. And I want to comment on this, I think that one thing I really as someone in the AI is making sure we are not especially with public policy makers. The extinction risk is, is a really interesting thought process that academia and think - That's what I thought for many years, I thought it was a long and having philosophers and academics working on it was great. I think it's much more urgent. - It might, but this process Humans are in this messy process. So I think there is a lot of nuance. For example, we talk about nuclear. I know nuclear is much more narrow, but if you think about nuclear, it's not just the theory of It's really obtaining the system engineering, I'm sure you watch the So here, if we're going towards that way, I think we have a fighting because we are human society. We're going to put guardrails, I don't want to paint the picture that tomorrow we're going to especially in a robotic creating the machine overlords. I really think we need but I don't disagree with you that this is something we So this is the extinction bucket. The catastrophic risk bucket, I think it's much more real. I think we need the smartest people and the more the merrier to work on. So just just to comment weaponization, this is really real. I completely agree with you. We need international partnership, we need potential treaties, we need to understand the parameters. And this is humanity's, as much as I'm optimistic about humanity, I'm also pessimistic about as well as the destroying each other. So we've gotta get people working on this, and our friend Stuart Russell, and many of the even AI And second bucket you talk This is again, I mean 2024, everybody's watching the US election and how AI will play out. And, I think we have to get we have to get on the Technically I'm seeing more work now. Digital authentication technically is actually a very I think we need to invest in this. I know Adobe is, I know I hope there's startups looking at digital authentication. But we need also policy. And then jobs. I cannot agree more. I actually, you use that I think it's really at is human dignity. Human dignity is just beyond how many hours you work. I actually think if we do this right, we're going to move from labor in the sense that humans with the help of machines will be making money because of passion, and rather than just those jobs that are really grueling and grinding. And this is also why has a founding principle We see this in healthcare, one of the biggest I've got a doctor friend who walked to me and said, &quot;Fei-Fei I want to thank you for ChatGPT.&quot; I said, I didn't do anything. But he said that we are using medical summarization tool from GPT because this is a huge it's taking time away from patients. But because of this, I get more time. And this is a perfect example, and we're going to see this more. We might even see this So we have a chance to make this right. I would add another concern is actually you talk One of the power imbalance and it's exacerbating that as a huge speed is leaving public sector out. I don't know about Canada, not a single university in the US today can train a ChatGPT in And I think combining GPT-A100 or H100, probably nobody has it, but A100 cannot train a ChatGPT. But this is where we for curing cancer, for for economics and legal studies. We need to invest in public sector. If we don't do it now, we're going to fail an entire generation, and we're going to leave that power imbalance in such a dangerous way. So I do agree with you. I think we've got so and we need to get on this. This is why we need to and civil society. So I don't know if I'm saying or in a pessimistic, some were pessimistic to myself now, but I do think there's a - Well, optimistically, very vocal about this over there has been a huge shift key researchers going and and then public and policy shifting in a way that governments are So I mean, you are and US government, you've spoken to them as well, and you've sat with the prime minister or multiple prime ministers maybe, and they're listening right, in a way that they 10 months ago, 12 months ago. Are you optimistic about the - I'm optimistic that that there's this whole bunch of problems, both the catastrophic risks And I agree with Fei-Fei completely, the catastrophic risks are more urgent. In particular 2024 is very urgent. I am quite optimistic that - Yes, I agree. I think they're listening. But I do want to say, first of all, who are you listening from? Again, I see a asymmetry between public sector and private sector, and even private sector It shouldn't just be big there is a lot of agriculture sector, education sector. And second is then after all this noise, what is a good policy? We talk about regulation and I actually don't there's always America Where's Canada? - Okay, good, good for you. So I actually think we need building public sector, unlocking the power of data. We have so much data that whether it's forest fire traffic data, the climate data, and that's incentivization. And then there's good regulation, for example, we're very vocal about, you have to be so careful in regulating, where do you regulate One of the most urgent is where rubber meets the road, is when technology is now in the form of a product or service. It's going to meet people, food, financial services, transportation. And then you've got they're not far from perfect, so we need to empower and update them rather than wasting time and possibly making the wrong decision of creating entirely when we have the existing ones. - Okay, so we are almost out of time for the discussion part, but we're going to have a Before we started though, I'll ask two last questions. One is, I mean, our is going to impact virtually everything, and some of the positive It is going to help cure and diabetes and others. It's going to help mitigate climate change. There's just an enormous number of things, invent new materials. I see over here someone that can help in the energy and pharmaceuticals. And that's a big effort But there's this entire that could not be done So it's basically advancing science in a way that was part of, either fiction or imagination before it. Are you optimistic about that part of it? - I think we're both very I think we both believe it's on almost every field. - So I think for those in this room who are actually studying, it's an incredibly exciting because there's the opportunity to get involved in limiting the negatives, the negative consequences, but also to participate in to solve some of the problems as long as we've been around as a species. So there's, I think, at this really is one of the in human history. I hope that those of you who is actually go out and go after You can also work on like and other things, or making more Netflix But also- - Yes. So would my mom, who I If there's a Turkish or she's seen the very last episode of all. But for those of you who my recommendation is, try and think of the and what you could use this that is incredibly ambitious. And you have both done that, and kind of fought against to achieve that. There's a room full of people and a lot of people online, and others who will see this subsequently, I think, who are at the beginning stages of making those decisions. I think, I'm guessing to do that too, right, and go after the biggest, - Absolutely. I mean, embrace this, but I also would encourage, this is a new chapter of this technology. Even if you see yourself as a technologist and a scientist, don't forget there's because you need both to make this positive change for the world. - Okay, last question and then we'll get into Q Are we at a point where understanding and intelligence? - Wow, that's a last question. How many hours do we have? - Yes. - Okay, I'll come back to the yes. (audience laughing) - No. (audience laughing) (audience applauding) - Okay, we have questions Let's start on the far side. Do you want to stand up and - Hi, thanks, my name's Ellie. This was awesome and thank you so much, Geoff your work really to study cognitive science, and it's just amazing to I have a question, you mentioned the and for enabling universities to empower students to use And you also mentioned Fei-Fei to become a dignity economy and empower people to just and passion, and their expertise. I'm wondering if either of you have a perspective on the challenge that could emerge with overuse especially for kids and students as they're on their education career, and they need to be building skills, and using their brain, and exercising the meat Our our brains don't just continue to work and not accrue cobwebs And yeah, I wonder your and over-reliance, and just what happens around de-skilling and the ability to learn to paint when you can use stable diffusion, or learn to write like Shakespeare when you can have ChatGPT do it for you, and then as those systems progress and can accrue greater insights and more complex problem solving, how that impacts our - So I have one very which is when pocket people said, &quot;Kids will And that didn't turn out I think kids probably did but they got pocket calculators. But it's maybe not a very good analogy because pocket calculators Kids could forget doing arithmetic and go off and do real math. But with this stuff, I don't know. For myself, I found it's actually made me much more curious about the world. 'Cause I couldn't better go to a library and spend half an hour and look something up, and now I can just ask ChatGPT anything and it'll tell me the answer, and I'll believe it, which maybe isn't the right thing to do. But it's actually made me 'cause I can get the answers more quickly. - [Ellie] But you've had - Well, you have to- but normally I ask questions about plumbing and things like that. So, well the (indistinct). - So I'll answer this I don't know about you guys, ever since I've become Stanford professor, I'm always so curious, there's a mysterious which is the office of college admission. To me, they're the most mysterious people and I never know where where they sit till I got a And of course they wanted and college admission. And of course the question is related to, do we allow this in the And now that there is So I went home and I was I said, well I got this phone call and there's this college what do we do with ChatGPT and students? What if a students wrote using ChatGPT and blah blah blah? And then I said, what would you do? I asked my 11-year-old and he said, &quot;Let me think about it.&quot; He actually went back and slept on this, or I don't know what happened. And the next day, the next day in the morning, I said, what's your answer? He said, &quot;I think Stanford should admit the top 2000 students who knows how to use ChatGPT the most.&quot; It was actually, at the beginning I thought Like, it's actually a is kids already are seeing this as a tool and they're seeing their as a enabling empowering tool. Clearly my 11-year-old had what that means and blah blah blah. But I think that's how we And we should update our education. We cannot shut the tool like what Geoff said, and educate humans so that they know how to use - I've incidentally I've met He might be the president of (audience laughing) - If Stanford still exist. - Maybe let's go to this side of the room in the far corner. - Yeah. I want to ask about like, so we have really good but in many of the applications we need kind of a real time So like how do you see this area of research going in the future of using the abilities of to train fast, smaller models? That's the question. answer this question. - I'll leave it to you. - Well you're talking We need to start thinking the inference, and also depending on which, well, I mean, without getting all these research as well as, like even outside of you want to talk about? Okay, you don't want to It's happening but I But yeah- - We talk about things, he invests. - That's true. - I can't talk about it until the company says that - Okay, let's go back in the middle. Just right here. - Thank you. Yeah, Hi, my name is Ariel, I'm a third year Engineering Science student, majored in machine and then that conversation and then thank you Prof. I just have a question that maybe a lot of are interested in this where in this room? So just like in your 20s, like what drove you to and what drove you into Because I'm kind of like should I continue with like industry or a direct entry PhD, or like take a master and And I have like one more question that usually what do you look for? Like if I apply for a direct is that like GPA, or publication, Could you just like Thank you. 300 people in the room, and about 6,000 online who want to ask that question to you Fei-Fei. - You want to start? Your 20s. - Oh, I got interested in how the brain works 'cause I had a very smart friend at school who came into school one day and how maybe memories in the And I basically said, what's a hologram? And ever since then I've been interested in how the brain works. So that was just luckily having a very smart friend at school. - I'm going to be very shamelessly, if you read my book that's actually what the (audience laughing) - It's a very good book. - Yeah, thank you. No, seriously. I actually, I told Jordan and Geoff, there's so many AI books about technology and when I started writing I want to write a journey, especially to the young Not just a certain look. And that book talks about and in different settings realizing or coming to and realizing her dream. And it's not very different it starts with a passion. It really did start with a passion. A passion against all other voices. The passion might come from a friend, it might come from a movie you see, it might come from a book you read, or it might come from the that you felt most fun, whatever it is. And in the students I hire, I look for that passion. I look for ambition, a healthy ambition of not wanting to get a degree per se. And of course technically speaking, I look for good technical background, not just test scores. But honestly, I would have So the standard today is so high. So by the time you apply for a PhD, or a graduate school program, you probably have some track record, some, it doesn't have to necessarily, of course if it's Geoff's student, I'll take them without But even if you, and I'm saying this not to every student online, you can have a very different background. You can come from an What I look for is not where you are, but the journey you take, that track record shows shows your passion and conviction. - Having read the book, I will say that it is a I think to most people, who will read it. And just a plug, if you're in you can go to indigo.ca and But I think that people will be surprised, and really enjoy reading and understanding that experience, and you'll get a very answering that question. - Thank you. - Okay, there's about 50 hands up. All right, let's go over - Hey, thank you for the great talk. My name's Chelav, I'm at So I think benchmarks are very important. Benchmarks are like questions. ImageNet was basically a question and then people are trying And so right now LLMs and generalist agents that it's so hard to start thinking So my question's about, my It's about these benchmarks. So two things. One, if you sat down and you had five minutes to play with it, what questions would you this is the next And the second is more of what is the more comprehensive that we need in order to evaluate LLMs, or generalist agents? You can choose which one you want to, I guess think about or answer. Thank you. - Thank you for your question. It's a very good question. I will answer a different question that's just vaguely related. So this issue arose with GPT-4. How do you tell whether it's smart, and in particular, I was talking to someone called Hector Levesque who used to be a faculty and has beliefs that are almost the diametric opposite of mine but is extremely intellectually honest. And so he was kind of and he wanted to know how And so we spent time talking about that. And then I got him to give and he gave me a series so we could decide whether it understood. So the question was does what it's saying, or is it just using some fancy statistics to predict the next word? One comment about that is, the only way you can predict is to predict what the person is to understand what the person said. So you have to understand but you can predict quite So does GPT-4 really understand? So a question Hector came up with was &quot;The rooms in my house are painted white, or yellow, or blue. I want all the rooms to be And I knew it would be able to do that. So I made the question more difficult. So I said the rooms in my or yellow, or blue, yellow paint fades to white within a year, in two years time I'd like What should I do? And ChatGPT- Oh, and I said, and why? If you say and why, it'll ChatGPT just salted it said, you should paint the blue rooms white. It said you don't need to 'cause they'll fade to white. It turns out it's very if you don't use fade, but you use change, I got a complaint from somebody who said, I tried it and it didn't work. And they use change instead of fade. And the point is, if we understand fade to mean change color and stay changed. But if you say change, it will change color but So it doesn't give the same answer if you change rather than fade. It's very sensitive to the wording. But that convinced me it And there's other things it's done. So there's a nice question that that many chat bots don't get right and some people don't get right, but GPT-4 gets right, which is, so you see I'm answering the question, does GPT-4 understand, which is does have some relation - [Chelav] Yeah, yeah, precisely. - So the question goes like this, Sally has three brothers, each of her brothers has two sisters, how many sisters does Sally have? And most chatbots get that wrong. - What about humans? - Well, I just gave a and the interviewer asked that chatbots got it wrong. So I gave him this example and that was kind of embarrassing. - We won't ask his name, I'm just kidding. - No, so people get it wrong. - Yeah. - But I don't see how without being able to do a It's gotta sort of build a model. - Yeah. has these examples where playing Othello, even if you just give it strings as input, it builds a model of the board internally. So I think they really do understand. - And to take that a step further is that understanding cross - Oh no. - Yeah, I mean I accept the People only started when we passed it. - So that's the moving goal Okay, do you want to answer- - I want to quickly answer, first of all also applaud you for asking such a good question. I'm going to answer in addition to Geoff's 'cause I think what Geoff how do we assess the of these big models. But there are a couple One is, again, Stanford of foundation model is creating these evaluation metrics. You are probably reading the papers by Percy Helm and all that. I think also this technology that some of the benchmark is more messier than what you think for example, in collaboration for example, NIST, the US the National what's the T? - And the technology, We need to start benchmarking against societally relevant issues, not just core fundamental capability. One more thing, I want to open is that beyond the LLMs there are so many technology that we actually haven't built I mean, again, my lab is doing some of the robotic learning one, Google just released the paper yesterday on robotic learning. So there is a lot more research - [Chelav] Thank you. - Okay, I know we have a I'm going to maybe take and then maybe someone from Radical could read out a question Okay in the room, let's go for one that's not too far away from the last one here. Just right here. Okay. (indistinct chattering) Here's the mic coming. - Hello, I'm Vishaam, and I'm a graduate student and I'm doing my thesis So building upon something you mentioned that universities don't to train kind of foundation models. So same question, I want to work in AI and agriculture. I'm passionate about it, but I don't have enough I might think of a very good architecture, but I can't train it. So maybe I can go to industry then pitch them the idea, then I don't have the I don't know how they're going to apply it. So do you have some advice on how to handle the situation? - Do a start up. - Do a startup, that's Oh, sorry, I'll let you answer. - If you can get your hands on an open source foundation model, you can fine tune one of those models with much less resources than So universities can still do - That's a very pragmatic answer for now. But this is where we to the higher education leaders as well as policy makers We've gotta have national research cloud, I don't know if Canada has but we're pushing the US, we need to bring in the to be able to access the But you do have an advantage is that you have more opportunity to get your hands on unique data sets, data sets, especially for public good and play up that card. You could work with government agencies, work communities and whatever because public sector still has the trust and take advantage of that. But for now, yes, fine - [Vishaam] Thank you. Thank you so much. - Okay, we're going to We have thousands of watch parties at Stanford and elsewhere, so let's see if we can get a question from some people online. Leah's going to ask this question on behalf of someone online. By the way she's done an to make this happen so thank you both. - Thank you Jordan. (audience applauding) All right, thank you. So we do have hundreds and they're folks who are And so the first most upvoted question was from Ben Saunders or Saunders. He's currently CEO of an AI startup. And his colleague was actually student of Geoffrey Hinton's in 2008. And he has asked about and a lot of these building responsibly, and they're thinking about what measures can help them as teams be proper stewards for good versus bad, and what it actually - Great question. So responsible AI framework, there's a lot of framework, and I think somebody has estimated, a few years ago there from state nation, state I think it's really to build a responsible framework. There is a lot you can borrow, even Radical is is making one, and create the value and recognize that AI product is a system. So from the upstream, data integrity, how you build models, the deployment, and create a multi-stakeholder ecosystem or multi-stakeholder, whatever team to help you to build this responsible framework and also create partnerships. Partnerships with public partnership with the civil society that worries about different dimensions from privacy to bias to this. So really try to take, both have a point of view as a company, but also be part of the ecosystem and partners with people So that's my current suggestion. - I'll add to- Do you want to? - No, that was a much better - I'll just add a little bit. I think to Fei-Fei's point, by working with people who I think there are people who are thinking and leading on this, in our case Radical, we've written into every single term sheet an obligation for the company Initially when we did that, some of the lawyers who what is this? And tried to cross it out, But we're also, we've been working on a responsible AI investing framework that we are going to And we've done this in partnership with a number of different We've met with 7,000 AI and I think we've invested in about 40. So we've seen a lot and tried to build a framework that others can use going forward. And we'll open source it so we can develop it and make it better. But I think there's a lot that by just reaching out to others who are thinking in a like-minded way. Do you want to ask another question? - Yeah, great, there's so many questions, so we'll only get to a But playing off of that, a lot of these questions have to do with the relationship with industry, considering how big of a role industry, and the private sector's now And some folks are even asking, should researchers and also be taking management courses today? - Sure. - I have to tell you a story I managed a small group and we got reports every six months from the people who worked for us. And one of the reports I got was, &quot;Geoff is very nice to work for, but he might benefit from but then he wouldn't be Geoff.&quot; (audience laughing) That's how I feel about (audience laughing) (audience applauding) - I don't have a better story than that. (audience laughing) - We have about a minute and a half left, so maybe let's do one more Let's see. Do you want take? Yeah, no, beside you. Sorry. All right, hopefully ask quickly and then we'll get a quick answer. - Thank you. And it's Good to see you Fei-Fei. My name's Elizabeth I work at Cohere. So my question is, from a private sector perspective, we work with everybody to to the broader society, on the specific public sectors and research institutions, universities who has a lot What is the best way to find the mutual kind of beneficial relationship that we can contribute Thank you. - Give them some money. (audience laughing) - Thank you. (audience applauding) - Or H100s, we'll take H100. But look, it's very important. I advocate for public sector investment, but I also actually probably more so advocate for partnership. We need government, private sector, and public sector to work together. So the past four years at Stanford HAI, this is one of the main is create an industry ecosystem. And there's a lot of but if I'm talking to university leaders or higher education, is that I think we need to embrace that. We need to embrace that responsibly. Some people will have but I think this Both sides are important. Create that partnership, be the responsible partner for each other. And resource is a big thing. We would appreciate that. - [Elizabeth] Thank you. - Okay, with that we're I want to thank you both. I feel very privileged always to be able to call you both friends, and Fei-Fei you're a partner, and Geoff, you're an investor, and have these conversations So it's great to get you both together and let other people hear So thank you both so much for doing this. Hopefully it was as informative (audience applauding) And we'll turn it over to Melanie Woodin, Dean of Arts and Science at U of T. - Thank you so much Jordan. So Geoff and Fei-Fei and Jordan on behalf of everyone in the and the thousands joining us online, we are deeply grateful for such a profound I can say, and I think many of us know that being part of a university community offers a never ending set of opportunities for engaging conversations and lectures. And as Dean of a Faculty I have the pleasure of But I can say without reservation that tonight's conversation And of course this conversation Geoff, when you shared your concerns with the world about the we all listened and we to try and understand this complex issue. Whether it's reading opinion pieces, watching your video, or reading long for journalism, we really tried to understand So to hear directly from who spent so many years now leading the way in human-centered AI is really, truly powerful. So with that, thank you both and thank you everyone here and big thanks to Radical Ventures and the other partners And so with that, the talk has concluded and we invite those of you to join us out in the foyer Thanks for joining us. (audience applauding) (audience indistinctly chattering)