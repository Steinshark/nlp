- Hi, I'm Tim Berglund with Confluent. I'd like to tell you what Apache Kafka is, but first, I wanna start For a long time now, we that store information in databases. Now, what databases encourage us to do is to think of the world in terms of things, things like, I don't know, That's a thermometer, Maybe a physical thing, like a train, let's see, here's a train. Things, there are things in the world. Database encourages us and those things have some state. We take that state, we This has worked well for decades, but now some people are finding that it's better, rather than to think of events first. Now events have some state too, right? An event has a description but the primary idea is that the event is an indication in time Now it's a little bit cumbersome to store events in databases. Instead, we use a structure called a log and a log is just an ordered An event happens and A little bit of state, a little bit of description of what happens, and that says, hey, that As you can see, logs are They're also easy to build at scale, which historically has not which have been a little cumbersome in one way or another to build at scale. Now Apache Kafka is a system using a fairly standard, historical term. It calls them topics. This is a topic. A topic is just an ordered that are stored in a durable way, durable meaning that and they're replicated. So they're stored on more than one disk, on more than one server, somewhere, wherever that infrastructure runs, so that there's no one hardware failure that can make that data go away. Topics can store data for like a few hours or days or years or hundreds of years or indefinitely. Topics can also be relatively small or they can be enormous. There's nothing about that says that topics have to be large in order for it to make sense, and there's nothing about that says that they have to say small. So they can be small, they can be big. They can remember data forever. They can remember data but they're a persistent record of events. Each one of those events happening in the business. Like, remember our user, her shipping address or or a thermostat reports has gone from comfy to, Each one o' those things can be an event stored in a topic, and to think of events, Now, back when databases ruled the world, it was kind of the trend We'll just build this that uses one big database all by itself, and it was customary, for a But, these things grew to a point where they were difficult to change and also difficult to think about. They got too big for any one developer to fit that whole program at the same time. And, if you've lived like this, you know that that's true. Now the trend is to write lots and lots of small programs, each one to fit in your head and think about and version and change And these things can talk to each other through Kafka topics. So each one of these services can consume a message from a Kafka topic, do whatever its computation and then produce that message that lives over here. So that output is now durably recorded for other in the system to process. So with all this data real time streams, and but imagine there are dozens or hundreds more in a large system. Now it's possible to build new services that perform real-time So I can stand up some that does some kind of gauge, some sort of real-time analytics dashboard and that is just consuming messages from this topic here. That's in contrast to where you ran a batch process overnight. Now it's possible that yesterday is a long time ago for You might want that insight to be instant or as close to instant And, with data in these topics as events, that get processed as soon as they happen, it's now fairly straightforward that can do that analysis in real time. So you've got events, you've got topics, you've got all these little services talking to each other through topics. You got real-time analytics. I think if you have those you've got a decent idea of kind of the minimum viable understanding, not only of what Kafka is, which is this distributive log thing, but also of the kinds of that Kafka tends to give rise to. When people start building systems on it, this is what happens. Once a company starts using Kafka, it tends to have this viral effect. Right, we've got these that are records of the We've got things talking through them, but there are other systems. I mean, what's this, There's probably gonna be, you know, another database out there that was built before Kafka came along and you wanna integrate these systems. There could be other systems entirely. Maybe there's a search cluster. Maybe you used some SAS product to help your sales people organize their efforts, all these systems in the business, and their data isn't in Kafka. Well, Kafka Connect is a tool that helps get that data in and back out. When there's all these you wanna collect data, so and you wanna collect that data and get it written into a topic like that. And now, I can stand up some new service that consumes that data and does whatever computation is on it now that it's in a Kafka topic. That's the whole point. Connect gets that data in. Then, that service produces some result which goes to a new topic over here and Connect is the piece that moves It to whatever that external So, Kafka Connect is this process that does this inputting and it's also an ecosystem of connectors. There are dozens, hundreds of connectors out there in the world. Some of them are open source. Some of them are commercial. Some of them are in between, but there are these that you can deploy to in a declarative way. You deploy them, you configure them. You don't write code to do this reading from the database, this writing to whatever that external system is. Those modules already exist. The code's already written. You just deploy them and Connect does that integration to And let's think about the work that these things do. These services, these they have some life of their own. They're programs, right, but they're gonna process messages from topics, and they're gonna have some computation that they wanna do over those messages. And it's amazing, there's really just a few things that people end up doing, like, say you have messages, you wanna group all those Like, come up with the total that passed a certain point or something, but only a certain kind of car, only the green kinds of cars. And you've got these other, say you've got these orange ones here. So, right away, we see go through those messages. We're gonna have to group by some key and then we'll take the group and run some aggregation over it or maybe count them or Maybe you want to filter, and, let's see, make some room for some other topic over here that's got some other kinda data, and I wanna take all the messages here with messages in this topic, and enrich, when I see I wanna go enrich it with the data that's in this other topic. These are common things. If it's the first time that might seem unusual, but those things, grouping, aggregating, Enrichment, by the way, in database-land, that's a join, right? These are the things that They're simple in principle to think about and to sketch, but to to make all that happen takes some work, and that's not work you wanna do. So, Kafka again, in the box, just like it has Connect it has an API called Kafka Streams. That's a Java API that handles all of the framework and infrastructure and kinda undifferentiated stuff you'd have to build to get that work done. So you can use that as a and get all that done in a scalable and fault-tolerant way just like we expect for modern And that's not framework You just get to use it Now if I wanted to do on the data in this topic and I didn't wanna put it in the service. I didn't want to stand up a Confluent has a language called KSQL that I can now write some Select from this topic, I won't write the whole query out, but it's a SQL-like to be able to do real-time Where do those results Well, I think you'll that the output of this query just goes into another topic which I can then do further analysis on, stand up other services to process, use Kafka Connect to It all kinda fits into the platform. And when I say platform, is a distribution of Apache Kafka that you can use in a number of ways. Number one, there are open components of Confluent There's a lot of these connectors. There's KSQL, components like that. You can just download and use for free. There are other components that come with an Enterprise subscription, things like multi-data center support, Enterprise-grade subscription Even those, of course, if you just want to go download it and use it are So nothing is stopping even with those subscription features, and, if the idea of and running on your own infrastructure seems old-fashioned to you, you can also use Confluent Cloud. Confluent Cloud is a fully-managed, serverless, Kafka in the cloud. It lets you get all of without thinking about (upbeat music) Now, if you're a developer you know the thing to do Got a resource for you. It's called Kafka tutorials. That's kafka-tutorials.confluent.io. There's a bunch of executable examples with narrative explaining They'll help you learn and producing and and KSQL, all this kinda stuff. And there are tested running examples ready there for you, with explanation of how to do it all. If you wanna learn more in general, confluent.io Check those things out. Let us know if you have any questions. And I hope we hear from you soon. (upbeat music)