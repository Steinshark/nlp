Welcome back, aspiring professional Let's learn how to set up logging in That means we're going to learn to stop As always with so-called &quot;best that work for most use cases. However, you know what's best for so if you have a good reason, Don't blindly follow this advice With that said, let's get going At mCoding, we do code reviews, Do you have a problem with your code? Worried about your architecture? Or do you just need some extra dev hours? Why not make me part of your team? Anyway let's get back to logging. The built-in logging package is very old It doesn't follow PEP8, the docs are a mess, and many tutorials are outdated or quite frankly But for all its quirks, the the de-facto standard for logging in Python. It doesn't matter if you're using a cloud the standard is the built-in logging package. But do you really even need logging at all? Hey man, you came to me. If your app doesn't need logging, that's up to All right, let's see how to get started. You might think you just import logging, and then get to logging with your messages. When you run the code, based off the log level And I wouldn't blame you if In the most basic cases this is totally fine, Why? Well, if you care to do logging to at least two different places, Or you want to log higher priority things maybe you want to send an email if You can manually make handlers and but, trust me, just don't do it that way. Instead, use dictConfig. For some reason dictConfig is hidden and not so much as mentioned As the name suggests, this lets you that explicitly lists all of the necessary namely the filters, formatters, The basic config hides these objects which makes for a really slick but for more useful logging setups I find It can get really confusing if you don't have a good mental model for what So here's the one picture to keep in Loggers are the things that They have a &quot;.info&quot; and you can logger.debug to log a debug message, logger.exception to log the That creates a log record, which is an object that contains all Things like the message and the current thread or async task, the Every logger can set a level to drop and optionally some filters to drop So you could do something like drop all Or you could do something more sophisticated like sensor private user data that The logger then passes these log records Handlers tell you how and where to a file. over email. or Each handler receives the log record and, and some filters that allow it to drop if a record is dropped by a handler, it But if it was dropped by the logger Assuming the message passes when it comes time for the handler to actually But currently this is a Python object. that it uses to convert the log record The formatter is what lets you customize Like is it the log level and then the message? Or maybe you write JSON, or maybe Formatters are typically where because it's the formatter the log record to actually include in the message and that depends a lot on your specific use And this is almost the complete picture. Except this is the picture for the root logger, Loggers are accessed and created by name, and if you split the name by dots then So the A.X logger is a child of the A By default, once a child's done handling a log So if this log record was generated all of A.X's handlers would run, and all of A's handlers would run, then it would propagate up to the root This is done to make it easier for users just by disabling certain loggers. Once again, if a record is dropped by to include propagating up to the parent. But if it's dropped by a logger, But slow down there, this is way more Having all these handlers and filters is unnecessarily complex for most use cases. And it often leads to subtly broken configs. So here's what I recommend. See all these non-root handlers? Delete them. Unless you've got a good reason, This is simpler, but also having all that any messages generated by third-party the same way as messages Filters? Same deal. There's a decent chance you but if you do put them all on the root logger or their handlers. Leave propagation turned on, which is the default, so that all messages propagate However, don't use the root logger in your code. If you use any of the top-level logging functions So don't use any of those functions. Make sure to use your own logger, which you get by using logging.getLogger and passing in This will create the logger first then you can use your logger.info And remember, your logger We're depending on propagation to and have the root logger If you have a small- to medium-sized application, If you have a very large application, then you should make one non-root logger for You definitely don't need a logger for every file. That'd be a waste because these are globals With that all in mind, let's get back to configuring logging for a few As a baseline let's just have a simple If you're ever confused about the config, draw it out like this and then use This &quot;version&quot; is required This is so that they can change everything &quot;disable_existing_loggers&quot; does what it says, it disables anything that's not I'm going to go ahead and set this to false so No filters in this configuration, Next define a formatter named &quot;simple&quot; We didn't specify what class this formatter is, so by default it just uses the It accepts the format string like this, using Yes it's kind of weird but just deal with it or, foreshadowing, wait a minute If you want to customize your own the available variables in Next we need to define the single stdout handler, and set our &quot;simple&quot; formatter as In order to get it to actually the built-in logging stream handler The &quot;ext://&quot; slash here means &quot;external&quot;, as in this is a variable that's And voila! In just 16 lines we've configured I know, I know, but keep in mind this more of verbose style is going to be a lot So stick with me. Despite the fact that we're using dictConfig, that doesn't mean that we need to a literal dictionary in our Python source. Nothing wrong with that, to keep the logging config in a Personally I prefer to keep my config in JSON, so then load that JSON when If you wanted to use YAML instead, it would look basically the same except and you would &quot;import yaml&quot; and do Let's bring those side by side just Obviously YAML is a lot more condensed, but I And also there's no YAML parser built into Python, whereas there is a built-in JSON parser. So if you wanted to, you would have &quot;pyyaml&quot; is a popular choice. Keeping the log config in a separate adjust the logging config to their preference. You know, if you trust your Second setup. Let's modify the and then all logs go to a file. Change the &quot;stdout&quot; handler to &quot;stderr&quot; Then, create a new handler and set A rotating file handler keeps appending logs in this case 10 kilobytes. After it reaches 10 kilobytes, it After three backups it starts 10 kilobytes is a pretty small limit, this is You probably want to pick a few megabytes. After running the script a bunch of this &quot;my_app.log.1&quot; and then We're still using the &quot;simple&quot; formatter here. But since we're saving to a log file, We accomplish that by adding this new &quot;detailed&quot; formatter and setting it as the We include much more information in the format string, and we're also showing which allows us to customize Pro tip: use an ISO-8601-compliant format This way our log contains a lot For a lot of applications, But, if you really care about then I really suggest making one crucial change. Take a look at this log file. Glancing over it I can visually distinguish but notice that we have tracebacks in here. And what if log messages had newlines in them? If I wanted to parse this programmatically all of the data that I put into it. But it's kind of just in free-form text with That's kind of intractable. The solution? Store persistent so that they can be parsed easily later on. This is a change in how to convert so that's the job of the formatter, But oh wait, there's no There are a few you can pip install, Supposing we did, you'd think you'd here and then pass in whatever arguments here, and those will be keyword That's what's happening here Uhh, nope. You can use your own class but if you do then all of the keys are So I could use &quot;format&quot; and &quot;datefmt&quot;, Why is it like this way? Change &quot;class&quot; to &quot;()&quot; and then call this and pass this as a keyword argument. You'd have to do the same thing like if I made my own custom handler that didn't Okay well with that weird road bump So we're going to pass in these format keys, which is going to be a dictionary where the key is and the value here, like &quot;levelname&quot;, is the variable that we're going Okay so let's go ahead and write this class. We're in a new file here and we just Nothing special in the init, we just store Then we need to define this &quot;format&quot; function. This is a thing that takes the I'm using &quot;@override&quot; here to indicate that It's not strictly necessary, but it's a All we do is extract out the record data into a dictionary and then use the &quot;json&quot; As far as actually extracting those Regardless of the config, I chose to include the message and a timestamp in We pull in any exception data if methods in order to extract things out nicely. And for the rest of the keys we just grab It's pretty straightforward and you And donzo! Update the config to use the Check our log file and we A slight warning though, Each line is valid JSON. This format is called JSON Lines and So to parse it you just read the file And double pro-tip: now it's actually really easy to add To do this we can just use the &quot;extra&quot; Give it a dictionary of extra information and Then just update your formatter to pull in those extra attributes and now any Here's the {&quot;x&quot;: &quot;hello&quot;}. If you're getting too many logs and you'd then you might need a filter. The process of creating a custom filter is Inherit from the built-in Filter, then define Given a record, you return a bool to indicate So this non-error filter does kind of the Setting the level to &quot;INFO&quot; would mean were &quot;INFO&quot;, &quot;WARNING&quot;, &quot;ERROR&quot;, &quot;CRITICAL&quot;, but setting this non-error filter would You can also alter the record here, like if you wanted to censor private I'm not going to deal with filters for the rest Using this non-error filter, create a logging but error messages to stderr. You're going to need the Okay okay, surely there are no more glaring At the risk of using a forbidden word By its very nature, calling a If a user makes a request to my web app I don't want to add 10 round-trips worth of time But currently that's what will happen because The solution? Use a QueueHandler Collecting log data isn't the slow part. The slow part is sending A queue handler stores your log while an associated queue and passes them off to other In order to configure this, create The class is &quot;logging.handlers.QueueHandler&quot; These are the handlers that it dispatches to, so basically take the handlers that put them here and then change the queue This &quot;respect_handler_level&quot; for which results in the behavior of sending every so yeah, that's probably not what we want. I'm going to set this to true There's one more thing we need to which is that because the queue that's not something that's When we set up our logging we need We accomplish this by getting the if it exists we start its listener's thread. We also register an atexit callback in and shut it down gracefully when the program ends. Alternatively, if you want to keep you could also subclass the queue handler And success! We finally have a high quality, non-blocking logging setup Feels good, doesn't it? But notice I said logging for your Application authors know who their users are and Whereas if you're writing library code, you don't know who your end user is and Conclusion: for library code, You can still use logging, create loggers, Just don't configure it with Let applications do the configuring. If a user doesn't configure logging, that warnings and above will be printed to stderr. If a user of your library does configure logging, then don't interfere with what formatters or other things Finally, do you remember log4j? It's an extremely popular logging library for and cause absolute pandemonium in the business with millions or billions of users remote arbitrary code execution vulnerability. At the heart of the vulnerability was combined with a plugin that allowed Anyway here's Python's &quot;makeLogRecord&quot; function For example &quot;from a pickled I'm not saying this is actively vulnerable. but in-case &quot;logging4p&quot; Thanks for watching, and So if you're still not satisfied with your Don't be afraid to reach out. Did you know that this entire channel So huge thanks to everyone on patreon and If you'd like to support the channel Don't forget to subscribe and slap that See you in the next one.