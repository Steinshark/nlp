Michael Krigsman: Welcome to CXOTalk Episode a peek inside Cognizant's Advanced AI lab Babak Hodjat: I am the CTO AI for Cognizant. I where I am currently. This is where our flagship Neuro AI platform, which helps Michael Krigsman: You were one of the NLP processing techniques used and is there a link between that Babak Hodjat: I was working on technology called multi-agent-based these systems can be. While AI was still in needed to scale. When you put multiple AIs A friend of mine, through challenged me to make use of that same and controlling things like the TV set At first, I thought that was, you know, Natural language was the first non-numerical quite solved. It's very, very difficult due to But then he challenged me, and I worked on command and control, using a multi-agent based a big departure from the traditional way of doing semantics, and context, all the while being then moving to Japanese would be This opened up the door to many possibilities ultimately, led to being able interaction core that ended up being Siri. The relationship to today, in some ways, is where we see how scaling AI and moving it into in a multi-agent manner is preferred over a agenthood and multi-agent systems are The motivation is different. Back then, you reduced the domain of and gave it specific tasks in conjunction they would interact and solve a Today, a large language model, which is the very powerful, and it can be many different them what to be. It's kind of the inverse: they to reduce that domain to tell them what their set what we want them to do in a particular context. very different angle but ending up more or less in Michael Krigsman: When we talk about agents, or the term agentic AI is now becoming more you use the term multi-agent systems. Babak Hodjat: We all are familiar with large These models take input and generate output. images, video, or all of the above. The An agent, however, is distinct from a model and it can affect its environment and observe Let me give you an example. If you go to some calls to the Amazon API, it will It's so good that the code might You might be able to rely on and trust that code. The distinction, though, is that an maybe in a container, make the calls to Amazon, and then modify the code if it was broken &quot;Here's the code.&quot; So that's one agent distinction Now, regarding multi-agent systems, this means we have different functions in In coding, we might have a project manager, a backend coder versus a frontend versus a UI designer. And we board where we're posting tickets So, right there, I listed a number of different that's how, as human coders, we have a choice. We could either rely agent and ask it to do all of those. Currently, we have limitations on we're expecting the system to do is very high, and observing how various elements of For us to set up a system like that, we way anyway. So mapping that modular to the way we set up a team larger software package that we want the team is basically by creating multiple agents, each For example, the product manager, project their own agent. In the context of the what it needs to do, what to expect to get Then we set it off to operate. There are several can think of ourselves as agents in this structure structure. This is unlike, for example, treating we ask to do something, and then we expect it to So that is one of the important reasons and even organizations, as multi-agent Michael Krigsman: So, are you attempting to then model the construction of an organization each of which is designated to accomplish a Babak Hodjat: That's great. You've It goes beyond software. For example, from is already inherently modular. We've that's been the underpinning of a lot of and objects are just a tiny step away from as being this modular system that and it has some very interesting properties. We But this goes beyond software. We can look at in these nodes. They could be human, software, As long as we can actually list those including what to expect coming in, what to expect to leave, and what to task the agent to if we can actually define these relationships, organization that's not necessarily a piece So, yeah, that's an area of interest to me. What human-centric or human-augmented way? How do you What are the properties you gain? Because running costs, too, right? You're running large language you are actually tasking; you're still step of this organization. Depending on to operate this thing. So, on the other hand, There are a lot of very interesting Michael Krigsman: It sounds like that encapsulates large language models to nodding your head. Okay, so then we know How do you prevent your army, or Babak Hodjat: Large language models can hallucinate. They make stuff up because be truthful. They're trained to pass muster and it's another reason for us to &quot;agentyfy&quot; and make it very clear what you expect, you The other aspect is that we need to make the agent that tells us when we can There is some very interesting recent research, that measures uncertainty on large language that context is important--this is something not in a general scope. Given a an output that we get from the agent, If we now have a measure of that, and we can say, &quot;Hey, right here, what this so I need a human to verify it.&quot; This systems from an agentic perspective versus a Michael Krigsman: Subscribe to our newsletter, CXOTalk.com. We have phenomenal shows coming end of the year. So check it out! Join us. Greg &quot;Won't an army of agents cut hallucinations because of self-checking Babak Hodjat: Absolutely. The fact is, you responsibility to check other agents for things of agents working together, and the response I what I was expecting, I can also go back to it and to that agent. So, even automatically, between the Now, having said this, we are faced with being the basis for a lot of what we do systems would never hallucinate. for marketing reasons or whatever, tells you take it with a grain of salt. That that's not possible, but we can gauge other thing we need to remember is that we're agents. So while we do have tools to try to at their core, these systems are deep-learning are black boxes. It's very difficult for Now, the good news is, we've of systems since industrialization. It's just that and we really can't read another person's mind. larger organization, and we know how to do that. this unknown new era of multi-agenthood. through industrialization and setting up these to make sure that agentyfication operates There's one other thing I wanted to mention amazing in this new era of multi-agency. we had to define the language between agents. these agents needed to issue to each other in now. In fact, the native language of a large What does that give us? There's a reason it did. It's very expressive and now you have an organization where the say if we had software--is expressing This makes it robust and future-proof. You in your software. One of the examples I use is and we had databases. They were not lost the database wars back then. But these for 15-20 years. They were legacy. The reason difficult to yank them out and upgrade them or the software. Probably, the people That is a thing of the past now. That robustness, now agent nodes, gives us an intent-based and to replace and upgrade without caring about between the intent and the call into the specific So that gives us a lot of flexibility just software engineering background, I think that's Michael Krigsman: You said that we have been through organizations from the beginning from an ethical perspective, one fundamental of everything that we know, and we could call when it comes to data-driven decision-making, about potential biases that live in the Babak Hodjat: There may be, and certainly large language models. We need to control risk. There's also bias inherent in the data Before I address the question directly, I want that's only large language models operating based we've done a disservice. That's not where we want they've collected, historical data around the and so forth, that data is invaluable. We have to even use what is now called &quot;traditional&quot; (as of So, we have the agent, which is a large a machine learning-based or analytics-based, making its decisions. That is much more reliable doing guesswork based on its reasoning. It opens the data in the world that is ingested to It still doesn't take away data itself that we've collected, So the principles of responsible AI, which we had still carry forward and are even build them into the framework we use To be realistic, in the past couple of it's scary because we've been distracted by the and we're like, &quot;Wow, this thing is so useful. the responsible AI part of it later. It's become one of the things that we are really emphasizing agentyfy. Built into it is a framework that as well as responsible AI, ethics, and It's important, and there's no simple, general and then you're responsible.&quot; Michael Krigsman: We have a very interesting Malhotra. He says, &quot;How do you envision the workers evolving over the next decade? And what capitalize on this workforce transformation Babak Hodjat: We did research along with Oxford The methodology was really interesting. We took job into its constituent tasks. Then, we said, and here's where we think it's going to be Which one of these tasks is it going to on the job. Amazingly enough, it This is the reality. The way to look at it is so that the focus is on the part of that set of be the exclusive domain of humans. And yes, we agentic AI to cover the rest and to help those would have a harder time keeping up, to help There are cultural reasons why humans, will have an important, central role There are cultural reasons, for sure. As there are going to be preferences built in. For &quot;Arts now, you can produce many pieces of art generated by machines. What is the future of art?&quot; photography. People thought that painting would you get a photo, and there's so much of it There is a little bit of that. There's also value Like, if this is created by a human versus this human society is going to be different. And that There is a lot to unpack here, and so it's a little bit outside my comfort zone many reasons why, at least in the foreseeable Going back to the Oxford study that we need to do within an organization is list to be disrupted. There's going to be time. but we will have the time to upskill, reskill, we're going to be much busier operating Michael Krigsman: Over time, social expectations the outcomes that technology gives us. What today we accept as a natural course of Babak Hodjat: That's exactly right. There may be would make us very uncomfortable, including Just picturing it! But yes, societies change, But we don't have to worry about that right now. Michael Krigsman: Lisbeth Shaw, on comments regarding GenAI versus agentic Babak Hodjat: A generative model generates and it generates stuff. An agent has but then to actuate. So that actuation, that is the distinction between an It's as if you have a little sandbox &quot;Hey, if you're writing code, run the code, if it's broken before you respond to me.&quot; So But it doesn't have to be a sandbox. It might this call.&quot; &quot;Somebody just submitted a request get all the information and verify that they're and here's the API for, I don't know, opening Do it.&quot; That's what the agent is going to do. A unless you give it the facilities to operate, call Michael Krigsman: We have another question couple of years ago, he wrote about AI which on the surface seems like a silly jobs from senior business leaders? After all, Babak Hodjat: When we look at an organization, as and more consequential and less data-driven. improve, and optimize decision-making at of money to the top nodes. I'm saying that so I guess I'm speaking against now we have the capacity to help with Now, when I talk about AI decision-making, we're always doing that. Like, AI and then we use the insights to make given that humans have this exclusive domain of We're not very good at making We are usually emotional, and we're subject to the we get. The recency of something affects how a single outcome or objective at a time, whereas one outcome. And we don't really have the capacity So often, we walk in with a gut sense skewed and biased and often could be We're paid for making decisions, taking the risk. good at making decisions, but the decisions we a lot of risks by taking them. So the value we quality decisions. And I think AI systems can be They can already look at many more factors optimize against more than one outcome &quot;I want to improve revenue while reducing reducing bias.&quot; It's like, right there, mentioned. I have to have all four in mind So I think it's really important to start There's a good methodology for capturing the bringing in the data that is consequential to &quot;In this context, here's what I think happen if you do this. Here's how certain of your action. And here's an explanation Also, if you want to do something else, let me know, and I'll try to predict what the Michael Krigsman: I find myself surprisingly replacing senior execs. Let me tell you why, based study that we call &quot;the wisdom of the crowds.&quot; because LLMs, if they're big enough, have all the doesn't it make sense to call on the LLM to make history, knowledge, actions, and outcomes to guide lead to the best decision. And so, from that Babak Hodjat: No, I disagree with that is fixed in time. It's only trained &quot;GPT&quot; stand for &quot;pre-trained.&quot; These they're trained. So don't rely on The second thing is, yes, it knows a lot there. Maybe you can rely on it for some of it's the wisdom of the crowd. It knows the here and now of you and the decision you need So don't rely on that. You it will give you some good advice. Thirdly, if you do have data, you can rely on from decisions you've made in the past and the that data and specific ML and analytic models a digital twin, or an ML-based digital twin, of against that digital twin and come up with a Let me give you an example. Let's say some adjustments to the refinery process to Would I go and ask an LLM what it'll give me some tips on what to look into, the state I'm in right now, the price of oil I have to give it all that information. Then, it available in this particular refinery, the many combinations of changes I can make that On the flip side, I have a lot of data about the the refinery. Putting an ML model of the refinery would give me a digital twin that I is this: which knobs and levers to pull and turn I would go with that any day over an LLM an LLM might be a good sounding board, but in create these agent-based systems that have these Michael Krigsman: Wilson Suarez has a evolutionary computation, another area Lab. Wilson Suarez's question is this: where humans don't make good decisions, Babak Hodjat: Emotions, I think, are very abstraction of a set of sensations, we have. They're typically not So, making emotions central to our decision-making that affects us, versus a sequence to decision-making. I don't think of source and informing decision-making versus Let's set that aside for a moment. Regarding of sensations may have been evolved. I'm trying here. There is an interesting aspect that And creativity is interesting because the mainly in text--that informs a large not capture very new stuff that we might While a large language model might be able to and are interesting, in an interpolative way, on how evolution adapts to new situations There's a lot of interesting work being done creative solutions for new situations, approaches. What does that mean? It means that the large language model or a deep network--you differently. Many of these are useless; they're them are useful and different enough that you their traits with some of the other models. you end up with new and interesting, And evolutionary computation: up until now, that many of your listeners might be familiar or we have two parent models. Both are kind of some of that, and maybe tweak something a mutation, and we create a new model. Then, we it is more interesting and better than Recently, though, we've observed that you algorithm. It's as if you have a human, with human &quot;Wow, this trait here is interesting, and that reasoning, they are going to use those being very mindful about how you generate dose of randomness and so forth, but it has There is this give and take. Evolutionary into state-of-the-art AI, which is large large language modeling is also bringing Let me give you one very from our lab. We fed an evolutionary-based the papers published at a conference. We took domain. We fed it the history of the papers: We had the system map those papers in terms of map with these papers on it. You will quickly cool idea, and then other people build on and a cluster of papers there. Every once in a that is totally out there. It brings a a cluster starts building around that through One of the interesting things you can do now is at ICML 2025, what are the papers, and clusters are going to shrink? And in what are you going to get very interesting papers? What's even more interesting is that you can titles and abstracts of those net-new papers. That evolutionary techniques, and large language a topic or domain and predict what Michael Krigsman: Why does this approach as conversion rate optimization Babak Hodjat: Conversion rate is very interesting. It's configured in a certain way, and you if people click and buy, or click and spend If you modify that page, you very quickly In other words, it's fitter or less fit. That A/B testing. &quot;Let's divert a percentage designed to see if it does better.&quot; Now, the problem with that is that you your incumbent page and the new page. That doesn't try new improvements, or keep up with and your user base might So, one thing you can do is create variations of population of possible pages--redirect some of your you direct more users to the higher-performing doing better, you can mix. There might be elements and you can mix those. Perhaps the resulting It's almost like running an evolutionary process because they're ultimately the ones who determine very, very well. It improves conversions. The Sentient, had a company that branched out of They were able to show not only that they but also that they can leave this system running certain events happen, and the preferences of almost like the design of the page changes and Michael Krigsman: What does this have to do you have a demo showing the use as you're discussing this, &quot;What are evolutionary algorithms, and what Babak Hodjat: Let's say you and it's encountering unknown terrain all initially, it doesn't know about. So one were talking about--have it interact with try to walk initially, but just try to sense its Then, build a model of that environment. You know, if you fall and break your neck in a the real, physical world, you might be breaking That's what we were trying to illustrate: there &quot;evolutionary surrogate-assisted &quot;Look, you should always create Remember how the agent is operating, doing &quot;Create a model of that environment.&quot; Track you do. Based on that track, create a model. in the real world all the time, try things can optimize against that model in When you look at that walking robot, we telling it. At first, the environment that It looks like, &quot;Oh, the trees are levitating,&quot; or it hasn't had a lot of experience trying to learn to walk, it's also trying to learn you see the environment stabilizing the outside. That's because every once in a in its model against the real world. Based What's interesting is that it's actually solving head can be pretty fluid. For example, if a tree much harder than walking around a stationary tree. levitate, you're definitely going to be able That's one of the interesting properties of this It's also future-proof. You can suddenly and it very quickly adjusts its internal model and technique that allows us to do that quite rapidly. Michael Krigsman: Can you provide any advice hurdles organizations face? And quickly, please. Babak Hodjat: Businesses obvious use cases of generative AI. already &quot;agentyfying&quot; things. They've gone in but I want it to work against my proprietary for example, retrieve proprietary and they want an agent to operate that app. So I think the next logical step is to have these so you don't have to force the user to choose and they sort it out amongst themselves. I feel happen organically. You need to take steps I think it also has the so you need to think ahead about what this So yeah, I think I'm an optimist. I think enterprises coming our way. I just think Michael Krigsman: Babak Hodjat, CTO for AI at and thank you so much for taking the Babak Hodjat: Of course, I enjoyed it Michael Krigsman: Everybody listening, thank to our newsletter, and subscribe to our YouTube shows coming up with amazing people between now Huge thanks again to Babak have a great day, and we will see you soon.