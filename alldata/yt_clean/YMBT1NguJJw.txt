In this video, we'll start by creating a very we'll start containerizing our app. We'll create image using the Docker CLI. Then, we'll run it 8080 to the localhost. Along the way, we'll test Then I'll show you how to convert the exact same discuss how to build and rebuild images using in the video, I'll show you how to hot reload First, we'll start with the imperative what we want step by step. Step 1 is to build On the other hand, Docker Compose uses describe the desired state in a YAML actions to maintain that state. If we it will use the build block to build the image, talk more about Compose features after I show Next, we'll start using environment variables our app. I'll show you three different ways of files to provide environment variables, which is We'll talk about new Compose features such to provide credentials, like passwords of environment variables. I'll show you how to and provide it to the app. We'll use short syntax when we need to specify the mount target of the configurations and secret files to be mounted Next, we'll talk about how to separate source configuration files. With configuration files, you hardcoded values for each specific environment. configuration files into containers. Then, similar to secrets, with the same API. You mount that config into the container. You can use Next, if you decide to run stateful applications between container restarts. The old way of doing you would take a directory or a file on your container. Everything that the container your local file system. However, this approach Another, more advanced, and preferred way bind mounts are dependent on the directory volumes are completely managed by Docker. mounts. For example, volumes are easier to back volumes using Docker CLI commands or the Docker Let's say you are actively working on a the source code. To test it, you would need I'll show you how to reload your application whenever you make a change and save the file, we need to create another Dockerfile Next, we will add a PostgreSQL database to our Then, I'll show you how Flask and PostgreSQL names as DNS. Additionally, we'll create a Flask and PostgreSQL into that virtual network. secrets to provide the password for the database In production, you would almost always place your we'll use Nginx as a load balancer. We'll round-robin algorithm. In our case, we would have on a single Linux server, you would use at least you can deploy a three-tier application as balancing traffic but also as a web server to To slightly improve security, we will We will place Nginx and Flask in the the private network. This way, if the Nginx be able to reach PostgreSQL over the network. using depends_on. In this case, the Flask container. A more advanced approach is to create endpoint and only start the Nginx container after approach is more reliable than simply defining Finally, we'll deploy this stack to a remote such as using restart policies. Most importantly, renew a Let's Encrypt certificate using Nginx to the internet, secure that endpoint Using this exact approach, you can deploy any and secure it with HTTPS. By the end of this application locally, deploy it on a single To summarize, we'll start by developing a we'll add a PostgreSQL database and Nginx for private Docker virtual networks. Finally, we'll We'll expose only Nginx to the internet and secure We'll also set up automatic renewal for the be able to deploy a full stack to remote linux The original Docker Compose command-line binary Python and invoked with the docker-compose on your host using a package manager or by as the V1 version of Docker Compose. At the top use a version element. You could specify values Compose file format. Also, we typically used a Version two of the Docker Compose command-line Go and invoked with the docker compose top-level element in the compose.yml file. itself. When you install Docker on your host the recommended file name is compose.yaml. supported. You can even use the -f flag to provide The main takeaway is: don't use as it will be ignored anyway. Use the docker Now, let's talk about use cases. First of all, many developers use Docker Compose for local of the production setup on their laptop. Redis, or any other dependencies that their quickly start working on features or fix bugs Also, many open-source projects provide quickly spin up the project locally and Another use case is when you don't have a to deploy production-ready applications on you can do so only vertically to your server. It's much easier to Another use case, which is rare these days, is to Swarm. Usually, if you reach the point where you would create a Kubernetes cluster and convert your Alright, let's go ahead and start. First, let's Flask is an incredibly popular Python framework Now, let's switch to that folder and create a is used to create an isolated space for your way, you can have multiple Python projects locally and this approach allows you to Now, it's not enough to just install you start working on the project, you and it shows on the left which Next, we need to install Flask into this project. it doesn't really matter, but you can use the double equal Whenever you build artifacts such as Docker This means using the exact versions of rather than pulling the latest In Python, there are multiple ways to lock oldest approach is to use a requirements.txt requirements.txt, that lists all the packages To create a snapshot of all current versions, use the pip freeze command and At this point, we have the Flask package and all as well as a folder for the virtual environment. and .dockerignore files. Anyone who wants own brand-new virtual environment and install Alright, let's create the app.py file, which You should use this name since we First, let's import the we need to initialize the Now let's create our first which is a common path to return about the running application. In Flask, want to accept on a certain endpoint like Next, we need to define the Python for processing this request. In the function, we'll hardcode the version for object with a version key. You can also specify return 200, which means everything is okay. We'll check instead of creating a separate one. So, it Now we can run the Flask application locally and CLI, which is installed when you run pip provide the file name without the extension, you can override the port and the Remember, this is just the development server, I'll show you how to use hot reloading for your In a separate tab, let's use curl to you should use 127.0.0.1 and Alright, it works, and we got the hardcoded Now, let's improve it a bit. Instead of hardcoding This is a common pattern to separate source First, in Flask, we need to import the os module. it from the environment. Let's use APP_VERSION app. In a real-world scenario, you would have Now, go back to the terminal and run it again. If we try to get the version now, it will be null because we haven't Let's stop Flask and export Unix-based systems, you can also use Now, you can see we have the version. session. If you open another terminal you need to run Flask from If we try to curl now, we get the version, is a problem with environment variables. They machine. Later, I'll show you a more secure way Now, let's start containerizing our application. we'll create multiple Dockerfiles for let's import Python, which is based on Alpine, a very small Linux distribution. We frequently Next, we need curl. We'll use it later in let's define the working directory. the image where all your files will be copied. Next, we need to add dependencies to that We won't copy the Python files at this stage and those layers are cached. If the Flask you only changed the source code, this step especially in your CI/CD pipeline. These and most CI/CD platforms charge by the minute, Next, let's go ahead and Finally, copy the Python files inside the Docker them one by one using this approach. For a large copy the whole project. In the latter case, don't out the virtual environment and other unnecessary For the last step, we define the command to use the this web server. We also need to expose Before building the image, we need to add this web server to the dependencies. Let's Then, use pip freeze to We will no longer use the Python virtual Just remember, if you want to add new Before using Docker Compose, let's build the image username, then the image name, image tag, and need a Docker Hub account for this tutorial, but The build process will go step-by-step through the Dockerfile, executing all Now, we have the image. When you start a the following command to map the application like 7070, on your laptop. Most but if something is already using that To test, we can use curl. We no longer we can use localhost, which is the same Flask with the default command. Also, we need to which we mapped to port 8080 inside the container. And it works, almost. We have not so we got null in the response. One way to fix this is to explicitly provide this variable in the docker When you hit the same /about Alright, now we can convert this setup and create a compose.yaml file, which but older options like docker-compose.yaml are I like to add three dashes at the top of the YAML YAML files in the same file. For example, can create Deployment and Service objects in the Then, we define the top-level you can create multiple applications. name for our service. Keep in mind that use this name as a DNS name to communicate Next, we define the image we want to we're just converting the docker run you some tricks later to improve We'll map the same port, 8080, inside Finally, we provide the environment variable for the version. This is one way, and Optionally, you can override the project Docker images, volumes, networks, etc. By which in my case is 199. In the real world, it's To run it, go to the top level and run docker foreground, which is sometimes convenient because to run it in the background and use the docker As you can see, it will create a named bridge all possible network drivers you can use with Then, Docker Compose starts a single If we try to hit the same /about Now, what if you're actively working it all the time? Let's change To test this, we need to rebuild folder and run the docker build command tag instead of constantly incrementing the so you can override even a semantic version tag, such as ECR in AWS, have an option to make those Next, we need to change the to stop Compose running in Let's rerun Compose. Test it, and we get the app prefix, so this is one you need to perform two steps: build the image it's not very convenient. Now, let's define the build we need to specify the context, which that application are located. In Optionally, you can specify the Dockerfile to use so you can omit this, but later so we'll use this to change the build steps. By the way, you can remove the image tag, name and the service name for the image, or it to tag your image. I prefer to keep it, and Now, let's change app_version back to you can use the --build flag to force Compose time you change the source code. I'll show which means you can get the new app To test, use curl one more time, and you should Let me show you other common ways to provide Docker Compose. We frequently use them to set In the previous example, we hardcoded values fine for some configurations. However, because we always commit the compose.yaml file To decouple secrets and configurations from the In this case, you only specify the variable name, Then, create a file to define you can commit the compose.yaml file stay local on your laptop or server. To Additionally, in the Docker Compose file, you need definition. This way, you source all environment container. It's very straightforward, and you will community when they provide a way to run Now, to test all those secrets, let's for testing purposes. Initialize We'll keep adding new secrets to that First, let's test the DB_PASSWORD if we can get it using this approach Finally, let's return the dictionary, which will be converted to JSON, Let's run Compose one more time, and don't forget to use the --build To test, let's hit the /secrets You can see we have the devops123 database Now let me show you a similar we explicitly set the APP_TOKEN environment with the previous database environment variable, The biggest difference is that if you forget Docker Compose will show you a warning. This is Let's also get this variable and Now, let's rerun Docker You can see the warning immediately if we forget to set this variable. In my If you try to query the /secrets endpoint, Another way to pass environment variables using the export command. This is pretty application at the beginning. Or, you can set Let's test it one more time, and it looks like Now, let me show you a more secure to the container. Environment variables and it can be difficult to track access. They errors without your knowledge. In a nutshell, we create a file with and mount that secret to the container. This way, it's not very convenient in some cases because and some open-source projects do not support this. After creating the file, we need to define call it api_key, which will be the file you just have a reference to the Additionally, we need to explicitly allow secret. This is the short syntax, and I'll we just need to provide the secret name. Now, in the application itself, we need to location is /run/secrets/&lt;secret Let's go ahead and rebuild the Flask container. If we try to use curl, we'll get you can't automatically expose those but you can change the location. This are using open-source tools or databases that To change the mount path, we need to first target path. In this case, we mount the same Let's get that second API key from the custom Alright, we can rebuild the image one more time. If you hit the /secrets endpoint Next, let's talk about configurations. The goal environment-specific values. For example, in a development database. In production, you would have different hostnames, users, etc. This way, for each environment. You can simply supply the Let's go ahead and create a very simple YAML real world, you can use JSON, YAML, or other file Traditionally, we mounted these configurations mapping a file on your local file system to relative to the Docker Compose file. For example, On the right-hand side, you specify where you want to mount that file. I'll put it in Usually, you would not use environment suffixes Your application, in all environments, Now in Flask, let's create another /config files. We'll create a config dictionary and is just for testing; you wouldn't have Let's go ahead and rebuild the Docker image. If we use curl to hit the /config In the new Compose version, you can also do exactly the same thing. The API Let's create a new my_config The next step is to add the config property to similar to secrets, and your config will be you can use a more verbose syntax want to mount it. Almost all open-source specific location. In this case, we'll To test, let's read that file and include Next, we need to rebuild When you try to access the /config endpoint again, you should now have two Next, let's talk about how you can persist anything you store inside the container will Therefore, you need a way to persist data There are two main approaches. which is bind mounts. Using this approach, local file system to the container. we used before. When you bind a your local everything the container saves in that folder Now, let's go ahead and test this. First, let's import requests from Flask. We'll use to test persistence. This endpoint If we receive a POST request, we want to save some check the type of the request. If it is a POST inside the container exists. If it doesn't, we write &quot;Customer record&quot; into that file, and On the other hand, if we receive a GET request, we to the client. So, we use the /data directory Now, let's go ahead and test Docker image to include the /volumes endpoint. To send a POST request, we can use need to send any data along with the request. Alright, we got a response that the customer Now, let's change the POST request to a was able to read the test.txt file from When using Docker Compose, you can either all data inside the container will be saved. Control + C, the Flask container will be stopped. If you try to get the customer data from the bit confusing, but you should not rely on this you will remove and restart containers you would lose all your data. Let me show you. Now, just run docker compose down, will be removed along with all Let me restart it again. If you try to get the customer record from test.txt file no longer exists. To create that's the problem--some applications, such as Alright, let me show you the binding a local directory to the Inside the compose file, select an my-data. This directory can be at the same create it inside the Flask directory. Just So, on the left-hand side, we have my-data under we bind this directory to the container's saves in that directory will also Let's run docker compose down Now, run compose up one more time. Whenever you send a POST request this on your local file system. You can see the To test this, let me stop and remove Now, let's run compose up again. And if you try to send a GET request, you we validate that bind mounts work, but approach would be to use Docker volumes to such as easier backup, management sharing among multiple containers. You Alright, let's go ahead and test volumes. mount since we will no longer use it just use the volumes top-level element To mount that volume, we use the and the target directory on the same /data directory inside the container. This time, let's run it in the background by adding the -d option to To get all the volumes, you can use docker your Docker volumes. You can also use the inspect Now, at the bottom, let's use curl to send Then, we need to remove the Flask container to make sure this approach works. If we send a GET request, we'll get the customer I suggest you use volumes instead of binding a Now, when you are working on some feature, you you can rebuild the image every but let me show you another way that does framework-specific, but you can apply similar So first, let's go ahead and create another It's very similar to the previous using a wildcard (*) and start Flask using Next, we need to update the Dockerfile want to run Flask in debugging mode so updated in the container. For that, enable debug mode and specify the Flask Then, under the volumes section, we want to map the entire Flask folder to The last thing to note is that since we copy we need to avoid copying some internal folders conflict with the container environment. similar to a .gitignore file. .dockerignore files for Python, but mostly Let's grab the first example we find As I said, the most important part Alright, let's go ahead and rebuild the image. You If we try to hit the /about Now let's add the &quot;app&quot; prefix Whenever you save that file, Flask will there's no need to restart Docker And now you get app_version. This approach debugging. Don't use this Dockerfile In this part, let's deploy Postgres and We'll follow best practices and provide the we need to create a file Next, define the secret and specify is located at the same level Finally, create a volume for the all your data if you restart your Postgres. Let's also create a network for both This way, they can communicate and use the other. Let's call this network &quot;private,&quot; and have another video explaining all the All other parameters are optional. For driver. You can also optionally provide and all your containers will Now, let's create a Postgres service. We will you can expose ports to the local host, application. By default, all ports are map the Postgres port if you plan to run Next, we'll use environment First, let's create a user and a let's provide the location of the secret in that Postgres will take that path, read the Next, we need to provide the For persistence, bind our Postgres data volume to Place this database in the private Additionally, let's place the Flask application At this point, we can run compose up in the Postgres database containers. you can use the docker ps command. We need a user and a table for the Flask application. name to match yours (e.g., 199-postgres-1). items. Since it's a to-do app, we need Next, we need to create a user for the Flask app. Then, grant all the necessary The next step is to install the Postgres driver forget to activate python virtual environment. We Make sure to get a snapshot of those In app.py, let's import the connection to initialize the connection with the and password from the environment variables. to Postgres. Don't forget to return the and select items from the database. initializing the Flask application. functions. The first one will take The second function will return Finally, let's create another /items we will save the item to the database. If it from the table and return them to the client. variables for the Flask app. We need the you can use the service name as a DNS. variable with the Postgres service name. Alright, we can deactivate the virtual environment it since we added additional Python packages. a POST request. Let's create another one as well. just send a GET request. You can also SSH into In this section, we'll deploy Nginx in Nginx as a load balancer. In our case, we scale it to multiple instances. This is a common First, let's create a dependency. We only when the PostgreSQL database is already is not very useful. It simply defines the order example, we want the Flask container to However, depends_on by itself does not check if is healthy. It works in this case only because the 30-second timeout to wait for the database. So, but I want to show you that this option exists. Next, let's create an Nginx configuration to load balance traffic. We need to define the upstream list all the backend servers. In our case, By default, Nginx uses the round-robin algorithm, but you can configure it to use have another video explaining different load For the location, we use that upstream service. Let's use the compose config top-level we can create an additional virtual network and the public network and keep the PostgreSQL if your Nginx gets compromised, it's not possible Now, let's create the Nginx service itself. Alpine. For Nginx, we need to map ports 8080 In this case, we need to mount location inside the container Let's place this container inside the public and place it in both the private network and the to reach the database, and the public network We no longer need to expose Flask or PostgreSQL Finally, let's create a proper health check for after the Flask application is not only created Instead of creating a separate health check endpoint. The main requirement is successful status codes between 200 and 300. It's very straightforward. As you remember, and we can use it to hit the /about endpoint. this service will be marked as healthy. We also need to create a depends_on block Alright, that's pretty much all. Let's You can see that the PostgreSQL container is Then, Compose waits for the health check to As soon as curl hits the /about endpoint, and Nginx will start right after it. Now we can test by hitting Nginx In the logs, you can see that the request Let me show you the container networks. You can run docker ps or docker-compose ps Let's go ahead and inspect Flask. The Flask app public virtual network and another in the private Now, let's SSH into the Nginx container to Use the following command to check ensuring Nginx can access it. Now, let's see if the PostgreSQL It says that nginx cannot resolve the PostgreSQL DNS. If you try to access PostgreSQL by Now, let's see if we can resolve Flask. Yes, we have the IP address from As expected, we cannot resolve PostgreSQL to the IP address since it is located In this section, we'll secure certificate and prepare for Linux server. We'll also automate You can do this at home using the public IP or you can set up a virtual machine in the do it in AWS. However, the process is very First, let's declare a few environment to use your real email address here. If Let's Encrypt will send you a You can also select how often you want to check Encrypt issues certificates that are valid Certbot will automatically renew them. The default You can also tweak other parameters. environment variable to 1. This means you'll issue certificates. Once you verify that you to use the production environment and issue real number of certificates per week per domain, Next, create a similar Nginx config, but still declare the myapp upstream service, don't need to set up a redirect from port It's important to replace the domain with your where you want to store the private key and much it. You can use the same approach for Before we add Certbot, let's make sure our restart to always. This way, if a container restarted. This setting is necessary in the such as an EC2 instance, restarts, this all the services once Linux starts. It's Next, we need to change the Dockerfile. hot reloading and is optimized for production use. I discovered a weird behavior on variables provided in the config with and get values from the .env file. config with the TLS section and comment out Nginx needs to obtain and store the private and we want to persist those files between Nginx would need to issue a new certificate, let's create a volume for Nginx To automate the TLS certificate, we'll You can use it as is or build instructions. It's a relatively popular Now we need to expose port 80. The HTTP-01 back to Let's Encrypt and prove that we manage for HTTPS. As I mentioned before, Nginx will Next, let's mount our new Nginx config to a For persistence, we need to add a to /etc/letsencrypt. This is the default We also need to provide all the environment including your personal email address. command to verify that all environment for the containers. This is a Now, let me quickly create an EC2 other cloud provider; it's very generic. Give it a name like &quot;myapp.&quot; You can keep the t2.micro for the free tier and sufficient for testing. key will be saved in AWS, and you should keep the this private key to SSH into the Ubuntu instance. challenge and port 443 for HTTPS. That's pretty In this case, we use the default VPC. All subnets and virtual machines will automatically Let's wait a bit until the EC2 instance Under the Security tab, double-check that you you won't be able to get a certificate. If you want, you can limit the source for Next, we need to get the public IP and Before we can SSH, we need to private key to be accessible only by our user. username is always &quot;ubuntu,&quot; and you'll need to Next, we need to install Docker on and you'll be directed to the official Docker First of all, we need to set Copy, paste, and run the provided Next, we need to install Docker itself, paste, and run the commands on the server. a &quot;permissions denied&quot; error on Linux. To use it, To fix this on Linux, follow these steps: Add your current Linux user to that Docker group. command or start a new session. Next, we need to copy all the files to the remote file and other configurations, or you can use the You will need to change the key location and use the current directory to copy all files, At this point, we have all the files on the config one more time to ensure all your compose file. This is useful because Docker Make sure you provide your real email and double-check that the For the first time, I suggest running Docker in If you uploaded your Docker image to Docker Hub, it will rebuild the image locally. For application (which I would not suggest for pushed the image before running compose Alright, Certbot will generate a private to request a certificate from Let's You can see the issue: we didn't create a DNS IP address. Let's go ahead and fix it. It does you just need to create an A record and point In my case, I use Squarespace domains, but every it takes a couple of minutes, but in edge You can use dig or nslookup to verify your domain to the public IP address, we can Let's also run it in the foreground for get the certificate. You will see that You will also see a message in the logs indicating stored locally. browser and test if we got the certificate. is for testing only, as we used the staging Let's can get this test certificate before switching Alright, let's set the staging environment If you change this locally, don't again to copy the file to the server. sure the staging environment variable is set to 0. you can remove the volume where Certbot saved This time, let's run Docker Compose following command to tail the logs of Certbot will generate a new private key and challenge. Since we already created the DNS Alright, you can see that we got a new real renewal every 8 days. This does not mean that it only means that Certbot will check if one if it will expire in less than 30 days. This time, we shouldn't see any warnings. You will see that the certificate is Also, let's test the HTTP to HTTPS Now, let's test that the restart policy containers with docker ps. You will Now, let's restart the Ubuntu server containers automatically after the reboot. Now, you can see that Docker Compose started and the uptime is only a few seconds. If we try we get a response. If you want to scale your Kubernetes, which is the de facto standard for on my channel and other tutorials. Thank you for