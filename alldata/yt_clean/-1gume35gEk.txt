Hey everybody, my name is Timothy Hanson. I'm Angeles, California, and I'm also the And I'd like to thank Capturing webinar today, and for asking me to be a going to talk about today is photogrammetry with RealityCapture. And trying not 'motormouth' and talk super we're going to talk about why photogrammetry with RealityCapture, the gonna give you 5 tips for photogrammetry in mind, and then we're where I'm gonna show you how that you've taken and run through an photogrammetry? Let's say that you have to have an accurate recreation, a 1:1 representation of a structure or an meet your project, you have to get this is you would bring in a modeler and then bunch of time creating the asset and, and that it would take to do that. him or her, you know, model for say 2 model, and then, once that model is done, looked at artist, and have he or she thing set up and to finish the asset. So, all man-days, basically a month's time, dollars and what the cost typical freelancer's rate would be $500, that by 20 days, you're looking at about for this, this one asset. Which is, you ballpark of a typical asset on a project asset. But let's look at the time. It took architectural structure that I'll show I had about 3-4 months ago photo-accurate-down-to-the-gum-on-the And you can't get better than, you can't where they were down to the millimeter, error but photogrametry will give you an So 4 days versus 20 days. and that 4 dollars a day for freelancer, So you're looking at a cost of photogrammetry for a perfect asset or doing it traditionally. That's a big So making that even more sweet, let's say had. You can get 5 assets and the time huge time and cost savings, especially like 20 assets that it needs or, you know, So that, that money and that time is just further you go. So that's why like a rigged animating asset, if photogrammetry is a way to go. It's cost saving. So that's why I would photogrammetry. Because when it comes down to just dollar bills, they're a great way to go. So, now that we've talked about let's talk about 5 tips that capturing imagery for photogrammetry. So imagery, when you think about film or about typically these beautiful bokeh, really smooth beautiful images. For photogrammetry you want to shoot a high f-stop to eliminate as much depth of field as possible. Depth photogrammetry. Because, if you think many clean and clear features to solve image is super soft, the software's not So you want to shoot the high f-stop, kind of the opposite of what you would but you're not shooting a film - you're clean, sharp images. I'm gonna show you shot at f-16 or f-18 and then another you the difference in terms of depth of why you want to shoot like this for photogrammetry. So let's take a look at that. So, looking here at this example, we have 2 images: one at an f-stop of 3.5 and another and an f-stop of f-18. And you'll in the f-3.5 version you can see that things go very soft and blurry as we get further away from the focal point. But then if I switch see all these leaves are not sharp, it completely in focus and this is what you depth of field version. You want to shoot this image to be perfectly clear, work with. Okay, so that was tip number one. And now goes tip number two. The second thing that I would suggest for people to photogrammetry is your lighting. Now, you use as your base before you go in to to capture, if you have control over, you shoot in the morning - early mornings, sun is coming up are the best times to of factors. One, early in the morning a bunch of looky-loos getting into your drone?' You know, that kind of stuff... morning while everybody's still asleep. early in the morning is it gives you your enemy. Shadows and depth of photography for photogrammetry. So you diffuse lighting. That's the best thing. know, when I look outside and I see an know that there's gonna be no shadows on the kind of time of day that you want to super harsh, contrasty, you know, of that. Because what's gonna happen is, if for your photogrammetry you're going to you don't want those shadows and that because then, when you go to light your coming from this direction but the key took the image, now your shadows are image is going to look weird. So you wanna possible. So lighting, think about it, no shadows, no baked in lighting. The third tip I would lensing. Don't go crazy on the zoom lens the other half right a 100 or 85, you want to stay consistent. That way you give the software the best, solve. If it doesn't have to calculate zoomed out, it's gonna give you a better higher resolution solve. So especially too Mavic 2 Pro and that has a fixed lens shooting with my drone, I'm setting my they're in perfect harmony and it helps later on. So keep your lensing consistent towards a wider lens, like the 24-28 image and the more you can get in the to solve. And, also to, I would more image top-to-bottom than you do coverage side to side as you walk around better. So, then, the fourth thing, which is is parallax. Parallax, parallax, parallax. if you think about it, you want to take subject. That way the software can solve and, doing it this way, you'll have less are going to be much cleaner, much, you to just doing concentric circles around multiple angles. You don't want to shoot I would, like I said I, use a drone, so I get down on it like that or I'll get can. Get from a high vantage point. Then low. Get under it, shoot at it as much as from every conceivable angle. That way point cloud is gonna give you a better, shoot, shoot. If you think you have enough there and take some more pictures. A especially as complex as this model images. A combination of about 300 to 400 or more from the DSLR down on the ground. As high-resolution images that you can get, as many images as you can get and to completely capture that object for angle. All right? And then, the last tip, about cleaning those images before you suggest is to use Lightroom. You can use tools, specifically for this type of get into RealityCapture. So which you wanna do is, you want to go into Lightroom and you want to calculate for lens distortion. distortion of the lens as you can and distortion on the lens, then you want to shadows as possible and highlights. You know, your white balance evened out. You one way or another because that's just even, no shadows, no superhot highlights, That's gonna give you the best image to best success. And so you want to make a images and then run that across the whole set. You want every image to look exactly like the one before it and the consistent color for texturing and solve before we roll into this walkthrough and time effective and, you know, 5 tips: no lensing, lots of parallax and lots of you start your RealityCapture session. Alright, so let's get started with an actual walkthrough on how to use RealityCapture. What we're gonna go over is the steps that it takes to make an amazing structure like this, recreated from nothing but just involved. Out of the gate with this, this do is you want to come to this Workflow starts with RealityCapture. Basically your imagery. And now there are some basically, you know, if you bring in your hit start, it will do exactly what it model with the texture and, you know, structure like this it's far too complex process. You're gonna need to know how to manually manipulate things and use a process to create an object that's as able to rely on just using the Start simpler objects. But something that's this, you're gonna have to do it manually. we want to do, so I'll come over here to our images, the things we've taken and tab right here. That's the first thing that you've stored all your images, and I 1,450 images, and you want to just go ahead, click select all and hit open. And then, what that's images into this tab here, where you'll can see it brought in all of these combined, there's drone photography, you can see here as well as just standard DSLR information that you're gonna want to you can see, within each image you can data, as well as showing you what the by. And now that's a good tip, when you're photography is it's best practice to here that the majority of my DSLR on a 28 mil, now if we scroll photography, you can see here I named it can see as well that those were shot on using a Mavic 2 Pro and the standard camera lens on that one is a 28 mil lens so you will be good to go. Now, ah, this little error message here is just because at this time the version of RealityCapture that I'm working on just their database but it's not going to your point cloud in your scene. So, that's images are in and we have everything going over to this Alignment. And when we cloud using the images that we've just here and click Align images and it will point cloud. Now, for the sake of time in the to the actual generated point clouds so gate and then we'll go from there and upon that solve and get things like the photography in order to get them to mesh use things called control points. Now, I point out too is, any solves that you do something that RealityCapture calls Basically it's a point cloud that's it was able to solve for out of the treating every image like a camera, for I pull out here and go to Scene and then these, all of these are representative of of these cameras are basically just an patterns that I used in order to capture all this data is basically the, the number one is you want to have parallax and the way taking photography, is you want to take around the object as possible. And here the path that I took - where I took a very basically taking an image at intervals basically I walked around I just took a step to the right, fired off an image and structure, and again, walked around closer with each loop to where, you know, get in the tighter loop around and then also again, did many, many, many loops around the most parallax as possible. And, now, look in at these cameras themselves, like camera is basically pointed at the at this mullion here. And why taking the important is even though you're doing the angle of the camera so that you can So, say for instance, if we just look at basically the data you want to get from you want a shot that's dead-on, you want three-quarter angle on this side and three-quarter angle to capture the other the top of structure, then you want to do that, again, as I was taking these around and around the structure, is would focus in on just one mullion and step to the side, take a picture, step to the mullion the focal point of my image then I would start off at a this mullion here the focal point of my make this my focal point, step to the an image, and then doing the exact same making this side my focal point of focus, focus, I mean, basically, you can almost just by looking at these camera, the how you're gonna maximize your imagery RealityCapture can solve every single on the ground. It has everything is a faithful one-to-one recreation of what this you've taken a photo of basically every help RealityCapture to solve. So, again, tangent on actually how you take the getting back to the components, now as we said, each image that is used, considering that a camera, and so what 1,200 out of 1,400 available cameras were used to create this point cloud. So let's look at this what is just generated raw, let me walk 'cause we know what the dots are now, we don't need to see them, so this is the point cloud that's generated from cameras and basically what that means is the photography taken on the ground, it taken by the drones because it didn't saw all of the images from the ground, component, and then, if we look down here see that this is all the photography and representations, that this is all the from here we've got a really good amount the top of the structure and the little closer and come from a side angle, about what's inside the structure and two sections where basically it's like that's from a drone, I solve for this, I images that are from the DSLR, I solved here on the ground imagery, you can see resolution on the top of the structure ground we don't really see the the roof the drone to capture the top down and the ground but now how do you get these two things to, to merge and work together, how do we and get the point cloud generated with you do that is with control points. And see here's Control points. So you want to do is come down to this Control points Create and then what that's going to do it'll start out at 0. So in that point, actually here's a point 0 right here. I'll feature that I stuck my point on and if basically on the bell portion of the defined piece of rust corrosion, like scroll through and look at another image... zoom in here... Some of these images are preview to generate. All right, there we almost like match moving, if you're something like that. Control points you trackers. And you want to lay those down something that is easily visible from that in multiple images the software that this is that same point, I'm going generate my solve. And so if I scroll you can see this point zero out here on hover over the point, you'll see, over control point essentially merges And so, we have, you know, roughly, you know, maybe 30, 30 or so images that we have tied to this one control point and you on this p number, this number here is this point and, now, a good control point cloud is gonna be well below a pixel are basically point 4, point 3, control point that we've chosen, this point is an excellent source of And that's gonna help RealityCapture image. All right, so we see why this is a know, tie in a bunch of cameras on the able to get those two components to that drone imagery to tie in with the if I come down to actual, the final really good, but come down here, I'm gonna cameras from the drone linking up two helps us is it allows RealityCapture to these drone images and I have these other, this is all connected. So I need to that I've been making and merge them has all of the information.' And this one information from our, our ground images, I mean to make this a little wider so down to like individual slats of wood, recreated. I mean this is a 100% faithful recreation of this exact location out there in the world, the day. But so that's how you use clouds and to make your components mesh together into something that you can solve for and mesh, and then texture. Alright, so now that we've gone over how create our point cloud, and get back to using the aligned images and control points, the next thing we want to do is to reconstruct and create our mesh. So here, you'll start out with and there are Normal Detail, and High Detail. generate just, you know, just a mesh that blocking, and just make sure that, you faithfully and there's not areas of low images. If you haven't taken enough the mesh, and then you'll have to go back control points to get more data in those more pictures on wherever that structure honestly, the one that you're gonna want and high detail, there's, you know, the you more detail but the speed decrease compared to normal, and when you can get detail you get from high detail and normal, and you know, less than half the time, you're gonna want to use normal detail. I mean, really, with these kinds of models - the from high detail, you'd never notice it, of models. That's, that's one of the great don't have to do that high detail it's really, honestly, it's amazing. so that Normal Detail and what it's gonna I have one here... And this is what a model out of the gate. Now, right now, it it and things like that but that's the machine that I'm on in the raw state out massive. For example, like this guy the next step of this process is how to down into something that's more some, I mean, the, the final one that I million tris but it was closer to 2 it's mesh solve. And that thing was So this is an actual contiguous solid better from afar. It's just RealityCapture is really smart in the way that it parses information onto your video card, just basically lock you up. If there's an you a point cloud representation of it. So from here, in Reconstruction, what we're guy, reduce it down, and the way you do tool. So what you do is, when you click on this little menu down here give it an exact target to hit. Or you could basically the default here is gonna hit that's a pretty good one to go with so So once you've simplified that model, it's million tris down to about 3 million difference at all in the mesh itself. And gonna want to do a couple things: You're it's gonna do, as it says here, if you corruption in the model. Check Topology things and, and fill them in. filling in, so the steps that I do is, Integrity, Check Topology, Clean Model, and most part, these three here will take it been decimated down, the next thing you before we can pull our textures, we want in the Unwrap parameters, again, this for the amount of definition and just a RealityCapture pulls some pretty good and Mari, where you no longer have to sit every single object, we don't live in don't. So but RealityCapture will pull some really, really strong UVs and give you here is, you can set the maximal texture it to output. So you can go with, you know, anywhere from 16K, 8K, 4K, down to 2K images. I in the 16K or 8K range. And then you you want it to have. So instead of one you UDIM image, you're gonna be able and parse it out amongst 10 tiles or 12 it's gonna calculate the ratio of the versus the resolution of the texture, and of projection fidelity that it possibly 'okay, for 16K maps with 12 UDIM tiles, representation of the images that flawless. So to prove that point, let's did, pull the model and the texturing on. here, in this area under our model and count of textures was 17 and, basically, I 16K maps each, and that gave me a 74% quality was a 107%, so basically, using only 75% of the images that I took to scan for the model, terms of the texture reprojection. And so point-on, spot-on accurate, cranny of this object, again, down to the Everything's recreated, one-to-one, I mean, again, you, you don't have to use television so I, I want to have you know that can be cost prohibitive in terms of you know, this ratio here basically is to keep an eye on. So, however you work text resolution, or less UDIMs and number here, this texture quality, is at know that you've faithfully recreated photo reference that it had to work with. All right, so that's, you know, the long and short of it, that's the entire process, and that will give you this one-to-one faithful accuracy in detail and, you know, we've video but this whole process, all in, took four days and now it could have been a doing the high detail so it would be normal detail. And you can keep track of looking down here. So you can see Overall was 3 days 19 hours, the texturing time took just under or just over a day. essentially the point cloud generation, at about a little less than a day to nearly 1,500 images, another day to mesh the object, and then just, just over a day to texture round that up and just say that it was create a faithful one-to-one pixel-accurate, texture-accurate recreation of this structure. And, again, 4 days take to have, you know, a regular like this, like taking 2 weeks roughly it, that's an enormous time savings when you're creating, you know, assets like of a real phenomenon and places and RealityCapture can save you is let me drive home that point one more of work versus what it would take in did this by, by hand, manually, with a team multiply that out by, you know, this is have ten of these, say you have a hundred save using photogrammetry and RealityCapture in particular, it's, it's just astounding. You'll, you'll never want to all my shows and I've been (laughing), I've been ringing the bell out there, on, in my studio, and among other studios and you're doing any kind of onset data using photogrammetry and you need to be name is Timothy Hanson. I'm a visual California, and I'm the founder of MAXDEPTH.tv. You could find a number of tutorials and specifically one on RealityCapture by hanging the MAXDEPTH.tv. Thanks.