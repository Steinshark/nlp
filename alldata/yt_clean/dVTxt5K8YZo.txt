Sam Altman is out as CEO of OpenAI. A superstar CEO on one side, and the other 747 of 770 employees letter to the board five days Sam Altman is back. Does this even count as a firing? This was a brutal. I guess I'm not really supposed But this is what now with Trevor Noah. Hey, what's going on? Nice to meet you. How are you doing? Good. How are you? Absolute pleasure, ma'am. I'm too. Thanks for taking the time. Thank you. at what I feel like is a crazy time, Feels like the craziest time Yeah. Lived through. Yeah. I mean, you're at the. You're at the center of it all. So I wonder what that feels like, I'm just an avid watcher of everything in this space And I feel like you're somebody I mean, I mean, just just Sam Altman was on the shortlist Not to get that thrilled Of course. Wait, why? I have had more attention this year to have in my entire life. Oh, happy for Taylor Swift. Oh, so you don't want You don't want the attention? I mean, it's like fun in some ways. And it's, like, useful in some ways. But, from, like, a personal life, Trade off. Yeah. But, you know, this is it. Now, like, Right. It's it's the infamy Do people That's the kind of trade off Yeah. You just feel like you never. I'm sure it happens to you, too. But I never get to be anonymous Yeah, but people don't ask me Don't ask Exactly. Exactly. There's a People might want a selfie from me. That's that's well, congratulations. You are time magazine's Yeah. That's that's that's probably one Because I guess a few weeks ago. You might not have been I don't still been able I guess it was for your work before. I don't know how it works. How how does it feel I'm still, like, Yeah. I mean, because one of the things is how much I love the company Right. And, you know, I had a couple where I went through, like, like, It felt like in short but a very clarifying moment for me was, the like. So it all happened on like a Friday and then the next set the next morning a couple of the board what would you like to talk about And I had really complicated but it was very clarifying at the end Like, I really I love this place And I think this is, like, important And like, It feels hiring and firing is something I mean, I know back in the day, you know, you were at the And you were fired And everyone has a story. And what are we what what is. I don't want it to be. Oh no no no no no no no. Don't tell me, You know, you get the research Oh, I mean, I had, like, decided like a year earlier Right? It was like a complicated transition I had been working on both OpenAI NYC and, like, very much decided Okay. All right. So then. So then you've never been fired. And this is a tough place It doesn't even count as a firing. And you know what I was going to say? It's not like this was a brutal. I guess I'm not really supposed it was this was a very painful thing. Well, I think that felt to me personally, the way it was handled. Yeah. Yeah. I can imagine, you know, you know, getting getting fired It became it became a trend, especially, people would talk about that would go out. And then, you know, thousands of employees You seldom think it would be possible for that to happen And then and then I think even more to a CEO the Steve Jobs of this generation You don't say that about yourself. No, I think I think a lot of people say that about you, I was thinking about this the Steve Jobs of this generation I think you're the Prometheus No, you really are. It seems like to me And you are at the forefront of this, and this and this time Where once I was, was only the stuff You know, you are now the face of the Yeah, like civilization five. Do you think it'll change everything? I thought I do, I mean, I, I could totally be wrong about what I'm about to say, something that everybody, almost The definition is hard, that people will look at and say, That's that you like, you know, a human Let's before what would you say between what people think AI is general intelligence is? We're getting close enough people define it is important So for some people, some significant fraction Yeah, of course we'll find new jobs. but for other people, more like a system that can help Okay. And those are obviously milestones have very different but the even though I so stuck with it, You don't like which term? AGI. Okay. All all that I think it really means really smart AI, but it's, it's become super fuzzy And I think largely But the point we're going to make AGI And then at least in the short it's going to change the world much less than people think I, I think society The economy has a lot of inertia. The way people live Yeah. And this is probably healthy. this is probably good we all kind of do things in society, as the super organism and is kind of used to it. So watching what happened I think was instructive. People had this like real freak Yeah. Said, wow, I didn't think Here it is. And then they went on and it definitely changed things. People definitely use it. It's a better technology And of course, you know, GPT four And five, six, seven whatever for was the moment in ChatGPT interface, I think was the moment from not taking it seriously And yet life goes on. Is that good for us as humanity and society, I think, or as, of this product, do you wish that we all stopped I guess, take stock of where we are? I think the resilience of humans individually Okay. And I'm very happy and adapt to new technology to just like, you know, part of the world, the I think Covid was a recent Yeah. You know, like, yeah, the world And then it felt pretty normal I mean, another example but instructive was It was a couple of years ago a lot of my friends maybe those aren't real UFOs Everyone. Yeah. And yet they just kind of, and played with their kids Yeah. Because, I mean, What are you going to do? What are you going to do? If they're flying by, they're flying So so do I wish that we had taken we are doing that as a world, I'm a huge believer that iterative deployment of these We want we don't want to go build AGI off Yeah, we know what's coming all at once here we are. Like, you think we have to get used to it And so this conversation, now that society that our leaders, where people actually use have a feel for it, what it does, where the risks are, I think that's awesome. And I think like, maybe in some sense our mission was to adopt. So far, was to adopt the strategy Like, and then built it up and then dropped, deployed it. You know, it's interesting. You today AI building, And it feels like And I saw a post of yours. Where did you come in Not anymore. I'm back now. I did okay one day during the middle. All right, I saw you, I saw you, where you came in as a guest, that's a weird one. It was like coming home, Yeah, that was an it is home. It felt like it should have been to, like, But I was like, so exhausted on so much adrenaline. It really did not feel momentous in the way that I guess I could say It should have been like a funny, and tell stories that were like that, like one of my I, I was very tired, very distracted. and, you know, we thought the board was going but in case they didn't, which is like our lowest level by one of our, like, best people. And, you know, he gave me a. Yes. That was like, a very proud moment. That you still got the skill, the badge was not as poignant Right? I'd love to know what you think as CEO, to have the level of support that we've publicly seen You know, when the story broke and I, because I know, you know. No, no, because I know you can't comment the internal investigation stuff Yeah, I mean, that stuff. But what I mean is, you know, I know you can sort of and, and, and what's been happening It's rare that we'll see a situation, You know, you have this company doesn't exist The next minutes you release ChatGPT the simple prompt, just a little chat I think you go to 1 million users in the fastest time Five days? Yeah, five days. And then it shoots and it very quickly, it went from nobody in the world I was explaining it to people I had to show them like poetry And then people and now it just becomes where people are trying to come to grips with what it is But but on the other side, you in some way, shape or form, And and the people are behind you. You know, we see the story. Sam Altman is out no longer CEO. And then the swirling everything. I mean, I'm like you. I don't know They were crazy. One of the craziest things I saw was they said, like someone said it was They said, I have it on. Good, good. I have it from good sources for trying to have sex with the AI. That's. That's what someone. I mean, I don't even I, I saw that I was like, the moment, I should officially deny Yeah. And I don't think it could happen because I don't think the combination of the two things. But but what what got me was how the salaciousness of the event AI into a different spotlight And one of the big things you had from your team, we're with Sam. And that doesn't normally happen CEOs and its employees are generally in some way shape or form, Yeah, but it feels like What I'm about There's plenty of places I think this one, though, Other than me is sort of like a But, like, I think one thing a mission that people really believe And it was a I think what happened people realized that the mission and the team that we have all worked and made such progress too, like that was, under real threat. And I think that was the It was really not about me you know, hopefully people like me It was about the shared loyalty we all feel, and the sense of duty and wanting to maximize our chances at the top level, what do you think Is it to get to artificial general, distributed as broadly as possible all of the safety challenges Okay. That's that's an interesting, I would love to chat to you You know, getting into the safety as a, as an organization, the very genesis of OpenAI and you'll you'll correct me But, you know, very much with safety in mind. You know, where where you brought And you said, a company, the most ethical AI possible And you see that even in the the way the company defines how its investors but even even that changed Do you think do you think you can I mean, there's Do you think that you can a world where money doesn't define you're trying to do it? It's it has to be some factor. Like just if you think these systems alone, play on the field of capitalism, Okay. But I don't think it will The and by the way, I think it has huge flaws, but relative to any other system I think it is still the best thing But that doesn't mean we shouldn't and I think we will find ways to, spend the enormous, like, record that we will need to be able to continue to advance that was like one of our learnings It's just the stuff is way right? Like we knew we kind of knew but we just didn't know You've always been That's that's something Yeah. You know, even when, one of the people you invest with now Yeah. Power. They said the first thing he thinks about is, How can we solve it? And the second thing he says This I don't remember. I'm terrible with name. Interesting. but I know it was somebody you work No, it is. It is. Right. But I haven't heard Yeah, yeah, but it is. I think that it it's it's observations across many different like facets of companies that scale often yields So like scaling up these AI models scaling up the fusion And all of these obvious but some non-obvious ways to scaling up companies Scaling up groups of companies like Y Combinator has non-obvious And I think there's just not taken seriously enough. And in our own case, we knew scale if we had been smarter or more courageous thinkers we would have, like, But it's like, really hard to say. I want to go build a $10 billion So we didn't write, and we learned But we did. But now we see how much scale and again, I have I have nothing against Well, no, that's not true. I have a lot of things against it I have no pushback that it's better than anything else Have you have If I could design a system? I have, a different Yeah, but like, you know, like, how AI and capitalism are going AI, one of the things that we. So we were right of our initial assumptions It was possible which a lot of people laughed Oh man, we got ruthlessly but even some of our thoughts about how to get there, But we were wrong which of course happens You know, for how we thought before the language model stuff We also, I think, had of what it was going and we didn't understand this idea iterative tools that you kind and so about, well, when you build an AGI, And we sort of thought about it is and then this moment of AGI and, give that over to some other system I now think it can be. And I'm really happy about this navigate. I think it can be, because it's different But but in some other sense, We've added something to the tool People are going to use that to do people not one AGI in the sky. It's you can do things I can do things I couldn't do before. We'll be able to do a lot more. And in that sense, I can imagine a world our mission is that that massively impact everything else. And I'm pretty excited about that. Like, I love that because I personally really think for the internet. but we just like, That's the downside of capitalism, Yeah, yeah. one of them, I think there's much But we put this tool out there for free, and we're not like, We're not trying to make them All right. and I think that shows path that we can do more on. So so let's do this. You know, you know, in our time together, so many things you know, we won't be able to answer there are and a few spaces And I guess the first and most what what what happens now Where do you see it going? You know, one of the things I found was what the new board was. How the new board was, was, you know, where previously you had Now you don't. Yeah. You know, where previously you had no financial incentive on the board. Now you do. And I wonder if if you worry part of implementing is now gone, You have a board that's now not you know, defining a safer future and getting this thing to be as good well, I think our current, our previous governance structure and board So I'm all for figuring out And I'll support the board obviously the burning board and that'll be something that I think and voices of people advocate for people who are and be really thoughtful about the lessons we can take from the past very complex systems that interact Right, as good as possible, the bad and sharing the upside, so I'm, I'm excited at getting all these things right but but yeah, like diversifying the board, making sure major classes of stakeholders figuring out how we make this continuing to push for governments governing this technology, but I think of doing this that we can think of More to like help. Let them help That's all super important. that'll be one major thing going the board and governance. And yeah, it gonna really like but I think there's so committed to all the things Then there's another if you asked me a week ago, I would have said stabilizing But, internally, at least, We did not lose a single customer. We cannot lose a single employee. We continue to grow, We continue to ship new products. we are key partnerships. Feel strengthened, and things are on pace there. And the sort of research and product of next year, I think feels better but there's a lot of clearly there's like a lot of external stabilization. We still have to do, and then and then beyond that, like, we're. Really confronting the possibility we have not been planning ambitiously You know, we had we had like ChatGPT plus right now, you have We just ran out of too many people. And so given how good we think the future systems and how much people seem we have been like behind their plan and we'd like I mean, I found myself constantly You know, when, when, when the whole whenever, whenever there's a storm, in what's happening You know, and I wondered, like, when this all broke, like, well, What what was going on in your world? On a personal level, people say about me is I'm like, I am good at sitting in the eye of the hurricane while it, like, and staying super calm. And this was this time, like, this was the experience of, like, being in the eye of the storm I was in Las Vegas at F1. Oh, okay. Yeah. You an F1 fan? I am, yeah. Who's your team? Do you have one. I honestly I like It's hard to say okay. But I feel like that's the answer. Everyone would say I still It depends on when they joined I was a Schumacher fan Well I mean Nigel Mansell then like Ayrton Senna But yeah okay. Well he's I like now Verstappen I see why and just like like I Why watching it when so often. But it's it's incredible. so I was like so excited for that. that first night That first night, someone, like, they forgot the well done, So someone drove over it. The first lap blew up Oh, wow. Stop to the practice. So I didn't get to watch it. I never got to watch any race I was in my hotel room. I took this call and got fired by the board. And it was just this, like, I was like, I was confused, It did not feel real. It was like. Like obviously like upset But confusion was just like It was like it was just in a fog. In a haze. I was like, I got didn't understand It happened in this, in my opinion, crazy way. and then in the next like half hour, I got so many messages And who is this from? Employee. Everyone. Every every like it was. My phone was just like unusable notifications nonstop. And I, like, hit this thing That message got delivered late. So I couldn't even like, you know, so it's just and I was like, talking to the team here, trying Like, Microsoft is calling everybody it really was like. Unsettling and didn't feel real. And then. And then I kind of, like, and I was like, you know what? I, I can go on and I can I really If I can't do it, I'm And just thinking about the best way Greg quit. Some other people quit, started just getting like tons of messages we, you know, want to come like work And at that point, I was like, not on my mind at all. It's just like thinking about But, I kind of didn't industry event this was because I, All I could tell was I was getting Right. Because you're actually And I was just trying to, like, I figure out what I wanted to try and then flew back to California, met with some people, and, and kind of was just, like, at that point. But, you know, also But and then I stayed up Couldn't really sleep. Also, it was just like and then it was sort of but I'm sure I still have not. Like, and a little bit just trying You know, I'm sure as I have time sit and process this, I'll, like, Right? Do you straight back into everything? Because it it, you know, to You can see in your eyes and the world that it can never return from, so you're all of a sudden, it doesn't seem like you'll be able to achieve it But as you say, Microsoft steps And Satya Nadella says, hey, come, We'll we'll rebuild this team. If there's one if they've worked with him, He is. He's unrelenting. He does not believe in in If you if you have a goal and it seems like, like you're You said nothing You weren't disparaging in any way. but it feels like I mean, I think it's anything I won't like bounce back from, to go through this and not have it That'd be really. Did it feel like you were losing Yeah. I mean, like this. We started Like first day of work and then I've been like, I was working on this but I've been like full time And it has like. AGI in my family are like So losing one of those is like, and again, it like. Maybe in some sense I should say I going to work on AGI and that care But but of course, These people are users, everything we built up here. So, so yeah, I mean, it was just, The only comparable set of life experience And this, that one was, of course, and that was like But the sense of, like, confusion and loss and, you know, you get like, like a little bit of time But then there was so much to do, like, And it had to be like to pick up the pieces of his life and it wasn't until, like a week to just, like, Holy shit, so yeah, that was much worse. But it was there's like, echoes of that I can only I can only imagine when you when you look towards the future of the company and, how do you not between moving OpenAI forward, continuously, propelling yourselves but then also also, you know, do you do you have Is there is there some system if we feel like we're creating something that's going we will step in, we will stop this. Do you have that ability Yeah. Of course. Like we and we've created systems that we've chosen Oh, interesting. and I'm sure we will again Or we've created a system we need much longer to make the safe Like with GPT four. It took us almost eight months before we were ready to release it, to do all of the alignment Right? Right. I remember and yeah, That's just the people in here and being committed to the mission. So that will continue on. and I one of the things about this team is, The ability to operate well in chaos, crisis, I give them like an A-plus on that. They did such a good job. And as we get closer very powerful systems, and the team we have built you know, to, like, keep your head cool in a crisis I think the team here really proved And that's super There were I saw this thing you know, the thing is that Sam can run the company And I think that's totally wrong. I think that's not at all I think what happened is the company can totally run And it's a it's a culture The culture is ready. Like I think that's I'm just super Really happy to be back and doing it. But but like I sleep better at night. Having watched the team manage through there will be bigger challenges But I think in some subjective sense, this is the hardest one and now we kind of like realize that the stakes and that we're not just in some, in we're just not a regular company. Oh, yeah. Far from it. Far from it. Let's, let's talk a little bit about that. ChatGPT OpenAI, you know, whatever it may end up calling it, you've got whisper, name ideas, name brand, I would love it. I feel like ChatGPT has just done it. You know, I feel like it is now. You. It is? Yeah, it's a horrible name, But a change, it's you can't change. You think you can change it I mean, could we drop it down to I don't know, I don't know, maybe sometimes I feel like a product grows beyond the marketer's dream. Yeah. Space. And people just have it. Yeah. No marketer no name for this, but we may be stuck Yeah. And it's now I mean, the just like, fascinate me. You know, I remember when you know, and it was just an idea and seeing how it worked that could create a picture but noise and, And they were going, but we didn't get the picture from There was no source But that's not possible, right? It saw something I was like, and it's so hard sometimes it's even hard to But but when we when we look living in, you know, GPT 3.5, GPT four, GPT three, you know, five, six, seven, I like to remove the technical term and talk more about, like, One thing we saw in a jump, was between chat GPT three, 3.5 to 4. We saw what we would call reasoning a little bit of like creativity Yes, yes, yes, exactly. And when I, when I look that you're creating now, you know, and now the specialized do you think that the use case is going to change Do you do you think that what might right now just be like a little chat like, do you think this will be or do you think it will become where everything becomes You know, a world that's trying to do things for him, that's doing things for them, like, Obviously, but where do you see it going I think it will be a mix of those. It's it is hard to predict Probably I'll be wrong here, I think it'll be a mix One, the base that I have a hard time with conviction, saying, here's So that's going to take a long time. But I think that's where What's Like what's like not in the next few years. Okay. it will get much better every year But like, I'm not sure I was gonna say I'm certain. I think it's, like, highly likely plenty of things that the model does But but doesn't You know, when I when I talk when I talk to anyone who's involved the number one thing people say People keep saying, there they go. We were surprised ChatGPT was learning about this field, and all of a sudden Or we we thought we were teaching it it knew how to build bridges So for what it's worth, that experience of maybe between like 2019 and 2022 or something like that. Okay. But now I think we have learned Now we trust the exponential, So GPT five or whatever we call We will be surprised and that it can't do. But no one will be surprised Like, at this point, I think we've really internalized the second thing you touched on, these custom GPT and more importantly, on, like the personal GPT, Yeah. And that, I think is going to be a giant thing where if you want, these models will get to know you, things in the way you want, work And I think a lot of people yeah. I mean, I can see It almost makes me wonder if, you know, the new work almost your resume, your GPT is almost more valuable Do you know what I mean? So yeah, it's like a combination and everything you thought. And the way you synthesize ideas combined And I mean, this is this is me. Just like thinking of a crazy future you literally get to a job And you say, well, here's mine. You know, we always think of these like agencies, I'm going to, like, But it'd be interesting with what you're saying is how other people interact Like this is your impression, I can see getting to that what are we culmination, it's a strange thought, I'm constantly fascinated by by where it could go You know why? When when ChatGPT In those first few weeks, How people quickly realized I know it's not robots, they're like, oh, The machine wasn't replacing the just it would, you know, people people Yeah, truck drivers, etc.. And yet we've come to find that, no, those jobs are actually harder And it's in fact unquote, like stinky jobs, you know, Oh, you're a lawyer. Oh, they might not need you know, ChatGPT five, six, seven, you know, you you're an engineer. You are like, where do you. The human body is really an amazing it really is. Do you see any advancements the human body or. We still in, like, mind, like, eventually. Like humanoid. Like robots. Yeah. To work eventually. but you know, and we worked on that We had a robotics program. we we made this thing that could do a Rubik's Cube with one I think there's like a bunch of different insights rolled into that. But one is that it's just much easier to make progress in the world of bits Like, the robot was hard It wasn't hard advance hard research problems. It was hard and that it wasn't that accurate. And the simulator was bad and whereas like a language model, it's just like You can make way faster progress. so like for focusing push on more productive problems in a very important way. I think. Solving the cognitive tasks is the more important problem. like if you make a robot, it can't necessarily help you make a system to do Yeah, but if you make a system it can help you figure out Oh yeah, that makes sense. And, and so I think, like, cognition was the core of the thing And I think But I hope we'll get back to robots. Do you do you have artificial general Like like how do we know personally. Like when I'll feel like mission. Yeah. Like what? What what? Because everyone talks about But then I go, So this comes back to that point where everyone's got I'll tell you personally when we have a system Okay. I'll be very thrilled. But that feels like That seems like It's beyond, I think what most people maybe because this is what I think of how do we define that Are we defining it as brilliance or are we defining it as like a child intelligent, for sure, You know, they just they come out, they don't know how to walk, And you're constantly programing this Yeah. To get to where it needs to go. So how will you like if you get to old child version of a system that you know, can just go autonomously Yeah. figure out the world in the way Oh, yeah, we can call that an AGI if we can. If we can really address that. Truly generalized ability to be confronted with a new problem Not perfectly. Four year old doesn't always But you know, Are we able to get there thinking and the mind seems like it will you think we can get it So I'm sure you know about this. One of my favorite stories I think it was actually a project but they had this. They had this, AI that was trying to learn how to discern Right. And it was It was like 99.9% accuracy. However, it kept failing with black people It kept on mischaracterizing them and the researchers kept working. And they were like, what is it? What is it? Was it at some point? And this is I mean, I tell the story I mean, but I found it funny at some point they, they sent the AI to Right. So they sent the AI to Africa. And then they told can you work with this for a while And then while the I was running with their data sets and more and more accurate But in the end of it, the difference between a male face All it had been drawing And so the I was going, people rosy cheeks and maybe blue And then the other ones are men. And because the researchers said, yes, you're correct, It just found like a quote unquote you know, Yeah, way beyond what I understand. But it just figured out a cheat code. It's like, oh, I understand what you And it gave it to them. And then they realized, because black women when it comes to makeup you know, But we didn't know that And so I wonder, how will we know that the AGI doesn't know Or will we know Like, how do we know? And what is the cost of us when it's intertwined You know, one of the things on is the ability to understand So right now, interpretability is like That's the field of, like, And there's different ways you can there's even levels you can try to understand what every Or you can like look at as you know, which of these And there will be even But but the ability to understand hopefully have them explain to us to certain conclusions I think we're going to make progress there before I think how these systems are capable of they do, and also how our own brains So I think we will eventually get I'm so curious. but it seems to me that we'll have more progress in doing what we know works better, and having them help us And also, they will just be fooled less often. So a more sophisticated system might not have made And they learned a deeper level. And I think we see evidence of stuff You know, there's two things you think of when you say not get fooled One is the safety side, We one of the first things You remember they were like, it thinks that And it thinks and people love using with with large language models, Yeah. Because I always think, they should be trying to understand but they've, they've done, a disservice in using the word think. Yeah, quite a lot. Like we need to use familiar terms But I agree with you Because if you're saying it thinks go, well, And it's like, no, you know, it's it's really just using to figure out where words most likely What do you think you're doing? Yeah, that's an interesting one. That's that's what. And now. So now is the ideas that we put together. We talk about hallucinating. Let me start with the first part. Do you think we can get to a place AI doesn't hallucinate? Well, I think the better version an AI that, that doesn't hallucinate at a similar rate And on that one I would say yes, But actually, like a big part of why is that they do novel things. And if it only ever. Yeah. Like hallucination Well that's what I was like, isn't hallucinating part Totally. If you think about the way. Let's like if we think about the way They look at a bunch of data. They got this idea and then they start thinking, well, maybe I should try this experiment. And now I got this data back Now I'll come up with this new idea, come up with new hypotheses, Yeah, that have never existed before but then have a process go figure out And that do make sense. that's like a key And how do we prevent the AI from, you know, like, that garbage in, garbage out output How do we right now, that humans have created It is learning from what with, with everything OpenAI's, the anthropic, the lambdas, It feels like we could get to a world more information and it may not be vetted How do we how do we then? Is is the AI going to get better in a way that it might not be vetted? Like, How do we figure that out? So it comes back to this issue how to behave in different contexts, like you want hallucinations but you don't want hallucinations accurate facts on a situation. And right now you have these systems these beautiful new images in some important sense, but then you have a system that Again, it's gotten much better, but and it's fine. I think it's good if these systems generated data, as long as there is a a process what data is good it's not enough Because if it's coming up those may start off as but you know what is good? What is bad, and then also that oversight of that process in control but with those constraints, I think to be future systems are going to be and then you reminded me I've been wondering, I don't know but I would like to know by, say, GPT 5 or 6 or whatever That feels like an important. Milestone, actually. Now what? I'm saying that out loud. Maybe it doesn't. Generate in what way? Oh, like where the model is producing more words So there's, you know, 8 and that does seem interesting. Speak You can figure out what that is. I mean, you yeah. What does it is the question on the other side. Yeah. That's why I was taking it back I if for some reason it feels like it feels like an important milestone kind of way because maybe humans are, writing the whole time. And that's where things I think it's I think it's worth like the yeah, the amount of I don't use the word thinking not to use Maybe just the amount of like words Yeah. I'm going to lose you soon. So I want to jump into a few, that I think if I don't ask all of you. okay, so one of the main ones, Personally, we always talk about They fed data sets That's The cost billions so that the computers can learn. How do we teach an AI to think that have given us the data So, for instance, how do you how does an AI learn that we've put out there? You know, when it comes to race, when it comes to the ideas, how do we teach it If we're feeding we don't know yet, but that's our big that's like one of our biggest is it's like, and I hope that a year from now, But I don't know yet. Okay. It's really important. However, This is going to be a force to combat injustice in the world I think these systems will be. They won't have the same deep flaws they will be able to be made far less sexist, far less bias. They will be a force I think, you know, if you make AI tutor or a great that helps the poorest more than the richest have to, even I don't have like an answer but I do at this point feel confident Of course, we have to do some hard societal work to make them great for sort of increasing justice Okay, maybe that that leads in perfectly to a second question, what are you doing? What is OpenAI doing? Are you are you even considering how much this new technology the haves and the have nots. Every new technology that's come out has been amazing for society But you can't deny if you have it, you've got it all, and if you don't, I think that art, we'll learn a lot But currently I think one really truly free service, which means no to more than 100 million people and the fact that it's not it's not fair to say anyone, we have still blocked but trying to get closer and closer We can do that really high quality, that is important to all of us and I think that there's other things with the technology, cure diseases with AI available to the world, But putting this tool in the hands and letting them use it that is super important. And, and I think we can push this much, much further. Okay, two more questions. Can I add one more thing that. Yeah, Go ahead. Yeah. The other thing that is who gets to make the and not say or do and not do, Yeah. And I like right now it is basically the people And no one would say that's like So figuring out of this technology, but how we how that's like a huge challenge Well, that's sort of goes to what the safety side of it all, you know, we spoke about this right When designing that always has to be that it can change the world You know, there's been an outsize ability Is it possible the first And then the second part of it is what is your nightmare scenario? What is the thing would make you press a red button Yeah. When you go, you know what this we have to shut down. And so the first one is can And the second part is The way I think about the insight that you started with, the number of people harm, goes down every decade That seems to me to be like a deeply have to confront. second, about making a system safe. I don't think of it Like we say, airplanes are safe, Very infrequently. Like amazingly infrequently. To me, we say that drugs are safe, you know will still that can cause some people Right. And and so safety is not like something is acceptably safe Right. And that I think we can get to but it doesn't mean things aren't I think things will go really What we have to prevent and and I think society Messy but good process for collectively determining what safety That is a complex negotiation as a society have gotten better but we have to prevent and I think what you were touching on is that the kind of catastrophic So nuclear is the example You know, nuclear war And so the world treated it and has done The last, almost 80 years. and I think there will be things with certainly one example is AI being used to design Yeah, that can cause a huge problem. I know I think computer security issues, an AI hack beyond what any human could do And then there's another category which is if the model gets can it can help design the own way exfiltrate and make a lot of copies More of like the sci fi scenario. but I think we do as a world need to stare that in the face. Maybe not that specific case, but or potentially even existential risk we can't precisely define it doesn't And so we're doing a lot of work here and measure when they might come, and I think all the people who say, you should just talk about that, you know, issues of misinformation they are wrong. We have to be safe Okay. That's terrifying as I as So. So then I go, oh, by the way, about running for governor? Was that a no, no, no, very briefly in like, 17, 2017. Okay. Or 16 even something I thought. So that seemed like a, you know, so like a couple of weeks, entertainment of an idea. Okay. Okay. I guess my final question for you you know, the what now, If Sam Altman could wave a magic wand exactly what you hope it will be, what will it do for the future? What what what all the upsides And I mean, this is like a Thank you for asking this. I think you should always look, I think we are heading into the greatest period of abundance and I think the two main drivers of But there are going to be others too. But those two things, the ability the ability to make it happen, where the limits to what people can like what they can imagine and what we can I think this is going to be amazing. We were talking earlier like, gets a better educational experience Like the richest student Yeah. What does it mean than the richest person with the best What does it mean freed up to work on whatever even if it means they have to be what does it mean if everybody can? You know, presumably you and I both, Yeah, but I don't think that's true Yeah, I agree, what does it mean if everybody gets and that they have, of a large company So, you know, maybe everybody gets 800 even smarter AI And people just get to create I think this is remarkable, and I think this is a world and it will require a lot of work in addition like society is going to have the fact that we are I'm very happy about it. I'll. I'll leave you with this I'm a huge fan, huge, huge You know, like, My my dream has always been to have to the best possible You know what I mean. Literally, because they can learn at their pace. By the way, what's happening to learn things. The stories Phenomenal. It really is. you know this like 14 year. Yeah. And I learned It really is. And especially as it becomes even more multimodal and all of that's I dream about that. To your point, health care I dream The one existential question and I hope you will, though, is of humankind? Once I has effectively supplanted you know, whether you throughout history, defined our progress. You know, there's a time And so, You should think about it. Religion was really great at getting people to think beyond themselves. And I wake up to serve God. Whichever God you were thinking of, I wake up to please God. I wake up and it makes humans, I think one it makes them something, and two, it gives them And and I feel like as we as this, the one thing I hope how many people have tied to what they do versus who they are. And once we once we take that away. When you don't have a cloak, when you don't have when you don't have an assistant, when you don't have You know, we've seen Oftentimes there's there's a mass backlash. Like, have you thought about that? Is there is there a way How would you describe it? Our purposes right now, it's survival in some way, shape or form, how we've been told survival You have to make money But we've seen the that has been redefined. France has a great example and I think they still have but the artists fund where they went You just make things, Yeah. And that was that was beautiful. I know you were a fan of UBI, We shouldn't go Well, I just should be tied to their, I think that's like a waste of human But, yeah, Why wait, It's like, why do you think universal Because you don't or your money on things So and you spend a lot of time I mean, the last I saw was like, there's like a $40 million project I, I don't think universal of course, to the challenges But I do think that, like, eliminating poverty is just I think will lead to a better society But but I don't think giving away Like giving away tools I think it's more important, want to be architects of the future. I think as much as I could say thread of meaning, I think it is like, you know, survive Yeah. Individual basis. But, but collectively collective desire Now we get off track lots of times. But but the human story is like And that that is technology. That's the way we treat each other. That's like going off that's understanding the way And I have so much confidence No matter what tools we get, that to thrive as a species that's not going to go anywhere. So I'm super optimistic about what two generations from now. But what you got at is really you know, already in their careers and don't want change. One thing we've seen with previous is in about two generations, and people can adapt Right? But not in ten years, Right. I think to some degree, as we said than people think, but still faster than society what that's going to mean and I'm definitely a little afraid of we're going to have to confront it, I'm confident we'll figure it out. And I'm also confident that, like you better tools than we had, that absolutely astonish us. And I hope they feel like horrible Like, I hope the future is and desire to, like, go off and figure it out and express ourselves and better world I think that's wonderful. I'm really happy about that. And I think in some sense we shouldn't make too much of this, We and you know, where one of the bad guys is like, oh, I think it's Vader is like, with this technological terror It's like nothing Yes, I do feel that way about AI which is like we shouldn't be too impressed the human spirit will see us through Technological revolution. I mean, it's I hope you're right, The one, the one really choppy. No. You know, and the one thing as, times CEO of the year I think you'll continue to be that, because of how much impact open are going to have on us, one thing I would implore you feeling you had when you were fired, that's going to put many people because I see And I hope as you create, you'd You know, what I did went to like early Saturday morning I wrote down, what can I learn about this when other people go through and blame me, like I'm And have you figured it out? A lot of I mean, there's a lot of useful, I gained out of this whole experience relation of values, For sure, was a blessing in disguise. Like it was at a painful cost. But I'm happy to have Well, Sam, thank you for the time. Thank you. Really, really enjoyed it. I hope I hope we do chat in a year. about, that'll be That'll be awesome. I was definitely What now with Trevor Noah is produced by Spotify Studios in partnership Well 73 and Odyssey's The show is executive Jenna Weiss Berman, and Barry Finkel, and Marina Hankie. Music. Mixing and mastering by Hannah Brown. Thank you so much for taking the time Thank you for listening. I hope you enjoy the conversation. I hope we left you with something. Hopefully we'll see you again Same time, same place, Next Thursday,