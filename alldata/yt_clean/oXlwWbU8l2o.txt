Everyone and welcome to this Python and open about everything you need to know. To get to start off with the very basics that is media files with image transformations, and Then we're going to move on to the most advanced color spaces bitwise operators, masking, histograms, to sum things up, we'll be talking about face so how to detect and find faces in an image In the last video, we'll be building a deep the characters in The Simpsons based off some on my GitHub page, and all relevant links that sounds exciting, don't forget to head see you in the course. Hey, everybody, and Over the next couple of videos, we're going to perform all sorts of image and video related be delving into what open CV is really is. library that is available in Python, c++ and of deep learning that primarily focuses on images and video. Now, I'm going to assume your system. And a good way to check this dash dash version. Now make sure you're running whatever we do in this post wonderly work Python two, so just make sure that you have python.org and download the latest version we can proceed to installing the packages one is open C. So go ahead and do a pip install you may find people telling you to install team dash Python is basically the main package dash Python includes everything in the main provided by the community. So this is something of open CV functionality. You may also notice package. Now NumPy is kind of a scientific used in matrix an array manipulations, transformations, be using NumPy in some of the videos in this them before. It's simple and relatively easy I'd like you to install a sphere. So go ahead this is a package that I built to basically is basically a set of utility functions that vision journey. It has a ton of super useful workflow. Now, although we're not going to in fact, we'll only begin to use this in our a deep computer vision model. I recommend to worry about the installation process later this package, or just simply want to explore page in the description below. Okay, that's be talking about how to read images and video video. Hey everybody, and welcome back to to be talking about how to read images and in this photos folder, and a couple of videos this video, we'll be talking about how to end we'll be actually talking about how to a new file and call this reader dot p y. And input CV two as CV. So the way we read in cv.im read method. Now this method basically image as a matrix of pixels. Specifically, of a cat here. So we're going to say photos this image in a variable called IMG. Now you this photos folder is inside my current working relatively. Now once we've read in our image, the cv.rm show method. Now this method basically two parameters we need to pass into this method case is going to be kept and the actual matrix IMG. And before we actually move ahead, I wait key zero. Now the CV or wiki zero is waits for a specific delay, or time in milliseconds zero, it basically waits for an infinite amount I didn't worry too much about this, it's not we will be discussing some parts of it towards this and run by saying Python, read dot p Cool. Now this was a small image, this was to try and read in this image of the same 1600 image. So we're gonna say Cat on a school as you can see, this image goes way off screen. of this image were far greater than the dimensions on. Now currently, open CV does not have an far greater than your computer screen. There be discussing them in the next video when and images. But for now, just know that if it's possibly going to go off screen. So that's to reading videos in open CV. So that's called is we're actually going to read in this video by actually creating a capture variable and Now this method either takes an integer arguments Now you would provide an integer argument webcam or a camera that is connected to your be referenced by using the integer zero. But your computer, you could reference them by zero would reference your webcam, one would to your computer to would reference the second be actually looking at how to read an already we'll be reading this dog, this video for the path so videos, slash dog dot mp4. Now, different from reading images. In the case loop and read the video frame by frame. So thing we want to do inside this loop is say read. Now this capture dot read basically the frame and a Boolean that says whether Do you display this video we can actually by saying TV on show and we call this video way to stop the Do from playing indefinitely ff is equal to equal to Ord of D. There we once that's done, we can actually release windows. And we can get rid of this. So basically instance of this video capture clause. Inside frame. By utilizing the captured read method, the CV dot m show method. And finally, for we say if See, we don't wait ki 20 if and that if the letter D is pressed, then break And finally, we release the capture device need them anymore. So let's save that and like this. But once it's done, you will notice this error. More specifically a negative 215 an error like this negative 215 assertion is that open CV could not find a media file Now, the reason why it happened in the video CV could not find any more frames after the broke out of the while loop by itself by raising same error. If we comment this out, we uncomment image. So I see me Oh wait, wait key, zero, error. This basically again says that open at a particular location basically, it could that's pretty much it. For this video, we CV and how to read in videos using the video talking about how to rescale and resize images Hey, everyone, and welcome back. In this video, and rescale images and video frames in open files and images to prevent computational lot of information in it and displaying it computer needs to assign. So by resizing and of some of that information. rescaling video a particular height and width. Generally, change the width and height of your video dimensions. The reason for this is because not support going higher than its maximum in 720 P, chances are it's not going to be a video frame or an image, we can create a can pass in the frame to be resized and scale set as point seven five. So what I'm going to frame dot shape of one of one times scale. thing for the height. Now remember frame no frame or your image and frame note shape of Now since width and height are integers, I values to an integer by converting it to an we're going to create a variable called dimensions, height. And we can actually return CV don't pass in it interpolations of CV dot into on CV dot resize in an upcoming video. But for a particular dimension. So that's all a function that frame by a particular scalar value, which actually try to see this in action. Let's code. And we can paste there, we don't need I'm going to do is after I've read in the frame on this go resized, and set this equal the scale value is point seven, five. And by passing a frame on the scope resized. Resize. del p why that was an error. Okay, we don't Run. And this was our original video. And video resize by point seven 570 5%. We can to to maybe point two, so we rescaling to new window. So let's close that out. Now you that out, change that to cat dot jpg. And the resized image. And we can create a resize pass in the IMG. So let's see that in Rome. with that. This is actually the big image of this image. So let's close that out. Now video frames specifically. And that's actually is specifically for videos, and will work that. Let's call this depth change rez. So of the image of video. And we can pass in to do is we're going to say capture, don't the same thing with capture dot set four comma the properties of this capture class. So three height. You can also expand this to maybe think you can reference that by setting this in the width and the height. Now, I do want images, videos, and live video. Basically, method. But the changes function only works from an external camera or your webcam for this is not going to work on standalone video just doesn't work. So if you're trying to go with this function if you're trying to video, then go with this function. So that's about how to resize and rescale video frames we'll be talking about how to draw shapes, I'll see you guys in the next video. Hey, In this video, we're going to be talking about and create a new file and call this draw dot going to input the NumPy package that open to input that as MP, we will read in an image photos, photos slash cat dot jpg, we can display receive out of weight key zero. Now there drawing on standalone images like this image or a blank image to work with. And the way saying blank is equal to NP dot zeros of shape 98. You ID eight is basically an image the and see this image, see what this image looks like save that and run Python drawed or p you can draw on. So we're going to be using But feel free to use this cat image if you'd is try to paint is trying to paint the image by saying blank and reference all the pixels zero. So by painting the entire image green, in passing the blank image, save that and to give it a shape of three, basically, we the number of color channels. So just keep image that we get cool, we can even change 255. Save that. And we get a red image over of the image by basically giving it a range from 300 to 400. Save that and run and you we're going to do is we're going to draw a the CV don't rectangle method. This method which in this case is blank. And it takes type if you'd like. So the point one will the origin. And we can go all the way across zero comma 255 comma zero, which is green, is basically saying the thickness of the borders. image by saying let's call this rectangle can comment this out since we don't need this goes all the way from the origin to 250 comma so we can go from 250 to maybe 500. And it basically divide the image in half. Now there color. And the way we do this is instead of is equal to CV dot field. That basically fills Now Alternatively, you can also specify this the same result, what we can also do is, instead what we could do is we could say, IMG done two, and image dome shape of zero, divided image is not in fact, God, this is blank, a nice little rectangle, or square, if you is it scaled the rectangle from instead of basically has dimensions, half of that of and draw a circle. Draw circle. This is also And we pass in the blank image. And we give of the center for now let's set this to the 250. Alternatively, you could also get this it a color of zero comma, zero comma 255, of let's say three. We can display this image, a nice little circle over here, that has its Again, you can also fill in this image by we get a nice little dot here in the middle. And that is how to draw a line a standalone say draw a line, we use a cv.in line method. on and two points, that's just copy these draws a point from zero comma zero to half And then it draws a line of color zero comma 2255, d 5255. And it's green thickness you this image. See you don't on show colas line, that goes all across from zero comma, zero play around with this. And let's draw a line the way to 300 to 400, save that. And you've comma 400. Cool. And finally, the last thing to write text on an image that that's right is very straightforward. We see we do a CV blank image. We specify what we want to put origin, which is basically where do we want 225 and 225. And we can also specify font And we will be using the CV dot font unschool you have complex you have duplex you have inbuilt phones. But for now, let's use a triplex. how much do you want to scale the font by, a font, let's give it a color of zero comma two. Commit that out. And we can display this text and pass in the blank image. And we get play around with it and say, Hello, my name I when we're dealing with large images, but this except for maybe changing the margins let's say it's zero comma two to five. And is yes. So that's it. For this video, we talked rectangles, circles and how to write text be talking about basic functions in open CV, whatever project in computer vision you end in the next video. Hey, everyone, and welcome going to be talking about the most basic functions in whatever computer vision project you end function. And that is converting an image we've displayed that image in a new window. channel blue, green and red image. Now there those BGR images to grayscale so that you rather than the color itself. So the way we CBT color, we pass in the image that we want a color code. Now this kind of code is CV we're converting a BGR image to a grayscale image by saying CV don't show passing gray run your Python basic.pi. And this was the image. Let's try this with another image. in Boston save and maybe change that to Boston. this is its corresponding grayscale image. from a BGR image to a grayscale image. The to blur an image. Now blurring an image essentially image. For example, in an image, there may of bad lighting when the image was taken, and so on. And some of the ways we can actually blur. There are way too many blurring techniques of this goes. But for now we're just going to do is we're going to create a blurred image. And this image will take an associate image size, which is actually a two by two tuple CV uses to compute the blown the image. We'll scope so don't worry too much about this, an odd number. So So let's start a real simple And another thing that we have to specify ahead and try to display this image, the same to notice some of the differences in this is applied on it. Right this people in the And over here, they're slightly blurred. To increase the kernel size from three by three this is the image that is way more blurred next function we're going to discuss is how trying to find the edges that are present cascades that are available. But for this detector, which is pretty famous in the computer process that involves a lot of blurring and and stuff like that. So we're gonna say, Kenny, the image, we pass in to threshold values, Let's go ahead and try to display this image, Save that and run. And these were the edges see that it hardly any edges found in the the buildings. And quite a few, you know features some of these edges by essentially blurring of passing the IMG, we pass in the blur. See far less edges that were found in the image. the amount of edges that were found by a lot of the edges by applying a slight blur. Now how to dilate an image using a specific structuring we are going to use is actually these edges, gonna say dominating the image. And the way CV dot dilate. And this will take in the structuring And we'll take a kernel size, which we'll will also take n iterations of one. Now, dilation the time, but for now, we're just going to this image by saying CV dot m shope. Call that and run. And if these were, if these can maybe increase the kernel size to maybe does hold on. And nothing much was done. Not the number of iterations to maybe three. And see subtle differences with the amount of is a way of eroding this dilated image to not going to be perfect, but it will work roading and we call this eroded is equal to image, pass and dilated, it will take a kernel and given n iterations of one just for now. clothes eroded, eroded and if this was your image, this is basically the result you get same as a structural element. But you can you can see that between this and this, there of these edges, we can maybe try to match is an attempt to get back this edge cascade. can see that you compare these two, they look same. So essentially, if you follow the same same edge cascade. And probably the last function and crop an image. So we're going to start frames and images in the previous video in going to touch on the CBO resize function resized equal to CV dot resize, this will in a destination size, which let's set this in this image of the park, and resize that So we display this image by saying saved out run. And let's go back to this image. If this was resized to 500 by 500. Now by default, background, and that is CV dot into on the is useful if you are shrinking the image to original dimensions. But in some cases, if the image to a much larger dimensions, you or the inter on scope cubic. Now cubic is image that you get is of a much higher quality underscore linear. So let's touch on cropping. that images are arrays. And we can employ a portion of the image on the basis of your to the image. And we can select a region from display this image Cole is cropped, possibly go back here of this original image, you try be you. Yeah, it's basically this portion. we talked about the most basic functions in to grayscale by applying some blur by creating that dilated image by resizing an image and In the next video, we're going to be talking translation, rotation, resizing, flipping leave them in the comments below. Otherwise, everyone, and welcome back to this Python going to cover basic image transformations. likely apply to images, including translation, So let's start off with translation. Translation and y axis. So using translation, you can any combination of the above. So so to translate we're gonna call this def translate This translation and take an x and y, x and y basically stands along the x axis and the y axis respectively. a translation matrix. So we're going to call And this will take in a list with two lists to say, one comma zero comma x, and zero comma we can import NumPy, import NumPy as NP. And we can essentially get the dimensions of the of image don't shave off one, which is the the height. And we can return CV dot warp to trans MIT animal taking the dimensions. our image. And before we do that, I do want for x, you're essentially translating the implies shifting up positive x values implies positive y values shifted down. So let's create this equal to translate, we're going to pass shift the image right by 100 pixels, and down the show, translated and translate tip. Save p y. And this is your translated image, it to the right by 100 pixels. So let's change and down by 100 pixels. So we pass in negative free to play around with these values as you to the left, negative y shoves it up, x shifted down. Moving on, let's talk about rotation. an image by some angle. Open CV allows you you'd like to rotate the image around. Usually specify any arbitrary point it could be any 40 pixels down, and you can shift the image image, we can create a rotating function, an image angle to rotate around and a rotation going to set is not so we're going to grab by setting this equal to IMG dot shape of point is none, we are going to assume that going to say rot point is equal to width divided divided by two. And we can essentially create matrix. By setting this equal to rot met is going to pass in the center the rotation point and a scale value. Now we're not interested we can set this to 1.0. value we can set a the height and we can return the rotated image met the destination size which is dimensions. function. So we can create a rotated image rotate the original image by 45 degrees. So and pass and rotated. Save that in rock. And it was rotated counterclockwise by 45 degrees. clockwise, just specify negative values for rotated clockwise. Now you can also rotate rotated by 45 degrees further. So let's call rotate or rotate tid. And we can rotate this it clockwise. And we can see the.on show called rotated, rotated, whatever, rotate it. And reason why these black lines were included no part of the image in it, it's going to image and rotated it by 45 degrees, you essentially triangles. Now if you tried to rotate this trying to rotate these black triangles along of a skewed image. So there's additional triangles the trouble and basically add up these angles change that to 90 and retake the original the image that we were trying to go for, take rotate this 45 degrees image by further 45 those two angle values. So so far, we've covered rotation. Now we're going to explore how to from what we've discussed previously. But we can create a resized variable and set this image to resize and the destination signs is CV dot inter underscore area. You can maybe underscore cubic. Definitely a matter of preference the image. If you're shrinking the image, or stick with default. If you're enlarging underscore linear or the dansko cubic cubic with over high quality. Again, I think it's So we can display this image. I can resize we've got a resized image. Next up we have need to define a function for this, we just to CV dot flip. This will take in an image either be 01 or negative one. Zero basically is over the x axis one specifies that you the y axis and negative one basically implies as horizontally. So let's start off with zero flip in Parson boop, Save and Run. And this Let's try out a horizontal clip how we get a horizontal flip, we can bring these two images, then it was flipped horizontally. not that obvious, but bring them together We could also try to flip the image vertically as a flip code. And the image was flipped images, but reverse mirror images. And the cropping again, I'm just going to touch on and set this equal to IMG and perform some that and run. We didn't display the search. past and cropped, Save and Run. And this is can be brought together, cutting gram holders. we talked about translating an image, rotating image and cropping those images, we are basically There are of course, way mo transformation just to keep this go simple and beginner friendly, So that's it for this video. In the next video, countries in an image. So if you have any Otherwise, I'll see you guys in the next video. video. In this video, we're going to be talking Now contours are basically the boundaries continuous points along the boundary of an they're not the same as edges. For the most as edges. But from a mathematical point of things. contours are useful tools when you and recognition. So in this video, I sort and how to identify them in open CV. So the an image file, and I've displayed that image I want to do is convert this image to grayscale IMG CV dot color on this go BGR to great, we're on the same footing. I'm going to run a gray image over here. Now after this, I image using the canny edge detector. So I'm going to pass in the IMG and we're going to And we can display this image calling this run it I didn't save it, save it in ROM and image. Now, the way we find the contours of Now this method basically returns two things, this is equal to CV dot find Cantu's. This a mod in which to find the contents now this you want all the hierarchical contours, or external countries, or, or retter list if next method we pass in is actually the cone to set this to CV dot chain, unscrew approx down look at what this function does. So essentially, structuring element or the edges of a found which is essentially a Python list of all found in the image. And hierarchies, which But essentially, it refers to the hierarchical if you have a rectangle, and inside the rectangle, you have a circle. So this hierarchy is essentially these courtrooms. This even retinal list essentially returns and finds the cuantos. Read a list find in the image. We also have Reto external only the external conduits to all the ones tree returns all the hierarchical contours, system that is returned by record underscore to will list to return all the contours in approximation method. This is basically how approx none does nothing, it just returns use red chain approx symbol, which essentially in the simple ones that make most sense. So if you use chain approx none, you are essentially of the points of that line, chain approx simple line, compresses it into the two end points line is defined by only two end points, we in a nutshell is what this entire function can essentially find the number of cartoons list. So we can print print length of this we can say these many contused. Found. Okay, quantos in the image. And this is huge. This So let's do a couple of things. Let's try approx none, and see what that does. See how difference between those two, because I'm and sin there are a lot of edges and points So let's change the back to symbol. And actually, image before I find the edges. So let's do Blur can pass in the gray image. And we can of blur. So five by five. And maybe we can disko default. And we can if you want to, and pass an error we can find the edges on And as you can see this significant reduction just by blurring the image. So it went all times just by blurring the image with the is another way of finding the corner shoes detector, we can use another function in open to comment this out. And down here, what I'm is equal to CV don't threshold, this will threshold value of 125 and a maximum value For now, just know that threshold essentially image. So if a particular pixel is below 125, it's going to be set to zero or blank. If by five. That's all it does. And in the find in the thrush value. So let's save that. Let's Okay. threshold missing. Okay, I think I forgot type. So this is CV dot Thresh. On this go, Okay, let's run that. And there were 839 contours print ad to display this Thresh. Image, passing image you're using 125. close this out, using value, we got this thresholded image. And image, we got 839 concepts. Now don't worry we'll discuss this in the advanced section thresholding attempts to binarize an image, that is either zero or black, or white, or that you can actually visualize the contours drawing over the image. So what do we do real and after this, I'm going to create a blank of image dot shape of the first two values, are 28 we can display this image because blank a blank image to work with. Let's save that dimensions as our original accounts image. these contours on that blank image so that found. So the way we do that is by using the image to draw over fill blank, it takes in in this case is just the quantities list. how many countries do you want in the image. draw all of them, we can specify a negative So let's set this to red zero comma zero comma two. And we can display the blank image. So pass in blank. Save that and run. Okay, there Okay, so these were the cartoons that would threshold value thresholded image, it's not to do is instead it found the edges of this to draw it out on this blank image. Let's one so that we have a crisper view Okay, so in the image. And in fact, if you try to visualize with Kenny uncomment. That out, run. blows be an image. Okay, let's look at Kenny, let's And that makes sense, because our firing coaches and finding the controls. But we can do that. let's use Kenny. So we can pass in Kenny here. much the same thing, right? It's basically you can get away with thinking of contours but you can think of them as edges. Because of like the edges of the image. Right? The the points along the boundary, those are basically uncomment that out. Let's see what that does. we didn't pass in blood. Okay, 380 countries So generally, what I recommend is that you find the corn who's using that, rather than contours on that. Because like we will discuss The simple thresholding has its disadvantages. one value, dread binarize the image using most ideal, but in some cases, in most cases, it's the simplest, and it does the job pretty we talked about how to identify quantities to find the edge cascades of the image using quantities using that and also trying to binarize finding the contours on that. So if you have below. I'll be sure to check them out. Otherwise, Hey, everyone, and welcome back to another of this course, where we are going to discuss we're going to be doing in this video is actually in urgency. Our color spaces, basically a an array of pixel colors. RGB is a kind of other color spaces like HSV, lamb, and many this image to grayscale. So we're going to is default way of reading and images. And So the way we do that is by saying gray is image and we specify a color code, which is we're converting from a BGR image format to image I st gray and passing in grip. Let's had a problem as a comma, Save and Run. And image. Cool pretty cool. grayscale images intensities at particular locations of your this image to an HSV format. So from Jeff value and is kind of based on how humans think that is by saying HSV is equal to CV dot CBT specify a color code, which is CV dot color, syringe called as HSV and pass in HSV. Let's this BGR image. As you can see that there are reddish. Now we also have another kind be color space. So we're going to convert as L times A times B, but but v free to use CVT color, we pass the MG and the color on colas lamb pass and lamb is wrong that and This kind of looks like a washed down version format is more tuned to how humans perceive I mentioned that open CV reads in images in And that's not the current system that we Outside of open CV, we use the RGB format, format. Now if you try to display this IMG CV, you're probably going to see an inversion Let's try to input mat plot lib dot pie plot commented that out. And we can try and display dot, I am show pass in the image. And we could maybe let's comment this out, save that and you compare with the image that open CV read, completely different images. And the reason and open CV displays BGR images. But now if display it in matplotlib, for instance, matplotlib and displays that image as if it were an RGB of color. So where there's red over here, you see a red, and there are ways to convert open CV itself. So let's comment that out. over here, let's say BGR to RGB. And what CV dot CVT color, we can pass in the BGR image we're going to do is specify a color code, to RGB. And we can try to display this image And we can also display this in matplotlib. dot show, save that and go here it is you in is this. And this. Now again, you see an CV because now you provided open CV and RGB And that's why there's an inversion of colors. and matplotlib is default is RGB. So that's keep this in mind when you're working with matplotlib for instance, because do keep in take place between these two libraries. So essentially converted the BGR to grayscale, RGB BGR to RGB, what we can do is we can do image to BGR, we can convert an HSV to BGR, GL, and so on. But here's one of the downsides. directly. If you wanted to do that, what do BGR. And then from video to HSV. So we're HSV, two BGR. Okay, so the first thing we from HSV to BGR is equal to CV dot CVT color, code will be color on Cisco HSV, two BGR. this HSV, two BGR and pass in HD on the scope we're not interested in this. So let's close two BGR image. If this was the HV image, we this with lamb. So let's call this lamb to this and paste that. We can get rid of Mapplethorpe's and run. Okay, that was a mistake. We said Cool. So if this was the lamb version, this lamb and from lamb to BGR. So that's pretty to convert, we discussed how to convert between and RGB. And if you want to convert from grayscale direct method, what you could do is convert and maybe that's possible. By directly. I open CV could come up with the feature like hurt you to write extra lines of code, at hard. In the next video, we will be talking in open CV. If you have any questions, leave see you guys in the next video. Everyone and we're going to be talking about how to split a color image basically consists of multiple you see around you all the BGR or the RGB merged together. Now open CV allows you to So you can take a BGR image and split it into what we're going to be doing in this video, park that we had seen in previous videos, color channels. So the way we do that is by the respective color channels, and set this So the CV dot split basically split the image this image by saying CV dot I'm sure, let's do the same for green image and pass in G are and we can actually visualize the shape print the image node shape, and then print shape and then print the our dot shape. Basically, the image and the blue, green and red and run Python split merge dot p Why. And these the blues, the blue image, this is the green are depicted and displayed as grayscale images regions where it's lighter showed that there values and regions where it's darker, represented So take a look at the blue pick the blue channel the original image, you will see that the shows you that there is a high concentration the trees or the grass, let's take a look of pixel intensities between the between the And take a look at the red color channel. are red are whiter and the grass in the sky means that there is not much red color in a look at the shapes of the image. Now this the additional elements in the tuple here represents three color channels blue, green, shapes of BG and our components, we don't shape of that component is one. It's not mentioned to display this image using see even if I'm because grayscale images have a shape of one. together. So the way we do that is by seeing dot merge. And what we do is we pass in a save that in let's display that things either image. And we can pass in merged. So let's image by basically merging the three individual is a way an additional way of looking at the instead of showing you grayscale images, it the blue image, you get the blue color channel for that channel. And the way we do that is The shapes of these images are basically grayscale create a blank image, a blank image using do is we're going to say blank is equal to to the shape of the image, but only the first of you iemt, eight, eight, which basically channel, what we're going to do is we're going is equal to CV dot image, we're going to pass And we're going to do the same thing for green comma g comma blank. And we're going to do to CV dot merge of blank comma blink, comma, blank image basically consists of the height channels in the image. So by essentially merging so blue, green and red, we are setting the only displaying the blue channel. And we're the blue and the red components to black. blue and the green components to black. And and red. Let's save that and run and now you channels. Take a look at this, you now be Here you can see lineup later portions represent represent the high distribution of red and distribution of green. So essentially, if towns and merging them together, you essentially image. So that's pretty much it. For this three respective color channels, how to reconstruct in that channel, and how to merge those color the next video, we'll be talking about how blurring techniques. If you have any questions, I'll see you guys in the next video. Hey, In this video, we're gonna address the concepts before I mentioned that we generally smooth and noise that's caused from camera sensors image was taken. And we can essentially smooth by applying some blurring method. Now Previously, is kind of one of the most popular methods see that Gaussian Blur won't really suit some many blurring techniques that we have. And video. Now, before we actually do that, I let's actually go to an image and discuss blur. So essentially, the first thing that or window. And that is essentially this window here. Let's draw another line. So this is specific portion of an image. And something change it to blue. Yeah. So essentially, this size. Now kernel size is basically the number here, we have three columns and three rows. Now, essentially, what happens here is that So essentially, blur is applied to the middle also called the surrounding pixels. Let's happens here as a result of the pixels around let's go back and discuss the first method averaging is we define a kernel window over will essentially compute the pixel intensity the average of the surrounding pixel intensities. intensity was one, this was maybe two, this the new pixel intensity for this region will intensity. So that's summing up one plus two seven plus eight, and dividing that by eight, pixels. And we essentially use that result or the true center. And this process happens slides to the right. And once that's done, all the pixels in the image. So let's try going to do is we're going to say average, method is a method in which we can apply averaging is IMG, we give it a kernel size of let's display this image called as average, average p y net Gosh, we have to pass an average, average blow that's applied. So what the algorithm a candle window of a specified size three for a pixel using the average of all the surrounding is we get a blurred image. So the higher kernel going to be in the image. So let's increase And we get an image with way more blur. So the Gaussian Blur. So Gaussian basically does of computing the average of all of this running a particular weight. And essentially, the you the value for the true center. Now using than compared to the averaging method. But to averaging. So let's print that out. Let's Gaussian Blur. And this will take in the source just to compare with the averaging. And another x, or basically the standard deviation in to set as zero. And we can put that out, call that and run. If you can bear with this, you but this is less blurred as compared to the because a certain weight value was added when to the next method. And that is median blur. blurring is basically the same thing as averaging, of the surrounding pixels, it finds the median blurring tends to be more effective in reducing and even Gaussian Blur. And it's pretty good may exist in the image. In general, people vision projects that tend to depend on the So let's go back here. And the way we apply and set the Z and set this equal to CV dot and this kernel size will not be a tuple of to three. And the reason for this is because size will be a three by three, just based Let's call this median, blue, and pass in I set that to seven. And comparing it with to look at this. And you can make up some like as if this was your painting, and it and smudge over the image and you get something is not meant for high Colonel sizes like seven effective in reducing some of the noise in to three by three. Let's copy that, change that to three. And now let's have a comparison This is your average in blue, this is your can see that there is kind of less blurring the differences between the two Very subtle, the two. Finally, the last method we're going natural lateral. Now bilateral bearing is a lot of advanced computer vision projects, blurring methods basically blur the image you're reducing edges in the image or not. the edges in the image. So you have a blurred well. So let's call this bilateral and multilateral And we pass in the image, we give it a diameter isn't a kernel size, but in fact, a diameter. a sigma color, which is basically the color color sigma means that there are more colors when the blue is computed. So let's set this your space sigma. larger values of this space, central pixel will influence the blurring take a look at that sigma spacing. So for the value for this central pixel, or the true values for the Sigma space, you essentially from this far away, or maybe this far away, particular calculation. So if you give like in this region might influence the computation 15. For now, and let's display this image. and pass on bilateral. Let's save that and let's compare with all the previous ones that with averaging way much better. Let's compare slightly blurred. If you compare with the thing. Okay, it kind of looks like there's diameter to I know 10. And not much was done, like the original image itself. So let's try this to 3435. Let's set this dude 25. We're values. And now you can basically make our like median blow. We need even larger values. looking like a smudged painting version of here, but the council looking smudged. So trying to apply blurring the image, especially higher values of this basic mouth or bilateral you tend to end up with a washed up smudged that in mind. But that kind of summarizes averaging, Gaussian, median and bilateral about bitwise operators in open CV. So again, them in the comments below. Otherwise, I'll and welcome back to another video. In this operators in urban CV. Now, there are four If you've ever taken an introductory CS course, bitwise operators, and they are in fact used we're working with masks like we'll do in operators operate in a binary manner. So a and is turned on if it has a value of one. NumPy as NP. And what I'm going to do is I'm equal to NP dot zeros of size 400 by 400. it is what I'm going to do is I'm going to a rectangle and draw a circle. So I'm going we can say blink dot copy. And we can pass margin of around 30 pixels on either side. And we can go all the way across to 370370. not a color image, but rather binary image, White, and give it a thickness of negative then I'm going to create another circle variable going to say blank, don't copy, we are going the absolute center, so 200 by 200. And let's And give it a color up to five, five, and So let's display this image and see what we've this rectangle and passing the rectangle. the circle, it's called a circle. And pass r p y. So we have two images that we're going this image of a circle. So let's start off that is bitwise. And so before we actually show you what it does. So essentially, what go and is equal to CV dot bitwise. And, and source images that are these two images, rectangle, let's call this beautiful lines, and let's you get back this image. So essentially, what placed them on top of each other, and basically can make out when you take this image, put that are common to both of these images. And common regions are returned. So the next one simply returns both the intersecting as well try this bitwise OR is equal to CB dot bitwise in circle. Now we can print that, let's call was or save that and run and bitwise OR, okay, OR basically return this funky looking this is it took these two images, put them over found regions that are not common to both them. So, basically, you can just put them this is what you get, but this image over one is bitwise XOR, which basically is good So this found the the intersecting oops, the back, the no one intersecting in interest intersecting regions. So let's do that I say underscore xR, we pass in the rectangle, passing we can display this CV and I'm sure close Save that and run. And here we have the non you put them over each other. Pretty cool. returns the intersection regions bitwise, well as the intersecting regions bitwise XOR, if you take this bitwise XOR, and subtract conversely, if you subtract bitwise, and from essentially, that's a good way of visualizing And finally, the last method we can discuss anything. What it does is it inverts the binary bitwise. Not is equal to CV dot bitwise. underscore So let's set this to the rectangle put out. tangle not, we can pass in bitwise not see look at this image, it found all the white and inverted them to black and all the black it converted the white to black and from the with the circle. Let's call this circle, we and the resultant the resulting circle, not This is a black hole for physicists out there. I just wanted to introduce you all to the In the next video, we'll be actually talking in a concept called masking. So if you have below. Otherwise, I'll see you guys in the In this video, we're going to be talking about we discussed bitwise operations. And using perform masking in open CV masking essentially image that we'd like to focus on. So for example, if you're interested in focusing on the faces masking and essentially mask over the people's the image. So that's basically our high level how this works in open CV. So I basically other thing I'm going to do is I'm going to do is I'm going to say blank is equal to NP with the first two values. Now this is extremely to be the same size as that of the image. give it a data type of UI eight, you can see this. It's just going to be a black image, what I'm going to do is I'm going to draw my mask. So I'm going to say mask is equal blank image on the blank image, we can give dot shape of Have one divided by two divided a shape of zero divided by divided by two. I'd say 100 pixels, give it a color of 255, can visualize a mask as mask and passing mask. And this is essentially our mask. There's is the image that we want to mask over. So going to say masked image is equal to CV dot So IMG, IMG, and we specify the parameter image over here. And we can display this image, masked, save that and run. And this is essentially took this image, you put this image over and passing the mask is equal to mask. That's And, you know, play around with this, let's let's say 45. Save and Run moves down to zero, running. And we get the image of the cat, draw a rectangle instead. What's bottom blank, it a static endpoint of let's copy this and this way, in 100 pixels. This way, we can that, right? This is this, this is the square. So let's actually try this with. So let's So we have got an image. Let's try it with to save that run. And this is the mask that And essentially, you can play around with shapes, weird shapes. And the way you can a circle or rectangle and applying bid wise can use that weird shape as your mask. So Oh, we're going to say let's, let's call this a rectangle. Let's just grab it from this this rectangle copy that piece over time the create this weird weird shape is equal to this rectangle and we don't need to specify let's close this out try to see see it on the weird shape and wrong. masking undefined the weird shape that we get. We're not really close this out. Use this weird shape is mask. the final mask image and this is essentially call this a weird shape mask image, weird And essentially you can, you can do pretty experiment with various shapes and sizes and of your mask has to be at the same dimensions why not maybe subtract 100 pixels possible, like subtract tubal on it. I don't know whether just say, image on shape of while I'm okay, are we? Why are we even using image, let's the size of this. And we get this assertion same size, in function, whatever. So essentially, it's going to fail and throw you an error. masking, again, nothing to do different. We've from the previous video, and you will see in the next video, where masking really comes your histograms. So if you have any questions I'll see you in the next video. Hey, everyone, video, we're going to be talking about computing allow you to visualize the distribution of it's a color image, or whether it's a grayscale distributions with the help of a histogram, will give you a high level intuition of the compute a histogram for grayscale images and gonna start off with computing histograms this image to grayscale is activity don't code of of color underscore BGR. To gray, Great. Now to actually compute the grayscale call this gray underscore hist and set this essentially compute the histogram for the is a list, so we need to pass in a list of computing a histogram for one image, let's thing we have to pass in is the number of of the channel we want to compute a histogram for a grayscale image, let's wrap this as have to do is provide a mask do we want to of an image, we will get to this later. But basically the number of bins that we want when we plot a histogram, I'll talk about now, just set this to 256 wrapped as a list. thing I want to do is specify the range of for our case, this will be 02256. And that's use matplotlib. So import map plot matplotlib.pi PLT dot figure, a PLC figure. Let's give it We can essentially give it a label across Let's give this a y label and set this equal And that's why label. And finally, we can histogram. And Valley, we can essentially dot x Lim have a list of 02256. And finally, save that and run Python histogram, dot p in this image. As you can see, the number the the intervals of pixel intensities. So region, this means that this is close to 5060 are close to 4000 pixels that have an intensity of, there's a lot of peeking in this region, of pixel intensities of close to 3000 pixel with a different image. Let's try this with And there is a peaking of pixel values in most of the image is white. So given that will be a peak into words white or 255. Five. histogram for the entire image, what we can then compute the histogram only on that particular Let's grab this, grab this. Let's go right the first two values the sizes of the same. be CV dot circle of all blank. And we can by by divided by two, image doing shape of of 100 pixels, give it a color of 245 give a mask let's call this let's call as mask We can get the grayscale histogram for this this mask parameter to mask two instead of that does to our histogram MPs and undefined a mistake here. Oh, that's right. This is This is a this will be a circle circle. And so we so the way we do that is by creating bitwise unscored, and we can pass in the grayscale in the mask which is equal to circle. Now that x Sorry, I made a mistake, but hopefully the mask and this is the histogram computed there is a peaking of pixel intensity values in in these regions down below. Let's try cats cats to the cats though jpg. This is in this image towards 50. Okay, so that was move on to true To compute a color histogram, image to an RGB image. So let's call this instead of converting this image to grayscale, a mask later. That's come in all of this out. that's pretty much it. So let's start with let's define a tuple of colors, and set this of R. And what I'm going to do next is I'm of colors. What I'm going to do is I'm going by saying CV dot calc hist, we're going to will be I mean, this eye over here, we're it a his size of 256 and give it a ranges hist and give it a color equal to call. And And for this purpose, we can essentially grab can do a PLT dot show. So this should work. of him. We're not, we're not computing this But let's save that run. Oh, cool. And let's color histogram shouldn't make much of a difference. for the original image not for a mask. But this color image basically computed the plot green channel as well. So using this, you of blue pixels that have a pixel intensities around 50, peaking of green, probably around make up the distribution of pixel intensities and apply a mask by setting this equal to in order. It's a bit more than mass mass, size, okay, I finally got the error. So basically, of passing in this mask, this will actually fat mask, and we can change the circle to And we can change that to masked. Yeah, that's for this particular mask, I made a mistake histogram for one channel. The problem was and I attempted to use this s3 channeled mask isn't allowed in open CV. So that was my mistake. so confused, but essentially, this is it, section of this image. And this is what you area, high peaking of blue in this era, and that's it for this video. histograms actually intensities, whether for a grayscale image helpful in a lot of advanced computer vision the image that you get, and maybe try to equalize values here and there. In the next video, an image and the different types of thresholding. them in the comments below. Otherwise, I'll and welcome back to another video. In this in open CV. Now, thresholding is a binary to take an image and convert it to a binary zero or black, or 255, or white. Now, a very take an image and take some particular value value. And compare each pixel of the image intensity is less than the threshold value, and if it is above this threshold value, we we can essentially create a binary image just video, we're actually going to talk about thresholding and adaptive thresholding. So So in essence, what I want to do is, before to convert this BGR image to grayscale. So color, we pass in the image, we pass in the display this image called this gray, we can the simple thresholding. So essentially to we essentially use the CV dot threshold function. Thresh, which is equal to CV dot threshold. image, the grayscale image has to be passed we do is we pass in a threshold value. So to specify something called a maximum value. greater than 150, what do you want to set image. So we set it to 245. And finally, we thresholding type is essentially CV dot thrush it looks at the image compares each pixel above this value, it sets it to 255. Otherwise, it to zero. So essentially returns two things binarized image and threshold, which is essentially threshold value you pass in, will be returned display this image. So let's say cv.rm show, simple thresh hold dead, and we can pass in thrash. Da p y in this is a thresholded image from when we discussed thresholding in the essentially what you get. So let's play around to 100. And let's see what that does. And become white. So and of course, if you give will be white. So let's set this to 225. And actually have a pixel intensity of greater essentially create an inverse thresholded copy this and instead of saying Thresh, I'm I'm going to leave everything else the same. here, and instead of passing in the type of underscore binary under scope inverse. And can pass in inverse. So let's save that and this image, instead of setting pixel intensities whatever values that are less than 150, to all the black parts of this image will change will change to black. Cool. So that's a simple data thresholds. Now, as you can imagine, different threshold values. Now, kind of one manually specify a specific threshold value. cases, this will not work. So one of the things computer find the optimal threshold value it binary rises over the image. So that's So let's set up a variable called adaptive CV dot adaptive threshold. And inside I want to gray, I'm going to pass in a maximum value, value. adaption method basically tells machine threshold value. So for now, we're just going of pixels. So let's set this to CV dot adaptive C. Next, we'll set up a threshold type. This again, I think do different from this from that I want to specify is the block size, of the kernel size, which open CV needs to optimal threshold value. So for now, let's we have to specify is the c value. Now this subtracted from the mean, allowing us to essentially too much about this, you can set this to zero. finally, once that's done, we can go ahead this adaptive thresholding. And we can pass And this is essentially your adaptive thresholding we've defined a kernel size or window that is 11 by 11. And so what open CV does is it pixels, and finds the optimal threshold value over to the right, and it slides, it does the same thing so that it essentially slides adaptive thresholding works. If you wanted a threshold, just go binary and scope inverse, under the hood. Cool. So all the white parts black parts of the image have changed white. set this to probably 13 and see what that the previous hyper parameter. So let's try let's set this to maybe one. Okay, definitely a row that you can play around with these the mean, the more accurate it is, right, this basket. So let's maybe increase that image. But essentially, now you can make the adaptive thresholding, adaptive thresholding value on the basis of the mean? Now we don't something else. So instead of mean, let's see what that does. And this is the thresholded difference that Gaussian applied was essentially the mean across those pixels. So that's why we use the mean. But essentially, the adaptive Gaussian works in other cases, there's no with these values, see what you get. But that's video, we talked about two different types thresholding. In simple thresholding, we have in adaptive thresholding, open CV does that size and other computing the threshold of basis of the Gaussian distribution. So in section of this goes, we're going to be discussing So if you have any questions, leave them in them out. Otherwise, I'll see you guys in and welcome back to another video. In this and edge detection in urban CV. Now, you could that are present in an image. Now, they're completely different things from a mathematical away with thinking of gradients as edges from in the previous videos, we've discussed the kind of an advanced edge detection algorithm. But in this video, we're going to be talking image. And that is the lat placing and the left place here. So the first thing I want recalling the CVT. DVD to color color method, on describe BGR to grip, we can display this every pass. Great. So let's start with the called lap and set this equal to CV dot lap is it will take in a source image, which is a D depth or data depth. Now for now when whatever I do next, I'm going to say lap is to pass an NP dot absolute. And we can pass go ahead and import NumPy as NP and when I method is called this lamp lesion. And we Python good radians dot p y invalid syntax that. And this is essentially the law placing that is drawn over a chalkboard and then smudge method. Let's try this with another image. Let's call this the park. Save that in right. off this image. It's all the edges that exists in the image are essentially drawn over with that's essentially the left lacing edges you about why we converted this to in the UI and the Laplacian method computes the gradients this involves a lot of mathematics but Essentially, white to black, that's considered a positive have negative pixel values. So what we do of that image. So all the pixel values of And then we convert that to a UI 28 to an the crux of what's going on right over here. is the subtle gradient magnitude representation. Sobel computes the gradients in two directions, which is the gradients that are computed along And we can pass in the image, let's add this depth, which is cv.cv on school 64 F. And this to one and the y direction, we can set and call it soble. Why, and instead of one, visualize this let's print. Let's call this can say it's either long show Sabo y and set the gradients that are computed, this is over specific gradients and the sub x was computed gradients. Now we can essentially get the these two Sobel x and Sobel why, and the way combined underscore sobald and set this equal pass in Sabo x and symbol y. And we can display we get to combined Sobel and we can pass in is essentially the combined sobble that you took these two apply and CV dot bitwise OR, want to compare this with lat race in two you get will be completely different. Okay, and the Sobel with the canny edge detector. equal to CV, don't, Kenny. And we can pass image. Let's give it to threshold values of this image. Let's call this Kenny, we can see what that gives us. So let's compare that the last place in gradient representation, shading version of the image of the edges gradients in the X in the y direction. And and Kenny is basically a more advanced algorithm Like I mentioned, Kenny is a multi stage process, method to compute the gradients of the image. detector is a more cleaner version of the why in most cases, you're going to see the probably going to see a Sobel use a lot. Not So that's pretty much it for this video. And section of this course. Moving on to the next and face recognition in urban see, we're actually some face detection, and face recognition, with open CV is built in face recognizer. our own deep learning model to essentially always, if you have any questions, leave them you guys in the next section. Hey, everyone, now with the last part of this Python and about face detection and face recognition in this video is actually discussing how to a har cascade. In the next video, we will CV is built in face recognizer. And after learning model to recognize during the simpson scratch and use open CV for all the pre processing So let's get into this video. Now, face detection merely detects the presence of a face in an whose face it is. Now, we'll talk more about face detection is performed using classifiers. decides whether a given image is positive not. Now classify needs to be trained on 1000s faces. But fortunately for us, open CV already that we can use in any program. So essentially, are har cascades, and mo advanced classifiers to talk about local binary patterns at all how cascade classifiers, they're not as prone cascades. So I'm currently at the open CVS there are cascade classifiers. And as you that open CV makes available to the general fragile cat face, from face default, full Russian plate number, I think that's the same for detection of the upper body, and things want. But in this video, we're going to be going to use the har cascade underscore frontal go ahead and open that, you're going to get this. So what do you have to do is essentially, this raw XML code, all you have to do is click click Ctrl C, or Command C, and then go to file. And we're going to call this har unscrew in those 33,000 lines of XML code. Go ahead So we can go ahead and close this out. So classifier to essentially detect faces that face detect, face underscore detected py, image of Lady a person, that is this image this. So let's run Python face to face on in a new window. Cool. So let's actually implement convert this image to grayscale. Now face colors that are present in the image. These in an image and using the edges tries to determine need color in our image. And we can go ahead color, passing the image in CV dot color on this gray of color is gray person, we can And we have to pass in the gray. Okay, we move on to essentially reading in this har do that is by essentially create a har cascade cascade. And we're going to set this equal I essentially want to do is, is parsing the as simple as saying har en disco face dot essentially read in those 33,000 lines of har underscore cascade. So now that we've try to detect the face in this image over say faces on school rect is equal to har underscore we're going to pass in the image that we want going to pass in a scale factor. Now let's minimum neighbors, which essentially is a rectangle should have to be called a face. it. That's all we have to do. And essentially, an instance of the cascade classifier class variables called scale factor and minimum essentially the rectangular coordinates of rec. That's exactly why we are giving it faces essentially print the number of faces that the length of these faces on the score rect number, number of faces found is equal to, rect. So let's save that and run. And as you found one, and that's true, because there's the fact that this faces on school rec is the faces that are present in the image, what this list and essentially grab the coordinates the detected faces. So let's do that. So the comma w comma H, H in faces underscore rect, a rectangle CV to a rectangle over the original one is essentially x comma y. And point two give it a color. Let's set this to green. of two. And that's it. And we can print this this to detected basis. And we can pass in essentially see the rectangle that was drawn face that open CV is hard cascades found in image. So what I have here are a couple of of five people, so we're going to use that hard cascades could detect in this image. that to a group of five people. Save that to point real quick that the number of faces know that there are five people in this image. was face. So we can go real quick. So actually the five people, but it also detected two Now this is to be expected because her cascades So if you have something that pretty much a face, it has the same structure as the typical was recognized as face. But again, this is the sensitivity to noise is essentially modifying let's increase the minimum neighbors to maybe can see, now six faces were found. So I guess we essentially stopped open open CV from detecting another more complex image, a couple of people one, save rock. Now, as you can see that the And we know that this is not six. So let's just a bit. Let's change this first to three got 14. Okay, some people at the back want perpendicular to the camera, or they're wearing eyeglasses. This dude's wearing a hat, this actually change this to one. And let's see we got 19 faces that were found in this image. by changing these values. by tweaking these result. But of course by by minimizing these small cascades more prone to noise. That's hard cascades are not the most effective in not the most advanced, they are probably not advanced computer vision projects. I think effective and less sensitive to noise than use case hard cascades are most more popular. setup. And if you wanted to extend this to detect hot cascades on each individual frame it's pretty self explanatory. So that's pretty to detect faces in open CV using open CV as talk about how to recognize faces in open So like always, if you have any questions, the comments below. Otherwise, I'll see you back to another video. In this video, we will in open CV using open CV is built in face dealt with detecting faces in open CV using how to recognize faces in an image. So what people. Inside each folder, I have about 20 has 21 images. Anson has 17 Mindy kailyn has essentially going to do is we're going to we're going to train that right now. So on now this is sort of like building a mini sized, going to build any model from scratch, we're or we're going to do is we're actually going going to train that recognizer on these 90 going to call this faces ns, go train dog to input CV to our CV, and we're going to to do is essentially create a list of all the names of the folders of these particular type those in, or you could essentially create loop over every folder in this folder, and say P dot append, I, or we can print P. Let's on skirt trained on p y. And we get the same way of doing it. And what I'm going to do variable called dir, and set this equal to has, which contains these five folders of we can do is we can essentially create a function essentially loop over every folder in this going to loop over every image and essentially add that to our training set. So our training is called features, which are essentially to an empty list. And the second list will face in this features list, what is its corresponding one image could belong to Ben Affleck, the so on. So let's create a function. So we're person in this people list, we're going to folder in this base folder, going through folder. So that's essentially as simple as we can, we can join the der with person. And labels label variable, and set this equal way inside each folder, we're going to loop going to say for image to image in our stock the image Park. So we're going to say image, join. We're going to say join, we're going that we have the path to an image, we're going going to create a variable called IMG underscore scope path. We're going to convert this image IMG. On scope right here we can pass in t grip. Cool and now now with that done we can this image. So let's go back to face underscore variable here. Let's paste that there. And and set this equal to har underscore cascade gray image scale factor of 1.1 and add a minimum every face in this face rect. So for for x we are going to grab the bases region of interest, the face in the image. So we're going to say now that we have a faces a face region of list. And we can append the corresponding do features dot append, we're going to pass dot append label. This label variable is essentially converting a label to numerical values is computer will have, by creating some sort label. Now the mapping of we are going to list. So let's say that I grab the first image, for that would be zero, because Ben Affleck Similarly, elton john, an image of elton john the second position or the first index in the idea behind this. Now, with that done, see whether we got any errors or not. And let's say length, length of the features list, can do the same thing. This was copy this of labels. So that shouldn't give us any error. the features 100 and length of labels 100. 100 corresponding labels to this faces. So is we can essentially use this features and our recognizer on it. So the way we do that this, as the instance of the cv.face.lb p And this will essentially instantiate the the recognizer on, on the features list, and we do that is by saying face underscore recognizer list, and we can pass in the labels list. to convert this features and labels list to going to say, features is equal to NP dot is equal to NP dot array of labels, and save this to the typed object. Horse in detail print when this is done, so let's say craning this features and labels list. And we're going features.np y, and we can pass in features. dot nPy. And we can pass in the labels. So now the face recognizer is trained and we is that if we plan to use this face recognizer and manually repeat this process, this whole getting the corresponding labels, and then all over again, what we can do and what open trained model so that we can use it in another of the world just by using that particular this process again. But the only change that dot save. And we're going to give the path face unscrewed trend, dot yamo. So let's repeat you'll notice that you have face on scope well as faces, as well as features that nPy this train model to recognize faces in an a new file. And we're going to call this face we're going to import NumPy as MP and CV to not looping over directories, we can essentially let's do that. Let's go up here, grab this, by saying features is equal to NP note load to NP dot load with called as labels.np y. on the scope train that yamo file. So let's say face recognizer dot read. And we're going So face unscrewed face on screw trained dot we need to get the mapping. So let's grab all we have to do. So let's create a variable give it a path. Let's create eight. Let's this validation. I have one of Ben Affleck. And Graham, maybe this image from but I have And we can convert that image to grayscale I'm just going to BG BGR to Great. So let's on identified person that's patient on the going to first detect the face in the image. underscore rect is equal to r on this go cascade image, we pass in the scale factor, which and we can loop over every face in his faces w comma H in faces basis on score rect. We interested in finding your Why two one plus using this face recognizer to we get the label dot predict And we predict on this faces on is equal to label with confidence, off color values, we can probably we can probably say what we can do is we can put some text on on, we can put this on the image, we can create the person involved in that image, given an Give it a font face of CV dot font, unscrew scale of one point of 1.0 here to color of of two. And we can draw a rectangle over the over the image, we give it x to y and x plus of zero comma two five comma zero, and we done, we can find this display this image the image. And finally we can do a CV Delta we get Python. Python face on school record, pickles equals false. Gosh, where's that? come up with that out. there if you wanted use MP dot load. Since the data types are is equal to true. That's essentially but we're out. Save. And okay, we get Ben Affleck with 60% is good, given the fact that we only train this with another image of Ben Affleck, maybe And this again, is Ben Affleck with the confidence maybe to an odd person. Let's go to Madonna. change this to Madonna. And let's grab this a face because of the head. But let's face that obon TV's face recognizer built on face it currently detects that this person in the will be the confidence of 110%. Maybe there's went to 111. But pretty sure there's an error the discrepancies lie. It's not the best so So let's try this with another image. Let's of paper. Okay, this is Madonna with the confidence Watson had problems with elton john. Given Ben Affleck for some reason. Copy that chain that. Okay, elton john with the confidence is more accurate than what I predicted. before runs, and I got very good results. For example, seinfield or Ben Affleck. Madonna was detected Mindy kaylin. Minnie kailyn was detected as So I guess that we did something right. I runs. But hey, we get good results. And that's a confidence of 111%. Maybe there's an error for the most part, you can ignore that. Given So that's pretty much it. For this video, we essentially build a features list and a two lists. And we saved a model as a YAML read in that saved model saved YAML source on an image. And so in the next video, which we will discuss how to build a deep learning characters. So if you have any questions, the comments below. Otherwise, I'll see you to the last video in this Python and urban and recognize faces Pioli in open CV, and are a couple of reasons for that. One is the the recognizer on. Now, this is a significantly recognizes and building models. Ideally, you'd per class. The second reason lies in the fact Now as you go deeper into especially computer things that can actually beat a deep learning in this video. Building a deep computer vision now generate open CV GS for pre processing normalization, mean subtraction, and things to be building a very simple model. So we're In fact, we'll only be using the open CV library size before feeding it into the network. Now, deep learning model before. But this video of Kara's now I want to keep this video real goes on in more advanced computer vision projects. code. So if you've never built a deep learning that for you. So kind of one of the prerequisites having a GPU. Now GPU is basically a graphical training process of a network. But if you we'll be using candle, a platform, which actually before we get started, we need a couple of installed Sierra at the beginning of this The next package you require is conero. And for deep learning models built with Kerris. useful to you, if you're planning to go deeper Now, installing this package on your system GPU on your machine. If you don't, then you a pip install conero. And can our actually that in mind. So with all the installations the data that we're going to be using. So is the Simpsons character data set that's data that we're interested in lies in this consists of a number of folders with several has about 12 128 images. Homer Simpson has So essentially, what we're going to do is them into our model to essentially classify want to do is go to kaggle.com slash notebooks, Advanced Settings, make sure that the GPU the GPU off of that click Create. And we should to Simpsons. And one thing I want to do is installing a couple of packages over the internet. in our notebook, you need to go head to add by Alec city, I should pop up, go ahead and inside a notebook. So the first thing I want And now, now the reason why I'm doing this again, is because candle does not come pre tell her to install it on your machine. And with it and experiment with. So once that's all the packages that we're going to need. input seer, we're going to input conero. We're input CV to add CV, and we're going to input we want to do is in basically when building all your data or your image data to be of image data, this size is the image size. So will actually have to be resized to a particular the network. Now with a lot of experiments, well, especially for this Simpsons data set. So how many channels do we want in our image. we're going to set this to one basically grayscale. say car on the scope path is equal to the actual data lines, and that is in this Simpsons for where all our images are stored in. So going to paste that in that. Cool. So essentially, essentially going to grab the top 10 characters, class. And the way we're going to do that inside the Simpsons underscore data set, get data set, store all of that information inside order, and then grab the first 10 elements, made sense. So what we're going to do is we're going to say for character in our stop list, underscore dict of car is equal to length We're going to join the car on a scope pump is we're going through every folder or grabbing the number of images in that folder. And we're called car underscore dict. Once that's done, order. Sending order and the way we do that dot SOT unscored dict of car underscore dict. finally, we can print the dictionary that have. As you can see, Homer Simpson has the we go all the way down to Lionel, who has going to do is now that we have this dictionary, grab the names of the first 10 elements in of characters list. So we're gonna say characters. is equal to an empty list. And we're going going to say characters, dot append, and we're zero. And we say, if count is greater than specify a count of zero, and increment that what our characters looks like. So we've essentially So with that done, we can actually go ahead a training data is as simple as saying train we pass in the car on scope, puff, the characters, size, as we say, is shuffle equals true. So go through every folder inside car on the set. And we'll look at every element inside look for Homer Simpson, inside the Simpsons whereas Homer Simpson, it even finds Homer folder, and grab all the images inside that set. Now, as you may recall, in the previous Each element in that list was another list Now the label that we had was basically the list. So that's essentially the same type Simpson is going to have a label of zero, label of three, and so on. So once that's to basically the progress is displayed at to the terminal, you can basically just set leave things just as it is, since there are may take a while depending on how powerful a minute or so to pre process our data. So try to see how many images there are in this of trip. And we have 13,811 images inside visualize the images that are present in this plot as PLT, we're going to do a PLT dot bigger. to give it a big size of 30 by 30. Let's do element in this training sets are zero and off gray. And we can display this image. Now this image is because for some reason, open So that's why we're using matplotlib. So this legible, but to a machine. This is a valid is we want to separate the training set into That basically is a list of 13,811 lists inside elements, the actual array and the labels set, or the arrays and the labels into separate feature set and labels is equal to car dot the training set and give it an image size basically, what this is going to do is going set and labels and also reshape this feature it can be fed into the model with no restrictions once that's done, let's actually try to normalize to normalize the data to be in the range of reason for this is because if you normalize the features much faster than, you know, not set is equal to square dot normalize, and have to normalize the labels. But we do need from numerical integers to binary class vectors. del Kara's dot EDU tools input to underscore to two categorical, and we get possible labels, the length of this characters list. Cool. we can actually move ahead and try to create worry too much if you don't know what these train on the training data and test itself say x underscore train x underscore Val and equal to sere dog train, Val split. And we're using a particular validation ratio, which basically what we're doing, we're splitting sets and validation sets with using a particular go to the validation set, and 80% will go on some memory, we can actually remove and going to be using. So we do that by saying and we can collect this by saying GC dot collect. image data generator. Now this is basically new images from already existing images to and make it perform better. So we're gonna generators, dot image, data generator. And image generator from the caros using the Kara's a training generator. By setting this equal in extra rain and wind rain and give it a create some variables here. That's set my network for 20 bucks. So once that's done, actually proceed to building our model. So making this video, I actually tried and tested provided me with highest level of accuracy. that we're going to be using. So we're gonna create Simpsons model, we're going to pass size, we're going to say set the number of we're going to say, we're going to set the the length of our characters, then we can, to binary binary cross entropy. There we get power, we can set a learning rate equal to nine, and we can set Nesterov to true. So the same architecture I built and will actually go ahead and run this. And we can go ahead And so essentially, what we have is a functional API. And this essentially has a bunch of layers, So another thing that I want to do is create callbacks list will contain something called sheduled the learning rate at specific intervals better. So we're going to say call callbacks we're going to pass in conero.lr on SCO LR learning where shedule Let's go and input. input learning rate schedule. And that should train the model. So we're gonna say training in the train gin, we're going to say, steps train divided by divided by the batch size. We're going to give the validation data validation and y underscore Val. And we're going to say length of y on school Val, divided by divided can say callbacks, is equal to callbacks, that steps for epoch. And that should begin with a baseline accuracy of close to 70%. going to use open CV to test how good our going to use open CV to read in an image at pass that to our network and see what the to this Simpson test set. So let's go ahead Let's look at our characters. Let's just print on. Okay, let's look for Bart Simpson. Probably we got an image of Bart Simpson. So click this equal to our string. And what we're gonna m read test on secure path. And, and just m show, we can pass the image, pass in the we can do a PLT dot show. Okay, PLT show. So what we're going to do is we are going will basically prepare our image to be of the images we use to prepare the model in. this will do is we'll, we'll convert this is equal to CV dot, CVT color, and we're gonna dot color on scrub BGR. To gray, we can resize mg is equal to CV dot resize, we're going with size, I'm going to reshape this image. of image. We want to reshape the image to And we can return image. So let's run that. is equal to model dot predict and prepare So let's print predictions. And essentially, class, what we can do is we can print their say predictions of zero. You're not trying dot m show. Let's pass in the image. And PLT ver. That's right. Yeah. Okay, so this is that buttons in is in fact, Lisa Simpson. image. Let's try probably this image is Bart that to two, eight. run that. This is Bart we got Lisa Simpson. So let's try with a different to copy this. All the way down there. We got definitely not the best model that we could Right now this base discounting has a baseline it to go to at least 85%. In my test, it had why this went to 70%. But again, this is to models is a bit of an art. And it takes time project. So that's it for this Python and of a general introduction to open CV and what scraped the surface and really this A whole while we obviously can't cover every single to teach you what's relevant today in computer parts, building deep learning models, which vehicles, medical diagnosis, and tons of other world. And so all the code and material that on my GitHub page. And the link to this page before we close, I do want to mention that in the beginning, we barely use it throughout make sense to you right now. But if you plan computer vision models, Sierra lasher proved lot of helper functions to do just about anything. And if you want to contribute to these efforts, with your changes. And if it's helpful, it and you'll be added as a contributor. If you Kara's then conero will be useful to you. software that you'll be using. So anyway, course, if this goes helped you in any way vision, then definitely like this video, subscribe videos on Python computer vision and deep enjoyed this post and I'll see you in another