Hi everyone, It's Jakub Vanko for and I would like to welcome you to The topic of this webinar is processing It will be a tomb specifically. I won't try to pronounce the name of the tomb, because I would probably watched it, so instead of talking about it, let me So here we have a bird's eye view of the you might think that this is very simple object, there shouldn't be any problems with the well actually that is very far from the trying to align everything together, because these image sets were acquired in different periods of the day, so some some were acquired in the afternoon or And the problem wasn't that I was getting multiple components, I was getting just one single component, but this component was containing misalignments. And I think the reason for this is, because These misalignments were causing visible artifacts both in the mesh surface and also in the texture. That is actually a good thing, because now I can actually show you, what I did to fix these problems, so when you encounter these misalignments in your own projects you will know what to do. I will go over the general workflow. I will not be describing in very in have some experience using a Reality Capture that you know the user interface. So if you are a total beginner I recommend you to go watch some of our beginner tutorials first and then this webinar will make much more sense to you. Okey? So now let's go over the main topics of this webinar. So first I will going to talk about the data capture, so I will introduce you the equipment that was used and also how many images were used during the reconstruction, because these are the things that people are very interested in. This will be a combination of photogrammetry and I will go over the general workflow. So I will show you the settings I used. I will go over the alignment I will be using the component workflow, I first aligned them separately, into a single master project, and then continue with the processing. I will show you some CLI examples. CLI stands for command line interface and I was using CLI scripts for batch processing, because most of the processing on this I had other tasks during the day, I always that I launched in the evening and the next day in the morning, when I come to my computer, the processing will be finished and I Okay, so the main topic will be fixing and I was using control points, but they I had to tweak the control point weights so I will go over that in detail. I was for disabling enabling cameras. One reason find and disable the misaligned cameras, then I was using selections for reconstructing the mesh, that means that I tried to reconstruct the mesh only from laser scans and drone images to save time and later for the texturing process I was disabling the laser scans, because the laser scans would degrade the quality of the final texture. So we will go over that and in the end I was using texture reprojection, because I was still having some blurry blurry textures on the laser scan mesh and some artifacts, so what I did. I reconstruct a second mesh from photogrammetry only, textured it and which has better geometry. I had to tweak the reprojection values little bit, but again I will go over that in detail during the webinar. So now let's take a look at the final result. So this is a render directly from Reality Capture. This is actually the simplified mesh it has around 40 million polygons and it has three 16k textures applied to it. to get the optimal texture size to achieve Here, there's another render again from Reality Capture, but this time in the solid view mode. So this is the best possible result I was able to achieve. It could still probably need some clean-up, but it is much much better than the first initial result, that I was getting. So in the next few slides I will show you the misalignments and how I fix them. So this is one example of the many So a double wall. So this is clearly a huge To fix this, I was using control points and weights of the control points, so and After I was happy with the alignment, I proceeded with the reconstruction of the mesh and that's when I noticed these artifacts, so misalignments, but this time the misalignments were subtle, not so large than in the first example. This, this little mesh part that we was reconstructed only from laser scans. And I was provided with pre-registered laser scan positions. So I didn't tweak the or mess or play with the alignment of the laser scans. So that means that something was wrong in the laser scan alignment. So I had to find the misaligned scan Right away you can see that there is far less detail, because the misaligned scan stations were the closest to the wall. So that's why there is less detail and also there is a little bit more noise on the wall, but this was the most consistent result, that I was able to achieve There were no large visible artefacts, only the mesh was not so detailed and it was little bit more noisy. But I decided to go with this result and Then after I textured the mesh, I got doesn't look that great and this was again the laser scans and between the photogrammetry. So then I was thinking how to fix this. photogrammetry without any laser scans. I textured it and the textures were fine. And then I transferred the texture from which has better geometry, but with the reprojection tool I was able to achieve this quality of the textures. So much much better. So for it depends on your use case for someone this result would be good enough, but someone little bit tweaking of the textures. It really depends on your use case, but I was happy with the result and it was much much better than the first initial result. Okay, so let's talk a little bit about the data Capture. So equipment used, the data set So I would like to use this opportunity to thank them for the data set and they were using a DJI Phantom 4 Pro for acquiring the drone images. They used a Sony A7 Mark III with Sigma 14 millimeter lens for the ground images. They were using two fire focus scanners for the laser scanning and they also used GNSS receiver, Trimble Geo 7X for surveying the ground were used for georeferencing the project. So in total they acquired 57 laser scans, 895 drone images and 1698 terrestrial images. And together they survived five ground control points. Okay, that would be for the initial presentation. So now we can start Reality Capture and continue with the live demonstration. So let's launch Reality Capture right here by double clicking on the icon. And right now I reset the application before. So right now everything is using the So first I want to bring in my my There are multiple ways how you can do this. You can actually go over each settings. So we have the application settings right here in the workflow tab, in the alignment tab we have the in the reconstruction tab we have the texturing settings and we also have the I can not activate it, because we have no So you can go over each settings and set waste of time, so I created presets for my I would go to the workflow tab, go to the application settings, go to the global settings and import. Okay, so let's do that right now. Yes, import Are you sure you want to perform this And I do not want to show this again. Okay, so let me find my settings folder. So these are my settings, click on open. And the application needs to restart, because I'm changing the cache location from the system temp file to my dedicated SSD drive Okay, so it will need to restart. So let's wait for Reality Capture to restart. So this is my blank project and now when I Right away you can see that the cache location changed to my G drive that is my dedicated SSD drive and another thing that I changed here is the import settings by default the group calibration by Exif is set to no. I like to set this to yes for the first initial alignment, because this way Reality Capture will treat the images from each camera, with the same lenses, as the same group, so they will have the same calibration parameters. For the next alignment I will ungroup but I will talk about it in detail during Another thing, that I changed here.. Coordinate system, yes, this is changed by default, it's the local coordinate system Euclidean. This project is in WGS84, because the coordinate system and the output system that is the corresponding zone to the area Okay, one more thing. If you want to import your settings, but only you want to for example, you want to change only the application settings, or you only want to change the alignment settings, right here. So you will not use the import global settings, but you can use this tool. You can reset the settings here, or you can load the settings and this tool will only change the alignment settings. So here you can see again. I have some presets, alignment settings echo, reconstruction settings echo, texturing settings, unwrap settings and so on. So if you had different presets, but you want to keep for example the reconstruction settings the same and the application settings. You just want to say change the alignment But this time It's totally the same thing. So I will click on cancel. Okay, let's quickly go over the alignment settings. So I will show you what I changed. Max features per max features per image. I actually use the default value. So I will keep it at 40 000. Image overlap, I always use image overlap the best way to go. But you may Another thing that I changed. Max feature reprojection error by default it's set to two pixels. So we can change that to two, but for the second and third alignment I always try to lower the max feature reprojection error. So for the first initial alignment I will use two camera prior settings. All of all this is the same, because the terrestrial images have no priors. The drone images have priors, but the GNSS receiver on board of the drone is less accurate than a survey grade GNSS receiver. So the accuracy XYZ accuracy 10 meters, that should be okay. And okay for control point prior settings, I will leave this at default, because Global Digital Heritage didn't provide the accuracy of the surveyed ground control points, but this is pretty reasonable. Five centimeters in the horizontal accuracy and ten I think, that it should be even better. I changed the distortion model from brown three to brown three with tangential and I will keep the pre-selector features to ten thousand, that is also the default value. This extra sensitivity that's the default value to medium. One tip, if you are using only drone images and you are getting the banana effect. If you are using drone photogrammetry you probably know, what I'm talking about. To fix this banana effect I recommend you to always group your images together and This will fix it. Okay, the reconstruction settings should Let's just check really quickly. GPU to use, yes my GeForce RTX 2070, let's set to true. Okay, image downscale previews, downscale is set to four normal model is set to two by default. When I was reconstructing the So it wouldn't take so long. But again, I will get to that. This is the use parchment cloud, yes. I didn't change And here, mesh filtering, model import, these are all the defaults. I didn't change a thing here. let's check the default unwrap parameters. Yes, I changed this. I changed this maximal texture resolution 16k and style by default is set to maximal texture count. And It's set to one like this, but I will use the fixed axle size and optimal text size to get the 100% of the 100% quality of the texture. So if I change something, I will go back So now we can bring in the images. So there are multiple ways how to do this. You can go to the workflow tab and use one of these icons, use the inputs icon or the folder icon or you can drag and drop Lately I'm using a lot of shortcuts. So the shortcut for add folder is Ctrl plus Shift plus Enter. So I will press Ctrl Shift plus enter and navigate to my folder, my work folder. Photogrammetry yes, this is the tomb. Image set and let's use this tomb interior. Global Digital Heritage provided me both with RAW's and JPEG's. And I proceeded with the JPEG's. I didn't tweak I didn't make any changes to the RAW's and exported the JPEG's. I just used the JPEG's they provided me. Okay, so select the folder. Click on OK and right away you can see the imported images right here. In the 2DS view. When I change this to 1DS, we can see how many images were imported, so 779 images. So the next thing you would do. You just would go to launch the alignment. Either from the workflow tab right here. Click on align images or you can do the same from the alignment tab here. Online images or again I'm using shortcuts. So I will, I would press F6 to align the images and then you would have to wait a couple of minutes for the alignment to finish, but I actually didn't. I didn't work like this. As I mentioned, I will I didn't even save the project. You could save the project and then launch the project from the CLI script and run the alignment like that, but So I clicked on this. I created a special folder just for the image lists. Let me just find it. It should be, yes here. Image lists and I created an image list. So, I will just keep the default name images let me show you, what it what It's containing. So let's go to brought, not settings, projects image lists, here and when I open it, well It's actually image list and I will use these image lists later for selecting the images. It can really speed up things, because aligned together and now from multiple in this case image lists are the way to go. So, I exported the image lists for each each image for each image set, so I will delete this one, this is the one I created now. I have the all drone image drone images image list, terrestrial images from the afternoon, And I prepared the CLI script and let me Yes, let me open it and let's get over this script really quickly. So, the first line will set the Reality Capture installation folder to the path. The second line will set my working folder as an environment variable, so when I'm saving or when I'm saving the project, opening the project, I don't have to always write this whole path. I will just instead of the whole path, I would just use this cesta, cesta means path in Slovak language, so I use this word. So, first I would the script would launch a Reality Capture, created a new scene, set app group calibration Exif to true, this means that this is the this is the same setting like this setting. I will show you in the user interface. Workflow, settings, import. Yes, group calibration by Exif. It's already set to yes, so Reality Capture would remember this, but I just put it here. Just in case, I was just copying and copy and pasting and building building this script really quickly, set instruction for motion images overlap to low. Yeah that is, that is this setting right here. Alignment settings, image overlap low, the reprojection error to 2 and that is the default value, structure for motion detector sensitivity medium that is again the default value. Set structure for tangential 2, so by default It's just brown EPS G4326 that is WGS84 and this is the output coordinate system, this is the UTM images from this image list, so this is, this is the drone image list. It would add all of the images. After the alignment it would save the project here. I would import the image selection this time to select all of the cameras set prior calibration. Calibration calibration group to minus one, this would ungroup them and I would also ungroup them from the prior lens group and align again. This would fine tune the alignment and Then it would again open RC, create a new scene and continue with the next image set, so the next image set is the terrestrial images from the afternoon. I don't have to repeat this set set all of these values, because they were already set and I would just again edit, add the images, line, save, select all of them, ungroup them, align again save and quit. And it would do for all of the image sets. Here this last Reality Capture instance would be create a new scene. Add the image list from the, this is the laser scans. I was already provided with the LSPS from Global Digital Heritage, align and save. There was no need for any kind of realignment, because they were imported as as fixed, because I was assumed, because I assumed that they pre-registered the laser scans in their own laser scanning application alignment from RC. Safe, quit and this next and then this last command would shut down the computer, so it maybe this took, maybe one or two it wouldn't run during the whole night. So, after this script in the morning I had Let me show you the results right now. I am running multiple instances of Reality From version from version let me just check. Zero one nine three three you can run up to if you didn't know that, so this is a new feature and it is actually quite good, because now, if you are running some kind of processing and one of your show them something else, you can do that right now. You can keep running your processing and you can open another Reality Capture instance and open another project, so that's what I'm doing right here. So, this instance is containing just the laser scans, so this is the laser scan compoment. Our support team is frequently receiving so dense like in their laser scanning application. You do not have to worry about that at all, because all of the points are stored in the memory and all of So, if you don't see all of your points after everything is fine you don't have to worry about that all. So, these were the laser scans, now let's open for example this tomb interior. Will take a couple of seconds. Yes, so this is the interior again 778 images one image wasn't aligned. And you can actually check which wasn't, which which image was not aligned. If I change the 1DS to 2DS right here and go to the scene context tab, but this view needs to be highlighted by this blue outline and you will click on show unregistered. Here you can check the image that wasn't aligned. Let me change the layout to this layout one plus two and let me drag and drop here, so this image wasn't aligned And it actually, It's pretty sharp, maybe there wasn't enough overlap between this image and the other images, so that's the reason why it didn't align together. Okay, so this is the tomb interior, let's check the next component, terrestrial images morning. Let's open that. Yes, so this is the alignment. Let's check how many images were aligned. So, all of them. All of them were aligned together and even here you can see the two components that were created, so this was the first alignment, when all of the cameras were grouped. Then then the images were ungrouped, aligned again and after the fact I just renamed the component from zero and one in brackets to terrestrial images morning I renamed them, because when I was exporting the components it would already have this name assigned, but I will show you how to export a component in a couple of minutes. Okay, so now let's check the next images afternoon. And right away you will see a little little changes in the color and that's, because it was shot in a different period of the day. So, this one's our afternoon and the first ones were in the morning I think. 500 of so for the first component 540 images out of 542 images were aligned and then the next alignment added one more image. And now when I select this component, because right now the first one is selected by this marker right next to the name. Let's check which wasn't aligned. Again highlight this section, this tab and go to the scene. I need to change it to this and click on unregistered so this image was not. Yeah and I see why because it is blurry and there's a bag over here and a bottle of water. Yeah, so it makes sense that this image wasn't aligned, because It's really not that great. Okay, let's open another component. these drone images and you will see something will be different in this component. Let me zoom out. You will see these you probably know what these are. These are the residuals they show the difference between the prior position and the adjusted position Because and these are actually In the 1DS. This marker, when I hover my mouse cursor over the marker you will see Geo-reference so the images were containing Geo-reference both of them. Actually I turned off the all the components together, but I will show you how I did that, because I was only using the Geo-reference from the ground control points. Okay, I'm not sure if this is the last Interior, yeah those are those that is all of them. So, now I will show you what I what I would I want to export this component. I would But I need to have the proper component so I want this one. A little change, let's So, I would go to export, registration and components and here are my exported components. So, I would put in the name. The name is I would just click on save. But again I didn't use this way. I wrote a simple CLI script to do this for me, because I am very lazy and I like to batch process. So let me show you the script real quickly. So, here I have alignment component export. Let me open it in Notepad. So, here again this is just copy paste setting the paths again Reality Capture would load, launch. It would load the project, select the component 01, because the first component was component zero, the next component was zero one and then rename the select component to Mleiha tomb drone images. So, this is the same name as you see here. It's the same name. Then export the selected component save And I did this for all of the components. for example the laser scan component it was very large and It's I didn't have to wait and sit by my computer to wait for it to finish. Okay, after I had all my components exported. I opened a new project. So, let's open a new project. And I imported all of the components to Reality Capture. So, I go either from the workflow tab and the alignment tab, import component. And I would select all of my components and import them. I will just select one of them, because I don't want it to take too long. So, this one. This is the smallest one. So, I will use this one. Let's wait for the component to import. So, just one second that's great and you will know a component is imported when you see it is this star next to the component name. So, imported component. So, I brought all of the components together and then I used this tool from the alignment tab, these merge components tool and this tool is actually a you would have to go to the alignment settings. And the option is actually missing from here, but in the advanced in this advanced section you would have it is set to NO and when you set to YES it will only merge the components, it will not add new images to the components. So, we decided that this was confusing and when you start a new project brought in your images then the first alignment you would have zero images aligned, because it would expect just to align the components together, so we removed it from here and bring it right here into the alignment tab. So, we just click click on this. One important thing to check is when you click on the for example this first input, you need to check these features, feature source. Features feature source here right here. So, when you, you have three options. you would want to use this option when you have the same cameras in multiple components, but at this moment I don't have that. I don't have the same camera and multiple components. Okay, so I can not use this option. Then you have these two other options, use So, use all image features would take a lot of time, because it would use literally like it says all of the image features, but instead I just want to use the so this was the, this was in this case this was the best option to use. So, I use this option and after that I would So, let me close this project and open the project that is containing all of the merged components. So, it is this one. All components and right So, right here. Here are the double walls, so be a little challenging in this situation when you have double walls, so I will show you how I managed to place the control points. So, first I will isolate the misaligned part. To do that, you can place the clip in box tool, but what I prefer to do is first So, I will use the same part right here as I used before for placing the control points. So, I will just place the reconstruction region on the grid. Adjust it's bottom and top like this I can rotate it a little bit so I will jump to the top view by pressing 2 on the numeric keyboard or you can do it from the scene context tab right here display. So, I will rotate it a little bit like this move it I'll take a look from the side from the left view by pressing 4 on the numeric keyboard. Okay, this is great. Press 0 to go back to the perspective view and now I will create a clipping box from the reconstruction region. So, to do reconstruction region like this. So and I can even adjust it a little bit more, edit the which tie points or these points belong to is this photogrammetry. So, let's figure out that first. So, I need to select a couple of these points. I can use these point selection tools right here. I can use the rectangular tool or the lasso tool. I prefer the lasso tool, it can be also activated by pressing D on the keyboard. Select a couple of points for example here. Yeah, it's okay and now to disable the tool press D again or you can also press the right mouse button to disable the tool or you can click also here. Now we have a couple of points highlighted and I will use the find images tool. And we have seven inputs selected, let me zoom out in the 3D view. Yes and we can see that those are actually the laser scans, so this second wall, this this wall is from the laser scans and this is from the And it also makes sense, because this wall has more noise you can, I'm not sure if you can see it in the video, but there are some floating points. Laser scans are nice, nice and clean. Great, so now I want to place the control So, let me change the layout to, yeah I can use this layout and I like to keep this top right corner as 3D and all of the rest as 2DS. And now I want to drag and drop these 7 selected images into a 2D view. So, I will hover over the selected image press Ctrl and drag and drop it right here. And now when I use the right arrow or left the right arrow key first. But I need to be in this view of course one, two, three, four, five, six, seven. I'm at the end. One, two, three, four, five, six, seven. Yeah, so I'm browsing only the selected cameras right now. So it is, It's making a lot easier to place the control points. So, let me find a good spot to place the control point and I like this dark spot right over here. So, let's place a new control point right here. To activate the control points tool I can go to the alignment tab and click here on control points tool or I can use the shortcut F3 which I prefer, because It's much quicker so I will press F3. And click right here. So, it created a new control point number three and it is marked only on one image. Let me disable the tool for now and let's find another image. So, let's use the right arrow key and I need to find similar feature to actually figure out where it should be. Not maybe here. I think this is the spot right here. So, again I can press F3 make sure that this point is highlighted or I can just drag and drop like this. Now we have, now we have two images some suggestions. So, we can actually check the suggestions when I click on the first image right here. The blue marker, so this blue marker is now when I use the up and down arrow key I will just browse or go through these five images. Arrow down. So here's a suggestion. Here's another one, here is another one, this one is already marked. And this is the last one. This is hard to see. This one's marked, this should be OK. So, the error is under one pixel, so I can keep this to get rid of these two I will just it needs to be highlighted and I will just go and clear suggestions to get rid of them. OK, now I need to place this same control point on the next on the first wall. So, the wall from the photogrammetry. So, what I will do I will try to, I will activate the point selection tool by pressing D again. Make selection right here. Disable the tool by pressing D again and now click on find images. You can see that now I have a couple of So, again I will just press Ctrl and drag and drop the images right here. Highlight the window and now when I use the left and right arrow keys I will just go through all of this all of these selected images. So, I have to over there. So, I will use this image and I can use this image as reference. So, we have this large brick with this So, let me go. These are too far away. I want So, let me go back. Let me zoom in. Where is it? And this looks like this part and here is the dot. There is the dot right over there. OK, so again I can just activate the tool. Make sure this point is highlighted, because right now it is not highlighted. If I click here it will create a new control point. See control point for. I don't want that. Just delete it and I will drag and drop this control point right here, but you have to hold down the Ctrl key, otherwise you would move the control point in this image. Okay, so let's find another one. So, this one is good. Highlight it and now I should get more suggestions any minute if I place multiple control points. So, again here. And you can see that the errors are in red and this is, because of the misalignment. These errors shouldn't be so big. So, let's find more images and from different perspectives. Maybe let's try, maybe let's try a drone image. Let me go through the images really quickly. This is the spot right here again let's drag and drop. Now I started to get suggestions. So, let me go through these suggestions. So, I will click here and I will mark, see it's a little bit far away. And now when I'm still holding the left mouse button and now when I press the down arrow key it will confirm the point and it will switch to the next one. Like this. Again down arrow key, again, again.. This is not good. So, when I release the left mouse button now it will mark it, but I know It's bad, so I will delete it right away. Delete this item. Maybe I can try this one. Right here and because these suggestions are so far away from the actual point, this is the indication of the misalignment, so this is the way I placed all of the control points. I will go back to the OnePlus One view right now. Make it a 3D view and clear the clipping box. I want to clear the clipping box, write this. I will clear the reconstruction region. And this is how I placed control points in multiple spots that were very misaligned, so I placed some here, I also placed some here. You can see that there is also a misalignment right here. This point should be right over here. And then I run the realignment with the default weights and actually nothing changed. It was the same way. Then what I did I selected all of the control Wait, It's different value, because this is the new one. I will get rid of it right now. Like this and right now they are set to 100, because I tried 50 and 50 was still not enough to correct the misalignment. So, I went all the way to 100 and after the alignment with the 100 weights I got this component. So, this is the misaligned one and now I will try to switch to the realigned one and you will see the differences. It will take a while, because probably the laser scan component is the one that is slowing all of the things down. Again I have some clipping box here so I will clear it. Let me go to the scene context tab and clear the clipping box right there and see the misalignments are gone. There are no double walls. So, I thought that everything was fine, but caused the artifacts in the meshing and in the texturing. Okay, so after I had this realigned component and you see that there is no marker here, there is no Geo-reference, let me just make this wider. There is no Geo-reference and that's, because when I was merging the components together, I selected all of the drone images and I can actually do that right now. I can actually do that. And this will be one So, I want to select all of the drone shots. So, I could actually go and select them manually using the camera Lasso 2, which is activated by pressing C and select them like this, then add to the selection by now I'm holding down the Ctrl key and adding to the selection, but this is not the way to go. So, I will press Ctrl D to deselect everything right click to deactivate the camera Lasso tool and let's use the image list. So, I will go to the workflow tab and here I have the image selection. Click on that and let's go to our folder with And It's right here. I want to select the drone shots. These are the ones. Click open and now all And the way I disabled the Geo-reference from the cameras was right here. So, I have 894 selected inputs and right here in the prior pose. Previously or originally there was position and orientation or just position I'm not sure right now. Position and orientation probably. And right now the residuals are huge, because the whole project shifted, because right now it is not a Geo-reference, It's just shifted into an unknown place, but we will fix this. But this is the way how I disabled the So, I put this absolute post to unknown and Now, I want to Geo-reference this alignment. So, I need to bring in my ground control points. To import my ground control points I can do it from the workflow tab using this import ground control, or there is this option right here in the alignment tab. Right here import ground control. So, I will click on that. Let me find my ground control points. I already prepared this text file let me Just to show you what is.. So here, right click open with Notepad. So, It's just five points. This is the label of the points of points five, four, six, seven and eight. And these are the coordinates in WGS 84. So this is the longitude. This is the And they are separated by space. What I like to do is also incorporate this in the name of the file. So It's a GCP WGS 84 underscore latitude, underscore longitude, underscore altitude and the separatory space. Just not to make mistakes. This is just, this works for me. Okay, so let me close this. So I will click on this open. So and now choose the file format, so I need to switch this. So It's name It's name longitude and latitude and I lack latitude longitude altitude and can determine the separator automatically. So, it knows that the space is the separator. Ignore first line no, because there So, this can be left to NO. And the coordinate system is correct and position accuracy.. These values are from the alignment tab. The default values if you remember, I mentioned that Global Digital Heritage didn't provide me the accuracy, so I left it at default. And now I will click ok and they were So now what I need to do is place these ground control points in the component. So what I did. There are multiple ways, because right now you don't know where's the north, where's the south, you don't know how it is orientated. You would know that if I let the approximate Geo-reference from the drone shots, but I didn't use it right now so it will be a little much challenging for me to place the control points but I can handle it. Okay so let's try to change the view again. Let's keep the top right corner as a 3D view. Let's change the bottom right corner to a map view. I will zoom in to the ground control points and now when I rotate this 3D view little bit, now I can align it to the north and now I have an idea where the ground control points should be. Okay so ground control point number five should be somewhere around here. So let's try to find it and let's try to place it. I will activate the control point tool again. Highlight ground control point number five and hover with my mouse cursor over the point cloud and here in the bottom left view I have a 2D view and I get live previews of my 3D cursor actually on the point cloud so it is displaying images that can see the place. That my mouse cursor is over. So here we have the ground control point number five. I don't have to place it really that accurate right now. So maybe, okay I will place it here. Because I will refine it's position later. Okay, so that would be control point number five, then I would add control point, ground control point number six. It should be somewhere around here. Let's try to place it as well. So again activate the tool. Highlight the corresponding ground control point and let's try to find it. And actually here it is. I can place it and zoom in. No it's actually number eight. I'm blind, yes this is number eight. So no I have to delete this two suggestions, highlight number eight and again place it right here. We'll zoom out a little bit like this. Okay so and then I would continue with the other ground control points. So let me disable the control point tool by right clicking and now I will select the first suggestion for ground control point number five, but I need to make sure that this 2D the blur cursor blue cursor like this. So I would click on it. Move it to the down arrow key. It would confirm it's position and select the next image like this like this and now RC gave me multiple other suggestions so I can go over all of them. This is actually a laser scan and it's visible that's great. Because they were probably placing and removing the ground control points around the time they were using the laser scans, because I noticed that some laser scan positions do not contain the ground control points. But I guess we're lucky that this time. So I can place it here and go through all of the drone shots. I will not conf all of them only a few of them like this. But basically it's the same thing like Like this like this and so on. I will not And again I also increased the weight I need to have my control point selected and here, here's the weight. So again I increased it to 100. And that's it. After I placed all of the I ran the alignment again and saved the alignment. And after that I was continuing with the reconstruction. So you would go to the reconstruction tab, set the reconstruction region. So I just wanted to reconstruct this tomb in the middle of our point cloud. I didn't want the other surroundings. So I can actually demonstrate it. I set the reconstruction region. Let's try automatically. Okay not bad. Let me just change to the OnePlus One view. So we have a larger 3D view. I will on the new numeric keyboard. Adjust the position like this. Like this from one of the side views. So and this was my reconstruction region. And now I could just click on normal detail and the reconstruction would run with the downsize of the original images set to two. I actually didn't disable any cameras reconstruction I mean, because I was confident that the alignment is fine. So what I actually did, I exported the reconstruction region. I will show you how I did that. I went to the reconstruction tab, export reconstruction region and the reason why I did this is because I used another CLI script for the the reconstruction and I used a command to load this reconstruction region. I can show you the script right now. Let me just open my file explorer. Let's find the CLI folder. Here is the batch file reconstruction. So let me open it with Notepad and let's check it out. So again this is just copy and paste to define the paths. So I would run Reality Capture, load the project - reconstruction, because I saved it as a reconstruction.RC project. I would select the component Georeferenced, because after this alignment after this realignment I created another component and I renamed it to Georeferenced. So it would select that component. Then set reconstruction region. Yes it would load the reconstruction region that I exported. Then it would calculate the mesh with the normal detail after the reconstruction it would save the project, select the model number one, because there will be only one model, but I put this command there anyway. Rename the selected model to source, then select largest model It would select the...If you have any in the mesh, it would select the largest connected part and then I would invert the selection to select the remove selected triangles command to get rid of them, because I don't want them in the next steps. After this it would save again the same project to reconstruction.RC project. Import image selection and this is the image selection for the laser scans and after that it would disable them from the texturing so the command is enabled texturing and coloring to false. So the laser scans would not degrade the quality of the texture. I want the texture to be created only from photogrammetry. Then I set the unwrap max unwrap style. No this is the unwrap resolution to 16k and wrap style to fixed axle size. Unwrap fixed axle size type 0 this means the optimal. So I would get 100% quality this right And then I would set texture recolor want my mesh to be recolored. I'm just not used to work with vertex colors. I prefer working with textures and then it would use this calculate texture command to calculate the texture and save the project. Save the project and quit RC and then And in the morning I was checking the results and there were the artifacts and the mesh surface and also the texture was terrible. So that's when I decided to pick a smaller part of the mesh and start And now I will show you what I did, okay? So let me close this and I can also close this project right now. By the way if you are interested in CLI help view and right down here you have the command line interface, all CLI commands, these are the CLI setting keys and values and so on. If you click for example this here are all the commands and that I used in my CLI scripts, because I memorized some of them, but of course not all of them. So sometimes I need to go here and check. And I just copy and paste these commands to build up my scripts, but once you get used to it you will just copy and paste your scripts. Modify them and actually I like it more than working with the user interface. It's not always possible, but when it is Okay so let me go back. I can close this project. I do not want to save it. And now I will open the project with the reconstruction. So right now you can see that I have I was doing some experimenting. But I will show you basically what I did. So let me disable this model. Let me view the tie points. Okay right like this. Let me clear the reconstruction region as well. Okay so I decided that I will make my opening or window. So first I created a reconstruction region. So I went to set reconstruction region. Let's make it on a grid again. Like this. I will adjust it. I will adjust it from the top view. Like this like this and the back part of the reconstruction region, I put it almost in the middle of the wall, because I wanted to only play or experiment with the front side of the wall. So this is from the top view like this. Like this and like this. Okay and here you can see multiple experiments. So I tried lasers plus photos only. Then I tried lasers only. Then I tried lasers only plus disabling scan scanned station, that was right here. Because it was causing the artifacts in the mesh surface. And then I have lasers plus photos plus the disabled laser scan position and I found that the lasers only test minus the one scan station was the best result. But I will show you how I disabled and enabled the cameras right now. So let me just make the cameras a little bit bigger. So we can see them like this. Maybe a little bit bigger. Like this. So I will select all of them by pressing Ctrl A and here you can see that I have almost 3000 inputs. And enable alignment meshing texturing coloring and weight and texturing, all have different values. Because I was tweaking all of these Let me check let me deselect everything by pressing Ctrl D. Yes, these red cameras are totally disabled from anything from the reconstruction and also from the texturing so you can see that I only enabled the cameras that were in close proximity of the tomb. So but I will enable all of them right now. I will select all of them and press Ctrl R and again because the first control are disabled all of them and the second control are enabled all of them. So now when I.. Let's press Ctrl D or I can also deselect them by this command. Where is it? Here, deselect the shortcut is Ctrl D. Now none of the cameras are in red. Everything is enabled and I will select them again all of them and enable everything. I will enable them in alignment enabled in meshing enabled in So now I created a clipping box from the reconstruction region. So I went to the scene. Create clipping box. Create from reconstruction region Deselect everything by pressing Ctrl D. Now I use the select point tool. So from the alignment tab point lasso tool. Or pressing D and I selected these I disabled the tool and I use the find these points. So these are the images. Then I invert the selection like this by pressing Ctrl plus I or by pressing this command, invert like this. And I disabled them again so press Ctrl R. And they are disabled. Great I can deselect everything again. And the next thing I did was to select using the image list. So let's select them. Let's go to the workflow tab. Import image selection. Use the laser scans. Open again invert the selection. Like this and again disable all of the Now when I deselect them.. a few scan stations that can see these points. And actually when I click here on inputs you can see that all of the images are disabled. All of them. And from the Point Cloud Rig here only some of them are enabled. That can see these visible points. selections to use as few inputs as possible to make faster experiments because if I would calculate this small mesh part with everything it would take much much longer. And I didn't really want to waste any more time because I was already spending too much time on this project. So let me show you the actual results. So let me highlight the lasers only test, yes. Let's go to the.. We are in the solid view, but I want to disable the type ones. Like this. Okay so you already saw this in the beginning of this webinar in the presentation. And the other best..This is the lasers only plus one scan offset of test. So I found this to be the most consistent one. So I decided to go with the laser scans only. But here you can see that the top of the wall or of the tomb was not visible from any laser scan position, because they were at ground level. So I needed to enable a couple of drone shots to reconstruct even the top. So we can start all over again. So let's clear the clipping box. Let's view the tie points, let's disable Let's select all of the laser scans actually. Yes let's do it like that. And I don't have to use the image list actually, because they are grouped nicely under this point cloud rigs. So I will select the first one. Scroll down And select the bottom one, but I need to hold down Shift key. Like this. So now all of them are selected. And now I will press Ctrl R, it will disable all of them. I will press Ctrl R again and this will enable all of them. Next what I did is to select all of the drone shots and enable all of them first. So I would do that with an image list. I will go to the workflow tab import image selection, select the drone images. So it's this one. Enable all of them and there should be all enabled. Yes and then I went to a side view. Not the top view. The side view. And I decided that I will disable all the cameras that are above this point. Or above this line. So I would deselect everything by pressing Ctrl D using the camera lasso or by pressing C on the keyboard. I would select all of these like this, like this and press Ctrl R to disable them. Disable the tool deselect and now only the laser scans and only these drone shots will be used for reconstructing the mesh. Okay I almost forgot to disable also the scan station, because this was the one that was causing the artifacts around this window. So I will quickly disable them press Ctrl C for the camera lasso select and press Ctrl R to disable them. Great and I almost forgot another thing. I will show you one tip. For example when I was making the selection for the drone shots, so let me do the selection one more time. I will again activate the camera lasso. Select all of these cameras like this. And now if I press Ctrl Shift F1 Reality Capture will remember this selection. So I will deselect all of them and now when I press Ctrl Shift and one I will select the saved selection before. So this is a great tip and it was very useful when doing such selections as I was doing in this project. Because later during texturing I was doing multiple selections. I was selecting the outside the cameras that were further away from the tomb. I didn't totally disable them. I just lowered the weight in the texturing. But I will show you that in a couple of minutes. So now I was prepared for the reconstruction. My reconstruction region is this one so I need to update it. But if you remember I exported my reconstruction region so I can use the same one again. So I can bring it in from the reconstruction tab, from import and import reconstruction region. I have another folder just for it. I have multiple reconstruction regions, because I was for the tests. I was not just using this small area for the testing. I was using different areas also. But which one's the main one..This one! Reconstruction, this is the one. And after this I just went to the reconstruction tab. Of course I saved before the reconstruction like this. And then I didn't run a CLI script, because I was doing this in the middle of the day. So I just run normal detail and I went for lunch. And it actually was pretty quick. Maybe I can maybe you can check. I think this is the one that was created, so this mesh. Not enough video memory. Yes I know it do not show again. And when I see the report here. So the depth map calculation time took 59 minutes meshing three hours and 21 minutes. And overall processing time was around 5 hours and 23 minutes. So but luckily I have another computer so I could do other work as well. Okay and so I will disable the tie points. And this is the mesh that I actually got, but we are only viewing it in the vertices mode, because it has 243 million triangles and it's more than my GPU can display at one time. So I simplified the mesh to 40 million polygons, it's this simplified one. I will view it in solid view. And this time we will be actually able So there is still some noise visible from the laser scanner, but it is much better than the initial results. So this is the surface. After this mesh and started the texturing. So first I needed to select all of the scan stations and disable them for texturing. So again I can just quickly load the image selection. So laser scans and I just went here for the selected inputs. There are some different values, but I want to enable texturing and coloring set to disable. Okay so the scan stations are disabled from the texturing. Next I want to enable some of the drone shots are already enabled. And I want to also enable the ground images. So I can do that again with image lists. So I can go to the workflow. Import image selection, zoom interior. I want to enable them and I think that I kept the weight in texturing at one for all of these cameras right here. Then I imported the selection for the afternoon. Like this. So again I need to enable them and wait in texturing. I probably change some of the weights here, but I don't see a reason, that I should done it, because they are relatively close to the wall. So I will change it to one for all of them. Like this and then I select the rest again by using the image selection and it was from the morning. Yes, again I enabled all of them for texturing, but I lowered the weight. It was only about, let's check this one 0.01. for all the sets from the morning, because they were further away from the wall. And after all of this was done I went to the reconstruction tab, I checked the texturing settings if they are what I need. And I set 16k, I set fixed XL size and the optimal text size. And after this I just click on texture and I had to wait a couple of hours to it to finish and that's when I got this result. Model textures, let's display this first picture. It will take a couple of seconds to load, because it's three 16k textures, so it's a lot of data. But we are starting to see something and you can already see, that there are some artifacts, there are some blurry, I got this. And you can see that some parts are okay, but some parts are looking just terrible. So at this point I was trying to figure out what to do next. And of course you could do some fixes with projections in other 3D software, but I wanted to fix everything in Reality Capture or not everything, but as much as can be done. So I decided to make a test. So I used all of the photogrammetry images all of the sources to create another mesh and it's this one. It's the mesh that I called texture. Let me click on it. Let's see the report in some settings. And here you can actually see that I used the image downscale factor for that maps to 4, because I didn't want it to take too much time. So I reconstructed the mesh only from the photogrammetry inputs and then texture it. Again with the same enabled cameras. And I can actually turn on the color. No, it is actually in sweet mode, but because I don't have any vertex colors, so that is why the point cloud is not colored. So to view the textures I had to always create renders using the export render tool. But then I decided to.. And I make some renders and I noticed that the texture is looking fine. So I decided that I will transfer this texture from this photogrammetry mesh to my laser scan mesh. And for that I used the texture reprojection tool and it's located right here, in the reconstruction tab. So I selected my source model. And it should be the texture, because I will be transferring the texture from the mesh gold texture and my simplified mesh. And when I use this reprojection distance I was still getting bad results, still some artifacts and still some blurry parts of the texture. So I decided to switch this to custom. And I increased this custom reprojection distance to 0.5. Like this. And then I just clicked on reproject and to display it. My simplified mesh has two color layers. This first one is the bad texture and this color layer number two is the good texture. So let me load it right now. And this will be the result that you saw in the render, that I showed you in the beginning of this webinar. Again let's wait a couple of seconds to finish the loading. And you can already see, that it is looking much much better than the previous texture. And that's it. That is how I got my best result so far. I'm not saying, that this is the final result. I will try to take another look at this project, but that's it. I hope you learned something new and if you like this kind of content and these types of videos, please let us know and we will try to make more. So it was Jakub Vanko for Capturing for watching and have a nice day, bye.