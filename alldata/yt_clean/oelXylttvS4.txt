Hi, everyone, and welcome It's a great pleasure for me Professor Tim Barfoot. Tim is a professor at the where he's also the associate Institute. And he's also a of the Vector Institute. Tim got his PhD from the And before becoming worked at MDA Robotics, made the Canadarm manipulator It's essentially the to-- which went on the space Station. He was also visiting professor back in 2013 and was director at Apple in 2017 and 2019. Tim is working in the broad and is interested in developing mapping, planning, and control long periods of unstructured and And for his work, he with a number of two best paper [INAUDIBLE], award from the and a Canada Research Chair. Moreover, he is an IEEE of the University of team that won the SAE Autodrive in a row, impressive. So Tim is a member of the the Transactions and the Foundation Board of And he served as the general Robotics Conference in 2015. Finally, he's the State Estimation for read for people working in And without further [APPLAUSE] Just an audio check, you Yeah, great, well, thank you and the lovely I've had some really wonderful already today. So let's keep the I wanted to give a talk today bag of different things. But it falls under I guess, is to get many of these mobile robots out there there's sort of a that we're having to deal with So my title, Robot Navigation when and Geometry Won't Cooperate.&quot; And we were talking but a little bit of just our group does curiosity research, where we're just kind and what we can do with them. And then we also mainly because of the way the is, with industry, try out a lot of these large robots out in the world. And I think really it's this of trying things out to the drawing board in that circle that makes for So this is my graphical I'm going to try to squeeze under this overall theme of cases of some of these You don't need to read But those are all the-- I can share the slides after. But those are all came out in the last two years. So we'll briefly talk a little that we're working with effect to get new I'll talk a little on our ability to do particularly with radar. I'll give an update we've been doing on off road of a technique that we've visual teach and repeat. And then I'll switch gears in the back end of are these certifiably much of that work started here. So hopefully there's to listen to that stuff. So let's dive in which is Doppler odometry. So one of the things I've is getting my hands on don't typically make So this is just a little of some of the things before they become popular popular, everything came from micro for getting very low cost to star trackers for the on the bottom right. This is, like, the and it can produce pretty much matrix directly from a single obviously. And we even got our hands that were able to produce image long before the current products And we were doing things like and doing computer to do sort of real by even extracting long before we had deep learning And so, following the sensors that we're that I think are kind of maybe and are very Radar is kind of an old sensor. It's been around I saw a really over in the CSAIL building But radar and robotics is still technology, I would say. And so we're trying to think And then how many people have So this is quite a fun, There's a couple make these optical sensors effect to get per point on every point in a point cloud. And so, we've been thinking This was actually-- was started by some from Apple and the left and did a startup. And they asked if I could and see what I could do with it. So we'll talk a little bit from this Doppler LiDAR. And for those that maybe need the Doppler effect allow us to do-- so use the Doppler using a slightly different than the typical LiDAR or radar. Well, radar always But LiDAR doesn't So they use frequency modulated And the idea is you're sort has an increasing frequency. And in the frequency space, that That chirp bounces And when it comes back, And by actually measuring the chirp, you can get some measure And because there's another which is the Doppler also causes a small if the relative motion between is nonzero, you get these two And so, the radars that we use what they do is they And then they send a down chirp. And then those frequency stays the same sine. The other one shifts sine. And you get two equations And you can solve for both to the target, which So that's just a quick synopsis And then as we start we can do with these there's a few There's sort of an obvious which is can actually of moving objects almost by just sort of thresholding between you and the scene. We're not actually going going to talk about. But that's a nice application What we will see in is that we can handle situations. So if you're driving, I came on the way from the airport And if you were like iterative closest point clouds to estimate your you would get into there, where there's an along the length of the However, with the new we can now actually solve in these geometrically And then another kind of is, you're looking This is actually now a in the middle of a snowstorm. And because you're if you don't get from that, two systems of you actually don't Here's data from a Velodyne, one pulse to get a return. And you can see in there's just a lot of that are falling from the sky. Whereas you almost get for from the data in So that was just kind of a I'm not even sure that knew that was going to be But that was kind of fun. So again, you all of these long tail Sometimes you can solve some of right. And so, as need to think about both We're really systems are trying to put the So I've got a Doppler LiDAR. I now have this new radial What can I do with that? And so, the first thing was trying to estimate motion, And you could imagine building that is using a number of information. So we might be accumulating We're then moving. And as we get observations from we build these factors So those are typical We might also have factors that try to encourage And then the new bit is these per timestamp at every time that And so, we can actually That's the obvious thing to into a big factor graph that for the motion of from one frame to the next. And we actually do this So very, very typical sort optimization problem with coming in. This is a bit of an eye chart. But we've done a lot on a real car where And the net net of it is that our algorithm is the fourth row We're doing a lot better particularly in the situations like tunnels. But somewhat surprisingly, also like highways where off to the side of the a lot of other moving vehicles, And just to show this is the data from the Here's our motion to ground truth over the And we're sticking pretty And the places where you are, as I said, in This was an example of And it's about 300 meters long. And you can see a typical algorithm is this orange line. It actually estimates than the true length Whereas by using the we're able to keep track of biased towards no motion, which to do without velocity. So yeah, our errors dropped down So a little bit of an but a nice way of pretty hard by just The next thing that we thought odometry was, could with using the point Well, we're using But we're really focusing more A typical iterative is going to require at each iteration, between every and points in the And that's the most So what we thought could we actually the six degree of from these radial and then just integrate that to get motion? And it turns out you With only one Doppler getting radial there's actually an You can only measure the in three degrees of freedom You can't get any of the three However, we actually did a And it turns out more of these colocated on the roof of a car. And it turns out, if you have three you can actually recover of freedom velocity of And it's the non quite important that allows you Unfortunately, we only So we got around this. Although in theory, we got around this problem a heading gyro with to try to recover the full six and then integrate And it turns out that there's up your estimator this way. These are some equations that But the point is that we have to build are both linear in the unknowns, degree of freedom velocity. So we have gyro measurements. And we have these radial So both our measurement models So we can actually as a fully linear estimator for with this source And as a factor graph, you We still have some We have the heading gyros. And then we have some velocity And we do all this in a so that we can account for of the measurements. And if you do that, can actually do pretty The quality of it depends of the heading gyro. We didn't have a great Black line is ground truth. Green line is our is not as good as the that I described a But we're still sort of, doing a pretty good job And this algorithm runs in per LiDAR frame. So it's super cheap. You could run this basically on right inside the to tie up your CPU with So we think there's some You could probably run this for meters, then do And that would to produce overall We then turned our to do a similar thing And it turns out, the LiDAR guys for us, which is that they directly on the sensor. The radar guys didn't So we're working with Navtech. In fact, their sensor doesn't Doppler velocities. But they provided a that was able to, the raw materials that the Doppler velocities at But we actually had to come would take the raw returns along do some correlation. You get very noisy compared to the LiDAR signals. So we actually had to run would produce the overall of the platform that the But once we did got pretty good You can see this is this video down on the right. Sometimes that's Video down on the right the orange is the stuff that's And then the blue and the are being accepted by RANSAC. And if you then into an estimator similar to you can estimate And again, we use to recover the angular velocity. In this case, we're doing it only measuring velocity in 2D. We actually took this out scenarios. We went for a nice went through a progression of so of suburbs where there's lots then a very, very And then it turned was the hardest was actually went over some water. And so, there's almost no even walls, which made it the velocity returns. And when we tested on these different can see, as you might expect, more challenging, the that are doing something just which are these blue poor job of tracking which is the red But our algorithm which is doing this very In fact, this algorithm runs in And so, again, could just on the processor that's It's pretty much good for several hundred get a match back to a map. So we were pretty because again, to solve a problem that would on the software side. So that's the first part. Now I'm going to talk-- The next part, of course, is We want to maybe use a map and and then correct think we are on a map with We've been thinking about this We've got an ongoing with General Motors about the impact of I guess, the same on the different components for a self-driving car. And my part of that is the And, I guess, we've been mainly could we take a radar and build module that works as well as a applications. And we've been focusing on For those that built a data set called publicly available. It's hosted on AWS. It's a bit unique in a few ways. So A, it's got this combination and radars. The other thing that's is we redrive the same 10 again over an entire year. Many of the data have this driving of routes. So we can use any one of and all the others And you can swap up those roles. There's a lot of-- it was over the whole year. So there's several sequences storms, sunny days, at night in a snowstorm. There's lots of data there And there's even a leaderboard that you can submit I maybe won't bore you too much that we started with. But we took something like where we're matching point or radar back to generated during a teaching And the baseline algorithms perform pretty close to the So we're getting about 5 error for on road driving. The radar is sitting at So it's not quite as But we've got some ideas on talk a little bit about those. And there's some actual you can think about when you're for localization on the road. For sure, the radar sees through But surprisingly, the LiDAR does as well. There's one situation that was pretty difficult was in a snowstorm. And what happened was, ice accumulated on the And it actually just made to see out through a The radar, of course, kept had snow accumulated on it. So LiDAR does pretty until you get fully The other thing is there's a lot that you can see between So you could imagine you build a map using And then you try to localize on a poor weather day. So we experimented a little And you might want to do that mapping cars that are out there So you would still Again, a bit of an eye chart. This is just saying a little Our LiDAR localization, and localize with LiDAR a centimeters actually, root mean squared error. Radar is somewhere And then building a map with is a little bit worse. It's at the moment like centimeters of So there's some work to be done. The change of modality One's 3D. One's 2D. How do you how do you turn for the radar to localize? There's some open So one of the things-- in an interest to try to close performance and the radar a handful of centimeters, we've been thinking about artifacts in the radar data. So if anyone's you can see all there's about seven or of weird artifacts that happen You can see some of them in One of the things we was just trying to would build a mask, that would pay attention to in the of the radar. So we think of this as a radar And to do this, we actually of iterative closest point. In this case, our map is LiDAR. And we're trying to localize And the radar is being deciding a weight to apply to And so, we actually gave poses from ground truth And then we just back propagate to try to learn this And at first, it kind which was it sort of ignored But we found some good that it was learning were a bit better than that. There are some examples some cars in the original data. And those are moving. And by the way, we're not giving in this project. We could probably do But the mask is able to remove that are closer to the vehicle. I think this picture is This is the original radar scan. And this is what it looks So there's a bunch of echoes There's some sort of noise in this field. Often you get these in the radar data that really of the geometry in the scene. It's doing a pretty good to the point where it doing something reasonable. So that's been a We probably have our We haven't actually put yet where we can see what to the original So we're kind of Another thing I is a lot of times focus on building We're always trying to build build a better mousetrap. I think we could spend tools of our algorithms. And so, one thing that we've can we build a tool that will and then decide how try to predict how well it's So we're calling, trying to attack the iterative And the idea is, under that you could apply data that's coming off the What's-- if you pick a class of everything, it can corrupt could you actually work out and then see what the effect of ICP's ability to localize? So maybe you have to know where you are within all the time. If there's a big an occlusion or a whole bunch of or passing your car and they produce a bunch of that don't match could you actually into producing a bigger error? And we've looked at this a I won't get into the details. But we had one way where this in a white box fashion. So we looked at the And then linearize the algorithm And then actually to come up with the worst scan under some constraints that It's able to do things take part of them this way and And that produced the in our iterative And then what you can that you've built, and you can scheme everywhere in the map where are the places that large errors if I had the worst sensor data? In this case, red is bad. So we learned that there on this route-- and this road for a different where we could say places where to be a little bit brittle. If there's something that's then you're not going to So it's a baby step But I think it would be work in this area to find ways of in an adversarial manner. And, actually, of in the era of deep learning. So a second way that we was to just try to train a take our input LiDAR scan possible way to maximize our under some constraints all the points off to infinity. And it's more subtle than you trying this on not version of iterative that's got trimming. So it's got outlier rejection We can't just move to infinity to maximize error. The algorithm is knows that there are outliers, So you have to move the points get classified as that you maximize the error. And so that's what this So we can train And interestingly, build a heat map the worst possible errors And it turns out that the was more analytical and predicting very similar hotspots places that we thought be less robust. So this is, I think, I think there's some Right now, if you going to give you this Probably there can do that will make the plausible, some inductive into the network that a car in some weird would maximize the That was the second So we did a lot Let's move now This is going to be I have this with this problem of long-range So you're looking at a fairly that we call visual So we've driven manually And now we're localizing So this is a robot It's had one demonstration It's only got one laptop, This is pre-neural networks. So there's no neural networks There's no global map. There's no GPS. There's no IMU. There's really nothing. There's no semantics or So it's really just sort of in the visual scene to So it knows where it is It's using model predictive over time. And we're able to get a robot in its tracks in without assuming about the environment. So we've been working on One of the things that we've recently is what obstacles that get added to and the repeat. So now you're looking of our LiDAR version of So this is out at Canadian This is actually their robot. Another thing I is pass your code into and have them try to run it That's a real test if on someone else's robot. So this is just using And you can see that there of easy obstacles that it's rudimentary obstacle detection. And then it's planning a local planner, which then the right homotopy class and then a model predictive the path that gets executed. So there's some open remain for this problem. How do we actually It would be nice about the classes One of the things I've been to move towards is open like detect that there's to hit without knowing what are in advance. So there's some things we've In fact, we've gone Because we're working teach-and-repeat pipeline, this leader. And I've been kind of to come on the market for 14 we were thinking as more like an image product images. And we had this very that was able to do this. It only did it at 2 hertz. It was the size of And now you can buy the like the size of a grapefruit. And it produces images And they are 360 degrees And so you can start to do some Of course, vision come a long way in 14 years. So one of the things we've been run like Meta's Segment Anything intensity images to are happening in the scene? And because we're we've already been through So we can actually simplify into something that we call We want to compare to what we saw when we did And so the idea that or one idea that we've been So we'll register the live And then we'll render intensity We'll then run Segment Anything will produce a set of masks. And in this case, that's been added to the scene. When we prompt in that area, But in the map, So when you prompt in that And you can actually do some union to compare the masks and the repeat. And that's a very what's changed in the And the video on the right, just go back and forwards the video on the right, being detected as a change. In this case, it's just a person These are fairly early videos. That's a person match between the segmentation But it doesn't know anything or any of the semantics of that. It's just based came out of Segment Anything. So that's one way about trying to get change I'm also excited that-- the name of my lab, by the way, Lab. I haven't really done anything but I'm kind of very excited into space robotics now. So the company that I used to MDA Robotics-- It's actually called The name keeps changing. So Canada actually to possibly build vehicle for the Artemis program, I guess, to build this rover. And so they've asked to take our LiDAR and make it the main navigation vehicle bid that they're And so we're actually working months. This is actually We were testing on this vehicle That was probably the last And now we're going to be about 14 or 15 years later. But the cool thing is that the is the right rover for that we built because most of are doing science. They're sort of doing and soil, and things in the And then they move a little This is an engineers rover. This is the one that's going to between a lander and a habitat. And so there's this problem that's inherent to the And so that's they've asked us to take and try to use it So stay tuned for more on that. The other thing that's is, of course, because we recently tried to build scheme based on the radar. And we just submitted where we talk I was a little surprised If you look at the radar in this fairly off road-- we talked about what is an This is an off-road environment. The radar scans are There's not a lot of that I would have said work pretty well. But even just using from points we're actually able to and drive autonomously mean squared error. That was surprising to me. I wasn't surprised in the vicinity of buildings But in this vegetation I was very surprised that Key to doing it was that to really get the to last between weren't a lot of usable How good is it? There's some numbers we could show where the errors where the errors are high, red. We didn't actually have in these experiments. And the biggest errors were sort of on the order of And so radar off road, If we get it to work, because it means pretty much in every weather And you can see the This is easy radar data. There's a fence. There's a tennis court. There's some buildings. You can see this very obvious This is in the flat, that I just showed And then here's an three-dimensional And you can see that there's Suddenly, the radar because the robot's pitched. And the radar is That's a bit of a problem. So I think there's done to make this work on off-road situations. To that end, we're actually set called the FOMO data set. We're in the process with the University of Laval, where we're doing something but now off-road, through a really environment with and all of that. So stay tuned for that. I think I made it to do the last part of the So I've mostly been and I saw Russ just came in, so that he's interested in. I've been mostly talking about of mobile robots. Let's turn to the back end now. And so I probably don't need to is to most of the because I think a lot of the But just for those many of the algorithms as state estimation problems And we build a bunch of cost And we're trying to find minimizes that cost. And if you crack open any most of the algorithms will basically be finding local And that's kind of a problem. So our cost functions If we start with some we're going to converge far from the right answer. And so what we'd is have algorithms that find So could we do that? And, of course, the I'm a Canadian, so it It has to be sometimes. And there's sort of a one well-trodden path. Russ has got a different But one of them is this original some algebraic into another non-convex constrained quadratic program. But now this has a And then there's a that we can go to something using a technique called Shor's if you define big X to be the transpose, you can exactly here. And then you end up with that you relax. And that's the relaxation. And once you drop this the remaining problem is which is a convex be solved with something like There's also something called you can get directly is also a convex problem. And so what these techniques is something called And, in general, will kind of sit here, the and the dual problem And it's always true that The minimizer of higher than the blue, which or they could be equal. That's called weak duality. When we have strong duality, kiss at a point. So the dual comes up. The convex relaxation touches the minimum of the And so there's a few If you can solve and find the minimum of you're guaranteed now of the black function. Or you could solve the and that would be also And so that's basically what If you want kind of take a really simple It's just a quartic. It's got two minima, a red If we want to turn this into is we define a new 1, the original variable And then we can write as this quadratic formula. But now there's that we need to account We need to say that the And we need to say the square of the second entry, But these are now also So we have a quadratic cost We can then do the standard where we drop the And then it's like just a couple using an out-of-the-box You can solve that, and And lo and behold, our So since it's rank 1, basically, We can say that we of the original problem. And you can see corresponds to the correct so very, very simple idea. But to get it to is a little bit And I guess there's been tons We were not the We're followers for sure. Rotation synchronization trying to get a to sync up with each other, with Dave Rosen and Luca, Really, really amazing that uses some pretty to do global optimization Pointcloud alignment, Really, this is actually where you can align point of a lot of outliers that you're still finding the There's some really It's a very long paper. The appendices-- they They went like A I think they went There's a lot of but I've read it all at It's a really amazing paper. Some other work that of U of T with Jon they were looking at certifiably So there's lots and lots of in the robotics community. We kind of jumped And we worked on a We were talking So one thing you is to add to the that you can say that there So we've been working on some estimation. Talked to Alan somewhere He's also got range-only I didn't mention but that kind of makes We did some range-only And one thing we did that of stuff-- oh, actually, was that we So in the original they were doing pose but there were no landmarks. We showed that we could and include landmarks this with the same complexity as And then more recently, at matrix-weighted Slam. So the idea is like you now have a matrix represent an isotropic noise. If you had a stereo camera, in the depth direction. You might want to under that constraint that-- you have more uncertainty in It turns out that makes the Inherently, the starting from a quartic instead So lots and lots of things that We're by no means done. There's many more things that But we also wanted I'll skip that one, actually. This was another catalog item. We also wanted to take a step It's actually pretty with a new global solver So we wanted to we onboard people into the catalog a And my postdoc, did a really nice piece of it's a little bit But in some of these problems, to the SDP, the It turns out that that problem solutions all the time. And so what you can add some more extra redundant constraints-- into affect the original problem. But they reduce the feasible But finding those is not the easiest thing So we actually built a tool able to enumerate all of these from some-- it's almost a where we just generate data that can be done pretty trivially. And then we solve actually a QR problem, and out pops all that we could possibly need. And then we can even those constraints and add them until we see that the problem and that we get So here we're trying to step and just think it easier for people to bring Another thing we've been is like, OK, now we've a favorite thing that is actually train by back propagating So there's tons of good but they're all centered on So we actually showed in this but it's on archive-- that we could actually backwards through our SDP so that we can now actually labels at this end and on those labels through So we call that SDP layer. You can combine it with any that you want and And there's an we were learning some features We're training the And we're actually through one of these didn't seem so obvious that But we can basically we have a certified Now, we have certified gradients And we showed in that converge to the if it was a local solver those gradients are bad training of the network. So that's one more thing. And then the last mention about this stuff a lot of these problems the solvers are not And because we're kind of as generic we're applying very, very and these kind of They don't really know about And so they're not fast. They're not exploiting the So we had a paper at by Frederike, where we for a class of problems a particular structure called actually make these So rather than variable in our optimization, in our problem. And we would assign one smaller You can actually then into a generic SDP solver And then it actually takes a lot Chordal problems are a little but most problems in the where you're matching have some motion model are chordal problems. But as soon as you have with a loop closure, you now anymore. So we're working at to improve this or reduce have to have a chordal problem. This is kind of what happens They're taking And they're turning it back into using a clique tree. And so we're kind of trying to about how we could speed that aren't originally chordal. That's all I've got. I made it all the way Thanks for your attention. I did all the talking. These people did all the work. And these people did all So thanks a lot. [APPLAUSE] Oh yeah, one more quick I'll just plug here is that Luca is leading an awesome handbook on SLAM. And I'm helping a little bit. And we just actually the first part of this. So if you're sort of to get into how SLAM works and hopefully this is going to be The fact that he is helping I think he's doing a lot of But thanks for mentioning. Thanks, Tim. Great presentation. We have time for Let's see. Yeah. Oh, thanks for I'm just wondering regarding-- I'm curious about the So you mean we this part could be Right. Yeah. So the idea with that-- attacking the ICP algorithm. So in that heat map it basically means that when and corrupt the point possible way at going to produce a final error exceeds some Oh, then can he exploit or pose graph optimization or some uncertainty? Yeah, interesting. We haven't thought about that. We thought about it more from So if you had a route that you were hotspots that were you might actually choose through the city to But I hadn't really as quantifying loop closure like that. Possibly. OK, thank you. [INAUDIBLE] from to get suggestions about like [INAUDIBLE] Yeah interesting, interesting. Yeah, I mean, I GANs are a thing. I suspect you could some kind of where you're trying to corrupt But you have some and the algorithm that's trying And they're playing Possibly. We haven't gone down Hi. Thank you for coming. My question is a bit more high you guys have been working with. Obviously, like the high quality ones can be I know those Ouster LiDARs of dollars, some of them. So my question is-- Tens. There we go. So in terms of these algorithms in I know for maybe something like they're willing But in terms of or scalable use for how do you anticipate this in the sense of trying to about how much money and making them affordable for Yeah, that's an So I guess there's a couple So one part is that most are prototypes. So you're not actually right now of what cost if they were being on every car on the road. The price is going to drop when you do that. Case in point is So most modern cars now, maybe not the very cheapest have automotive radars hidden And those were once But now, because they're on you can build that And so I think we can probably Like when I started working and probably others in the Now, they're $20,000. And we're still using And so the costs are going But it's a good question. If you were going to would you be willing to were necessary for autonomy onto For me, that wouldn't I like driving, so I probably surplus to have autonomy And that's basically what all If you want to do why most people are not for this stuff anymore. They're targeting robotaxis, where you can into the cost of the going to recover it because use, whereas personal vehicles, I suspect we're not on personal vehicles Well, thank you. And just a quick follow up, so do you anticipate that like if you look at where they're purely do you anticipate to shift towards trying to just like you were mentioning, go down In price eventually? OK. I have a bit of a specific so I really like LiDARs. What I'm kind of is that there's going to technologies. We're kind of already seeing it. One of the LiDARs I but it also looks like a camera. And another LiDAR that I but it also kind of because it's got What I'm kind of hoping is that will converge. And you're going to the size of my fist is going to produce high images with depth and velocity on every point. And it's all going to be solid because it's going to use for the actuation and so on. And it'll all just be And it'll cost like, I don't It's actually surprising. There's a LiDAR in my iPad. And it's a very small LiDAR. I don't know if seen these, the size of your thumbnail. What do you think that costs? Yeah, it's about like $3. And it produces a 64 point point low power. So I think we just have to wait. There's a Moore's that I think is in effect. Cool. Thank you. You're really out of time. But maybe if there is a quick By the way, I waited for the And it eventually did show up. So there's an existence proof. Thank you for the great talk. In your experience as what's most underappreciated doing field experiments? And what's the most challenging? Oh gosh. Yeah, we were talking a The first 10 years of did exclusively field robotics. And none of those So it's a little endeavor in many cases. The hardest part, doing the experiments in a way as anecdotal, like no if I were to do it I want people to thorough enough that the results and drew from the experiments And so that's hard, I think. If you're trying to compare have you designed a broad that you're going to give some to the A is better than I think that's So I'm not saying I have a Try to be as And I will just isn't exactly what are categories of for which you can write a paper tested a new algorithm. You've just really stress If you go to the IEEE there's a systems paper-- or sorry, a field report paper. Said it wrong, where you can actually just-- the novelty comes from the the algorithm so that you whether A was better are the limitations of And so there's some for doing really good field Data papers are another one. So it's not just always testing a new algorithm. Got to get a new algorithm. Got to get a new algorithm. I think we also just have to be Thanks. At the risk of abusing I think there is a request So last one. Make it fast. Thanks for your time. One quick question about what looks like in terms of where, methods are going of the handwritten or I think we're on a trend of software 1.0 getting And there's that Yeah, where are we there? And where can we be I'm just curious about we're at in that trajectory. Yeah, just one more [LAUGHTER] Yeah, I guess I was a I was talking But I took Jeff Hinton's neural And he taught me all and restricted And I was like, that's I'm going to go over And then now he has a And yeah. I mean, you got You started using Copilot to help write code. Like it's doing some It's not trivial. And so, yeah, we have to Does it mean we on all of these other things? I don't think so. I just think you have to find that stuff into what I guess I'm not really deep learn everything. I'm not really on Yeah, photons. Ooh, photons to atoms. I don't know. I'm not really on I still kind of believe where I sprinkle into the appropriate places, but Maybe I'll get to retire before All right, let's thank Thanks. Thank you so much. [APPLAUSE]