(calm swelling music) (dramatic upbeat music) - [Announcer] Please Adam Selipsky. (upbeat music) - Good morning and welcome I am so happy to be here, with more than 50,000 and more than 300,000 Thank you, thank you (audience applauding and cheering) That's right, thank you. (audience applauding and cheering) Now, we've always done this event just a little bit differently, and re:Invent remains above a learning event, and the opportunities to learn We've got more than 2200 sessions and you can connect with an in the expo, all around. And of course, there are many, with fellow members of the AWS community. So we've also got a great Yesterday, last night, diving into all of our And tomorrow we've got Swami as well as Ruba's partner keynote. And then of course Werner But I'm extremely excited in store for you right now here today. So let's get started. So one of the things is the sheer variety of the customers that I get to meet. I mean folks from every every use case, and there's And innovators all over the to drive their businesses, including leading enterprises Just to name a few, in financial services, we're we're working with Goldman Sachs, NASDAQ, Fidelity, Allianz, Itau, BBVA, HSBC, Capital One, In healthcare, we're working Novo Nordisk, Roche, Moderna, Illumina, Medtronic, 3M Health In automotive, we're from BMW to Stellantis, Nissan, Hyundai, Ford Motor and of course more. So many amazing customers and partners and still just a smattering of the leaders we're working with to shape the futures of these industries and all of the customers, One customer partner we've for a number of years is Salesforce. So in 2016, Salesforce chose AWS as their primary cloud provider, and today Salesforce uses data services, many others, to power key services and many others. And yesterday we announced that we're significantly to bring new capabilities Salesforce is gonna be It's already, you know, AWS will be using more and we're making it easier for developers to quickly build and deploy by bringing together Amazon Bedrock with Salesforce's Einstein platform. We're also helping to with our new zero-ETL integrations between Salesforce data compute and data service, so the customers can get And we're also building between Service Cloud from Also, for the first time, Salesforce is gonna be on the AWS marketplace, making it even easier for to buy and to manage Salesforce offerings. So with this expanded partnership, AWS and Salesforce customers to innovate and build applications, but it's not just global enterprises. The most promising up and comers also continue to choose AWS as well. According to PitchBook, there are more than a thousand with over a billion dollars in valuation. And the vast majority of unicorns, over 80%, choose AWS. Like Wiz, a cloud security Wiz is the world's largest and fastest SaaS company to Really amazing. Or Ultima Genomics, one of Fast Company's most And Ultima is revolutionizing by reducing the cost Or Plaid. Plaid's, a data startup like Venmo, Acorns, and Robinhood that millions of people are Customers of every size, organizations you might never imagine would rely on the cloud, I just recently heard a high-end, expert guitar maker, located in a tiny village in Ireland. And they're using AWS technology to create an electronic passport program that's going to ease the passage of their very special guitars, for musicians as they I mean all sorts of use Enterprises and startups, small and medium sized community colleges, government The cloud is for anyone. And our customers are serving critical needs, and dreaming up the They count on us to be to innovate rapidly, to and enable new ways to All on AWS. So why is all this happening on AWS? We are relentless about working backwards from our customer's needs And of course, we were the first, by about five to seven years, to have this broadest and that we still have today, and we're the most secure But we also think differently and their potential. And this has led us to to push through the barriers of what people thought was possible, so you can do the same. Reinventing is in our DNA and it continues to drive us every day. After all, this is how In the early days of we experienced firsthand how to provision and manage infrastructure, and how much of the undifferentiated that distracted really talented teams from really innovating. So we set out to rethink IT infrastructure completely with AWS, so everyone, even a kid could have access to the available to the largest and most sophisticated organizations. All on demand, all secure, all reliable and all cost effective. Now, folks got pretty excited about this, as they moved into the cloud, some even hosted data and posted videos of It was really, really fun. At least it was fun for us. So we reinvented infrastructure to optimize for scale, for from routers to cooling systems, And because we look at our global infrastructure from that of other cloud providers. And that is still true today. For example, the AWS global infrastructure spans 32 geographic and we've announced plans Each and every region consists of three or more And no other cloud provider provides that in every single geographic region. And this is critical. Within each region, the AZs by a significant distance up to 60 miles, or a hundred kilometers, and then they're interconnected that provides single Now each AZ is at least one with its own redundant power, water, networking and connectivity. So if there's a utility failure, human mistake, or even a natural disaster, the region remains operational Now, others would have you think that all clouds are the I mean, imagine if you by a single data center, or if you thought your in France for example, but it turned out that they're actually in the same location. I mean, one incident like a water leak followed by a fire could take for days. (speaking french) Having the broadest and the deepest set of capabilities matters. Like having three times compared to the next which makes a huge difference And having 60% more services than the next closest cloud provider. So you can innovate without constraints. We reinvent so that you can reinvent. Take storage, for example. So we certainly didn't invent storage, but we reinvented how people consume and scale storage in the cloud with our very first simple storage service. So back in the day, storage which could take weeks to provision and obviously had finite capacity. So S3 provided highly durable, highly performant object storage, that customers could scale And I remember talking about in 2006 on the day that it launched, and folks had a hard I mean, it was so dramatically lower than what they were used to. But we kept going. We added a whole lot of storage tiers, including S3 Glacier Deep Archive, which delivers archive storage at less than a 10th of But why should you have to even figure out which storage tier to use? So we built S3 intelligent by automatically moving data to the most effective access tier when access patterns change. Intelligent tiering has you ready? Over $2 billion. But it's just storage, right? (audience applauding) Here's to the savings. But it's storage, right, I mean, surely this can't be an area that's ready for more reinvention? Well, recently we've for your most frequently accessed and most latency sensitive workloads. Workloads that need high like financial trading fraud detection, and Now, these workloads access data up to millions of times and do require single And so today, what happens from S3 to custom caching solutions and then run analytics at these speeds, but managing multiple and APIs has a lot of complexity. So we looked hard at what Okay, are you ready for the (audience cheering) Okay, so today I'm excited to announce Amazon S3 Express One Zone, a new S3 storage class, purpose built... (audience applauding and cheering) Purpose built to offer and lowest latency cloud object storage for your most frequently accessed data. S3 Express One Zone uses and software to accelerate It also gives you the option for the first time, and you can bring your next to your high to minimize latency. So S3 Express One Zone supports millions of requests per minute with consistent single the fastest object storage in the cloud, and up to 10 times faster Now, the faster data up to 60% on your compute costs as well. For workloads that require the And the data access than S3 standard. So you can run these workloads So for example, with S3 Express One Zone, Pinterest has observed over while reducing their total cost by 40% for its machine learning powered visual inspiration engine. Now this is enabling them and personalization, improving So 17 years ago, S3 reinvented storage, by launching the first And with S3 Express one zone, to change how developers use storage. The same simple interface, same low cost, and now even faster. Let's look at another general purpose computing. So we realized almost 10 years ago that if we wanted to on price performance for we had to reinvent for the cloud era, all the And in 2018, we became the to develop our own general when we announced GRAVITON, our server processor chip. And customers loved the cost for scale out workloads like microservices and web applications, but asked for more. So we brought you GRAVITON2, which improved performance sevenfold for a wide variety of workloads, Our current generation GRAVITON3 delivers up to 25% better compared to GRAVITON2, and the best price performance in EC2. Importantly, it also uses 60% less energy for the same level of performance. And this is so important and that's compared to The energy efficiency is only Today we've got over 150 across the EC2 portfolio, and more than 50,000 customers, including all of the use GRAIVITON based instances to realize price performance benefits. For example, SAP, they've to actually power SAP And with GRAVITON, SAP is seen up to 35% for analytics workloads and aims to reduce their carbon footprint, their carbon impact, by an estimated 45%. Super impressive. We are relentless about innovation and we continue to push So today I'm excited to announce the latest generation of AWS GRAVITON4. (audience cheering and applauding) GRAVITON4 is the most powerful and the most energy efficient chip that we have ever built, and 75% more memory GRAVITON4 chips are 30% faster and perform even better like 40% faster for database applications, and 45% faster for Java applications. We were the first to develop and offer our own server processors. We're now on our fourth Other cloud providers on their first server processors yet. We're also announcing the preview of our first instance based R8g is part of our memory They're designed to deliver for workloads of process, like databases or real R8g instances provide the and energy efficiency for And there are many, many more Highly reliable regions durable, instantly leading price performance These are just a few examples to constantly deliver what you need to drive your infrastructure, your innovation, and your businesses. And for nearly two decades, we have been so intent on providing with the broadest and with the fastest pace of innovation, the most reliable, the And of course the largest and of customers and partners. And these advantages are always relevant, but no more so than today because they're also the foundation for reinventing with generative AI. Now here too, you're and deepest capabilities, and the security and you need at all. Amazon's been innovating We use it across the company, to optimize things like our to create better retail to deliver new experiences or our 'just walkout' shopping technology. GenAI is the next step in and it's going to that we interact with at work and at home. We're ready to help you because again, we think to meet your needs, and And because we're intimately to reinvent ourselves, we with your reinventions. From startups to enterprises, organizations of all with generative AI. They wanna take the momentum with early experimentation and turn it into real and innovate, innovate, innovate. So we think about generative AI as having actually three of a stack, and they're And we are investing in all three of them. So the bottom layer is used and large language models, and to run these models in production. The middle layer provides and other foundation models that you need and all the tools that you need to build and scale generative AI And then at the top layer, that are built using Fms, so of generative AI quickly, without even needing any So let's look at the bottom So with the foundation models, there are two main types of workloads, training and inference. Trainings to create and prove Fms, by learning patterns from And inference uses that to to generate an output such And these workloads of compute power. So to make GenAI use cases you need to run your training. You need to run your inference cost-effective infrastructure for ML and AI. Now GPUs are the chips that of mathematical making them popular for from ML, simulations, 3D rendering. And we've been collaborating to bring GPUs to the cloud, building compute instances that support a wide range of use gaming, HPC, machine learning, and now of course demanding In 2010, AWS was the first to with CG1, or the cluster GPU instance. Then we were the first with our P3 instances. And then we were again, the first to offer the with our P4 instances in production. And earlier this year, yes, we were the first major cloud provider to bring NVIDIA H100 GPUs to market with our P5 instances. And the P5s are providing for training they're and 40% less expensive than P4s. Now having the best chips but to deliver the next you need more than just the best GPUs. You also need really high that are running these GPUs. Our GPU instances can be and they're interconnected with up to 3,200 gigabits per second of networking through our elastic And this enables customers in a single cluster, providing up to 20 exaflops which is equivalent to a supercomputer. And all of our GPU instances that are released in the last six years are based on our which reinvented virtualization and networking to specialized chips, so that all of the service to running your workloads. And this is not something that other cloud providers Now with Nitro, this delivers performance but at a lower price. And the Nitro system also that continuously monitors and protects and verifies the instance are all robust. We've worked closely with NVIDIA and our virtualization to bring our GPU instances to customers. And today I'm thrilled to announce that we are expanding our with more innovations the most advanced infrastructure for generative AI workloads with GPUs. And I'd like to invite Jensen Huang, founder and CEO of NVIDIA, to tell us more. (audience applauding and cheering) (upbeat dramatic music) Jensen, so good to see you. - I'm thrilled to be here. - Yeah, thank you so much It's amazing. So, as I've just discussed, so we've got a long partnership, AWS, NVIDIA have been doing I'm so excited about how You and I were talking collaboration's amazing. It's been happening for a lot of years, and I'm just thrilled to - Thank you, it's great to be here. I'm thrilled to be here to celebrate the amazing work of our two teams. And to help announce You know, we've been working In fact, AWS was the world's first cloud to recognize the importance and you put the world's a long time ago. And since then, this is in the last several years alone, just for the Ampere and Hopper generation, we've put up, deployed that's three zettaflops, - [Audience Member] Whoop. - Yeah, exactly. Most nations will be happy with AWS has 3000 of them, and I'm delighted to see that we a deployment of a whole the L4, the L40S, and the brand new H200. The H200, this is really an amazing thing, the combination between the brand new TensorRT-LLM optimizing and H200 improves the large language model reducing the cost in just Now our collaboration starts and we're ramping so incredibly fast, each quarter we're more than one zettaflops more in AWS, one zeta flops more each quarter. It's an unbelievable number. And all of this is of because of the accelerated Our two teams stood up a whole but we're also bringing the NVIDIA AI stack, our NeMo LLM, large language model framework, the Retriever inference model for RAGs. Our BioNeMo, digital biology, large language model foundation models, Isaac Sim on Omniverse for robotics. This is something that Amazon Robotics uses to simulate its robots, and it's incredible Just all of these stacks, we're gonna integrate into AWS. So our two teams have - Busy indeed. And that was a lot of (Jensen laughing) Yeah. So, as you said, the collaboration's to access amazing technology, and they're gonna need it to Now, one of the big is that AWS is gonna be, you to bring the latest NVIDIA with a new multi-node NVLink And maybe you could tell us and what makes that computing and how we're working - Well, we're both really And the reason why Arm is so incredible is because we can mold of computing needs that we have. It's incredibly low energy, And so Grace Hopper, which is GH200, connects two revolutionary in a really unique way. It connects them together using called NVLink, at one terabytes per second. And it's connected in a coherent way, so that the GPU could access the CPU can access all And so the two of these in a really fast way. The second thing that we did of extending NVLink to So now 32 Grace Hoppers could be connected by a brand new NVLink switch, and that becomes one unit. And with the Nitro, AWS Nitro, that becomes basically one I mean, you gotta imagine incredible horsepower, because of AWS Nitro. And then we connect it with AWS EFA, your incredibly fast networking. All of these units now can an AWS ultra cluster. So I can't wait to see - I mean, it's really an I mean, how customers one can only imagine. I know that the GH200s are what customers are doing. It's gonna be available, of course in EC2 instances coming soon. Now, in the world of a lot of companies are into their business, and it's great to see the infrastructure, but it extends to the and all of the other So this leads of course to the second big announcement we have today. So partnering AWS NVIDIA to bring the NVIDIA DGX Cloud to AWS. And I'd love to hear a little bit about how the DGX Cloud's an important - Well, first of all, DGX This is how our researchers advance AI. We use AI to do neural graphics. The way we do computer graphics today is impossible without AI. We use AI to advance, to advance our digital biology models. Our large language models, for self-driving cars. We use it to simulate Earth-2, a digital twin of the earth to And so DGX Cloud is We are incredibly excited to NVIDIA has ever built. We're gonna announce inside our company, we call it Project Ceiba. Ceiba, you all probably know, since you're at a AWS conference, is the largest, most We call it Project Ceiba. Ceiba is gonna be sixteen thousand... Sixteen thousand three connected into one giant AI supercomputer. This is utterly incredible. We will be able to of the largest language models, these large, extremely large and be able to train it Essentially reducing the cost of training, in just one year, in half. Now we're gonna be able multimodal MoE models, these next generation These 16,000 GPUs will be 65 exaflops. It's like 65 exascale And so I can't wait for Our AI researcher's chomping at the bit. Now of course, this is also with partners and customers who need to build custom AI models. You know, it's great to be able and there's gonna be a whole in public clouds. It's gonna be available in SaaS companies, for example, Salesforce that you mentioned earlier. They'll have all kinds of and generative AI models. But a lot of companies need to build their own proprietary models. And so we set up the AI factory so that we could partner with them, to help them create their custom AIs. And now it'll run all on AWS, collaborate with our customers on AWS, connect them all to your security services, and all kinds of other and then deploy it all in AWS. So we're gonna be able to do - It's all amazing. I mean, you guys have You know, we've been working hard, to see us come together even more tightly. I mean, it's just gonna to customers who are really gonna need it. But we appreciate the collaboration, appreciate working with you and look forward to a lot - Thank you, Adam. thank you, Jensen. - Have a great show, everybody. (dramatic music) (audience applauding) - It's been a great partnership. We've really appreciated it. Now let's talk about capacity, or actually getting access to So customers who wanna often need large amounts of It has to be together, or in clusters. But they don't necessarily of it all the time. For example, customers training a model, I mean, they might stop to or make other changes, and then they want to do more training. So what this means is that short term cluster capacity. And it's something that really no one, no cloud has been addressing. Until just a few weeks EC2 Capacity Blocks for ML. And EC2 capacity blocks for in the industry, that enables any customer to reserve the highly sought after GPU capacity to run for short duration And this eliminates the need hold to capacity that they're using, just so they can be certain if they need to use it later. Now, EC2 capacity blocks are interconnected with our EFA networking that we talked about this morning. And that enables customers to in a single cluster So with the capacity for their ML workload and they know that they're when they need it, and Now support for the latest generation, high performance GPUs, you know, combined with our networking, cluster management, these are reasons why to run GPUs in the world. But to drive innovation that our customers want in ML and AI, we realized a few years another place we'd have to innovate all the way down to the silicon, just like we did with GRAVITON for general purpose computing. And that's why we built So Trainium is our purpose-built chip for training machine learning workloads, machine learning models. And Inferentia is our inference on those models. So earlier this year, we already announced the second generation of our Inferentia chip, Inferentia2. And because we optimized for inference, the two instances, which offered the best, lowest while also delivering up to and 10 times lower latency Customers like Adobe, they've all seen, you And they are, you know, deploying their generative with Inferentia2. We've all seen a lot of Our Trn1 instances, powered by Trainium, have been deployed by a lot of customers, including Anthropic, partners And our own Amazon search to train large scale deep learning models. They're taking advantage of scale reliability and low cost. But as customers continue to on larger and larger data sets, we realized we needed to keep pushing, pushing on price performance. We're never done there. And today I'm really excited to announce AWS Trainum2, our second generation. (audience applauding) It's our second generation for high performance training Trainium2 is designed to deliver up to four times faster performance compared to our first generation chips. And that makes it ideal for with hundreds of billions, or Trainium2 is gonna power of EC2 ultra clusters, and will deliver up to 65 And we expect the first are gonna be available next year, and we are really excited to see what customers are gonna do with them. Meanwhile, a lot of other cloud providers are still just talking We've also made a lot of exciting progress in building the software tool chain that supports Trainium and Inferentia. So AWS Neuron is our that helps customers get maximum Neuron supports machine like Tensor Flow, PyTorch, with JAX support coming really soon. And so customers can use to build training and inference pipelines with just a few lines of code. And Neuron supports the including 93 of the top 100 and counting. Importantly, you also need the right tools to help train and deploy your models. And this is why we have Amazon SageMaker, our managed service that makes it easy for developers to train, tune, build, manage machine learning In the six years since we've introduced a lot like automatic model tuning, flexible model deployment, and built-in features like responsible AI. SageMaker has been instrumental for tens of thousands of AI21 Labs, Thomson Reuters, AstraZeneca, 3M Health Information And SageMaker can train models with up to billions of parameters. For example, TII has trained the 180 billion parameter Falcon FM, which is the world's largest on SageMaker, using 3000 GPUs, and petabytes and petabytes And you can also deploy this We've also been working to support their models on SageMaker, and have collaborated to create the Hugging Face AWS to help accelerate training using SageMaker, Trainium and Inferentia. So if you're building your own models, AWS is relentlessly focused the best chips, most powerful petabit scale hyperscale clustering and the But of course, an enormous just want to be able to access the most powerful models out there. They wanna get started quickly, experimenting with different FMs, and testing different use cases, and to meet the enormous But they also have questions like, which model should I even use? And how do I decide which How can I move quickly to build and deploy generative AI applications, and how can I keep my That's why we're investing in that middle layer of the stack. Now we know that many of to access a powerful and LLMs, other foundation models, and then to quickly build all the time maintaining And that's why we built Amazon Bedrock. So Bedrock is the easiest generative AI applications for LLMs and other foundation models. And customers in every industry to reinvent their user experiences, their products and their processes. And to bring AI into the So why Bedrock? So first, you enjoy the the many of which are available first, or in some cases only on Bedrock. You can add your own easily and privately with of customization options, and you get enterprise because we designed it And the customer excitement's We made the service generally and now over 10,000 customers are using Bedrock around the world, across virtually every industry. Adidas is enabling developers to deep technical questions. Carrier is using Bedrock to predictive analytics, systems alerts, and data trends to And these are helping customers reduce their energy consumption NASDAQ is using Bedrock to automate investigative workflows on suspicious transactions, and to strengthen their and surveillance capabilities. So many more, including Cox Automotive, GoDaddy, LexisNexis, Merck, Omnicom Group, They're all using it to build But it's still early days. Everyone's moving fast, and at the same time, the is evolving quickly, with new developments And customers are finding that different models actually work better for different use cases, or on different sets of data. Some models are great for summarization, others are good for and still others have And then there's image generation, search use cases and more. All coming from both proprietary models, and models that are publicly I mean, things are moving so fast. And in that type of environment, the ability to adapt is the that you can have. There's not going to be And there's certainly not providing the models that everybody uses. So you don't want a cloud provider who's beholden primarily You need to be trying You need to be able to even combining them And you need a real as you decide who's got but also who has the dependability that you need in a business partner. I think the events of the past 10 days have made that very clear. We've been consistent for the whole history of AWS, and that's the approach when we started talking about almost a year ago. And that's why we continue to innovate, to make building and of foundation models Today, Bedrock provides access from leaders like AI21, as well as Amazon's own But we didn't stop there. We were the first to make through a fully managed API. And we also recently announced our expanded collaboration with Anthropic. So Anthropics, a longtime AWS customer and one of the world's leading Their model is Claude, and they got others as well, excel at a wide range of tasks from sophisticated dialogue and to complex reasoning and So as part of the collaboration, Anthropic is gonna use to train future generations And Bedrock customers are not available in other for model customization and So to dig in on what we're I'd like to bring out our partner, Dario Amodei, who's the CEO Let's give him a hand. (upbeat dramatic music) Great to see you, all right. Oh, we have chairs, let's sit. Dario, thanks for being here. - Thanks for having me. Earlier we talked about how Claude is available on Bedrock, but before we dig into that, let's just talk a little bit and what makes Claude so unique. - Yes. So Anthropic was founded on the idea that we can make AI models and steerable while still The founders of Anthropic who worked at OpenAI for several years. We developed ideas like GPT-3, reinforcement learning scaling laws for language behind the current generative AI boom. Seven of us left and founded Anthropic. Our foundation model Claude, in addition to being safe and reliable, excels at a lot of knowledge work tasks like content generation, complex reasoning, things like that. We have an industry leading context window of 200K tokens, that's which makes it well suited for areas like legal, finance, insurance, coding, things like that. And about half of the Fortune 500 are using, or are testing Claude. - So amazing progress. So just a few months ago, obviously Amazon and Anthropic announced kind of an enhanced Anthropic named AWS as for mission critical workloads, and you're gonna be training, and deploying future generations of Claude and foundation models on AWS. So just tell us a little bit what led up to this and how that relationship - Yeah, so, Anthropic's use of AWS goes back to our early history. Back, you know, all the way - Way back. - [Adam] I mean who can - We trained our first model on AWS, and so we're excited now you guys are our primary cloud provider for mission critical workloads. I would say the partnership First is the compute side, which we've been doing, you know, throughout our history. The second is on the We're very excited to We really recognize the to customers working together. And the third side is the hardware. We're currently working with you guys to optimize Trainium and and hopefully for other use cases. And we really believe that we can achieve that four x faster than the that you just announced, you know, if we optimize these things together. And so putting together layers of the stack, really to customers, together, that Things like customization of and unique fine tuning features. - Well, it's a... The respect we have for you I mean, truly world-class expertise for the Anthropic team. I've really enjoyed working together, and you know, the models So obviously we are aiming to, and I think are in the incredible array of customer experiences through this collaboration. And of course, our own Amazon to Anthropic models on Bedrock And we're not only working to but we're giving them early access to unique features that they're anywhere else. And we're out there together, with our generative AI innovation center, working with customers in the field, helping them to actually get targeted. And that's allowing us, of course, to bring this expertise, and the domain specific expertise that they need to customize the models. And as we've been out there together, and it's been hot and heavy, particularly the past, but before that as well, what are some of the most that you've seen? - Yeah, so I'll give three examples across different industries. There's, there's many others, but this should give a sense of the range. And, you know, we've seen One example in the biomedical space, we're happy to announce I'm a former biologist for any way AI can advance medical science and, you know, bring lifesaving drugs to people around the world. In the legal space, we made deployed it through you to help with their legal search, you know, in a way and produced citations. And in the finance space we're working with Bridgewater Associates to develop an investment Beyond that, you know, just some examples, we've engaged with seven outta 10 of some of the largest and banking industries, and, you know, could tell similar stories about other industries. So, you know, we're excited and where all of this goes. - That's incredible momentum. Just the financial services with that many leaders. So just last week, you're So, just last week you so that's got a whole and key capabilities. Maybe you can tell us a - Yeah, so Claude 2.1 really, that's targeted at enterprises. So a few different features. One is we've doubled our context Tokens is a term of art in the AI space. What it amounts to is about 150,000 words, which is a relatively long book. And so use cases like reading the entire long book, and one of my favorites, putting multiple documents and asking the model to A second feature is that of so-called hallucinations, that aren't true by about two x. We've seen across the industry, a core obstacle to deployment is people are worried that models will say things that aren't true. No one has perfectly solved this problem, but we are really leading the way in getting more and more reductions. And then we also have some beta features. We're introducing system prompts, and a developer workbench. Again, all tools targeted at people building for enterprises. We're excited to see all the use cases that emerge from this. - I'm speechless. That is such incredible progress. You talked about the really important topic. You know, just more broadly, that AI should be, you know, and benefit society. And we've been engaged a lot of groups and organizations that are and deployment of responsible AI. In fact, I keep bumping into Dario around the world at some of which is nice. So I know this is a And can you tell us a Anthropics work in this area? - Yeah, I mean, you know, we were founded on and You know, I would where we've done work in this area. One is the way we design our own models, and the other is the way for the ecosystem, and bring others along, so that ultimately everyone So large fraction on the of our research org works on safety. We've put a lot of work into, you know, making our models hard to break, making them secure against There was a recent study where people tried to adversarially and it found that they were able to successfully break Claude than they were able to break So, there's a real difference here. (audience applauding) Second, we've put a lot of seen inside the models. There's no commercial but it's been a long that relatively soon for both compliance and for understanding what models do, and therefore reducing bad we'll be able to make a lot of progress. On the wider ecosystem, you know, we always try to do something, and then competitors, other players in the and do the same thing. An example of this is a where we front loaded of model scaling, a kind of like what's done for cars and airplanes. And in the policy space for governments to build up their ability to evaluate and measure AI systems. If we're not able to we'll get either no regulation or poorly informed regulation. We need to all work together to make sure that we can develop quickly, responsibly, but in a way that's secure. - I just love the concept It's so positive. And what you're doing is so amazing. I mean, we've said it the whole 17 years that AWS has been providing so much of what gives us the coolest, most cutting and entrepreneurs in the world. And there is just no better in generative AI now and So it's great to be and really appreciate you - Yeah, excited for - Thank you. All right. (upbeat dramatic music) Alrighty, so amazing. Thank you so much again, Dario, for coming out and joining So the innovation around and we really look forward to working with all of our Bedrock Incredibly innovative space. And we're also excited about and other foundation models that we're building ourselves at Amazon. So our Amazon Titan models were created and pre-trained by AWS. And we are building to bring actually a few So we do have a lot of expertise here. I mean, Amazon has been got a long track record. We use the technology across our business, and we've learned a lot about And as a result we can provide that offer really powerful capabilities, and also great economics to support a whole bunch of use cases. And we carefully choose and the data that we use to do so. And we're actually gonna that our models, or their outputs, infringe on anybody's copyright. Now they're already multiple We've got Titan Text Light, which is ideal for text-based We've also got Titan Text Express, which is great for more like copy editing, copywriting. And we've also got the for search use cases or personalization. And we're gonna continue adding And if you're interested in that, then I highly recommend you tune in to Swami's keynote tomorrow. A little word up. Now all of the foundation models that I've been talking about, and they all enable a lot But to really drive your that understands your business, understands your And that's only possible to improve and customize the models. The models have to become unique to you. So Amazon Bedrock is giving you all of the purpose-built to customize the AI So with a few clicks you can to ones that are highly So one important technique Now with fine tuning you point the models to examples of data in S3, that you've labeled, labeled to provide context. For example, you might point to proposals, and you've labeled some of So in this way the model learns from you, learns from your data, what And then Bedrock makes a it trains it, it creates a private fine tuned model, so you get tailored responses. So fine tuning is available in Amazon Titan Text Lite and Express. And today it's also generally available for Cohere Command Lite and Meta Llama 2. And fine tunings coming (audience applauding) So a second technique for for your business, is called retrieval Another one of the terms So RAG allows you to when you want the model or up-to-date information. So Bedrock does this for you by calling and bringing back your own data, your data from multiple sources, including document repositories, databases and other APIs and more. So for example, the model might use RAG to retrieve search results from our Amazon OpenSearch Service, or documents from S3. In September we introduced called Knowledge Bases, that connects FM to your to supplement your prompts And today knowledge basis (audience applauding) All right, thank you. Alright, now, a third way inside of Bedrock is a technique called So continued pre-training is a technique that uses large amounts of unlabeled data, before you fine tune Here's unlabeled data, like the raw text of internal reports, financial plans, or research And that's gonna be used to and its reasoning capabilities, using things in your own specific domain. So continued pre-training is of course available in Bedrock today. Now all of these techniques, they're all powerful tools in making it truly useful for your business. And Bedrock makes it really easy to combine these techniques together. So a great example of a to customize their is Delta Airlines. So Delta's actually modernizing its customer service built on Amazon Bedrock. The new tool is gonna be in a more relevant and by accessing Delta's travel policies, realtime flight schedules, and airport conditions. So for example, it could like, how many bags can I And it can also do more can I carry my cat with me Of course, what else are Delta's been testing with different foundation including Anthropic Claude and a fine tuned Amazon And in this way they to answer different customer questions. It's really powerful how they can combine the most relevant information needed to answer any specific question. Now with the new customer service tool, Delta Airlines is aiming and conversational and it's gonna improve So everyone wants more relevant right? And Bedrock's making it a lot easier to customize those applications But at the end of the day, you want FMs to do more than just provide useful and targeted information. Ultimately, what you're to take action, to And we wanted you to to complete actions like booking travel, filing insurance claims, maybe ordering replacement parts. And this usually requires orchestration between multiple systems that And that's why a few months ago we introduced Agents for Bedrock. And today I'm happy to announce that this powerful feature (audience applauding) Now with Agents, GenAI multi-step tasks across company from answering customer questions about product availability, to taking a sales order and more. And building with Agents is really easy. First, you use Bedrock Setup Wizard to select the appropriate model. Then you give the model basic instructions to help the model like you are a friendly who helps customers return items. Next, you specify the lambda functions that execute the API calls that's relevant to the task. For example, return policies, And finally, you select the data sources. Then you just select 'create agent' and Bedrock configures your When the agent receives a request, it uses its reasoning capabilities to analyze and to plan the task. And the model works out the information needed, the APIs to call, and when to call them. Then it executes the plan, taking all the steps that it and then complete the task. All in the background. No need to engineer prompt, no need to train the FMs. No need to manually connect systems. With agents, generative AI is becoming an integral part of your business, making it easy to take No heavy lifting required. So we've talked about how to choose amongst leading models. And also how it gives you to customize your with your own data. And how it can help into your organization and your API to actually take action. But you won't actually use if it isn't secure and private. I mean, you demand the same the same security for generative AI, that you do for any workload. You really need this to have than everything you expect It's just like S3, EC2, RDS, Bedrock has got to have to make your data safe and private. And that's what it has. Bedrock customers can trust that their data remains protected. No customer data is gonna be used to train or improve the When you tune a model, we make we put it in a secure Your data's never exposed never leaves the AWS network. It's securely transferred It's encrypted in transit and in rest. And Bedrock enforce the you have with any of our other services. Bedrocks also supports a It's HIPAA eligible, it can be We've added a bunch of other security and governance capabilities, including integrations with CloudWatch, to track usage and metrics, CloudTrail, to monitor API activity and troubleshoot activity. And today Bedrock is SOC compliant. Now this helps ensure that customers can have strong controls and helps it be used in every business. Now beyond security, we need generative AI to be deployed in a safe, trustworthy, and responsible fashion, like we were talking And that's our North Star. And the capabilities that make GenAI such a promising tool for innovation, also do increase the potential for misuse. We've got to find ways to unlock generative AI's full potential while mitigating the risks. Now dealing with this unprecedented collaboration in a truly multi-stakeholder effort, across technology community groups, scientific We've been actively participating that have come together Earlier this year, I and other industry readers like Dario, as he announced that we've made a series of voluntary commitments to and the transparent And just this month I joined for his AI safety summit, to discuss new approaches of their new AI safety institute. Now, an important component is promoting the interactions and the applications that are safe, that avoid harmful outputs, and that stay within your And the easiest way to do this is to actually place limits on what information the And we've been working hard here. And today we're announcing (audience applauding) Now this is a new easily safeguard your with your responsible AI policies. To create a guardrail Bedrock provides configuration wizards. You can enter and enter a of the topics that you Guardrails can be used with accessible via Bedrock, including the custom through your own fine tuning. And you can also use So now you can have a across all of your GenAI For example, a bank could to refrain from providing Or to prevent inappropriate content, an e-commerce site could ensure doesn't use hate speech or insults. Or a utility company could remove personally identifiable from a customer service call summary. So we're approaching the in a fundamentally different way, because we understand what it takes to reinvent how you're going Just as you've used AWS to reinvent how you've built and innovated for years, and ultimately to transform Whether you're migrating building the next hot startup, or deploying your generative AI strategy, our approach remains the same. Customer obsession, innovation, of what joint success really means. To tell us more about how and is now reinventing with generative AI, please welcome to the stage Lidia Fonseca, the Chief Digital and (audience applauding and cheering) (bright uplifting music) - Hello everybody. (audience applauding and cheering) I'd like to start by asking, how many patients do you think You may be thinking in the millions, but in fact we treated with our medicines and vaccines. That's one out of six A truly humbling accomplishment. And we're grateful to be and ethical company, listed in Fortune's World's Forbes' World's Best Employers and Time Magazine's Pfizer is experiencing an exciting period of innovation and growth, with the launch of 19 medicines This has never been done, by us, or any other pharma company. It is an incredibly ambitious goal. And we are well on our way, Digital data and AI are And what differentiates Pfizer is that we apply this our 36 plants and the 149 quickly and at scale, to bring medicines to patients faster. Our success today rests on the groundwork we laid for technology and AI to flourish. Centralizing our data, creating standard platforms, and building a secure foundation, all to innovate for maximum impact. We could not have achieved without our close relationship with AWS. So let me share a bit In 2019, Pfizer and AWS created a pioneering scientific data cloud that aggregates multimodal data from hundreds of laboratory instruments, empowering our scientists to search all historical in real time, compared to weeks or months in our prior fragmented environment. And the scientific data and computational research. And with AI algorithms that the most promising new molecules. Building on that success in 2021, Pfizer embarked on one of going from 10% of our moving 12,000 applications One of the fastest migrations This move to AWS saved and helped us exit three data centers, reducing 4,700 tons of CO2 emissions, or the equivalent energy use But very importantly, it enabled and at scale. For example, we reduced time from months to hours, speeding up data generation And when Covid hit, AWS was one of the first scaling us into the tens of thousands of additional cores in the cloud. Accelerating manufacturing When we ran computationally to understand how to AWS jumped in with additional And when we needed to submit AWS increased our capacity, enabling Pfizer to move In fact, it took just 269 days, from when we announced a COVID-19 vaccine with BioEn Tech, to the day that we received the FDA's emergency use authorization. This normally takes eight to 10 years. (audience applauding) Thank you. With the world waiting, and distribute the vaccine We held firm to our Well, science did win and Pfizer's industry leading allows colleagues to see and resolve issues in real time, yielding a 20% throughput increase, our mRNA prediction algorithm yielded 20,000 more Imagine the lives impacted. To give you an idea of the scale, prior to Covid, Pfizer produced 220 million vaccine doses in total and scaled to 4 billion This is now at the heart and we're applying these innovations to our other medicines and vaccines. More recently, AWS helped us supply AI to generate alerts about potential prompting us to reroute shipments to continue delivering medicines ahead of Hurricane Ian's landfall. Digital and AI make it possible for Pfizer to bring medicines to faster than ever before. Now let's look at what's next. As you heard, Pfizer to drive innovation and More recently, we are which is estimated to of 750 million, to a billion Real tangible value. Using AWS cloud services, Pfizer quickly deployed VOX, our internal generative AI platform, allowing colleagues to available in Amazon Bedrock and SageMaker. AWS's breadth of services and the variety of LLMs in the best tools for use cases marketing and more. Enabling Pfizer and AWS to prototype 17 different use cases AI and generative AI will help us identify new oncology targets, a process that is largely manual today. With AI, we can search and scientific content in a fraction of the time. And algorithms generate and validate potential targets to improve our scientific success. With Bedrock, we can scan the marketplace for companies and assets, automating the creation to prioritize potential acquisitions. In manufacturing, Bedrock takes the optimal to identify what we call the golden batch, and uses generative AI to detect anomalies and recommend actions to aiming to improve cycle time by 25%. AWS's agile culture aligns well with Pfizer's light speed way of working. We look forward to to understand not just how AI but how they help us disrupt the industry. To close, we're excited to accelerate our battle against cancer, with Pfizer's proposed a biotech focused on cancer therapies. We plan to bring Seagen's leading edge antibody drug conjugate technology to more patients with cancer faster. You see, we hope to achieve with cancer what we were able to achieve with Covid. Our work with the AWS this great momentum, fueling our ambition to change a billion lives every year, not just in a pandemic year. Thank you AWS for helping to patients faster, because in the battle against disease, time is life. Thank you all. (audience applauding and cheering) - One out of every six are impacted by Pfizer. I mean, that is just so Lidia means so much to us, to help deliver all these capabilities, these breakthroughs that Thank you very much. - And thank you, Adam. AWS has just been a amazing partner. - Thank you. We look forward to more. (dramatic music) - So organizations across for agility, for speed, and for the scale that they But this requires employees And we know that not enough and that there's a large skill So generative AI is of course the next incredibly exciting new opportunity, but it's only gonna add to that gap. And so we're investing to that are gonna be needed across AWS is committed to training with cloud computing And we're well on our way with (audience applauding) And we just recently launched which is providing deep cloud expertise to help students launch And we've also launched a hundred and AI courses and resources And just over a week ago, which is our new commitment to another 2 million people by 2025. And to help students around the world to learn the foundation skills and to prepare for a career in tech, we actually created an AI and machine learning scholarship fund. Let's meet some of the recipients. - [Vani] My name is Vani Agarwal. - [Jose] My name is Jose Tapia. - [Olympiah] My name is Olympiah Otieno. - [Jose] Without the AWS I wouldn't have been able know what tools are - [Vani] The Nano degree my interest in AI. I constantly try to go out there and talk to girls who are - [Olympiah] In Kenya the rates at which the is devastating. So my colleagues and I have With AI, farmers prevent the The fact that I was able I now know that I am capable (audience applauding) - I mean, this is why But we're actually lucky enough here with us today. So come on, let's give (audience applauding) There we go. (audience cheering and applauding) To both of you, I'm so proud. I'm really proud of And I just really hope is just a great, great experience for you. Thank you so much for letting And for everyone watching, to build and to have that kind of impact. And we see a huge opportunity to help that by infusing generative AI that people are using We believe that generative AI seamlessly with helpful, whether or not you know the first thing about foundation models, RAG or any of the rest. And that brings us to The applications that by generative AI, leveraging We believe that generative AI, of course, has the potential over time to transform virtually every customer experience that we know. It can pour through the nooks and actually help you find data that you didn't even know existed. And then help you put it to optimal use. It can generate insights that and it can take projects that were slogs and make them a snap. Now, one important example is how generative AI can radically faster. And so last year we released which helps you build generative AI, which helps you build faster and more securely by in near real time. Now with CodeWhisperer, developers use a natural language prompt and then receive accurate code suggestions in every popular IDE. And for 15 of the most A CodeWhisperer gives for general code examples. And of course, we made for providing specific Customers, including Warner and the Cigna group have to accelerate their And Tata Consultancy Services, Accenture, and HCL Tech are making to tens of thousands of employees each. Now KONE, a global leader in the elevator and escalator industry. They actually believe that CodeWhisperer is a game changer for them. We want as many developers as And so what we've done to make the code suggestions in it free, free for individual use. Now the recommendations in CodeWhisperers are great for general coding tasks, but general coding suggestions can only get your developers so far. Imagine you've just hired a new developer. Even if they're world class, they're not going to do their best work until they understand your code base and your internal best practices. And AI power coding tools are similar. You can have a great tool, and relevancy that makes your solution has to understand And the best place to find that context, is inside of your internal and your packages. That's why a couple months that allows CodeWhisperer to securely learn from to provide much, much more and useful code recommendations. And with customizations, CodeWhisperer is an expert on your code, and can provide much more creating an understanding of your languages, and your classes. And of course, any We never use customer's to train any of our underlying models. Now to understand the impact we worked with Persistent, a Now, their studies showed that developers using CodeWhisperer an additional 28% faster with 28%. And AWS is the only major cloud provider that's currently authorizing offering a customization capability and use today. And we are really excited about CodeWhisperer customizations, and how it's gonna help and increase your impact. But we're just getting started and we see a lot more potential For example, think about So these days it seems is experimenting with them, right? And what the early providers is really exciting and it's genuinely super But in a lot of ways these at work. I mean, their general knowledge and their capabilities are great, but they don't know your company. They don't know your data, your customers, or your operations. And this limits how useful They also don't know much They don't know your what information you use, and what you do and don't have access to. So critically, other providers they've launched them without data privacy and security capabilities, that virtually every enterprise requires. And so many CIOs actually banned the use of a lot of these most inside their organizations. And this has been well publicized. And just ask any chief or CISO, and they'll tell you, you can't really bolt on and expect it to work as well. It's much, much better to build security into the fundamental So when we set out to build we knew we had to address these gaps. Had to be built in from the very start. And that's why today I'm really proud and excited to announce Amazon Q, a new type of generative designed to work for you at work. (audience applauding and cheering) Q lets you answer questions quickly, with natural language interactions. You can easily chat, generate that's all informed by an your data repositories, your operations, and of course we know security and privacy are, so that Q understands and your roles and your permissions. If a user does not have permission to access something without Q, they cannot access it with Q either. And we've designed Q to meet enterprise customers' stringent And we never want business we're never gonna use that content for Q, to train underlying models. I really believe this is We want lots of different kinds of people, who do lots of different kinds of work to benefit from Amazon Q. Now, as you might expect, and builders be more efficient, more knowledgeable, and more proficient. So for starters, Amazon Q for building on AWS. Now to supercharge work we've trained Amazon Q on 17 years worth of AWS knowledge, so it can optimize and operate applications And we put Amazon Q where you work. So it's ready to assist you and documentation, in your And in your team chat rooms like Slack. You can chat with AWS Q to learn unfamiliar technologies, It's an expert in AWS best practices and For example, you could ask Amazon Q, how do I build a web application with AWS? What are my options? It's gonna answer with a that you could use, such as Amplify, Lambda or EC2. And then it's gonna offer reasons why you might consider each service. From there, you can further through natural language, like which of these would be preferred if my app only needs to and only has very infrequent traffic? Lambda. Amazon Q's gonna take your and it's gonna provide you with the best possible recommendations. And once you've chosen a service, you can ask Amazon Q, And Q's gonna give you for configuring the solution, plus links to relevant information, to documentation and so on. And this is just the is gonna help you with your work. For example, if you encounter in the console, you just press the troubleshoot And Q is gonna research the error, and it's gonna suggest how to fix it. Amazon Q can also troubleshoot It can analyze your end-to-end and help resolve That is a huge time saver. Now what else can Q help us with? How about choosing the So you can just tell and get an accurate, quick and economical instance type recommendation. For example, which EC2 instance types provide the highest and transcoding workloads And you get your This is all very cool, and we expect that Amazon so much time in architecting and optimizing your workloads. But that's not all the Q can do for you. Amazon Q is also gonna be If you're unfamiliar or you need to dig in into Amazon Q and CodeWhisperer is by using its deep knowledge of AWS, and its understanding of your code bases. So you need to add tests, just ask Q, and it's gonna automatically And this is gonna make a huge But we knew we could do even more to help you build even faster. For example, think about everything that goes into building a new feature. You have to understand write all the code, add tests, And a file could spend hundreds, to even thousands of lines of code. And this is a daunting task. If you're using Amazon CodeWhisperer, it's gonna generate chunks which is a real time saver, but that still leaves all the rest. So this sounds like a job for Amazon Q. Specifically Q's feature which is gonna automate the of adding new features So instead of all that work, and Q is gonna use its expertise, enriched with an understanding and it's gonna do all the So Amazon Q will create the draft plan, which you can then collaborate and iteratively improve till it's polished and ready to go. And then Q really kicks into gear. It's gonna implement the in your application, and you remain in control to review changes and ensure So this is hours of work with just one good prompt. And this feature is available and will soon be fully You will not currently from another major cloud provider that can do this for you today. But we're not done yet, let's keep going. We know that developers slogging through the muck that comes with maintenance and upgrades. Maintenance and upgrades, big deal, right? So take take language version How many of you're using because it's gonna take months, or even years to upgrade? Hands. Oh yeah, a lot of 'em. So migrations inevitably come with a lot of nuance and edge cases. And so you end up spending and rewriting the code and trying to get it to compile and work. And sometimes these programs take so long, that it feels like you're in just as one ends, the next begins. It's not hard to understand the temptation to just maintain status quo, but doing that means that you miss out on performance improvements. And it means much worse to potential security vulnerabilities. And that's why we built into Amazon Q, code transformation, which to transform code in that it takes today. All a developer has to do- (audience applauding) All a developer has to do is ask Q to perform the code transformation. And it handles the rest. From identifying and upgrade and mandatory code package to replacing deprecated code, and incorporating security best practices. Q's even gonna run tests on So we've been using this application, this capability internally So with Amazon Q transformation, a very small team of Amazon developers successfully upgraded from Java 8 to Java 17 in just two days. Now I'm gonna say that again, 1000 application upgrades in two days. That's how long a single (audience applauding and cheering) I mean, this is months, months if not years of A lot of very happy people I promise you. So today, Amazon Q can work but soon you're gonna be able to use it to help migrate your .NET And there are a lot of stuck on Windows because required in making the migration. And this is an opportunity on costly licensing fees, on and the security benefits. Well, what about the other All the folks in marketing, finance, HR, product management, and more. There's so much information spread across your organization's all of your applications, and people in all of They struggle every day that they need to then transform and taking actions and to say competitive. Hmm, finding relevant information, making recommendations, taking action. That sounds familiar, right? Yep. Amazon Q is also your business expert. Q has connections to over 40 So employees across the organization can ask complex questions nuanced answers, that are And again, secure is secure, It respects your existing roles and the permissions that are We're really excited about this, and I actually wanted to show you just a little bit of Amazon Q So to put Q through its paces, Dr. Matt Wood to the stage. (upbeat dramatic music) - Thanks Adam, and good morning everyone. I'm excited to give you a new type of AI assistant, designed to be an expert in your business. With Amazon Q, you can relevant answers to your most all delivered securely and privately. Getting started with Q is simple First, you configure Amazon Q, by connecting and of your own organization. Q connects to existing data Microsoft, Google, Slack, and more, supporting over 40 popular and services right out of the box. Once connected Amazon Q starts indexing all of your data and content, learning everything there is This includes understanding product names, organization structure, all the details that make As well as indexing the Q also uses generative AI to understand and capture the semantic information which makes your business unique. This additional semantic information is captured as vector embeddings, allowing Q to provide which are tailored to your Your data remains completely at all times. Amazon Q never shares it externally, or uses it to improve any And that's it. Surprise, there is no step three, just open Amazon Q in your with a fully customized secure assistant, who is an expert in your business. You communicate with Q through this friendly web application, designed for everyone in Q knows who you are and And because Q understands you can ask far more and get tailored answers For example, you can ask Q to analyze which product features customers are struggling with and recommend ways to improve them. As soon as you hit enter, Q gets to work on and preparing an answer. Q starts by creating a set of Q then uses all of the to find relevant data, and picks the best ones, before combining everything All in just a fraction of a second, using the power of generative AI. Amazon Q remains faithful citing them in line, so that you can validate Q's experience might be magical, but there is no magical black You can upload new Word documents, CSVs and other files on the fly to Q, to incorporate into its responses, letting you ask questions which hasn't yet been added And Amazon Q was built with from the ground up. So even if you were to seek information to which we don't have access, Amazon Q respects your only returning information Admins can also restrict sensitive topics, filtering out inappropriate where necessary. Finally, Amazon Q can take through a set of configurable plugins. As an example, if you update, say, your training priorities, Q can automatically notify leaders in Slack, and update dashboards in ServiceNow. Q allows you to inspect so you can review them and And after the action runs, Q will link to the So in summary, Amazon into the business world, and actionable guidance tailored We can't wait for you to try Q and see how it will With that, back to Adam. Thanks a lot. (audience applauding) (dramatic upbeat music) - That was awesome. Amazon Q is gonna make a huge Employees are gonna love how Amazon Q is gonna help solve problems, discover and synthesize new information and lift folks out of monotonous And IT is gonna love how all of this comes with rigorous security and privacy. Now, I know at least are wondering if Amazon does that mean it can help And of course the answer So we've been working for a while to make business to people without BI expertise. We think anyone should of their data using natural language. And so Amazon QuickSight, now has Amazon Q features built in. First Amazon Q is gonna that it takes business analysts to create dashboards and reports, from hours down to minutes, by letting them simply tell Amazon Q what they want to visualize. For example, regional sales by Q comes right back with that diagram and you can add it to And you can tell Q to Say you wanna change the chart by month and color coded by region, your wish is Q's command. With Q, you can get But even the best dashboards don't tell every angle of the story. For example, you can ask Amazon Q, where did we have the highest sales? And you can get a response You can ask a follow-up question, even as little as one word like &quot;London.&quot; And because Q maintains the context of your current conversations, you can get insights Now, enabling people to is a big step forward in be even more data driven. But not everyone is A lot of people consume and reports, and so so is telling stories with data. And as your business expert Q is here to make that easier too. Let's say you wanna on your business in North America. You can ask Q to write a monthly and make recommendations for next month. And Q's gonna give you You choose the ones you want, And in seconds you have a And it's completely customizable. You can actually add more by asking Q to add a And Q will generate a short summary, and then you can further shorter, or reformatting it to bullets. Let's make it longer. Once we're happy with the story, we can securely share it with others. With Amazon Q and QuickSight, you now have an expert BI assistant, that's gonna make it easier and it's make it easier for end users to get answers to end insights faster. And these new Q capabilities in QuickSight are available in preview today. (audience applauding) Now, a lot of organizations that are targeted to horizontal use cases, or specific lines of business. And AWS has applications So our first specialized was Amazon Connect. So it's born in the cloud and of course Amazon Connect easy to use contact centers application that's reinvented customer service. Generative AI that knows your business is gonna have an incredible impact on the whole customer service experience, across so many different industries. Your customer service teams are at the heart of your businesses, delivering interactions for good and for bad. So getting this right really matters. Today, contact center gathering information from customers, to understand their questions, and then they spend even more time searching for the right answer. Now, connect has made with machine learning but we knew we could make it even better, for your agents and waiting on the other end Enter Amazon Q and and this is gonna give contact Agents can chat with Q, directly inside of Amazon Connect to help them respond quickly Live chat with Q with but what if you can make Now inside of Connect, Q is assisting with proposed or with links to relevant So contact centers, are also gonna get a generative AI boost. Connect now automatically that supervisors can use and to uncover agent And for administrators, and interactive voice responses, through simple natural language prompts, streamlining the process. Amazon Q is just the first of many specialized industry and that are gonna supercharge Amazon Q. So stay tuned. Amazon Q builder, your AWS expert, AWS Q business, your business expert, Amazon Q in QuickSight, your and Amazon Q in Connect, All engineered to offer to the information that And with with the built-in that you know and that And this is just the start to reinvent the future of work. We continue to innovate across to bring you what you of generative AI for your organization. Performant, cost-effective infrastructure, a new secure, private easy way to build and scale powerful new applications with foundational models. Generative AI applications that can be enriched with And it's all on AWS, that gives you broad choice and enterprise readiness. But it's so early in the game and we're incredibly excited about what we're gonna be able to do together. Now there's one more thing for any of this to work. And that's data. Your data. No one else has it, no one else Your data's key to apart from the pack. And as we've discussed, generative AI has just made it so much when you tailor your data. So let's hear from a longtime customer, about how they're using data to create first class So please welcome to the VP of Connected Company at BMW. (audience applauding) (keyboard keys clicking) (upbeat music) (upbeat dramatic music) (audience applauding) - Thank you. Hello everyone. It's fantastic to be here. I couldn't agree more, data is key. The automotive product complexity and development speed is essential. Let me show you how BMW is mastering data, accelerating the development process, and delivering best in class anywhere and anytime. Across the entire product portfolio, from BMW to Mini and even Rolls Royce, BMW is providing game and experience powered by AWS. We optimize our tech stack, and use data by leveraging Let me give you some examples. Cloud data hub, BMW Central Data Lake, built by BMW and AWS, hosts data from our And while upholding the On top of it, teams can build as well as deploy updates and improvement. Together we are exploring innovative use of machine learning, This automated driving platform is BMWs next generation of This automated driving platform is capable to handle several from our global test fleet. We are accelerating our and validation process dramatically, for our product launch in 2025. With our route optimized we are providing real based on driving style, or available change in We also use Amazon technology like Alexa, for our intelligent personal to create unique customer Our connected vehicle AI and forms the backbone of the largest connected vehicle fleet. Ready for some more Let's dive in. 20 years ago, BMW introduced and we come quite a long way since then. Now the BMW group has the with more than 20 million Over the last three years, we migrated the connected By utilizing the global Worldwide, we are updating over the air, on a regular basis. Those numbers are growing constantly. It requires to manage more than with over a thousand Ultimately, we are processing more than 110 terabytes of data traffic per day, with a remarkable reliability. Look at these numbers, However, with our new this number will triple Let's change perspective and take a look at a couple of numbers More than 8,500 software create first class code for The BMW 7 series runs on over Our worldwide DevOps teams execute more than 110 by using more than 60,000 virtual CPUs. To keep up with our to scale up and accelerate development whenever it is necessary. Let's take a deeper Traditionally, BMW comes from Every developer had to on a physical test track. Today, we are using innovative technology to streamline our infotainment The new approach allows us to remotely to our global developer teams. An example is using Amazon and testing, in order to improve Our next step is to extend this approach to build a fully virtual digital twin. Now let's talk about the product, and some exciting feature we On the picture, you can It's our way to emphasize Take the impressive round OLED display in our new Mini family, Speech is rapidly becoming for interacting with vehicles. We have a long history However, this year we are raising the bar. We will use Alexa technology to bring our intelligent to the next level. Now let's take a seat in One of our most exciting It's the 30 inch screen It is spectacular, integrated in the car. It gives you a real cinematic experience. With Fire TV, our customers their favorite series and movies. It's our strong collaboration that unlocks new possibilities, enables us to think about So one last thing to give you This is the BMW Neue Klasse. This will launch in 2025. BMW has been always on the forefront of automotive innovation. The Neue Klasse will be a quantum leap in customer experience. It will take the driving As you can see, the Neue Klasse introduced a completely new interior. With the BMW panoramic vision, we developed a new head up pillar to pillar, for the perfect driver All of this emphasize, improve, BMW is mastering data, accelerating the development process and delivering best in class anywhere and anytime. This is absolutely exciting, and all of this is happening right now. AWS and the BMW group are to shape this future. Thank you all. Goodbye. (speaking german) (audience applauding and cheering) - What an incredible data and I mean the incredible for your consumers. Just amazing. Thank you Stephan. - It was a pleasure. as always. - Thank you. (upbeat dramatic music) So, as Stephan has just made so clear, success with AI, as well as with nearly every relies on having a strong data strategy. And one question I hear from how should I think about data Well, the answer is your data is your differentiator. Now, we've talked about CodeWhisperer, customizations, Amazon Q tailored for your business, and examples from Delta (indistinct) adding context to your generative AI applications with your own data is absolutely critical to providing value. Now, in each of these examples, the data used to customize the application has to be up to date. It had to be complete and accurate. It had to be discoverable, and it had to be available So the first step in achieving all of this is to making sure your Now, generative AI is that you want this. Having effective is gonna increase your insight. It's gonna reduce your cost, and it's gonna accelerate innovation. To understand this, just think about how many different issues when trying to make the most of your data. Organizations have it comes from different origins, and it comes at various scales and speeds. Different teams all are gonna work with different data in many, many different types of ways. And then how you want to use You're storing it, you're you're analyzing it, you're There's no one tool or unless you're willing to make cost, or capabilities. But you don't want to So what you need is a that accounts for the scale and the many, many purposes You need to integrate it that's spread all over to of what's happening and And of course, you need governance, so that you can have the right balance of access and control You need it all, if you miss even one aspect, is significantly hobbled. So in order to make sure and process the data, you've gotta have a comprehensive So you can get the price performance, you can get the speed, the flexibility, and the And that's why we have set of cloud data services out there. To start we have Amazon S3, and customers use S3 to make hundreds of thousands of data lakes, where they can bring structured data together with unstructured data, and make it all available for analytics and machine learning. We also offer eight relational databases, including Amazon Aurora, the that's built from the and is still the fastest We also have eight non-relational databases, including Amazon DynamoDB, which is used by over I'm sorry, a million customers, for its serverless, single at any scale. And we also have the of analytics services. And this includes our Amazon Redshift, which delivers up to six, or even seven times depending on your workload, than other cloud data warehouses. And we've got Amazon and other big data workloads. And Amazon OpenSearch Service, with tens of thousands and hundreds of thousands of And that all processes, And many, many, many I won't go through them all. But you need this breadth so that you can never have on performance, or on scale. And instead you can choose Now, we've already talked so I'm not gonna dwell on that here. But you need to be able to feed your AI and everything else that you're doing in your business. And the second thing that you need, as you move to put data at is to break down your data silos. Most people have data spread and databases, analytic spreadsheets and more. And to get the most value from your data, you need to be able to use it And to do this today, most or try to connect the called ETL, or extract, Yeah, I see some of you 'Cause you know, right? You know exactly how bad It is terrible. First, developers have to design an ETL pipeline architecture. They have to decide where and it's often coming Then they have to write and remove duplicates. They have to filter out and identify corrupted data. After all that, you have to load your transformed data to its new destination, which once again means more code to write. Then if something changes, like a data engineer or adding a new field, and update all of your code once more. It is monotonous, it is tedious, and it is just a whole lot of unfun work. Which is why we introduced our And in this future you can frustrating process of ETL. Your data's automatically connected from the source to the destination. It's that easy. And you get your data ,where No more building and managing complex, brittle processes and pipelines. It's really exciting. But is it real? Well as a down payment, last year we announced a fully between Aurora, MySQL and Redshift. Within seconds of data you can use Redshift to do on petabytes of data. You can enable this integration and zero ETL. It is incredibly easy. Now this first zero ETL integration is already done. But we want to deliver so much more. So I'm really excited today to be announcing three with Redshift. Let's get 'em all done at once. Aurora PostgreSQL, RDS These zero ETL integrations and Amazon Redshift are all Today. (audience applauding) So that makes... Yeah, you don't like a muck, do you? So that's four of our and non-relational databases, together with the data warehouse that gives you the best price performance, without any of the ETL. Fantastic. But remember, we're not So of course our next question was, well, where else could we Now, many of you need to use search on your transactional data, to enhance the experience So for example, if you have and you wanna provide to your user, you'd use similarity search on transaction data that's gonna So to do this, currently you're you're managing complex from your database to a search engine. And tens of thousands of you to Amazon OpenSearch Service for its powerful search capabilities. I bet you can tell where So today I'm really pleased to have unveiled one more DynamoDB zero ETL integration generally available today. (audience applauding) And this new integration makes it so easy to search DynamoDB data And it's just the first of to our OpenSearch Service that's gonna help you do more with data. So our new zero ETL integrations are bringing transactional data and analytics together And customers are really of a zero ETL future. So you can be certain we're Now, we've talked about all and how you can have without the painful ETL burden. Next, you wanna empower to use your data to its fullest. You want them wallowing in asking questions, sparking ideas. You wanna give people access. But there's one problem, your data is incredibly valuable, so you want to grant access only to the right employees You need to keep it safe and secure. So you also need control. Access, control. These are opposites, right? No, you can have, in And the key to making sure is governed, has access, is governance. Creating visibility into your data and controlling who can access your data and when they can access it. With robust governance, you're to the data they need and only that data. And when you know what data you have guardrails and tools that builds confidence. And then people within the organization develop trust in the data, you actually empower rather than stifling it. And so to help you with governance, we developed Amazon Data Zone. Data Zone is a data management service that helps you catalog, discover, share, and govern data across your organization. And we're getting great feedback from lots of different customers, including the financial And we're really pleased with the impact that Data Zone's having. And we're gonna continue to Today, Data Zone uses machine learning to automatically add But in order to find the customers still have to choose like explaining the data's purpose, or clarifying column descriptions. Now this helps employees It's really important because if you don't know the data exists, the question of access But adding all this metadata is tedious. It's a manual process, well no longer, we're making your cataloging even smarter. And today I'm really pleased that automatically suggests To add context for your data (audience applauding) Customers simply choose a data set and Data Zone will use generative AI to create business using our train models, making These descriptions can or even further clarified or edited for your exact preferences. Data Zone's also gonna for how to use your data. This is a huge, huge time saver, and this capability is to find the right data We're gonna continue to innovate, to help you use data governance Whatever you wanna do in your business, you need an end-to-end data strategy that provides capabilities across the entire span of your data needs. You need to easily And you need your data to be governed, to be confident that in the right ways, by We're making AWS the best place for all of your data needs across all of these different areas. And when you have all this and when you're ready to make in AI and across your We've talked a lot And here at AWS, the most important To support you in all the ways that you wanna adapt and evolve, we continuously challenge ourselves. We try and think differently. We try and give you the capabilities that you've always wanted and even some maybe that Now, this isn't the work of a few months, or even a year, but we're okay with that. We're okay with that because So third party selling on Amazon, Prime, even AWS itself was a big bet. I mean, it took a lot of years and a lot of capital to build out the on-demand infrastructure services, that simply became known as The Cloud. This long-term focus is a good thing. Being willing to think is a good thing. It's the only predictable way to profoundly changed what's Now there's another big You might've heard of Project Kuiper. (audience cheering) Yeah, Kuiper. (audience applauding) Kuiper is building a constellation of thousands of low Why? Well, hundreds of millions lack fast or reliable, or Project Kuiper's gonna help by delivering fast, affordable of customers operating places without reliable internet connections. In fact, just last month, the Kuiper team successfully proto satellites into orbit. It's just an incredible thing. I mean, they put satellites up there, they're working flawlessly. Everybody's really happy. Let's take a look. (upbeat dramatic music) (audience applauding and cheering) Maybe I should have stopped there, right? Wow. I mean, Kuiper is a global that's gonna provide coverages in places that have never had coverage before. I mean, imagine the power of delivering, in really hard to reach places, the ability to access the the same reliability that most of us take for granted every day. Now, the possibilities for but so are the benefits to And there are all sorts of use cases, like renewable energy providers, that want to analyze in real time data from offshore wind farms. Or first responders who need during natural disasters. Or organizations that are looking for connectivity backup in Kuiper's gonna help to And AWS customers are already that this opens up to their sensors, their data, their networks. It's going to be amazing But some customers of course, don't want their data running And as you know, security is So today I'm really excited to announce, that in addition to public Kuiper's also gonna private connectivity services. (audience applauding) And now you're gonna be able to move data from virtually anywhere, over And as you use these you can use it inside And early adopters are gonna in the second half of 2024. So we make big bets like these, so that customers can do things that they couldn't imagine before. And you come on this journey with us because we are willing to take these kinds of audacious leaps. And the benefits have been enormous. The exciting challenge ahead is to look closely at our to reinvent it. To dream up experiences that and make them real. We are so excited to be your that we're building together. And I'm thrilled that we get This morning has been incredible. I want to thank all of And thank you to everybody watching. And of course, thank you for working so hard to make this happen. (audience applauding) Now the team does have up their collective sleeve. So I dunno if you remember I mentioned Lowden guitars in Ireland, well we actually have from our friends at Lowden, and we've invited a talented guitarist, a longtime AWS favorite, So we have got a great conference Now let's get out there and reinvent. Thank you. (audience applauding) Take it away, Zach. (guitar strumming)