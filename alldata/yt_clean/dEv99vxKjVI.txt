- The following is a He's the CEO of Tesla, SpaceX, Neuralink, and a co-founder of This conversation is part of the Artificial Intelligence Podcast. This series includes leading researchers in academia and industry, including CEOs and CTOs of automotive, robotics, AI and technology companies. This conversation of the paper from our group at MIT on driver functional vigilance during use of Tesla's Autopilot. The Tesla team reached out to me offering a podcast I accepted with full control and the choice of what I ended up editing out I've never spoken with Elon publicly or privately. Neither he nor his on my opinion, nor on of the scientific method that I practice in my position at MIT. Tesla has never financially and I've never owned a Tesla vehicle, and I've never owned Tesla stock. This podcast is not a scientific paper, it is a conversation. I respect Elon as I do all other leaders and engineers I've spoken with. We agree on some things My goal, as always with is to understand the way One particular point of was the extent to which will improve outcomes and for how long it will remain relevant As someone who works human-centered artificial intelligence, I believe that, if implemented camera-based driver monitoring in both the short term and the long term. In contrast, Elon and Tesla's focus is on the improvement of Autopilot such that its statistical safety benefits override any concern for Elon and I may not agree on everything, but I deeply respect the behind the efforts that he leads. My goal here is to catalyze a rigorous, nuanced and objective discussion in industry and academia one that ultimately makes And now, here's my What was the vision, the dream, of Autopilot in the beginning? The big picture system level and started being installed in 2014, the hardware in the cars? What was the vision, the dream? - I wouldn't characterize it's simply that there are in the automobile industry. One is the transition to electrification, and then the other is autonomy. And it became obvious to any car that does not have autonomy would be about as useful as a horse. Which is not to say that there's no use, it's just rare, and if somebody has a horse at this point. It's just obvious that cars will drive themselves completely, it's just a question of time. And if we did not participate then our cars would not relative to cars that are autonomous. I mean, an autonomous five to 10 times more than a - In the long term. - Depends what you mean by long term but, let's say at least for perhaps 10 years. - So there are a lot of very with Autopilot early on. First is showing on or in the Model 3 and what the combined sensor suite sees. What was the thinking behind that choice? Was there a debate, what was the process? - The whole point of the display is to provide a health check on the vehicle's perception of reality. So the vehicle's taking in information from a bunch of sensors, but also radar and And then, that information vector space with a bunch of objects, with properties like lane lines and traffic lights and other cars. And then, in vector onto a display so you can confirm whether the car knows what's going on or not, by looking out the window. - Right, I think that's an for people to get an understanding, sort of become one with the system and understanding what Now, have you considered showing more? So if we look at the computer vision, like road segmentation, lane detection, vehicle detection, object there is at the edges, some uncertainty. Have you considered revealing the parts that the uncertainty in - Probabilities associated with say, image recognition or something like that? - Yeah, so right now, it shows a very clean crisp image, that there's a car in front of me and the system sees there's but to help people build an intuition of what computer vision is, by showing some of the uncertainty. - Well, in my car I always look And there's two debug views. One is augmented vision, where it's basically we around objects that are recognized. And then there's we what which is basically vector summing up the input from all sensors. That does not show any pictures, which basically shows the car's view of the world in vector space. But I think this is very difficult for normal people to understand, they're would not know what - So it's almost an HMI challenge through the current things that are for the general public understanding of what the system's capable of. - If you have no idea how you can still look at the screen and see if the car knows what's going on. And then if you're a development engineer, or if you have the then you can see all But this would just be like - What's your view on how So there's three, I would of Autopilot that are really important. So it's the underlying algorithms, like the neural network architecture, there's the data that it's trained on, and then there's the hardware So, look, algorithm, data, hardware. You only have so much money, What do you think is to allocate resources to? Or do you see it as between those three? - We automatically get because all of our cars have eight external facing cameras, and radar, and usually GPS obviously, and IMU. And we've got about that have that level of data. Actually, I think you keep quite - Yes. - Yeah, so we're approaching that have the full sensor suite. I'm not sure how many have this sensor suite, but I'd be surprised if which means that we have - So there's this huge inflow of data. - Absolutely, a massive inflow of data. And then it's taken us about three years, but now we've finally developed our full self-driving computer, which can process an as the NVIDIA system that we and to use it, you unplug and plug the Tesla In fact, we still are exploring the boundaries of its capabilities. We're able to run the full resolution, not even crop the images, and it's still got headroom The full self-driving computer two systems on a chip, So you could put a boat through basically any part of that - The redundancy, are they - Yeah. - Oh, so it's purely for redundancy as opposed to an arguing where they're both making decisions, this is purely for redundancy. - Think of it more like it's a twin-engine commercial aircraft. The system will operate best but it's capable of So, as it is right now, we can just run, we haven't even hit so there's no need to actually distribute functionality across both SOCs. We can actually just run a - So you haven't really explored or hit the limit of the system. - [Elon] No not yet, the limit, no. - So the magic of deep learning is that it gets better with data. You said there's a huge inflow of data, but the thing about driving, - the really valuable data to I've heard you talk somewhere being an important moment of time to use. Is there other edge cases or perhaps can you speak what aspects of them might be valuable, or if you have other ideas, how to discover more and more and more edge cases in driving? - Well there's a lot of There are certainly edge cases where, say somebody's on Autopilot and then that's a trigger and says, okay, did they or did they take over wasn't working properly? There's also, let's say what is the optimal spline for Then the ones where there are the right ones. So you then you say, okay, do the following. And then you get the optimal spline for navigating a complex intersection. - So there's kind of the common case, So you're trying to capture of a particular intersection and then there's the edge case where, as you said, not for convenience, but something didn't go exactly right. - So if somebody started And really, the way to look at this is view all input as error. If the user had to do all input is error. - That's a powerful line 'cause it may very well be error, but if you wanna exit the highway, or if it's a navigation decision that Autopilot's not then the driver takes the difference? with Navigate on Autopilot, and without stalk confirm. Assuming control in order or exit a freeway, or doing the vast majority of that will go away with the release that just went out. - Yeah, so that, I don't how big of a step that is. - Yeah, they don't. If you drive the car then you do. - So you still have to keep your hands on the steering wheel currently when it does the automatic lane change. There's these big leaps through through its history and, what stands out to you as the big leaps? I would say this one, without having to confirm is a huge leap. - It is a huge leap. It also automatically overtakes slow cars. So it's both navigation and So it'll overtake slow and take highway interchanges, and then we have traffic which introduced initially as a warning. I mean, on the development the car fully stops and - So those are the steps, right? You've just mentioned some things that are an inkling of a What would you say are roadblocks to full self-driving? - Actually, the full self-driving the Tesla, what we call, FSD computer that's now in production, so if you order any Model S or X, or any Model 3 that has the you'll get the FSD computer. That's important to have Then refining the neural net All of that can just be provided The thing that's really profound, and what I'll be emphasizing that we're having focused on autonomy, is that the car is with the hard word is capable of full self-driving. - But capable is an - [Elon] The hardware is. - Yeah, the hardware. - And as we refine the software, the capabilities will and then the reliability and then it will receive So essentially, buying a car today is an investment in the future. I think the most profound thing is that if you buy a Tesla today, I believe you're buying not a depreciating asset. - So that's a really because if hardware is capable enough, that's the hard thing to upgrade usually. - Then the rest is a software problem-- - Yes, software has no - But, what's your intuition How hard are the remaining steps to get it to where the experience, not just the safety, is something that people would enjoy? - I think people it enjoy It's a total game changer for using Tesla Autopilot on the highways. So it's really just to city streets, adding in navigating complex intersections, and then being able to navigate so the car can exit a parking even if it's in a complete And, then it can just drop you off and find a parking spot, by itself. - Yeah, in terms of enjoyabilty, would actually find a lotta use from, the parking lot, it's rich of annoyance when you have to do it manually, so there's a lot of benefit to be gained from automation there. So, let me start injecting the human into this discussion a little bit. So let's talk about full autonomy, if you look at the current being tested on row like Waymo and so on, they're only technically autonomous, they're really level two systems with just a different design philosophy, because there's always a safety driver in almost all cases, and they're monitoring the system. - Do you see Tesla's full for a time to come, requiring supervision of the human being. So its capabilities are but nevertheless requires a human to still be supervising, just like a safety driver is in other - I think it will require for at least six months or Really it's a question of, how much safer than a person for it to be okay to not monitor the car. And this is a debate that one can have, and then, but you need so that you can prove, statistically speaking, that the car is dramatically safer than a person. And that adding in the person monitoring does not materially affect the safety. So it might need to be 200 - And how do you prove that? - Incidents per mile. - Incidents per mile. - So crashes and fatalities-- - Yeah, fatalities would be a factor, but there are just not enough fatalities to be statistically significant, at scale. But there are enough crashes, there are far more crashes So you can assess what is Then there's another step And probability of permanent injury, the probability of death. And all of those need to be by at least, perhaps, 200%. - And you think there's a healthy discourse with on this topic? - I mean, there's no a disproportionate amount of attention to that which generates press, this is just an objective fact. And it also generates a lot of press. So, in the United States there's, I think, almost 40,000 automotive deaths per year. But if there are four in Tesla, they will probably receive than anyone else. - So the psychology of that I don't think we'll have enough time to talk about that, but I the human side of things. So, myself and our team a paper on functional vigilance of drivers while using Autopilot. This is work we've been was first released publicly, collecting video of driver So I saw that you tweeted so I can at least guess - Yeah, I read it. - Can I talk you through what we found? - Sure. - Okay, it appears that in that drivers are maintaining we're looking at 18,000 18,900, and annotating were they able to take over control in a timely manner. So they were there, to take over control, okay. So this goes against from the body of literature Now the question is, do you think these results hold across So, ours is just a small subset. One of the criticism is that, of drivers that may be highly responsible, where their vigilance with Autopilot use. - I think this is all I mean, the system's improving so much, so fast, that this is gonna Where vigilance is, if than a person, then adding a person does, the effect on safety is limited. And, in fact, it could be negative. - That's really interesting, some percent of the population may exhibit a vigilance decrement, will not affect overall statistics, numbers on safety? - No, in fact, I think it will become, very, very quickly, maybe even but I would say, I'd be at the latest, that will decrease safety. Decrease, like imagine Now it used to be that there And you couldn't go on and work the lever to move between floors. And now nobody wants an elevator operator, because the automated elevator is much safer than the elevator operator. And in fact it would be quite dangerous to have someone with a lever that can move the elevator between floors. - So, that's a really powerful statement, and a really interesting one, but I also have to ask and from a safety perspective, one of the passions for me algorithmically is camera-based detection but detecting what the cognitive load, body pose, that's a fascinating problem. And there's many in industry who believe you have to have camera-based Do you think there could be benefit gained from driver monitoring? - If you have a system that's of reliability, then driver But if your system is dramatically better, more reliable than a human, does not help much. And, like I said, if you're in an elevator, someone with a big operating the elevator between floors? I wouldn't trust that. I would rather have the buttons. - Okay, you're optimistic of the system, from what you've seen with the full self-driving car computer. - The rate of improvement is exponential. - So, one of the other very interesting design choices early on is the operational design So, where Autopilot is So contrast another vehicle is the Cadillac Super in terms of ODD, very constrained to particular kinds of highways, well mapped, tested, than the ODD of Tesla vehicles. - It's like ADD (both laugh). - Yeah, that's good, that's a good line. What was the design decision in that different philosophy of thinking, where there's pros and cons. What we see with a wide ODD is Tesla drivers are able to explore more the limitations of the system, at least early on, and they understand, together with the they start to understand so that's a benefit. The con is you're letting drivers use it basically anywhere-- - Anywhere that it can - Lanes, was there a philosophy, design decisions that were challenging, that were being made there? Or from the very beginning with intent? - Frankly it's pretty crazy letting people drive a two-ton death machine manually. That's crazy, like, in the I can't believe anyone one of these two-ton death machines, and they just drive wherever they wanted. Just like elevators, you could just move that elevator with that can stop it halfway It's pretty crazy, so, it's gonna seem like a that people were driving cars. - So I have a bunch of questions about the human psychology, - That's moot, it's totally moot. - Because you have faith in the AI system, not faith but, both on the hardware side and the deep learning approach will make it just far safer than humans. - Yeah, exactly. - Recently there were a few hackers, who tricked Autopilot to for the adversarial examples. So we all know that neural network systems are very sensitive to minor disturbances, these adversarial examples, on input. Do you think it's possible to defend against something like this, for the industry? - Can you elaborate on the - A neural net is just basically a bunch of matrix math. But you have to be a very sophisticated, somebody who really and basically reverse-engineer is being built, and then that's just exactly causes the matrix math to be slightly off. But it's very easy to what would basically negative recognition, it's like if the system sees something that looks like a matrix hack, exclude it. It's such a easy thing to do. - So learn both on the valid so basically learn on to be able to exclude them. - Yeah, you like basically wanna both know what is a car and what And you train for, this is a car, and this is definitely not a car. Those are two different things. People have no idea of neural nets really, They probably think neural nets involves, a fishing net or something (Lex laughs). - So, as you know, taking and Autopilot, current still seem, in some ways, to be far from general Do you think the current approaches will take us to general intelligence, or do totally new ideas - I think we're missing a few key ideas for artificial general intelligence. But it's gonna be upon us very quickly, and then we'll need to if we even have that choice. It's amazing how people between, say, the narrow to figure out what a lane versus general intelligence. Like these are just very different things. Like your toaster and your but one's much more - You're confident with the world's best toaster-- - The world's best toaster, yes. The world's best self-driving... yes, to me right now this I mean, I don't want us to be complacent or over-confident, but that's what it, that is just literally I could be wrong, but it that Tesla is vastly ahead of everyone. - Do you think we will ever create an AI system that we can in a deep meaningful way, - I think AI will to fall in love with it very well. - And that's different than us humans? - You know, we start getting into a metaphysical question of, do emotions and thoughts exist in a different realm than the physical? And maybe they do, maybe But from a physics standpoint, you know, like physics was and from a physics if it loves you in a whether it's real or not, it is real. - That's a physics view of love. - Yeah (laughs), if you if there's no test that you can apply that would make it, allow you to tell the difference, then there is no difference. - Right, and it's similar to they may not be a test to what the real world - and the simulation, and therefore, from a physics perspective, it might as well be the same thing. - Yes, and there may it's a simulation, there might be, I'm not saying there aren't. But you could certainly imagine that a simulation could correct, that once an entity in a way to detect the simulation, it could either pause the simulation, start a new simulation, or that then corrects for that error. - So when, maybe you, an AGI system, and you get what would that question be? - What's outside the simulation? - Elon, thank you so it's a pleasure. - All right, thank you.