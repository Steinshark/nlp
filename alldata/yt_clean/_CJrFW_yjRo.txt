In this video, I will be covering everything that you need to know to get started with the OpenTelemetry Collector. So thank you very much to user Vivek Shukla2480, who's commented to tell me I missed a few things in some previous videos. And actually, that made me realize that I've missed the entire topic of what the OpenTelemetry Collector is, why you use it, how it works and how you'd actually run it. So, here it is. First up, what is the OpenTelemetry Collector? Well, you have telemetry producing entities and you need to get that telemetry from there to one or more storage systems or back ends of some sort. So the collector is the way that I recommend you do that. The collector handles all aspects of receiving, processing and exporting that telemetry data. So how do you actually run an OpenTelemetry Collector? The good news is that the collector comes in different formats. There is a standalone binary, so you can run it on bare metal machines, your laptop or a virtual machine, just as a normal executable process. And the collector is also bundled and available as a docker image. So running it with something like docker, podman or docker compose is of course fine too. You can also use Kubernetes to run your OpenTelemetry Collector. No matter what operating environment you find yourself in, the collector can probably run there. So back to the collector itself. It's important to realize the collector is actually a collection of components that you mix and match together in whatever combination and order that you like. So these components are receivers, processors, exporters, connectors and extensions. Don't worry, I'll be discussing each of these in detail later in the video. So between these different component types, receivers, processors, exporters and the rest, there are hundreds of different components, which makes it almost guaranteed that there's already something for your use case, but of course you can write your own too. And don't worry, in future videos, I'll be picking each of these receivers and diving deep into the components I use and recommend, as well as any that you asked me to cover in the comments. So subscribe and let's get on this learning journey together. Okay, so recap, we know the collector is a thing that can do something with telemetry, but let's break down the components to see how that actually works. First up are receivers. Now picture the collector as a black box that you want to do something with. The receiver is the way the telemetry signals, that's metrics, logs, traces and events, get into the collector from a telemetry producing entity. And there are two ways of getting this data, push or pull. In the push model, data is pushed to the collector. In the pull model, it's obviously exactly the opposite, the collector reaches out to an endpoint and pulls the data back in. So you'll also hear this referred to as scraping the data. The very first receiver you're likely to encounter on your learning journey is the OTLP receiver. Now OTLP stands for open telemetry protocol. This receiver opens a listening port on the collector and waits for open telemetry protocol data to be sent or pushed to it. For example, a telemetry producing entity will send spam data to the OTLP receiver on a particular collector. The file log receiver is an example of the opposite of a pull based receiver. Now the file log receiver's job is to sit and wait and watch log files and pull any updates, i.e. any new log content in the collector. If you're interested in the file log receiver, I've already done a video on the file log receiver linked above. So go check that out and then come on back here. Of course, you can use one or more receivers in your collector so you're not limited. It's perfectly possible to use, for example, the OTLP receiver and the file log receiver and the Prometheus receiver all at the same time. Okay, so now that you have data making its way somehow to the collector via these receivers, well, what next? Next are processors. Processors take data from those receivers and do something with it. For example, the batch processor takes telemetry data and batches it up. For example, rather than sending 50 individual log lines to your storage system, your back end, meaning 50 round trips, the batch processor would place all 50 log lines, if you configured it that way, and send that in a single batch. Another example of a processor is the log deduplication processor, which, as its name suggests, deduplicates identical logs in a given time span and then adds a new field onto the single log line that gets sent with how many duplicates were actually removed. Again, there are lots and lots of processors available just like receivers and I will be picking and choosing and digging deep into each one, so watch out for that content in the future. Okay, telemetry data is now inside the collector and we've mangled and mashed it and processed it into something that we are happy with. Well, what next? Of course, we need to send it somewhere. Exporters are the way to tell the collector how to send and where to send the data when you're ready to send it out of the collector. The most common exporter you will see is the counterpoint to the OTLP receiver. It's the OTLP exporter. These exporters are the opposite of the receivers, of course. They send data out of the collector in the open telemetry format. Another example is the debug exporter, which as it sounds is very useful for debugging. It takes your telemetry data and sends it out to the console. As you'd expect, because there are lots of places to send telemetry data, there are lots of exporters and I will dive into them in future videos as well. But just to say, most companies, most vendors and most tools are now kind of standardizing on using the OTLP exporter. So now we've got three components, receivers, processors and exporters and different types of telemetry, spans, metrics, logs and events. So how do these things all work together? Well, remember that you can have multiple receivers, multiple processors and multiple exporters. So the question now is, well, how does a certain receiver know it should work with a certain processor and a certain exporter but only for to process log data? The answer to that is pipelines. Pipelines are the way you specify how all of these things are tied together. A pipeline is defined based on its data type, for example, a log pipeline. A log pipeline will then have a receiver, a processor and an exporter and you'll have a second pipeline for metrics. The most basic pipeline might be a single log receiver connected to a single exporter, so logs are received and sent to a single destination. Now, while we're in the server section of the config, I will quickly mention the telemetry configuration section. This is where you can set up observability of the collector itself. After all, it would be ironic if this key component of an observability system wasn't itself observable. Receivers, processors, exporters and pipelines are the four main elements that you will come across day in, day out and these are the ones that you will use most often. But I'm afraid our learning journey isn't quite finished there. What if you wanted to bridge between different pipelines? Taking the output of one, using it as the input of another, perhaps to build complex logic, multi-pipeline logic and perhaps to translate between data types. That's what connectors are for. For example, using the count connector, you can count the number of loglines from one pipeline and then output that represent that as a metric. Finally, extensions expand the capabilities of the collector so that it can do other things that aren't directly related to the processing of telemetry data. For example, what if you need some sort of authentication? There are various authentication extensions like the basic auth extension, which adds basic auth support to the various components of your collector. I know that was a lot to take in, so rewind and re-watch this a few times until it syncs in. If you're new to open telemetry and observability, it can sometimes feel overwhelming, but this is really all about getting those three types of data. Metrics, logs and spans from A to B and the collector facilitates that. As I've mentioned in the future, I will be creating content which takes, for example, a single receiver, processor and exporter at a time at once and dives into the functionality of each of these in depth. Again, I've already done this with the file log receiver, so if you missed the card before, check the video description and I'll put a link to that video in the video description. Thank you very much for your time and your comments. I really do appreciate everyone who takes the time to subscribe and comment because it helps me to understand what content you need and what content I need to learn so that we can all learn and grow together. So stay tuned for the next video. Well, I will explain the different open telemetry collector distributions that already exist, and if you're not happy with those, how you can actually build your own. I'll see you then.