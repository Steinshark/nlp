It was pretty obvious, I think, to everybody. What was obvious? - That accounts that talked about Palestine were getting censored inappropriately. We had thousands of such cases. - Meta, the parent company of has a well-documented anti-Palestine bias. Instagram is taking down my stories. That post was removed. Shadowbans. This is censorship at its finest. - Human Rights Watch has called Meta's censorship of content related to Palestine "systemic and global." We spoke to a former Meta engineer who witnessed the suppression in real time, tried to fix it, and then was fired. Why did they fire you? racially and ethnically motivated. I guess they couldn't write being, like, "too Palestinian" as a reason. - And he's just one of many Meta workers about an internal culture of suppression, censorship and retaliation within the most powerful social media I am currently under investigation by Meta for circulating a letter. - Did you feel like you had a target on your back because you were so vocal in your Palestine activism? - We uncover how Meta limits what its employees are allowed to say at work, and how that affects what you are And the company's deep ties to Israel, which include powerful decision-makers. Someone who was in the Israeli army is deciding whether content about Palestine is allowed to be shown to people. It's deeply disturbing. After Oct. 7, at Meta, things did change a lot for the worse. If your family members were killed in Gaza, you're not allowed to talk about it. If you do talk about it, your job is at risk. - And some employees say the company's nearly 4 billion users deserve the truth. - You have all these journalists that were murdered in Gaza, injured, risked their lives just to get these stories out there. And Meta, as a platform, completely failed them. I owe all these people an explanation. What was your job at Meta, - I was at Meta for two years, and my job related to working on improving recommendations on both - This is who we'll call Omar, an upper-level engineer who is Palestinian American. He wants to remain anonymous to Part of your job was actually to that were being wrongfully censored or banned? - Yeah, so one of the projects that I worked on was related to breaking news and A bunch of accounts were basically Their content wasn't showing up in recommendations. We just got a lot of reports both - According to his lawsuit, Omar was specifically tasked by Meta in October 2023 to "assess the quality of Instagram integrity filters as they related to Gaza, Israel and Ukraine." Around this time, as Israel's war on many Meta users were alleging that pro-Palestine posts were being removed, accounts were getting deleted, and that they were losing access to certain features, like the ability to go live. A Human Rights Watch investigation confirmed Meta was even deleting comments, like "Free Palestine" and "Stop the Genocide," as well as Palestinian flag emojis. Among the accounts Omar looked a prominent young photojournalist from Gaza with over 17 million followers on Instagram. - Omar noticed that many of Motaz's Instagram posts were misclassified as containing "sexual activity or nudity,&quot; flagged internally as "pornographic." This significantly limited the reach of his account. - Some of them were difficult to look at but in no means pornographic. Marking images and videos of injured and dead children as pornographic, you know, I find deeply offensive. - Omar told me that the culture at Meta is such that when there's a problem impacting millions of users, it's all hands But he said that when it came to accounts associated with Palestine, typical protocol was not being followed. Tickets were opened and then "mitigated," "resolved," and "closed" with the same timestamp, indicating that someone on the team was dismissing issues without actually investigating them. And two colleagues messaged Omar privately, telling him to stop looking into the issue, even though it was his job to do so. What do you make of the fact that procedure was not being followed? - It struck me as very odd, unprofessional. I've never seen that in any company - Omar says that even though many of his colleagues were aware that some of Motaz's posts were wrongly tagged as pornographic, they remained labeled that way for days. And the only person who got in trouble was Omar, the one who pointed it out. Despite glowing performance reviews over the years, Meta fired him. And they did so just days before hundreds of thousands of dollars - They claimed that I had a personal relationship with Motaz Azaiza. That is why I was terminated. - We reached out to Meta regarding a series of allegations, but they declined to comment A company spokesperson previously said that Omar had violated "data access policies," which are rules on how employees can use company data. What was your reaction when you found out you were fired for this? - I guess mostly confusion. Like if you're gonna make up a reason, make it sound like a little bit more believable. But I guess they couldn't write being, Had you ever met Motaz Azaiza? I have never been to the Gaza Strip. Had you ever communicated with Motaz? There's really no way for me to have met Motaz. - Do you personally know a former Meta engineer named [redacted]? - This is the Palestinian photojournalist - Motaz, who now lives in Qatar, spent over 100 days documenting the genocide of his people, as Israel banned foreign journalists - Motaz estimates that 40 percent of his posts have been removed or censored since October 2023, and his account was temporarily As of today, his reach on Instagram is limited - people who don't already follow him can't find his account unless they How did it feel for you to be in the midst of this genocide under constant threat for your life and then having to deal with these issues of censorship? - Motaz says that some of his posts are graphic, but that's because they're depicting the reality of Israel's unrelenting assault on Gaza. - And to his point, many have been calling out what they say are double standards in how Meta has chosen to adjust its policies during other global events. Meta uses something it calls a It's a way to allow certain content to stay up if it's deemed important to the public interest. For example, shortly after Russian forces invaded Ukraine in 2022, Meta relaxed some of its hate speech rules for users in Ukraine, even allowing them to call for Meta had argued these tweaks were necessary to ensure that Ukrainians could freely speak out online against President Vladimir Putin and the Russian forces. Meta even temporarily allowed users to praise a Ukrainian neo-Nazi group, explicitly when it came to defending Ukraine from Russian occupiers. But those we interviewed say Meta hasn't given such exemptions to users in Gaza. How does it feel to you to know that Meta relaxed its regulations on accounts in Ukraine after the Russian invasion, but they haven't done the same for Palestine? - In fact, Meta may have made it harder for people in Palestine to speak freely. After the Hamas attacks on Oct. 7, Meta reportedly manipulated its automated content filters throughout the region to curb suspected hate speech. But it applied the strictest filters to any posts specifically coming out of Palestine. - So when you have this over-enforcement based off instructions given by Meta and guidance given by Meta, where things related to Palestine all that gets funneled into the training data. So if you look at the underlying training data, it's likely to be very biased. - Omar told me these biases led to two particularly egregious incidents after Oct. 7. One involved WhatsApp, the global texting app also owned by Meta. When users searched for the terms or "Muslim boy Palestinian,&quot; WhatsApp's AI suggested images of children holding guns. But searching "Israeli boy,&quot; "Jewish Israeli boy," or even "Israel army&quot; didn't suggest any images with guns. Another incident involved Instagram and its auto-translation of Arabic to English. The word "terrorist" was inserted into some Palestinian users' bios. Meta apologized in both cases and said they were caused by technical glitches. - So you could say that like, the AI algorithm or machine learning model made a mistake, but if you know the bias exists and you prevent your own employees from fixing it, it's very hard for you to say, like, to claim it's a bug. - Especially, he says, considering how long these problems have been an issue at the company. Because back in 2021, during Israel's two-week assault on both Gaza and occupied east Jerusalem, Meta was similarly accused of stifling pro-Palestine voices and hashtags. The following year, a report - that Meta itself commissioned - concluded that Meta's actions during the crisis "appear to have had an adverse human rights impact on the rights of Palestinian users." In response, Meta said it would begin to implement many of the report's recommendations. But Omar - and many other Meta workers we spoke to - say since those events in 2021, Meta hasn't done enough to make things better for its users or its employees. I am currently staring out my window looking at my place of work, which is Meta. I've been working at Meta for the last three years, and I was recently let go for my - I met up with Saima Akhter in New York City. She began documenting her frustrations with Meta while she was still working there. Meta's mission statement is to give people the power to build community and bring the world closer together. I think that's a beautiful mission statement. But, the problem is: Are we still holding true to our mission statement? And that is where I got into trouble. - By December 2023, more than two months into the war on Gaza, some Meta staff had grown increasingly frustrated by the company's actions. So Saima spearheaded and circulated an internal letter to leadership addressing their concerns, including the censorship on social media. So many of us have been hearing about it from our friends and our communities, and what are we supposed to do? So, internally we have been trying to raise these concerns and these alarms. - She says around 450 colleagues signed the letter in less than a day. The leaders found out about it, They kicked me out of all systems. They put me under investigation for two months. And they would not tell me anything about what exactly I had violated. And then I also found out that they were going into people's inboxes and even people's Google Drive trash cans to delete any copies of the letter. Up until that point, did you know that Meta had this type of, like, surveillance on its employees? I did not. I was very, very stressed and very scared about what was happening. - We wrote to Meta asking about Saima's letter, and why the company deleted any trace of it. A spokesperson responded: Did you ever try to raise it to the Yes. So many of us had conversations with managers and HR and met with top-level leaders. I believe that it's mostly just met with dismissiveness, or, at worst, censorship. - After a three month suspension, Saima was allowed back to work. But she was ultimately fired a few months later when Meta found out she made a personal copy of a different internal document and many other colleagues were working on. That's what really has led me to just speak up because I think others are going through this. I think my conscience doesn't allow me to sleep without trying to do something about it. - We asked Meta to comment on claims made by Saima and others that advocating for Palestine A spokesperson repeated their previous response: - In December, eight members of my family were horrifically martyred by the Zionist entity. This includes my cousins that you can see here. - Saima helped organize this vigil. It's for Palestinian Meta employees who have lost family members in Gaza, and it's taking place outside Meta's since employees say Meta won't let them talk about Gaza at work. When our Palestinian and Muslim community within Meta try to grieve together, we are censored and told these topics - Ramzy is a Palestinian American data analyst who has worked at Meta for three years. There's been plenty of posts from leadership, giving their sympathies to Israelis and their families right after Oct. 7. But for us, for Palestinians, it's like we don't exist. There's absolutely no support from leadership. - What was it like for you to go to while seeing what's unfolding in Gaza It's been really difficult. I've been challenged, like depressed and anxious, debating, like, what has this company come to? I used to believe in the mission of like bringing community together. But seeing the mass suppression it tears me up inside to give my labor to this company every day. - When asked to comment on the allegation that Meta leaders have failed to fully acknowledge the grief of Palestinian staff, a company spokesperson responded with: Did you see other political causes Oh, for sure. Ukraine was BLM was always supported. It was great they were talking about it - I think that was exactly what they should be doing. And when they came to Palestine, it was just immediately shut down on all of us. So you were there when the Ukraine war started, and you saw people able to post about it? - But posting about Gaza's not allowed. - Many of our sources at Meta told us about this - an apparent systemic removal of the internal platform on which Meta's nearly 70,000 employees communicate. What kind of posts was Meta removing internally among its own employees? Many of us employees wrote heartfelt messages about just Palestinian culture and the beauty of Palestine. All deleted. When we just tried to mention the humanitarian crisis that's occurring in Gaza, that was deleted. Who deleted them? The CEE team. It's the team that monitors what we can and can't talk about internally. - CEE stands for "Community It's an internal policy Meta rolled out in 2022 that forbids the discussion of controversial topics at work. Our sources told us CEE violations could impact performance reviews or bonus payouts. But Saima says posts about Palestine were nowhere near controversial and estimates that hundreds This post was one of the ones It honored Nakba Remembrance Day, when Palestinians commemorate displaced by Israel to create a Jewish state. But she says this post honoring the Holocaust -- with near identical language -- was not removed. And some told us that the removals claiming that the CEE team even removed posts featuring watermelons, including this post advertising the Meta Muslim club's plans to serve watermelon cupcakes at a companywide fair. Watermelons are a symbol because the colors match the Palestinian flag. The CEE team told the Muslims club they couldn't serve the cupcakes and suggested "a tasting of traditional Muslim sweets" instead. My team was shown dozens that workers say Meta removed. They included posts about Palestinian dance, food and olive trees. Even posts questioning the takedowns were said to have been taken down. If Meta has such a difficult time in moderating content amongst its employees and does it in what I believe to be a biased way, how can I and others trust that it can moderate content for billions of users? - In an email, a Meta spokesperson Being met with such dismissiveness and silencing is very jarring. What is my company doing? What are the leaders of this company doing? Tech companies have been firing people who are sympathetic to the Big tech has gotten very good at creating pretense for firing people. - That's Paul Biggar. He's a tech entrepreneur who runs Tech for Palestine, an organization looking to amplify Palestinian voices in the tech industry. He also tracks pro-Israel connections Big tech has taken a number of different approaches towards Gaza, but all of them have been extremely pro-Israel. - He, and several Meta employees we spoke with, say this is especially true with Meta where there are numerous Israeli and pro-Israel people in powerful positions. One of the most senior people at Meta - Rosen is the company's Chief Information Security Officer, and prior to that he was Vice President where he helped build Facebook's But before all that, he served in the Israeli military's elite Unit 8200, the secretive cyber intelligence group infamous for spying on Palestinians Rosen is based in Tel Aviv, where Meta has offices and He was someone who spent, you know, a significant amount of time being part of operations that were suppressing Palestinians. It's deeply disturbing. There is a pipeline from the - That pipeline is apparent at Meta. According to our analysis of LinkedIn data, there are dozens of current Meta employees who've publicly disclosed that they once worked for the Israeli military's Unit 8200 - many immediately before taking their current job. Why should the average person be concerned about this pipeline between the Israeli military - and specifically Unit 8200 - and the tech world? - Tech decides what we can see Meta decides what's visible on Instagram. Anyone who is using big tech's platforms is using platforms that's influenced - And influenced by the Israeli government, too. In 2015, Israel formed the Israeli Cyber Unit, an agency that sends requests to social media companies to remove content it says incites violence. In a five-week span after Oct. 7, that agency issued 9,500 takedown requests to social media platforms. These companies complied and took down that content 94% of the time. The majority of these requests went to Meta. Other high-ranking officials within Meta have ties to the Israeli government, too. - It's my pleasure to welcome the public policy director at - Jordana Cutler is the company's for Israel and the Jewish Diaspora - a position which has no Palestinian Cutler previously served as an advisor to Israeli Prime Minister Benjamin Netanyahu, and said this about her job at Meta in 2020: Inside the company, part of my job is to for the people here in Israel, voice of the government, for their concerns. I have an opportunity to really influence the way that we look at policy. - There's also Nicola Mendelsohn, whose husband was an Israel lobbyist, and who outraged many Meta workers when she was recently seen posing with the executive director of StopAntiSemitism, which, despite its name, is actually an organization dedicated to doxxing and harassing people who show support for Palestinians. And there's Meta's former who remained on the company's board of directors until January 2024. She recently fronted a documentary claiming there was a campaign of systemic mass sexual violence against Israeli women on Oct. 7. While there's been little evidence they have been used to drum up support for and justify Israel's attacks on Gaza. Sandberg did not respond to our request for comment on this story. - Someone who's so significant to the company, that influence is obviously gonna be spread throughout the entire company and the people that are hired and the people that are in senior positions. So this is like built into what Meta is. - Meta CEO Mark Zuckerberg also reportedly donated to an organization responsible for spreading Following Oct. 7, Zuckerberg the Israeli search and rescue organization that perpetuated the infamous Meta did not comment directly on Zuckerberg's donation, or the numerous other potential conflicts of interest we asked about. Instead, when asked if these ties influence the company's stance on Israel/Palestine, a spokesperson said: But Paul says that those ties may help explain how human decisions - not AI - help drive the platform's stance on We've seen a number of Meta policies, especially on Instagram around suppression. They deliberately are making these policies. - Like the decision to limit the reach of political content on Instagram, which Meta quietly rolled out in early 2024 amid global criticism of Israel's onslaught on Gaza. Or expanding the hate speech policy to include posts that target Zionists, a move many critics warn could stifle legitimate critiques of the Israeli government. - People should be able to People should be able to criticize an - And then there's the Israeli military's alleged use of Whatsapp metadata in deciding who to kill in the Gaza Strip, as reported by the Israeli-Palestinian The independent outlet reported that Israel is using AI systems that generate targets for assassination. Palestinians identified as targets by these computer programs are more likely to be bombed in their homes. One of the inputs Israel is believed is whether a person is in a Whatsapp group with someone else who is suspected Israel has not publicly confirmed that it does use Whatsapp data this way, and Meta told us that, But Meta engineers had been aware that governments around the world have the ability to exploit this vulnerability, and reportedly warned the company of this Do you believe that Meta is complicit in killing innocent civilians in Gaza? I want you to think about what that you make a product and your product is getting people killed. Your responsibility, it's to do whatever it takes to fix the problems that are getting people killed. And Meta instead decided to do nothing. To my mind, that makes Meta complicit. I think when we look back in 20 years at how the genocide happened and how complicit big tech was, all of us are going to wonder - Israel's nonstop bombardment of Gaza has killed more than 41,000 Palestinians as of October 2024, and 2.3 million remain trapped in the tiny enclave with nowhere safe to flee. The International Court of Justice is Meanwhile, millions of continue to try to post about the horrors imploring the world to do something. - As for Meta's employees who are trying to advocate for Palestinian rights and humanity, their fight to be heard remains an uphill battle. Tomorrow's gonna be my last day at Meta. - Because I can no longer give my that I believe is complicit in the murder - Shortly after our interview, unable to access enough food or medical care, had died in northern Gaza. Saima has since ramped up her organizing with other tech workers around the country as part of the No Tech for Apartheid campaign. And Meta's lawyers are trying to to a confidential arbitration behind closed doors, to avoid a public trial. Omar and his lawyers are fighting that move, because they believe the public A hearing is scheduled for later this year. What are you hoping to get out of this lawsuit you've brought against Meta? - My main demand is really just, like, treat all your employees with dignity and respect, including the Palestine, Arab, Muslim ones. Because if you can't treat all your you're not gonna treat all your users with respect. - Meanwhile, our sources within Meta tell us that there remains a widespread sense of suppression towards Palestinians and their allies. Despite that, many employees have not been deterred from continuing to advocate for equity both internally and on the I wanna tell you that there's a growing some are still there, but some have been fired - and they're fighting to hold Meta accountable. What do you say to them?