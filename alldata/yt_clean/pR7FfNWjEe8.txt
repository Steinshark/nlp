Your attack surface just got a lot bigger. that is taking the world by storm and can do with it and new risks. In fact, 4 out of 5 can really trust generative AI because they have They have concerns related to privacy and don't address those issues, we don't have trust technology. So what do we need to do in order to that will allow us to take a look at these issues. how it works. Well, what starts is we have data. and we use it to train and tune our models, which the data to train the model and then ultimately is where we get our output. So this is how the at how we're going to secure each one of those. model? How do I secure the usage? And it turns take a look at that I'll show you before the video data itself. This is the data that we're going a bad guy is going to look at that and see what it exists, they're going to try to mess it up. I'll tell you. And what they're going to do in If they poison the data, then basically they that go then into the training and tuning of the a consequence of that. Another thing that could attack would be where someone breaks into this maintain a large set of sensitive information. And be a more unintentional versus exfiltration is effect is the same. This sensitive data--and we may model and tune it because that will make it more result, now this ends up with a big bullseye on it we're going to have to try to secure that. How be taking note of is we should do data discovery sensitive data is. Maybe these data sources were But now that we brought all this together as a controls and we need to. Classify that so that we necessary. We want to also use cryptography so out or gets exfiltrated out is of no harm. No one also add things like access controls, which make system using strong multifactor authentication to monitor the system. I want to know if this actions and do the right sort of countermeasures about securing the model itself. Now, how does develop models for their organization because it's effort. So most people are leveraging existing source. And knowing where you're getting your So typically I would import models from a lot of maybe I get a model that I think is trusted one that has been modified in some way. And so the models as a supply chain, and I have to do that go into whatever system I'm going to use. So I can trust what my sources are, and I need to be not just bad information, actual malware. There concept to show that malware could be introduced be able to look for those kinds of things. Also, to communicate out to other services--maybe to it directly ourselves. That API path could also introduce some sort of error that then affects elevate privilege, well, I need to be concerned limit what it's able to do so that it's not able out, or even modify parts of my system. I want guard against some of those kinds of things. And but how about an IP attack, intellectual property? copyrighted works in one of these sources, because not really I'm permitted to be using. So what against this? Well, I need to scan my systems look for any type of of of harmful code that's able to harden my system. That basically means I'm all the default user ID and passwords. All of to withstand an attack. And I do that hardening by as I can. Then I use things like role-based access like this can't do more than it's supposed to per account basis. And then look at my are trustworthy, make sure that they don't contain legally and things like that. So while these are more IT, this is IP. usage of our generative API? We've looked at the out one of the main ways that this system can actor, is through what's called prompt injection. on a list of top 10 vulnerabilities mentioned by So prompt injection. In that case, we have a user large language model or generative model that's do things that it was not intended to do. Trying It's almost a semantic attack. It's an attack with So we basically with that can also sometimes bias comes out of the system is now not as trustworthy may do is a denial of service. If I send enough maybe it starts bogging the system down. Because can answer it. So we send in a bunch of these and keep up anymore. And then the last one that I'll might not be able to just break in and steal your storing of your data and securing all of that. queries into the system and then take the output can basically mine the model in order to get potentially go build their own version of this. the process. So what can we do to guard against should do is monitor. In this case, monitor the those. We'll never be able to put all the kinds that someone can never get in. But we need to at will probably be a new class of tools that we're machine learning, detection and response. So this for a long time, but something that's specifically models. This is going to be a new emerging area some of our fundamentals using security a security orchestration, automation and response see the abnormal inputs. I can see if the system things like that. If someone's carrying data out. order to be aware. So there you have a way that Okay, now for the big reveal of the two elements I told you I does not exist in a vacuum. It runs on IT systems. all of this--traditional computers. And the way talked about before. That's what supports all of what they do. And what I've discussed before, is integrity and availability. Those are the concerns concerns don't go away just because now we move always done, plus a little bit more. And that that I've been talking about in the video. But infrastructure itself and doing the basic blocking system. And then finally, the last element here is but it's a big concern for the functional I need to be able to direct, manage, and monitor it's fair, that it's not biased, that the model introduced some incorrect information in it. occurring. I need to be able to keep up with And ultimately make sure that the system operates well. Put all of these things together and this if we think about--to summarize--what I've AI to create better security. And there are a do in order to make us better. Make this a force ever done. And then what has been the subject of that the AI is secure. So it's AI for security then we win. Thanks for watching. If you found more about cybersecurity, please remember