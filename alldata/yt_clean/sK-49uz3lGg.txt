During the mid 1960s a revolution The idea of packing dozens of on to a single silicon chip It laid the groundwork for a modern society would evolve. In less than a decade, this and materials sciences would incomparable to anything In the March of 1971, the semiconductor product set the stage for this new era. Composed of a then-incredible 2,300 processing unit or CPU was released. Initially created as a custom solution for use in the Busicom 141-PF that year to the general public. With prophetic irony, the the chip touted the slogan "Announcing a new era in But what made the Intel Take calculator and solve any let's say 22 divided by 7. What we just did was issue Instructions are elementally commands that a CPU executes. Every computer program ever made, games is composed of millions of these instructions. The 4004 was capable of 92,500 instructions per second. For comparison, ENIAC, the first years earlier could only execute But what made the 4004 so increase in processing power electricity, was about 3/4" long and This was miles ahead of in today's money, 180kW power Fast forward to September the Intel Core i9-7980 XE. This CPU is capable of performing a second, a 900,000 time What did it take to get here? In this 2 part series we explore the technology that paved the way for in the powerhouse of CPUs today. This is the evolution HOW A CPU STORES DATA In order to understand how a CPU examine what a CPU actually does In digital electronics everything It's an elemental representation A bit can represent a zero or one, off, or any other bi-state value. In a CPU, a "bit" is physically If we combine multiple "bits" together more combinations of discrete states. For example, if we combine what's known as a byte. A byte can represent 256 used to represent numbers. In the case of a byte, any number But in a CPU, how we is completely malleable. That same byte, can also represent Other expressions of that byte When we combine multiple what's known as a word. Words are expressed A 32-bit word contains 32-bits. A 64-bit word contains When processors are created, the forms the core of its architecture. The original Intel 4004 processor This means data moving chunks of four bits at time. Modern CPUs are typical 64-bit, are still quite common. By making use of larger word sizes and consequently larger numbers. A 32-bit word for example, billion different states. Of all the forms data can take one is that of an instruction. Instructions are unique bits executed by the CPU as operations. An example of a common instruction values together or move a word memory to another location. The entire list of instructions its instruction set. Each instruction's binary code is typically assigned a known as a assembly language. If we look at the instruction set focus around performing math or conditions or moving it from one For all intents and purposes, instruction processing machine. They operate by looping fetch, decode, and execute. As CPU designs evolve these three step and technologies are implemented that But in order to fully appreciate the mechanics of basic CPU operation. Known today as the "classic or [RISC] pipeline", this paradigm designs, such as the Intel 4004. In the fetch phase, the CPU be executing into itself. A CPU can be thought of as It pulls instructions and data from within its own internal environment, This data is typically stored in Random Access Memory or [RAM]. Software instructions and more permanent sources such as But at one point in history even flip switches were used. When a CPU loads a word of data contents of a location in RAM. This is called the data's address. The amount of data a CPU can by its address capacity. A 4 bit address for example, can only Mechanisms exist for addressing more but let's ignore these for now. The mechanism by which data moves A bus can be thought of as the CPU and RAM is which each But we also need to transmit the so a second highway must be added the data word and the address word. These are called the data bus In practice these data and address connections between the CPU and superhighway on a circuit board. When a CPU makes a request for region of the CPU loads the address it wishes to access. It then triggers a control line Upon receiving this request the RAM of the requested memory location. The CPU now sees this data on the bus. Writing data to RAM works in posting to the data bus instead. When the RAM received a "write" bus is written to the RAM location The address of the memory location in a mechanism called a register. A register is a high speed internal "notepad" by CPU operations. It's typically used as a temporary but can also be assigned to keeping track of the current Because they are designed innately only have a handful of registers. Their word size is generally coupled Once a word of memory is read into the address of that words, known as On the next fetch, it retrieves Accessing data from RAM is typically This is due to the need to physically distant from the CPU. On older CPUs this doesn't present get faster the latency of memory The mechanism of how this is of processor performance and will series as we introduce cacheing. Once an instruction is fetched In classic RISC architecture, a complete instruction. This changes to a more elaborate instruction set archicture, in part 2 of this series. When a instruction is decoded, two parts known as bitfields. These are called an A opcode is a unique series of function within the CPU. Opcodes generally instruct the CPU data between a register and memory, on a registers and branching. Branching occurs when an the program counter's address. This causes the next fetch to occur to the next sequential address. When this "jump" to a new program called an unconditional branch. In other cases a test can be done to This is known as a conditional branch. The tests that trigger these such is if a register or or greater than a number, or Branching allows program crucial to the power of a CPU. Opcodes sometimes requires data This part of an instruction Operands are bits piggy backed onto Let say we wanted to The binary representation of the instruction and extracted by the When an instruction has an embedded its know as an immediate value. In some instructions the operand self, but contains an address to a This is common in opcodes to be loaded into a register. This is known as addressing, complicated in modern CPUs. Addressing can result in a need to "leave" the CPU but this Once we have our opcode and operand table and a combination of circuiry various operational sections of In some modern CPU's the decode phase This allows for the changing in how CPU is configured for execution. In the execution phase the now This may occur in a single depending on the opcode. One of the most commonly used the Arithmetic Logic Unit or ALU. This block of circuitry is designed perform either basic arithmetic or The result are then outputted flags, such as a carry over, The output of the ALU is then sent in memory based on the opcode. Let's say an instruction calls placing the result in that register. The control unit of the CPU of the instruction into the ALU, load the value of the register ALU output to the register. On the execute trigger the loaded into the register. In effect, software distills groups of circuits to interact In a CPU these 3 phases of operation way through the instruction of the Gluing this looping machine A clock is a repeating pulse use mechanics and its interface CPU clock rate is measured by the The Intel 4004 ran at 740 KHz Modern CPUs can touch clock 5 billion pulses a second. On simpler CPUs a single clock fetch, decode, and execute stage. As CPUs get more sophisticated clock cycles to complete. Optimizing these stages and their increasing processing power and will The throughput of a CPU, the amount a second determines how "fast" it is. By increasing the clock rate, through its stages faster. However as we get faster The period between clock cycles for every possible instruction If a new clock pulse happens completes, results become Furthermore, increasing clock rates power dissipation and a buildup degradation of cirucity performance. The battle to run CPU's faster dominated its entire existence. In the next part of this series we'll from that simple 2,300 transistor microcomputing boom of the 1980s, and designs of the 90s and early 2000s. We'll introduce the rise of the move to larger bit CISC to multi GHz clock rates.