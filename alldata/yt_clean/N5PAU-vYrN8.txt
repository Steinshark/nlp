Intro we'll compare Nginx with Caddy, a web In the first test, we'll use both Nginx and with default compression enabled on both latency, which we'll measure using we'll check how many requests each web we'll monitor CPU and memory usage as well as network traffic. Finally, we'll measure In the second test, we'll use both and load balancers to distribute traffic to we'll measure the CPU and memory To run all my tests, I use AWS and the latest EC2 For example, in this video, I'll provision an same EC2 types for the applications. I'll also to run my clients and generate load. I also for service discovery. I run each benchmark for 50 dollars per test. I use Terraform to create a VPC and all necessary test, I use Next.js, a React-based JavaScript compile it to HTML, CSS, and JavaScript files. server, each with 2 CPUs and 8 GB of memory, create a self-signed certificate authority To generate load, I create an EKS cluster using Kubernetes jobs. I provide each client servers. This setup is typical: both web servers to reduce payload size and HTTPS for security. TLS to HTTP/2, a more efficient binary protocol. EC2 instances behind each server, using the same configured as a reverse proxy and load balancer to it. Here, we're not using compression because the hardcoded data to the client. Additionally, I IP address using the X-Forwarded-For header. from a client, it terminates that request and using its own IP address as the source. If of the client, you'd use the X-Forwarded-For Configuration Overview I mostly used default settings for Nginx, I got a pull request from Melroy with benchmark. I made a few additional configuration These changes didn't have much impact on improved Nginx's performance in the second and load balancer. This configuration and I had to increase the open files limit. port 443 for HTTPS, and provided a certificate second test, I declared an upstream service to distribute traffic to the applications. and that's about it for Nginx. You can find the link will be in the video description. version, 1.26.2. For this test, I used the latest Now, on the other side, we have Caddy. As point is simplicity. If you don't want to spend which does everything Nginx does with minimal beginners. According to the documentation, a production-ready setup for Caddy. "production" settings to test it. Caddy, enabling compression as well. I provided my directive to serve the website. By default, it fair, I used a format similar to what Nginx and For the second test, I also used minimal in terms of functionality, both web servers use For Caddy, I used the latest 1st Test - Web Servers the first test. As far as I'm concerned, latency along with availability, of course. At the start latency in serving the static website. Based on fail first. Memory usage, on the other hand, is GB limit. You'll also notice that Nginx transmits because its compression level is a bit lower. reaches 50% CPU usage, and its latency starts to your use case, and your expectations request, beyond which it would be considered a timeout, after which a 408 status code is At around 8,000 requests per second, you Nginx in terms of the number of requests per spikes become noticeable, which I believe may be mistaken. Let me know what you think about these At around 10,000 requests per second, Caddy is Nginx. For this test, I deployed Nginx and Caddy here. Now, let's see how many requests Nginx It took a while, but eventually, Nginx reached same result as in the previous video with Apache. the previous test, Nginx reached 80% CPU usage and same number of requests, it kept running. test duration. As you can see, the First, we have the requests-per-second graph. started to degrade and maxed out at around 10,000 managed to process over twice as many requests, Next, let's take a look at latency, measured After Caddy began to degrade, we expected start of the test. Nginx was much more stable, For client-facing applications, lower latency is Next, we have CPU usage for both web servers. so lower CPU usage generally means a better user Next is memory usage. You can see several the total memory available to each web performance or lack of it in this case. see an increased error rate toward the end of really only 1 or 2 requests out of thousands per there aren't any errors for Caddy. Nginx tries to doesn't accept new requests when overloaded. Finally, we have network traffic. At its 600 MB per second, while Caddy If you're a beginner or a web developer who server, Caddy is a great choice to start with. If Caddy is ideal, but Nginx offers better you could save nearly half the infrastructure but if you're just getting started and using Caddy will work fine. Alright, let's go ahead and run the second test. proxy and a load balancer. At the start, I was but this didn't last long. By the time we reached Caddy's latency started to increase. In contrast, What surprised me most in this reverse proxy test much more load than those behind other reverse with Apache, it showed the same trend. If you In this test, Nginx's memory usage but memory usually doesn't play a significant At around 10,000 requests per second, Caddy as in the previous test. I suspect but let me know if you have other thoughts. Caddy reached almost 100% CPU usage and could no notice latency spikes at this point. Now, The entire test took almost 3 hours, and Nginx This is significantly higher than in the Apache if you're planning to use Nginx as a reverse relying on default settings. for the entire test duration. could handle only around 14,000 requests per at around 27,000 requests per second. start of the test, Caddy initially performed Next is CPU usage. On the availability graph, Caddy's availability Nginx only dropped to 99.99%. Then we have CPU usage of applications something unusual here with Nginx. Let me Finally, we have memory Now, I see a use case for Caddy as a web server setting up a load balancer and reverse proxy, you architecture and learning more about web Nginx provides much higher throughput with lower instead of Caddy, I'd recommend a others. I'll definitely test more Thank you for watching, and