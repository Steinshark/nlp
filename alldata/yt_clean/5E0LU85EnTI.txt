In this episode you will learn everything one of the major new features of the JDK 21. To avoid blocking a platform thread. This And instead of blocking the You will learn why they have been added to the them, what performances you may expect from Let us start from the beginning: why The effort to add them was huge, it took massive, so there must be a good reason. problem that has to do with asynchronous Suppose you have to query a remote database for and you need to fetch the full You are probably going to write this kind of code. First, you need to create a request, probably in the form of a Json object. the network. After a while you get a response, and then you unmarshall this object This is the kind of code you end up with, simple simple to test, and simple to maintain. it is performing this request? it's just in-memory computations, so order of several tens of nanoseconds. network. This one takes much longer, probably And your CPU is not doing anything waiting for the response to come from the server. computation: the unmarshalling of a Json On the overall, this code executes So to compute how busy your CPU is, you just need and unmarshall the Json response, that is several waiting for a response from the server. that's the order of magnitude. In a nutshell, The first solution you may be thinking about is the classical model is to have on request per This has been working for years, years ago. busy 100% of the time with such an approach? So need to keep your CPU busy 100% of the time. with 10 threads you have a CPU usage of With 1000 threads you can expect 0,1% To have a CPU busy 100% of the time, you It turns out that a thread in Java is actually sometimes called a kernel And this thread consumes quite some resources. upfront. So creating a million of them But there's worse: creating a thread also So creating a million of them would which is a little more than 15mn. in a loop, depending on your operating system, at about a few thousand threads. will quickly reach that limit, and your CPU So unfortunately, the solution that each request is not a viable solution to This has been known for years, and this is why If you take a step back and examine the initial actually two solutions to improve this situation. of requests per second. you need to launch your requests in parallel. not lead to a viable solution, because So at this point you have indeed two solutions: less expensive than the current kernel, than one request per platform thread. means that you cannot write your code What you need to do is to split this code into inputs, is doing one thing, and produces a result. operations as lambdas, and then you need to wire In a nutshell, the job of this framework is to get the outputs, and to transmit these What you are creating are pipelines of are executed by the framework you are using. correctly execute your operations in the threads it has, to keep your CPU busy, and At some point, one of your lambda will launch immediately return, to make sure that it it. Avoid writing blocking lambdas. has nothing more to execute, it is free to do and there is a handler somewhere that will Your framework knows this handler, it knows then it is its job to run your next lambda, data. This lambda is invoked, once again, by Because these two operations are two different else in the meantime, like launching There is obviously an overhead in doing that, and much more efficient than blocking a thread. and optimized over the last 10 years, and this with great success. Using this technique, of requests per second, and you have many What does it require from you, as a developer? code. Remember, you need to create these Now I would like to take you through Nurkiewicz, a famous author and speaker, and The problem you need to solve is the following, doing some online shopping, and what you want a database, and that you send this user and email The first step consists in making sure Then you fetch the shopping cart. chose, to compute the total price, pretty simple. and record the transaction id. the email with all the details of the transaction. and the code is simple enough to understand. sure that the business process because it's just a simple piece of code. executing it step by step is easy. unit tests, don't you?) is also super easy. that tells you: &quot;oh, if a person spends more that person a coupon&quot;, you know exactly what And this code is going to be very simple. do with this code is easy, because it is just a that exactly maps the business process The only problem is that, as you saw, it to adapt this code to the asynchronous What would it look like to adapt this The CompletableFuture API is part of the Well, it looks like this. And that's a problem. the problems that this code has? was easy to follow, and thus, it was easy in implementing the business process. Let me just highlight the portions What you see is that they are drowned in a mess of how these pieces of code actually work together. business code are hard to spot, See? What if the return type of this call that you are returning the right thing? the new business requirement we just talked about our site, we need to give that person a coupon&quot;. And how can you add it in this mess? Debugging such a code, for instance, running Writing unit tests is also super hard. All which is not really a unit test anymore. but unfortunately they are not the only ones. version of the code, the stack trace will give running. You know exactly where you are, and what Because it is there, written in the stack trace. version are executed by your framework. which means out of the context of your application that triggered this processing, was and it is now gone, doing something else. Meaning that it is not in the stack trace anymore. lambdas, getting the results and forwarding the So if you examine the stack trace, you do not is your framework calling your lambdas. If you are lucky and an exception is thrown within you there, and you can do something. null value for instance, that triggers a then you are in trouble. Because the stack trace Suppose one of your lambda doesn't return, because If you are lucky you have a timeout somewhere the stack trace tells you that a timeout about what lambda actually triggered the timeout. have a stranded lambda, that is preventing a lost somewhere, in some event queue, never to be Not having a meaningful stack traces has and for the same reasons, impossible to profile. performances, but the cost of maintenance is So if we step back to our initial problem, can dramatically improve your requests per but you also understand that it comes with So now you are left with the first solution Before we move on, we need to answer a question: to make it so that you could solve less expensive threads, and not having to Well the answer is in this little table we in the order of a million threads. in the order of a thousand of them. a thousand times less expensive than the current If this can be achieved, then writing becomes compatible with the number And you will not need to write Would it work if the gain is only a hundred Well, no, because in that case And if the gain is 500, then So to reach max throughput, you would A,d This new type of thread So gaining a factor of a thousand, is And this is what virtual threads are giving much lighter than platform threads, You can easily launch a million Virtual threads are so lightweight, that When you need one, just create it and let What is the magic trick that makes this possible? magic trick, just engineering, and Underneath you still have platform threads, are using to execute several tasks in So the trick is still about running A virtual thread has to run on top of a platform And if you want to have a million of these platform threads. first virtual thread an run it. previous example, and let us make the so that we can run it in a thread we create. which is very easy too. You now have two ofVirtual(), to create virtual threads, and Of course you can still use the old pattern, You can then use one of the methods available on need: you can set the name, and you can allow And bytheway, there is also a factory method that called newVirtualThreadPerTaskExecutor(). The virtual thread on demand, everytime you submit This executor service may be very useful if you on such an executor service, and you want to check And then, because a virtual thread is a can do with a regular thread: you or suspend it, or you can join it for instance. virtual thread, which is: you cannot make it a a daemon thread. So having live virtual threads in It also means that all the problems you may come Race conditions, deadlocks, visibility, programming stuff, is still there with But the good news is that it also means ensure the correctness of your code Now, let us take a closer look at how the code from our example. virtual thread is executing a Runnable? threads, which is bytheway a modified fork join So your virtual thread is mounted and your task is executed by this platform If you print a virtual thread, you will get this mounted on the worker 1 of the Fork Join Pool 1. that many actually: one for each core of your CPU. a request on your database. It This is a blocking code, and you know that This is exactly the role of a virtual it is actually executing a blocking I/O operation. running on, it unmounts itself from this that is its stack to somewhere else in What is happening under the hood is the following. special object called a Continuation. This so you should not use it in production. that executes your virtual thread, When a blocking call is issued a call to Contination.yield() is made. And thread from the platform thread, and copies the Of course Contination.yield() is only invoked the context of a virtual thread of course. &quot;Hey, I won't be needing the CPU for a while, so please, remove me from this platform thread&quot;. in Java NIO, actually all the blocking been refactored to call this Continuation.yield(). And that also includes the synchronization And then at some point the data from the response monitors this data then triggers a signal, that takes the stack of your virtual thread from the and puts it in the wait list of the platform Because this is the way the fork join and another thread is available, then this other So you may observe that your task thread to the other while it was blocked. the hood. As you can see: no magic, just What is the cost of all this? And are there any are indeed caveats, so let us go through them. is the cost of running it in a platform expensive to run a task in a virtual thread Let me say that again: it is more expensive it in a platform thread. Because the cost of blocking a lower than blocking a platform thread. Well, it's the cost of moving the stack of your from the stack to the heap memory and back. but it is certainly much much much less to block a platform thread, that would include the So running a task in a virtual thread is because there you will have this gain. in-memory computations in a virtual this is not why virtual threads have been made. threads, you'll actually You are not doing I/O in If you check how the JVM is working, you will running in a platform thread, and the same These are in-memory computations, The caveat you need to know has to do with Moving this stack around is OK, as addresses on this stack. You cannot but you can in C or C++. And your Java So if the JVM detects that you have native it will pin it to its platform thread to And a problem you may have heard before is that If you have a synchronized block thread is pinned on your platform thread. Well, your first reflex should be to do A performance problem may occur if you pin a If your native code, or your synchronized block will take in the order of the hundreds of you will not see any performance loss. is guarding some in-memory data structure to On the other hand, if you have some I/O operations thread for hundreds of milliseconds, then maybe The good news is that you can replace your that will do the same without But remember, you don't have to do that, pinning a virtual thread on its platform As usual when it comes to All right, let us wrap up all this. threads are a new kind of threads Cheap to create, you can have million of them non-blocking asynchronous code anymore, thread is just fine. Please, do it! them on demand, and let them die at You should only run blocking, typically I/O computations is useless, don't do that. code or when you do some synchronization, your That may be an issue if you are doing I/O One last word: odds that you will not your application. But don't worry, most of supporting, or working on supporting virtual Spring, Quarkus, Spring Boot, or Helidon. It you want to learn more about virtual description, I just added links to other If you're interested to learn more about you can check the other episodes of this And with this I'm out of coffee, so,