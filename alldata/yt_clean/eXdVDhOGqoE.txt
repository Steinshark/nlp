So I've been an AI researcher And a couple of months ago, A random stranger wrote to me saying that my work in AI Now I get it, AI, it's so hot right now. (Laughter) It's in the headlines sometimes because of really cool things like discovering new or that dope Pope But other times the headlines like that chatbot telling that guy or that AI meal planner app featuring chlorine gas. And in the background, we've heard a lot of talk existential risk and the singularity, with letters being written to make sure that doesn't happen. Now I'm a researcher who studies and I don't know what's going and nobody really does. But what I do know is that there's some because AI doesn't exist in a vacuum. It is part of society, and it has impacts AI models can contribute Their training data uses art and authors without their consent. And its deployment can discriminate But we need to start tracking its impacts. We need to start being transparent so that people understand AI better, so that hopefully future are going to be more maybe less likely to kill us, But let's start with sustainability, because that cloud that AI models live on and powered by vast amounts of energy. And each time you query an AI model, Last year, I was part which brought together from all over the world to create Bloom, the first open large language but with an emphasis on ethics, And the study I led that looked found that just training it as 30 homes in a whole year and emitted 25 tons of carbon dioxide, which is like driving your car just so somebody can use this model And this might not seem like a lot, but other similar large language models, like GPT-3, emit 20 times more carbon. But the thing is, tech companies They're not disclosing it. And so this is probably even if it is a melting one. And in recent years we've seen because the current trend in AI But please don't get me started In any case, we've seen large grow 2,000 times in size And of course, their environmental The most recent work I led, more efficient model emits 14 times more carbon Like telling that knock-knock joke. And as we're putting in these models and smart fridges and speakers, the environmental costs So instead of focusing on some let's talk about current tangible impacts and tools we can create to measure I helped create CodeCarbon, a tool that runs in parallel that estimates the amount and the amount of carbon it emits. And using a tool like this can help us like choosing one model over the other or deploying AI models which can drastically reduce But let's talk about other things because there's other impacts of AI For example, it's been really to prove that their life's work without their consent. And if you want to sue someone, So Spawning.ai, an organization created this really cool tool And it lets you search to see what they have on you. Now, I admit it, I was curious. I searched LAION-5B, which is this huge data set to see if any images of me were in there. Now those two first images, that's me from events I've spoken at. But the rest of the images, They're probably of other who put photographs of And this can probably explain why, when I query an image generation model to generate a photograph more often than not Sometimes they have two arms, sometimes they have three arms, but they rarely have any clothes on. And while it can be interesting to search these data sets, for artists like Karla Ortiz, this provides crucial evidence was used for training AI models and she and two artists to file a class action lawsuit for copyright infringement. And most recently -- (Applause) And most recently Spawning.ai the company where I work at, to create opt-in and opt-out mechanisms Because artwork created by humans for training AI language models. (Applause) The very last thing I want You probably hear about this a lot. Formally speaking, it's when AI models that can represent stereotypes One of my heroes, Dr. Joy Buolamwini, when she realized that AI systems unless she was wearing Digging deeper, she found were vastly worse for women of color And when biased models like this this can result in false accusations, which we've seen happen For example, Porcha Woodruff at eight months pregnant because an AI system But sadly, these systems are black boxes, and even their creators can't say exactly And for example, for image if they're used in contexts based on a description of a perpetrator, they take all those biases for terms like dangerous criminal, which of course is super dangerous when these tools are deployed in society. And so in order to understand I created this tool called which lets you explore the bias through the lens of professions. So try to picture Don't look at me. What do you see? A lot of the same thing, right? Men in glasses and lab coats. And none of them look like me. And the thing is, is that we looked at all these and found a lot of the same thing: significant representation across all 150 professions even if compared to the real world, the US Labor Bureau of Statistics. These models show lawyers as men, and CEOs as men, even though we all know And sadly, my tool hasn't been used But I recently presented it as an example of how we can make tools even those who don't know how to code, to engage with and better understand AI but you can use any terms And as these models are being deployed, are being woven into the very our cell phones, our social media feeds, even our justice systems And it's really important so that we know both how it works And there's no single solution or copyright or climate change. But by creating tools we can start getting an idea and start addressing them as we go. Start creating guardrails And once we have this information, companies can use it in order to say, OK, we're going to choose this model this model because it respects copyright. Legislators who really need can use these tools to develop or governance for AI And users like you and me to choose AI models that we can trust, not to misrepresent us But what did I reply to that email that said that my work I said that focusing is a distraction from its current, very tangible impacts and the work we should be doing for reducing these impacts. Because yes, AI is moving quickly, We're building the road as we walk it, and we can collectively decide Thank you. (Applause)