AI offers boundless potential, diagnosis to making empowering us with education. The potential is immense. While AI can realizing this potential to solve some really important challenges. So I would like to talk with learning we termed We began to develop this some of the challenges that we Because despite the we also have plenty of that remain to be solved. So first among the AI We require huge gets fed in immense models. And these models have huge costs. We also have an issue because if the data the performance of the Bad data means bad performance. Furthermore, we have where it's really how the system makes decisions. And this is really for safety critical So let me show you the And I will show this to you in driving application. And then we can So here is a self-driving car, at MIT using traditional And it does pretty well. It was trained in the city. It drives really well in environment. It can make decisions It can recognize the goal. So it's pretty good, right? But let me open the this vehicle makes decisions. So you will see in the You will see in the upper left And the decision-making engine in the middle with blue And there are about that are working together And it is absolutely how the neurons the vehicle does because There's also half a Take a look at the where we see the attention map. This is where, in the image, to make decisions. You see how noisy it is? You see how this vehicle is at the trees on the So this is a bit of a problem. Well, I would like to do better. I would like a vehicle whose And in fact, with we have a new class of models. And here, you can see the for the same problem. Now you will see consisting of 19 artificial And look at the attention map. Look how clean it it is on the road horizon and is how I drive. And so liquid networks seem to than deep networks. And because they have many other properties. So in particular, we can and turn them into Now, that could show the humans And so they are much where we can have is understandable. We can apply liquid networks Here is a solution And this is driving a plane in The plane has to hit these And it's really extraordinary is 11 artificial neurons, in order to solve this problem. So how did we accomplish this? Well, we started by the framework. And in continuous networks, is defined by a series of And these models are kind of includes standard recurrent neural ODEs, continuous liquid networks. And it's really by using differential equations networks, we can model very like problems that For instance, in the half-cheetah standards. And it can be modeled elegantly networks. However, when you take an solution and you model like can you get this you actually get performance better than a standard LSTM. And so, however, with liquid OK, so how do we achieve Well, we achieve it with two First of all, we that defines the We start with a linear and then we introduce over the synaptic connections. And then when we plug these we end up with this equation. And so what's interesting that the time constant that is actually dependent on x of t. And this allows us to have are able to change their on the input that they We also do some other changes, architecture of the network. And you can read about And so, now, let's go of a whole suite of networks, and other solutions. So back to the driving you'll see that all previous looking at the context, And in fact, we have for this result. We can actually solutions are causal. In other words, they in ways that are consistent with of causality. Now, I promised you But these networks are defined So you might ask, do they really because that would actually Well, it turns out solution for the hairy equation And the solution It's good enough. And you can see in this chart, and in blue, the solution And you see that they are really So these liquid networks can because they form causal models. Unlike other models defined like neural ODEs and these networks recognize when by certain interventions. And then they learn how to All right, so let me to convince you that these So here, we have a We are training a drone Notice that it's summertime. So we give our drones like you'll see in this example. And these are not And we train a for instance, a standard And now, when we get the in that environment to find you see that the model The attention is very noisy. And then also notice that because now it's fall time. So the context of Because deep networks are they don't do so well. But look at our liquid They are so focused on the task. And the drone has no We can further go all with the same model And we get a good solution. And finally, we can even entirely. We can put it in an And we can go from a static The same model trained in does well in this example. So this is, again, a provably causal solution. So liquid networks are a new They are compact, And they have shown great under heavy distribution shifts. Thank you. [APPLAUSE]