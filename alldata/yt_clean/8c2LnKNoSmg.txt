Have you ever wanted to have a conversation with a llama? Well, you can't today. But Llama models are the next best thing. Today I'll cover what is Llama and we'll talk about how the Llama model is transforming our world as it is and talk about the past, present and future. So let's talk a little bit more about what is Llama. First, Llama is an open source model, which means it's built with open data and the code is open for all of us to consume and use it. It also means that we can do a few special things with the model. Because it's open. First, it's transparent so we can see exactly how the model was built and we know its shortcomings as well as where it may outperform others. Second, we can customize it. There's a lot of benefits to customization and being able to actually parse the model, potentially create smaller models and do things like fine tuning to make sure the model works. Specific to your use case. Third is accuracy. We can have more accurate models with smaller size, which means less cost and less time to build. So. How overall does Llama differentiate from other models on the market? Well. The biggest thing is it's much smaller than some of the proprietary models on the market. Again, this means less money, less time, which can be huge benefits to you as you use and consume it. Second, related to customization. You can build models specific to your domain and your use cases, right? So you're not using a general purpose model that answers everything. You're able to take that model and make it specific to you. All right. Now, let's talk about the history of Llama. So the first version of Llama came out in February of 2023. And what Llama does is it's trained on words and sequences of words. And it takes the previous word and tries to predict what the next word is. And the first version of Llama range from 7 billion parameter model up to a 65 billion parameter model, so much smaller than other models that were released on the market at that time. And really the first of its kind for the small model market. Next, we had version two of the model come out in July of 2023, and this included some performance updates. And we focused in here, Llama did on the 7 million model and going up to a 70 billion parameter model. And if we look at the performance compared to size, what this did with each release is with the first release, you know, let's just say we had performance, good performance and small size. Now with the second release with the V2, we had stronger performance relative to the same size, so much higher performance. And that focus really continued on with the future releases. So we had a Code Llama release. In August. of 23. And these were code models specifically. So more domain specific models than the prior models released. And one of them focused on Python. So very helpful for developers out there that want to use open source models for code development. Next we had Llama three. Llama three was long awaited and came about in April of 2024, earlier this year. And with the Llama three model, very exciting. Again focused on the same range of models from 7 billion to 70 billion and a few other sizes in between. But again, Llama was focused on increasing that performance relative to the same size. And we see that trend continue all the way into the most recent release in July of 2024 with Llama version 3.1. And there's many exciting features of the Llama 3.1 release. The first is this model is multi lingual, which is very exciting. So we had some training data before that used previous languages, but this model has heavily focused on having the latest multilingual capabilities and can fully converse in many different languages. Second is the context window. The context window is the amount of data that is output of the model relative to the number of tokens. So what this means is that now Llama can produce more text for a single run of the model. And this is exciting because you have more ability to run the model in different places. But it also introduces some security risks. And to combat that, Llama has been some of the first on the market to introduce techniques like Llama Guard. Which impacts and influences the security. So this makes sure that techniques like prompt injection are less likely and preventable from happening with that context window. And finally again, Llama focused on power. So this time lama went much bigger in size, but better in performance with actually releasing a 405 billion parameter model so much, much larger than the 70 billion and 65 billion that we had before. But we see exciting, strong performance that competes with several of the other large models on the market that today are proprietary. And this model is completely open source. Okay. Now let's talk about some of the best ways you can use the new exciting enhancements with Llama 3.1. First is for data generation. So you can actually take the 4 or 5 billion parameter model and you can generate your own data. This is particularly interesting to data scientists and data engineers that may have spent. Days or weeks, sometimes getting access to the data you need to build a model. Well, now you can use synthetic data generation to generate the data in just a matter of minutes, which is huge, huge productivity enhancements. Next, we have knowledge, distillation. So we can take that model and break it down and also find more specific domain applicable use cases. And then finally, we can use the model as an LLM judge so we can look at several different LLMs and use Llama to evaluate which model is best for our given use case. Today we covered what is Llama. We covered the past. We covered the present. We covered the most common use cases. But let's think about what is the future of Llama. What are you most excited to see in the next Llama release?