Intro no Rails just Ruby with Node.js standard library. Ruby on Rails--a large framework Active Record--with bare-bones Node.js. Konstantin with a pure Ruby implementation, which I had to test it, so I released an updated and optimizations specific to Kubernetes, As always, we'll measure latency using the p99 histogram buckets. For throughput, we'll measure handle. We'll also measure the saturation of the pod limit and memory usage. And, of course, we tests in Kubernetes. Finally, we'll measure error In the second test, my goal is to simulate database. Additionally, we'll measure the latency each language, as well as the CPU usage of the I run all my tests in AWS to make them more as I use in my production environments. I use 4xlarge Graviton instances to run the clients. instance with a local SSD disk to host PostgreSQL. 50 dollars per benchmark. To run my tests, I use Terraform to create all up a VPC with all necessary networking components, a couple of subnets. If you want to replicate Next, I create a production-ready EKS Node.js is famously a single-threaded work is done on a single thread), you can in Kubernetes, by limiting each pod to For example, a large EC2 instance has 2 CPUs, utilize all available resources. I do the same for pod with a different number of threads in each affinity to ensure that these pods are colocated I also create a second instance which are cheaper and ARM-based, to I use Kubernetes jobs to For the second test, I provision an on its own EC2 instance and use a Route 53 In the first test, I send a GET and it returns hardcoded objects to the client. For the second test, when I send a POST request payload, generates a UUID and timestamps, and returns that object with an ID generated by which is a very common practice. For Node.js, I use the standard library few endpoints. We have a /metrics endpoint for database latency, a /health and an /api/devices endpoint that returns a few which are identical between the two applications. handle POST requests. First, it parses generates a UUID along with the current I use the fastest available Node.js Postgres query as in the other application. Additionally, of buckets to improve accuracy and record the latency for successful requests, but in practice, also essential because timeouts can For this test, I use the latest On the other hand, we have the it no longer uses Rails. This application also which handles both GET and POST requests. it follows a different naming convention, but endpoint is created by the Prometheus define it explicitly in the app. returns the same devices as Node.js, For POST requests, the application parses the and then uses a connection pool to save the the same labels to measure request duration. which helps make the test results more accurate. RAILS_MAX_THREAD, but there's no Rails here--this There's an important difference in how you can create as many independent connections however, the connection pool is limited by the you set the pool size to 100, it will still particularly important for the second test. I found that the best performance with the using a single thread, which is the same number a single thread limits Ruby to just one database this, Ruby's throughput was significantly reduced. finally decided to use 10 threads, which allows Node.js to 10 connections to maintain consistency. monitor database connections in real-time. it uses the same facil.io C library as the Zap and produces similar results, as you can 1st Test let's go ahead and run the first test. Right has lower latency but also uses less CPU, which different thread settings, and optimizing an is very different from VMs or bare metal servers. application, surprisingly, the latency increases, this behavior with cgroups in one of my in Kubernetes, if you're running a CPU-intensive of threads to match the CPU shares defined in the and this rule seems to hold for the Ruby At around 40% CPU usage, you can notice that which results in higher latency. Kubernetes will You can also see downward spikes in availability per application, the graphs show average At around 35,000 requests per second, Node.js can some requests. This is consistent with other tests Even though Node.js was able to it's not very stable, and it shows significant let's see how much more Ruby can handle. almost 80,000 requests per second. If you look (which uses the same C library), you'll notice around 84,000 requests per second. In that which might explain the difference. To be vs. Node.js in this test but rather the underlying Now, let me open each graph First, we have the requests-per-second graph. You Node.js started dropping requests and ultimately on the other hand, handled up Next, we have latency. Ruby's latency is at the start. And of course lower is better. and was throttled by Kubernetes earlier, Next is memory usage, which doesn't really play a standard library, high memory usage can reduce potentially forcing Kubernetes to kill the in this case, memory usage doesn't Next is the availability graph. I have a and when this threshold is Finally, we have CPU throttling. You'll side because I used a single thread; throttling becomes much greater. 2nd Test run the second test. Here, I had to increase the performance. However, if I kept it at 1 thread, In this test, Node.js and Ruby went head-to-head with Ruby's CPU usage even higher also measured Postgres CPU usage to ensure the as it did in some of my previous tests. Kubernetes began throttling Ruby, likely due to beyond the available CPU shares, the more likely around the same time, which was expected. outperform Ruby, but at around 10,000 requests causing it to fall behind Ruby. Looking at database load decreased due to Node.js failures. Ruby reached 12,000 requests per second at around process additional requests. graph for the entire test duration. Node.js reached nearly 10,000 requests per but failed again shortly after, while Ruby Next is client latency, which remained similar Then, database latency: Most of Node.js's client bottleneck. It's possible that 10 connections per pay attention to dependencies like databases At the start of the test, database latency was 1 and 2 threads for Ruby, which gave much since Ruby's database connections equal the number Next, Postgres CPU usage, which reached 70-80%. type for the database to prevent it from becoming the hardware with a 400-connection limit. If the optimal connection limit for Postgres. the difference in usage between Then we have memory usage. availability graph shows a few Finally, CPU throttling: Ruby relies on its C has limitations for database and other service around more efficient libraries. Due to this, but I'm interested in hearing your thoughts. you might find interesting and you which uses the same c library. Thank you for