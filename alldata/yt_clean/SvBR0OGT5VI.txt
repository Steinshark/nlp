So I'm excited to share a few spicy But first, let's get philosophical by starting with this quote by Voltaire, an 18th century Enlightenment philosopher, who said, &quot;Common sense is not so common.&quot; Turns out this quote to artificial intelligence today. Despite that, AI beating the world-class &quot;Go&quot; champion, acing college admission tests I'm a computer scientist of 20 years, and I work on artificial intelligence. I am here to demystify AI. So AI today is like a Goliath. It is literally very, very large. It is speculated that the recent ones and a trillion words. Such extreme-scale AI models, often referred to as &quot;large appear to demonstrate sparks of AGI, artificial general intelligence. Except when it makes which it often does. Many believe that whatever can be easily fixed with brute force, bigger scale and more resources. What possibly could go wrong? So there are three immediate challenges First, extreme-scale AI models and only a few tech companies So we already see But what's worse for AI safety, we are now at the mercy because researchers do not have the means to truly inspect And let's not forget and the environmental impact. And then there are these additional Can AI, without robust common sense, And is brute-force scale and even the correct way to teach AI? So I'm often asked these days whether it's even feasible without extreme-scale compute. And I work at a university so I cannot afford a massive GPU farm Nevertheless, I believe and can do to make We need to make AI smaller, And we need to make AI safer Perhaps we can draw an analogy here, Goliath being and seek inspiration from which tells us, in my interpretation, know your enemy, choose your battles, Let's start with the first, which means we need AI is passing the bar exam. Does that mean that AI You might assume so, but you never know. So suppose I left five clothes and it took them five hours How long would it take to dry 30 clothes? GPT-4, the newest, greatest Not good. A different one. I have 12-liter jug and six-liter jug, and I want to measure six liters. How do I do it? Just use the six liter jug, right? GPT-4 spits out some (Laughter) Step one, fill the six-liter jug, step two, pour the water step three, fill the six-liter jug again, step four, very carefully, And finally you have six liters that should be empty by now. (Laughter) OK, one more. Would I get a flat tire that is suspended over nails, Yes, highly likely, GPT-4 says, presumably because it cannot that if a bridge is suspended then the surface of the bridge OK, so how would you feel yet randomly fails at such AI today is unbelievably intelligent (Laughter) It is an unavoidable side effect Some scale optimists might say, All of these can be easily fixed as yet more training data for AI.&quot; But the real question is this. Why should we even do that? You are able to get without having to train yourself Children do not even read to acquire such a basic level So this observation leads us choose your battles. So what fundamental questions and tackle today in order to overcome I'll say common sense So common sense has been To explain why, let me draw So only five percent that you can see and interact with, and the remaining 95 percent Dark matter is completely invisible, but scientists speculate that it's there even including the trajectory of light. So for language, the normal matter and the dark matter is the unspoken including naive physics which influence the way So why is this common sense Well, in a famous thought experiment AI was asked to produce And that AI decided to kill humans to turn you into paper clips. Because AI didn't have the basic human Now, writing a better that explicitly states: will not work either because AI might go ahead thinking that's a perfectly And in fact, there are that AI obviously shouldn't do including: "Don't spread the fake news," which are all part of our common sense However, the AI field for decades as a nearly impossible challenge. So much so that when my students started working on it several years ago, We've been told that it's a research shouldn't work on it in fact, don't even say the word Now fast forward to this year, I'm hearing: "Don't work on it And: "Just scale things up and nothing else matters." So my position is that giving human-like robots common sense And you don't reach to the Moon by making the tallest building Extreme-scale AI models do acquire an ever-more increasing amount I'll give you that. But remember, they still stumble that even children can do. So AI today is awfully inefficient. And what if there is an alternative path A path that can build on the advancements but without going so extreme So this leads us to our final wisdom: innovate your weapons. In the modern-day AI context, that means innovate OK, so there are, roughly speaking, that modern AI is trained on: raw web data, crafted examples and then human judgments, also known as human If the AI is only trained which is freely available, it's not good because this data and misinformation. So no matter how much of it you use, So the newest, greatest AI systems are now powered with the second that are crafted and judged It's analogous to writing specialized and then hiring human tutors These are proprietary data, by and large, speculated to cost We don't know what's in this, but it should be open so that we can inspect and ensure So for this reason, have been working as well as moral norm repositories to teach AI basic commonsense Our data is fully open so that anybody and make corrections as needed because transparency is the key Now let's think about learning algorithms. No matter how amazing by design they may not be the best suited to serve And these language models do acquire but they do so as a byproduct Resulting in unwanted side effects and lack of common sense. Now, in contrast, human learning is never but it's really about making and learning how the world works. Maybe AI should be taught So as a quest toward more direct my team has been investigating including symbolic knowledge distillation that can take a very large that I couldn't fit into the screen and crunch that down to much smaller using deep neural networks. And in doing so, we also generate, symbolic, commonsense so that people can inspect and even use it to train More broadly, we have been tackling of common sense, ranging from physical, social and visual common sense to theory of minds, norms and morals. Each individual piece but when you step back, it's almost as if these pieces that we call human experience We're now entering a new era in which AI is almost like with unique strengths and weaknesses In order to make this powerful AI sustainable and humanistic, we need to teach AI Thank you. (Applause) Chris Anderson: Look at that. Yejin, please stay one sec. This is so interesting, this idea of common sense. We obviously all really want this But help me understand. Like, so we've had this model How does a child gain common sense apart from the accumulation of more input and some, you know, human feedback? What else is there? Yejin Choi: So fundamentally, but one of them is, for example, the ability to make hypothesis interact with the world We abstract away the concepts and then that's how we truly learn, as opposed to today's language model. Some of them is really CA: You use the analogy by extending a building a foot at a time. But the experience of these language models It's like, the sort of, Are you sure that given the pace each next level seems what feels kind of like wisdom YC: I totally agree that it's remarkable really enhances the performance So there's real learning happening due to the scale of the compute and data. However, there's a quality of learning And the thing is, we don't yet know whether just by scaling things up. And if we cannot, then there's And then even if we could, do we like this idea of having very, that only a few can create and own? CA: I mean, if OpenAI said, you know, we would like you to help can you see any way with what they have built? YC: Certainly what I envision will need to build on the advancements And it might be that there's some such that ... I'm not imagining that the smaller It's likely that there's right the winning recipe So some synthesis of ideas CA: Yejin Choi, thank you (Applause)