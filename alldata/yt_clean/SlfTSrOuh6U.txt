We all hope for a peaceful future, but if where we went to battle in giant robots to of android killbots. So welcome back to another Scifi Sunday here Today's topic is a popular one in science suits or drones or automated tanks, fighter It is worth noting that this is not just scifi wars this entire century and even a bit before, roles. So, I thought we would look both at the modern future options. Some years back we did a look at the topic basic idea of people wearing powered armor use some updates, and more detailed looks, Thursday in our Dropships episode. But it's not really terribly likely that And definitely not off the battlefield, as place to begin. For every soldier or combat unit you've armor, you've got the robots doing field building your equipment. Robots in factories are already a game changer precision manufacturing and high speeds that but also the robust economies and infrastructure units, and elite units at that. It is entirely possible we might see a future the use of autonomous armed drones, or even Indeed, fear of artificial intelligence running scifi setting has humans doing the piloting And we've looked at that topic more in our In that case, then maybe your robots aren't they still are, they're just heavily armored behind. And amusingly, at least in the short term still new, few, and finicky, we might opt the people who would otherwise man those factories Eventually you presumably use your robots Though a civilization that replaces humans replacing humans with robots in all capacities, footnotes. And we're hardly ignorant of that scenario walks of life, more and more serious and sober on them. And no place is that better exemplified than battlefields and law enforcement. I'm not sure how most of us would feel about better than being killed by one in combat, to be rather cold and indifferent to your ideally. So while there's a lot of talk about whether the actual authority to pick a target and it's not just a case of robots having permission We're also talking about scenarios where detaining a prisoner of war, or determining the threshold to fire on. And for that matter, if the target is actually hostile robots, ones that maybe looked a bit We should also rule out any serious use of more than a loose mental guide, especially In his classic robot novels, Asimov lays out letting us be harmed, to obey us, and to not And Rule 2, obedience, supersedes 3, so you 1 supersedes 2 and 3, so you can't order Or to stand idly by while someone shot you, Needless to say, that's a real pain in the and your own war machines keep trying to disarm We've discussed the flaws and problems there Robert Miles from Computerphile did a great and of course Asimov himself pointed out tons Most of those stories were usually either 3 laws or how it had seemed someone had, but Sorin Matei wrote an article over at Strategy ethics of robots in combat and that petition robots' signed by thousands of scientists, like Stephen Hawking and Elon Musk. The article very appropriately references "the first and only law of robotic warfare", war machines, the more devastating one's A peer conflict is one where both combatants like having the same tech for their equipment, effective weapons, like computer-controlled fast and terrifyingly high. So the problem is, we don't actually want someone can build ones that don't have those or just pervert them, like changing the robot's swap us with trees or cows. Asimov hand waves that in the novels by having a product of centuries of improvement piled them would result in an unstable brain that code is ever more buggy like that, built layer own mind as we age and learn, but it still People have every motivation to find a way lethal force, especially governments, so that outclassed. So you keep the killbot files in a vault awaiting at least, so when the enemy does you have That's the first rule of Warfare, after Ethics in warfare always get murky too but titled "Ethical Robots in Warfare" in and concerns about use of wartime robots, Establishing responsibility - who's to robot? The threshold of entry into warfare may be and fewer human soldiers - this could violate The possibility of unilateral risk-free warfare, It simply can't be done right - it's targets. The effect on military squad cohesion and warfighters may not accept ethical robots Robots running amok - the classic science A robot refusing an order - the question in humans. The issues of overrides placed in the hands The co-opting of an ethical robot research other political agendas. The difficulty in winning the hearts and minds are allowed to kill. Proliferation of the technology to other nations Some of those points Arkin lists are harder in other episodes too, like AI Run Government list for contemplating the topic and will Though this episode isn't meant as an advocacy Like everyone else I can see the many advantages too, though in terms of a lot of the current about killer robots yet. I don't see an ethical issue either with or scout an area. We were already using them for that when I checking out IEDs. Things get more gray after that, of course, today and are honestly more focused on what Incidentally, we are not yet at the point a powerful threat to a normal soldier, that outclass us, but for now the big advantage and reasonably covert. They're still expensive though, with predator each, and even the more modest TB2 drone from I think one can make a strong argument that point, and in many applications is more about The small nation of Togo, whose entire military bought some of those TB2 Drones. Obviously you can pick up a cheaper drone and mounting a gun on one isn't exactly Unsurprisingly there's laws against guns added drones to that list. But it's not a big technical challenge, and recoil is a serious issue. The Israeli drone, the Smash Dragon, can mount it's a person doing the aiming, however work of keeping everything aligned. All that work with cameras, and keeping them other weapons. There really isn't much stopping us from that we have increasingly found with automation like a person, but rather to make it smart trained to use it. My robot vacuum cleaner needs to be smarter able to prepare my taxes. Very little brains are really needed to aim and no personality or intelligence is really It only needs more brains if you want it to get that from a conversation with its human And that's where the assumed trouble and In practice, though, as ChatGPT shows us, doesn't really require vast intellect. And your options for what to shoot or not better success rate than trained soldiers on a range that pops up bad guys and civilians, We don't have that yet, but what we've is that it's almost always easier to make for specific tasks, even things like that, And the thing about a general intelligence slow. Oh, a computer brain might be faster than do a specific job slower than an equivalent So we don't want a killbot with human level to us, and not likely to be better at its The one with a large library of object identification - you or I or some general AI that lacks decisions. And this is usually where folks start contemplating wrong person or fire on civilians in a battlefield mistakes already happen. It's not about making a machine that's that performs as well or better than a human And honestly, a lot of times the people controlling if it's even as good as a human at target and their human isn't, so a robot that's civilian as one of your own soldiers would you mostly want your own forces not be shot. If you can do that by having to further endanger easy trade. Which raises the issue of friendly fire but since any such robot needs to be remotely And there is such a thing as an unhackable one-time pad for accessing it to give certain IFF parameters and the emergency off switch, of them being hacked and of having such high-level use. Ultimately the big thing to remember when a rogue or enemy-hacked gun drone might be,in than hacking an automated car. All the various technologies we have to prove into the same general bucket. How do we make this piece of mostly automated and proper human user without letting others law enforcement or higher command in the military. Not easy problems but more in the sense of so someone isn't hacking your gun drone, your credit card, and so on. Dismiss for now the idea of a human intelligent I don't see that being necessary and don't I'm guessing anyone brave or dumb enough a super-intelligence instead. Now where we might see human-intelligent or at the strategic level. Though remember that the computers have been everyone used to call the ultimate game of finished the 20th century out. Personally, while I enjoy chess and poker, great analogies for life or battle, nonetheless is just data sorting, risk assessment of that of other statistical calculations that computers Key thing to remember though is that the computer a learning machine that's picked something we wipe it. Folks talk a lot about how to control or chain to remember is that you can reset the AI, brain to see what it was really thinking, So if I've got an AI I think might be a it's not actively doing its job or dial You can also real-time play its thinking, AI to run through it's brain and look for humans?" Critical issues for us to overcome in dealing get off on the never-ending thought stream safe?" - which seems a bit of bizarre machine, and our tendency to assume any intelligent us and be better at everything and outsmart As we're seeing more and more, AI is definitely fears of them are not terribly realistic. Like everything else, they have limits and So, your strategic computers are probably run odds and doing a lot of checking. The machine might notice weaknesses or things in a rush. It could also be sucking in the data from with different locations and ranges, using that into telling you where the enemy assault assessment of numbers and strengths. It is not easy for a spotter to see something and give an accurate count, let alone a real there are, how many howitzers, how many rifles, And yet an AI need not be anything like human and useful data like "There are 167 artillery 115 self-propelled, 155mm guns, each given and in engagement one we noticed that these overlapping 20 were most accurate, while these and here are the ones we deem highest priority Give a report like that to a general even some superintelligent machine or crack division him bull. But we know that there is nothing actually battlefield asset by a number of metrics - visual sounds, etc - or to have seen each volley or the speed of the vehicles. Then compiling all that. That same sort of simple AI can be doing things guard shifts which locations on your perimeter If this were old-school scifi we would have say "I knew Johnson was on that tower, he whereas Jackson is always drifting off and towers went quite, I knew the enemy must have asleep, your expensive computer didn't know data." Which sounds nice for fiction but in practice analysis that simple machines excel at. It might also be trusted to have read that which normally a sergeant or captain wouldn't, details that would help or harm someone's But in the end a general intelligence can especially where deceit and improvisation We use the term human-machine teaming a lot from a human aided by an AI rather than one So our AI forwards the analysis to the watch the watchers, and note that Jackson's heart while Johnson's has simply stopped. So at the tactical level, what does this human-machine Well, it could be akin to JARVIS and Tony needs a fairly sophisticated AI to coordinate Or it might be the big giant robot of course. There's a lot of arguments on the pros and versus walking battlebots, with the big disadvantage need to armor, but the main one comes down So folks suggest a very humanoid form as easy seated in a cockpit with a joystick. And the answer there is that AI is doing most Your brain is enormous, and most of it is for running all your motor functions and managing and sense organs. So here we have the AI act as an extra region move into an actual motion, including balancing to make it better. That's probably unique to each person and able to have a good baseline for a new pilot And you're not normally the one making the it is, you can just override it. It becomes like a reflex, such as flinching, Same sort of thing applies to independent of bots accompanying them into battle, and to something that was basically a big track a fast armored coffin shaped box carrying grab you, close up, and run to safety. One might be just a big mobile generator on spider leg chassis. And the person there is basically just modifying They probably are in some power armor themselves role telling the big walking guns to cease Of course that suit might be empty and the be some copy of their brain loaded onto it not neuron and brain speed. There are a lot of options and in the millennia phases here on Earth and different ones in In the short term though, we will definitely but I don't expect many to be given autonomous uploaded human mind. Those basic techs will get improved regardless, There's also an occasional concern that doing all the dying, but the military has given the precedent of horses and canines the bots, get protective of them, get very them unofficial medals. So, while we're likely to feel a little because of robots, I don't see people getting Nor do people hesitate to get angry about Also, at least for the US in recent years, compared to prior conflicts and yet it was wars. We shouldn't assume nations get more belligerent and using robots for your combatants doesn't They still have your manned bases and your For good or ill, one thing seems sure, robots to stay. I guess the bigger question will be whether battlefield, and if so, will it be because or because the only conflicts being fought they killed us all off. But that is the first Rule of Warfare after sure they won't point it at you, and the give a gun the ability to pick targets unless The future of robots in warfare can take on being used to attack is by stealing people's This isn't alway illegal either. A lot of less ethical companies sell your made this harvesting and trading of your personal You're allowed to ask companies to delete do so, but it's not very practical for a and send those requests and the replies to Fortunately that robotic blade can cut both to find places where your personal data is for you. All you have to do is sign up, give them permission they go to work, and your data goes away. They handle it all but you can check up on how detailed and risky it was considered. I couldn't believe how many places had my Icogni makes them take it down, and they keep Incogni is available risk free for 30 days, and get a full refund if they aren't happy Use code IsaacArthur at the link in the episode annual Incogni plan Go to https://incogni.com/isaacarthur So that will wrap us up for another Scifi month for more on futuristic warfare as we like to be in one. But before then we have plenty of more episodes for a look at whether or not alien lifeforms and what that might look like. Then we'll continue our look at the future or boarding actions. After that we'll head in August to look but on the Moon, then we'll head trillions and the final twilight on the Last Planet. If you'd like to get alerts when those and the like, subscribe, and notification buttons. You can also help support the show on Patreon, ways, you can see those options by visiting You can also catch all of SFIA's episodes Nebula, along with hours of bonus content, As always, thanks for watching, and have a