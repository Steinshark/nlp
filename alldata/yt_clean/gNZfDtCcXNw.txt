This is a Radeon R9 Nano. It's not only a in 2015, it's also a very old card. But don't the single fan shroud this card is hiding to develop and today is in such high demand, on gaming GPUs. This technology literally disassemble it so I can show you what I'm What you are looking at is AMDs Fiji GPU. but if we compare it to a traditional graphics First, Fiji is missing the memory chips that next to the GPU die we can see four tiny chips. that Fiji doesnt use traditional graphics first GPU to use next-generation High Bandwidth of HBM, it was also the first GPU that implemented chips are sitting on top of another silicon The use of HBM for gaming cards died with interposers are only used for very expensive and Intels Ponte Vecchio are not only the moment, they also wouldn't be possible without invented to make this little GPU a reality. time and trial and error, which is why Fiji time ever. Let me tell you the story of how The story of Fiji begins all the way back the iconic 8800 GTX from Nvidia. Crysis wasn't were Stalker, BioShock, Portal and Call of memory had finished and AMD was going back the same time very difficult question: how Simply scaling the clock speeds of GDDR5 memory higher power draw, taking more and more power power world, you cant spend the majority of you need that power budget to run the GPU GPU scaling. Something new was required. At smaller, especially notebooks. For this reason perfect next-gen video memory: maximize bandwith at the same time. And of course it had to With these two, or rather three, goals in It was a green field project, everything was was that in order to increase power and space memory needed to be build up vertically instead If you think the early stages of such a project Building prototypes was a major part of the first proof of concept protoypes didn't even AMD started with mechanical samples of a CPU be integrated? What type and connection density quickly came to the conclusion that a layer to support high-speed interconnects, because memory is placed on the PCB around the GPU on the PCB with your nake eye, as they have But if you run data paths on silicon, they you to run a lot more connections than you because it allows you to miniturize. But this If you are placing the interposer between data and power connections have to go through The solution are so called through-silicon they were invented back in the 1950s. IBM and first integtated circuits with TSVs were basically super small copper pillars that layers above and below. And they were perfect the same time new technologies like waver It's always fascinating to me how on one hand but if you look close enough it comes down with each other. The magic part is that they're After the interposer design and and the use method of choice, engineering samples moved From this point on, SKHynix also got much HBM. In 2011, after a few generations of ever towards the next big step. This time things an actual interposer. A 335 square mm GPU was placed ontop of a 500 square mm silicon for the future HBM chips. The thought that ontop a silicon interposer using TSVs is insane chips clearly showed one thing: the initial high density interconnects with a interposer But things needed to get bigger, a lot bigger. produce, because it was below the 858mm2 Fiji GPU alone was close to 600mm2 in die-size four HBM stacks next to the GPU, it was clear 1000mm2, well above the reticle limit. To produced the interposer for Fiji, Amkor, which for assembly and test services. Sadly I couldn't problem was solved back then. Today methods 2015 it might have been another technology. a large interposer leave a comment down below. challenge. tackle different problems. Just stacking two enough to achieve the ambitious goals of power to a 5-high silicon tower, with four of the chip acting as a logic die. The logic die interposer via microbumps and also provides to the GPU, which for this very reason is It's here were AMD and SKHynix used the TSVs connected to the memory die that sits above to the next memory die via TSVs, and so on. tower. And because HBM is using four memory provide a lot more data paths, resulting in This is very visible when we compare a single memory module. A G5 module provides a 32-bit modules thus has 8x32bit connections and a stack alone already has a 1024-bit bus and HBM stacks, the total memory interface was The stacked memory modules allow for a much On the flipside, this also means you need all of the data paths that you just created, interconnects, as it alows for much smaller than if you would try to connect memory and the cost of the interposer and the increased smaller micro bumbs and smaller data paths, of them on the same area - thats what high and more wires. And since everything is so there are more TSVs that actually needed, of them fail to connect during packaging. comes to clock speeds, the HBM clocks much is achieved thorugh a wide interface, clock HBM chips itself actally have a lot in common its a much simpler design if you ignore the HBM can also run at lower volatages, considerably Something I found quiet interesting is the the base logic die, is produced in a DRAM optimized for memory cells. AMD and SKHynix realiable produce a logic die in a process of job. And even today, modern HBM stacks by the memory manufacturer in a DRAM process With the overall design and the HBM memory This final prototype was a complete 1:1 replica manufacture such a complex chip. ended with the release of the R9 Fury and a half years later. That's how long it took on the shelf. And while this is a huge amount 8.5 years actually seems like a short amount technologies. just talking about it. We got super lucky, Fritz took highly detailed pictures of AMD's GPU apart using heat, so we can have a more and Twitter accounts in the video description you are into amazing pictures of chips of This picture is great, as you can clearly to the huge Fiji GPU, and the interposer that fair to call this design elegant. There is the HBM stacks then the GPU, but at around Next, the picture of the broken chip has almost are till intact, the one to the right is showing left has been completely removed. The interposer we can clearly see how the bottom of the interposer, micro bumps, while the silicon interposer and thus the higher connection density. This the best way to understand how a interposer compare the size difference and its clear actually is compared to organic substrates. right opposite to each idividual HBM stack. beautiful pictures from Fritzchens Fritz, him out. access to such advanced memory technology? Nano GPUs performed a lot better than most was the Nvidia GTX 980 Ti and in 4K, both to performance, at least initially. Even Nvidias most of the time within the margin of error. had a 50% bandwidth lead over Nvidia. 50% more and the Titan X even had three times metric when it comes to 4K gaming. AMD's HBM HBM capping out at 1GB, four stacks were limited if you buy a high-end card, you want it to In my opinion the greatest flaw of Fiji was Dont get me wrong, it wasn't a bad architecture, it couldnt actually translate them into frames. over the 980 Ti, but just managed to keep compounded and Nvidia started to develop a One product that did not disappoint is the the video. The R9 Nano really took advantage by using HBM memory. And because its smaller thermal dissipation, the Nano was also clocked greatly impoved efficiency. AMDs Vega made the switch to HBM2, which increased increased clock speeds. With only two HBM2 a 2048-bit wide bus, half the size of Fiji interface. Interstingly the higher clock speeds width and Vega 64 had less memory bandwidth a 7nm shrink of Vega, AMD actually had three pivoted back to GDDR memory and has been using move to HBM for gaming GPU. HBM is superior to GDDR in almost any way, and high performance at the same time. All is almost exclusively used in super expensive But not only is HBM much more expensive than it's also in short supply. And the same is TSMCs CoWoS, which is used to connect GPU, a $1600 dollar RTX 4090 is too cheap to use Nvidia knows it could sell a $20,000 dollar still reigns supreme for gaming GPUs and there a switch to HBM any time soon. think that two of the most important technologies interposers, can be traced back to this tiny technologies exist, but it played a major design can be mass produced. today we are in a similar situation as we AI GPUs once again is memory, as compute develops there are engineers sitting in a room somewhere, could look like. Nano would definitely be in it. From a technology else at the time and even today, with its packaging complexity of current gaming GPUs. supply is being build up like crazy and at using HBM again. Tho it most likely will take too great, once the cost of production comes a issue any more. using, a HBM GPU like Fiji or Vega. Do you to HBM in the future? And how could the next a comment down below, I always like to read I hope you enjoyed this video and see you