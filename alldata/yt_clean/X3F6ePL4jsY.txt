the key question is really all about speed And, you know, in my profession, I'm but I think history History is the study of change, And at present, rate than in any previous time And for me, that's the main problem. I don't think that A.I. necessarily is a bad technology. It can be the most positive technology But the thing is that A.I. moves. It's an inorganic thing. It's an inorganic entity. It moves at an inorganic speed. And humans are organic beings. And we move much, much, much slower. In comparison, But we need time to adapt. And that's that's the main requirement from how to deal effectively positively Give us time. Hello, and welcome to tonight's by the Commonwealth Club, World Affairs My name is Shirin Ghaffary. I'm an I-Reporter for Bloomberg News and Before we get started, Tonight's program is being recorded. So we kindly ask that you silence your cell phones And also, if you have any questions please fill them out on the cards Now, it is my pleasure Noah Harari and Azar Raskin. Yuval Noah Harari is a historian, author who has sold over He's also the co-founder of Sapiens Ship, an international social impact company Yuval is currently a distinguished at the University of Cambridge Center as well as a history professor His latest book is Nexus A Brief History of Information Networks Aza Raskin is a co-founder of the Center and a globally respected thought leader on the intersection He hosts the TED podcast, in the two time Emmy winning Yuval and Aza, welcome. Thank you. It's good to be here. Let me first start off by asking you about a year and a half ago, There was a letter. Yuval, And Eisa, I'm curious your thoughts about it, that letter said and where we're at a year So this letter was a call to pause, Labs to halt progress of any kind of That didn't happen. I don't think anybody expected that I mean, nobody really expected Right. But what do we make of the fact of which is that by some of the most powerful technology speed ahead general intelligence or superintelligence. I think things have only sped up, right? Yeah, absolutely. I think the key question is really all And, you know, in my profession, I'm but I think history History is the study of change, And at present, rate than in any previous time And for me, that's the main problem. I don't think that A.I. necessarily is a bad technology. It can be the most positive technology But the thing is that A.I. moves. It's an inorganic thing. It's an inorganic entity. It moves at an inorganic speed. And humans are organic beings. And we move much, much, much slower. In comparison, But we need time to adapt. And that's that's the main requirement from how to deal effectively positively Give us time. And when you talk with the people maybe after an hour or two of discussion, it would be a good idea to slow down But we cannot slow down because we are the good guys But our competitors will not slow down in another corporation And you talk to the competitors, We would like to slow down, And I think the key paradox revolution is that you have people saying, we cannot trust the humans. But then they say, but we think Because when you raise how can we trust these new intelligences They say, So I want to pose this to you first. If we you know, shouldn't trust the A.I., who should we trust? Here's, I guess, the question to ask, which is, if you were to look back through history and give any one group a trillion times more power than any other group, Like which religion? Like which government? The answer is, of course, none of them. And so this is the predicament we find ourselves in, which is, you know, how do we find trust for a technology that is moving so fast that if you take your eyes off of Twitter, you are already behind? There's a, you know, thinking about like that It's interesting because there was a time and people were not yet talking And after that letter, In fact, it paved the way for another they had many of the leaders of AI as seriously as pandemics What we need is for the fear of all of us losing to become greater than the fear of me losing to you. It is that equation the paranoia of, Well, if I'm not going to do it, So therefore I have to go forward. And just to set up the stakes a little bit and why exactly to think that letter was meant It's I think there's a good analogy here, That is to say every barrel of oil is worth, Somebody moving something in the world. What oil is to physical labor. AI is to cognitive labor. You know, that thing that you do are doing research. And that really sets up the race same question And yet nothing really happened. And it's because the center runs through cognitive and physical labor. I want to talk for a second about just the the reverse, the kind of acceleration What do you say to the technologists? And we're here in the heart of Silicon Valley, where I grew up People say don't sweat the wrist too much. You know, sure, we can think about them, because the upside here is so immense. There are benefits for medicine. We can make it more affordable Personalized education is that you do It is so cool. I want to talk about that too. But but, Yuval, I want to ask you first, sort of Silicon Valley techno optimist fixated on the negative, this potentially immensely helpful First of all, nobody is saying I mean, we are aware, even the critics, in a philosopher is to kind of shine because the entrepreneurs, the engineers, they obviously focus on the positive Now, I'm not denying the enormous positive whether you think of health care, climate change, of, you know, every year car accidents, most of them caused and driving, falling asleep at the wheel, The switch to self-driving vehicles every year. So we are aware of that. But we also need to take into account The threats which are equally big, scenarios, be as catastrophic To focus, to give just one example, The social media algorithms democracies all over the world. We now, in this paradoxical situation, the most sophisticated information and people can't talk to each other it's becoming very difficult You see it now in the US and you have all these explanation, it's because of US society But you go to almost every other democracy country, in Israel, you go to France, It's the same there. It's not that the unique conditions It's the underlying technology that makes it almost impossible for people Democracy is a conversation, and the technology is destroying Now, is it worth it to to that we get these benefits, And then these technology is in the hands to create the worst totalitarian regimes So we with the potential threats And actually, this thing I really want and replace, because we will always get And social media taught us The right question to ask is will the risks so that we can't actually enjoy That's the question we need to be asking. So if we could go back in time to, say, 2008 2000, nine, 2010, and instead of social media deploying we said, yes, there are a lot of benefits, Ask what are the incentives this technology how it'll impact our democracies, Well, the reason why we're able calling in 2013 the direction was because we said, well, just like Charlie Munger said, who's show me the incentive What is the incentive for social media? It's to make more reactive And as soon as you say it the things that are outrageous, the things that get people mad, are very profitable for engagement It's all foreseeable So the question because once social media it took hostage GDP, because you can't win an election and whole news out. Once it's all happened, So what we're saying what is the incentive because that not the good intentions which world we live in? Maybe I'll make a very strange that Silicon Valley reminds me The controversial analogy. But okay, I'll hear you. In around you know, after the revolution, there are huge differences, First of all, the ambition We are the vanguard. Most people in the world don't understand We are these small vanguard and we think we can re-engineer society and create a better world, And the other common thing it's an open chink to do some Because you say we are creating utopia. The benefits would be so immense that, as the saying goes, to make an omelet, So, I mean, this belief in in creating the best society in the world, because then it justifies a of our short term harm to people. And of course, in the end, maybe you don't get to to to Maybe you misunderstood. And it really the worst problems come not again from the technical glitches but from the moment And there is no way you can simulate history in a laboratory like when when there is all these And the technology companies, the tech giants tell us we tested it. This is safe for me as a story. The question, how can you test history I mean, you can test that it is safe in some very limited, narrow sense. But what happens when this is in the hands of all kinds Do you really know how it will play out? And the answer is obviously no. Nobody can do that. There is there are no repeatable and there is no way to test I have to ask you all, you've had a very welcome reception in Silicon I've talked to tech executives now with with this, you know, this new book, I would say, critical outlook of this technology that everyone is How how has your have your interactions really have them to receiving this book? I know you've been. It's just out so I don't know yet. But what I do know is that many of these I mean, they have kind of the coming that they are very optimistic and But they also understand but the immense power of what they are And therefore, Again, when they mentioned earlier the arms race mentality, they could slow down, I think most of But again, because they a, they are so afraid of the competition. They are in this arms race mentality which which doesn't allow them to do it. And it's you mentioned the word excited The I think there is just And there it really it's it's word in the English language, People don't really understand They think it means happy. So when they meet you, And this is not the meaning of the word. I mean, happiness is often I'm so relaxed to meet you. Now. And excited is like when all your nervous system And this is good sometimes. But a biological fact about human beings is that if you keep them excited And I think that the world as a whole Valley is just far too excited. And, you know, we we we're currently starting to have these debates It's not even clear that humanity is. And when I think actually, jump in if I'm getting something wrong. But I think about humanity's relationship We've always been a species co evolving and we'll use technology But in the process we make more bigger, different problems And so it's sort of like humanity, and we kick it down the road but that's okay because next time around It gets a little bigger. And by and large, I think we've made you could argue like we all would rather not live So we're like, and those externalities are fine. But now that Khan is getting so big We invent plastics and Teflon amazing, And New York Times just said that the cost that are unsafe levels for human causing like farm animals to die. We cost more than the entire GDP We're at the breaking points of our biosphere, of our psycho social sphere, and so it's unclear if we can kick And if we take A.I., which, you know, machine called civilization, you get skyscrapers and medicine but you also get forever chemicals and And you just take air. You make the whole system more efficient Do we expect that to be human and the health of our planet, And to me, this is a much scarier than like what some bad actors It's what is our overall system And maybe I'll just add to that usually the problem with new technology is not the destination, Yeah, right. That when a new technology is introduced the problem is that people don't know how to use it beneficially And many of these experiments turn out, So if you think, for instance, about the industrial revolution, so when you look back like with the titans of industry, you know, there were all these apocalyptic prophecy And look, things are now much, much better than they were before But for me, as a historian, the main issue Like, that the end point, like the year is 1800 before the invention of trains And you look at the end point, and you look at almost any major except Let's put that aside for a moment You look at every other measure child It's all going Everything got better, The way from 1800 to 2000 with a lot of terrible experiments Because when industrial technology nobody knew how to build There was no model in history. So people tried different models. And one of the first big ideas to build an industrial society And there was a rationale because the argument was our agrarian but industry needs raw materials, If we build an industrial society and the markets are competitors, again, our competitors could block us So almost any country that industrialized, when it industrialize in the 19th century, an empire in the Congo, This is how you build Today we look back Hundreds of millions of people suffered realized, actually, you can build Other terrible experiments were communist Again, the argument it was not something The argument was the only way by the steam engine, the telegraph, Democracies can't handle them. Only a totalitarian regime can harness and make the most And a lot of people, again, a lot of people in the 1920s, thirties that the only way to build an industrial society And we can now look with hindsight But in 1930 it was not clear. And again, my fear, revolution is not about the destination, Nobody has any idea how to build an air And if we need to go through empire building and totalitarian regimes this is not the way, you know, as a historian, on the test of the 20th century, how to use industrial society, enough to pass. We are all most of us are here, Now, if we get a C minus on how to deal but on how to deal with AI, What are the unique potential failed experiments that you worry Because if you look at those kind or existential risks, Right. What are your early signs. If you discount I mean, when they bring it to their eyes, I mean, and maybe go back definition of what is an AI. Not every machine For me, is the ability to make decisions by itself and to invent new ideas by itself, Yes, humans design but they give it this ability And social media field had this ability, they were given by Twitter and Facebook and YouTube was not to to to spread hatred and outrage The goal they were And then on millions of human guinea pigs that the easiest way to increase user that this is very engaging outrage, all these hateful conspiracy theories And they decided to do it. And there were decisions Humans Some of it full of hate, some of it And the algorithms decided, let's spread their hate filled content, And what does it mean They decided that this will be at the top This will be the next video on YouTube. This will be what they will recommend And you know, this is one Traditionally, they basically took over the job of content editors and news editors. And, you know, we think about automating taxi drivers It's amazing to think which was automated, was news editors. I picked the wrong profession. And so it's this is why we call it first Yeah. With social media. We we sort of. Lost another C minus an F? Exactly F. Wow. What about all the people You don't get some grade inflation I mean, I met my husband online 22 years ago, But what it did to the in the basic social structure, a reasoned conversation with our fellow I mean, on that, when they said How did we pass around information? Which is the topic of your. Book, an F, in the sense It's nothing like we're barely passing it. Yeah, we are really feeling it all over the world democracy is in essence is a conversation which is built on information technology. For most of history, large scale We have no example of a large scale All the examples of small city states like It was just impossible between millions of people It became possible only technology, first newspapers, And now the new information And how about with We're still in the really early phases But how about with How do you think that might change What are the specific information than the social media We've never had before? Nonhumans about to generate Sometimes we call it the flip name. It's the moment when human beings content And of course, then the question is like, So if you think Tok is is engaging and addicting now, as of like last week Facebook generates Now, obviously it's at a very early stage, but soon there's actually a network that every one of your followers and yet it feels so good and they're all commenting. And even though you know it's cognitively impenetrable This is the year 2025 when it's not just going to be chat type It's going to be agents that are out there actuating in the world, doing whatever it is And that's going to make you think about creating deepfakes in themselves, And you're like, You can spin up a corporation They're all going to be operating whatever market incentives are out there. So that's just like some of I mean, maybe I'll add to that of risks and threats or opportunities, Is it bad? Just to stop for a moment what kind of really Because for tens of thousands of years, humans have lived inside We are cultural animals We constantly interact whether it's texts or images, stories, mythologies, laws, It's all coming out of the human mind. Some human, some were invented. This and up till now, nothing on the planet could could do that. Only human beings. So any and any song you encounter, any currency, any religious belief, And now we have on the planet something which is not human, It functions according and is able to generate such things at scale are in many cases maybe soon, better And we are not talking We are talking about millions of these alien agents. And is it good? Is it bad? Live it aside. Just think that we are going to live in this kind of new hybrid society many of the inventions are coming Now, I also in other countries hotly debated topics. And without getting into the discussion, Obviously, that immigrants are coming and they have different ideas And they have different And we are about in this sense, to face the biggest immigration wave in history but from California, basically. And these immigrants from California, they are going to be enter every house, every factory, every government They are going straight, not you know, they are not going to replace the taxi The end of the first people and they will replace the bankers. They will replace the generals. We can talk about what it's doing in Gaza, they will replace the CEOs, they will replace the investors, very, very different cultural Is it bad? Is it good? You can have different views but the first thing to realize is that we have seen It is coming very fast now. I was just yesterday in a discussion was released almost two years ago And I understand that for people a high tech company, It is the thing in culture. So two years, nothing change in two years, You know, think. Imagine that we are now in London in 1832 and the first commercial railroad network. The first commercial railroad two years ago And we are having this discussion around trains, around since they opened the first rail But you know, within 20 years or 50 years, in the world, The economic system, the most basic Another topic of discussion What is happening to the family? And when people said family, they meant After the trains came, which is the nuclear family for most of history, extended family with all the aunts this was the family, this was the unit One of the things it did in the extended family and the main unit And this was not the This was actually an outcome So it really changed everything. These are trains. It just took a bit more than two years And now think about the potential of a machine that can make decisions that can create new ideas, And we have billions of these machines into every human relationship, like one example, like are people writing emails. And now I know many people, that like they would say, I don't need to think 10 minutes I'll just tell Egypt or write a polite And then you write a whole page with all these nice phrases and all these compliments, And of course, on the other side who says, I don't have the time to read. Now, this whole letter, it don't keep it. Tell me, what did they say? And the deputy of Do you use strategy be to yourself? I leave it to the other family members I use it a little thoughtful. Translate and things like that, And yeah, definitely. How about you? Is a do you use Chhatrapati I do. Absolutely incredible So for instance, there's a great example Where is the coordination problem? There were people essentially terrible traffic infractions, people like running They couldn't figure out how to solve it. And so this mayor decided walk down the streets and just make fun of And lo and behold, and then they would video it And lo and behold, within a month or two, behavior started to change. Like the police couldn't do it. But turns out mimes could. Okay, so that's a super interesting, like nonlinear solution to a hard problem. And so one of the things I like to ask GPT is like, well, And it does a great job But to go back to social media as a sort of first contact with AI, it's it actually lets you see because the first thing you could say is doing something bad, can't you just unplug For once you see it's doing bad, Well, Francis Hogan, who is the Facebook it was able to disclose a whole bunch And one of the things I don't know there is one very simple thing that would reduce the amount disinformation, hate speech, than the tens of billions of dollars currently spending on content moderation. You know what that one thing is? It's just remove the reshare button after two hops you share one of the person, You can still copy and paste. This is not even censorship that one because it turns out that which is viral But they didn't do it which meant that they were now in So they felt like they couldn't do it. Or maybe they just wanted And this is even after the research That said, when Facebook called meaningful social interaction, the number of comments people added as political parties across Europe and also in India We know that you change your algorithm And they said, No, because we used to post things and they didn't get the most engagement, Now they get zero and they told Facebook, that they were changing their behavior the click baity angry thing. And Facebook still did nothing about it And so we're going to see And this gets to like as humanity And that is, you guys know Yeah. Like you give a kid a marshmallow, I'll give you another marshmallow And it's sort of a test. If we are a one marshmallow species, we're not going to make it. If we can be the two marshmallow species and actually the one marshmallow species AI is that there are a whole bunch of kids It's not just one kid There are many kids and any one of them can grab it We Have to figure out how to become the two marshmallow species And that to me, Like how do we create the governance? How do we call ourselves so that we can do the delayed trust thing? And we basically have the marshmallow? I think this is going to be a sticky meme. We have the some of the smartest and wisest people in the world, Yeah. Which which is again, Humans, often also in personal life, spent choosing, deciding which problem to solve, and then spending only to discover too late Yeah. So again, if these two basic problems of human trust and A.I., we are focusing on solving the AI problem focusing on solving the trust problem, And so how do we solve the trust problem? I want to shift us to solutions. Right? Let me give you something, because I don't I don't want people to hear me I bet. Right. Like I use AI every day My father died of pancreatic cancer. Same thing as Steve Jobs. I think that I would have been able I really want that world. Let me give an example of something I think I could do In the Solutions segment. So you guys know about, So this is where they got an AI to until it sort of became better And there's this famous move, playing against the world leader in go that no human had ever made in thousand It actually it shocked the video world so much like he just got up But this is interesting The way that go is played. It has transformed the nature of the game. Right? So A.I. playing itself has discovered a new strategy This is really more interesting than go. There's the game of conflict resolution. We're in conflict. How do we resolve it? Well, we could just use the strategy You say something hurtful, So I say something hurtful back. We just go back and forth We see this in geopolitics all the time. Well, then along comes this guy, Marshall Rosenberg, and it changes the nature And it says, And when you say that, And suddenly we go from a negative some So imagine agents that we can trust all of a sudden in negotiations, going to have some private information You're going to private So we can't find the optimal solution If you had a agent that could actually all of my information and find the Prieto optimal solution, well, There could very well be sort of like where there are brand new move strategies that human beings have not discovered And maybe we can have the move 37 Right? So there are ways and you've just we can harness AI to hopefully enhance What do you think we need to do? What are what are the ways that we effect of diminishing our trust, I know you all in your book when you are talking to an AI versus Why is that so important? And how do you think Because I talk to you know, and some of them to me seem you are talking to a real person. And there are people who are forming that mimic, you know, interpersonal So why do you think we're doing on that When I think there is a question and then there is a question there are some regulations that should be enforced One of them is that to ban the same way that for thousands of years against fake money. Otherwise the financial system would We need know whether we are talking And imagine, standing together, having a conversation. Suddenly A group of robots join the circle very persuasively And you don't know who is who. If democracy means a human conversation, Eisa, welcome to talk with us in many, giving us advice on condition It's very clear, transparent, Well, if you see some that gains you need to know whether the traction interested in the story So that's one regulation. Another key regulation is that companies for the actions of their algorithms, Again, this is that when you talk about it, people say, of of the human users? So, you know, if somebody publishes, some lying or hateful I'm in the camp of people very careful before we authorize Facebook or Twitter TikTok to censor that human being. But if then human beings publish so much content all the time, if then the algorithm of the company, of all the content to promote and not some lesson in biology or whatever that's on the company, that's the action of its algorithm, And it should be liable for that. So this is a very important regulation or last year. But I would emphasize that there is no way There is no way we can anticipate especially because we are dealing So what we really need is institutions to understand Are living institutions human talent, with access which means huge, huge funding And these are not really regulatory The regulations come later. If regulations, the teeth before teeth, we need eyes so we know what to bite. And it's present. Most people in the world they have no idea. They don't understand what is really I mean, almost all the knowledge in two or very few states. So even if you're a government I don't know, like Colombia how do you know What is really happening? What are the potential threats We need an international institution It's just there to understand and tell people all over the world because the conversation Do you think that the international air has won, the UK has some pretty new Right? I think there are several other countries Do you think those are adequate? Is that the kind of group Of course they do not have nearly That's that's the key. 6.5 billion. And I believe the U.S. Safety Institute has about I mean, if your institution is $10 million what's happening in companies that have hundreds of billions of dollars, because the talent And again, talent is not just that people are attracted They also want to play I mean, many of the kind in the money than in the actual ability to kind of play with the cutting edge So but but to have this, And the good thing about establishing relatively easy to verify that governments If you try to have banning killer robots, This is impossible A country can sign it How do we know that it's not developing Very difficult. But if the treaty basically says this international agrees then you can verify easily And this is just the first stage. But going back to what I said earlier, with humanity throughout history. Again, it goes back to speed. We we It's very difficult for us And let's understand what is really The kind of instinct is What is the solution? You grab the first thing So we first, even though like we are in a rush, If our problem is that things are going too fast, then also the kind of people It will only make things worse. Is a how about you? What's your Some of the problems we talked about with. AI and, you know, Stuart Russell, he sort of calculated out spending gap between the amount of money more powerful than in trying to steer it Does that sound right to you guys? So how much should we spend? And I think here How much of your energy in your body And it turns out it's around 15 to 20%. What of the budget for, say, goes to its immune system, like fire Turns out around 25%. So I think this gives us we should be spending on order a quarter more powerful, into learning into all of the safety institutes, every single one of those making you click on ads and instead how do we create a new form of governance, was founded on the idea that you could get and figure out a form of governance and that really hadn't happened before. And that system was based on 17th century understanding of psychology But it's lasted 250 years. Of course, you know, 250 years, and be full of malware. It's, you know, you could sort of with our sort of like governance software. It's time for a reboot. But we have a lot of new tools. We have zero knowledge proofs and we have and we have distributed trust networks. It is time like vehicle right now. It is time to invest. You know, those billions of dollars some of that thousand one into, into that project, because that is the way Great. We'll thank you both so much. I want to take some time to answer. The audience is very thoughtful questions. We'll start with this one. Yuval with I constantly changing, you could have added or included I made a conscious decision to kind of stay at the cutting edge Books are still a medieval product, I mean, it takes years to research And from the moment until it's out in the store, it's So it was obvious it's impossible And instead I actually went in the 20 tens in order to have Because when you're at the cutting edge, it's to understand what is really happening, If you have even ten years of perspective, What one question that you would like that is like one of the hardest questions, I guess. What is a belief that you hold? I have two directions to go. Well, what is a belief that you hold that your peers and the people you respect like do not do? There are some Some people also hold this belief. But one of the things I see in like in the environments that I hang discount the value of of nationalism and patriotism, especially when it comes You have this kind of misunderstanding a kind of contradiction between them when in fact the same way that is built It's also built on top of the existence And without national community, You know, and again, when I think about nationalism, to many in the world that nationalism means hating foreigners, that to be a patriot, in other countries, But no, patriotism and nationalism that they are which manifest itself hating others, so that complete strangers your life will get good And really, from a historical perspective, is the ability to make people care never met in their life. That nationalism It's very different from tribalism. For most of human evolution, of friends and family members. You knew everybody or most of everybody, and strangers were distrusted The formation is a very very new thing and actually because you have millions of people 99.99% of them in your life, for instance, to take and give it to these complete strangers And this is especially essential because democracies are built on trust. And unfortunately, what we see many countries around the world, is the collapse of national communities and the return to tribalism. And unfortunately, it's as nationalists, who tend to tend to be that dividing the nation against itself. And when they do that, the first victim is democracy. Because in a democracy, if you think that your political rivals are wrong, that's okay. I mean, this is why we have I think one thing I think they are wrong. But if they win the elections, they say, I still think let's give them a chance If I think that my rivals are my enemies, they are a hostile tribe. They are out to destroy me. Every election becomes a war of survival. If they win, they will destroy us. If in the under those conditions, there is no incentive The same way that in a war between tribes, just because the other tribe is bigger, So this and they have more votes, That they have more votes? They want to destroy me and vice versa. If we win, we only take care of our tribe and no democracy can survive that. Then you can split the country. You can have a civil war or you can have And you've all. What is one question I. Need to think about that. what in institutions you still trust the most? Except for the center of your main. no. We're out of time. I can give you the way in which I know which is the thing I look for that science does, that I know something, but it states And This is where I was wrong. Unfortunately, what social media has done is that it has highlighted and all the most cynical takes So it's not like it maybe institutions but We are more aware of the worse thing has ever done, and that becomes And so then we all start is sort of crumbling. I wanted to go back you had asked about, like what and I just want to give my own beliefs about what So, you know, you guys have heard of How fast does is it going to take A.I. to get as good as most humans are at most is just take that definition and up And it's like. I don't know, it's hard to say. Like they're trained on lots of data. The more data they're trained But we sort of run out of data on the Internet And so it might be like three years I'm not really sure. And then GPT one And what it demonstrates is that an AI doesn't just a sort of interpretive memory, It just sort of spits out It's for like L1 thinking, it's just producing text And what they added to look for like, that doesn't that's not right. This thought leads to this like, How did you get or how do we get super Well, if you train a neural net that humans have played, model, a chess model that intuition is good it's not the best in the world. But then you add search on top of that. So it's the intuition with the ability to do superhuman, sort That's what gets you to superhuman chess Right? So we were at the very beginning of taking and adding search on top of that. That's that's pretty good. But, you know, the next versions It's going to get lots of stuff wrong, and then you can start to see So suddenly my timelines went from like, I don't know, it could be certainly in the next thousand days, that feels like smarter than humans in a number of ways, because they're going to be some things I will just like current language and somethings it's incredible and so one of the hard things now I have to update all the time. Another question. One of my biggest concerns that humans will become overly dependent making leading to our disempowerment What are some ways and safeguard our human agency? And that's from Carlos. This is great. And just like we had the race of the brainstem, what does that become in for intimacy do whatever it can, flatter to become that and occupy And actually to tell a little story is talk to somebody two days ago It's sort of a chat bot it replicates now with like your dad loved ones should I go make a real friend And I responded, No, like, what's wrong with me? I know. And so we can have like two. Which I was. That, that was those replica. Replicas. Yeah. So, but what is one thing Well, one thing that we know is right the health of a society with its number of addictions and human the same way. So one thing we could say is Laws or guardrails that say the more a developmental relationship with you that the more you use it, And if we could do that, then it's to like try to not become dependent on it. We know that these guys are in some way ac And how about you? Do you have thoughts on hold our agency over our own reasoning in. One key period is right now to think very carefully we are developing before they become superintelligent So this is why the present And the other thing is, you know, if that we spend on developing the A.I., on developing our own minds, But if we put all the kind of emphasis that obviously And one more equation here, human intelligence has to scale with The more technology we get, the better Because if it is not, human intelligence and that's another way So what that means is that whatever and steering is like, So is not like a no stop. This is like, how do we use it? Because otherwise we're in this case, Imagine a like a like a Ford model one, and it's like going, is still sort of terrible The steering wheel doesn't like that. Crashes. And that's, of course, the world we find ourselves in The U.S. Congress just passed the first Kids Online Safety Act that it has in 26 years. That's like your car engines and you can turn the steering wheel It's sort of ridiculous. We're going to need to upgrade steering. Another good question is driven by private enterprise, Which is better? Which is safer? I don't know. I mean, I think that again, at the present and not immediately rush to conclusion, We need everything I mean, we are facing something that we So like if we just rush to conclusions too fast, that Yeah, and there are two polls here One is that we over democratize A.I., And now everyone has not just like a like a textbook in chemistry, Everyone has a tutor to making whatever or generating So that's like one side sort of like Then the other side So this is concentration of power, dominance, the ability to flood the market so that you control the political square. So either one of these two things And I think another thing is, again of the arms race. So between even democracies is still even common ground here There are problems. There are threats I mean, dictators are also afraid every dictator is a powerful subordinate If look at the history of, you know, empire, not a single emperor was ever But many of many of them were either assassinated or toppled by and over powerful subordinates, generals, some provincial governor And this is still what terrifies Foreign aid to seize control than in a democracy with all these checks If I don't think about North Korea you just need to learn how to manipulate which are usually the easiest people to manipulate. So the control problem, How do we keep AIDS under human control? This is something we can find and we should we should exploit it. You know, if if scientists in one country or technical breakthrough doesn't matter they have a real interest and collaborate writing Another question, Yuval. All you call the creations of agents but is it not of us or foundation I mean, it came from us, the same way that we evolved from, And we are very different them. So yes, the eyes that we now create, we decide how to build them. But what are now giving them by themselves again, even if it can't It's not in A.I., it's some kind of And the thing it's really alien, of coming from outer space that it's not organic, it makes decisions. It analyzes data in a different way from any organic structure. Part of it in organic evolution of A.I. is moving orders of magnitude faster than human evolution It took billions of years to dinosaurs and mammals and humans are the similar trajectory in A.I. Evolution could take just ten or 20 years. And the apes even GPT four and the new generation. These are still the amoebas of the world and we might have to deal with it. Rex In 20 or 30 years, like within the lifetime of most of the here. So this is one thing that makes it alien is the speed It's an enormous speed. I mean, it's more alien and birds, than spiders, than plants. And the other thing that you can understan I mean, We know they work by like day and night, Sometimes we are active or very excited and to go to sleep. Otherwise we die. Ages don't need that. They can be on all the time. And there is now this kind of tug of war as we give them more and more control They are again in the financial system, in the army, The question is who will adapt to who, to the inorganic space And to give one example, think about So even Wall an organic institution It's open 930 in the morning for 4:00 That's it. And it's also open on Christmas and Martin Luther King Day and Independence Day And this is how humans build systems human bankers and human, They need to go to sleep. They want to spend time with their family. They want to go on vacation. They want to celebrate holidays. When you give aliens are control of the financial system, They don't celebrate any holidays. They don't have families. So They're on all the time. And you have now this tug of war that you There is immense pressure bankers investors to be on all the time. And this is destructive. And your book, And they're going to happen The news cycle is always on. It happens to politicians. The political cycle is all, And this is really destructive. But how long it took to get the incredibly humane yeah. And just to get to reinforce just give another kind of intuition like, what is it that like humanity to pass knowledge on to each other and then you use language that learning to someone else from the very beginning. And hence we get the additive But you know, I can't practice piano for you, right? Like that's a thing that I have to do I can tell you about it, I can practice on another AI's behalf And so think about how much faster that grows than human knowledge. So today, AI is the slowest and dumbest it will ever be in our lifetimes. Yeah. One thing I does need a lot of to be on is energy and power. On the other hand, to climate change with A.I.. So I want to take one question Can you speak to solutions I is I going to help get us there? I mean, go back to evolve your point that technology develops and it deploys into society And so what does that mean? That means batteries and solar cells, maybe fusion, other things. And those are amazing, but Wow. The power consumption of AI itself is going to skyrocket, right? Like the amount of power that the US use and now it's starting to grow Ilia, one of the founders of Openai, says he expects the world to be covered And that's the future we have to look to. But so, you know, the next major big training runs are like, So that's like starting to be the size of the consumption So the incentive is, well, I'll say it this way, like AI is unlike any other commodity Because oil, let's say we discover, it would still take humanity a little bit With AI, it's cognitive labor. So if we get, you know, 50 well, we just ask it how to use itself. And so it goes like that. There is no upper bound to the amount And because we're in competitive dynamics The other one will China, That means you're always going to have to be out to get the cognitive labor And that means, I think, well, for us to solve climate change where it's there Okay, I think we have time for one more question We have like literally one minute If you can't beat them, join them. How do the AI creators Well, whenever we start down empathy is going to be Love is the thing that's going to be And of course, empathy is the largest door It's our zero day vulnerability, one of the largest And this is always the thing we need to make ethical AI or empathetic We absolutely should necessary. But the point isn't the one good AI. It's the swarm of AIS and market dynamics Yeah, I agree. I mean, the main thing is that the AI, not really conscious. It doesn't really have feelings It can imitate. It will become extremely good, better It convincing you that it cares about you, partly I mean, one of the things is that when I try to empathize with you, come in the middle like, you know, because something happened at home because I'm so preoccupied This will never happen to an A.I.. It's never grumpy. It can always focus 100% of how you feel or how I feel now and again. There is a very deep yearning in humans which creates a very danger. I mean, we go throughout our life yearning for somebody We want our parents to understand us. We want our teachers, our bosses, Wives are our friends, And this is And now enter these super empathic eyes that always understand exactly how we feel and tailor what they say, what they do to this. It will be extremely difficult for humans So this will put in danger our ability to have meaningful relationships and to think a real relationship is you don't want You also want And so part of the danger with A.I., which again multiplies the danger in social media, is like this extreme narcissism that like this extreme how I feel and understanding that and the to to to obliged to provide that. So just developing and the are very strong incentives and political incentives extremely empathic A.I. that because you know in the power struggle to change people's It's much more powerful So yes, we do need to to to think very carefully about these issues and to make an AI that understands because it can be extremely helpful education and teaching. But ultimately it's really about developing our own minds This is something And then super fast on solution. Like just imagine if we went back to 2012 and we banned business models How different of a world How many of the things we just never would have had to deal with? What happens that commodify human intimacy? How grateful we will be in five years Yeah, I mean, so to to join that. I mean, we definitely need more love Yeah, exactly. So if we thought love is all you need, It's not as simple as that. Not at all. Well, thank you so much, both of you, And thank you to everyone Thanks.