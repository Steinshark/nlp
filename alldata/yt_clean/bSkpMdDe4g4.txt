- My talk is called What Has Unbolting the Compiler's Lid. Which is the longest and most Titles, it turns out, are very hard. So why am I up here It's definitely a question I'm (audience laughter) As Jason, in his wonderful my name has rather unexpectedly which has led to some this last week. I've not only had people oh, had people come up to as if we're old friends, and I'm looking at them smiling going, &quot;Who are you?&quot; And then they say, &quot;Thank which is amazing. Or I've been in conferences and people have been talking about like how there are those that are always background for your own name, and I'm so it's been very very very surreal, but thank you for the very warm reception. I'm going to talk a little bit about me just so you know how it with this idea for Compiler Explorer. Like a lot of people, I'm sure, I started, a long time ago, programming on these 8 bit computers here, which is, as Jason alluded to, still I'm still hacking around After a few years of trying I've been writing stuff the only way you could get back in those days. I moved over to the ARM processor, I sort of hung onto the and then, when the leap came, I made it all the way to 32 bit. And back in those days, of GCC for my computer, writing assembly code. I even ended up writing in assembly, complete with and everything built in just because that was pretty much the When I finally was introduced to C, I considered it a bit It was kind of like one of it got in the way of that I wanted to write. But when I got to university oh, wow, suddenly it's very dark in here. Nobody falling asleep, right? When I got to university and realized that the only way that write software that would my one ARM computer that I had, And at that point, things moved That led to me getting a job in the games industry, where Still kind of on the fence between writing assembly code and C After that, I had a dabble so for those people who work on C++ tools, I have a huge amount of sympathy for you. The language is absolutely dreadful and is the worst thing to have to parse. So if you see anyone from like JetBrains or anything like that, give or anyone from Eclipse. I then worked at a small Internet startup. And then I moved on to DRW, where I do sort of low latency stuff. So you can sort of say I've always stayed pretty close to the metal. So what about this talk? It's an amazing opportunity to speak to so many C++ developers, what am I gonna do with this time? What do I love, what do I I love assembly, you've from the last few slides. So I wanna make sure that you guys are happy and aren't it's a useful thing to do Not all the time, and I'm not saying that you should go out and or that you should even but you should be able of your compiler and, know what it's doing. And when you do that, you'll appreciate how much work has gone into the compiler and how clever the compiler is. There's a lot of glamorous features that come out in the language. You know, all these new meta classes, Herb's awesome meta classes ideas. Reflection is coming and all the template meta programming with the compiler, that's awesome. But that's all in the frontend. It's very important as well that the code that comes out at the other end, the thing that actually is is efficient, well, first, is correct, and secondly, is about as So the outline of this talk is that, and I give a little bit of a backstory as to how Compiler Explorer came about. I wanna give you a very I wanna ask the question, &quot;What has my compiler done for me lately?&quot; Which is just to say I'm gonna look at some of the optimizations, that compilers do. Now, of course, these are so they're all totally contrived, but hopefully you'll get, And then I'm gonna talk a when you type into my website, what's happening behind code results back in front of you. So in 2012, a friend and I were at work and we were discussing whether or not it would be possible for the C++0x flag or the and start using some of these new features that were coming through, you know. Things like range fors, auto And being a high frequency trading shop, we can't just say to everyone, &quot;Go ahead, &quot;just use whatever cool we need to make sure that So we concocted an example which is, as you can see, by reference, vector of and it's just summing them all up. Yes, this could just be but bear with me. And we wondered that this that is just a looping over into that, looping over by using an index into that container. That would be how we'd write it before, we wondered whether or not the much nicer code here just We've been bitten before some managed languages in particular that we had some experience in order to iterate over And that would generate things would go on behind C++ doesn't have garbage, we would like to check, you know, we should test these things. Which one of these is And that would be kind me talking about how And if my clicker works, Before I get into a we're gonna sort of tell you, give you at least enough information to know about how to read assembly, I'm gonna It's really beguiling of your compiler and start to kid yourself that you can see what it's doing and know instinctively that or this other thing is best or like, there are fewer instructions things like that. If any of you were in here he gave just a tiny glimmer of the kind of complicated things that a modern processor and While you can obviously about what's going on, and you should definitely Google Benchmark or one of the that's out there that have done their best to try and make it as although microbenchmarks Or you can, a quick shout out to Fred if he's in the audience somewhere Hey. Which is an awesome online to check out two different snippets and compare the performance, again, using Google Benchmark behind the scenes, but also in an interactive online way. And I've, I click a down, whoops. So let's talk a little bit about x86. Well, first of all, I compile for x86 platforms Good. I had this terrible fear that suddenly, everyone was gonna say, All right, who does There's a few hands. What about 32 bit x86, is A smattering. Anyone got a more exotic processor that they regularly build for? Oh, yes, some PDP-11, right? (laughs) All right, well, that gives it would be really embarrassing now if suddenly I had to to talk about, but we're and specifically x86-64. We don't need to know too much about it. All you need to know, it has registers. These are 64 bit values Back in the 32 bit version of the chip, there were only eight of ax, bx, cx, dx and all these things, and some of them have like but for the most part, as general purpose like variables. Luckily, when AMD decided to extend out to the 64 bit version, they which was handy, and instead they just called them the Those are where the integers are stored, that's like your integer There are some other or ymm and zmm, depending of the processor you've got. Any of your sort of will happen in there, and will happen in those registers too, but by and large, and I'm not gonna talk about those registers. The only other thing there's an ABI, there's talk to each other, and And that convention is that, the arguments of that function and then some other registers. And then, if you're returning a value, an integer value, that is, And there are rules about which registers you're allowed to overwrite you have to preserve, but if you don't need to know. That's kind of like our ABI Now, registers, as I've said, are 64 bit. But they have all these different names. So this is, I've given but this is true also for and even, you know, r8 through r15. If we put an r at the beginning, we mean the whole 64 bits of the register. If we say eax, we mean a 32 And we just get the bottom 32 bits. And for complicated reasons, it zeroes out the top 32 bits. That's not true of ax, ah and al, which are these names and then the two bottom bytes, I mean, this is kind of backwards compatibility I think the 8088, by adding on these, widening the registers and giving them new names each time. Once you've got registers, you So that's when we finally get So instructions can take anywhere between zero and three operands, I'm using the Intel syntax here. Yeah (laughs). (applause) God, I had a whole vs spaces and things, it was gonna get that much of a clap. By show of hands, who uses Intel syntax when they're looking at assembly? Oh, okay, and who uses the AT&amp;T syntax? Oh, oh good, I thought I was This is why Compiler Compiler Explorer has because it makes sense (audience laughter) And everyone else is wrong, I'm sorry. No, because I grew up, and they all have like the destination on the left hand side. So if you see anything on my slides, the destination of the instruction is gonna be the left hand parameter. So operations could be add, subtract, exclusive or, and, all those kind of bits and pieces. And then sort of uniquely Specific to CISC type those destination and things that are up there They often are, but they references to memory. And being as complicated as it is, the reference to memory can actually be more than just a memory address. We get this huge let of we get like a base, which is a constant. We can pick another register and say add that register to it. And then we can also and add a multiple of one, Obviously, this is handy because you wanna have a of the array, and then you wanna get like the ith element, you're gonna and then you're gonna multiply to kind of move it forward So that's really powerful. But it sorts of blurs the line about what a single instruction should be. I mean, if you can do And in fact, this is the kind of thing we're talking about of instructions there, I on the other side. You can kind of see the where like, the first one it says r14 is an address from it and interpret it as Second one is just adding Then we can start to see addressing modes where we can add whatever's r14 plus a it would read out like the if r14 was an integer array. And then that subtracts sub That is doing that array index operation that I was just saying about. Now, it turns out that is so powerful and so useful that just says hey, compute the address that I would otherwise want to read from and just give me the result of what that address computation is. That's that penultimate the load effective address. It's kind of a glorified to effectively do like the like take the address of But it is also effectively just adding a bunch of things together you might argue, than the And then it's worth calling out this thing on the bottom here, that xor edx, edx. It seems kind of weird to do exclusive or on But as you've probably worked out, if you take any number and you end up with zero, of setting edx to zero. Why might you want to do it that way? Well, in order to encode move eax, 0, you would for move down and then you'd that correspond to the Whereas this exclusive to encode the op code, so it's smaller and more compact in There are also some architectural reasons inside which are super but I don't have time to go into here. So in summary, funny 64 bit registers, they have different names, in rdi and rsi first, operations are with the and destination and or those memory references. Okay, so now you all know Where were we, we were these two implementations of over a vector of ints. Which is better, well, Let's have a look at the assembly, that's how we look at these things. This is Compiler Explorer version So I was running g++ on a temp file, putting the optimizer on, telling it to just output the assembly outputting to dash, which is standard out. And of course, the very Pipe it through c++filt don't mean anything to me, is just removing all of the funny lines, the dot directives the in order to talk to the a real program out but And we got something like this. I don't know if you know It's a command that takes another command and it just sits there and it keeps running And you can even put a difference from the And so I just split my ran that in one side There you go, Compiler Explorer. We found it so useful. We were able to answer about how the code was being compiled, and once you've got a tool like this, you start thinking hmm, I So I went home that night, that this was a great solution, And so what do you do when very pretty, you could use a Or you could go to the web. So, oh gosh, I'm so glad that loaded. This is Compiler Explorer, many And this is the example, so But I'm not gonna show the it is too small, oh, I'm gonna have to... All right, is that just about readable? Yeah, oh good, and the Okay. So here's our example. And on the left hand On the right hand side, that comes from it. I'm compiling with GCC 7, 7.1 here, it's the version I wrote this talk with and I'm paranoid about changing anything in case it all moves around. Inside the compiler and C++1z and arch=haswell. Haswell is an Intel variant and is in most servers, in my experience. Just to sort of give a brief sort of wave, hand-wavy introduction, we're gonna go into a little bit more detail in a second. If I mouse over this yellow area here, you can see that there on the right hand side a bit bolder, although it's The color coding tries to with the assembly output. So although we don't really apart from my crash course we can see the int result = 0 So we know that xor eax, eax is the same as eax = 0, so we can at least sort of see a parallel between those two things. Similarly, if I look this is where we're Now again, because we're we might reasonably intuit to hold the value of the through its loop. And indeed, this is the add eax, DWORD PTR [rdx], I'm gonna accumulate into eax with whatever is pointed at by And then you'll notice that there's no actual assembly That's because, when the compiler is finished executing this the result is already in the eax, which is where we needed to leave the return value for our caller. So there's actually no instruction. I mean, typically, I guess you could argue this red here should be but it's not perfect how Okay, so before I get too far into this, I would just like to show you what happens if we turn the optimizer off. So optimizer off, and I'm not but the compiler does pretty So this is kind of interesting and useful just to sort of see fully what it is that you have asked the compiler to do. And we can see that there's that's been generated here, have been emitted. And if you went to the you'd know that they were marked as weak and things like that. But on O1... Yeah, we've got a mov eax, 0 here, it's funny that GCC has decided that just replacing mov eax, 0 with xor eax, eax is just not worth doing at O1. I don't know quite what And then if you put it on O3, but not very good for, as we know. It's amazing. I mean, look at this stuff. There's pages of it, and I'm sure it's all super super awesome and it uses all these vector instructions, which are super cool and everything. But we'd have to benchmark to make sure that was actually faster I trust the compilers a lot, but anyway, it's too much to fit on the slide, so I'm kind of settling for All right, anyway, what It was are we okay to do a range for? Now, I am gonna drag down one of those and I'm gonna paste the code hide away the hidden set of The font size is slightly too big here, but I'm sure you'll give me the benefit of the doubt for a second, so I'm gonna go for (auto x : v) result those two lines, and nothing's happened, 'cause all I've done is The UI is such that I need to now actually slave a compiler to that window, so I'm gonna pick up a compiler and I'm gonna put it over here. And then, just to make it a fair fight, I am gonna grab the same and paste them in there. Okay, well, I can scroll up and down and see that there's 14 instructions there and there's 18 instructions there, but there's a better way to I'm gonna bring down a diff view and I'm gonna maximize it, all right. This is all good, there we go. All right, this is what I wanted to see. This is the two versions side So you can see, on the left hand side is the version that is zero to v.size and just and on the right hand side is the version that's using the range for. Now, again, with the measure everything and you can't just look at these things, we can which is that, although at the beginning, this region or 10 to 14, is identical on both sides. So even though we wrote the code in two completely different ways, the core loop, the bit that's actually running over everything is identical in both cases. And the difference in the top bit is of a couple of instructions. We might reasonably expect them to perform very very similarly. Oh, hang on a second, I was And that is, for the purists among you that are saying why don't Accumulate begin(v), end(v). Typing under pressure is never easy. Ta-da! Now, if you are eagle eyed, absolutely identical, give or from the handwritten for loop. So use your standard algorithms I think is the takeaway there. Let's just quickly take apart that code. So this is an example of how, I would take it apart and try to intuit what's actually going on and So if you remember, we're taking a vector of integers by reference. Now, there's no such thing as a reference in terms of the hardware, as far as the processor's concerned, so effectively, what a pointer to a vector of The first parameter, the will be an rdi. And you can see these are reading from rdi and rdi+8. Now, it would be easy into the trap of thinking at the list of integers itself, it isn't. It's pointing at the vector. And in at least GCC's this is what ultimately, all the template stuff, you get to. And that is we got a structure which has three pointers in it. The first pointer points to The second pointer points of the array, and the third the allocated region of storage So that means that we can have more space than we're actually vectors will grow to that they need, and they will shrink down, well, they won't shrink Sorry, I'm getting carried away here, but the interesting thing here is not encoded inside that structure, we just have two pointers. This will become interesting. So here is the difference here are the bits that's different. On the left hand side, counting based approach, we've got the range based approach. Those first three instructions the sub, the mov and the shift right are effectively taking the end pointer and subtracting it from the begin. That tells us how many bytes are there between the beginning and And then that shift right by four, you know, if you're gonna be dividing by two, and if you shift right twice, So what we've effectively done there is that's the size call. So the size call's been made. And we now know how in our vector that we're Implicit in that shift right is a sort of comparison with zero. So if we got a zero result, and that je, jump if equal, will disappear after the .L4, which is the just return zero part of the program. So so far, we've said if so, we're done, great. So now we might reasonably while it counts up until it hits the end of the, like until it hits that size, has happened here, the that we never used that And then we're just reading and it's basically gone in and rewritten the whole thing for us a pointer to the end of a pointer forwards So it now needs to know where which we all know is actually in or was in rcx at the beginning. Compiler has unfortunately and so it's had to add rdx back into rcx in order to reconstitute the end point that we had to start with, unfortunate. And then it sets the result to zero there. So a little bit of extra and I think, I mean, there are probably some compiler writers I don't think I'm speaking out of turn to think that that could be I don't know if there's anything, oh, there's a note there, (mumbles). (background noise drowns Oh, okay. So I think the comment was that Clang was giving the same output, Is that right, we-- (background noise drowns I see. (background noise drowns Okay. It's difficult to communicate. Yeah. The comment was that there or there may be an issue if we could talk about it at the end, perhaps that would be clarified, 'cause otherwise we're gonna But that's great, there they can help me make this better. On the range side, of course, is that range for is being rewritten to be get the begin, get the and walk it from begin to end. And so that's exactly So there's no funny working out how many iterations we need to do and then effectively throwing away the number of iterations there. The loop, we already saw, so I don't think I need to We're just reading each and adding them to the accumulator. And then, when the iterator hits the end, we stop looping around and we just hit that return instruction. I think we can probably a couple of instructions they're identical, which is great, really, because that means that go ahead, use the much rather than counting. That's excellent. Also, we learned that make a huge difference. And in fairness, I the two versions with working out whether or not that changes if we try counting I'm not sure that we would, be worth checking, and of course, you would benchmark it if And we saw that standard so we should really just be Okay, so that's an example you can do if you start sitting And as I say, you start the compiler does for you. So the first thing I'm gonna talk to you about is multiplication. Again, as I said in the beginning, these are all slide examples very small and very simple, So this is what a multiply passing two things, x and y, edi will have the first parameter, esi will And we need to get the listed to me, the And this is what the compiler emits. That's cool. But can we do better than that? Multiplication, if you looks something like this, done by hand. I'm sure there are much cleverer things going inside the there's a lot of adds happening, and this is only a four bit multiply, so there's gonna be So on a Haswell, where at least a 32 bit It's a miracle that they in four CPU cycles. Now, a CPU cycle is roughly so just get that around your head, right, we're still talking about much more than a But an add is one cycle. So maybe there's a Or maybe my clicker What happens if we happen to know that we're multiplying by a constant? We know it happens all the time. You might be walking an array or getting the ith element of an array, and you need to be able to multiply by We might reasonably expect as a shifter where we can shift shift up and therefore so we might expect it Let's check. Oh, no shift. It's that funny lea instruction. Like I said, it's a glorified add, you have to think of it as an add, but the cool thing about lea is that you can have a different whereas the shift on x86 is in place. So it avoided an instruction here just to move things around and instead it said okay, and then put the result into What about some other numbers? Surely, it's gonna need a Well no, because we can use the lea again. All right, well, now we know can do one, two, four or eight. So there'll be no surprises and there actually aren't. If we go to 16, we're gonna and there you can see the two instructions that it would otherwise had to have used if it was just using shifts alone. Now, again, for anyone who you can see how clever that processor is at moving things around it's very very clever to not have two instructions But what happens if we Okay, it's given up on us. So there's obviously a compiler writers are not I know. (audience laughter) I know that-- (applause) Oh, no, wrong one, I know that I can build I know that 65599 is 65536 so that kind of, I can build so I'm gonna do that and I'm gonna make better code than the Oh. (audience laughter) (applause) Well, that's awkward. So yeah, it turns out the No surprise there. So not only is it smart enough is faster than all the that it would otherwise have to do. It has worked out that my is actually equivalent to a I'm gonna save you from yourself here. (audience laughter) That, of course, is only true If we go back to the Yeah, you see. I am still channeling Michael Abrash's big book of awesome optimizations and I can still write better Well, no, still. If I turn this into the multiply that it really should've been all along, the compiler is actually even smarter than that sequence of instructions, I have no idea what it's doing though, I haven't bothered to work it out. So the thing that, the answer really is let the compiler do the things for you, it's gonna be smarter than you. And I guess as a sort is like telling it what is probably important as well. I mean, I don't think for a long time, so I think you're safe on this particular one, All right. That's multiplication, and multiplication with a constant as well, so What about division? If you hated doing long you probably, like me, And processors don't like So this is the code a divide or a modulus. It turns out that the circuitry that they use to make a divide also gives you the remainder at the same between these two it picks to return eax or edx. So it's one of those funny the idea of instruction the two registers that aren't even named in the instruction, it's crazy. Anyway. A 32 bit divide on a Haswell That's eternity. I mean, it's still only But it's eternity compared The other thing that I haven't is that there is only on your Intel chip. And it's not even fully pipelined. So those multiplies, for multiple multiplies on the multiple concurrent multiplies going on. They're also pipelined, which means that you can start a new multiplier every cycle and get the but least if you have a chain you can kind of get one The divider, no chance. The divider, you're just, it's wedged, it's gonna be, you're gonna be waiting for 20 to 30 cycles and no one else can use it. Can we do better? Click, there we go. Well obviously, trivially, and that constant is a power of two, we're back into shift land, right. So I have moved over to just to avoid extra code, with signed numbers too. So now there no magic lea to save us here, it's which is cool. And you can't even see the code because I scaled everything up to try and let you see it, okay. So there it is, x over 2, and you know, no surprise, it's gonna shift it times But how often, I mean, in fairness, how often do you do integer division, but how often do you do Not that often, I'm guessing. So let's try three, what happens here? Ah. We've lost a divide, on the right hand side. We've got some movs and things with a funny scary looking What's going on here? Well, compiler cleverness again. What's happening is that aaaaaaab value is actually two thirds by 2 to the 32. So like effectively a where the fixed point dot is so it's 32.32. So if we multiply by it, shifted up by 32 bits. And if we just discard which is what that mov eax is doing, then what we've got is the answer with a fixed point And then we halve it. So why are we multiplying by two thirds? Well, it turns out that, in order to cover the entire range of an integer, an unsigned integer at least, to do it by a third by two thirds and then shift it down. And there are some very for determining the exact sequence of operations you need a particular range of And I saw some copies of, there's a book, I saw some oh, that's great. Sorry, cancel. I've been clicking report problem, but nothing seems to happen. So anyway, that's division. So if we've done at what modulus does. And modulus is effectively just a divide so that the bit is grayed It's a bit that's, and then we just multiply and you'll see it's using to multiply it by three by that's quite clever. And then it subtracts it and you get the remainder. So why am I banging about Well, they're used in hash maps, which is everyone's So if you've got a hash value, you've probably got a 64 bit number that's come out of you like doing whatever crazy operation on your string. And now you've got your 1,021 that you need to, sorry, your hash list, that you need to start indexing And the only way to kind and smoosh it into the is to modulus by the number of buckets, which is great but we've just seen, it's about the slowest thing you can do. Now, obviously, if you know ahead of time that your container is exactly 1,021 buckets, that does mod 1,021, ah, modulus by a constant, I'll generate that cool code for you. And you're done. But of course, most of the we don't know how big our unordered ones anyway. And so there's going of how many buckets I just gonna mean there's And that's unfortunate because hash maps are meant to be the fast thing. Again, we're only talking about, you know, 10 nanoseconds, but these In fact, so much of a difference that libc++, after a certain point, gives up using prime the good way of doing the number and it starts using powers not actually like perfect, number of buckets, it's probably okay. And at that point then, to pick the bottom few bits So obviously, people some smart people, I'm looking, some people are looking at so I'm assuming it's them, some people are thinking about this kind of stuff. And in the case of say boost multi_index, there is an even cleverer thing where they have like a certain of the buckets so they we have 20 different each of which is a prime number. And then instead of just they do a switch statement on and they have case 1021 Or the equivalent, I think Which means that yes, you've and yes, the compiler's and jump to the right part, you're just gonna do a couple It's obviously worth thinking about. People cleverer than me are And that actually is relying is going to do this you wouldn't write it that way if you didn't know that Who went to Phil Nash's talk earlier? There's a few. Cool, I thought he was gonna There are a number of data structures for which it is convenient the number of set bits in an integer. Now, who has ever actually had to do that? Gosh, actually a lot more than I thought, I mean, Phil's hand's up, of course. That's surprising, I this sort of example and everyone like, why would we do that? But anyway. So this is a way to count We're gonna pass in a while there are still bits And then at a &amp;= (a-1), it's like one of the oldest bit twiddling for clearing the bottom set bit. Go around again, once we're done, we return the count. Let's see what our So this is GCC. GCC has done something quite clever here. It has got a loop. You can sort of see the yellow And then the red line it's replaced with a blsr instruction. I'd never seen the blsr instruction before until I actually prepared for this talk, and it turns out it's custom It clears the bottom set bit and lets you kind of put it into another register, so there is just, you know, That's pretty cool. So it's picked an instruction which does exactly what I want, that's super clever. Can we do better than that though? I imagine there's some at the moment. Oh yeah, we can do much better. So turns out there is an x86 instruction whose only reason to be is to it's so common that people wanted it that Intel put it into Now, just have a think about Like, there's no bearing there's no hint there the number of set bits. There are some builtin pop count things that you can do which tell the compiler I wish to do this, and will let you either emit or the instruction if it's supported on the architecture I've picked. But I was blown away when this So all the bits of code that I have that actually used the could be replaced with the human, well, I guess bit manipulation and stuff, but you know, more readable to me, That's an awesome achievement. The last one I'm gonna a bit of a toy example. So standard caveats apply. And that is this summation, and I've used constexpr that this is all C so far (audience laughter) So we're gonna sum up to the value x, and so we're just gonna of starting at zero, counting up to it and adding it to our sum, brilliant. And then we're gonna like it's gonna sum up to 20. And so we're gonna have a look how does it, oh, oh right, okay. Well, it's constexpr, right. Constexpr means it can in the compiler, right, in the constexpr context, it turns out, but let's just replace or let's replace it with an It's still the same, right. So the compiler can see it, we're up to and it says, just working out if this Now, this is a stupidly In general, you might find this happens in code snippets that you're pasting into Compiler Explorer, and the trick for this is to make sure it depends on something the compiler doesn't know. So in this case, the compiler doesn't know how many arguments they're so there we are. Now we can actually see And again, GCC's done a cool thing. It's unrolled, no it that's the next bit. Okay, so it's a pretty I'm not gonna bore you but you can see the shape of it, and you know, if we we can turn on the O3 again, you can see, look at how cool, again, I mean, I'm sure, I don't know how many command line before that's more efficient than the previous version, I don't know. But let's have a look at Oh, that's interesting, there's no loop. There's a test in that blue region, and that test is just or equal to zero, then the answer's zero. And then that yellow block, to sum += i, I don't know how the compiler came to that conclusion, a funny lea and a multiply. What's going on there? Well, as most of you probably know, there is a closed form Clang has worked out, and it's replaced a code yeah, that's pretty awesome, right. (applause) Even more interestingly, the thing that I've always It has, in fact, replaced They're equivalent. The reason being is that what happens if we passed an INT_MAX, right? It would've worked, the for INT_MAX, but it wouldn't have worked if we had to do x(x + 1), it would've all gone horribly wrong. I mean, how you'd get INT_MAX in to a prime function is essentially, they've dealt And it turns out you can tinker and it will like, move just give you a close Just think about what an order n piece of code a linear, sorry, a there's another hand going up here, hi. (background noise drowns Right, so the observation was that overflowing an integer is and so why should it compile? It's because the compiler isn't allowed to start doing undefined my x wasn't overflowing. Yeah, so you can't introduce, because for all it knows, the value was actually intmax beforehand did it overflow the integer, undefined behavior. We can talk about it afterwards, anyway. Okay, these are dumb examples, The compiler does so much more than this. I tried to get a slide some of my favorite things. I'm an old school sort of 00, So I still use the keyword I know, but compilers at seeing through that too. They can do static devirtualization in all the cases where they can prove that a type is of a particular type and they can get rid of the And now they're getting like saying I've looked because of LTO and I've said seeing that there is exactly one and so I'm going to assume that every call to that interface is to that It still has to check, on the vtable pointer of the function it's gonna call to, in case you've dlopened something and loaded another implementation. But ultimately, it's and put a big check at the front. And that's pretty cool, but And of course, the compilers and it's doing constant I don't understand, I'm I'm just a guy at the looking up in awe and wonder And I think back to that 20-something me, who always thought that the C compiler was basically a glorified macro assembler, and now I just realise how wrong I was. The compiler has done you should really be thankful the compiler writers put into and most often correct too. All right, so that's my for compiler writers, and a little bit about how G-Compiler Explorer, I nearly said GCC Explorer again, gosh. Compiler Explorer works. This is the second talk of this conference where I'm gonna talk about So yeah, it's written in Node.js, which is a common JavaScript framework. And I know we sometimes for having funny defaults if you just take a look (audience laughter) I mean, honestly, you and you'll find three cases at least that will make you just, I don't know, give up on the whole it's easy to stop then get and once you start a project and it becomes really successful, to like go oh, I should in something else. And the irony is, the only other sort of big open source libraries is a web server written I would've used that, but never mind. So it runs on Amazon's infrastructure. Oh, this is what Node.js But you know, this is gives you a very primitive You just say hey, I'm being posted to me at this URL, feed them to the compiler, maybe do a bit of and then give it back. So straightforward, I wish it was as easy to do some things like that in C++, and I'm sure there are people in room, who can tell me libraries to make it that easy. Behind the scenes, it all runs that means EC2, which is I have an edge cache, oh, that it started out as so literally the world's smallest computer that Amazon would give And as demand increased, it got more and more sophisticated, which is to say that the onion layers have and now it's just a bit But anyway, it's now So hopefully, when you load the page, it comes up pretty quickly. There's a load balancer So when you actually make your post, it gets fed out to one that I have in the background. Those instances are VMs And within those VMs, there are Docker images. So Docker is this sort of very which allows you to bundle together data and sort of run a process in a namespace, which means it can only see so it's a bit like a VM within a VM, although much lighter weight. That gives me a certain from all the crazy code not taking down the whole thing. And also, it gives me a I can run the exact binaries locally that were gonna be deployed to the site. Most of the time, I don't break And for a long time, I used to build all of the compiler images actually into those Docker images. And that started getting less fun when you get 40 or 50 and you try and build and then you have to try and and you know, it takes for a node to start up, all this data before it can even start. I solved it with the and that is I just have a big NFS mount that everything stays The compilers themselves, I started out by apt-get installing them. So the Docker images kind and so you would shell into all these commands, I would gcc-blah blah blah blah or whatever. That was great, it was very convenient. But then I was finding that the compilers I'd originally put on the were being deprecated on GCC 12 or 14 or 16, so I just because it had some ancient compiler that I wanted to keep. And I wanna make sure that the URLs that you guys are sharing which is a whole other story, you know, URLs are forever, forget like it's like URLs stick So now they're built I've spend quite a bunch good practices for building compilers, and so I've kind of canonified that, it's all on my website, which And they're built in Docker I have reproducible I'm very passionate to be able to clone this the same compiler the And more to the point, I chucked them on S3 And I keep getting emails from Amazon because there have a who's discovered that they on S3 and they didn't mean to. Well, I actually mean to, the is that you can actually and if you have enough hard disk space, you're gonna get 40 gigs dumped onto your hard disk, which is cool because then you can run of Compiler Explorer your code to me, for example. That's the open source ones. Very kindly, Intel have provided for the ICC- they're somewhere else. And the Microsoft compilers which is a bit of an admission of my lack of understanding of how more than anything else. I'm glad to say I've met up with Andrew and some of the other Microsoft folks who are gonna help me and we're hoping to get some proper support into Compiler Explorer, so that's a really exciting thing that's coming up. (applause) Thank them, thank them. And you know, security. Well, I only got an email from someone who thinks and maybe they have, I don't know. Turns out a compiler is waiting to happen, it's Compiler writers are awesome, as I think I've already said enough times. They're not really security experts and they're not really, they they're on a trusted system. But I had no idea how many into a compiler. You know, you think a I'm not actually executing But GCC has a plugin architecture, you can supply a -F plugin and point it at something which is a So if you can cause the compiler to crash, but having written the file somewhere, and then my cleanup code then you might be able and then do another compile and then you're in. Only happened once. (audience laughter) Also behind the scenes. GCC uses something called specs files, which I don't claim to understand, but it seems to be part of the processes, the many, many pipelined processes that comprise the compilation, through CC1+ through the AS assembler and all that kind of it's a set of shell commands to run. And of course, you can say, actually, I'd like you to use my And again, you're back as long as you can write a that says run, I don't then you know, you're in. I sort of started down a route of trying to harden everything, and then eventually I came to the conclusion I can make it completely bulletproof. And so I've accepted that the principle of what's the worst that can And that is, you can hack one of my nodes and you can take down the Docker instance, and even if you don't get the worst you can do and then something else will and it'll start up again. So hopefully, that's not too bad. Even if you escape the namespace jail, which You're in a VM which has I'm saying this for where someone's gonna email me &quot;actually, true,&quot; but oh well. Anyway. So Docker protects me And I experimented for a long which is a Unix specific a dynamic library to be loaded and then you can replace so I have a little bit replaces open and read and just has a blacklist and whitelist of all the different files that you, that I was allowing the compiler to read, and that was my way of #include/etc/passwd, ha ha ha. Which is essentially the kind of thing that people try first. Turns out though the compiler 'cause he wants to know And I thought well, And then it was oh, /proc/cpuinfo, I'm like, Why should I let it read And it's like, well, mach=native, and how else is what CPU it's running on? And so on and so forth, everything was basically I just threw my hands up (laughs) So I guess we should talk a little bit about that frontend, the bit you see. So another huge props to Microsoft here. Visual Studio Code's editor that you can, written in JavaScript, that you can just take and it's awesome, it's And it does everything I'd ever want. That diff view, for is just a native thing It had long been on my Things like bug number three. And then, when I moved over which was the previous it had this diff feature. I was like oh, that's two lines of code to And then the funny sort that I see other people wrestling with, which is more of a testament at user experience and I'd like to, thanks to both the teams behind those things, it's those things, it made it copy paste the website together. And clicker. So the code's on GitHub. There are two repositories, the first one has all of the Node's code so effectively, if you you should be able to git clone that and type make, and then you're done. You'll have your own local running version of Compiler Explorer. The second line there is the image, which has all of the Amazon stuff, it has all of the Docker container stuff, it has all of the compiler So basically, if I were to be knocked over by a bus tomorrow, you should be able to reconstitute Compiler And if you, oh, I've done that one. And there will be more the next C++ Weekly, Jason's So this is a slide I plonked in earlier so I haven't really thought But this is inspired by the conversations I've had with you, you folks. And that is, I think I use Compiler Explorer, why it was made. And I've been surprised at how differently everyone else seems to use it. There are a few people who like to show cool and cute optimizations but it has become this sort I think Jason alluded to that that, you know, it's which is, you know, And I know that some of the compiler teams are using it internally to test out things that they're doing and the Clang and the GCC bug forums, and there are over 100 to Compiler Explorer links. And people use it to like sort you can just drop, the drop down has like so many compilers, you just oh, it was introduced in I've also seen people or heard of people using it as a kind of REPL. Which, you know, if you're doing a bit of template meta you can write, you know, constexpr codes that uses it or static asserts. And you can start like I think this sort of shows It's a nicer experience which posts your code across the Internet to someone else's machine that than it is to just do it locally. So I wonder if tools might have some ideas from that. And I've also seen people using it as a training resource, which you know, to be on this you know, teaching C++ and making sure people understand how to write this code and understanding the when we write code is I feel like Compiler Quick sneak, sneak? Yeah, sneak peak, I always get of things that are coming soon. There is CFG, that is a coming very very soon, in fact, it's on the beta site or beta site. So if you go to godbolt.org/beta, then you'll see that there is a new icon on the far right hand you can click and drag, that shows how the different I'm also looking to so you've noticed that as many people have said, It should just be godbolt.org, well, should really just be but you know, no one's with renaming it now. So I'd like to have all you know, there are other there's Haskell, there's They're all there, and it would be nice to have them all in one different URLs, you two different editors from two The Go version and the and then see how the assembly I fear that will lead to some flame wars, so I'm not taking any And then the one thing is executing the code. I mean, it's fair to say, there out there and they are check them out as well, there's OneBox and other ones that But they have, some of those and that's awesome, because it's even better if you can But you've seen my amateur so I've really gotta before I allow arbitrary code to be run. But it is coming soon and who know much more about this than me. Okay. We're at the end now and This is not just me. Compiler Explorer is now, I'm glad to say, getting a lot of contributions so Ruben, Gabriel, Simon And the other people that or taken the time to contact me directly and tell me about issues that they found or have suggestions for the site and, you know, it's awesome, it's that has been a labor of love, that you were scratching that actually, it's and not only that, that they are willing to help you with it. Thanks also to the Patreon I'm in an embarrassing a small amount of money which is awkward, so I keep just to counteract it, then you'll get faster compiles. (audience laughter) Thanks to the awesome there we go, spoiled the ending. Thanks to the awesome C++ have been a great source of and of course, thanks to while I talk about my Go and read some assembly, thank you. (applause) Thank you. We've got time for some questions until I'm told otherwise, so yeah, hi. - [Male Audience Member] where you showed the - Oh, you're gonna find a hole I'm not, I'm, oh, somewhere in here. Hold up. I think it would stick out There it is. All right. - Yeah, so the interesting the Clang transformed x - 1 'cause it's worried about overflow, but the multiply can also overflow because the whole thing cannot overflow, right. So if you look at the it uses some very weird in the compiler, it Yeah. - Oh, I see, well, there's somebody who actually knows what (laughs) - [Male Audience Member] will also have this. - I don't know, we've got Thank you. I guess on this side, hi. - I actually had a question about scope. Other tools that I've used provide external libraries Any plans, or is that even - Let's have a look, hang on. Just the other day, thank you, Twitter. Oh, go away. (laughs) Never do things live, let's So we now have a relatively of adding libraries in, is one of the more recent - [Male Audience Member] That is awesome. (applause) - So thank you, Google, heads up on that. Oh, thank you, I guess, hi. - Hi. Okay, so you said you like people to use it to share code, right? Any way of making links shorter? - Well, the link shortening. So I have a thing. At least at the moment, I'm I think I should make that your code, my life is far to read your code, so I other than compile it and throw it away. And I don't even wanna store until I have like some so what actually happens so when we do the long URL, You've seen it, it's like, it's giant. So then I use Google's link shortener to turn it into the and I've been reliably, - [Male Audience Member] - Yes, it fails at 8,000 characters. So I'm gonna have to pony up at some point and actually store your data, the sort of features that And we've got some ideas and to do it in a way that means that your data is safe and backed up, because I never want that's really important to me that people can still go back to Stack and find some awesome reply to something and then still have it work. - [Male Audience Member] Okay, thanks. - Thank you. Hi. - Regarding that optimization with the hash table where you of the length of the hash table-- - [Matt] Right, the boost - And then you do a switch. Well, those possible fixed to each other, they're all spread apart. So you're gonna wind up which is a whole bunch of ifs, - Yeah, yeah. I simplified for the it actually does is it just So say it has 20 different and it switches between 0 and 20 then. And it knows that the 9th is 1,021, I know I but it was actually like, return hash percent 1,021. Does that make more sense? - [Male Audience Member] Well, if you have a bunch of cases you can't have a jump-- - Right, they wouldn't they would just be numbers as the 20 possible sizes. And then, of course, it and so you just jumped Yeah, I'm sorry, I oversimplified that otherwise I'd spend and as you've probably I guess you were here first, yeah, go. - Hi. Do you have any idea to support execution? So I think that, if you I think it can be supported. - That's right, so I mean, it's already been the to put JavaScript's backend support, and so I can compile asm.js and then WebAssembly And so yes, there is a WebAssembly, shipping it back well, you can play with the only computer you're That has a certain appeal to it, but there are many many compilers here that don't have backends for WebAssembly. And so, I mean, I guess one I mean, if you came to I'm sort of strangely passionate And if you've ever seen I also love talking and how the internals of processors work. In my dream job, I would sit down and I would write a JavaScript with all the pipelines and everything, and then I could like complete the circle and have everything together, and then you could execute it locally and see how all the caches work and But no, at the moment, I think execution will probably remain on the server side. - [Male Audience Member] Okay, thank you. - Thank you. Oh yeah, go. - [Male Audience Member] I have one more-- - Of course, go for it. - I just came here, you my team members working and do you have any idea to - I would suggest that point it at your own compiler, on which files it can it's not running in a Docker container when you run it locally, so you can do -I and point it at user, include Linux or whatever you'd like it So when I'm using I'll use it locally and I'll and then I can just #include, you know, my thing that I'm and then write a little test function, I can see how the assembly's generated. So I think you could probably - [Male Audience Member] Oh, - You're welcome. - I appreciate it if you but how much does this cost? - Oh, I don't mind telling you at all. I'm spending about $120 on and then there's, just And then there's like transfer the other miscellaneous, the about 150 on that, and then that I have like, you know-- - [Male Audience Member] 150 per. - Month, sorry. 150 a month. And then there's a bunch of other stuff, it ends up being of And you know, I dither on what so my patrons are currently you know, awesome, so I'm like net up, although if you count-- - [Male Audience Member] by 10 or something like that. It's just gonna keep going up. - I mean, maybe. Don't make it anymore awkward than it is. So yeah, if people have got that may involve larger sums then I'm all ears for adding stuff that's like a mouse Thank you. Oh, I guess now I've lost so I'm gonna just go alternating. - Do you think it's possible to support like LLVM intermediate - Yes, absolutely. - Like I think 'cause especially for people who's - Can anyone remember what, lvo, lve? (audience chatter) Oh, well, there you are, So it already is, don't I can just put command line options in it and it just works, right. It looks-- (laughs) Yeah, so it's sort of it will just dump whatever I'm not being clever here. But we have got some, I mean, you can see there's a load of redness in We're gonna be putting in syntax highlighting of LLVM, And it would be nice to like It's gotten more and more sophisticated, the filtering that I do has gotten more and more sophisticated 'cause the function that you're interested in and not all the fluff that comes in. I don't know enough about LLVM to know how to do that, but that'll be coming down the line. - [Male Audience Member] Yeah, - It also support -e, which which is how people do the we do have that over here, you know, #includes passwd.h, whatever. Yeah. Does that answer your question? - [Male Audience Member] - Thank you. All right, over this side now, hi. - I'll bring this comment As far as I know, there is an Yeah, you can look it up in Google, the one I know is in bellard.org. And it runs an entire it runs everything even somewhat fast. I don't know how, that guy's crazy. - That would be fun. Yeah okay, thank you, I think, last question by the look of it. - How do you get the to assembly lines? - Oh, magic. No, I just pass -g, whatever you type in, there's always a -g in there and luckily, the assembly output has the hint to the assembler and I parse that out. I also support STABs because there's some ancient compilers but it's not that sophisticated and I've filed a few bugs with, about like where they is correspondence to what, and because there's some obvious glaring guys, I'm sure that you to the right spot, but we'll see. Okay, I, oh, is there, Thank you, everyone, thank you so much. (applause) (bright music) - Bash Films can shoot your link to presentation slides, add titles and edit your event live for - How is this even working? So this is actually a more you know, look at in a lot of ways. So let's profile it. Do a little bit of time Let's see exactly what it or slower based on the different inputs. We could really gain a lot of at the profile like this. - I worked at Sesame to be a writer's assistant on a show called Sesame Street English, which was to teach English It seems very simple, the but it's actually really that is not only for young - Confession like this is therapeutic, I hope you all get something out of this, but if you don't, the therapy so thank you. Seven years ago, I was at (mumbles) for my previous employer, which was a large I had what was up to that point - And then came the anger. Anger at ourselves, because for America's first space disaster. We wrote two more words as mission controllers, Tough meaning we will never again shirk from our responsibilities because for what we do, competent, take anything for granted. We will never stop learning, from now on, the teams and mission Because as a team, we must never fail. - One other thing. We're all in a very fortunate position, we've been very lucky in And I think, as part of the mission, it's also good sometimes to (applause) To make sure that we take this platform and use it towards worthy causes. That's good karma, that's - We understand that that are specific to your organization. Please, email or call your particular event. We look forward to discussing your goals and helping make your event a success.