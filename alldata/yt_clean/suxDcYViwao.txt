- Hello. My name is Martin Doyhenard. I'm a security researcher And today I'm going to present that can be used to obtain in a persistent connection desynchronization vulnerabilities. The agenda for today. First, I'm going to make a quick recap And even though I expect the most of you already know what request smuggling is, I'm still going to make And then we'll also talk about and about one in particular through the same, through for both demos and examples. After this introduction, I'm going to explain what and how to use it for And I will show how to from a persistent connection, and how to obtain reliable Next, I'm going to demonstrate how to concatenate multiple responses and build malicious of the victim's browser. I will demonstrate how of a, of an HTTP proxy, by storing a crafted of any endpoint the attacker wants. Finally, I'll explain and inject arbitrary messages that will be stored in the delivered back to other So, request smuggling is an by Watchfire which abuses the differences and a back end server. These differences are related calculates the body length of our request. And this, the idea is to, the attacker sends a request containing such as content-length or And if the front end calculates using a different header, then it will be possible to split prefix for the next message. Let's see an example of this in which two content-length headers In this example, the proxy will only use the first content-length if multiple headers with And the back end will content-length to calculate the body size. When the attacker sends this request, the front end will forward as it will think that However, when this message only the first five bytes of the body will be considered to The extra 27 bytes will be split and used as the prefix of the next request processed by the back end. If a victim's request arrives it will be concatenated causing the back end to issued a request to when instead it was issued And, as the session cookies the application will But also the response of back to the victim. And if it contained any malicious payloads such as JavaScript, it will be executed on the client's browser as well. But these attacks were as they were thought to be, that they wouldn't be But this changed in 2019, when James Kettle &quot;reborned&quot; this idea by providing a new methodology to, first, detect different then, confirm that it is smuggle our request, and finally, to explore features provided by the web application. What's more, he was able to demonstrate that these techniques could be applied in many real systems, and it was possible to from different vendors. Also in 2019 and 2020, many of these desynchronization variants were presented by researchers. These are techniques the discrepancy between servers by hiding messages in the headers, such as the content-length, In most cases, this is done by placing extra special characters, such as a space or an unprintable letter. And in this way, a server the header name or the value as a valid content-length header. But even though these flaws it is also possible to by using a feature that the HTTP protocol itself. And to understand this technique, first, I'll explain the difference between an end-to-end and a hop-by-hop header. So, end-to-end headers are to travel from the client and forwarded by any proxy in the middle. On the other hand, hop-by-hop travel only to the next node And for this reason, proxies and they should be before being forwarded. And one of the most defined in the HTTP RFC This directive can be used that could be used to the connection between two nodes. And these options must not So again, they should not receiving them. Some of the known collection options are &quot;close&quot; or &quot;keep-alive&quot;, but also the protocol any custom value he wants. And also allows to use as an extra header to give the proxy or the on how to persist the HTTP communication. So let's see an example two connection options. First, the client will declared and then, the two as separated headers. But when a proxy forwards this request, it will remove both the and as well as all the But what if instead of as a connection option, we declare an end-to-end header When the proxy receives the request, it will consider the bodies of 13 bytes, and it will forward it. But before it does, it will as it was declared as a connection option. So when the back-end receives this, it will think that the body is empty and it was split the message. This would cause that the smuggled data is used as the prefix for Now this issue was reported under the Google vulnerability reward program, and Google fixed it, to use it to smuggle requests Now let's see how this can be leveraged to in web applications. First, we could use request smuggling to bypass front-end controls, such as filters to forbidden endpoints. And this can be done by which will not be seen by the proxy, and will be forwarded to the backend. However, this technique does for most resources, and it will fail if the by the attacker, and if the filter is not placed in the vulnerable proxy. Another exploitation technique is hijacking the victim's request, but this can only be done offers some data storage feature. That is, the attacker can if it can be stored or retrieved, which is not that common And also these kind of or in most cases, are only So the attacker would need or a valid session. Next, we can use request existing vulnerabilities, But in this case, the attacker the payload without having And in this case, you will not have to force the, the client to trigger the The same idea could be regrading interaction, but to do this, or to improve these kinds of vulnerabilities, to find another vulnerability, such as the cross-site scripting, because if not, there will And finally, the can be used to perform such as web cache poisoning. And this can be done by for caching a resource, in the backend's request. However, this is only possible to, it's only possible to poison and only if the proxy ignores If this is not the case, then the malicious by the web cache, and Some other techniques But in most cases, it is required that the uncommon features, or have so I'm not going to talk about them. So... (clears throat) By now, all attacks rely the request queue of a However, exploiting these as you would like. There are many (indistinct) of these vulnerabilities. So we would like to But what if instead of we would look at attacks of the connection? With this in mind, I what would happen if instead for the next message, we will smuggle a complete request that will alone produce an extra response. If this happens, the proxy but it will receive two from the backend. And if a victim later sends it will be forwarded, but in this case, the remaining extra response, which corresponds to will be sent back to the victim. And as the victim's response an attacker could then to hijack the form response. And if this response was for example, then the attacker some sensitive information, or any other session token that was intended to the victim. To better understand this requests and responses are and at the backend. First, both the attacker and to the front end. They will be stored in the the backend server through However, when the malicious it will get split, producing And now all three responses, by the attacker and the one will go back to the proxy. Here, the first, the first response would be And the second one, which corresponds to the smuggled message, would However, as the proxy it will wait for a new, for a new message before forward the last response. In this case, if the attacker he will be obtaining, the victim's response, also some sensitive information, such as, as we already said, for example, the session cookies that were, that were created after a login request. But what if instead, these techniques in real, in real systems. We would find that the are not as we expected. And that their reliability can make us think that they So here we can see some, the communication between And in this capture, an desynchronize the response a request was sent, the connection was closed by the proxy. This means that the attack is failing. And the reason for this is that the, the proxy resets the receives an extra response. And therefore we cannot before the proxy creates a new request. And only after a thousand requests, I was able to smuggle a single response, and actually hijack a victim's message. But of course, this is not the So why this is happening? And to understand this, first let's take a look at And to do so, I will explain one concept that was introduced in HTTP 1.1. And in which all the First, remember that the biggest change between HTTP 1.2 or 1.1 is the ability to persist TCP connections and just send multiple through the same connection. This means that the client to close the connection Instead, it could use it increasing the performance of the network. However, this concept with another important by the HTTP protocol, which is the ability to through the same connection. So, HTTP pipelining is what multiple requests without previous responses. This means that if a client needs to send, let's say, two requests, This can be done at the same time, concatenating them And it is the job of the to split them and resolve each, producing the corresponding responses. And as we saw in previous examples, the way each request is depends only on the order they The first response would and this will be done by using the first-in-first-out scheme order. And that's why we will call them request and response queues, because they will actually work as queues. There is no other way of and requests, such as an ID or anything. So the only way to do it where they were issued But here's the catch: Most proxies won't enforce pipelining, meaning that if two or more reach the proxy, they they won't be concatenated together, and they will be, they won't be forwarded Instead, they will be free TCP connections, which And so the attacker won't be able to play with the connection and this will prevent the attack. But also future requests, which in the server, won't go that the attacker used previously. And this is because the by the attacker is received by the proxy, and will be interpreted This is because the any new requests, and so it shouldn't be If this happens, then the a problem in the communication, and will just close the connection. And also, when closing this connection, the extra response that was and so it won't affect So what can an attacker First to hijack our response, smuggle two responses, but they cannot be sent because as we saw in this case, the proxy will close the connection because it will see an extra response. So to avoid this, a new by the proxy, so when the connection is persisted. But these new requests the first response goes back to the proxy. This is because the proxy won't forward any other requests through until the request, until the request queue of this connection is free. So the idea will be to send as this final message, and this request will take and the server would take a response for this request. And this time will be just enough for the next victim's and reach the proxy's request queue. Therefore, when the it would be sent back to the client, and the attacker will now be and hijack the extra is the response that was It's not necessarily that take a lot of time. It is just about knowing that, it's just about knowing this time, and calculate the transmission This will allow an attacker to know the best time between payloads, and the best time that he has to wait before sending the next attack. And, under normal conditions and backend servers, I was able to observe huge improvements. Okay? So I was able to actually see smuggled and the connection And as you can see, the same attack using a different smuggled endpoint will, will give much, much better results. In this case, the connection This means that the for 14 clients. And that is a really, really good number, if we think that before one of a thousand. And so, if we are able to that will produce an extra response, what would stop us from From a technical to smuggle 1, 2, or 10 requests, that would produce 1, 2, And this will be useful for but for now, we can see that that we can, that we can perform and that we can leverage First, it is possible to inject to effectively distribute such as JavaScript using as we already saw. If we send instead of one, many different smuggled requests that will produce this payload, then we will be able to poison the next N amount of clients. Also, nested requests can be used to consume resources from both the backend and the front end server, and as well, requests can produce multiple messages that would need to be This could consume a lot of CPU time. And as the responses must and thus the responses and in some case stored, the memory buffer of the application. But it could also with classic request smuggling technique. And if an application with allows for content reflection, even if this reflected it is possible to also hijack instead of only a response. And this will be done by The first one will be an HTTP which only propose is to just as we, I explained previously. And next, the second smuggled request, will not be completed, and will, will try to reflect that is also concatenated with it. This is done, as in any other by using a content-length the body of the, of the request. So, as always the first to the attacker. And this will allow that arrive to the backend, the proxy won't forward through the TCP connection. After this, the sleeper and the response will be Now, if this last a large content-length, sorry, it would use the victim's request as part of the body, but it was still need more data. And as the connection is empty, and the attacker can that will complete the body, it will cause that the response containing the victim's request is sent back to the attacker. So after seeing this I was kind of excited, but is it possible to also when responses are sent back? Of course, we could as with desync variants, but for this, we would need to control of the response. And that will probably And that's not something However, I also start thinking, is there a difference on is calculated between the And the answer, given The difference is that for the body must always be empty. And these responses are like the 204 and 304, but also responses that are So what makes it so interesting, is that not only they that generated them, be an exact replica of the So when a, when a HEAD the only difference that to the same end point will be that the body will not be there, but the rest of the And this includes, of Even though it is optional it does most real applications. And if it appears, the if the GET response contained a body. Instead, it will contain the same value, and will hope that the proxy is special, and that it that should be ignored, because it's the, it's the But if the proxy fails to was issued from a GET, then what would happen? And of course, the body, in this case, the content-length in and it will indicate our own value because the HEAD response will contain header with a different value than zero. A desynchronization will cause are not properly matched by the proxy. It would be possible to to generate a malicious response. This will contain a content-length header, which in this case will the actual size of the body. If an attacker smuggles two the first response generating, will generate the carried message, which, generated by the carried Next, another request and it will be forwarded to the backend. Now the back end will send it, will send the first response, which in this case will When this message is it won't be forwarded right away. This is because the content-length header states that the body is not empty. And the request matching this, this response contains the GET method and not the HEAD method. This means that if the body, if the body of the response was empty, but the content-length then the proxy will wait and then forward this response. So when the next response it will be used as part of the This will now be delivered which is the, which And also the remaining sent back to the next But that's only if the a valid HTTP message, To understand these ideas, let's see how the different HTTP messages travel through the connection. First the attacker would send which will forward it There, the message will and the first response will as always. After this, the victim in this case, a GET request, except for the HEAD one. Their request will also be And when the smuggled they will be concatenated together and sent back to the victim. If the remaining of the split response are not a valid response, then the connection would be closed, and the response will be And that is because the proxy there was a communication error. But why it could be useful to concatenate multiple responses? We were already able to and the responses that So anything that we can concatenate, we could also have sent And is that right? Well, not really. And this is because we, when we concatenate two responses, one of them will have its of the previous message. This means that if the data which is something rather let's think of a redirect allow an attacker to reflect some data in the headers of their response. Then an attacker would in the body of the request, And if the headers contain directive, such as the text/html, then this reflected content in the headers will now be And this could allow let's say, a malicious JavaScript payload, or any HTML attack that he desires. And of course this will be And the same applies for in a non-scriptable content-length, So if we are able to let's say, the plain text type, then we can convert this to different headers to, to, to change the behavior And of course, this effect can be combined with other techniques to reflect other requests and responses So now we will see a demo. I was able to prove all these techniques in three major vendors, but unfortunately, they were not able to fix the issues at the time of this presentation. So to solve this problem, I using a (indistinct) and the nginx last version In this case, the (indistinct) HTTP parser is vulnerable to the desync variant that I explained previously, so it will be possible to connection header to First, we can see that the three endpoints, all with The paths are /home, /helloSmuggle, and also any other path we, with any other string will be used to redirect to the homepage. Again, Here, in the, we can see this in the If I send the helloSmuggle we can see that the response written as zero, and a content-type header saying that the body should be The same header will, with the, sorry, the same healers with the if a HEAD request is sent. And just as expected by Also, we can see that the feature (indistinct) in the location header. This will be used to place and hijack the victim's browser. So now, using Turbo great contribution from James Kettle, I will smuggle the concatenated response, which will be sent back to the victim. Also consider that this the same features found in and so this applies to, to many, to many real systems that in almost any, any company. You can see that once all following victim's requests obtain the malicious response. And only when any request this JavaScript will be executed, and this will happen every for anything in the, in the system. But finally, if the attacks stop, if the attacker stops sending then the desynchronization will conclude, and the user will see that the application works as expected. Still, this attack gets even worse when a web cache is available. Remember that the, that request smuggling could be used to poison certain endpoints with other existing responses? Well, with response smuggling, An attacker would be able to and the responses that can be used to, to poison these endpoint that the HEAD response contains which will cause that the message And, as the attacker can send it is possible to poison the which will be split also by the proxy. And this will cause that the with the response of the smuggled message. As an example, let's see smuggles a HEAD cache, cacheable request. As you saw, the proxy will back to the attacker. Next, it will concatenate or the HEAD response with that will tell the web with the second smuggled response, in this case, containing And finally, the next request, which was also issued by the attacker, will be responded, this time which will force the for the future requests. So, when a client request, so, when a client requests that the attacker specified, the malicious response will be sent back without the need of any stored in the cache for Again, I believe it will help to see this in the following diagram. As I said, the attacker will one containing the smuggled payload, and the other specifying the This can be any endpoint even non-existent endpoints will work. The request will get split by the proxy and forwarded to the backend server. And as you can see, the from the source, so this will work, even if pipelining is not In this case, the request in the same connection, the only difference is that but not concatenated. Now the backend server will, again, split the messages and produce that will, that are Here, both responses will but sorry, the, yeah, both responses will but the second one will for the endpoint indicated in So the second request that the will be used to store of the response. This way, when a victim issues a request for the same endpoint that the proxy will find a match and it will return the stored the malicious payload with the JavaScript will be sent back to the, to the victim, that the attacker injected. Remember that this technique can be used every time a web cache exists, as there are no extra requirements. Even if the cache-control there will be at least to start poisoning the cache And that is if the, if there is a web cache of the communication chain. And the same thing can into storing their own And if their response contain sensitive, sensitive victim's data, it will be placed in the cache, and later, an attacker can access it that the victim requests. This is known as web cache deception, and in this case, it can dynamic responses, such from login requests. They will contain among any other data, data such as session that the victim will So again, in this case, to store anything, and it cache deception attack, because the dynamic information can be stored. Now for the second demo, I will use the same lab but this time with a new In this case, it will also And this will be As you can see, this is but in this case, the cache-control header is used to indicate that should be stored by the web cache. In this attack, I will attempt to poison the /helloSmuggler endpoint using the same redirect in the body of the HEAD response, as we already saw in the previous example. However, this time, the the cache directive and will gets stored for any endpoint The same connection desync to smuggle the response, and also our request for will be placed pipelined So the second request that the last request that we the request that will be poisoned. When these, once this request is sent, the /helloSmuggler and all following requests containing the JavaScript This will cause that their to open an error message, and on any end point the attacker wants. So the same test is performed and again, the URL gets poisoned, and every time a victim the JavaScript will be retrieved opening an alert box, and that the attack was successful. Finally, the last exploitation technique involves using the remaining as another extra message in the response queue. Exploiting these behaviors exploiting HTTP response such as those obtained from and in those cases, an attacker using some reflection in the header name or in the header value, which will allow the attacker to control the boundaries of the headers. In this case, the idea the HEAD message to split the response, which contains reflected data in this body and in these headers. In this reflected data, to include line break characters to build a valid HTP response. This behavior is not that rare in, in reflected data is inside the body, as there is vulnerability This is not true for line in the headers. So that's why it's so rare and that's why it's so rare to find HTTP response split vulnerabilities. So again, the first non-standard response will go back to the attacker, And then the following will be forwarded through The backend will send back and they will be which will forward the which issued the last request. And then, as in the case, as in this case, the remaining bytes are a valid HTTP response. They will be forwarded which sends a request to the proxy. And this case, if the attacker was able to reflect the line break, to set any arbitrary response, controlling both the headers and the body of the message. However, this attack is because it requires that the proxy either stores the response, or that the pipeline, or pipelining is allowed, if no web cache is available. So that's why it's hard to, of attacks, or this kind of techniques, and why is not that HTTP response splitting vulnerabilities. So, some conclusions to finish. First, we can say that that response smuggling does not rely on extra vulnerabilities or This is because most of the requirements for the explained techniques that the HTTP protocol offers. What's more, almost no exploration, no exploration phase is required, and attacks presented only with few static endpoints, such as the one we, I Also, using response smuggling will allow an attacker to hijack both requests and responses, in all cases, fully compromising the Next, using nested injections, and arbitrary cache poison, it will be possible to (indistinct) users taking valid responses either by affecting the or by storing malicious payloads, What's more, response as well as classic request to modify or control a of a persistent connection. This completely compromises the integrity of the connection queue, and And also client process can be controlled using arbitrary JavaScript is possible, or when the web And finally, with a detailed analysis of the transmission and processing time, is it possible to increase and obtain these results with So all this should be once and for all understand that a desynchronization should be seen as one of the or the most critical web vulnerabilities, that a system can have. Now, I will answer any and you can also send me any question or doubt that you have, or if you would like to you can do it through my email or through my Twitter account. Thank you.