If you haven't stayed up three nights existential crisis about it, you probably It is a weird thing. What's it mean to be human? What's it mean What will my kids do? What does it mean stuff? Is this real or is it an illusion? Nobody actually knows where AI is heading But, we shouldn't feel like we don't have and leaders, you get to make these choices increase human flourishing. As individuals, we get to decide how to be AI is here to stay. That is something that want to handle, and to learn to work with, and to just be scared of. I'm Ethan Mollick, a professor at the Pennsylvania where I study innovation, intelligence. I'm the author of the book Co-Intelligence: Living and Working with AI. Artificial intelligence is Basically, AI is a very For a long time, that was about numerical algorithms of math so that Netflix could could figure out where to site its next use data to make sure its cars were The thing that these systems were bad at So if your sentence ended with the word filing your taxes or filing your nails. What happened that was different was the In 2017, a Need&quot; outlined a new kind of AI called the basically let the AI pay attention to not the entire context of the sentence, the Large language models work by taking huge on the internet. There's a lot of Harry that's what the internet contains. And based on all of this data, the AI goes this is that really expensive part that And during that time, the AI learns the words called tokens. So it learns that that &quot;hawk&quot; and &quot;potato&quot; are not closely dimensions in a multidimensional space we predictions. But it turns out, unexpectedly, when large language models get big enough, didn't expect. We didn't expect them to be good at beat doctors under many circumstances. We didn't expect them to be good at than most humans can. And so they're things. Interestingly, &quot;GPT&quot; doesn't just stand for the &quot;GPT&quot; in &quot;ChatGPT&quot;. technology,&quot; which is one of these once in a Things like steam power or the internet that change everything they touch. They alter how we relate to each other in ways So you can't think in certainties. You four scenarios in the future. The first is which is that the world is static, that think that's unlikely. In fact, whatever ever going to use. Even if the core large language model another ten years of just making it work that'll continue to be disruptive. So I isn't static. It's evolving. So I want to skip actually to the last three. So scenario four is AGI, artificial that a machine will be smarter than a explicit goal of OpenAI. They want to And there's a lot of debate about what than a human and it can do all humans' Then we have artificial superintelligence, ASI, and humans become obsolete overnight. about this, and I think it's worth because other people are. But I think that that scenario tends to something that happens to us. And I think what I call scenarios two and three, which is continued linear or We don't know how good AI is going to capability is about every five to nine doubling time. Moore's Law, which is the going, doubles the power of computer six months. So this is a very fast rate It's very likely that AIs will continue to and now is a good time for you to start to makes you human or good at things, and what want to start handing off more to the AI. We have a lot of early evidence that this there's now multiple studies across fields to legal to marketing to programming suggesting twenty to eighty percent tasks for people who use AI versus don't. The problem with being human is that we're and a lot of decisions that are bad result AI is very good and a cheap way of to listen to its advice, but getting its for a moment, forcing you to think and the license to actually be really creative So you can ask it to create crazy way to solve this problem? What's the most is the worst idea about how to do this? worse? It can be very unnerving to realize that think of it as a very human trait. But I help us be more creative, that actually is creatively, and having a partner who can often feel liberating. One of the weird things about large language models LLMs are very bad at math. Computers are weirdly emotional and can threaten you so it can be very hard to know in advance nobody actually knows the answer. We call that there's almost a spiky shape to what part of what you need to do is understand know when the AI is likely to lie to you &quot;Hallucination&quot; refers to the idea that what the AI produces could be entirely made up, plausible The thing about AI is, though, everything it there. You might start to become more biases. You might think it's more capable like a psychic. It's really good at that it's accurate so often is kind of And hallucination rates have been dropping sharpen your own intuition with working something that might make you concerned. When you ask people about the future of insiders called &quot;p(doom),&quot; which is your not have a p(doom) that I really think probability to things going wrong. agent. We get to decide how this thing is used. And if we think about this the right way, this frees us from boredom and But I think we need to think about the technologies, you know, and what the internet versus social media. There are personal about how we use it at an at a societal level. And it's not an does. It does what it does because society