Computer problems are a fact of life and Sometimes the fix is as simple as just turning it off and turning it back on again But other times it's not and when the system you're talking about is running an air traffic control system Controlling a bunch of ATMs or say routing 9-1-1 calls keeping them up and running can be a matter of life and death Now the stakes aren't nearly as high for us but this server here runs multiple apps that we rely on every day accelerates our game downloads with Steam caching and It runs our DNS if that service goes down it breaks literally everyone in the company's internet Which my boss informs me, isn't great. So how do we make it more reliable? It's already a server We build more servers and what's really cool about this is everything We're about to show you courtesy of Intel who sponsored this video and sent over their new Emerald Rapid Xeon CPUs can be done on Nearly any computer even your dad's old Dell that is as long as you have more than one So if one leaves for cigarettes, we can still play catch More than one Dell not more than one dad. Oh Well, anyways, I'm done. You want to check this out? Yeah, let's have a look You got your lovely cat picture your crab rave on that computer. Mm-hmm. Watch this like I can yeah, I can interact with this Let's just give it a second. Okay, that's it's going Now it's on this computer and like no bamboozle here. Look watch. Whoa, watch watch watch boom unplugged I can just completely interact with this as I normally would so what's going on here? What you guys just saw was the programs, the lovely drawing, the entire operating system Just teleporting from the computer over here to the one over here. No trickery. This is possible. Thanks to the magic of Virtualization we've talked about it before but if you're not familiar Virtualization allows you to slice up a single machine into multiple less powerful Virtual machines and this setup leverages that technology to allow us to move these virtual machines between multiple Physical computers that way if one breaks another one can immediately take its place and the best part is that while this all sounds super Fancy all the software we're using is both open source and free and we're gonna show you guys how the setup works in a little bit First, I want to take a look at the servers We're gonna be using for our setup gigabyte sent over four of their R163-SG2-AAC1 servers These are barebones So we're gonna have to add a few of our own parts, but we should be able to build this in what like five minutes I'd like to see you try this guy. We're gonna add some of our own parts starting with a pair of Patriot 480 gig SATA SSDs that will function as a mirrored boot drive this kind of per machine redundancy isn't strictly speaking necessary because We could lose an entire machine in our configuration without having any issues But having them in pairs makes our lives easier in the future potentially since if one of them fails We can just replace it and then rebuild it from the other one. Then on the other side of the machine We're installing two of these Keoxia CD6 7 terabyte drives for fast bulk storage That leaves us six more SATA bays to do nothing with and two more NVMe bays for potential future expansion Moving back. Let's get our CPU installed. We're using a Xeon Platinum 8562Y+ in each node These were graciously provided by Intel and with 32 cores 64 threads and 4.1 gigahertz max turbo clock speeds These are gonna give us a ton of compute to share between our virtual machines all at a modest 300 watt TDP We're gonna have it and the rest of the parts linked in the video description now I've never installed in this socket before so Good luck me step one is to install the carrier on the CPU and you can tell which one of the three you're supposed to little marking right there on the CPU IHS line up our little golden triangle with our Gigantic gargantuan hole in the whole thing triangle. Oh, this is adorable It's got a cute little arm so you can break the thermal paste seal with the cooler so you can get the cooler in the CPU separated more easily, love to see it speaking of thermal paste. We're gonna be using a Honeywell PTM 7950 pad available at LTT store.com This stuff is absolutely perfect for a server install because it lasts not forever But for a very very long time without maintenance now, you might think okay, go ahead put it onto the CPU socket You'd be wrong instead. I'm going to install it onto the cooler I'm gonna know how to do that in a sec. So arrow and arrow so maybe Hey, there we go Love me a vapor chamber Okay, we're gonna make sure all these are clicked into place look for our little arrow here line that up with the arrow on the socket Make sure that the locks are in their unlocked position then you should be able to just That's it's locked. Oh, that's it. Okay next comes something you don't see me do very often and that is use a screwdriver other than the LTT screwdriver and that's because these need to be Torqued to a specific value that is 6.9 inch pounds Nice, it's so cool to think that if I was doing this, you know performing maintenance on the server Upgrading a bad RAM stick our entire operation could be chugging along as if nothing happened Speaking of RAM. We've gone with four 96 gig micron 5600 megatransfer per second registered ECC dims That's a somewhat unconventional choice because especially in a server giving up half of the memory channels means that we will be giving up some performance, but We don't really need all of the performance for now and 384 gigs is a ton of capacity for our needs at the moment And of course if anything changes we can always add more without any downtime to our services The only thing that's really important here then is making sure that we install our sticks in the correct slots Which is not always super intuitive. So make sure to consult your manual. We don't need a GPU for now Though we could add one in the future so that means all that's really left is these NVIDIA ConnectX-6 cards now 100 gig networking might seem a bit overkill but because our setup uses high-speed drives in four servers and We want to be able to withstand two server failures. Anytime we're writing data. It has to be simultaneously written to the drives on at least Three machines that ensures we have three up-to-date copies in the event of an unexpected failure Now if you were doing this at home, you obviously wouldn't want to spend this kind of money But the good news is that you can do this with as few as two machines And if you're not trying to run a high speed caching server for a hundred people 10 or 25 gig cards are available for a fraction of the price and you can connect them directly to each other without an Expensive switch. I mean even one gig could work for light applications like ensuring that your home automation system never goes down Enough chit-chat though Let's get on with the demo and show you what happens if one of these things goes to heaven in a live environment but not before we get them in the rack and set up specifically here in the lab server room because if you didn't notice earlier the Studio server room is kind of running out of space at least until these machines are up and running and we can take the machine They're replacing out. Let's go grab the servers Fortunately, the rest of the machines are now magically built off of camera and we can just slide them in what the hell is going on Oh, there we go. Beautiful. These gigabyte chassis come with nice tool-less rails. So installing these in our nice ginormous Hammond rack should be pretty easy It's getting close I can taste it We just need networking like we mentioned before a hundred gig But what we didn't mention before is that each is getting two of them Specifically one to each of the network switches in the rack that way if one of those switches has a problem The servers will stay up and we even get an added bonus because some fancy Dell magic called VLT We get the throughput of both of these cables. So 200 gig to each servers pretty sick All that's left then is power and like any other good server IPMI Which is a management interface and allows us to control the machines, even if they're not working They have like a hardware problem. You can still access them. We can turn them on turn them off It's kind of magic if you have a server that doesn't have IPMI I don't even know if that's a server really There are two main elements to making this setup work clustering the hypervisor which controls our virtual machines and clustering the storage Which you can skip if you have existing network storage you want to use instead If you're not interested in how to set this up You can skip ahead to here to see what it's like when it's up and running This isn't gonna be a perfect step-by-step guide But with the documentation you could find down in the description, you should be able to replicate this setup pretty easily Starting with networking We added both of our hundred gig ports to a bond Created a bridge and then added a VLAN for three different networks, one for our VMs to use one for cluster communication and one For the storage. They can all technically run on the same network But the cluster needs low latency and the storage ideally uses jumbo frames. So splitting it up like this is best practice You'll also need to add each nodes cluster network IP address to the host file on each node With the networking up and running enabled the no subscription repo and disable the enterprise repo It's not recommended by the Proxmox team for production They want you to pay for the enterprise repo which is a bit more stable But the free one is totally fine for a home setup run any pending updates before proceeding then make sure you have a reliable and ideally local time server configured on each of your Individual servers as the clustering software wants the time very closely in sync to stay happy With that out of the way We can set up our cluster which handles syncing the configuration and management of any virtual machines between our physical machines and it also orchestrates Migrating or restoring them when a machine goes down Creating the cluster just takes actually a few clicks But you might want to consider the size of your setup before you continue That's because in order to make sure everything stays in sync in case of an issue with a machine You need the majority of servers online and available to be able to say hey I see that one's offline, but you know, we're still good They call this quorum if you have an even number of machines Let's say four like we do and each server gets the default single say or vote The minimum possible majority is then three servers So that means we can only withstand one going down which is the same amount of redundancy you'd get if you had three machines because You can only lose one to have two if you only have two computers Then you only ever have a majority when both are online, which obviously doesn't work That's not safe But you can screw it around this by adding a third machine like say a raspberry pi to be a tiebreaker But that's kind of beyond the scope of this video Once you're ready select the cluster network in the creation menu and then join the other machines to the cluster once they're in you should Be able to see them in the web GUI of any of the machines. Now on to clustering our storage by default Proxmox is very heavily integrated with Ceph an open-source distributed storage system That's pretty easy to set up and maintain with that in mind newbies should start with Ceph and you can follow the great tutorial on Their wiki, but it isn't the most performant in a small cluster like this So we're gonna be using something called LinStore with drbd or distributed replicated block devices another open-source storage system It requires a bit more manual configuration But they do have a purpose-built tutorial for Proxmox and host the files for free with an optional paid Enterprise version that operates on a similar model as Proxmox itself. Unlike Ceph. It doesn't handle its own storage devices So we mirrored our two Keoxia SSDs with ZFS first and then pointed LinStore to that once it's installed and configured Then you can add the clustered storage to Proxmox Create a virtual machine with that storage and it'll automatically be replicated in real time to the number of other nodes you specify and if You happen to migrate a VM to a server that doesn't have a copy on it It'll automatically stream the data over the network from one of those nodes in what they call diskless mode, but let's just try it Pretty nice right? Looking good. It's like even cable managed. I know right? So 200 gig on each of them nice Who are you people and what have you done with our infra team? I made one small adjustment just for you Look at the drives. They're in the same spot. No, they're not the top one's different I hate you so much. Why would you do that? But more importantly does it work? Yeah, obviously. Okay. Well, here's your Windows desktop. Obviously. He says what editor a Supercut of things not working here, please Jake. We have a leak. Oh god one failure You just downgraded my Wi-Fi. Four drives aren't working? Did you actually break it? Anyways, you see our windows, right? Yeah, our windows is running right now on number four, which is the bottom server Yes, now obviously remoting into the machine over Wi-Fi Okay, the video playback is a little bit choppy. That's not gonna affect the type of workload we would normally be running on something like this like a DNS server or like Are we finally doing Active Directory? We will, not not today not today But can now but this is the kind of setup that you want for something like AD. Live playing the video Let's migrate to number one which is the top one The process will be a little bit faster, but basically what it's doing is Copying the memory like the RAM what's actually in memory and then once it's done most of it It pauses the operating system for a split second copies the last tiny little bit and boom that is so cool You're exactly where you were before because the storage is already there, right? So in terms of actual downtime like interruption to that experience 17 seconds No, 270 milliseconds. Oh, I thought you were pointing the other 17 seconds. Is that whole process? Oh, yeah. Yeah. Well, that's kind of downtime No, cuz that if there was somebody using this like as a virtual desktop for instance They would see like a quarter of a second blink and otherwise like nothing changed. I wanted to show a more Realistic to us demo. Sure. Come hither. Here's a plex server We've got some videos on it. And this is on server number one. Okay, let's play a video Now we go and move our plex server to a different machine So it's copying the RAM at 2.5 gigabytes a second. So it's like 2.8 gigabytes a second. That's pretty good We haven't done any actual to oh, it's already done and no Interruption because video playback like many other applications uses buffers to hide small interruptions in the service in this case Downloading the video in small chunks a little bit at a time. Yeah, roughly 10 second chunks It looks like here which is plenty to cover That 146 milliseconds of downtime You want to try a steam download with Lan cache? I mean you should yeah, why not? Yep, we're CPU bottlenecks for sure, using, you know 80 to 90 percent of a 24 core thread Ripper But I realized I made a little bit of an oopsie here. I look you can see the CPU usage We're using 4% of our 8 CPUs that I assigned to this steam cache. We can see our network traffic's going up sick Except I made this as a container not a VM and the thing with containers. They're great They're a little bit lighter weight better performance, but they run within the kernel of the main system It'll shut down that container and then just reboot on the other machine, right? Which means it's fine, but there'll be a longer downtime delay, but way less than Hey is that thing working? Oh, I think the Internet's not working. Somebody should go look at that Yeah, trying to figure out what's going on fixing the machine getting the machine back going so cool You're talking about the matter of a couple minutes maybe. yeah now for the most impressive demo yet the Unexpected migration, which one am I yanking? Okay. So number one has three VMs on it. They're all in the high availability Jake's chain Ahh! What? Means teasing you. Oh I Get it Okay, sorry, which one I wasn't even listening to you. Number one! Number one. And we'll see how how fast it does. We're looking at server one from server two. So go for it From my understanding this process takes a minute or two Okay to go. Let's already detected the node is offline. Sure is. If you're doing scheduled maintenance You can actually go and just shut off a machine and then it will just be like, oh crap I need to move all those things before I shut off which is a little bit nicer in this case It has to be like sure the server is down So all three of those are yelling at what was this say? Hello? What happened? Are you alive? What's going on? I can hear them Hello, what happened? Are you alive? What's going on? Oh, oh, it's something so in theory it should Distribute them evenly because that's the option that's set right now. Right in terms of its workload. You mean? Yeah, there is also a mode that does like resource checking sure But right now it's going how many VMs are in each one and just like feeling that number. So it's even. That is so cool. Okay, so what service was running on that one was that the steam cache so we should go download a game You can do go to Plex right now. Let's go do it. Let's go to it. Come on. Let's go. Wait, we could take this door and No movie magic What but also magic virtualization magic? This is flipping awesome And it's gonna be an absolute game changer for the way that we manage our infrastructure and like I said at the beginning I think the coolest thing about it is that this type of architecture doesn't even have to run on the kind of Emerald Rapids latest server technology that Intel and Gigabyte and Micron and NVIDIA all sent over here So the takeaway for you guys is whether it's for work or whether it's just for your home automation or your Plex server at home Something like this is absolutely attainable with potentially very little financial outlay I go buy some used like 8th gen Intel core processors. Those are pretty cheap some cheap DDR 4 and You're off to the races or if you're doing this more properly for your business check out Intel Emerald Rapids and their whole line of Xeon and GPU products down below Where were you pointing down below? That's the description Get your mind out of the description