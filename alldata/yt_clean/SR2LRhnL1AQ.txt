Intro In this video, I want to share the updated between Rust and Zig. I got a lot of tips as well as a couple of PRs, I'll quickly go over the optimization again with the optimized code. I used the same So in this video, we'll compare Rust with I'll use the Actix HTTP framework for Rust I got a Pull Request from a Zig expert with And as always I'll generate enough load to Actix (Rust) Overview based on a previous benchmark I ran between the and Rocket. Actix had the lowest latency Zap (Zig) Overview written in Zig. It's essentially a wrapper benchmark results, it should outperform I didn't compile the application with few minutes after I released the benchmark, I Zig has four build modes. The first is Debug mode, which is the default and is applied this. This default mode is what I used in application was so slow. The other modes are ReleaseFast prioritizes performance and safety and keeps all safety checks. Finally, You can read more about building your Zig apply on this page. I also got another pull request from a Zig server using the same endpoints. Based on local almost 200,000 requests per second. This test was The only difference I made was compiling performance over size. If you're interested in this PR. To run this test, I used a production-ready one with xlarge instances to run 4xlarge instances to run the clients that available in my public GitHub Alright, let's go ahead and deploy in AWS and let them run for about Let's take a look at CPU usage. Rust that the pure Zig implementation's CPU cAdvisor show 0% usage. Sometimes, they On the other hand, we have memory usage. Let's take a closer look at the kilobytes, Zap uses 22 megabytes, and the kilobytes. While this doesn't really mean much, Alright, let me go ahead and deploy some load. I have 20 pods for each the number of virtual clients will increase will probably reach around 4,000 virtual For the first couple of minutes, you can At the beginning of the test, you can while Zig and Zap stay close to each other. more CPU at the beginning. For this test, I megabytes of memory, with each application Once in a while, you might which is the ratio of successful requests multiplied by 100. Since the average request client timeout to 200 milliseconds. So, when which is reflected in the availability graph. By around 50,000 requests per second, you start applications. In terms of latency, we have the then Rust. CPU usage follows a similar pattern. Occasionally, some clients will experience only a few requests fail, which doesn't At around 75,000 requests per second, the and its latency increases. This of requests the pure Zig application At around 81,000 requests per second, it becomes behind, so I'll remove it from the graph at this Now, I'll keep only Zap and Actix on the you might remember that the Zap application, handle around 83,000 requests per second. Let's As we reach 100,000 requests per second, and availability. I wouldn't recommend running instead, you should scale them horizontally and set an autoscaling threshold, But for now, we're trying to find out which application can handle more requests By the way, you can still see the values for the graph. You can even see that Kubernetes is heavily 125,000 requests per second, which is the maximum Let's continue the test for a few more minutes. Alright, I got pretty much the same results for processing around 160,000 requests handled around 127,000 requests per Now, let me open each graph for the entire test First, we have the requests per second. If you can processes more requests with lower latency, Next, we have client latency. Let me also show the latency before Next is CPU usage for each application. Here's the memory usage. Availability graph. And finally, we have CPU If you can improve any of these applications, please create a pull request. Also, let other benchmarks on my channel. Thank you for