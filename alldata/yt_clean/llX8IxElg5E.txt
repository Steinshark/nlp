As we consider what Strawberry means for the AI world, it's natural to evoke analogies to Move 37, the famous move in the second game of AlphaGo versus Lee Sedol. That was a famous, surprising and very unconventional move, placing a stone at the fifth line on the board, which was rarely seen in professional play, especially in high stakes games. Top human players would normally avoid such a move because they'd consider it too risky and inefficient early in the game. Even AlphaGo itself calculated that such a move had only a 1 in 10,000 chance of being played by an expert player. Normally, Lee Sedol needed only 1 or 2 minutes to consider each move he made, but this time he was baffled. As you can see from the look on his face when this move happened, it took him more than 12 minutes to think about what to do next. And along with Lee, professional Go players and commentators alike were stunned. Some even thought that maybe AlphaGo had made a mistake. But to the contrary, although Sedol had been ahead prior to Move 37, that gambit shifted the advantage in the game, setting the stage for a second consecutive victory by AlphaGo in the best-of-five match. Later, Fan Hui was quoted as saying, "It's not a human move. I've never seen a human play this move. So beautiful, beautiful, beautiful." In short, Move 37 was an iconic moment in AI history, implying that artificial intelligence might indeed be capable of achieving extraordinary things beyond mere probabilistic models built on training data, albeit data consisting of 30 million moves. It was a moment when the world saw AI do something that looked a lot like reasoning or strategy. That was 2016. Now fast forward. Sequoia Capital has just published a very thought-provoking assessment of the AI market today, with special focus on emerging reasoning capabilities and how those abilities may likely play out for stakeholders and investors alike. Here's the paper, written by Sonya Huang and Pat Grady, who are both partners there. I'll leave a link to this for you in the Comments. For this discussion, I'll also be referencing this recent article from OpenAI, which I'll link to as well. This one provides details about a notable model that's been mysteriously described until now as Strawberry, and also as Q* and which now has emerged from stealth mode with the much less mysterious-sounding name of o1 and which, as we'll see, has remarkable reasoning capabilities. Despite the rather plain sounding new name, there's still an element of mystery here. The actual approach used by OpenAI is a closely guarded secret, but at a high level, we can say that this model uses chain of thought reasoning coupled with reinforcement learning, which is something I've described in a couple of previous videos. Basically, this approach breaks down a request into a series of smaller questions or statements, and then strings those together. It turns out that this approach greatly improves model performance, and in the particular case of o1, it's starting to look a lot like how smart people actually solve hard problems. Let's bring that to life with an example from the OpenAI paper. Here's the prompt. We can see that apparently something's been encrypted and a sample's been provided that appears to be the decoded version of the message. Using that example as a basis for cracking the code, the model's being asked to decode the second block of text. Obviously, this is not something that a basic LLM is designed to do at all, no matter how large the corpus of text may be that it was trained on. And here's the result in GPT-4o It summarizes the question. It knows that it should follow a step-by-step process to solve this. It indicates that word division is an aspect of the problem. It reiterates the original divisions it was given in the text that it's been asked to decode, and then it fails to solve the problem. This is like the moment when Multivac says "Insufficient data for meaningful answer" in the famous story by Isaac Asimov. So how would you or I solve this? Well, first it looks like we have four words in both the encoded and the decoded text. Can it be so simple as a one-to-one mapping from one of those to the other somehow? Clearly, each word in the encrypted version is longer than the decoded output. Is there a pattern? Wow, there sure is. Each encrypted word is exactly double in length of the decoded word, assuming that they really do map. Okay, so here's the alphabet with each position numbered 1 to 26. Okay, let's take a look at the first two letters of the first word. Based on alphabet position. 'oy' is 15 + 25. That's 40. What's "t" ? that's 20 Hmm. That's exactly half. Can it be that simple? Let's check the next two letters "fj" is 6 + 10 which is 16. An "h" is 8. Half again. Looks like we might have something here. Now, over to OpenAI-o1. Here's that response as compared to GPT-4o. It found the key to decipher the code! So what's the decoded output secret message? There are three r's in strawberry. By the way, do you see how this reasoning process we just went through is at least one full step removed from the way LLMs work, which is based on similarity between word embeddings? That's pretty interesting. Clearly o1 is capable of something remarkable, and the OpenAI paper goes on to give other examples of o1 as applied to computer programing, chemistry, physics solving math problems, and several other domains. Now, what does this mean for business, investing and strategic planning? To answer that question, let's look at how LLM models improve as a function of training time. On a log scale, it looks like there's still ample opportunity to build even more powerful models than o1 as you can see here. it doesn't look like the top of an S-curve to me, but there's now a new dimension. It turns out that the longer this type of model is able to consider its solution, the higher the performance, and that's even more pronounced, as you can see here. And that one also doesn't look like it's topped out. Far from it. Comparing the two side by side, it looks like there's still plenty of upside on both factors, but it's this green one on the left that's new, and that potentially changes the game in new ways. The technical term for the one on the left is inference time compute. Whereas the one on the right is the familiar pre-training compute. The Sequoia paper asserts that the latent power available from inference-time compute will drive us toward a world that enables massive inference clouds that would need to be able to scale dynamically based on the complexity of the task. So where are the best opportunities to create sustainable competitive advantage based on that? Here's the Sequoia view. They ask: Imagine you want to start a business in AI. What layer of the stack should you target? Good question. Breaking that down, they then ask: Do you want to compete on infra? Good luck beating NVIDIA and the hyperscalers. Do you want to compete on the model? Good luck beating OpenAI and Mark Zuckerberg. With the constant leapfrogging we've seen for state-of-the-art capabilities, They likened that domain to a knife fight with price per token for GPT-4 coming down 98% since the last Dev Day. Next they ask: Do you want to compete on apps? Good luck beating corporate IT and global systems integrators. Oh wait, that actually sounds pretty doable. That's a good one guys! In short, the investment premise is that an important new AI frontier has emerged with considerable value available to be unlocked by founders who focus on applications that can deliver moments like Move 37, suggesting solutions that are not simply buried somewhere inside an avalanche of training data. So this creates a paradigm shift. What seemed trivial before now seems positioned to unlock enormous value. As the authors state: Two years ago, many application layer companies were derided as "just a wrapper on top of GPT-3." Today, those wrappers turn out to be one of the only sound methods to build enduring value. What began as wrappers have evolved into cognitive architectures. This premise further states that there's an unmet need in the market for applications that deliver domain-specific reasoning, beyond what a general model can do. Following this, the authors take us step-by-step to a conclusion that the primary opportunity for startups is not to replace incumbent software companies. It's to go after automatable pools of work. Interesting. Let's bring that idea to life as well. Here's the brand page for one of the examples cited in the Sequoia paper, which is a company they invested in, obviously. XBOW is an AI-powered pen tester that does penetration testing to simulate a cyber attack on a computer system. The idea is that human pen testers are highly skilled but very expensive, which limits the size of the market. But apparently XBOW is able to match the performance of top pen testers, which reduces the cost of that service dramatically, which greatly multiplies the size of the market by opening the door to continuous pen testing by companies of all sizes. So this is an example of what we're talking about. Here's how Sequoia looks at this. By analogy, they point out that the software market in 2010 was 350 billion, and the cloud market had 2% of that back then. By this year, that market has grown to 650 billion, and the cloud portion has grown to 62% of that, growing from 6 billion to $400 billion. In fact, cloud was a key driver in the overall growth. Now think about XBOW again. They're not taking share from software companies. Those were human services they replaced, but so expensive that the market was small. So Sequoia is saying that the new pie is the combined software and services market, which is $10 trillion dollars, of which, at 3 billion currently, AI has far less than 1%. Imagine the avalanche of change, risk and opportunity that stretches out before us today. It's not wrong to think carefully about the risks that this creates for numerous business models, and even for entire geographies, especially those where a key component of GDP comes from outsourcing services to more developed markets at offshore rates. But to close things out on a high note, here's how Sequoia thinks about the opportunity side of this. Here's their list of companies that created $1 billion or more in revenue in each of the past two waves of innovation. And here's the blank canvas that waits to be painted with new logos in the age of agentic AI. Maybe your logo or mine. For this, the XBOW example is worth a thousand words. Thinking carefully about offerings like that one will surely help us to point our arrow in the right direction as we invest our money and our talents in this new age of agentic AI. Meanwhile, thanks for watching and see you next time.