Welcome to this After an extremely successful complete DevSecOps bootcamp, which so many of you in and so many companies to upskill their engineers. After seeing this immense I wanted to create a DevSecOps to get an idea of what that is, to get a basic understanding DevSecOps tools, and get their very first hands practical implementation So in this crash course, we're going to go through of what DevSecOps is, as well as see some hands So you get an understanding And then if it spikes you can decide if you want a full DevSecOps bootcamp demanded skill set way ahead in your career. Security is important at all levels of software development lifecycle. the application's and underlying infrastructure, which could be on premise And it's important to the level to properly secure things or some data gets leaked, Where their user data or company or their systems get attacked the price they pay expensive than actually And it's expensive, both financially but also that means all companies However, it is pretty difficult biggest challenges companies of security and what may be to actually implement First of all, often feature development is more incentivized in customers. That's what provides the direct And very simply, that's what brings in money So security is like You don't get so much for implementing great security. But if a security you get real punishment. So security stays in application development infrastructure configuration The second issue is, even if you and your to implementing great security, you still have a challenge systems themselves are becoming Think about the modern In our application systems, we have a large application that is running cluster on cloud platform, using tons of different persistence in ten different You may have like a a SQL database, NoSQL database, and so on, and tens of external application may be talking to. we have a streamlined CI CD to the cluster. Imagine how many entry of an attack surface such allow different These levels could be within So your own code or third party that allow for SQL injection, or cross-site scripting from clients or even worse, then you may have security application container operating system layer, all these different third packages that you may need environment that may have Now that container will like Kubernetes cluster. So here we have Like is the access to the Is server publicly accessible the internal network? Have you opened any unneeded nodes that allow access into the Now that's just outside What about inside the cluster? do they have wide open thousands of pods can all Can the control plane accessed from within Is the pod two pod and so on. Now Kubernetes is not just right? It's running Let's say it's a cloud So now the security continues Then the underlying Are people able to ssh into the If they can do that, they could potentially access on that server directly, or the container processes processes running Or what if access is generally like permissions are not and credentials are spread on different platforms so attacker may easily access Continuing with the CI CD what about CD accessing your deployment updates? What permissions does your CD Is it able to delete Kubernetes namespaces? So basically if an attacker system like ci CD platform, will they attacker then get Stored in your CD platform Kubernetes cluster. Account basically all that it connects to. And if yes. What permissions do Are they restricted or can And we can go on and on with questions around different We'd like secret credential rotation But I think you got the point. Security is complex have become complex. Security is. Afterthought means security issues get analyzed And there are two problems First of all, this creates long iterations the release process compared security issues earlier during And second, when you're checking all features and bug fixes and 50 you may more easily oversee way more things to test, and more issues may slip Also, naturally, you have high chance of human are done manually and less to the automated approach. Now you remember my simplified definition of DevOps. what it really comes down any tool or concept use on the way of releasing to the end user fast And this applies whether or infrastructure changes. if security is a bottleneck that should become part to eliminate this showstopper. So DevOps naturally But as I often say, reality in theory or how different scenarios. it's so happened that DevOps it focused on development and efficiency and speed But security teams and external not streamline, not automated, So as a reminder to kind the importance or bring back of security in DevOps, And as you know, DevOps affects entire software So DevSecOps is naturally security and integrating DevOps steps from start along with application tests, So the responsibility of fixing implementation still lies and different engineering in those specific areas. But DevSecOps creates and automated steps called the security posture basically giving us a visibility So how does DevSecOps do this? Automation is the key just like it is in DevOps. we automate checking layers of security of the software And there are tools those automated tests. So what are those automated in the release pipeline Edit first we want to check Do we allow for SQL sanitizing user input? Are we using weak algorithms to encrypt So all these checks that we're to validate for any such vulnerabilities is called security testing, or Sast, where various SAS tools code for any of these issues. So it basically scans patterns of allowing cross-site scripting, and so on, and common coding mistakes to such security issues. And in the DevSecOps we cover the individual security So you actually understand what it is, exactly what a cross-site what client or server and so on. And we even learn how to fix So instead of just having just in theory, you actually see hands on how be fixed in the code itself. Now we also want to check our And this happens way too forget to remove API keys or hardcoded passwords And they basically end in the commit history, and secret scanning tools can the code and identify any hard like access tokens, API keys, any credentials, certificates, in the bootcamp, we go into detail cases of when this happen, as well as how to use hooks so they don't even Commit history because they get can commit the changes. Now, we also want to check whether people that we use in our like libraries, frameworks that we're They are code as well, right? So those engineers may just like our engineers. And this is called software Allergies or SCA. So we use SCA tools to scan dependencies for any already discovered And we identify whether versions of third party software And again, here we have a whole Or explain how these vulnerabilities are documented how the SCA tools actually dependencies and identify any Once you found that you vulnerabilities and more how to actually Now these are all static checks. But there are some security only be caught is actually running. And this is called dynamic security testing or Dest, which is a testing method a running application different vulnerabilities. this could be SQL injection with different parameters that you are not So the Does tools basically to the application the application responds, what data it returns And this way they can identify weaknesses in the application. We also want to validate artifacts that we're producing. there are tools that scan any security issues on the For example, are we using Are we using a deprecated operating system package? Are we using a bloated that we don't actually need. So we are increasing the attack So there are all these tools these type of security checks. in DevSecOps bootcamp, we basically go into details the practical application and implementing those tools. One of those concepts usage of the tools called the false positives, as well as how to visualize and analyze them management tool. We basically combine all tools and see what issues with what severity levels, where exactly in the application and some recommended options Understanding what's called that are a big part the discovered issues. And also what's very is to reference the real world wherever relevant, whether there is a how the things should work, and how these tools are actually Things like how to balance that increase and when to run separate for example. So I go into detail in this kind So these automated security phases of release and can even before the developer And the CI CD pipeline So it gives us fast feedback be introducing in our systems, through changes in code or This is called shifting security because another important fact in the release stage we discover the more expensive it is So instead of reactively in production and patching them, we are proactively reducing that they end up in the first place. Now, talking about reactively issues in your systems, I want to give a shout the sponsor of this video, which is one of the important and compliance automation If you've been in DevOps you probably already know is a well-established technology in the industry. Chef compliance provides and these profiles can be easily organization's specific security You can schedule those or multiple environments, and you can run them to basically automatically about any configuration, drift, For example, running a profile that checks properly and two because of a misconfigured. To remediate chef can automatically reset configuration based Chef uses the concept which provide flexible recipes files to specify the correct API server Yaml. Using a simple chef we can confirm the managed has the correct cookbook When the chef compliant skin the Kubernetes system meets all And by the way, the whole Kubernetes security benchmarks themselves topics which you also cases in our DevSecOps bootcamp. DevSecOps is a huge exciting of the DevOps, which is already you explicitly integrate engineering processes. So large That means lots of tools So 1 or 2 hours is really just DevSecOps ocean to learn So I try to take out DevSecOps bootcamp to teach and I have carefully you the basics to get started of DevSecOps, and get the understanding DevSecOps can be implemented So now enough with the theory. We're going to be working with one project for the entire demo, and that is an open source which is a Python based project. And this application so that it can serve as a demo So we can actually see vulnerabilities discovered So that's the project Since it is Python specific, we're going to see how various scanning tools based that an application is using. And in order to work I actually forked the project So we can start from a clean skins whatsoever. So I removed all I made a couple of adjustments step by step from the start. And I'm going to link in the video description. So in this demo we're going a release pipeline security checks So we're going to build And we're going to do Since we are on GitHub. If you don't know I actually already have a crash So you can watch this video and get some Of course, I'm going to explain some but that should give And as I said, I do not have any pipeline code so we're going to build So here you see we have a tab called actions. So if I go here and you actually you have some templates So instead of writing the GitHub you can just go with one And templates are based of your application. And as you see what we are using And it is suggesting us template or Docker image And we're actually going from scratch. However, I still want to show you how So for example, if we choose a continuous with Pylint since we're continuous integration pipeline. So CI pipeline actually this will do two things. First one is in my automatically create So this was not there before. And inside that it will And then pylint dot Yaml file. So this path will be This is the location where a pipeline code automatically. So we can automatically And the second thing a boilerplate code integration pipeline. And this Again, if you go through my understand the syntax as well. So basically we could take But I want to show how So first of all I'm going So we're going to build multiple And second of all I'm of these and just remove. So we're going to start And as you learn in the GitHub the application whether it's a CI or CI, CD pipeline is one of the That's why we have these We can name our pipeline main dot Yaml file. So I'm going And then we want to configure will get triggered. And we wanted to get And you can actually specify to trigger this pipeline for. if I had multiple except for the main, I can say I only want these A list of specific branches, because this is a continuous it makes sense to always run it, no matter whether it's a main So that means we can. Basically say whenever there no matter which branch that is, we always want to run And now we can start writing And this is going to be jobs that we're going to run And the first one we're to be assessed job. So we're going to run static tests on our Python application. And we're going to use which is a popular tool applications to run static as you know already, I always repeat that the tools as necessary as knowing So you could theoretically However, of course, when you compare the tools you have to consider So first of all, the adoption, If it's largely used there are a lot of people to this project. If it's an open for example, then that is definitely because you don't want to be who is using a tool that nobody Another one is, of course, how easy it is to integrate Is there already official So basically this simple to decide what tool to use, like the specific features as much because most of the They can be configured So for most common use pretty much the same. So bandit is a very popular And it's also pretty why I chose that one. But again you can choose You can also choose multiple So you can actually tools that do sass scanning. And basically you can compare maybe one of the tools that others were not That is a common So let's go ahead and write you learn in the course multiple steps or actions to execute during the job. So let's configure all So first of all let's We are running bandit skin. We also want to specify that we want to run it on an ubuntu machine. Because then the installation of the tool Cetera will depend on which operating system we are executing the job or the steps on. So we want an Ubuntu Runtime and now we can write We're going to start by checking out the code, obviously. as you learn in the course, the jobs get executed on fresh on GitHub hosted machines, and you can choose that machine should have. And that means it's a fresh It doesn't know anything It doesn't have any tools pre-installed on them. So you have to explicitly Plus check out your application And obviously we want to scan So we want to have the code where the job is going So check out the code and we're Called check out. Version two, and this will take care our repository code. To set up Python on this job no tools are pre-installed, so we have to explicitly install for the job. And we need Python because So we're going to install package manager called pip. So we have to install Or basically prepare the Python And again, for this kind of common they are actions. So we're going to use That is called setup Python. With this version and we can specify a version that we want to set up use, because whenever we are obviously we want to have which version of the tool So we're going to define That's the version And by the way we can find as well to see what attributes So if I search for setup This is the action. And you can see all that you can set here. So Python installation Now we want to actually execute the bended skin right. So as I said it's a So we're going to install package manager. So it's going to be And for this we're going directly on our ubuntu machine using pip install Super easy And finally we want to run command or bandit skin. With a command called bandit. So this basically scans in the current folder. So this is a location where We're saying everything All the files that it contains So whatever folders subfolders that contain all of that should be scanned. Very simple and straightforward And the folders or the code checked out with the first step. So that means the application And after installing bandit bandit scan against that entire So it will check and scan in the application code And this is how you set And now we want to commit And as I said because we have or GitHub slash GitHub will automatically And it will know there is a execute on code push. So this will trigger our zest So let's do that. Commit the change I'm going branch for simplicity So let's go ahead and do that. And if I switch to actions the workflow is already running. So let's wait for its execution. So run bandit scan And if I go inside, we're going to see And as you see, the job failed. And that is good the bandit scan actually vulnerabilities in our And it failed the job marking is not releasable, which is the purpose So let's go ahead and check And right here in the run the test results listed If I scroll all the way down, you see all those are possible that it detected. And right here we have a summary lines of code it scanned and how And one helpful thing that the is it doesn't only tell us, hey, there is a security issue but it also marks it with because not all issues important or equally risky. And that's why we need So we have the severity says these are some issues, but they are low severity cause as much damage. And they are high So this could be a more risky, highly exploitable And this is an important because as you see, we have way more low severity severity issues. And in practice this creates from the actual severe issues. So usually in DevSecOps the scanning tools severity or medium especially when we are first scans to the team, because we imagine we're going now we're going to start and if there are any you have to fix them. And the tool finds hundreds most of them low severity level, so developers don't have and they don't know hundreds of security issues. So this may create a lot and just destruction much value to the team. You won't be too popular Instead. If you show hey, we ran this and it detected manageable for the developer the usefulness of the skin that aren't fully bought and the tools can be tweaked them to only focus on what's tools to the level that we 100% Another metadata here along with the severity So confidence is basically about the discovery itself. So it found a high issue means it may be an issue. But the tool itself that it detected So it could be a false positive. So for example here we have that is medium severity. which means the tool that the issue is and actually So that could be a false we can configure the tool severity or low confidence on the important findings. And all security scanning tools As I said, most of them work So let's configure bandit low severity issues as well And for all these tools, you have the official you can see the command and configure those needs for your application. it has an option to configure we want to focus on and level want to focus on, and let the tool ignore So we're going to use our bandit configuration. So going back to the repository And let's. Edit or bend it command So basically we're going focus on medium and high and high confidence findings. So we're going to add So we're going to copy them. Add them here. Take this one and that's it. Basically that's Let's commit the changes again. Let the pipeline run. The bandits again failed again. now let's see how many issues so the summary stays the same. So we get the information However, the logs themselves, you see we only have medium with high or medium confidence. Findings have. Decreased, which means this is more for the developers now. So they can actually go those issues one by one, because they're just a handful And again, if you're just So this is the very first tools to your project team. You can even start with only And once you have those fixed, As the next step, we're going to configure a reports file and to the findings of the scans instead of just displaying them Again, we can find two options for that. First So that's going to be the name We can name it whatever we want. And the second one is the format So you can produce reports This could be CSV, HTML, Json, And note that all of these for machine consumption which means there are actually upload these scanning reports, where you can visualize in a findings there in one place. And I'm going to explain later in the demo. But for now, So we have the findings So we're going to export So let's go ahead and do that. It's going to be And we're going to produce And let's call this benefit And as I said, the purpose of generating is so that we can take that has the findings inside it to a vulnerability such as Defect Dojo, that will then consume the contents of it in a nice the information the description, and so on. Whatever the tool which makes the analyzing issues way easier. if you run the pipeline if you have multiple tools, you have to have a central and manage all those findings, or the team of developers can those findings in one place, as well as compare the pipeline runs management tool manage them through the logs. very important part and how to consume them, how to analyze those which is one of the most management tools for DevSecOps. And you learn all of these So right now we are generating to make it possible to download we have to create an artifact uploaded for the pipeline at of the pipeline execution. we want to have another step that artifact and make for us. So let's call And there is an action for that, because it's a very common use It's called upload. Artifact. you can check what the latest And we can provide the name of the artifact. So how it should be called Let's call it banded findings. And of course we need to tell Now, as I said, the jobs in GitHub actions run fresh new machines that spin All the steps get executed there and when the job is done, Everything that we including the reports file, So that means We're taking the file on that machine. It's going to be thrown And we're going to say you take it as an artifact so we can have after the pipeline has run. So even when the machine we still have So the path points to the actual And this is just what we want And they will make this file the pipeline run. However, there is one more thing we need which is the way GitHub is that whenever any the next steps will be skipped, if the Python installation because of whatever reason so this command failed, the next Which makes sense, because usually this is an order the tasks where the next step on the previous one. And that means when the bandit which it will fail security issues in the job, However, we want the findings uploaded with those findings. So even if it fails to explicitly tell GitHub which means whether the previous it doesn't matter. Always So let's commit this. And now, we should have the bandit file available there. So let's There you go. So the job failed. You see the artifact section? And now we have this bandit I can show that it was not So here we don't And this is the Json file. So in the zip file there And here we have all about those findings. Additionally to was displayed So that's how it looks like. As I said this is or for those vulnerability you can upload the reports file display those results in a UI. Awesome. So we have scanning code using bandit, which does But we also learned that not code or the dependency code, but also the application may have security that will allow the hackers And since in the modern Docker and containers the artifacts that we in our release pipelines and Docker image. As you have probably already you know that it's built so every single image a security vulnerability. just as a reminder, are basically whenever Could be a Linux Alpine which is a lightweight And then on top of that, we install a bunch of other for our Python application system packages and tools. All of that basically add And just like in we have libraries with vulnerabilities. We may have operating system with vulnerabilities. So we may actually be using images or operating system And the same way we want to understand how secure that we are building And we have various tools And in this demo, I actually chose a Docker part of Docker itself that is that goes through the image for security issues. And it does that actually So let's add a job for Docker how vulnerable or how And of course, to be able to scan a Docker build a Docker image. So we're going to extend to build the Docker image. And then we're going to scan So let's go ahead and do that. So right here we're And this job will contain and then scanning that image. Now this could be So for example we can push to a Docker repository. And in a separate job from the repository and scan it. we're going to have one job on that job execution machine. We don't have to pull And then on the same machine scans against that image. So I'm going to call And I can actually just copy this. Let's call these build. We're going to run And here we're going The first one is again going because we need our application file to build the Docker image. Now for this job we actually Instead we need Docker installed the job is executing to execute docker build and later Docker scout command. So the same way we set up Python here we're going So let's create a step. And let's actually search to install Docker. So. I'm going to look for set up see what comes out. And we have This is the location So basically just And paste it here. for any actions or any like installing they are prepackaged or ready reference from the marketplace, which just makes the creation But of course, alternatively, you can just run a command I prefer to use this action just easier cleaner code, especially if something changes You don't have to worry And then of course you have you to specify additional stuff. So for example I want version for our installation. And I'm going to do that with And. This is the Docker version. And I'm going to set it to one Let's do 2010 seven. And that makes Docker job environment, which means we can now And the first command will be And for that we're going to simply run docker build command. We need to specify the Docker for building the image. We can also specify so we can reference it later So we can call this my And we can tag it with And then we have to specify which is the location take as a build context. And this is going to be where the application code is. And that's our Docker build The next step will be for any security issues. And as I said we're going to use from Docker itself, which actually does a very of the images on multiple any security issues. And we can actually use two commands of Docker scout. One of them is called Quick view command will base image is outdated, and it will give of how to update it to make And then there is a more scanning that you can do Docker Scout CVS command. It basically gives of all the vulnerabilities And just like the other you can tweak it and configure additional flags that you are only severity level and so on. So let's go ahead and add a step So we're going to add Let's call this Docker scout. And we're going to run a command is a multi-line command. And this syntax basically commands one after another And here we're going to first scout command line tool. And then we're going to execute And I'm going to copy the URL to the installation. So this will basically for Docker scout cli. So install scout dot s h Then we can execute that shell script to actually And here we can then execute As I said we can use both as well as to scan the complete So this is actually the main And that's what we Now let's actually try to run So I'm going to commit see the execution result. Again. You see that by default these executed on two That saves time because these be executed in parallel for the previous So your pipeline So the job is running. The image is being built. And we can also check the docker file. So this is a pretty simple We just have a couple So each one of those commands And we may be configuring or installing tools because they're outdated. And those things will be scanned And the Docker scout scan the reason for that is because in to Docker to execute So we need to authenticate and email address. So that's what we need to set So we can execute Docker And that leads to another actions which is project secrets variables that you can secret or sensitive data. in release pipelines, CI you have to integrate So you are maybe pushing to a maybe you are deploying and you have to connect to these Right? So you need a proper those credentials. And obviously you don't want Right. So in the settings security section. And in that security section So if I open that and So these are where you can for GitHub actions workflows. And we're going to create So basically whatever secrets will be available in the GitHub workflows. So you may have multiple And you can use these in all your workflows. So here I'm going to create variables for my Docker So basically these are the ones to log into Docker Hub. So if you don't have an account up here and you get your And I'm going to call You can call this whatever And this is my Docker ID. And now I'm going to create And with the value So those two values are here, which means I can now reference or in my workflow. So going back So before we execute we need to first And you probably already from various of my previous showed this. So a safer login password directly with password, but rather read it from So we're going to do echo and. Our password variable for referencing environment repository secrets or repository Actions is very simply curly braces like this. And inside that you have that contains all the secrets Like this. So this is referencing And then we are piping that to So we have the username to reference like this. Repo user. And we're going to read Stdin standard input. So this is going to read here and that's it. We don't have to provide login because by default So this login command will to Docker itself. And that's it. We are authenticating And after that we can execute So now we're going to commit And we're going to see image scan our pipeline ran. So now let's actually check First of all you see Let's see what it means. So we have the build Docker was built and then we have This is the login part. And this is basically quick view command you an overview of what image What is the base image. That we have defined that we are building on top of. And then it also tells us image is outdated, As you know from security we don't want to use bloated, unnecessarily large images the attack especially if we don't use of the tools in that image So this is like a And this is a more detailed And this is the Docker And here you see a whole which are a lot of issues. For different tools that we're in our Docker image. the curl package. Or this package with this specific version have all these vulnerabilities. And this is actually similar because just like you in your code that have libraries and so on. So you have these Here we have a couple of tools since we're using which depends on another that has some tools installed, Docker Scout basically goes including whatever base and it looks at the tools the tools that we're installing but also whatever tools And that's why we have We have a pretty large list that we found, because it basically went the way to the initial image, and we can actually check So if we look for Python So this is the official Python image. And in text we basically look This one right here. As you see, Docker Hub itself shows results for the base image, and this one is also supported And here you see the exact in this specific image and what vulnerabilities And as you see we have All of these are basically And the thing is if we don't or git in that image, then there's no need to use Instead, we can use a slimmer, lightweight image with a less automatically means less risk right? And this is that is used to create all those tools and so on. And again you have with critical high severity vulnerabilities. So you can kind of prioritize if you have critical issues by those critical So that's one thing using just But also this is one The newer version So of course upgrading would mean that some and vulnerabilities But you can also So we're not going to go But this kind of scan basically good overview of whether an outdated image or whether So you have lots of libraries have vulnerabilities. So you end up with a huge in your Docker image scan. we have this severity level And we have 23 critical issues or low severity issues, which means again this creates Look how large the list is. especially at the beginning running an image scan for your probably don't want to deal hundreds and hundreds fix them so you can focus And then basically step by step, move on to the less critical again, it makes sense command to only print out. Those two severity level issues ignore the other ones. you can even use recommendations command to give those issues And one more interesting your attention to is that for that are discovered. this one right here, you also have the fixed So it tells you which version than or smaller And it tells you that there that has this vulnerability so you can upgrade to that one rid of this security issue. And you also see that for some has not been done yet. So there is no safer But again, many of these apply to the low which means we can now go and configure Docker Scout ignore all of those. So we don't have list of issues, but we can kind of filter out issues and have them in the before we add these options directly here, I want to show you an of running Docker Scout action from the marketplace. And this is another good example actions from the marketplace. the main advantage of using is always that it's high level, and it's just easier working with the tool. but if you just want to run of parameters and configuration, it's basically the easiest And if I look for Docker scout. You'll actually see that there So this is an official action, which is always good to use Now obviously the installation itself was pretty simple, as well as running the Docker so there is no requirement instead for simplicity simple already. these ready actions make with a high level configuration about installing the tool. making sure that these curl So I just want to switch But to make sure you guys snippet in the repository I'm actually just going And I'm just going to create a new step. And this is going to use So this is Docker scout And then we have a couple Obviously we need to configure data just like we did here. So for that we have Docker Hub So we're going to do going to set all those So Docker Hub user is going Referenced like this. Then we have Docker and I'm just copying this stuff make any spelling mistake. There you go. So we have And finally we have the command to execute some kind of command. So we can basically execute We just need two of them. List them here like this And that's it. So this is basically exactly Looks a little bit That's the only difference However when I execute this we more difference of using of running the Docker which is an improvement. So let's commit the changes wait for the job execution. So this is the one with Docker And this is without. And let's So this is the workflow And this is without. So if I scroll down here artifacts and some information And when we execute and scan image with the official If I scroll down we see these. Visualization of results interface view itself. So instead of having to go we can basically see Here we see the breakdown how many critical, high, etcetera issues as well as the base of the entire image scan, which is actually pretty nice easier to analyze and kind and what libraries you're using to fix those issues and so on. you see all these libraries have any critical issues, etcetera. So it gives So that could be another the Scout action. And finally let's now tweak our Docker Scout critical and high level issues. we want to create this report generated for other tools. I'm going to edit If we check out the official what configuration But this time for the Scout And again if I bring We're going to see all the configuration options here. for example a more detailed and so on, we can also search So this GitHub repository action gives you a more detailed for different commands. And as I said we only level of severities. And this is option So we have only severities. And we can basically just separated list of what severity So I'm going to copy this. And I'm going to choose So that takes care of ignoring and medium level issues. And we also want to configure And we have this sorry file And again if I check this here expects a file name. So we can set this parameter And we can call this Scout Serif and. Of course, we have to upload so that it's available after Let's call these Docker Scout findings. And of course the name And that's our configuration. Now with this we're going and run the workflow again. And now up to this configuration, we see in the scan results level vulnerabilities by the tool and the list We see that only those critical or high vulnerabilities So we don't have this huge but we have rather manageable So we can even limit that only So we would basically be these libraries here. And again, we still see the overview on all including low and medium. the specific issues are only so it's not And additionally, we also have these Docker Scout as an artifact. And again we can download it in a vulnerability along with other reports. One more optimization we can is to basically fail vulnerabilities are found. if we go back we see there is this exit that is by default set to false. And we can set this exit which will be unsuccessful result which will fail the job. So again let's adjust And instead of default false, And let's commit the change. And wait for the result. And if we check you see that our image because we have security So we optimized that as well. So our pipeline is doing is scanning the image artifact for any vulnerabilities. And we're producing these And when you are implementing organization you have to use because otherwise inconvenient and hard to analyze or to basically just see of your application based on the security So it kind of unnecessarily And as I said, there are different One of the popular ones, is Defect Dojo, which is the tool I teach And of course, every time we run it will produce new reports. That means you don't want to be reports from each and then importing that manually Either you want to automate because it just happens to often So in the DevOps bootcamp, we want to learn things as they in a proper way. So actually show how to write script that takes the reports execution and automatically and automatically uploads reports in the defect dojo. you can group that per So we have a history of scan issues are increasing over time or they decreasing and getting The second important discovered the issues, those right. So first of all, Is it a DevSecOps engineer? Security engineer? So who is responsible for fixing fixing the issues or upgrading the library use vulnerable, unsafe Who fixes the Docker And this is important To know how DevSecOps how the responsibilities members in a practical, actual, So in the DevSecOps bootcamp, we go into the topic and responsibilities and also how this in an organization and involve all of these in the implementation and to kind of motivate can resist against it. What's also super important issue types like SQL injection, vulnerable third and how to fix those including Same with the Docker How to fix security issues And here it's important the CVEs in dependency scanning So we go into detail in all to analyze and find such issues. And then of course And we actually use project and completely different So these Python application is just to demonstrate the basic So we are actually not from this crash course So this should already give and understanding of DevSecOps. So you can actually implementing this already. you may want to know what the that DevSecOps also more advanced scenarios. Diving deeper and really grade DevSecOps processes. the obvious one is that deployment part comes after to servers on an open up another world like cloud security, server administration, secure deployment to the servers in today's world, no DevOps topic is complete is its own separate world concepts that are security So starting from security, network security within access control management, and. And DevOps and ops is anyways So policy is code, cloud compliance is code and so on. So there is a ton and topics involved this whole thing to a completely And that's exactly why bootcamp to teach because it's a huge subject. It's a very interesting So you need a proper guide with real life production use really good at this subject. plus the monitoring and logging on application level, cluster level So all of that is in That means if you need for your position, or if you work at a company projects actually need this, then DevSecOps bootcamp you complete picture of everything you need to learn We worked on this for almost and there is way more content, and the topics and projects comprehensive than anything So as I said, if this is a topic then I definitely recommend as a next step to completely career for just a fraction with this skill set will earn. So definitely check out the bootcamp in But if you just needed understanding of DevSecOps, and get your first practical then I hope I was able And this will help you in in your project. I'll be very happy And if it did, please let me know in the about this, what value you get and as well as share who you think will also And with that, thank you for watching you in the next video.