ANNOUNCER: The following program YASER ABU-MOSTAFA: Welcome back. Last time, we introduced some important development. And the first concept was dichotomies. And the idea is that there is an input there is a hypothesis that's regions from blue regions. But we don't get to see that. What we get to see are just the sheet if you will. And there could be very exciting stuff you get to see is when the boundary point turns red or vice-versa. So if you think of the purpose for the counting the number of hypotheses, a very large number. But if you restrict your attention to restricted to a finite set of points, don't have to count everything You only count it as different when those points. So a dichotomy is a mini-hypothesis, And it counts the hypotheses only This resulted in a definition that which is the number of dichotomies So we define the growth function. The growth function is-- you pick You pick them wisely, with a view to the number you get will be more than any points. That's the purpose. So you take your hypothesis set, which space, and then apply it This will result in a pattern of And as you vary the hypothesis within pattern, another pattern, So you will get a set of different that can be generated by this hypothesis And the number of those guys is It will play the role of the And that is the growth function. Now in principle, the growth function an input space and a hypothesis set, any pattern you want. However, in most of the cases, the from H will result in missing Some patterns will simply And that led us to the idea For the case of a perceptron in studied, we realize that for four that cannot be realized There is no way to have a line come from the blue points. And any choice of four points will missing patterns. Therefore, the number k equals 4, in this for the perceptrons. And our theoretical goal is to take that point, and be able to characterize the And therefore, be able to characterize We then talked about the maximum constraint that there And we had an illustrative example to you cannot get all patterns on any-- in this case, two points-- that is a very strong restriction on get on a larger number of points. So this is the simplest case. If you take any two columns, you That's by decree. I'm telling you that the hypothesis And then I'm asking you, under those get, how many different And you go and you add them case with only four. So you lost half of them. And you can see that if we have 10 restriction, there will be so many applies to any pair of points. Now, if you look at this schedule, particulars of the hypothesis set or the that the break point is 2. I could be in a situation, where the these guys for other reasons. But here, I'm abstracting only I don't want to bother to Just tell me that they have a break that single constraint, how many And I already have, by that a restriction which is strong enough That's good, because now I don't have set, and every input space, you give me. I just ask you: And I'm able to make a statement about than something. That is the key. We move on to today's lecture, and Generalization. It's very theoretical. And today's lecture is the most So fasten your seat belts, We have two items of business. The first one is to show that the growth indeed polynomial. The second one is to show that we can function, and put it in place of in Hoeffding's inequality. So basically, we are saying in the the growth function. Because being polynomial will And then, the second one is: we can We can do the replacement. These are the only two items. Let's start. We are going to bound the growth And I just wanted to point some If I say m_H of N is polynomial, it's not for the growth function, and show that the coefficients. All I am saying is that it is really I don't have to get the particulars I am going to just tell you that this something, less than a polynomial. That's all I need, because eventually Hoeffding inequality. And as long as it's bounded by Because the negative exponential discussed, and we are OK. So we can be a bit loose, which Because now you leave a lot don't need to study. And just talk about the upper bound in you want to get. The key quantity we are going to use, quantity, we are going to This is exactly the quantity we I give you N points. I tell you that k is a break point, and can you get under those conditions? In that case, we had three points And we answered this question We played around with the patterns until Now, as I develop the theory, in one of the results. I would like you to keep an eye and part of the slide, addresses the very The definition here is the maximum such that they have a break point k. So this is N and this is k. And the good thing here is that I didn't any input space. This is a purely combinatorial And because it's a combinatorial quantity, it down exactly, as it turns out. And now, when I pin it down exactly, you space, and the fanciest hypothesis set. You pick the break point for that, and problem of all the other aspects, and bound statement. You can say that the growth function, about, is less than or equal combinatorial quantity. The plan is clear. So let's look at the bound And we are going to do it recursively. It's a very cute argument, and I am So I want your attention. Consider the following table. Very much like the puzzle, we are N points, which used And I am going to try to put as many that there is a break point. So I will be putting the first pattern on, trying to fill this table. Now, I am going to do a structural through this division. Let's look at it. Still the same problem, x_1 And I am trying to fill this with a constraint of a break point. But now I am going to isolate Why am I isolating the last point? Because I want a recursion. I want to be able to relate this fellow, smaller quantities. And you have seen enough of that to might be able to actually That's why I'm isolating After I do the isolation, I am going matrix, into some groups. This is just my way I haven't changed anything. What I am going to do, I am going to constructed them. So we have a full matrix now, and I am in the first group. And the first group I Here is the definition These are the rows that appear x_N-1 are concerned. Well, every row in its entirety appears different rows. That's how I'm constructing But if you take out the last guy, it is 1 coordinates happen twice, once with extension +1. So I am taking the guys that whatever it might be. Could be -1 or could be +1, them in this group. Fairly well defined. So you fill it up, and these are all the Now, you go under this, and you this group to be alpha. It is a number. I am just going to call it alpha. And you can see where this is going, the B of N and k, which is the total is alpha plus something. That is obvious. I have already taken care of alpha, other stuff later on. So what is the other stuff? That is the stuff I am And you probably have a good These are the guys that happen That is, they happen with extension That is disjoint from the first group. A typical member will This is the same guy from x_1 up to It just appears here with +1, And I keep doing it. So what I'm doing, I just reorganize fall into these nice categories. The other guy? Exactly the same thing. So the second one corresponds to Now, that covers all the rows. I look at x_1 up to x_N-1. I either have both extensions, One extension belongs to the first second group in both ways, In terms of the counting, this has This also has beta rows, because And therefore, the number B of N and alpha plus 2 beta. That is complete. Just calling things names. So now, I am going to try to find can find a recursion for the big B of N and k are the maximum patterns I can get on N points, all possible patterns. That's the definition. I am going to relate that to the same and smaller k. So the first is to estimate I'd like to ask you to focus on And I am going to help you visually Now for a moment, look at these. Are these rows different? They used to be different when Well, let me see. The first group, I know they they have one extension. If there is one which is repeated, then extensions, in order to get different condition for being here. They are here because they These guys are the same. This one appears with -1, and But if you cut the last guy, this This second guy is identical So I cannot count these I can do that when I gray Now, these are patently different. Nothing here is repeated, because we said they are all tucked in here. These two guys, there are no two guys have the same extension. And supposedly, the whole row Therefore, these guys are And these guys are different from here I will have an extension. And then the guys here will belong to Very easy. Just a verbose argument, being different. Now, I like the fact that these guys are are different, I can relate B of N and k was the maximum number of that's how I am counting them-- such that a condition occurs. So what is the condition I can say that alpha plus beta, which patterns in this mini-matrix, can I say this small matrix? Yeah. The original matrix, I could patterns on any k columns, right? So I cannot possibly find all possible smaller set. Because if I find all possible patterns serve as all possible patterns And I know, that doesn't exist. So I can now confidently say that alpha of different guys here, is less than or have only x_1 up to x_N-1, and k, because that is the break Why am I saying less than When I constructed the original matrix, I looked at the maximum number And I told you this is And therefore, by definition, Here, I obtained this I took out a guy from the other I am not sure that this is the best way At least it's conceivably not. But for sure it's at most B of is the maximum number. I am safe saying that it's So I have the first one. Now, let's try to estimate This is the more subtle argument. In this case, we are going to only, the S_2 part. The guys that appear twice So let's focus on them. Now, when I focus on them, these They are here and here This block is identical The interesting thing, when I look at able to argue that these guys have The argument is very cute. Let's say that you have all possible small matrix. First, I have to kill these. These are not different guys, because So let me reduce it to the guys I'm now looking at this matrix. I am claiming that k minus Why is that? Because if you had k minus 1 guys patterns, then by adding both copies, will be getting k columns overall that know you cannot have because k is So now I'm taking advantage of the It's very dangerous to have k minus 1 know doesn't exist. Let's do it illustratively. Here is a pattern here. You add the +1 extension by taking this column. If you get all possible patterns on k have both patterns here, and you will points on the overall matrix. That enables me to actually count with the proper values of N and k. We can say that beta is less than equal to because I obtained this I didn't do it deliberately to maximize whether it's the maximum. But I sure know that it's less than or of what a maximum is. And that would be of what? I have N minus 1 point and I argued So I end up with this fellow. Both arguments are very simple. Now, we pull the rabbit out of the hat! You put it together. What do we have? This is the full matrix. The first item was just calling things matrix is B of N and k, I organized it such that there is alpha, another beta, so this one is the first equals alpha plus 2 beta. What else did I get? I got that alpha plus beta is at That was the first slide We have seen that. So this basically takes this matrix, And it has a break point k, because k bigger one. That's what we did. The other one is, beta is less than And this is the case where I only looked be more restrictive in terms of all an extension to add, and I would be So I ended up with this being less 1 and k minus 1. Anybody notice anything in this slide? How convenient! I have alpha plus 2 beta on one, and beta on one. If I add them, I am in business. I can actually now relate B of N and k beta are gone. B of N and k, now I know, has So you can see where the Now I know that this property And now all I need to do is solve it, in value for B of N and k. And that numerical value will serve as of a hypothesis set that Let's do the numerical I have this recursion, and I can see K, I can get bigger values, or I can get Let's do it in a table. Here is a table. Here is the value of N-- 1, 2. This is the number of points, the And this is k. This is the break point So this will be-- there's a break point 3, et cetera. And what I'd like to do here, I'd like on B of N and k. I'd like to put numbers here, that I know that number. And we can construct this matrix very, Here's what we do. First, I fill the boundary conditions. Let's look at this. Here it says that there I cannot get all possible Well, what are all possible -1 and +1. It's one point. So I cannot get both That's a pretty heavy restriction. So I'm asking myself, let's say you How many different rows can you get in Well, I'm in trouble. Because if I have the first pattern, and second pattern must be different from That's what makes it different. If it's identical in every column, then So you go to that point, And unfortunately, for that point So we are stuck. We can only have one pattern Hence, the 1's-- 1, 1, 1, 1, 1. That's good. Now, in the other direction, In this case, it's 2. It's very easy to argue. Now, I am taking the case where So I'm asking myself, how many patterns Well, the most is 2. Why am I getting 2's here? Because in the upper diagonal of am putting is vacuous. Here, for example, I am telling you how get on one point, such that no four Four points, what are You have only one point. So that's no constraint at all. Therefore, it doesn't restrict the maximum number I would get unrestricted, If I have one point, That's why you have the Now, I covered the boundary conditions, complete the entire table, given the Why is that? Because that constraint looks like this. If you know the solid blue guys, I Because this would be-- This is N and k. This would be N minus 1 and k. This would be N minus 1 and k minus 1. That's exactly what this says. So if I have these two points, I can an upper bound on this fellow. Let us actually go through The first guy I'm going According to this shape, I might What would that fellow be? 3, right? You just add the two numbers. How about the next guy? Anybody has a guess here? OK, 4. And then? A bunch of 4's. Always get 2's. I am actually happy about this because bigger than N, as we said, the So I should be getting all number of points I have. And as you can see, for For 2, I will get eventually the 4's. And for 3, it will be the 8's. So that is very nice. Let's go over the next row. Can I solve this one? Now that I got this one, I can become See where this came from? How about the next one, That should be 7, right? 8. A bunch of 8's. This is kind of fun. And you can fill up the entire table. So we have it completely It would be nice to have a formula, But numerically, we will have that. Now, let me highlight one guy. Do you see anything that I claim that you have That's the puzzle. You had three points. Your break point was 2. And now we know for a fact that the without having to go through through last time. Can we try this? Can we try that? You don't have to do that. Here are the numbers, just by computing Now, let's go for the analytic What I'd like to do, I'd like to number outright. I don't have to go through this So let's do that. This is the analytic solution Again, this is the recursion. And now we have a theorem. Yeah, when you're doing mathematical Otherwise, you lose your What does the theorem say? It tells you that this is a formula for B of N and k. What is this formula? This is N choose i, the combinatorial And you sum this up from So both N and k appear. N appears as the number here, and k summation-- appears as k minus 1. This quantity will be an upper You can now, if you believe that, you compute this number. And that will be an upper bound for the set that has a break point k, without the hypothesis set or the input space. It shouldn't come as a surprise you look at this, this is really combinatorial. Clearly, it will come But why is it this way? Well, what we are going to show, we are the quantity we computed numerically And we are going to do So the recursion we did, we are just How do you do that? You start with boundary conditions. What were the boundary conditions? We argued that this is, indeed, And hence, an upper bound on Now we want to verify that this numbers, when you plug in the value How do I do that? You just do it. Just plug in, and it will come out. I'm not going even to bother doing it. It's a very simple formula. You just evaluate it, and you get that. The interesting part is the recursion. I would like to argue that if points, then it will also And then by induction, since it holds this step by step and fill the schedule, the correct value for the numbers Everybody is clear So let's do the induction. We have the induction step. We just want to make clear You are going to assume that point and this point. So indeed, if you plug in the values for minus 1, and here it would be N minus particular formula. Then the numbers will be correct. That's the assumption. And then you prove that, if this is true, That's the induction step. Fair enough. So let's do that. This is the formula for N and k. You just need to remember it. N appears here and k appears here. Minus 1 is an integral This is the value for The value, for k, happens to be the sum So this is the formula that And we would like to argue what is this one? This one is for N minus 1, and still k. So this would be-- I am moved from here to here. So this will be the value here. And what is the other guy? That will be the value for N minus 1. And now it's for k minus 1, because It becomes k minus 2. This part belongs here. So this is the induction step. We don't have it yet. That's what we want to establish. So let me put a question mark established it yet. What I am going to do, I am going to reducing it, until the left-hand That's all. And then we'll be done with And since we have the boundary theorem we asserted. The first thing I am going to do, And I notice that the index goes Here, it goes from i equals 0 I'd like to merge the two summations. So in order to merge the two summations, number of terms, first. Very easy. I will just take the zeroth 0, which is 1, out. And now the summation goes from Now, I go to the other What did I do? I just changed the name of I wanted the index to go from 1 able to merge it easily. Here, it goes from 0 to k minus 2. So what do I do? I just make this i, and So i minus 1 goes from 0 to k Just changing the names. And now, having done that, I am ready And they are merged. Now, I would like to be able to take And you can do it by brute force. This is no mysterious quantity. This is what? This is N minus 1 times N minus divided by i factorial. And this one applies the same thing. So you end up with something, and then looks familiar. And then you reduce it So there's always an algebraic But I am going to reduce it with a very I am going to claim that this is-- the 1 remains the same. And this actually, the whole thing So these two guys become this one. Instead of doing the algebra, a combinatorial argument. That is, this quantity is identical Let's say that I am trying to choose And let's say that the room There are N people. How many ways can you chose 10 That is N choose 10. Let's put this on the side. Here is another way of counting it. We can count the number of ways you can the number of ways you can pick Right? These are disjoint, and they Let's look at excluding me. How many ways can you pick 10 people Well, then you are picking the I am the minus 1. So that would be N minus 1 choose 10. Put this in the bank. How many ways can you pick Well, you already decided you are on the 9 remaining guys. So that would be N minus 1 choose 9. So we have N minus 1 choose 10, plus original number, which Look at this. What do we have? This is excluding me. This is including me. And this is the original count. So it's a combinatorial identity, and torture of the algebra in order to Now, I go back. I look, this goes from I have this 1, so I conveniently put Have you seen it before? Yeah, it looks familiar. Oh, this is the one we want to prove. So it means that we are done. That's it. We have an exact solution for the Since we spent some time developing celebrate it, and be happy about it. First thing: yes, it's a polynomial, a polynomial, right? If we did all of this, and it's perfect a polynomial, then we are in trouble. Because although the quantity is in the utility that we are aiming at. So why is it polynomial? Remember that for a particular a fixed point. It doesn't grow with N. You can I get all possible dichotomies That's a question for the perceptron. No. Then 4, in the perceptron, Now, I can ask myself what the And the break point is still You give me a hypothesis set, That's a fixed number. So according to our argument now, the that has a break point k is less than or quantity, B of N and k, which is defined dichotomies you can get, under the And that was less than or equal So we can now make this statement. You go in a real learning Let's say you have a neural network break point for that neural I don't ask you what is a neural you don't have to know. I don't ask you what is the you are working on. You told me 17. Your growth function of your neural the space that I don't know, happens to know that I'm correct. So is this quantity polynomial in N? That's what we need. Because remember, in the Hoeffding, there If we get this to be polynomial Well, any one of those guys is what? N times N minus 1 times N minus 2, i factorial doesn't matter, So you basically get N multiplied by the i-th term. The most that N will be multiplied by k minus 1, the maximum. And then N will be multiplied Therefore, the maximum power in this This comes from N times N minus k times, that corresponds to the When you get N choose k minus Anything else, will give you a power This is the most you will have. What do we know about this fellow k? We know it's just a number. It's a constant. It doesn't change with N. And a polynomial in N. And we have achieved That is pretty good. Let's take three examples, in order to had before. This is the famous quantity by now. You know it by heart. I have the N. I remember k. I have to put minus 1. And that is the upper bound for anything Now, let's take hypothesis sets we the growth function explicitly, and see They had better, because this is math. We proved it. But just to see that this Positive rays. Oh, remember positive rays We have one dimension, Then we take from a point on, And we said that the whole analysis avoid what I just did. You don't have to tell You don't have to tell me-- you just have to tell me what? What is the break point? That's all we want. you can call it positive rays. You can call it George, I don't care! It has a break point of 2. That's what I pull. We did compute the growth We did it by brute force. We looked at it, and we see what a combinatorial argument. And we ended up, that the growth function Let us see if this satisfies This is supposedly And you substitute here for And the break point is k. So you're summing, from i equals You have N choose Plus N choose 1, also known So you get this to be less wow! Look at the analysis we did And we get exactly the same. With all the bounds and-- we think that there is But here, actually it's exactly tight. We get the same answer exactly, without what the hypothesis set was. Let's try another one. Maybe we'll continue to be lucky. Positive intervals. Yeah, I remember those were oh, I'm sorry. I am not supposed to ask any questions I'm asking about the break point only. I remember now. So tell me what the break point is. That was k equals 3. And we did compute the Remember, this one was a funny one. We're picking two segments out of So we ended up-- this What would be the bound according This would be again, this formula. And now k equals 3. So I have N choose 0 plus N I get 1 plus N plus something And I do the reduction Boring, boring. I seem to be getting it all the time. It doesn't happen this way. It will always happen But there will be a slack So, we verified it. We are very comfortable Let's apply it to something where we Remember this old fellow? Well, in the two-dimensional perceptron, argument just to prove that But we didn't bother go through ourselves, how many hypotheses can the Can you imagine the torture? We do this-- can I get this pattern-- And you have to do this for every The growth function is unknown to us. We just know the break point. But using just that factor, we are completely. And you substitute again You get another term, which is cubic. And you do the reduction. And lo and behold, you That statement holds for the perceptrons And you can see that this So now it was all worth the trouble, characterization of hypothesis sets. And we can take this, and Remember, this part, which has now polynomial. Proving that we are interested If it wasn't polynomial, we wouldn't Now, this is an interesting This one tells us that-- oh, and by the You actually can use it. We can put it in the Hoeffding Hoeffding inequality is true Now let's see what we want, to remind the total number of hypotheses We wanted, instead of this is Hoeffding, and this is the number bound, which we said is next is big, or M is infinite. And instead of that, we wanted by the growth function. So this is what we are trying to do. We are trying to justify that instead Well, it turns out that this is not We are going to modify the constants become clear. But the essence is the same. There would be the growth It will be polynomial in N, and it exponential, provided that there is Now, how are we going We are going to have What a relief, because I think So the formal proof is It's six pages. My purpose of the presentation here the proof, so that you don't get There are basically certain things And once you know that that's what you bullet and go through it line by line. The two aspects are the following. Why did we do this growth function? We used the growth function because it's But how could it possibly replace M? Because M was assuming no overlaps Remember? So now that we know that there are The question is, how does the relate to the overlaps? You need to establish that. So this is the first one. And when we establish that, we find that everything, except for Growth function relates So we will get a perfect handle error part of the deal. But in the Hoeffding inequality, And E_out relates to the performance So we are no longer talking about hypotheses. We lose the benefit of So what do we do about E out? That was a question that What to do about E_out, in order while we are just using a finite After that, it's a technical the final result. That's the plan. But the proofs are pictures. So let's have a blank page. And let's say you are an artist It's a very special canvas. It's the canvas of data sets. What is that? Every point here is an entire Fix N in your mind. So this is one vector. This is another vector. This is another vector. And this canvas covers the entire Now, why am I doing this space? Well, I am doing this space because the E_in goes to E out, depends Depends on the data set. For some data sets, you will For some data sets, you are So I want to draw it here, in order to overlaps, and then argue why useful for the overlaps. Now, we assume that there's And for simplicity, let's say that the So the total area of the canvas is 1. Now, you look at the event, the far away from E_out. And let's say that you paint to that event red. So you pick-- is this data What does it mean, good or bad? I look at E_in in that data set, compare hypothesis, and then paint So I have a hypothesis in mind, and I am leaving them alone, according to whether inequality or not. And I get this, just illustratively. And you realize that I didn't And that is because of Hoeffding inequality tells me So I'm entitled to put a small patch. Now we went from one hypothesis, which multiple hypotheses, using So again, this is the space of data And now, I am saying for the first What happens when you have Because I am using the very pessimistic my bets and saying you get Another hypothesis-- two of them. More. More. Oh, no. We are in trouble. The colored area is the bad area. Now the canvas is the bad area. That's why we get the problem Because obviously, having them disjoint Each of them is small, but Infinity of them as a matter of fact. This will overflow. Well, no, it won't overflow. Just figuratively speaking. So that's what I'm going to have. What is the argument We are not applying the union bound. We are going to a new canvas. And that canvas is called the VC bound, We'll see it in a moment. So what do you do? Your first hypothesis, same thing. When you take the second hypothesis, consideration. So it falls here. You get more. You get more. You get all of them. It's not as good as the first one. I never expected it to be. But definitely not as bad as the overlapping. And indeed, the total area, which is happening-- is a small fraction of And I can learn. So we are trying to characterize That's the whole deal with One way to do it is the one that hypothesis set. Study the probability distribution. Get the full joint probability involving two hypotheses, and Well, good luck! We won't do that. The reason we introduced the growth quantity that is simple, and is going The question is, how is the characterize the overlaps? Here is what is going to happen. I will tell you that if you look at painted at all, it will get Let's say that I have that guarantee. I don't know which hypotheses But any point that gets a red, it will If I tell you that statement, what area that is colored? Now it's, at most, one hundredth Because when I had them non-overlapping, Now for every point that is colored, So I am overusing these guys, and And I will get one hundredth of that. That is basically the essence What the growth function tells you is Number of dichotomies. If you take a dichotomy, this is not hypothesis on a finite set of points. There are many, many hypotheses that Remember the gray sheet Lots of stuff can be happening And as far am I am concerned, they So all of these guys will be behaving If one of them colored the This tells me that the by the growth function. That would be a very clean argument. And it would have been a very simple That the point being colored doesn't also on the entire space. Because the point gets colored What is a bad point? The frequency on the sample, that is from E_out. Oh, E_out involves the If I have the gray sheet and the I have to peel it off, look, and get So the argument is great, as long as you the presence of E_out? And that's the second What to do about E_out. The simplest argument possible. That is really the breakthrough Chervonenkis did. Back to the bin, just because it's So here, we have one hypothesis. And we have E out, which is the the error in the entire space. We pick a sample, and then we get E_in, on this one. So we have seen this before. And we said this tracks this, according And the problem is that when you have will start deviating from E_out, to the sample, you are no longer sure that deviation could be big. That was the argument. Now, I want to get rid of E_out. The way I am going to do it is this. Instead of picking one sample, I independently. So obviously, they are not Some of them are green But they are coming from Now, let's see what is going on. E_out and E_in track each other, because distribution. Now, let's say I look at these two I am going to call them They're both in-sample. It happens to be a different sample. So I have two samples. I am going to call this E_in, My question is, does E_in track Well, each of them tracks Because it was generated by it. So consequently, they A bit more loosely, because getting the sample error. On the other hand, if I do one polling asks 3000 people. Another asks 3000 people. These are different 3000 people. You fully expect that the result will So these guys track each other. OK, fine. What is the advantage? The advantage is the following. If I now have multiple bins, the exactly in the new tracking. When I had multiple bins, the tie and looser. Because I'm looking for worst case, and tracking now lost the tightness that one If I am doing multiple bins, and not looking at the two samples from each also get loosely apart Let's say, I tell you this experiment. You pick two samples. They are close in terms of If you keep repeating it, can you get other sample to be mostly green? Yeah. If you are patient enough, Exactly for the same reason, for it until it happens. So the mathematical ramifications of exactly the same way they happen here. The finesse now is that, if I samples, then I am completely Because now I'm not appealing I am only appealing to what It's a bigger sample. I have 2N marbles now instead of N. function on them. And now the characterization is These are the only two components you read the proof. Now, let's put it together. This is what we wanted. This is not true. Don't hold this against me. And to make sure, this is This would be direct substitution of the terms of M. We are not going to have that, but we Lets look and compare. These look the same, except Is this good or bad? Well, it's bad. We want this probability to be small. Bad, but not fatal. This one goes to here. I have twice the sample. You know why I have 2 now. Because now I use the bigger sample Oh, but all of this was about whether this will be a polynomial. Yes, you do. If it's polynomial in N, it's Because you get 2N to the That's a constant. And you still get N to the k. So that remains a polynomial. A bigger polynomial. I don't like it, but you It just has to be true, and And finally, you can see this is minus This is in the exponent. 2 in the exponent goes And now we knock it down That's really, really bad news. The reason this is happening technicalities of the proof, the epsilon And then will become epsilon over 4, just And when you plug in epsilon over 4 And so you get a factor of 1/8. That's the reason for it. So this is what we will end up with. And you can be finicky and try to basic message is that here is hypothesis set that has a break point. And this fellow is polynomial in N, decided by the break point. And you will eventually learn, because enough examples-- using that hypothesis, tracks E_out correctly. This result, which is called the most important theoretical result On that happy note, we will stop after a short break. Let's start the Q&amp;A. MODERATOR: First, a few In slide 5, when you choose the N points, of N points, or you just chose PROFESSOR: When I apply this to an actual these actually correspond points in that space. However, in the abstraction that just abstract labels. These are labels for which So although I call them x_1 up to in the abstraction here, they don't space in mind. But when they do, they will And I am supposed to pick the sample number of dichotomies, et cetera, as But it's a sample that I pick when I and a hypothesis set. MODERATOR: Also, there are they didn't understand exactly why PROFESSOR: alpha MODERATOR: Yeah. Why? PROFESSOR: Well, the short statement that alpha is I just didn't bother ascertain any I just called them names. If they happen to be If they happen to be So all I'm doing here is just calling extension, the number of Calling the guys that happen to I don't know whether alpha is bigger particular case. And it doesn't matter as far as If I call them this way, then it will of rows here is alpha plus beta plus So there is really no assertion about MODERATOR: Moving on to the case how it satisfies the bound. What happens if k equals infinity? No break points, basically. PROFESSOR: This is for the MODERATOR: Yeah. So for example, if you PROFESSOR: k equals infinity In that case, you don't have to bother No break points means what? Means the growth function is just computed it exactly. If you want a bound for it, yes, a polynomial. So all of these cases, we're addressing a break point, because that is the case And therefore, I can That is the interesting case. If there is no break point, this guarantee learning. So if I have a hypothesis set that set of points, I cannot make a statement that it will learn. And one example we had So convex sets have a growth function a very pessimistic estimate here, because very funny. You have to build the pathological case, And in many cases, you might be. But again, if I want a uniform statement point, this is the most I can say MODERATOR: OK. Just a quick review. How is the break point calculated? PROFESSOR: Calculated. The break point is-- this is the only input space and the hypothesis set. You basically-- you are sitting in Someone gave you a problem You decided to use perceptrons, and transformation. And you do all of that, and you And you would like to know some performance that you are going to get. So you go into the room, and ask yourself: this input space, what is the break point? So now you have to actually go and And then find out that using this let's say, 10 points in Very much along the argument we used for We found out that we cannot separate But the good news is that, you don't have the famous learning models, this For the perceptrons, we will For any-dimensional perceptron. So 20-dimensional perceptron, here's the growth function. Or, here's the bound. Similarity from neural networks, Not exact estimate of the break point, And again, in most of these cases, trying to bound above. And we have room to play with, because is a polynomial. So if you become a little bit sloppy point-- you say 10 instead of 7-- it's not going to break the back of It's just going to tell you more you need in order to learn? Which is more benign damage cannot learn at all. MODERATOR: OK. Can you come up with an example, where PROFESSOR: There's one case, didn't, where you take positive So positive rays, you And from a point on it's +1. Positive and negative rays, it means you return +1 first, and And the union of them is the model It's a good exercise to do. Take that home and try to find, And you'll find that although the break in this case the break And the reason is that for two points, know the ray can be here. So they are both minus. The ray could be here. They are both plus. The ray could be here. It's minus plus. But now, use the negative ray So now you can shatter two points. And you would fail only for the three different, because you cannot So you will get-- and the When you do the break point of the blue bound here. You will get that to be squared. Pretty much like here, because we have directly to squared. I don't care whether the 3 is coming positive and negative rays. It's 3. Therefore, the blue bound If you compute the number of dichotomies growth function, it will So there will be a discrepancy between growth function, to quadratic So there are cases that And as a matter of fact, this rather than the rule. In most of the cases, there MODERATOR: And this question drives It says, we have been focusing on to E_out, not in the So using our hypotheses, there are just training data as the real data. Why is that? PROFESSOR: This goes back to into the two questions. There was one question which We are trying to get E_in Why do I need that? Because I don't know E_out, and That is simply an unknown And I want to work with I cannot minimize something So if the theoretical guarantees tell me if I minimize E_in, E_out Then I can now work with a quantity That's the first part, that The second part is the practical. Now, I am going to go and This is the second part of it. MODERATOR: Also, they're asking if-- can you clarify more, why PROFESSOR: The VC dimension, I didn't say that word &quot;VC I said every building block that However, the good news is, what is The VC dimension. You will be completely content with the VC dimension, and weren't OK? MODERATOR: Yeah, the crowd is digesting the lecture. PROFESSOR: OK. As I mentioned before, if you didn't discouraged. It's actually very sweet material. And you can look at the lecture again. And you can read the proof. And you can do all of the homework, This is the most abstract, or the of the entire course. And if you get through this one, and good shape as far as the There will be mathematics, but it will Friendly, as in less abstract. For someone who is not theoretically mathematics is, the less they cannot relate to it. So this one has the abstraction. The other mathematics will be MODERATOR: What was wrong with the PROFESSOR: OK. Basically, the top statement It was my way of relating what has already happened. There used to be M in place So the growth function is here. There used to be M. So the easiest happening with the theory, is to tell M out, and replace it with this. As usual, it's not that easy. Even remember with the Hoeffding, here and the 2 here? Well, you have to have them, in order So for the statement to be true, we really didn't change the essence of a little bit different by changing And therefore, we have a proof And it captures the essence of that. I just didn't want to bother telling you the first place, you would have Why 4? Why 2? What is this 1/8? And forget about the essence. So the easiest way to do it, This is not the final form, Until you get the idea: indeed, But oh, in order to replace it, that we argued for. So I need 2N. Oh, and now the bigger samples are not of them is tracking the actual So I need to modify these So it becomes much easier to swallow. The technicalities will come in, in order MODERATOR: OK. Can you review the definition PROFESSOR: B of N and k. Assume you have N points, and assume So you're assured that no possible patterns on them. After these two assumptions, make You don't know where this came from. You don't know what space You don't know what the You just know that in your setup, that is the N here-- and the break point is Under those conditions, can you Can you tell me that the growth be bigger than something? That something is what I am So what am I doing? I'm taking the minimal conditions I have N points, and k And asking myself: what is the maximum have, under no other constraints, constraints? And I'm calling this B of N and k. Why did I do it? First, it's going to help, being an upper that has a break point k, because The second one, it's a purely So I have a much better chance of hairy details of input spaces, and And that is indeed, what ended We had a very simple recursion on it, And that formula now serves as quantity, which is the growth function situation, an input space, MODERATOR: Also, a particular question Slide 5. The question is, why does k not N to N minus 1? PROFESSOR: OK. Here, if you look at x_1, x_2, up to columns can have all These k columns could involve the last first N minus 1 columns. Just no k columns whatsoever can So when I look at the reduced one, N columns of these guys can have Because that would qualify as So k doesn't really change. The only time I had a different k that, if you have k minus 1 points which the smaller set, then adding the trouble with k columns. So for that, I needed an argument. But in general, when I take the And the k columns could be anything. Could be involving the last column, or Could be the first k columns, MODERATOR: How does this formalization PROFESSOR: Again, this So the classification of And as I mentioned, the entire analysis, extended to real-valued functions. It's a very technical extension that, in the insight. And therefore, instead of doing that and gain very little in terms of the regression functions, I am going to which is the bias-variance tradeoff. It will give us another insight into the real-valued functions directly, And therefore, I think we'll have both looking at it, and covering MODERATOR: There's this person that the bottom line that we can prove cannot learn everything? PROFESSOR: OK. We proved learnability under a condition When you say learning everything, about the target function. So the target function is unknown. What I am telling you here is that, if point, I can tell you that if you have E_out for the hypothesis you pick, It remains to be seen whether you are a level that will make you happy. I will never know that until So if the target function happens to be random-- unlearnable, you are not generalization question. The generalization question is I didn't bring it up here at all. It has to do with the The target function will come in-- will be small. I know that from the generalization Can I get E_in to be small? If the target function is random, you extremely difficult to fit. And you are not going to be able But at least, you will realize that that particular case. And in another target function, you will E_in went down. So the question of whether I can learn is independent of the target function. The second question is very much the good news is that it I can observe it, and realize how MODERATOR: Also, going back to a previous to multi-class problems? PROFESSOR: Basically, there inputs or the outputs. There is a counterpart. And instead of saying break point, And dichotomies, they are You have real values. You have no real values, so order to be able to reduce But the same principle applies, function you have. MODERATOR: I think that's it. PROFESSOR: Very good. Thank you, and we'll