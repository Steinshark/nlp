&gt;&gt; Hey, come check our next show it's on distributed Welcome to another episode Today we're going Sergey about Orleans Okay. Yeah. So, how about you quickly introduce yourself and then we'll go into the topic. &gt;&gt; Sergey Bykov. Orleans for many years now. To the whole story of getting it to open source Oh, happy, always &gt;&gt; Yeah, and we actually the open sourcing, &gt;&gt; Yeah. We have learned &gt;&gt; Yeah, we went a little bit before and yeah, that was fun. &gt;&gt; Always one of the fun because I was shocked like of let people glowing Don't you think from the backend but in the open that's what &gt;&gt; John, we we're still doing Actually, on that note, I know with our that I'm amazed actually at the number of that are working on the project. Have you had any success with &gt;&gt; Yeah, so, we have So, we have the number both the leisure side Like, I keep mentioning this guy, Dimitry, we merged over hundred &gt;&gt; Oh, my gosh. &gt;&gt; We focus on performance. We counted just through we'd double our [inaudible]. &gt;&gt; Okay. &gt;&gt; We count on performance. &gt;&gt; Yeah, that's super important. We have somewhat similar &gt;&gt; Oh, we have Ben. &gt;&gt; Yeah, we have Ben and presumably Ben's probably help &gt;&gt; Of course. &gt;&gt; So, how about we talk about what Orleans is Also, I just recently talked So, be good at some point to describe any similarities &gt;&gt; Okay. So, how do we explain Orleans in a couple minutes. &gt;&gt; Yeah, couple of minutes. &gt;&gt; That challenging, let's try. So, it all starts with good old days where server that was holding to a state and everything easy to manage locks. This whole model fell probably 20 years ago Because the moment you you have two copies have nothing in common, So, the world swished to stateless where you stateless business logic, storages, where everything It's inefficient read data for a request, right? So, you have conflicts, requests come to So, at the end of the day, you overload your storage. &gt;&gt; That's bad. &gt;&gt; Yeah, and of course &quot;Yay, we're going write directly,&quot; and then of cache and validation, So, you deal with two storages. So, the Dooley's model is saying, based on this idea that let's put stateful middle tier which have this virtual memory space. Essentially, where this objects will leave as if they're So, the coldest limitations of a single server machine doesn't scale, move to the cluster model. If something fails, that's &gt;&gt; Now, does it become The nice thing about the first slide that you although it has the expense of the system to the storage on throughput &gt;&gt; Yes. &gt;&gt; Yeah. So, with this system, well I need 3x of the cost to maintain this system,&quot; &gt;&gt; No, that's unfair. I because you need to have it's all you and and overhead of messaging, but you don't have to multiply. You can still have if you have 10 servers &gt;&gt; I see. &gt;&gt; That's the idea. we arrive to is like this. So, you have a cluster many these independent objects, we've called them grains in Orleans that leave they isolated, and they talk to But, because they're isolated, now we don't care if they or in different servers. So, from the users, developer perspective, So, we have this illusion but you program &gt;&gt; Okay. Makes sense. &gt;&gt; I can really show code, so the grain starts with which declares what kind They will have to be in sync the TPL benefit from all of that required me These objects are asynchronous. &gt;&gt; Right. So, is there which is like get me &gt;&gt; Yeah, that's So, how do you call a grain. You say give me a grain that implements this interface Then, to use meant specific and stable it could be e-mail, it could be Social Security number, Let's say, give me which in fact is and you can immediately &gt;&gt; Right. So, I see that when you get a new grain that So, that they're always &gt;&gt; Yes. &gt;&gt; For new grains, and then, the operations are Are there cases where you let a grain rest, and then get back. Then, that would if it's like currently residing on one of or that's the wrong way &gt;&gt; I think it all be So, implementation is simpler, just the clause that implements the interface everything The key thing here is that, You don't have to protect you can increment it and &gt;&gt; Make sense. That's more &gt;&gt; What? No, it's a guarantee. So, they SayHello will two threads in parallel &gt;&gt; I see. So, even if for example in there, will that not run on you're not allowed to do &gt;&gt; You can do different test. Test is always an exception. It doesn't respect- &gt;&gt; Okay. &gt;&gt; But, there is a way The key is, they will Within the context single grain there will always be serialized about &gt;&gt; Okay. &gt;&gt; But so, the key here it's a logical construct. So, user email, or phone number, and logically loose forever. So, you can always You don't need to create. You just say, &quot;Give me The grain may not be It can be just have But, the runtime will create execute all the calls, wait for it to be unused and then remove from &gt;&gt; I see. So, what I the grain doesn't really persist over time in the sense The fact that you again is not super meaningful, it's the data that it represents that is the more meaningful &gt;&gt; Yes and no. The state but also the runtime we call them activation, instance in-memory in Like a single instance in the single usable grain to So, you have both persistent which you can keep there contributes to low latency because you don't for a request anymore. &gt;&gt; Okay. &gt;&gt; You get more for that because this grain can talk which is a memory, you don't It's a very, very &gt;&gt; Okay. Makes sense. &gt;&gt; So, we end up with this cluster that actually handles a sliding &gt;&gt; I see. &gt;&gt; Which you gives you You only have memory used for these grains that are used right now or were used recently. You want to keep in-memory but other than that, you don't have to have resources, you don't have to put all your users' memory. &gt;&gt; I see. So, in we talk about like sparse, sparse allocation of drives. It kind of feels like this is a sparse allocation the entire universe that you might be trying have a million grains But there's only like 10,000 So, but you still represent the case that this million or the other whatever, 190,000, that they exist, they haven't been deleted &gt;&gt; They all exist the whole time, so that's why we call them virtual actors, like It stays is in page file, kind of a calling, but you can always get &gt;&gt; That's a good analogy. &gt;&gt; This is actually a difference with you mentioned Akka.NET. So, Akka or Orleans called There you explicitly So you would create, say create user actor X and then usually it needs to leave and then that the actor may create and then you to remove So, this whole is on use to a developer. &gt;&gt; I see. So more explicit. &gt;&gt; It's more explicit, it's more space to make mistakes because if something failed, Here, in this model, without any change, if right in this picture then it's only normal event because &quot;Oh, we lost actors we can immediately recreate &gt;&gt; Right. As long as to a database of some kind, then you're good to go. &gt;&gt; Yes. The key is that any application code to recover or to react to you just write the code for this class that gets activated, can persistent state, can do &gt;&gt; So, we saw with looked like for a grain, I think it was just her presumably there was reads Now, do those go through between the grain and the database or as I completely own writing to the database and the &gt;&gt; Both choices are available. So, you can go simplistic ecological say this is the property backlogs and this is the state Then we have a notion of providers, you declared So a user grain class a provider or Azure Table Then you just say right state, you update his properties call a single method But if that's not enough for you, if you want to be more advanced, you want a low partial state, you can just write any code &gt;&gt; Okay. So, a lot &gt;&gt; Yeah. &gt;&gt; Okay. So, how about we where Orlean's is &gt;&gt; In terms of space or &gt;&gt; Well, I guess you and little bit earlier which the main cases are desktop, mobile, server, cloud, and IoT. So, in which ones of Where's its sweet spot? &gt;&gt; Well, it's definitely Cloud is the natural place &gt;&gt; Yeah. I mean, from it's clear that elasticity both from the standpoint also from the standpoint and pretty much all the I mentioned don't have &gt;&gt; Right. Then from when we started Orleans the goal was the cloud That's where you have these that can guarantee that &gt;&gt; It makes sense. So, I know from having talked the big high profile users of Orlean's is the Halo service. I think it's been using Five years or something like &gt;&gt; Six, more than six. &gt;&gt; Yeah. Okay. Has Are they still happy with it? &gt;&gt; Absolutely happy. other people because which is a bigger scale then I should be fine with it. So it was a huge kind &gt;&gt; Right. So, is it the case that or I shouldn't put in a short number of, yeah, how would you describe like why it is that the folks at Halo What's the specific problem &gt;&gt; There are two points. We touched on scalability and that was one of But the other main goal was So, because you code to do a lot of handle failures or for example we propagate exceptions through So, you can write try catch As a result, you don't deliver failures and make So, developer higher and some people say they write some people claim I don't know what &gt;&gt; Somewhere between &gt;&gt; That's my feeling. to efficiency of developers work but also the fewer bugs you introduce. &gt;&gt; Absolutely. &gt;&gt; So, it's used in Has it also been adopted &gt;&gt; Yes of course. So, we had a public preview and then we open source Very wide range of applications, some things I wouldn't One of my favorite Energy Management where they have a lot of green power during distributed to So, they turn them on and using the system, right? Now, in release to excess energy and store Everyone thinks that we need the battery while you and then you heat water for free. That's fascinating project. a couple million Mouse Traps IoT. Send the signal that, there is a mouse suddenly &gt;&gt; Oh, literally. &gt;&gt; Literally. &gt;&gt; Mouse Traps. &gt;&gt; Yeah. &gt;&gt; What is it though about, I can kind of grasp of What is it about or the sun energy transfer story? &gt;&gt; The way can I explain it is, a leans shines when contexts and use a recession device. So, you have this water heaters They have their own properties. &gt;&gt; I see. &gt;&gt; Then you send requests to that specific context and say, &quot;Turn On,&quot; &quot;Turn Off,&quot; Because it's in memory, &quot;The Ghost Device&quot; we So, refraction of a device has a copy of state. You can leave there very low latency operations. &gt;&gt; Yeah. I don't think but with those kind of it's like Bi-power and then pump water with that cheap power and then, run the turbines during &gt;&gt; Kind of the same. &gt;&gt; Yeah. It's exactly. &gt;&gt; In reversal we did in Hawaii. &gt;&gt; Yeah. For sure. So, if folks are interested maybe just to try and to see what it's like are Where would they go to try &gt;&gt; Yeah. So, just go to Orleans, you'll find it there. We also have the Gitter chat That's where community hands out, and that sort of gives a lot they go and talk in real time and and hear their ideas So feedback comes in form issues and at the same time there where people just come and say. Oftentimes, they &quot;Thank you for you and &gt;&gt; Yes. It's very nice. &gt;&gt; It's kind of &gt;&gt; To get that. So, I guess One is, what are your aspirations for what you want to do with Orleans next? Then the second one is, just any closing comments. &gt;&gt; So, we just had a big like, first really major release The goal there, was .NET so people can run want. .NET Core has Linux It was a big deal for us when we restructure than we matured, that could be injection friendly, and be much more serious about And as part of that, we introduced data which keeps blowing once they distribute transactions that's completely impossible. They're slow and we that low connection scale So, that's the next big We have beta working and internal team that does virtual commerce &gt;&gt; Right. Make sure you take the right amount of money in one account and put in &gt;&gt; Yeah. They have Gold Coins for Cannonballs to spend Gold coins So accounting rules &gt;&gt; Well, I'd be happy I don't have to get No problem there. &gt;&gt; In closing, I would invite everybody to It's a great place. GitHub community, that sometimes don't even use Orleans yet in their day job. Just like the crowd of people because you in my opinion, track people direct an experience So you don't get people that, just do like lazy job, So, you have this whole that really know whether you're really passionate and other helping and So, I would advise and just check out their routines and ask questions very friendly. We're there, my team is there. &gt;&gt; That sounds like &gt;&gt; Yep, we mentioned joints. I had no problem hiring &gt;&gt; Yes for sure. Yeah that's where this whole That's a hiring mechanism. &gt;&gt; No. I mean it sets the bar. So it's like, there's the code and everyone now do your sloppy job or you try to do as best as you can, and you learn to accept feedback, it's not like the first thing defensive and I'm sure you &gt;&gt; Yeah. We're not doing that. Not being defensive. Well, thanks for coming by. It's nice to see you were on up having kind of two years ago on this. So take a look on GitHub, I think it's &gt;&gt; That's right. &gt;&gt; That's right. Because So, take a look, it's one of, basically, .NET Core's and give it a try. Thanks for watching another