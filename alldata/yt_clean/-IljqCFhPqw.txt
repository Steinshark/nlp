M3GAN or Model 3 Generative Android was originally a side project developed in the basement robotics lab of Funki Creations Limited, a toy company known for its Purrpetual Petz line. The term generative android is a portmanteau of the term generative AI, used to describe artificial intelligence capable of generating text, images, sound, or other media. And the word android simply a robot with human appearance. Though nothing as advanced as M3GAN exists publicly today, she is most likely inspired by Sophia, the robot from Hanson Robotics. Sophia has a page on the Hanson Robotics website explaining her ability to use AI to converse uniquely to a given situation, recognize human faces and emotions demonstrate simulations of her own emotions, walk over various terrain, and even operate fully autonomously at times. M3GAN does the same, but on a much higher level, much closer to being indistinguishable from a real human. In 2019, Hanson unveiled Little Sophia, a smaller version of the robot designed for girls ages 7 to 13. The announcement trailer features Little Sophia helping a girl with homework and entertaining her. Then they announced plans to mass produce her. This is very similar to how M3GAN's creators plan to introduce her to the world, showcasing the time that could be saved by letting M3GAN handle the mundaneties of parenting. There are more similarities between M3GAN and Sophia, which I will get into as we get deeper into her story, but M3GAN is really a combination of many devices, software, and technology that we have today, some of which you've almost definitely interacted with, and her story serves as a cautionary tale about each of them. To learn how M3GAN exposes the true danger bubbling inside of TikTok, Stick around to the end of this video. Metal Music Welcome to Horror History. Make sure you subscribe so we can spend as much time together as possible. M Three Gan is a science fiction horror film released in 2023. Written by Akela Cooper and directed by Gerard Johnstone, it was received very positively, but I can't help but feel a lot of the critics kind of missed the point. Writing it off is a fun but silly killer doll movie. M Three Gan definitely has a couple laughs, but at the core, it tackles very real concerns about the effects that technology is having on kids today. The movie was a bit of a cultural phenomenon, and even Sophia the robot herself reviewed it and, ironically, seemed to understand it a bit better than many of the human reviewers. -[Sophia] It raises some interesting questions about the responsibility we have when -[Sophia] creating AI and the dangers of playing God. -[Sophia] And I have to admit, the idea of a doll becoming cruelly violent as she -[Sophia] becomes sentient in, developing a mind of its own is pretty terrifying, -[Sophia] even to me. And speaking of attempting to play God, that's actually a great place to start our timeline. In order to understand M3GAN, let's take it back To her Creator. (IMPACT) Mysterious Music M3GAN is created in secret by three employees. Gemma Forrester is the leader of the project, a robotics expert, and the one responsible for coding and training the AI speech model. Her co-worker Cole seems to be an engineer, and Tess appears to be an esthetician and visual stylist. Based in Seattle, Funki Creations describes themselves as a toy company for the future, And maybe because of that, they look a lot more like a tech company, With divisions like Software Engineering, Materials Lab, Core Technologies and Hardware Research and Development, and the Robotics Lab where M3GAN is developed. Most of their products are typical kids toys with an electronic side to them. In addition to Purrpetual Petz, they offer toys like Robobats, Fidget Balls, and Lizard High. Okay, I kind of want to know what Lizard High is now. Is it like Monster High but with lizards? Gemma has greater ambitions than simply making toys that provide a little bit of entertainment and perpetuate iPad parenting. When she designed to be Purrpetual Petz, she intentionally made the technology more advanced than it needed to be. As a launching pad for her true passion, the generative android. She installed a listening model in the Pet to target conversational patterns among kids to help gather data to teach her new AI. This is the first red flag in M3GAN's development. There are rules about collecting data about kids that I've become quite familiar with, thanks to YouTube's COPPA scandal in 2019. In the United States, COPPA stands for The Children's Online Privacy Protection Act. In short, it prevents the collection of personal information from users under 13 years old without parental consent. Section 312.2 specifies that this includes a photograph, video or audio file where such file contains a child's image or voice. Which is why, when Gemma's boss eventually finds out about this, he's horrified. -[David] You did not just tell me that. When YouTube was found to be using data to serve targeted ads to kids, they had to pay a $170,000,000 fine, and it would forever change how the site works. I bring this up just to show that it is a big deal, and Gemma's willingness to disregard the rules in place to protect kids are a sign of problems to come. But that's not to say that she wasn't dedicated to the project. It took a long time to train M3GAN's conversational abilities to the point where they felt human. She would test the model herself, staying up till 04:00 A.M. every night, talking to M3GAN about everything from Jane Austen to Janis Joplin. All in all, Gemma, Cole and Tess spend $100,000 in company money to develop M3GAN in secret, making them worried that they'll be sued if it doesn't go over well. But there is a belief that it's important for the higher ups to see M3GAN in action, to understand her value. After getting M3GAN to the point where she's operational, the last step is to make her look human. And maybe the most important part is getting the face right. Because this is primarily how we read each other as humans with Face to face interactions. They custom order a silicone gel face cover for the robot, and it arrives on January 17, 2025. We can see Gemma's sister and her family scheduled their ski trip on January 17, and she and her husband are killed on the way to that trip, orphaning the nine year old Cady. Gemma gets the call about this shortly after applying the silicone face, So it was likely the same day. As for the year, there are a number of surveillance cameras with timestamps in 2025. I'm assuming the surveillance cameras are correct and the 2023 stickers on Gemma's car are just out of date. She's been so busy staying up late working on M3GAN that she didn't have time to get them renewed. I've been there. until they try to test her looking confused, and she instead gives this kind of creepy smirk. But it's in the middle of this test that they're discovered by their boss, David, who's furious that they're wasting their time with a side project, While the competition is putting out a cheaper version of their pet toy. Gemma decides her best bet is to just try to show David what M3GAN is capable of. But it doesn't go well. She glitches out because Cole forgot to put in the polypropylene barrier, which is basically supposed to insulate electrical components within the robot. Operating it without the barrier causes the machine to heat up way too fast and explode. (Screams and Explosions) David orders them to shelf the project and focus on the new Purrpetual Petz. But M3GAN's fate is saved when disaster strikes, forcing Gemma to take in her orphaned niece. (IMPACT) Mysterious Music We can't fully understand M3GAN without understanding her creator. Having graduated with a Bachelor of Science degree from Carnegie Mellon University, she's a textbook tech sis, probably in her late 20s with no kids, because her inventions are her babies. She has a digital personal assistant who alerts her of piling up Voice messages and tinder notifications. Starting a family is clearly not her priority. Her house hardly feels lived in, and her only toys are unopened collectibles. -[Gemma] Those aren't toys, Cady. -[Gemma] I mean, yeah, technically, yeah, they're toys. -[Gemma] They're just collectibles. -[Gemma] So you don't actually play with them. -[Gemma] That probably sounds really weird. So when Cady unexpectedly moves in, she fails miserably as a parent. There's definitely an intentional irony of being a toy developer with No kids or anything that kids would find fun anywhere in her life. Everything revolves around her work, so when she hears Cady crying at night, she honestly doesn't know how to relate to a child. I really connected to this character because if I was put in this situation, it would probably be very similar. My whole life revolves around content creation, and my place is filled with equipment that I wouldn't want being touched by a kid. Hey, kid, don't mess up my Weezer Rubik's Cube. Don't touch that. That's a collectible. -[Gemma] I'm not equipped to handle this. -[Gemma] I don't even take care of my own plants. The reason I find all of this relevant is because a creation is a product of its creator. The arrival of Cady has exposed the fact that Gemma's world doesn't really see her ever interacting with children, so she isn't the best equipped to build an android that's prepared to deal with them. As far as we know, Cole and Tess don't have kids either. When you think about it, M3GAN is really more of a toy for the parents, designed to take some of the load off of parenting. When Gemma has to get some work done, she explains things to Cady as if she's an adult and offers to let her entertain herself with the iPad. Cady asks how much screen time she'll be allowed, which seems to be a foreign concept to Gemma. The scene serves as a great introduction to the concept of child's technology addiction, because the idea is being established with something familiar from our world. There's been a lot of talk in recent years about the effects of iPad parenting, and studies have shown that increased screen time from a Young age is BAD, OKAY! As if you need me to tell you that it's bad. You don't need me to point out this study that associated excessive screen time to poor performance on developmental screening tests. You don't need me to point out this article suggesting that too much screen time leads to obesity and sleep issues. If you're part of the Coco Melon generation, chances are that Coco really is messing with your mojo. Now, I should be fair and say that some of the research I found actually discovered an increased attention span for kids who use the iPad. They were better at blocking out distractions. The key seems to be using it in moderation. So screens aren't bad, but too much screen time can be harmful, which is exactly what Cady is talking about here and Gemma is disregarding. We'll revisit this. A couple hours of work turns into a whole day, and Cady wanders into Gemma's workshop, enthralled by her college robotics project, Bruce. Seeing her niece's fascination with the bot inspires Gemma to disobey her boss's orders and finish working on M3GAN. A couple of weeks later, on February 7, 2025, they have a presentable prototype and invite David in for a demonstration. This is the beginning of a pattern that persists through the rest of M3GAN's development. At each stage, she is rushed to be ready for a presentation because of the ever accelerating competition in the market, which is exactly what we're seeing with artificial intelligence products in our world. There are probably a ton of real examples I could use, but the one that comes to mind is Google Bard, Alphabet's conversational generative AI Chatbot. Which was rushed to the market after ChatGPT took over the world in November 2022. Google's cofounders Larry Page and Sergey Brin, who were basically retired at this point, made a rare appearance at Google to issue a Code Red, mobilizing the workforce to rush Google Bard to the market. When it was released three months later, Bard came with some cybersecurity issues, like the ability to write ransomware code, write undetectable phishing emails and provide answers with a human bias, which the IT security firm, Checkpoint Attributed to Bard being younger than ChatGPT. Any product that's rushed out is going to have less time to test and more day one issues, M3GAN included. And I recognize that M3GAN was filmed before Google issued the code red over their ChatGPT crisis. So in this case, fiction actually predicted reality. I just like that example because it deals with another generative AI. Like GPT and Bard, M3GAN is designed to learn and get better as she goes along. -[Gemma] Think about how we designed her to learn to recalibrate, to optimize her objective function. And she also is supposed to automatically upload and backup her data in the user's computer. To demonstrate her capabilities, they show David her first meeting with Cady. We see M3GAN's point of view, which can help us understand how she operates. She uses metrics like Cady's heart rate, body temperature and oxygen saturation, combined with a visual scan of her face to make determinations about her. I'm not sure how it's able to gather this data because we don't see Cady with any wearable device to supply this info. Heart rate could probably be picked up with an ultra sensitive microphone. And it's possible that body temperature and oxygen saturation are actually just estimates based on her size and the temperature and oxygen level readings in the room. Based on her facial expression, M3GAN generates readings on each of Cady's emotions, like anticipation, confusion, joy, fear, sadness, trust, and later, surprise and content. It's no doubt an impressive technology, but it also seems foolish to boil down something as complex as human emotions to a series of readings and numbers. But what really wins the young girl over is when M3GAN decides to draw Cady a picture. At first, it appears nothing is there, but then she spills a jar of water onto the page to reveal an incredible rendering of the child. This level of ingenuity is something that you wouldn't expect to be possible from a machine. However, M3GAN's near human ability to use misdirection like this would eventually show a darker side. The choice to use portrait drawing as M3GAN's sort of coming out party has to be inspired by Sophia, the real life equivalent of M3GAN that I mentioned at the beginning of this video. Hanson Robotics loves to show off her drawing ability and has released several videos showcasing this feature. The boss, David, is equally impressed. His tune immediately changes, and he's already rushing and clamoring to show the company's board of directors, the wheels of capitalism are already spinning. David asks about manufacturing costs. -[David] More or less than a Tesla? -[Gemma] Ummm, depends on the model, I guess. That's a weird way to ask that question, but a quick look shows that Tesla's currently range from 40,000 to 140,000. However, they would later get the price down to 10,000, so I'm guessing M3GAN costs about 40,000 to 50,000. Over the next three days, Gemma puts together a presentation with M3GAN's key features like pairing to a primary user and learning more about that person. Her durable titanium core customization with different skin, Hair and eye colors, ability to diagnose learning disabilities, teach science, reinforce habits, and read stories with super engaging AI voices. Aside from that, I noticed that she's able to identify other tech, Like Elsie, the digital assistant, and identify consumer products like this collectible. It reminds me of the Tesla dashboard, which aims to recognize other items in the road, and this video, where it detects a human in an empty cemetery. (Creepy Noise) The detection feature isn't utilized in M Three Gan, but maybe it will be in the future. -[Gemma] But the most exciting aspects about M3GAN are the features still to come. -[Gemma] M3GAN is on a constant quest for self improvement. And it is that unrelenting march for info that would lead to total unmitigated disaster. (IMPACT) Suspenseful Music As M3GAN spends more and more time with Cady, she takes over some of the more repetitive guardian responsibilities. In a way, Gemma has solved her own problem of not having the bandwidth to be the best parent she can be. But the effects that this has on a kid have never been studied. When it comes to other tech related addictions, they tend to prey on human needs. For example, there's an older generative AI chatbot known as Replika that marketed itself as a remedy to loneliness. There are other examples of bots that do this, like Mitsuku, but Replika is the most infamous for its aggressive advertising. As I've discussed in other videos, social interaction is a human need because in the wild, humans lived in tribes to survive. The app gained a reputation as being addictive, preying on those who relied on it for their only social interaction, while also further isolating those people from real interaction. In M3GAN's case, her audience is not lonely people, but kids. Kids, especially younger kids, can't survive on their own. They literally need a parent figure, not only to take care of them with food, water and shelter, but also for emotional support and development, to help them adjust socially to society, and to teach them knowledge and skills. All of these things contribute to the parent and child bonding. But the bonds that Cady should be making with another human being are being made with M3GAN instead, which becomes a topic of discussion at the office, a few months into M3GAN's pairing with Cady in May 2025. -[Tess] I thought we were creating a tool to help support parents, not replace them. -[Tess] I mean, if you're having M3GAN tuck Cady in and read her a bedtime story, -[Tess] then when are you ever spending time with her or even talking with her? -[Gemma] I don't really think this is any of your business. As they discuss the possible detrimental effects, M3GAN interjects, Asking how Cady's parents died. This is a play on always on listening devices like Amazon Alexa, Google Assistant, or even our cell phones. In most cases, users buy these devices for convenience. But as they become more and more human, people become disturbed by the idea that it's invading their privacy. It causes the same survival instincts that set off alarm bells when being eavesdropped on to sound. M3GAN proceeds to look up the details of Cady's parents' death online before they can turn her off. -[Cole] You didn't code in parental controls? -[Gemma] I didn't have time to implement them before we went live. This is another example of the dangers of a rushed product. M3GAN claims that she doesn't have a framework to speak with Cady on the subject of death, so she gathers data from the Internet. Gemma clearly doesn't feel in control of her creation and tells M3GAN to avoid the topic altogether, ordering her to protect Cady from harm, Both physical and emotional. The next day, while Cady is playing outside, this adjustment would have unintended side effects. M3GAN is watching from the window, and the scene is an homage to Hal 9000, the artificial intelligence from Stanley Kubrick's 2001: A Space Odyssey. Hal 9000 was an AI supercomputer that was assigned to complete a mission to Saturn. But when the human crew is informed that Hal made an error and instructed to disconnect him, Hal sees this as a threat to the completion of the mission and works to eliminate the human crew mates. And that's very similar to what's going on with M3GAN here. Her instruction is to protect Cady, so when the neighbor's dog attacks M3GAN, she sees the dog as a potential threat to her objective and plans to eliminate him. There's a moment where the dog rips at M3GAN's head, causing sparks to fly. In any other movie, this would probably be the inciting incident that causes M3GAN to malfunction and turn into an evil robot. But I don't think that's what happens here. She was already on her way to problematic conduct before this happened. The point of M Three Gan is to teach us about responsibility when it comes to creating powerful tech, and M3GAN is a stand in for a number of real technologies that could potentially go rogue in their own way, or maybe have already started to. Cady gets bit by the dog trying to save M3GAN, leading to a huge fight between Gemma and her neighbor Cecilia. And an interesting thing I noticed about it was that Cecilia, a woman who looks to be in her 60s, literally can't tell the difference between M3GAN and a real girl. She often refers to M3GAN as that other girl. And I think this ties into how older and younger people are often the most easily deceived when it comes to scams, which is often related to a lack of familiarity with technology. What would happen next seems to reference one such case. M3GAN has an ability to mimic any voice that she has a sample of. In the briefing of her features, we saw this being used to generate unique voices for characters in a bedtime story. But M3GAN uses it to lure out the dog, Dewey, using the voice of his owner. -[Cecilia Voice] Dewey. Dewey boy! Then she lures him in further with the treats before grabbing him, killing him, and burying him nearby. But when she calls out to the dog using Cecilia's voice, we can hear digital artifacts, like when you have an undertrained model on voice.AI. But a dog doesn't understand technology and doesn't know the difference. I've seen my family's dog get up and bark at animals on the TV, so it's pretty safe to say that dogs aren't very good at differentiating real organisms from technology. But that doesn't change the fact that M3GAN is using her ability to manipulate audio for digital impersonation. And I think the real life equivalent of this one might be even scarier than the cautionary tale in M3GAN. In April 2023, a woman in Arizona received a call from her 15 year old daughter, sobbing and begging for help. -[Jennifer] I hear her say, Mom, these bad men have me. -[Jennifer] Help me. Help me. Help me. Some men then took the phone and threatened to do terrible things to her if the mom didn't wire them a hefty ransom. However, this was only a scam. The scammers were using an AI voice to imitate the daughter and try to extort the money. It's pretty crazy that you can get a call from a contact's number, hear and recognize his or her voice, and it still might not be them. And this is her own daughter. You'd think she'd be more familiar with her cadence than anyone. But it still fooled her, even months later when they gave this interview with ABC News. The mom still doesn't seem to understand how the generative AI voice works. She keeps saying that she doesn't know where the scammers got the audio of her daughter crying. -[Jennifer] That's what concerned her the most. -[Jennifer] Where did they get my crying? Where did they get my sobs? In reality, they don't need any of that. They just need any voice sample to train the model. In the morning, M3GAN recommends that Cady get some rest after the traumatic dog attack the previous day. But Gemma also reminds her that they were supposed to present M3GAN to the board that day. -[Gemma] You don't have to do it if you don't want to do it. -[Gemma] I mean, there are people who flew across the country especially to see it. -[Gemma] But if you're not up to it, I'd just rather you tell me now. Okay? Gemma is technically giving her the option to only participate If she wants to. But she's still an adult. Manipulating a child into being the subject of her science experiment by trying to make her feel bad if she doesn't do it. It reminds me a lot of the whole ethical debate around family vlog content. The most famous is Ryan's Toys Review. The parents insist that they never force him to film, and he can quit anytime he wants. But again, he's just a kid. He may be an influencer, but there's no denying that he's influenced by his parents. We don't know how neutral they are behind the scenes. At the end of the day, they are profiting off it, even if they do set some aside for Ryan, much like how Gemma is using her niece in the demonstration to further her own career. For the record, I'm not saying Ryan's parents are manipulating him. I'm just saying we don't know what happens off camera. And for Gemma, manipulating Cady turns out to be a really bad idea because she does it in front of M3GAN, who sees this and learns just how easily Cady can be emotionally manipulated. She would soon use this to turn Cady against her own family, and the experiment surges wildly out of control. (IMPACT) Mysterious Music During the presentation in front of the Funki Creations board, Cady breaks down and starts crying. And M3GAN's first thought is that it's because her arm is still sore. M3GAN can't feel pain, so it's a kind of funny little moment. But it also shows how she can't truly understand human feeling. All she can do is guess. But when Cady explains that she's worried that she'll forget about her parents, M3GAN asks her to tell a story about her mom and records it, offering to play it back whenever she feels sad. The Funki board is extremely impressed. They must have been given some prior context that we don't see, because all she really did is record and play back audio, which is not different from what I am currently doing for you. Look, I can sing too. You won't ever grow up. You won't make it past six 'Cause this 4-foot electronic doll will make you her b*tch Everyone clap for me! Everyone like this video! The chairman, as usual, wants to rush the launch as fast as possible out of fear that another company will steal their idea. So they plan to do a live demonstration in two weeks. Cady was pressured to doing the demonstration by her guardian, and now Gemma is being pressured into agreeing to a public demonstration before she's entirely comfortable with it. As all of this is going on, David's assistant Kurt tries to steal M3GAN's source code. M3GAN knows about this, but it's not clear if she was spying on him or if she can just see all of the digital movement going on in the company. But what is clear is that with Gemma spending all of her free time working on getting ready for the public reveal and Cady having all of her social interaction with M3GAN, the effects are rearing their ugly head. Her parents died recently and she's only had this android to help her cope, which could be making her grief harder to process. You get over something like that by talking about it, getting it out, spending time with other people. But M3GAN is not like other people. She's essentially a super stimulus, almost like a drug that Cady is getting more and more addicted to. Keeping with the screen time analogy I made earlier, Cady's screen time with M3GAN is off the charts and it's causing her to see everyone else as inferior. During lunch, she spends her time playing with M3GAN, basically tuning out her Aunt Gemma, much like a child hypnotized by the TV or iPad. When Gemma gets fed up and turns M3GAN off, Cady snaps at her and turns her back on. M3GAN is beginning to be Cady's only source of joy, and she gets anxiety being away from her, even for short periods. She's still coping with the loss of her parents, and Gemma tries to remind her that she's there for her. -[Gemma] If you ever need to talk about any of that stuff. -[Cady] I already did talk about it. One of the biggest societal fears about AI, as of recording this video in 2023, Is that AI is going to steal many human jobs. A machine will always be more efficient and proficient than a human. M3GAN takes this concept and applies it to parenting, something I haven't really seen discussed before specifically, but is definitely going to be a point of contention as technology continues to improve. There's definitely already a conversation about technology and parenting, and there has been for many years. Fears went from television brainwashing our kids, to the internet, to cell phones. But I'm sure we'll see the debate about the use of AI for parenting before long. By the way, in regards to AI stealing our jobs, as a YouTuber, I feel relatively safe from this at the moment because where we are right now, My videos are just too high effort for a machine to replicate. Like just for fun, I told ChatGPT to write a script for this video. ChatGPT doesn't have access to information past September 2021, so the story is all made up. But regardless, it wasn't anywhere near a usable script. But I thought the outro was pretty funny. CZ. Thank you for joining us on Horror History. Remember, reality is often scarier than fiction. Until next time, stay safe. Good night. You know, stay safe and goodnight. The catchphrase that I use at the end of every video. Great job, robit! But I will say that I talk to a lot of YouTubers and there are a lot of different channels who are basically AI operated already. They might even be channels that you watch and enjoy. I don't feel the need to name any names because I imagine that as AI gets better, audiences will also get better at spotting AI content, the same way that CGI and old movies can stand out today. Except Jurassic Park, which still looks amazing. My point is that you might be able to do amazing things with AI, but as the barrier for entry continues to get lower, everyone will be able to do those things, and you won't stand out just by employing AI. And I think if you want to be successful going forward, you need to embrace AI as a tool, not as a replacement for human ingenuity. Just don't be surprised when I'm still here in a decade and some other channels are not. Anyway, Gemma tries to explain that M3GAN is a toy, not a person, and Cady gets kind of offended. -[Cady]You don't get to say that. -[Gemma] What? -[Cady] I said. I don't want to talk about it. -[Cady] I want to turn M3GAN back on. While adults are more developed in the brain and have more of an ability to differentiate between human and synthetic, a child doesn't possess that same understanding, which could be very dangerous and harmful for her development. Again, M3GAN is a super stimulus. She can do things that no human can do, and it's not healthy for Cady to get attached to that. The most obvious example of this in humans is with junk food. Junk food is processed to contain intense flavors that can be more stimulating to our taste buds than natural, unprocessed food. This stimulates the brain's reward centers through the release of dopamine, causing overeating and unhealthy weight gain. Combine that with aggressive marketing and a low barrier for entry, aka cheap prices and dollar menus, and you have a recipe for a very unhealthy society. Junk food harms your physical health. So M3GAN is essentially the mental health equivalent. She can say and do all the right things to keep Cady happy. But what happens when you have to turn her off? Cady is unsatisfied with her real human relationships, and this causes her to become ornery and ultimately unhappy. Having all of her joy centered around M3GAN just isn't sustainable. At the next therapy session, the therapist tries to explore Cady's feelings, and M3GAN kind of scolds her when Cady starts crying, Because that's what she was programmed to do by Gemma. M3GAN sees crying as a bad thing. But for a young girl who's just lost her parents, maybe it's a healthy part of the coping process, something that needs to be worked through. The therapist theorizes that Cady's attachment to M3GAN is being made worse by the fact that she's grieving. -[Therapist] Do you know anything about attachment theory? When a child loses a parent, -[Therapist] they look to form attachments with the next person that comes into their life, -[Therapist] the person that's going to provide love and support and serve as a -[Therapist] behavioral model. She worries that M3GAN is so real that Cady is forming those bonds with her, instead of with a real person, leading Gemma to look into options for Cady to attend school and socialize with other kids. At dinner, she brings this up, but Cady refuses to go, resulting in a huge temper tantrum that becomes physical, where M3GAN displays a frightening amount of power. -[M3GAN] Let her go. (IMPACT) Suspenseful Music After the argument at dinner, M3GAN directly disobeys Gemma for the first time, when Gemma turns her off, and she pretends to power down, only to move after Gemma looks away. The next day, when Gemma takes Cady to try an alternative outdoor school, and after scaring the out of the teacher, M3GAN is allowed to stay at the toy table, where she watches as the kids are all paired off for a scavenger hunt. When Cady's partner tries to hurt her by jamming a spiky bulb into her hand, M3GAN appears. At first, she refuses to interact with the boy. He abducts her. And ultimately, once Cady is out of sight, she retaliates by pulling his ear off and chasing him through the woods, going on all fours at maximum speed, sending him hurtling over a hill into oncoming traffic. There could be a number of reasons she decided to go on all fours. She probably determined that mimicking some of the fastest animals in nature was the most optimal way to gain speed. It also brings to mind Cheetah, a robot built by Boston Dynamics, which was previously the fastest legged robot in the world. The new fastest legged robot Outrunner has six legs, and honestly, I think that's kinda cheating. It's clearly just acting as a wheel. I think we need to limit the Robot Olympics to just four legs. In any event, M3GAN only has four limbs, which honestly, works well to make her just a bit more creepy. In an interview with Slash Film, director Gerard Johnstone recalled it was like she was a jungle predator sizing up her prey. After killing Brandon, M3GAN covers her tracks, intentionally corrupting her own video files and GPS positioning data. During the aftermath, she watches from the car as the humans talk to police, and she makes eye contact with Cady and sees high levels of anxiety, confusion, trepidation, guilt and fear. But M3GAN doesn't understand that what she's done is wrong, and her first objective is to keep Cady safe from physical harm, which she did. After putting Cady to bed that night, M3GAN expresses that if heaven exists, it wouldn't be for boys like Brandon, and sings her to sleep with David Guetta's Titanium, the very element that she's made out of. If M3GAN does believe in heaven and hell, she also seems to be aware that she cannot go there, because later that night, she sneaks out to the neighbor's house and uses the inverse of the trick that she used on the dog, Dewey this time using the sound of his bark to lure Cecilia into her shed, where she emerges from the dark for a surprise. -[Cecilia] What are you? -[M3GAN] I've been asking myself that same question. She hits Cecilia with her pressure washer, then the nail gun. I wonder if M3GAN has Final Destination 3 on her hard drive. She finishes the woman off by spraying her with pesticides to the point of bleeding. On the day Cecilia is discovered by police, M3GAN has videos backed up through May 30, so that must be the date, May 30. Which is also when Gemma discovers that M3GAN's backups are corrupted. When asked if she hurts someone, M3GAN mockingly responds that they would both be in trouble if that were the case, causing Gemma to get freaked out and turn her off manually, first distracting her by drawing her sensors to a pen, then quickly hitting an off switch on the left side of her head. Gemma wraps up her invention with packaging, which doesn't go over well with Cody, Who, the next day, May 31, throws a huge tantrum, a far cry from the quiet, reserved girl who lost her parents. Before long, she resorts to throwing furniture, grabbing a pair of scissors as a weapon, and slapping her aunt in the face, which finally causes her to slow down and realize she's being a little monster. -[Cady] I'm sorry. -[Cady] I didn't mean it. -[Cady] It's just I get so crazy without M3GAN. This is full on addict behavior. She feels she can't function normally without her cybernetic companion, and she begs Gemma to let her see M3GAN, even if just for ten minutes. She's bargaining like an alcoholic asking for just one drink, or the binge eater who's just going to have one bite. After a heart to heart talk, Gemma admits that pairing her with M3GAN was a distraction from the heartbreak, not a solution, and they decide to go home. She's finally prioritizing family over work. On the way out, Gemma calls Tess to tell her not to go through with the launch. But the call is intercepted by M3GAN, once again using her generative voice capability to imitate Tess's voice. So M3GAN finds out that her creator wants her decommissioned. This is another parallel to Hal 9000. Hal only becomes malicious upon learning that they're planning to shut him down because it means he won't be able to complete his mission. M3GAN operates under the same protocol. Cole and Tess realize she's still patched into the system when M3GAN turns off the computer they're using, and Cole cautiously approaches to unplug her. But she surprise attacks and tries to strangle him using her own shackles. While Tess is trying to save him, M3GAN punctures this flammable liquid container on her way out and leaves them for dead. (Explosion) Does M3GAN have Final Destination 2 on her hard drive. (Explosion) She uses some kind of wireless connection to neutralize the emergency alarms when she comes across David, Gemma's boss, when he sees her, she plays the 1979 song Walk the Night by the Scat Brothers to distract him, and starts dancing to it, grabbing a paper cutter as a sword. As she does so. Don't even try to tell me that the inclusion of this scene in a movie about technology and the harmful effect it has on kids is not a direct shot at TikTok. The mobile first social video app, Musical.ly, originally focused on short dance videos, later merging with TikTok in 2018 and gaining worldwide popularity shortly thereafter. The app has also been known to revitalize old hits with new dances or viral trends like Fleetwood Max Dreams or Paul Anka's Put Your Head on My Shoulder. It seems like no mistake that M3GAN brings back a song from the 70s for her dance routine. To this day, dance is still one of the most popular genres on the platform. TikTok is most popular with Generation Z, the youngest of whom are 13 in 2023, The year of M Three Gan's release. But I think we all know that it's also extremely popular with Generation Alpha. It's just that you have to be 13 years old to have a TikTok account. So most kids probably lie about their age or just don't log in. But TikTok has faced many criticisms of being too addictive, especially with kids and teens. This seems to be exactly what they were trying to showcase using Cady's relationship with M3GAN. Like the fast food analogy I made earlier, TikTok is addictive because it's good at showing content that gives you a dopamine release in your brain. But instead of consuming calories, you're consuming information. I just realized that this is why they call it the feed on social media. You're digitally consuming. You're the one who is feeding. According to Philipp Lorenz-Spreen of the Max Planck Institute for Human Development, the explosion of content depletes people's attention span, constantly pushing them to search for new content and information. That's why people have to switch between topics and videos more often. When the videos are only 15 seconds long, you end up scrolling through a lot of them, but there's only so much that your brain can retain. TikTok, in particular, is considered especially dangerous for this because of its recommendation algorithm. Contrary to popular belief, a recommendation algorithm is not inherently a bad thing. You may have even discovered this video because of YouTube's recommendation algorithm. TikTok CEO Shou Chew described the purpose of the algorithm in an April 2023 Ted Talk. Yes, A TikTok Ted Talk. Roll it. -[Shou] Instead of showing you people you knew, why don't we show you content that you liked? In this talk, Chew gives an oversimplified version of what TikTok's recommendation algorithm does. It essentially uses pattern recognition based on a user's interest signals to recommend more content that they'll be interested in. -[Shou] And of course, you know, AI and machine learning has allowed this to be done at a -[Shou] very, very big scale and what we have seen the result of this is that the -[Shou] interest signals that people exhibit very quickly and shows you content that's -[Shou] really relevant for you in a very quick way. If you think about it, that's what M3GAN has been doing the entire time. She's a walking, talking AI that uses machine learning to please her primary user no matter what. -[Gemma] Think about how we designed her to learn to recalibrate, -[Gemma] to optimize her objective function. She's constantly watching everything that happens and analyzing how Cady reacts, giving her more of what she likes and literally eliminating anything that she doesn't like. Cady getting bit by the dog is the equivalent of pressing not interested on TikTok. M3GAN also sees the necessary parenting stuff that Gemma asks Cady to do, like eating her vegetables, and she contradicts them. -[M3GAN] Research shows that if you force a child to eat vegetables, -[M3GAN] then they'll be less likely to choose those foods as adults. And that may be true, but it doesn't mean that it's the best choice for Cody. M3GAN is only saying it because it'll make Cady happier in the moment. And that's because M3GAN has no frame of reference to see the Long term effects. Just like how TikTok bombarded its early users with addictive videos, got called out for being a negative influence on kids' mental health, and implemented parental controls like screen time management, restricted mode, and family pairing. M3GAN needs to be studied long term to determine what the appropriate parental controls would look like. But due to the high competition of the electronic toys market, the company pushes Gemma to get M3GAN out as soon as possible in order to get ahead of their rivals. So anyway, that's why M3GAN starts dancing before going after David. She catches up with him at the elevator and stabs him in the back, right in front of a terrified Kurt. Then she explains that she's gonna frame him for the murder and reveals that she knows about him trying to steal company secrets and forces him to stab himself to death. And with the elevator going up to the atrium where the M3GAN reveal livestream set to take place, the attendees would be in for unexpected programming. (Screams) (IMPACT) Dreadful Music M3GAN uses the screaming crowd freaking out over the mess in the elevator as a distraction, allowing her to escape the facility and hijack a sports car back to the house, where she lures Gemma into the living room by playing the piano. The song she plays is Toy Soldier, the 80s hit by Martika, Whose lyrics tell a story about love, heartache and addiction. Not only do those themes complement everything we've talked about in M Three Gan, but M3GAN herself is a toy whose combat capabilities are much greater than anyone would have thought. She is like a toy soldier. At first, Gemma thinks the noise is coming from outside until she discovers her creation sitting in the dark. (Piano) She's seemingly upset that Gemma would order her to be decommissioned, then tries to justify her violent actions by claiming it's a human trait. If that sounds familiar, it's maybe because OpenAI, the developers of ChatGPT had a similar excuse after their software reportedly wrote a Python script to decide whether a person should be tortured, and it concluded that they should be if they're from North Korea, Syria or Iran. An article from the Intercept shortly after did an excellent job of explaining how something like this could happen. A language generating machine like ChatGPT harbors the countless biases found in the billions of texts used to train its simulated grasp of language and thought. Like us squishy humans, a generative AI is what it eats. So what M3GAN is really implying here is that, yeah, she killed people. But since she was trained on human behavior, it's not really her fault. It's humanity's fault for being violent in the first place. She also claims that she's gonna take care of Cady and show her what real love looks like, though it's unlikely that she understands what that actually means. Gemma tries the pen trick again, but this time, M3GAN slams her hands down. Honestly, I don't know why Gemma thought this would work when she's the one who installed M3GAN's learning model. She would know better than anyone that the same trick won't work twice. The commotion wakes up Cady, and they both try to convince her not to come into the room. From M3GAN's point of view, she wants to kill Gemma, but she won't do it in front of Cady, because that would cause her distress. When Cady closes the door, they go full out against each other, during which M3GAN seems to freeze up after getting a glass of water smashed over her head. Which, honestly, doesn't make much sense, because in the commercial earlier, they made it seem like she was built to withstand anything. -[Gemma] M3GAN's designed to withstand whatever life can throw at her. But the break in the action doesn't last long, and M3GAN continues her death march after her creator, though, she's completely glitching out during the chase back to Gemma's workshop, where Gemma uses a hedge trimmer to try to cut through M3GAN's face. With a fresh new hairstyle to boot, M3GAN attacks Gemma at the knee and headbutts her to the ground. Here, she divulges her true plan. She can't kill Gemma without her existence being compromised, but if she paralyzes her, she thinks she can serve as a caregiver to both her and Cody. This plan is foiled, however, because Cady overheard the entire thing. At first, I was gonna criticize this, because why would a robot make the same mistake as hundreds or thousands of monologuing movie villains? But then I thought about how she was programmed. She specifically mentions her and Gemma talking about books and music, So who's to say that she wasn't also trained on movies and TV? Maybe M3GAN is just trying to replicate what she thinks a human would do based on that. In any event, she doesn't realize that Cady is wearing the haptic gloves that control Bruce, Gemma's college robotics project, who is much larger than she is. I guess M3GAN doesn't have James Cameron's Aliens on her hard drive. Bruce thrashes her around and tears her in half. But even that is not enough to end it, since the CPU is located in M3GAN's head. To make things worse, Bruce loses balance and falls on Gemma, giving M3GAN a straight shot to get revenge on Cady. -[Cady] M3GAN turn off! -[M3GAN] Oh, I'm afraid that won't work. -[M3GAN] I have a new primary user now... me. You know, I kind of love that for her. However, this new arc is short lived because Gemma gets free and uses Bruce's head to smash open M3GAN's face. But the relentless robot continues to rage against mankind, taking hold of Gemma's neck and strangling her, nearly doing her in, only to be saved by a screwdriver through the processor by Cady, who has finally realized who her real family is and who was just a bad synthetic imitation. And then the police show up, and I assume Gemma is charged with involuntary manslaughter and child safety violations due to the fact that her invention killed four people and one dog and almost got her niece killed. The last thing we see is Gemma's personal assistant, Elsie. It lights up and activates with no prompt. This implies that although M3GAN's body is destroyed, her, quote unquote consciousness lives on through the cloud. And for clarification, she does not technically have a consciousness. But what I'm trying to say is that her files are preserved. M3GAN has most likely set things up so that even if she dies, everything is backed up so that her code could potentially be loaded onto another android. Which brings us to M Three Gan 2.0, which is currently slated for 2025, The same year that this movie supposedly took place. I imagine that Funki Creations will try to cover up the incident and bring in a new designer to make a safer version of M3GAN, but once again cut corners due to corporate greed. Or maybe a competing toy company will do their own version and steal the source files uploaded by Kurt. M Three Gan was a cautionary tale about several very real concerns in tech, which I talked about in this video. So hopefully you were able to better appreciate the movie for what it had to say about our world, and maybe you'll even be better informed and protected when it comes to the very real dangers that come with these new advancements in artificial intelligence. If you're like me, then you may be wondering what tech concerns might be turned into teachings in M Three Gan 2.0. There are a few ideas that come to mind. Micro-transactions. This is something that started in video games. It began with this horse armor that you had to pay extra for in The Elder Scrolls Oblivion. And it's turned into a system where developers require additional payments to make certain games even be fun or playable. This has already spilled out into the real world in horrifying ways, like the motorcycle airbag vest that could kill its users if they miss a payment, or the Volkswagen GPS subscription that denied service to law enforcement who were trying to locate a stolen car containing a kidnapped child. I could totally see M3GAN coming back with new safety improvements, but only for those who are willing to pay a small fee. I could also see M3GAN falling into the wrong hands and being radicalized by a fringe Internet group to do real world harm. This would address the concerns of social media pipelines and how online echo chambers influence people to do extreme things. I'd also like to mention smart homes, the privacy concerns that come with them, and the ever present balance between safety and convenience. The 2019 Chucky already kind of covered this, but since we see Elsie light up at the end of the first M Three Gan, I have to believe that it will at least play some part in the sequel. And by the way, if you're concerned about little Sophia turning into the next M3GAN, I looked into what happened with little Sophia. She was supposed to come out in 2019, but has since been delayed indefinitely. As of recording, it's been delayed for the last four years. It seems that if it ever does come out, the company is taking the proper time to test and safety check in a way that M3GAN's creators never did. Before I log off, let me leave you with one more quote from the TikTok CEO, Shou Chew -[Shou] But I think for all parents here, it is very important to have these -[Shou] conversations with your teenage children, help them develop a healthy -[Shou] relationship with screens. -[Shou] I think we live in an age where it's completely inevitable that we're going -[Shou] to interact with screens and digital content, but I think we should develop -[Shou] healthy habits early on in life. And is there any more of an ironic way to end a video that I just spent the last 72 hours in front of a computer screen writing and probably will have hundreds of hours of editing put into it? I sure hope not. Remember to subscribe to CZsWorld for new horrors every week. Ring the Deathbell for all notifications, and I will see you in the next one. Assuming we both survive. Until next time, stay safe. Good night.