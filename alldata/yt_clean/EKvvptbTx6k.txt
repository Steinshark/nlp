- Hello everyone and welcome I'm Evan You, creator of Vite, and I'm really excited to have and I've got some big and it's about Vite and the So let's get right into it. First of all, a customary We've passed 15 million weekly downloads. That's more than double compared And just a few days with more than 3 million downloads. Pretty amazing. On the other hand, Vitest as the go-to JavaScript test runner, crossing 6 million weekly In the latest State of JS survey, Vite and Vitest topped the charts in almost every applicable category, most adopted, highest and most loved library overall. I was really pleasantly surprised so thank you to all And we have a vast ecosystem Vite is now the default tooling for most frameworks when building an SPA, and powers almost every except XJS. Vite-based frameworks of the most high-profile applications and websites in the world, to Shopify, Reddit, Porsche, It also has first-class integration with tools like Storybook and backend frameworks like Laravel. The significance of this is that frameworks building together on top of Vite can share Not only can they avoid assembling a custom build stack, they can also share plugins, test runners, and even deployment adapters, to focus on innovation in Saying this last year might but today, I think it's fair to claim that Vite has become the for the next generation With all that said, I would be that Vite isn't perfect. The trust that the JavaScript on Vite has pushed me to its future, and what I came to a pretty ambitious conclusion, and I want to go through my Let's start with why people love Vite. People love Vite because it makes web Now that, this implies at one point, everyone felt web development and it's true. Vite is hiding a lot of complexity from its end users under the hood. Internally, there are many change, or improve. We're only able to handle to the underlying tools that Mostly esbuild, Rollup, and SWC. esbuild is used for dependency bundling, transforming TypeScript, JSX. It's also used for target lowering, syntax lowering transforms, and minification in the Now, Rollup is used for and we use a Rollup-compatible SWC is not really needed by default, but if you're building a React app and want faster React refresh you should be using the that we provide. So when you're using that, to be using all three of these in one single application. Now, this architecture works, right? It's been working pretty but, and we are grateful to delegate all these but it has very glaring problems, and let's go through them one by one. First, I need to explain in the first place. We use esbuild, which is blazing fast, but its tree shaking and code and configurable as Rollup's. And its plugin system is to Rollup's. So we only use it to bundle This is called the dep pre-bundling or the dep optimizer, as we know it. By default, we also use to transform TypeScript, as I just mentioned, and minify We use Rollup for the production build because it is better suited for bundling applications given that it has better chunk control and a bit more flexibility in configuring the tree shaking behavior. However, Rollup is written in JavaScript. While the bundling performance it is much slower compared in a native language, And for SWC, one of the reasons in Vite by default is because On MacOS, the binary is 37 megabytes and that's more than and all these dependencies combined. And while SWC has comprehensive transforms and a high-quality minifier, it doesn't really offer a usable bundler. So even if we include SWC, we still need to use another bundler to cover the other parts. So we are unfortunately stuck with this multi-dependency scenario. The first problem that this leads to is There can be difference and Rollup handle mixed And sometimes, this that can only be discovered after production build goes live. Not good. Second is the massive inefficiency The same piece of source code in a Vite production build gets transformed, and serialized by these different tools. And worse, they're often passed to back and forth between native the Go process, and JavaScript main thread and then pass to Rust and So all these passing these large chunks of data across processes and it gets even worse when because every step, individual step between these of the source maps and merging them. Finally, the unbundled native but only up to a certain threshold. The network overhead when you of unbundled modules and it can take seconds for a page to load during development. While probably 90% of apps but the development experience for that other 10% becomes to a fully bundled approach. Unfortunately, in the current model, we don't have a good solution for this. We wish we could use a bundler to do full bundling but esbuild is incompatible and will result in even more development while using Rollup will just So sounds like we need to by building one ourselves. And that is exactly why But before we dig into as we worked on Rolldown, I found that even the abstractions below the bundle layer So why do we stop at the bundler? I realized that the challenge Vite is of the JavaScript ecosystem at large. JavaScript grew from a to literally the most widely used language in the world today. During this process, the many, many different tools to bridge the gap between and the rapid growth in the scale and complexity of its use cases. We're building more and and we had to create all to keep up with the demand of all these engineering best practices and newfound complexity and the requirement to bundle, We discovered these problems along the way and created tools to This is a blessing and a curse, because the JavaScript ecosystem is probably the most There are so many innovations, so many great tools that came out. It did give us all the tools we needed. But it also gave us a new set of problems, that is fragmentation, and in many cases, frustration. My conclusion is that to and inefficiency issues, for JavaScript is needed. It starts at the parser and transformer, linter, all the way up to the common layer of abstraction that supports And that common layer is Vite. And this is also what I believe Unified, high performance, composable, and runtime agnostic. First unified. All the different tasks of turning source code into final build artifacts by the same set of tools with the same consistent rules for configuration, module format interop, and path resolution. Second, high performance. For well-defined tasks like or bundling code, the in a compiled-to-native language with an obsession for performance Given JavaScript's scale today, performance improvements in that speeds up not only product delivery, and ultimately Third, composable. The toolchain should be composable. Each component of the toolchain should as a dependency. For example, the parser, the resolver, and the transformer should or MPM packages. There also should be so that users, while leveraging can still write JavaScript And finally, the core of the toolchain should Developers trying to leverage of the toolchain should not be forced to lock themselves into a We want the same development experience, no matter what runtime or target environment you are targeting, as long as you're writing JavaScript. Now, you might be thinking, isn't this just way too ambitious? Well, I used to think so too. Some other folks have But think about it. Four years ago, who would have believed that Vite would become for JavaScript frameworks as it is today? Well, I believe if we the right execution, the right leverage, and enough resources, this goal, despite it being very So this is why I started a a company building the next generation of JavaScript tooling. We have raised 4.6 million with participation from Amplify Partners, and many experienced founders We have built a full-time to realize this vision. Now, here is a big picture overview of what we are building at Void Zero. Oxc will be the foundational that supports everything. It includes the parser, semantic analysis, transformer, minifier, Rolldown is the bundler and will be the unified bundler of Vite. Through Vite and Vitest, we and tooling depending on So let's talk about the progress so far. This is the the progress chart for Oxc. For Oxc, we have already and resolver. Boshen, Oxc's project lead, will actually talk more so I'll be a bit brief here. For the transformer, we've JSX, we had refresh transforms and isolated declarations Our current focus is on with syntax lowering transforms. The minifier and formatter are and will be worked on after And now, how fast is Oxc? So this is the meaty part. To the best of our that it's probably the fastest in every comparable It has the fastest parser, the fastest resolver, and all up to three times faster than other Rust-written solutions. I have linked the benchmarks and you can check them out yourself after the talk via my shared slides. There are some other often to mention about Oxc. First of all, it uses for example, Babel. It also uses less memory than SWC. And it also shifts significantly to other solutions. Remember I mentioned the to include SWC by default of the binary size. So Oxc Transform, when used downloads the respective and on MacOS, the size less than two megabytes, and that is, well, almost 20 times smaller And if you use Oxc as a Rust it also compiles much faster because it doesn't rely heavily on macros. So that also improves your if you're using Oxc as a Rust developer. Now, onto Rolldown. For Rolldown, we have of the features you would Notably, CJS and ESM interop, basic code splittings, CLI, config file support and all that. Typical things you'd But on top of that, we which means Rolldown actually ships with built-in TypeScript built-in Node-compatible and everything that you expect from a fully featured resolver, and it also has finished such as production-quality tree shaking, advanced chunk splitting options, which is actually more and we have reached 90% Only some niche options and and it can already run a good chunk of official Rollup plugins, unless it relies on that we do not support. So right now, we are focusing The first is making Rolldown that has first-class support And the other is testing replacing esbuild and Rollup, and porting some of the Vite to reduce overhead. This work in progress which we currently just currently passes 98% of dev So we're on a very good trajectory to complete the test coverage in alpha state. Once we finish these two, there will be some more performance tuning, and code quality polish as a 1.0 beta. To get an idea of the we used a benchmark forked and we increased the number of components the benchmark contains. So in our version of the benchmark, we're bundling 19,000 of them are React JSX components and 9,000 are iconify JS files. Now, Rolldown completes That is almost two times and three times faster than farm and five times faster than rsbuild. Note that we don't even in this benchmark anymore because the bar would And if we try to bundle this application with the current Rollup-powered Vite, it actually just runs out of Another case study that is a bit more real-world to bundle Vue. Now, Vue's codebase is a It's a TypeScript and 62 dist bundles. There are cross-dependencies We use TypeScript everywhere, and they are pretty complicated cross-package dependency graph and some pretty custom So we actually, being able to migrate over from our previous to Rolldown actually simplified because there are multiple that are supported just as Now, notably, the bundle packages and TypeScript declaration, and Oxc's isolated are passing not only Vue's own tests, but also Vue's Ecosystem CI tests, where the built artifacts and test in the real build and test flows of a dozen downstream So this is a good testament for the production readiness Although we don't really consider we consider being able to pass very good milestone that we can use to verify how ready it is. Now, because successfully passing all of these tests required of the pipeline, including and format output, plugin compatibility, also, the pre-minify bundle of the output of Rollup, which means there is and dead code elimination quality. And of course, the performance. Here, we are comparing actually three commits at different times. 3.2 were about 19 months that we used were written in JavaScript. And it was also inefficient because we were essentially generating DTS for each package individually. Now, in 3.5, the current main branch, actually, probably in 3.4, we We migrated over to esbuild to the TypeScript transforms, we are using SWC for minification, and we moved over to Rollup So that was actually a but the main bundling because it was the only one that was able to retain the same bundle due to the tree shaking requirements. So in Vue 3.5 main branch, the current full build time 8.5 seconds, sorry, compared that's already a pretty big improvement. But now, after migrating to for the DTS emit, the whole build takes a little And this is not even the because right now, we and bundling in a separate In the future, Rolldown and bundling as built-in feature that's going to be performed in parallel to the source code bundling. So when that happens, for Vue will be well below one second. So that is the progress So first of all, let's This is Vite today. This is showing the with the Environment API merged. It still relies on esbuild, and if you're using React, you and you don't want to use Babel, you will still be using SWC, right? So this is Vite today, and in the worst case scenario, you'll be using three different tools that's wrapped inside Vite. This is the next evolution of Vite, and its current work in progress, as will be known as Rolldown Vite. It is powered by Rolldown It will greatly improve because now there's just one toolchain that handles both development It will reduce the internal overhead because there's just less code passing between different tools, and it'll greatly improve the because Rolldown is written So this is going to be the version that we'll be focusing on right now and we hope to get into early next year. And in the longer future, we of Vite that dedicates And we use the same bundling for development, Environment So this allows us to get rid of the unbundled network bottleneck for extremely large applications. It'll also ensure maximum consistency across browser environment, simulated Node.js server and also for production builds. It'll provide the best in all of these scenarios and also gives you a consistent toolchain that handles all the tasks together. And this is our long-term goal. Currently, it's in prototype stage because the first thing we that the full bundle and we can actually also have HMR on top of a full bundle And the full bundle mode very promising. From the benchmark, using the same React JSX-based that the page load is more to today's Vite, compared to And the HMR is also close to instant with some optimizations So that said, this is still early. Our current priority is to ensure the existing Vite ecosystem can smoothly start benefiting and Oxc, and this process We'll be working on this future and we hope to also be able to show you a more stable Well, that's it. I hope this gets you excited and JavaScript. We wouldn't have had the courage to take on this challenge and support from the Vite community, and we hope this work will and result in more great Thank you. (upbeat funky pop music)