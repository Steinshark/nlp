If you want what a service mesh is and learn Consul as well as understand in cloud and DevOps space. And get your first hands then this crash course You definitely want to stick because this is going super exciting crash course with First, we will see why we even technology like Consul We'll then see its including how it's used and multi-cluster environments. We will understand Consul and how it does all that. And finally we'll see a really of deploying microservices Kubernetes clusters on two and configuring the connectivity services across different And in case this sounds topics and use cases, remember you are on Tech World so you can be sure that I will the complex topics to understand examples So let's get into it. Let's say we have an e-commerce application like Amazon, which is a complex It has services for various like product catalog to manage product images, etcetera. We have a shopping cart adding products, removing them, We also have order management all the orders. We have user authentication obviously to manage user login and so on. You know, recommendation service. And let's say it also of supplier APIs and allows own shops or a payment with external So a bunch of stuff this huge application logic into microservices. And if you don't know and how they are designed, I actually have a separate video link in here. And of course these are interconnected. They need to talk to each other to shopping cart product the stock information on how Shopping cart needs service or user account. The user authentication services that require like verify user identity, or payment. For example, recommendation engine with User authentication Service recommendations based as well as talk to product details for recommended items. it is a complex network to talk to each other sure that the entire application and the user experience And while moving from monolith architecture introduced in developing and scaling One of the main challenges was the connectivity In monolith application application and one code base, so it's all function parts of the application. you have multiple isolated which introduces a couple like how do they talk on which endpoints, what communication Do they send Http requests Do they use message or asynchronous communication? What about When one service with requests from all How to deal with a situation and not responsive Like what happens if shopping is down but other services and it's just not responding? And how do we even monitor How do we know which services which ones are having issues, which services are overloaded or just slow in their response? So all of these are challenges infrastructure introduced. Now let's say we have our deployed within a Kubernetes in one of the US regions. Let's say we are a US mostly American users, but we grow and become super So now we need to deploy in those regions as well, geographically closer to our to make their user So we need the instance geographic regions to make loads fast and people good user experience. Now, this is another layer the question is how do we manage services across in multiple data centers? That introduces a whole of challenges of operating like networking and connectivity making sure those connections making sure the data regions and data centers. And you don't have data as if that wasn't enough, our microservice is using two for different purposes, By database engineers because let's say those by the whole company. Everything's interconnected. So it's not easy to move away and migrate the database Let's say it's a large machines and many replicas. So it would be an enormous that to a So microservice application with database services in on premise data centers. And that is even more connections between different Kubernetes clusters. it is a very common real use companies and projects. Now our story continues. Let's say one day right before AWS has an outage in multiple and we lose lots of business So management decided to make to have a failover to a like a backup, in case the main cloud provider So they replicate on Google Kubernetes Engine, which is a Google's managed because the chances of both at the same time is very low. And this is great for business But a new headache for the engineers. Again, connectivity across multiple network configuration and so on. So as you see, the operations especially in the modern, highly complex environments And that's where the service comes in as the communication network layer That solves many of the Now that's a bit simplified But essentially service mesh is the whole infrastructure features to solve these microservices applications communication between them Great. So now that we what Consul is and why we even let's actually understand how challenges that I talked about. And the great thing is that most are pretty similar in So understanding the concepts works will make it much easier service mesh technology as well. So I'm a big fan of concepts to understand what problem and what is the need. And technology is then a tool and fulfilling that need. So let's understand all a service mesh Let's imagine we have a city buildings and roads, and those apartment of residents in apartments, and those residents and sometimes they need residents to complete those. So they send messages to each And each resident has an own like an old address book the residents they talk where they can send The city is the buildings are the nodes, and the apartments are pods while the residents containers within the pods. And that phonebook is like for the applications they provide information with service name So basically where they have the services they talk to. Okay. So that's what we No Consul no service mesh Now let's see how our operate without a mesh. If a resident moves all residents who were to her need to now book with the new address. they will be sending address and wonder why And this would happen or database service gets name or port changes. Now the city like when someone Kubernetes cluster. So the administrators want through the services to be in one place so they can issues in the communication and fix those issues to see how responsive the residents So this residents need and report the city about their communications. Each and every one of them So making sure each properly and consistently up with the messages, they do all these other which is overwhelming So they're working over time. I know this sounds with surveillance system and making them work 24 but we are in a Kubernetes city, And in Kubernetes cluster, this is equivalent to adding applications to expose metrics. So we can scrape and collect for example, or adding logic to each communication with other when they don't respond or when like how do they retry And some residents might Some of them will just track and not all of it. They may all write in different readable handwriting's, so the central service will reports or that metadata about itself together, because they're all So essentially anything With other services, making sure the addresses proper handling of when a response back or if there and so on. The residents are responsible Now to optimize this city and release some workload from our residents and let them focus on their main tasks. we introduce a service Basically in every apartment we add a personal assistant. This assistants or agents I will send all those messages you don't even need to know residents that you You just write their name find out where they live, And when they respond back, I will receive the incoming them to you. I will also keep information that goes So all these administrative the messages are taken care agents or assistants, and residents can focus and the actual contents In Consul this assistants sidecar proxy containers of each service. As you know we have a service container and we can run helper or sidecar run alongside to support container in its job. So these envoy proxies will in the pod along the service. I have another video mesh with example of Istio. I explain the same concept so you can check it out as well. To get even better understanding different service mesh tools. if you are new to these microservices applications Kubernetes environment, I actually have a complete learn all these on projects as well focused specifically poly repo structures, and building a CI CD pipeline application on the git. And in our latest program you can also learn approach of working Kubernetes cluster, automating security checks for applications, and also learn about deployment of microservices mesh in Kubernetes using along with tons So if you are at the point to take your engineering definitely check out our courses in and learn these tools And all these for a fraction of what engineers with this in salary anywhere in the world. So how do these assistants do Because now they need to have to keep the protocol of things, instead of each resident Assistants actually with a shared address book, so each assistant will add resident or their service to it in this central registry can read that information So when a new pod gets scheduled it will get assigned So proxy will be automatically and proxy will say proxies or the shared network. Me and my service. And this is how you can if you want to talk that I'm assisting. And I will then forward Now, when any service other service, they can say to their I want to send this request to this service called payment. The proxy looks at the shared the location of the intended name or tags, and it will send the message where the agent or assistant the door and accept the message, and that agent will then deliver inside the apartment or pod. So essentially that means each other's endpoints at all. They have the assistance So we free the individual to even know this information into the service mesh. And when we have new and when old ones move out agents update So instead of a static file with endpoints, we have what's called that is always kept up to date Now let's say a resident a burnout from too much work, in which case their the information in the registry They can't receive and reply and I will let you know healthy and responsive again. So now if we have pod service on same or different other proxies will know to talk replicas of that service and not to the unhealthy replica information from the And again, all of this is handled just Don't need to worry about or keeping up to date replicas are healthy or not, and trying to retrieve these information from somewhere. They're completely Now, let's say while agents messages back and forth between some malicious actors to sneak into our city. So they entered our Kubernetes infrastructure and got access Now we have these on the streets roaming to sniff these messages especially if they sensitive data. Maybe they want to steal payment user data. Maybe they want to mess So if they snatch the envelope open it and read it, they will see all So ideally we want to encrypt between the services. So even if hackers managed system and network to see those messages, they can't understand anything it's all encrypted and only our because they have So that's another feature. Service mesh offers communication between services If you had 20 microservices encryption between them, you would have to change in every single service or receiving encrypted data. You would have to implement of the encryption keys sure that they are also And it's a lot of work on the that extra administrative communication that has nothing with the business mostly these are the things are probably not the most the best at implementing You kind of need specialized this with proper security. So the fact that you get these mesh is pretty powerful. the microservice itself is still which is unencrypted, but before it leaves it's captured by the proxy. The proxy has a TLS certificate key to encrypt the message. So when the request it's fully encrypted. When that encrypted request service or in Consul term, upstream dependency that services proxy will And we'll do that TLS routing it to its host service, which basically means it will with its encryption key text message to the microservice even if someone infiltrates network and was sniffing they won't be able because they are all encrypted. the microservices themselves this encryption decryption From their perspective, they're just sending unencrypted messages. The biggest advantage is that all that functionality which means it doesn't matter are programed or how other applications are programed over have no control. You can still use all encryption and error handling, etcetera with Consul on the applications or having support for TLS, And that is super powerful operating complex, Now, these end to end TLS between services Since each service proxy certificate to establish secure This individual certificate can to uniquely identify the service for example, each resident or service gets unique stamp or certificate. the assistant stamps with the stamp or encrypts So when the receiving agent that agent can verify is this stamp real or fake? Was it tampered with and does it belong to? So we know this message of the payment service. since it's signed we can now use this information rules about who can talk to who, like define whether payment to user authentication service is not allowed to talk for example. So after the identity proxies will check So this is really a payment this message that's verified. But is it actually user authentication service. So is this resident allowed or does it maybe have order if proxy sees oh, it's not supposed to be sending then it can block the message so it won't be forwarded to the If the rule allows it, so it will forward This is also called micro So instead of having a firewall group level or a subnet level, we have firewall on an which gives us a more granular to our services on which ports. That's why the term micro Now remember, city wants to have protocols to whom, especially when we limit those We want to see who is trying to the services supposed to be talking to, or generally which tenants Or who is sending and receiving? Are there any bottlenecks What is the error rate are we getting Maybe a few services are getting and are overloaded and on and proxies by being located in that traffic path where automatically end up which they can then expose system like Datadog And here's a great thing that collect and expose Consul proxies are all which is envoy proxy. So when they collect in different services, they all do it in the same way the same application. So they collect and expose format across all services. So it's easy to put together and build unified in Prometheus and Grafana, So this architecture gives and control things without having to do any which means we are flexible we want very fast, and configure things way for all the services. Now you're probably thinking address list of all They have certificate data talk to who based on the that they all share access to. So the question is how Or when a new proxy starts up, who provides it with all And where is this shared of information and certificates? And that's where the Consul With our analogy. Imagine these assistants all and they had in the city in its own building, This office is the You can have a single like a single Consul server pod replica. But if you are managing many you might need a bigger office. So maybe 3 or 5 Consul So these Consul servers push to the proxies like service the configuration certificates. So we don't have to do anything in all this data to the proxies. All of this is done and managed by the Consul servers. So we have basically automated And as I mentioned, those personal assistants have They talk to each other information and so on. And that network of personal And the central office that manage these assistants This means the data plane servers or the control plane, so that they too can focus of handling the communication and if something changes like the address service gets added or removed, they will get the update office automatically. It's like these proxies for the same organization, having access to the centrally so they can all do And this control plane maybe in the same city, which would be the same Or maybe they even have which means you can spin up cluster just for the Consul and then connect it to where the data plane is running. Now let's say we have multiple Kubernetes clusters with our microservices like in different geographic regions, maybe replicated on different And this is like having allied cities form a network let's form a partnership. So we will allow your services In this case, you can have Consul control So own control plane Or again you may have one headquarter Consul And it will manage all other which is a common setup. This way you can avoid offices and resources. For example in Consul in such multi cluster multi data Connecting services across which can be a really big challenge if you're doing mesh tool. So how does this happen Think of Consul planting guards of the city This guard is called So if payment service to talk to user authentication it will be the same process the payment service just says send this message to the user I don't know where it's running. You will figure out how Proxy will have the list provided by the Consul server, including services in all where it says okay, this user authentication so it could hand the message The guard will take and hand it over to the guard which is going to be the mesh which will then deliver service inside the cluster. And finally it will be service within the pod itself. And the response will to the payment service. And we're going to see use case in the demo part, where we will connect two different cloud platforms And the good thing is, it doesn't matter which cloud It pretty much works Now when we talk about multi it's not just Many companies, especially large have tons of applications on legacy systems Or they have a large company engineers team is managing And often that team already to manage and operate those on the virtual machines. So the overhead and then learning how the service on Kubernetes Or if it's a small maybe the overhead So these are real use cases services that will run on VMs to Kubernetes or cloud but these companies and projects advantage of the modern tools So the teams in that company in Kubernetes cluster, which now has to connect or connect with other legacy on premise virtual machines. And if connecting multiple clusters is a challenge, try throwing VMs in that mix Challenge of how do we connect service mesh tools make this low level network and letting you manage that on What's great with Consul is that while other also have this capability, Consul actually treats the VM with the same importance same as and doesn't treat or undesired guest because it's there So how does Consul work on VMs? an on premise data center with a bunch of private houses the application or service resident in the house Consul client will be living along the resident, and we will have its server as main office. You will then configure so that Consul server running to the Consul server so they can share information connection channel So now again you have in the Virtual Machine City Who will communicate with Mesh This way it can connect to other or Kubernetes clusters. And once the trust channel is established Now the residents of both through that secure channel. now with payment service cluster wants to talk They go through the same payment just says to its proxy, send this message Proxy will have the list provided by the Consul server, and it sees their database lives So through the mesh gateways get transported all the way in a different data center. a service mesh like Consul infrastructure layer features to solve these microservices applications communication between them. So in this demo part we're going to create a Kubernetes cluster on AWS using ECS service. So that's going to be Once we have the Kubernetes to deploy a microservices of services inside the cluster. And we're going to use an open application project from Google. So it's a little like a more And not just two services And once we have we're going to deploy and we're going to see how in each one What configuration changes to the microservices files in order for Consul and also explore a couple and what it gives Once we have all of that set up, we're going to create on a different cloud platform. And we're going to use fairly service on Linode I like using because it's to spin up a cluster there It's just very little and it's also very fast. So we're going to use for another Kubernetes cluster. But it could really be cluster that you want. So the And then in that linode we're going to deploy microservice and same exact And once we have that we're clusters together using Consul. And we're going to see of a service going down And it failing over to the same So basically a multi cluster with a service failover So let's go ahead and do Where along the way I'm of different concepts related So the first step is we're But of course we don't want because it's a lot the easiest thing to do. So we're going to use using Terraform and all the code the Terraform script, all of that will be linked So you can clone those So this is one repository my Kubernetes manifest files to configure Consul and deploy So all of that is going And we have the Terraform with the Terraform script And I have this repository so that I can work on it using So this is where we're going of configuring stuff. And I also have my account ready going to be creating the Elastic Right now we don't have any. And before we do, let's actually go through script and what we're It's pretty I'm using the modules So I'm using the VPC VPC for the EKS cluster. Our EKS cluster will That's very important. And therefore we have the public to the private subnet And then I'm just using the X obviously referencing this VPC. And we're basically configuring to configure our cluster. So first of all as I said to be accessible externally. So with this attribute we can create a public endpoint. Or we can let create Kubernetes API server. So we can connect kubectl for example or browser Right. So I'm setting To achieve that the is adding some security And this is actually to be able to do its job. And there are some specific on the worker nodes themselves, where the Consul processes will in order to allow Consul to each other, and for the Kubernetes to reach Consul And I'm actually going to the list of ports for Consul. So you see what they are and why just to make things simpler that you guys do not have any and just to make sure what I'm going to do is, as you see in the Terraform I'm actually going to open all and I want to stress that I'm because the security only those ports open that you and only those internal that need access to whatever on that port needs to have and nothing else. However, and I just want to make to follow along and to make any networking problems And finally, this is the managed So these are the actual worker configuration for the cluster. And here we're basically just And we're going to have three instances in the cluster. And finally we have these two which are also needed So these are basically for the dynamic volume is a stateful application. So it actually deploys component and it needs to store So it needs to create platform it gets deployed. we are making sure that creation Amazon Elastic Block Storage for the cluster by giving nodes to create the storage. we have to enable what's called which allows for automatic And once the cluster is created, I'm actually going to show so we can see that visually we have variables and I have added some default of the variables, so you don't have to set So these are basically private and public subnets. That's very important the one of the latest ones. This is the latest So that's what I'm using because we use that in a couple within the main configuration. So I extracted that as You can set whatever And there are two pieces or variables that you have yourself to execute the script. Everything else is configured So before you are able to make sure to go to your AWS create an access key pair values for the Terraform. So I have defined them in the provider configuration, which means I can just set Terraform dot vars file, And once you have that, you should be good Tfrs is a simple text So you have the key name, This one equals whatever And same for the access key. So set those two values in the file and we are good to go. That's the provider That's the version And now we can actually script to create So I'm going to switch to the going to do terraform init. So terraform init basically that are specified here dependencies of your code. For example in order As you see it creates where the modules and providers Those modules and this provider which means our Terraform We also have the Terraform We can execute Terraform apply. You can do Terraform But I'm going to do terraform And we have to pass that defines any missing VAR file is terraform tf vars. And this is our preview. All the things that will I don't need to look I'm going to confirm, and this is going to take to create everything, because lots of components And once the cluster has been we can continue from there. So the Terraform script was executed and it took some time, but it So now if I switch back to my that you have basically set I chose the EU central region, So this is my EKS cluster in the Frankfurt region. And if we go inside and check I'm going to show you a couple configured in our Terraform see in the UI as well. So I want to point out a couple First of all we have the cluster So we have the role the IAM role which is this one right here, as well as security groups And then we have on the node groups or the worker So if I go to compute we're that were created because that We have defined three nodes. So these are basically that are running in our account. we're going to see these three And we have the security group node level, which is this one And note that this security actually applies So this is the same security So it will be same And we have also configured policy for the IAM role to the node groups. So now the cluster or the control plane role. But the node group role And again we can see that right the instance configuration. And we should see CSI driver policy listed here. And I'm pointing this out you need to understand are configured separately. You have the control plane which is actually running in its And then you have the worker own role on port's own firewall So if you have any networking this should help to look for things basically. And finally last thing EBS CSI driver. Add on that we activated And you are going to see that in tab for the cluster. And right here we have which basically is needed provision the elastic block volumes inside the cluster. So in our case Consul needs a persistent volume. So this allows the cluster provision the Amazon block Awesome. So the cluster So we can connect to it using our application inside. So I'm going to switch back to my code editor. And I'm actually going So we have everything And we don't need anymore because we executed So now the next step connect to our EKS cluster. And we do that using AWS So this is basically a cube config file from the EKS credentials and without having this kube config file, and so on using which means you have to have it's pretty easy. Just go ahead and install on whatever operating system And once you have that, you need to also configure which can be the same access is using for this demo use case, because command line interface credentials to connect And I have already configured configure command. So just make sure that the and credentials configured here account as for Terraform, So. With that setup I'm going Update. Kube config. And you can actually provide for where the cluster So central one and we are going the cluster name as well. And we have that here This generic name. So I'm going to copy So basically what update kube is it fetches the cube which is like a credentials file And it stores it locally cube config location, where cube CTL will look is on your user's home directory So after executing this command cube config file in there. And there you go. You see the output that the cube Or the context of the cluster in dot cube slash config. So if you don't have the dot it will basically create file configuration in there. it will just append because you may be connected So all of those configuration That's how it works So nothing is specific here. And that means we now to the cluster using So let's see. Kubectl get node. We have our three work nodes which we have defined here. The first step is done We want to deploy into this Kubernetes cluster. So for that I'm going to the Kubernetes folder And I'm going to close this up and expand this. So these are all the config going to need in this demo. But we're going to start So that's all we need to deploy So actually we don't need of the microservice We just need a reference So this is a Kubernetes images of all But of course I'm going to link in the video description So this is an open demo repository from Google. And all those images are public to use it for demos. And this currently happens If the version has changed, you can check in the and you can just update So super simple actually, we just have a bunch The configuration is pretty They just run on different All of them have cluster IP internal services. And we have one entry which is the front end that will to all the other microservices. And here we see basically talks to all other services, and it is the only one service of type load balancer. And all those microservices memory database. Again, Nothing crazy here. So that means once we apply all the images will all the pods will be created, And we're going to have one to the cluster through Now for simplicity I'm not controller in the cluster. So we're just going to use directly to access which is going to be So let's go ahead and apply Config dot Yaml. That's all And by the way, there is one service slightly on purpose, which is It basically is missing So it's not going to be able but we're going to need in Consul. So let's execute And we have the output of all So we have quite a few and it will need a little And we're going to check So they will all be created So if we do kubectl get pods are up and running service which is going to stay state which is fine. We're going to use of an error in microservice So that was pretty easy. Now what we actually want So I'm going to do And as you see all our services for the frontend external. That means if you have watched you would know that load gets the internal cluster IP, but also the external IP able to access it externally. And this is the external balancer that will then map So where does it come from. That's also pretty easy When you create a load cloud platform, you are creating this load It will in the background balancer service to create So that's where the external And that means if I switch to EC2 service. That's where we have We should see our load end external right here. And this is basically the DNS right ending in 138 forwarding to this port which is So pretty simple. We just grab this DNS And since port 80 is the default just open it like this. Our microservice is deployed. Now the next step Consul in our cluster and use So how do we deploy Consul. There are several ways on Kubernetes cluster. One of them is using and another one Official helm chart which is what I'm going to use. helm, chart and open official documentation, always try to refer to the instead of some blog posts up to date. So for these are the instructions. We basically add the HashiCorp We install the Consul chart parameters we need. And if you have watched my helm you know that helm charts actually provide any parameters, any configuration options the service using those So for example, with Consul service mesh it has multiple features. And depending on which features you can enable them as the chart values or passing and to see what values to be set and parameterized. Obviously we need to see So we have a chart So that's basically the chart I usually actually prefer file in the repository. But as you see the repository So this documentation is up that you should reference. But even though it's an the chart highly configurable actually tweak it to configuration you have in mind. If you don't know there's this huge list of values understand what they're doing. And it's pretty difficult these configuration. So we're going to use a couple And I'm going to explain actually doing. But if you need any options you can find those I don't think it's the most and understandable, but at least you have So let's switch back And I'm going to walk that I have configured for our Which is actually pretty simple configuration. We have this global attribute the components that are part chart usually holds of multiple components components as well as custom So this applies First of all, we have the Consul We are enabling TLS the components and services. And since we want to connect or multi data center basically with each other, we are also enabling Then we have the Consul As I explained, the Consul server that manages all the proxies, And usually in a production at least three replicas, because if one replica dies, In our case, we're just going to use one So you can configure that here. This is an important Connect inject is basically the technical term functionality of Consul. And what this configures if we enable connect inject to automatically those helper containers, into the pods of services. So that's what enabled And then we have that says default false the default value. But I wanted to specifically So if this is set to false annotation inside files or deployment manifest inject the proxy into that pod. like this, then it will actually even if we don't have annotations in the deployments. And this is a good thing to have because it could be running in your cluster, that you don't want to have or you need to, or maybe you have some have any Consul So if you set it to false, you basically decide per where you want So I'm going to set it to true. And we actually want the proxy injected. And we don't want to add by one on each deployment. And that's the connect Then we have mesh gateway, which as I explained between multiple environments. So mesh gateway is like a guard the entry or exit of the city And you can also have multiple because if one of them goes or maybe becomes a bottleneck of requests, you can actually scale up And again, it's a feature that you can So if you don't have a multi or just for security purposes, you need to stay then of course you want And finally we have UI dashboard or UI where we can we can even configure stuff to be using in our use balancer basically means an external load balancer type so we can access the UI. So that's the configuration in our cluster to one, or inject the proxies in our allow us to connect with each other and also have stuff and configure some things. So I'm going to go ahead helm chart with these values. So I'm going to copy the first add HashiCorp repository. And now we can actually install And we're going to give our You can call it whatever I'm actually going to call differentiate it later from Kubernetes Engine deployment. So I'm going to go And then obviously we need I'm going to copy it from here. And actually when components it prepend Consul in the name. So that's why I'm not in the chart name itself. And I'm actually going parameters which can also But I'm going to set them to use the same values file deployment as well. So I'm going to pass in the And we're going to use. Version we have to pass the values file. That's our file. And finally the last going to set. A global config. So one of those global And that's basically the name. So you can name the environment You can give it a name And I'm also going to call So I'm going to execute And this should install all components in our cluster. And this gets executed going to do kubectl get pod. So first of all I'm going And now that I'm deploying in the same default namespace. But you could also have them especially if you have That would make sense. So we have these four pods. Obviously we need the server plane to manage the proxies And the chart name was taken as you see here for all Then we have the mesh gateway. One instance of it we have injector that is the one for injecting pods. And we have the webhook And as you see all the pods You can also check any other So we have this stateful set and those deployments services themselves. And one of them is we saw which is created as a load And it also gets its own with its own DNS name. So we can use that to access So let's go ahead and do that. And I'm going to make And one thing I want to point is that this external service accessible at the Https That means we have to access Http as protocol. Like this. And of course our browser which is signed by Consul CA we allow it. And there you go. And as you see we have only So basically Consul now One of them is a mesh as part of Consul. And the other one is Consul That means another The proxies have not been of the microservices to restart or recreate those So that's what we're So I'm actually going to delete our microservice deployment completely. And I'm going to redeploy bit adjusted configuration. There you go. And let's see. Looks good. Now, I actually have already with a couple of changes deployment specifically. So I'm going to open this file it and understand those changes. So first of all in order in our deployment that is So most of the things relevant for how Consul or whether it will inject it will handle the communication we can configure those you know, annotations are part components like deployments. And these are going to be on the pod level. So inside the template metadata the Consul So this will communicate our microservice sees to Consul, which is a pretty easy the Kubernetes native way. which is probably most seen one is connect inject. So basically this specific for us because we set inject default to true. as I said we can say we don't part in every namespace. We want to be able actually get those proxies. And we decide that by adding to the pod metadata, right. So every part that we want we can add this annotation However, when this is set which is what we configured. And that's what Consul cluster actually knows, So I'm just going Let's go to So we have the same We don't need this. And this is another Connect Service up streams annotation which basically does this service talk to. And how are those Remember I mentioned that once the service inside the pod care about where the destination and what their addresses are. They can just hand over of the service, and then proxy will figure out actually runs in. Kubernetes services are already using the service name and port So this is basically not in this case because Kubernetes we do need to communicate this one will be talking to. So that's kind of the And when we have this configured more change we're which is there is an environment to the service service is talking to. And in the previous this was actually the Kubernetes And again going back to my the service does not need service name that he talks to because to its proxy. And the proxy will listen on localhost because it's within So the containers within localhost and the same service is configured. So this request will basically of the Kubernetes service. But proxy knows that whatever points to is located here, which is the Kubernetes it's not like a huge game because Kubernetes already names pretty well, but that's So that's the annotation configured in services. That's the only annotation So I'm going to scroll of those connect inject that we don't need them. So I basically just commented out that annotation, but I'm still going to leave for your reference in case And then we have two last of upstream services And it's the same idea. You can just provide a list And then all of those will be on different ports. So basically the service always be talking of talking to all those as it was doing It will now only And then proxy will forward all to the respective services the proxy receives that request. And that means obviously different within the localhost So front end is the last has a bunch of upstream the same concept. Change And there is one more annotation end to actually be accessible, which is transparent proxy So transparent proxy is a feature of Consul for services to communicate other through those proxies, without being aware that those So they are thinking to the service, and proxies are capturing but services are unaware And with transparent proxy set we are saying that the service and it has to explicitly send and route the traffic And that's our slightly And I'm going to apply. This config Consul microservices so CTL apply. Consul and let's see. And let's give it a couple to come up. And. Let's do And there you go. So let's see what we have here. These are all the pods And you probably notice that for pod of the service, we have two out of two inside instead of one. And that second container And we can just log one of the what the proxy is doing. Logs and let's just So I'm going to do this. So basically when you have two which is the main container. So this is However we want to log And this is actually So this is the proxy that was And we also have So you need container from Kubernetes concepts that starts up before containers actually run. So it's kind of preparing the rest of the actual and init container exits And then the other containers run and the init container. Basically it prepares So remember I told information about what other So that if its host service it knows how to reach them. It also gets the TLS certificate encrypted communication. So all of that is actually container that injects all into the pod so that the proxy So let's actually log the proxy And we're just going to provide And. There you go. Consul's data plane That's the technology behind it. So we're seeing the envoy logs basically on the startup. What it's doing is it tries associated with the pod. for example, it will find and it will register proxies can talk to it. Awesome. That means if it doesn't find related or associated service, it will actually give that it couldn't find a service And this now means that all the work of registering these So this means if we go we're going to see all Because now Consul knows And for each service Consul is aware And in our case they have And we actually have a pod So the proxy is up. However the service itself That's why we have just one up and running. And we see Basically it's failing it's not accessible. This means that all the other about the issue of the service, without even sending a request And we can click inside the service. And what this basically displays talks to which other service, because payment service talking to all of them, but rather which service to which service. And right now we have no that limit any service to talk And that's why everything we can change that. if we go back And I'm going to go You actually see that the is not initiating communication other service. So there is no service service directly talks to. there are services that send request to the payment service, So this is actually the only that talks to the payment the request. That means all of these other that we are allowing So by limiting those saying payment service other than the checkout service, we are reducing the attack So that means if there was a bug like a huge we would actually limit can do by exploiting in the cluster, because we're limiting within the cluster communicate to and talk to. And we're going to use So this is the micro that I already explained, in which Consul basically firewall configurations on a service level. And that feature is called And there is an intention as a Kubernetes manifest file, which is pretty simple And we're going to create to say that the checkout service communication to the which is what we have because checkout Service will be not vice versa. And that's it. No other service is allowed And let's create that. And we can create another the services are denied to talk So basically by default and we only allow service as an exception. If I go back you see that this And we see checkout service that can talk to it. we can also create another the payment service itself services is also denied. Go back to topology. And as you see, this is on a specific you can do this for your entire And we even have a warning here to configure that for all And you can do that here if you want to automate this, configuration as code, which is the recommended you would create the Crds service intentions. So we have successfully in the EKS cluster proxies into all plus the ready service which is a third party So it lets us have the proxy whether it's our own to have that consistency the services which is because we can apply on third party applications own application, so we can decide which services to the database and we can encrypt with the database within our own applications. we're going to repeat in another Kubernetes cloud platform. So we're going to recreate state in another cluster. And then we're going to simulate a failover. When a service here fails in another cluster platform can take over its job. So we're going to deploy application in an Elk cluster. So I'm going to go ahead and log So if you don't have a linode account yet, as I mentioned previously, you can actually create The concept will so it's not anything This could work with any I personally like linode creation super fast That's why use it. But you can use So going to Kubernetes I'm going to call these Elk Consul. And I'm going to create these but it could be in a different It really doesn't matter. Just choose the latest I'm going to choose no Aicha because we just And let's choose the cheaper by switching to the shared CPU. And let's take the four and let's choose two nodes. Create a cluster. And this should be up So let's wait of those worker nodes. Our two nodes are running download the cube config So I'm going to go back and open a new terminal. And let's go Folder again, and we're going to have file to connect to the cluster. So right here in this basically we have executed the cube config file where kubectl will look for it. So wherever I execute kubectl it will connect to the eks in the dot cube So basically we're going terminal session or this to the cube config file of LCC. And then when we execute specifically it's going And that's very easy. We're just going to export variable called cube config. But again kubectl will going to set its location Alki kube config file is that's And there you go. So now if I do kubectl me to those nodes. Very simple. So basically kubectl will environment variable set kube config file. If it is then that's the cluster If the environment it's just going to look dot kube and try to find And for security reasons the permissions on this file. So right now it's readable for group and any other user. We can set it to 700. So basically remove any to anyone other than the owner. So we are connected which means we're going Install or deploy the Consul and deploy our microservices with the annotations. And this is going We're calling this helm of the Consul chart. We're The same values file. And this time we are setting So calling the cluster So let's execute this and Everything that was created. The four pods starting up What Consul also deploys along mentioned are the Crds. So we can also check those And there are a bunch of kids from the LCC itself, so we can Let's find only the things So basically you have that I showed you and so on. So it actually creates a bunch So you can configure Consul of Consul in the Kubernetes And you can find the Crds in their official So let's give it some Let's see if the pods are ready. And now we can deploy. Apply config Consul and enter. In the same way, we see that two containers in every part of microservices, which means the proxy in each service. And while let's actually. Check Because with we have the Consul UI as well as the front end And as I told you, it doesn't really matter you use because the concepts So the same way is on AWS. The load balancer component to the cloud native called node balancer. So this one right That's the IP address And we see that here. This is for the frontend And then we have the Consul UI on this endpoint. So exactly same configuration, which means we can actually the Consul UI in LKY. And as you see, that's what we called That's the name we gave when we deployed Consul. So it says okay here and here to make it a little bit easier when we do stuff And as you see all the services And all those parts except for the payment service have successfully started. Awesome. Now we have basically recreated the same exact environment in a different cluster, on a different cloud us to now have a failover. So if something happens we can always fall back to the we need to first establish because obviously now these So we need to connect them in EKS cluster can communicate in cluster. And for that we are going what's called a peer connection. So we're going to make And since both of them have inside on the Consul level, we are going to connect inside those two clusters can And it is actually pretty easy there is an option to do for this demonstration we're and simpler approach of Consul that peer connection. And in remember we enable These are the components to help us connect those two So the mesh gateway in EKS gateway in cluster. So those two are the And when we have Consul networks like we do here, different cloud platforms, then we're going to need servers or the control plane, basically to use mesh gateways the peering connection. So on both sides we're going to use the mesh gateway the peering connection And we can do that with one So this one here, and we're going to have to apply Consul deployments. I actually have already prepared right here. And you see how simple This is the CRD from HashiCorp. make sure to check in the documentation this a little bit later. So we're creating the mesh that enables or basically the mesh gateways for the And we're going to apply which means I'm going to do Mesh gateway right here. And I'm going to switch to and There you go. We can also check that the CD And as you see, we have this mesh component as I said, will allow to route through the mesh gateways. And now we are actually those two clusters. So first going to the ECS So that's our main data center. Not technically but just And we're going to go And we're going to add And we can give the peer a name. That's going to be the peer. So that's the name that the peer And we're going to click And this is basically a secure peer to connect to this one. So I'm going to copy And as you see this is And it's pending basically has to make using that token. So we're going to go to the now And now instead of generate to do establish peering We're going to call the other that I just copied at peer. And here we have this status Is the peer accessible or not? And if I switch back this one Very simple and straightforward Now as the next step we're service configuration So basically we're going to use of one specific service. And we're going to expose the service from this pier for the EKS cluster. That means the services here to talk to that And we're going to use service actually, which means we're going service from the cluster to make And I also have a configuration Let's go back right here. And as you see the configuration We have this CD called This is the name of the service And this is the name to consume the service. So basically just to demonstrate how this is going to work right now, if the a specific feature related will not work anymore is not available, the service So let's click in one And if I click on Add to Cart, everything works service is up and running. I'm actually going to. Yeah, I'm going to switch back going to delete deployment. Shipping. Service. There you go. The shipping service pod should be gone and should be gone from here as well. And now let's actually try function again. And as you see, it's not working service is not available. So what we're going to do like some of the services crash and they're not available, we're going to direct or we're to the peer cluster that has So the shipping service basically take over instead or crashed shipping service So that's what we want So I'm going to bring up Again I'm just going to apply. Like this. There you go. It works again. And now let's configure So in the LCK. So we have this exported And we're going to. Apply this. And if I switch back to my Consul. You see that we now have one which is this shipping It also shows the topology way in each cluster. It shows that as an imported So now if we go back to the list so we have all those other and we have this one that the service is actually So we have two shipping for this cluster. Now. Now there's one more thing side to create what's called And again service resolver And this is the configuration resolver component. So basically we're configuring resolver for the shipping two shipping services now. Right here. And we're saying that we're to the peers shipping So we are going to need resolver in the EKS cluster, because we have those two service in the EKS cluster. And we are defining a service saying that this should be So switching back to EKS I'm The service resolver. And now, the moment of truth. I'm going to delete deployment again in the cluster. And that add to cart feature So let's do that again I'm going to. Delete the deployment Switch back as you see And now let's actually Going to any product. And if it should work by failing And let's do that. Awesome. it used the service from a pure So that was basically our demo. I hope I was able to give and lots of new knowledge mesh technology generally, as well as what concepts details are involved If you made it till congratulations on gaining and knowledge in this area. We put a lot of work and effort so I will absolutely appreciate. leave a comment with your with your colleagues or anyone from learning these concepts. thank you for watching you in the next video.