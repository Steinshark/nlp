LOGAN KILPATRICK: Hey everyone, a new podcast that takes you I'm Logan Kilpatrick, I'll be picking the brains behind some of the latest and new products [MUSIC PLAYING] Ema, I'm super excited You're one of my favorite mostly because you love all that good stuff. Do you want to kick it off with you've worked on at Google, what you're focused on? EMANUEL TAROPA: Sure. I started working at Google I worked on most things the systems, ads, search Vertex AI or what was before real time detection of on everything involving large AI launches, from the initial to Gemini 8B. And I worked on all from being on call for directly on serving them to making changes to architecture like quantization, forth. And if you want to see LOGAN KILPATRICK: I love that. No, that actually is super, think it speaks push into this later But part of my takeaway of of Google is actually because You've built a lot of the might say, this is going to And then you're always like, no, It should only take-- like change should take 12 hours the infrastructure to do it. So I feel like that is one is you have that a bunch of these systems work. [MUSIC PLAYING] I'm curious what on where we are with ago, when at this point, even been announced yet? Have things sort that you would have expected Do you think we're the machine that makes the model I'm curious where your head is. EMANUEL TAROPA: You're asking You're very kind before. Oh, because you kind of know how long it takes. My take on it is I'm overly but then somehow, it I mean, last year, we were in the same micro like looking building with a bunch of office that were very nice and And then we did the same And then critical infrastructure and we're launching. So I was uncomfortably excited, But then somehow, it we ended up having a really, in December last year. And then we were able to and then March, and then And then we keep having so that's actually It's where are we now. I mean, again, it's a very in the middle of it. So I work with all of these they're kind of my So again, very biased answer. So I do like it, And yeah, I'm pretty bullish. If we did one thing was starting, and then just and making the system better. If you look at how we started or Sidekick, which is search outside know and suggest Again, people are like, Oh my God, you're going to use many resources. How would you make it work?" And I haven't met an we weren't able to crack. So I am pretty bullish. [MUSIC PLAYING] LOGAN KILPATRICK: I'm really on this system versus model in the future is actually going unquote, model versus the actual system And I think my take, at is like, there's actually almost that you can create and the infrastructure And I feel like some of the-- I don't know what your but it feels like long there is model innovation but it's actually an to make it work at scale that developers EMANUEL TAROPA: Yeah, I It wasn't an easy I still am not terribly happy and we do have especially on cost the interface to the Cache You know them very well, like kind of the examples how easy it is for So we do realize we have to be done there, to be generous But I do think that is actually pretty solid. And we will do what we do, So don't do a launch and So I think it's very important in place. That being said, without a really a nice engineering but it doesn't So users should get The real value comes and how well they're integrated from Workspace apps, all the LOGAN KILPATRICK: Yeah, EMANUEL TAROPA: So I think LOGAN KILPATRICK: Yeah, One other quick, maybe question before we talk I'm super excited to dive Back to this narrative of that trains the model. I'm curious if there was flip a switch and change process, like from to all the infrastructure If we could just make it would be a huge unlock for or even it could be an as far as one feature would really sort use cases that just isn't standpoint. EMANUEL TAROPA: Yeah, Look, again, can Yes, absolutely. Can we do it without of time spent on details and making sure it No, not that how quickly And, this is a very and like-minded people And that's basically But, if I were to would be a little bit we want to put out and then explain it hey, this is an experimental, humanly possible on our end to useful for the end users. And then maybe apologizing if there are And I do think that's a very but it's something do better going forward. As opposed to letting launches Kind of being a bit faster And then also, taking around them, and then bit the failure cases for them. LOGAN KILPATRICK: I think it's also extremely that balance in the because in a lot of cases, actually go and build your But I do agree, I and we're probably teetered. We're always teetered in the wrong direction, whether and constantly needing So I hear you on that. EMANUEL TAROPA: Yeah, I It's a global consumer company. It has a huge responsibility. Like it or not, it will be a versus what some So all of these have This is not finding certain things take longer But it's just like, we're on this thing, so we should That's basically the takeaway. [MUSIC PLAYING] LOGAN KILPATRICK: So, Flash-8B We landed this model internally, by you and who are training the model, who helped get this Why did we do this? What was the point of You were a super I think if it hadn't in all those we likely would not have So where did the Why did we make this Tell us part of that story. EMANUEL TAROPA: Yeah, sure. I mean, it started We were doing the long context this year, and all of and how do we get 1.5 Pro to be And then work on And then at that point, folks we do something like Flash. But like, no, no, no, hang on. Let's do Flash because and it's going to be And there are clear use cases So that has a very clear segment that really wants There are also very for which a smaller, also extremely capable on those work very well. So then we did Flash, and then I really want to be with like post-training or settings, something I alluded to this are coupled very directly or in the main system that and sorting of our results. Can we actually start at that end of the spectrum? So that's basically where well, this is a very And it gives us a from deploying it to was the intended target, to for data center workloads that of queries per second or more. So then, from there if it does the long and how good is it Then it becomes an interesting So then, a couple of and we kind of got the for it done in March. And then as you very took a little bit of how we want to place it, On the same topic should launch faster kind of going forward. Yeah, so that's basically Made sense. And then very little So I guess, yeah. There you go. Yay, validation LOGAN KILPATRICK: I love that. Why-- was it just like to do to make an 8 I had asked on Twitter if conversation and and there was some a lot of companies have 8 Is there like something in the model training process or do you have an intuition reasonably well EMANUEL TAROPA: Again, you're Last year, I said, "hey, nobody's putting LLMs on phones, right?" So we started the As we have a very we want to do something and for our first So then basically, how do we take this where folks maybe haven't do it on phones? And then have something that 100,000 or so could be distributed to 2 instantly. So that was the motivation on device models. We initially started Initially, we had something But then we're like, well, we let's just do Gemini. Let's push this forward. And then you have 4b so these are very natural capabilities also change. And changing the hardware I mean, that will take a while. So like, well, we changed We also change the type So we get a lot of experience if you want, with efficiently from something But then we also look at them wow, these are actually for the internal and with the usual with them, like routing cascading, serving and So if you say, hey, did you ago, and you had the My answer is a very But then things and then it seemed like so then we did it. And then other products overviews, Workspace found value in this And yes, we continue May or may not be [MUSIC PLAYING] LOGAN KILPATRICK: that was impressive about was going back to pushing to get this The memory that was just the weekly post in where you were like, are What's happening? What's getting What's the blocker? I'm curious, maybe less or we can use this launch I think that skill of navigating to get things out that you innately have. Do you have advice for people, as somebody who's about what has historically Is it like finding the which I know there's a ton of places inside of Google Do you have any sort of EMANUEL TAROPA: Yeah, I I worked with a lot of the So that's one. It's something like, you don't and they know they can So street cred, I guess. That's one, right? And then the second is just I mean, nothing off And then I think people respond everything work even if I'm annoying Which is, hey, why Why do we have so in saying yea or nay here? And things like that. But I do think in it is good to call in level as well as the And blameless postmortems, it's And then use that to what we do. It's the thing that has worked I mean, I know it for done it before I joined as an And it seems like it's And barring that, go on a LOGAN KILPATRICK: EMANUEL TAROPA: Go on a hike get sorted out like that I mean, it's common LOGAN KILPATRICK: Yeah, I don't know if this was Jeff about the thousands of that he's had with you over the years. And I feel like that actually At the end of the day, I think which is part of the reason why this stuff out the door. But you have to earn that credit respect and want to listen to. So it's wonderful that You made a comment on the narrative of getting You made a comment about and I this is actually one to me. And I know if this is just of Gemini is such that sort of carry down And without sort of giving of how we make the how is it possible that the And the answer might be but I feel like that's the that the model, even at can do a million token perform pretty reasonably EMANUEL TAROPA: I [LAUGHS] But we do have a fairly that we do model architecture, We insist quite a bit at all sizes of the models. This is not something Or like scaling ladder And then, yes, there will between them, as the But some of them, we are able to models to the smaller ones. So I would say it's a that we use. And in the 8B case, we had a capacity and transferable that we could pull this LOGAN KILPATRICK: EMANUEL TAROPA: So we don't basically, from everything that will not be a recipe LOGAN KILPATRICK: And I actually think a bunch of asked in the comments when I talking was around whether or 8B and things like that carries And just as a that is the value that which is we take all the these models on the of that same innovation ends up which is awesome to see. [MUSIC PLAYING] Part of this, again, of getting this You were originally, and but you were pushing to The price point ended up from a developer perspective. But I actually think there's of the outcome of the price that we've released. I think there's that you are sort of to make things free, to run these models, more and more intelligence into smaller models. The sort of efficiency across serving these models, And ultimately, at a lot of other technologies, to-- like, when I go use of different software I'm actually not usually At scale, CPUs are across hundreds and millions And like, it actually that that same thing will happen small AI models on Does that capture or am I missing EMANUEL TAROPA: It does. One of the very exciting years, two and a half years, of was to see the cost compression. Or best to look at it as get in a particular is how much energy do you need of quality to the end user? And it's been amazing. It's been quite a ride. I've seen it when we are from a few billion documents of documents 18 years ago. And then, I've seen it now. So given the trend that I witnessed very of working on all of the the next thing is giving this as possible for basically as So you can't beat free. So we can start there. I guess you could pay but maybe we don't But you can't beat free, right? So it massively allows what the technology does on their end, and you just How do you stack up that's in the field? And it's an exciting rabid competition here, So allowing people to make a call between you and I think, it's invaluable. So we should strive doing that. And the other one is Having a very cheap-- again, you can't beat free-- way of playing with long context and trying novel there will be glimmers There will be glimmers of, hey, for me, and this is how I built, And great. We've helped somebody. So that satisfaction The other one is, hey, it kind I really need the more capable for these other cases. And at that point, we because that will Again, that's basically what forward, is this balance and the company LOGAN KILPATRICK: Yeah. EMANUEL TAROPA: So why I'm pushing for like, hey, I very directly worked on in efficiency over Let's just make this as well, as much as possible. LOGAN KILPATRICK: Yeah, that the Google You can try the latest sort of There is no cost. There's no payment You can try the long context context window. It's all free. Same thing with the API. Most generous API free tier. 1,500 requests per day. You can use long and actually kick what this model is capable of. And I think removing that to get started, I think I think super, super get to that moment of actually and models being and all the other actually does unlock all these cases that you with other models So hopefully, we're at least to this vision that you have. [MUSIC PLAYING] Do you think there's an That was another Could we do a 4B model Does the trend of continuing to break down at a certain point? EMANUEL TAROPA: I mean, we did. Previous generation I'm not sure to what extent but we kind of did do that. We did use that model very We found very novel which were like actually to me, as well. Like, "hey, can it do this?" Yes. Yes, it can very well. So simplified a lot For instance, for examining And I'm not going to than using 10 or 20 we can use one of these models. And when you cross all the Is, the cost ends lower than sort of a very deployment to run almost-like systems that to ensure a particular quality to the users. So yeah, we did see it. We are continuing We shouldn't aim of having only for the people that Again, sort of back to two we should put this in the hands for-- you can't beat So we strongly believe in This is not just, going to release tiny models. They have to come and the breakthroughs made at the larger So like the Ultras, of compute intensity spent actually transfer pretty [MUSIC PLAYING] LOGAN KILPATRICK: You were a I'm curious. I've seen a bunch of are confused about the name, I think the decision was sort technical report of You also report to Jeff, is supposedly coming up So I'm curious, if we hadn't what is the name that you would EMANUEL TAROPA: I mean, It was there for the oh my God, we're going to spend more or less going to give more details here. But then we ended Yay. Good success. And then, what if we Well, then, we can Just partly joking, But I think it's a A name is a name, right? We should use more of our to generate the names for the That would be pretty neat. Or we can use the date that we Generate a little competition Who ships fastest, and Imagine this, Gemini, I don't for a model that we're going or 3035, or something like that. So that's all the insight We had Flash, and then, what Spark, Swift, Mini LOGAN KILPATRICK: You were I vividly remember you saying EMANUEL TAROPA: I threw a See what sticks. There you go. LOGAN KILPATRICK: Yeah. EMANUEL TAROPA: Sorry. LOGAN KILPATRICK: that the team that gets to decide the name. I feel like that would set up for teams to move quickly. I feel like maybe we'll adopt launches. EMANUEL TAROPA: Yeah, that You get to name it with that it's shipped, and to see who shipped Who took a bet on it, basically. Good or bad, right? I think this will focus to details across all of because A, they'll B, it should be a good launch. LOGAN KILPATRICK: Just before I go to a bunch and then get your closing from the Flash-8B narrative or Any other hopeful thoughts for Anything like that EMANUEL TAROPA: Yeah, I think just, sort of, relentless. Constant pressure, basically. I mean, you know it very well. On the flight to London in June, and the initial while landing and while getting crew saying, hey, you really and I'm like, the So these kind of making it really and they also help a lot And while I am all in particular of sectors move a lot faster than others, thing. And I do think it's an So relentless, constant stuff out very, very quickly. This really drives So sometimes breakthroughs can from the main pressures of But oftentimes, I've that the biggest breakthroughs environments. So I'm really looking forward LOGAN KILPATRICK: So am I. looking forward to it. I also think that-- I wouldn't describe it as the though, I don't sit but I feel like the blue canopy, for anyone in DeepMind is I think, one of the most There's just so many interesting building the frontier. And it feels like in the espresso machine that's sort of fueling that. That espresso machine is on world GDP as far as keeping caffeinated. EMANUEL TAROPA: And carry it from 2008, when I think at that point, We carried it with us across the It's a bit jaded now, if So it's an older model but and we love it. And yeah, it's intense, fun and excited, I guess, all of us. That, again, describes I mean, I don't know but it can be fun and generate and be nonstop, [MUSIC PLAYING] LOGAN KILPATRICK: to a bunch of rapid that people sent in So hopefully, we can get some as well. One of the questions was, will that we used for Flash-8B We talked about that. That's the general philosophy. The second question Anything you can tell EMANUEL TAROPA: Yeah. So on the Gemma side, like two or three weeks ago, with Gemma team. Again, this is like, this accessible to as We have to do this in a way we're doing internally gets released too early, But we do believe very strong Gemma offering, and we do And we're very intentional the type of changes So yes, it's a resounding We're working very closely. It's basically part one team. And then we want to have very good open source can get insights into, like, If anything else, that On 2.0, really good of work in serving which is what we're doing now. But I'll just leave it at that. LOGAN KILPATRICK: I love it. Another question that came in I don't know if we have in the technical report, EMANUEL TAROPA: I and I don't think we're So then we can move LOGAN KILPATRICK: I love it. Another question, why is there We shipped in 002 version of and this was one of the EMANUEL TAROPA: I There you go. So a very quick answer. I mean, I don't know. LOGAN KILPATRICK: Yeah, awesome. EMANUEL TAROPA: There's LOGAN KILPATRICK: I'll So I think the haven't shipped a stable version. But yeah, I do think it is 001 and 002 at the same time. So we'll keep pushing on naming EMANUEL TAROPA: Again, I'm just And I think someone else is we could change Dates seem pretty good. Dates and products seem So then, they'll isn't Gemini app of this particular model? And then, we'll be like, LOGAN KILPATRICK: I Let's do dated version for So we'll consider that EMANUEL TAROPA: Yeah, Sergei I think it's a great idea. We should probably push on this. LOGAN KILPATRICK: I'm with you. Another question. Why do smaller models Is it just like the knowledge is EMANUEL TAROPA: Maybe. It's a good question. I do think the want to tune them more intently like summarization, I think a It comes with It can make it more extractive but also hurts other And it's a balance But think of it as the larger scale application the more finely tuned for This is not to say that small good general capabilities. Like, pick your because there's so many of are already saturated. But to the extent, that's Have a benchmark. Look at what models that were larger, or an order and were a year and a or achieving on those with the smaller models. And yes, caveats and all this, that everyone But it's quite amazing LOGAN KILPATRICK: Yeah. No, I agree with you. Two questions. My second to last question, if you had to use a every single day what would you spend This could be your This could be solving But it has to be an at It can't be like, EMANUEL TAROPA: Yeah, Again, I'm biased. I'm a hardcore slash quality slash is what I would use it for. Access all my help me make sense of help me use it It's a huge inflection We should really make very useful for the end user. The amount of time it saves So I think we should press Again, this is my pet project. This is what I would Who's to say I'm not and I'll leave it at that. LOGAN KILPATRICK: I love is, it would probably only cost if you were actually running Ema, this has been wonderful. The final question, and then and get back to work. And hopefully, I'll see We can go for our run. What is keeping you to push and get these models Is it that narrative mentioned of retrieval What is the thing that is and excited? EMANUEL TAROPA: It varies Did the last night If it didn't, then maybe we right? It's the set of and it's the step function Peeling everything what makes me very And there are so many places can have this type of impact. So I mean, from an what more can one ask for? LOGAN KILPATRICK: Ema, this was an Thank you for taking the time Yeah, I'm excited. Hopefully we'll have We'll have you back on. And yeah, thanks for EMANUEL TAROPA: to the Strava run. We have to do our We'll arrange it to and stuff like that but we should make it happen. LOGAN KILPATRICK: We That's the easiest have to solve, so I I'll see you later. EMANUEL TAROPA: Bye. Thank you. Bye. LOGAN KILPATRICK: So that I'm so glad that I got a Hopefully you all enjoyed And for me, candidly, to do this conversation, was actually seeing the around the pace in and what I've experienced So I'm hopeful that this behind the scenes, as happens at Google, what it takes And also, just another quick take a village of people to I think me and Ema sort and represented a but it really does take like amazing people inside of to get to call teammates. Shipping stuff and especially really is a team sport. So I'm excited that we get