Here it is my friends concrete proof that satire truly is dead the 36 Nvidia grace Blackwell super chips and is estimated to cost over Obviously the big heat sink on the side is illustrative. You won't You happen to have a hundred thousand watts of power on tap and a But many of the technologies nvidia is introducing here will The biggest one isn't really obvious until you go under the hood in GB 200 Super chip now some of this we've seen before like this 72 core But these puppies right here these are all new very very exciting Do you guys see this tiny tiny line here thinner than the width of That is the gap between the two black well dies that make up a B200 Wait a second gpu Is that not two gpus? Yes, but also no While SLI might be dead for consumers, NVIDIA has been hard at work allowing multiple GPU dies to now act as a single GPU that allow multiple GPUs to act as a single super chip and that allow multiple super chips to act as a single- oh no! to act as a single cohesive processing unit and it is going to You speak English, right? Yes, I speak English. How can I help you? Do you speak chinese? I can speak a little, but it's not my expertise. Can you also speak segue to our sponsor? No, I am also skilled in survival and archery. Yes, you can. Yes, you can. It's fine. Ridge. Ridge has got your last-minute Father's Day gift covered Click on our link in the description and get up to 40% off their We'll get to the demos in a bit, but first, let's take a closer look at the product that is turning global tech media into Jensen Huang's Swifties. Nvidia chose not to disclose the number of CUDA cores, tensor cores, or even the size of the on-die caches of their new B200 Blackwell GPU, but they did give us some numbers to work with. Apples to Apples, they expected to hit around 10. Petaflops at FP8 sparse, which puts it roughly two and a half times each of these is expected to draw about a thousand watts hence the Liquid cooling each of our GPUs gets 192 gigabytes of HBM 3e high speed memory running at a casual 8 Equipped with 1.8 terabyte per second envy link and these numbers Whole each superchip has to B200 GPUs and a gray CPU for a total 72 arm CPU cores 864 gigabytes of RAM and draws a total of 2700 watts oh and by the way each of the 18 of these Blackwell compute nodes that make up an nvl-72 rack contains two Superchips good lord in California the rack that I was standing next to in the intro would $30 an hour to run or about a quarter million dollars a year Assuming you're paying residential energy rates speaking of running I'm gonna have to tell you about the spline on our way out of here. We got our hands, however temporarily, on what NVIDIA is calling This here contains 5,000 wires totaling over 2 miles, and is cleverly laid out to optimize the latency and power See, the networking all goes in the middle, right here, and the Blackwell compute nodes, like the one they just took from Now, they could have used fiber optics, except that that would have cost them a casual 20,000 watts of additional power consumption, so clever layout for the win. Put it all together and you've got a whopping 72 Blackwell GPUs, 2,600 gray CPU cores, 13.5 terabytes of HBM3E memory with over half That's good for 720 petaflops of FP8 training, delivering results And, if you didn't notice, with perfect linear scaling. Something that is only possible when integrating your system this tightly. Even the placement of the individual blades matter on our super micro rack that we're looking at here You can see that they've got 10 up top and 8 at the bottom with the 9 NVLink switch units sandwiched in between That's because timing the electrical signals matters a lot and is Unfortunately NVIDIA didn't have a switch for us to show you This piece of plastic, but each of the nine units can handle 14.4 terabytes per second of NB-Link. It is so integrated that entire rack as one massive power hungry single GPU and It's kind of hard to argue otherwise other than that most of the It's not doing graphics and I thought that's what the G was for and the craziest part is we haven't even looked at the craziest systems yet That was all MGX, a standard set of reference designs that's intended to be compatible with multiple generations, hence the MG. HGX is a whole different beast. In this, or on it, it is eight Blackwell B200 GPUs with a combined Absolutely ridiculous. But the difference between this and what I just showed you is This is purely a GPU board because this insanity is meant to be Now, Nvidia does sell their own DGX unit with this board and the But that's mostly intended to be a reference system. These eight GPUs. Get combined with NVLink, just like the rack setup, for a whopping 72 petaflops of FP8 training, while drawing nearly, really, 10,000 watts? Now, naturally, this much power is a little hard to cool, which is But the good thing about it is it doesn't require messing around If you're installing these into an existing data center, since those practically don't exist. So you've got to spread them out a little bit according to your And that is where Nvidia's new hardware networking products come in. This ethernet switch will do something in the neighborhood if I Which is all really cool, but what are we doing with this exactly? I don't know how about health care the tools I'm looking at right Generate potential drug molecules to disable them and then test Finding exactly what it is you're supposed to be taking a picture Why not let the machine identify it for you? That's all left Cool. Know what else is cool? Simulations like the one we're living in Behind me is earth 2 a climate and weather simulation program that A one kilometer by one kilometer basis ish, which is pretty cool But what if you need to simulate the movement of hot and cold air Well, you can do that too. That is nuts, which is all cool But what if I can't afford a DGX or an MGX to train those data sets? Well, you can still use or experience NVIDIA's new NIMS or NVIDIA NIMS are pre-trained and pre-optimized containerized AI models that And if that all sounded like gobbledygook, let's go back to that Facial animations can be an extremely time-consuming component of and are one of the big reasons that localization can be such a The NIM in use here allows automatic mapping of speech-to-mouth Meanwhile, this guy takes things two steps further, using NIMs for but also a third one that I think is perhaps the most interesting to me. There's a major concern right now in the games industry that AI is But this guy uses a NIM for data retrieval that is part of in- Instead of him just crapping out whatever response chat GPT might throw at you, he's actually got an extensive backstory that does need to be context-specific information that will help you advance the story. Now that is really cool, and we're just scratching the surface Nvidia is going to be looking to the gaming community, both gamers for inspiration for what to do with these, and oh, I've got G-Assist here might just be a tech demo at the moment, but it's a pretty darn compelling one. How do I craft a stone axe? Okay, that is cool, but what dinosaur am I looking at right now? Okay, that's kind of sick. And what's cool is the image recognition, and I believe the voice-to-text are both running locally on this RTX Series GPU. I don't know about you guys, but I think this is so cool that I don't know what to say gue to our sponsor. Backblaze. Losing your data is never fun. So having solid backups of everything is super important. And Backblaze is an affordable, easy-to-use cloud backup solution You can backup almost anything from your Mac or PC and access it anywhere in the world with their web and mobile apps. And they've restored over 55 billion files. With multiple options for how you can retrieve your data, including And if you're worried about accidentally deleting files, you can Plus, for organizational and business purposes, their advanced Backblaze has over 3 exabytes of data under their management and has the trust of over half a million customers. Including us. That's right. We not only work with them on a sponsored basis, we actually back So starting at $9 a month, it is hard to find a better investment So sign up today and get a free 15-day trial at backblaze.com/LTT. If you guys enjoyed this video, why not check out our video from We got a little bit more into the weeds and it was very, very cool.