Intro I got a lot of feedback from you on the with Golang. In this video, I decided to of both applications and discuss some To make this test more fair, I will both applications to create a simple I compared the Go standard library I've also got a few pull and I'll link them in the video description. To run the test, I use a production-ready and clients that generate load to that similar to what you would expect As always, in the first test, we'll measure each application can handle, CPU usage relative we'll look at the availability graph, requests over a total number of requests For the second test, I decided to we'll discuss how Kubernetes limits affect a properly configured Golang application--where the Kubernetes--against the default settings that many the GOMAXPROCS environment variable, and in the My goal for these benchmarks is not only applications but also to learn new techniques to share them with you. First, let's talk about Node.js. It is famously it creates one main thread for most it creates four more threads. However, none database operations. One thread is for the DNS the third is for cryptography (because it is Most of the work is actually done on the main of the work can be handled in the background this single-threaded model can even be more and I'll explain why in a moment. The problem with a single thread is that even always run on one core at a time. This doesn't operating system may migrate it to another core. is running on multiple cores simultaneously--it is The issue with the previous benchmark is that Golang applications. We'll cover these due to its single-threaded model, could whereas Golang, with its much better utilize all available cores and run tasks not Now there are two main ways to improve Node.js to use clustering mode and deploy the application second, and better approach, is to set a horizontally in Kubernetes. That's what let's cover Kubernetes requests and limits. In this example, a CPU limit of 250 is set. called millicores, which represent if you want a service to use 100% of a single value of 250 means the service is limited Most Kubernetes clusters today use cgroups to isolate containers Let's start with a simple example: with a single CPU. This could be either in a multi-core processor. By default, interval to distribute CPU time among You can think of 1 CPU defined in the which translates to 100 ms of CPU time. it would correspond to 25 ms of CPU If the application exceeds the time 100ms interval, Kubernetes starts to The key to better understanding is to interval that Kubernetes uses via cgroups this was managed using the cfs_quota_us and and replaced them with a single cpu.max file, For example, let's say we have an application with would look something like this: the first value (translating to 25 milliseconds and 250 time interval, which is 100,000 microseconds, This 100ms cycle repeats continuously as long as have 1 CPU, which equals 1000 millicores, with a single CPU, we have 100ms of CPU time on the node, proportionally distributed If there was only one service running on the to that service for each cycle by setting its you might want them to share the CPU equally. In giving each 50ms of time within every 100ms you could assign each 250m, giving each 25ms CPU time doesn't have to be distributed equally. which is 50ms, a second service 100m services 200m each which is 20ms each, for a When a node has 2 CPU cores, it now has 2000m or the different services running on it. For example, This service would then use a full 100ms if there's another service with a 500m limit, it As you can see, the more CPU cores you allowing you to schedule Up to this point, we've assumed that each entire interval. However, in reality, this and OS threads are typically subject to a 10ms meaning the thread will migrate between cores. Now, let's say you have 4 threads running benchmark with a Golang application. there are cores. In the previous video, I If I set a service limit to 250 and have 4 threads that limit will be reached 4 times faster. reducing the amount of work done over A limit of 1000m or 100ms or lower means the cycle. For services written in Go, understanding CPU-bound. With CPU-bound programs, you never And that's why we need to set GOMAXPROCS for our program. You can read more article. To run these tests, I used a production-ready instances to run my clients that generate Alright, let's go ahead and deploy both multiple pods for each application, I'll use the rather than tracking every single pod individually Node.js uses slightly more CPU than Golang, For the first test, I set GOMAXPROCS to You can hardcode it to 1 in this instance or Alright, let me start the test and deploy At the start, you can see that the p99 and it also uses a bit more CPU. I the number of virtual users until You can also notice that Node.js uses more Up until 16,000 requests per second, Golang's to converge at this point, and eventually, By the time we reach 34,000 requests Node.js is being throttled by Kubernetes, and latency. At this point, Node.js begins to At around 46,000 requests per second, and you can see its latency increasing as well. At around 52,000 requests per second, no longer handle any additional requests. However, its latency is still quite close to Golang's, At around 70,000 requests per second, Golang two pods with a 1-CPU limit each, so each instance Alright, let's take a look at the First, we have requests per second. Node.js processes many more requests than in the limit to 1 and scaling horizontally rather At around 36,000 requests per but it can still process some additional requests. Next, we have p99 client latency. Lower but it's not as dramatic as in the it stayed within acceptable It only reached 20 milliseconds. Now, let's look at the latency before both say that Node.js is a little more stable but it has fewer spikes until it reaches the Next, we have CPU usage. The the sooner Kubernetes will throttle it, it's always important to monitor how Next, we have memory usage. If Golang will start caching more and 100% memory usage and getting killed by Next availability. I set a timeout of 1 never reached by any of the clients, so that's Finally, CPU throttling. Since we set the there was less thread migration and wasted CPU, That's all for the first test. Node.js is still requires more attention to deployment due to I would suggest thinking about how you can and perhaps have autoscaling in place. Alright, let's go ahead and run the test between typical default deployment, where you not limit the number of Golang threads At the start, you can see that the p99 latency and it also uses less CPU time. The default setting GOMAXPROCS to match the number Both applications have a 1-CPU limit, but threads as there are cores--in this case, 2. the properly deployed Golang application where the number of threads is not adjusted In this test, we also deploy 20 number of virtual clients from 1 to by the end, we have around 2,000 virtual When we reach 30,000 requests per second, you increases, reaching 1 millisecond, while you could set up a horizontal pod of replicas when CPU usage reaches around to load-test your application and find out at applications have different bottlenecks. Some are At around 36,000 requests per that Kubernetes begins throttling At around 53,000 requests per second, Kubernetes setup, which represents the maximum number can handle. Let's keep going until the properly At around 70,000 requests per second, you and this represents the maximum number of Let me go ahead and open each First, we have requests per second. The handle only around 53,000 requests per version handled around 70,000 requests per Next, we have latency. You can see huge spikes in Every time Kubernetes throttles the application, Next, CPU usage. Once again, the default setup and due to thread migrations, it wasted more CPU. Next, memory usage. Memory usage default setup is slower and caches more requests. There are no changes in availability. The most important metric for this test is Golang application is throttled much more than the This demonstrates that by understanding how improve the performance of your Golang variable is only applicable to Golang, and when I how to efficiently deploy them in Kubernetes. interesting. Thank you for watching,