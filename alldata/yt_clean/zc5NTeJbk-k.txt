This is an artificial intelligence image it will create, out of nothing, an image it is capable of generating high quality And it's not just images, in recent developed that can generate text, audio, models are based on the same underlying In a few of my previous videos, I've explained But I only explained how neural nets can the neural net is trained with a bunch of tries to predict what the label will be for a new if you trained a neural net on images labelled that neural net would learn to predict which even for new images which it hasn't seen before. are solved is by converting the training dataset a curve through those points, so prediction And while prediction is certainly cool and very is just fitting a curve to a set of points. the creativity of these generative models come Well, all of these generative models, it turns out that the process of reduced to a curve fitting exercise. And Suppose that we have a training dataset to train a neural net to create new images which The first thing you might try is to train the predictor. Here we don't care so we can just use anything we like for black image. Predictors learn to map inputs to this predictor, once trained, should be able like those seen in the training set, right? Err, instead of producing a nice, beautiful This demonstrates a very important fact about labels for the same input, the predictor labels. For traditional classification because the average of multiple class labels this image could plausibly be given two valid labels. In this case a classifier would which means you end up with a score of 0.5 cat and it's arguably a better label than either of the a bunch of images together you do not get a Let's try something a bit easier this time. How scratch, we try to complete an image which has really easy and suppose there is only one Can we train a neural net to predict the as before, the neural net is going to that the missing pixel can take. But since the average value is still meaningful. The average there's no blurring effect. So, And we can use the value predicted by this neural net to complete images which are Great, so we can complete images Well, we can do the same thing again, train pixels, using the value of the second missing net to fill in the second missing pixel. Now and so we can use the first And we can do this for every pixel in the image; pixel when it and all of the subsequent an image starting from a fully black image, each neural net only predicts one pixel, And there we have it, we have just generated a one small problem. If we run this model again, creative, is it? But not to worry, we can fix this all predictors actually output a probability we just take the label with the largest if we want diversity in our outputs, we this probability distribution. This way, different values at each step, which therefore and we get a completely different image each But still, at the end of the day, this model is masked image, and predict the value of the next traditional image classifier is the label we used to be pixel colors which come from the original a very important point in practice: it means for this model, we can just scrape unlabelled view of the neural net, it doesn't know, nor original image. As far as it's concerned this is The generative model we've just created is called which removes pixels one at a time, and we train adding back in pixels one at a time. This is the very earliest use of auto-regression dates timing of sunspots. But auto-regressors Chat-GPT is an auto-regressor. Chat-GPT generates a probability distribution over possible next auto-regressors are not used to generate while they can generate very realistic In order to generate a sample we need to evaluate a neural net once generating a few thousand words to make have tens of millions of pixels. How can we For our auto-regressor, we removed one pixel at a we could, for example, remove a 4 train the neural net to predict This way, when we use our it can produce 16 pixels per evaluation, But there is a limit to this. We can't generate case, if we try to generate every pixel in original problem: there are many possible labels To be clear, the reason why the when we predict a bunch of pixels at the same all of them at once. There are lots of plausible and so the model outputs the average make sure that the generated values are when we predict one pixel at a time, the model and so the model can change its prediction for already been generated. This is why there's a the less computation we need to use, but the Although, this problem only arises if the each other. Suppose that the values were that is, knowing one of them does not the model doesn't need look at since knowing what they were wouldn't change this case you can predict all of them at So, that means, ideally, we want our model to each other. For natural images, nearby because they are usually part of the same often gives you a good idea of what color nearby in contiguous chunks is actually the worst way to are far away from each other, and hence more we remove a random set of pixels, and predict in each step for the same loss in image In order to minimize the number of steps we remove in each step to be as spread out as a pretty good way of maximizing the average We can think of our generative model as two removes information from the input, until that uses neural nets to undo the removal process, we have been completely removing pixels. we could instead remove only some of the adding a small amount of random noise to it. original pixel value was, but we do know it instead of removing a bunch of pixels in each This way, we can remove information from which is the most spread-out way of removing you can remove more information in each step, There is one small problem with this though. When the neural net off with some initial blank image. eventually ends up as a completely black image, process from. But now that we're adding noise, never converging to anything. So where We can avoid this problem by changing first scale down the original value and when we repeat this noising step many image will disappear, and the result will the noise distribution. So we can start our And there we have it, this is known as a denoising to an auto-regressor, the only difference is step. By adding noise, we can spread out the which makes the predicted values as independent fewer neural net evaluations. Empirically, photo-realistic images in about a hundred steps, Now that we understand how these generative models work at a conceptual level, if you are ever there are a few important technical First, in the procedure I described for net in each step of the process. This is certainly but it's also very inefficient, since we neural nets. In practice, you would just use slightly worse predictions, but the savings In order to train a single neural net you would remove a random number of neural net to predict the corresponding you can also give the number of pixels removed as pixel it's supposed to be generating. Now this one In the setup I just described, for is trained on only one generation we would like to train it on every generation of our training data that way. If you did the neural net once for every generation Fortunately, there exist special neural net that allow you to train on all of these the neural net once. There exist causal versions such as causal convolutional neural architectures actually give slightly auto-regression is almost always done with causal faster. The generation process for causal For diffusion models, you can't use have to just train with each data I described the diffusion model as predicting step. However, it's actually better to predict step. The reason for this is it makes the it predict the noisy next step image, then the at all different noise levels. This means learning to produce noisy versions of images. predict the clean image, then the model only which is all we care about. You can then the noising process to it to get the Except that when you predict the clean image process the model has only pure noise as input, so and so you get a blurry mess again. To avoid the noise which was added to the image. Once we it into this equation to get a prediction for the the original clean image, just in a round-about now, the model output is uncertain at the since any noise could have been added to average of a bunch of different noise So far we've just been generating images from allow you to provide a text prompt describing works is exactly the same, you just give the each step. These models are trained on pairs of usually scraped from image alt text tags found image is something for which the text prompt could In principle, you can condition not just text, so long as you can find here is a generative model that Finally, there's a technique to make called classifier free guidance. For this, be given the text-prompts as additional the same model learns to do predictions with or at each step of the denoising process, the and once without. The prediction without the the prompt, which removes details that are only details that came from the prompt, leading to In conclusion, generative AI, like all And that's all for this video. If you enjoyed any suggestions for topics you'd like to me to