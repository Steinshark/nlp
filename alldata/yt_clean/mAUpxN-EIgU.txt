- The video captures sort when it comes to the hair and you know, sort of like professionally-styled women. - But you can also see some issues. - Certainly, especially - [Joanna] These two women, not real. They were created by Sora, OpenAI's text-to-video AI model. But these two women, very real. - I'm Mira Murati, CTO of OpenAI. - And former CEO. - Yes, for two days. - [Joanna] In November when was momentarily ousted, Murati stepped in. Now she's back to her previous job running all the tech at - Sora is our video generation model. It is just based on a text prompt and it creates this hyper highly-detailed videos - [Joanna] I've been blown away yet also concerned about their impact. So I asked OpenAI to generate and sat down with Murati How does Sora work? - It's fundamentally a diffusion model which is a type of generative model. It creates a more distilled image starting from random noise. - [Joanna] Okay, here are the basics. The AI model analyzed lots of videos and learned to identify When given a text prompt, it creates a scene by and adding detail to each frame. What makes this AI video is how smooth and realistic it looks. - If you think about filmmaking, people have to make sure into the next frame with between objects and people. And that's what gives and a sense of presence. And if you break that between frames, then you get this disconnected sense and reality is no longer there. And so this is what Sora does really well. - You can see lots of that smoothness in the videos OpenAI generated But you can also see flaws and glitches. A female video producer on holding a high-end cinema camera. Suddenly, a robot yanks - So in this one, you can see the model doesn't follow the prompt very closely. The robot doesn't quite yank but the person sort of Yeah, a lot of imperfections still. - One thing I noticed there too is when the cars are going by, they change colors. - Yeah, so while the model it's not perfect. So you kind of see the from the frame there for a while and then it comes back - Would there be a way &quot;Fix the taxi cabs in the back?&quot; - Yeah, so eventually. That's what we're trying to figure out, how to use this technology as a tool that people can edit and create with. - I wanted to go through one other... What do you think the prompt was? - It looks like the bull in a China shop. Yeah, metaphorically, you'd imagine everything And you see in some cases on things and they're still perfect. They're not breaking. So that's to be expected this early on. And eventually, there's and control and more accuracy in reflecting the intent of what you want. - And then there was The woman on the left looks like she has maybe like 15 - [Mira] Hands actually and it's very difficult to - In the clip, the mouths So is audio something - With Sora specifically, not in this moment. But we will eventually. - [Joanna] Every time I watch a Sora clip, I wonder what videos did Did the model see any clips of Ferdinand to know what a bull in a Was it a fan of SpongeBob? - Wow! You look real good with - By the way, my prompt for this crab said What data was used to train Sora? - We used publicly available - So, videos on YouTube. - I'm actually not sure about that. - Okay. Videos from Facebook, Instagram. - You know, if they publicly available to use, there might be the data, but I'm not sure. I'm not confident about it. - What about Shutterstock? I know you guys have a deal with them. - I'm just not gonna go that was used, but it was publicly - [Joanna] After the interview, Murati confirmed that the licensed data does include content from Shutterstock. Those videos are 720p, 20 seconds long. How long does it take to generate those? - It could take a few minutes depending on the complexity of the prompt. Our goal was to really focus on developing the best capability and now we will start looking so people can use it at low - To create these, you must be using a Can you give me a sense of to create something like that versus a ChatGPT response - ChatGPT and DALL-E are optimized for the public to be using them, whereas Sora is really a research output. It's much, much more expensive. We don't know what it's when we make it available but we're trying to make it available at similar cost eventually - You said eventually. When is eventually? - I'm hoping definitely this year, but could be a few months. - There's an election in November. You think before or after that? - You know, that's dealing with the issues of misinformation and harmful bias. And we will not be releasing anything that we don't feel confident on when it comes to how it or other issues. - Right now Sora is going AKA the process where people test the tool to make sure it's safe, The goal is to identify and other harmful issues. What are things that to generate with this? - Well, we haven't made but I think there will be So similarly to DALL-E where you can't generate I expect that we'll have And right now we're in discovery mode and we haven't figured out exactly where all the limitations are and how we'll navigate - What about nudity? - I'm not sure. You can imagine that... You know, there are creative settings in which artists might want to And right now, we are working with artists and creators from different fields to figure out exactly what's useful, what level of flexibility - How do you make sure that people who are testing these products with illicit or harmful content? - That's certainly difficult. And in the very early stages, it is part of red teaming. Something that you have and make sure that people are When we work with contractors, we go much further into that process, but that is certainly something difficult. - We're laughing at some But people in the video in a few years when is impacting their jobs. - You know, the way that for extending creativity and we want people in the film industry, creators everywhere, to be a part of informing and also how we deploy it. And also, you know, what are the economics around using these models when people are - One thing was clear from all this. This tech is going to and become widely available. How are we going to tell the difference between what is real video - We're doing research and but really figuring out content provenance and how do you trust what is real content versus something that happened in reality versus content created for misinformation. And this is the reason why we're actually not because we need to figure out these issues before we can confidently - [Joanna] That was reassuring to hear. But there are still big concerns about Silicon Valley's and its ambition for power - It's not really a difficult between profit and safety guardrails. I'd say the hard part the safety questions and That's really what keeps me up at night. - There's this amazement but then we've also talked Is it worth it? - It's definitely worth it. AI tools will extend our collective imagination, ability to do anything. It's going to be extremely to figure out the right into our day-to-day reality. But I think it's definitely worth trying.