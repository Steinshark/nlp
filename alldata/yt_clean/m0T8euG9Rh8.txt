All right, everyone. Hello. Hello, hello, hello. Welcome to &quot;I Wish I Learned This Sooner,&quot; the talk where I go back about eight or so years to my naive little self and say, hey, listen up, buster. Here's the right way to do things. Of course, in Unreal Engine, there's 1,000 different ways to do things. And that's a good thing I wish I learned sooner, too, that there's no objectively right or wrong way to do most of these things. There's just some that work better in different situations. And as part of this talk, I'm hoping to convey and impart to you all here, thank you for coming, some of these lessons that myself and my company have learned over the years. Now, I do need to caveat this a little bit with calling this part one, because I did a run through of this the other day, and it was three hours. So as much as I'd love to hold you all here for three hours or talk at my natural speed and just go, hey, we're going to go through everything really quick and you're just going to see it all and you can play it back on YouTube and 0.25x speed, I know that would drive some of you up the wall, especially if English isn't your first language. So instead we're going to take things a little bit easier, and I'm hoping I get to do another part of this. So you're going to see a heavily curated version of this. And first of all, hey, not all of you know me. I should say hi. My name is Alex. What are a few things you should know about me? I am an Unreal Engine authorized instructor partner. I've been doing some fun work as a friend of Epic Games for a long time. I am not an employee of Epic Games, so nothing here is official Epic anything. But I'm very grateful that I was invited to come here and talk about this stuff with you all. I've created and taught many instructor led courses on behalf of Epic Games. If you go to unrealengine.com/training and look at the course catalog, I'm happy to say 25 of those courses have my stamp on it. So I've been educating for a while. I now fairly recently have opened the only Unreal Engine Authorized Training Center in Manhattan. I am going to be involved very soon with the Unreal Fellowship For Games. It'll be my first fellowship, and I'm excited to help out on the education front there. I co-host a little podcast called The Unofficial Unreal Engine Podcast. Works pretty well in totally audio format. We also have a YouTube channel with some fun virtual production, fake digital rooms. Thanks to Light Twist for providing us with that. And lastly, I run the New York city creative studio, Agile Lens Immersive Design, and we do a lot of work across architecture and live events and general emerging tech, R&amp;D sort of stuff, that Unreal Engine and similar software is very good for. # I'm also a very big fan of the #UETips. And so if you find me on Twitter or anywhere like that, you'll find me often trying to give tips like what you're going to see today and also retweeting other folks who use that hashtag. So what's the goal of this talk? I would say it's to make you a little bit sad, maybe a little bit angry. I hope that at least a few times over the course of the next hour, you grumble to yourself, maybe out loud, I wish I learned this sooner. Because you're thinking about all the time you would have saved if you only knew these things a little bit sooner. And I feel your pain, because some of the things that are in this talk today are things that I just learned a week or so ago. I very kindly thank you to everyone who responded to me asking on social media, what are the things you wish you learned sooner? Some of the things up here are things that I didn't know, and so I also wish that I learned them sooner. But hopefully by the end of today, there's some things that you've gotten a brief overview of that you get excited about. Hopefully these are-- it's a bit of a teaser, a bit of a taster. We're not going into deep, deep detail with any of these things, but I hope I'm piquing your interest with some of what we cover. And then you're going to go and look at these more and find all sorts of great videos and other discussions about them. Though I should also mention that most of the slides here are also-- each slide is a two hour course in its own right. So if you really want to know more about the Variant Manager, we can talk just about the Variant Manager for two hours. So keep that in mind. Topics. I did try to divide this up into some different categories. And yes, we are going to talk about virtual reality. Sorry for anyone in the room who's like, I do not care about virtual reality. It's still helpful for mobile development, and a lot of these techniques are useful in other situations. Virtual production, for example. But it's my passion, my favorite topic, so we'll get to that. Also, if you scan that QR code, you can get a copy of today's slide deck. So I hope you enjoy that. Three, two, one, next slide. Editor. We're going to start off with the editor. Sorry for anyone who missed it. It'll be on Twitter and that too. One more chance. One more chance. Three, two, one, next slide. OK. So let's go ahead and open up a sample project. Because why make this easy for myself? Let's do a live demo where everything can go wrong, and let's see what happens. So let's go ahead and open up the Wish I Learned project. And I am really looking forward to showing you some stuff. OK, hold on. Would you like to rebuild? I'm going to say no. OK. But we got some modules missing. No. OK. It's not opening. Well, darn, I don't know if any of you have encountered this before, but this can be a little bit frustrating, especially if it's not even that you upgraded to a new version of Unreal Engine. You just moved it to a different computer or something like that. And yes, of course, I'd love to go over with you all the ways you should be opening up Visual Studio to debug C++ classes and things like that. But I want to start with the really simple tips. And if you are trying to open up a project and it's giving you module errors, C++ errors, I would recommend starting with just try removing the C++. [GASPS] Oh no, don't do that. But it's just if you want to get the project open and kind of get started. So there's a couple of things you want to be thinking about in that situation. First would be the source folder. If there's any classes in there that aren't compiling properly, then I'll often start by just renaming my source folder something like backup. So now it's not being recognized as a source folder, but I haven't quite deleted everything. I might have some plugins that require C++. In this case I don't, but I might also disable my custom plugins and also call that plugins backup. And then the last thing, and this is the one that I actually did not know about for a long time, is if you open up your .u project file. I've just got Notepad++ up here. All you really need to do to kind of forget about C++ for a little bit is to go into modules and just delete this. Just kill it. And if you hit save, and you could do the same thing if you needed to disable certain plugins. We could go disable, disable, or false, false, false, I suppose. And if we save that and close it now, let's see what happens if we open it. OK, so let's see. It is opening, but oh no, we've got 8,000 shaders. That's going to take forever. Matt actually covered this tip very well in the talk before mine. But I highly recommend when you are using Unreal Engine to go ahead and try to open up into an empty level. So here, of course, we have what we would call a super heavy level. Look at that red. I don't think you should do that unless there's some reason why that is the only level you care about and you just want to go get a coffee and come back and have everything be ready to go. Ideally, you are opening it up into a level that is basically empty. And so of course, the easy way to do that is we could go in and we can change our editor startup map. And we could make it one that's simpler. In this case, there's a main map I quite like that is much lighter. Or I could go and do something like new level, create an empty level, save that. And that's just what we boot into. Ever since Unreal 5.1, we have on demand shader compilation. And that also helps cut down quite a bit on the amount of time it takes to get a project open. And you do need to keep in mind that if you're going to be opening up sublevels, et cetera later, that they will need to compile shaders. Maybe the biggest place I noticed this bottleneck is with the movie render queue now. You'll be like, OK, let's make my cinematic, and then it's 12,000 shaders compiling later before it actually happens. So do be aware of that. If you do want to compile all your shaders once you've opened everything up, I recommend using your filters. If you don't know about the filters, that's also a great tip. Just find the level filter. And I will click on Content and click Levels and I'll just basically grab all of those and right click them. And that will also often cause them to load. And if you're suspicious and like, I don't know, maybe they didn't load, you can also open up levels. And even if you don't actually want these to talk to each other, as long as there's not world partition going on, you can just drag them all into levels. And that will actually get them to all load and compile and exactly. You can see down there, it starts to compile shaders and do whatever else it needs to do to prepare. OK, let's go back over to our-- so yes, we went through this. If you get any kind of errors about your project not compiling when it opens, start with just removing C++. Then you can go into the great wide world of visual studio. Don't open your project into a super heavy level. Even something like the electric dream sample. I quite like that even though the PCG content there is enormous. It doesn't open up into that huge level. Same thing as far back as the kite demo. That was opening up into an empty level. So the PCG one for electric dreams has a much reduced, shorter, simpler project that you can open into, or a level rather. And then if you want to then go into the vast expanses of what's possible, you can do that as well. Next tip I want to go over is cooling your computer. If anyone has a stinky old laptop and they're like, I sure wish I could run Unreal Engine on this, there's actually a good chance you can. And so especially as someone who for a very long time was trying to run Unreal on something that had a GTX 970 mobile edition, I wish that someone had told me that there are some pretty good ways in Unreal Engine to simplify what is being rendered. So let's start with the basics. Of course, over in our settings up here, we have the engine scalability settings. And of course, having those Epic, Cinematic, et cetera, that's going to be more taxing. That's going to be heavier. One thing we can do is try to crank everything down to low. Now, that will often trigger new shaders compiling and that sort of thing. But the other thing I want you to be aware of, and let's go ahead and open up into our main map here, is that if you have Lumen and Nanite in your scene, you can see I'm a big fan of the content examples. So kind of aping that. If you don't know what the content examples are, by the way, there's a tip. Keep opening that. It's updated all the time. It's a wonderful sample project. But I was saying if you have Lumen and Nanite, you have to be careful. Because if you bring your scalability down too low and then I try to look at my Lumen scene, you'll see nothing's happening here because I'm actually at too low of a setting to see Lumen, global illumination, or reflections. You actually need to be at at least high for that to work. So now we can start to see how Lumen views this. If we want to check reflections, we can actually go to the reflections view mode. And you can actually watch in real time as we kind of cycle through the different reflection capabilities. So right now we are actually using Lumen, and then here is basically just screen space, and then there is almost nothing. Very, very small things visible there. And as long as we're looking at the view modes, these are also a great way to improve your editor performance. If you want to just go to unlit mode, if you don't need to know what the lighting looks like, you just care about textures. If you want to go to lighting only and you just want to see exactly that, how the lighting is going, that's going to be a lot less for Unreal Engine to think about. And while we are trying to think about is this actually running smoothly or not, I also highly recommend popping into your editor preferences. And there is an option here for show frame rate and memory. And you're saying, Alex, I already know how to show my frame rate and memory and all that. I can do that over here. And so we have show FPS and show stats. But that takes up some screen real estate and it kind of, for me at least, is distracting and clutters up the viewport. So I like this one, because for anyone who didn't notice, keep your eye on the upper right there. It just shows it to you in this very discreet way, and we can see we're hitting 120 FPS. This is a pretty powerful computer. We're not going to have any problems with it. But I like just being able to glance up there and see how's everything doing in the editor? My favorite tip, and I have to give credit to Alex Morrow, who gave me this a couple of weeks ago at a hackathon that Meta was hosting for VR, and my laptop was overheating so much. He's like, you know, if you just are in the editor and you type t.maxfps, which I've used before, but only in a build environment. If I want to set 60 as my frames per second as a fixed frame rate for the project, I'll use a command like this sometimes. But it's also great to use in the editor. So if I wanted to say, my laptop is so hot. And I can get away with, I don't know, 30 frames per second in the editor. Maybe you're OK with 15. As soon as I hit that, you'll notice in the upper right, we're dropping down to 30 frames per second. So you're actually telling Unreal Engine just for this editor session, it's OK. You don't have to work as hard as we want you to work when we're actually packaging and making a build. So I should mention as well that in the project settings, we can do fixed frame rate, but the con of this is you need to remember then if you're going to set this to something like 30 to turn this off before you package, because then you'll end up with a project that is built and shipped and you're like, why is everyone getting such terrible performance? Because you did that, you dummy. So it's like a pro and con of how you want to handle this. But I often like to be able to enter cvars right down there in the console command just for a given editor session. And I'm also a crazy person who will leave the same Unreal Engine project open for like four days at a time. And all that's going to persist as long as you are in that particular scenario. What else? What else? View modes. Real time override. Yeah, this is another good one that I didn't know about for a while. If you hit the dropdown over here, we're real time. It's a real time engine. We're seeing everything happen at 120 frames per second, or in this case, 30. I can crank that back up if I want to. But if I uncheck real time, if I had things in the scene like particle effects or metahuman hair grooms that are definitely taking up some processing power, if I turn real time off, it's not locking my viewport or anything. I can still move around. But you're now not doing any of those real time calculations just in editor. So that's another really useful saving, and it's easy enough to toggle on and off. You will see the first time you do that, you have to do it in two steps. You have to disable the real time override there. But then you're here. And before I forget, let's go ahead and give ourselves a nice frame rate again. Let's go back to 120. I don't even have to make it a max. Here's a quick tip. Generally in Unreal Engine, if there is an opportunity to enter a number, entering 0 is going to make it unlimited. And that happens with everything from dampening something. Like 0.0001 is going to be very slow interpolation movement and 10 is going to be faster. But the moment you turn it into 0, it's just going to go as fast as it possibly can. So similar here for p.maxfps.0. Oh no, my first mistake. I guess that's not true, because I just did that and still 30 frames a second. I did say most things in Unreal Engine do that. So I'm not totally wrong here. But oh, you know what it is? We did the fixed frame rate over in the project settings. I'm like, it's not responding to that. So yes, let's uncheck use fixed frame rate. There we go. Now it's back up to 120. And let's just test my hypothesis real quick there that 0 will make it unlimited. So we're at t.fps.60 right now. Let's do 0. Yes, 0 makes it go back to being unlimited. I don't need to be quite as embarrassed about what I know and don't know. Reduce cook size. So we're pretty much done with this talk. Let's get to packaging. If you want to have Unreal Engine produce a smaller file, then there's a few really helpful things you can do. First of all, and the biggest one is this checkbox here for cook only maps. Because this is where you tell Unreal Engine, hey, I know I kitbashed 50 different projects into here and they're all awesome, but I only care about these two. This is where you say Unreal Engine, I want you to basically go through the reference chain of what is happening for these two maps, but ignore everything else. Don't include that in the packaged build. Similarly, and this is a little bit trickier to do, is you ideally would disable the plugins that you're not using. And I haven't found yet a great way to follow a reference chain and say here's all the plugins that I'm actually using. The best I've been able to do is at least figure out which plugins are active. And so if I went to edit plugins and over here with settings, I could say show only enabled. But then I'm kind of still stuck in this place where it's like, OK, do I need 10x editor integration? I'm not sure what that is. And you might have to take a little bit of time to go through here and figure out what you can safely disable before your project starts to break. That's a good intern task, if anyone ever has interns. Just say, hey, go through it until everything is working OK. All right. Let's go back to the next one. Bulk editing with the property matrix. This is great, of course, for anything you want to do in batches. You've got a whole bunch of textures and you want them all to use SRGB. You've got a whole bunch of meshes and you want to set up LODs or a certain kind of collision typology for them. This is a really great opportunity for that. So going back over to our filters, we could just take a quick look at all the textures in our project. And if it's a little bit overwhelming to see them all as tiles, I can look at as a list. Nope, I always forget if it's list or columns I want. Columns is great, because of course now you have access to all sorts of other things that you can look at. And we can see, for example, dimensions. So maybe I'm thinking, OK, I'm packaging for really old mobile phones or whatever. I don't want any of my textures to be above 4k. I could, of course, identify the textures here that are 4k and go in and modify them and re-import them and that would be fine. But if I'm happy with what's going on in the editor and I'm just thinking more about particular device profiles or something like that, this would be a good opportunity for just selecting, for example, all the 4k textures, right clicking asset actions, edit selection in property matrix. There it is. And so it pulls all these up, and you can see there's a bunch of things we can edit at once. It's showing you all the common values or the common parameters for everything you selected. And if I type in the word max, for example, we see maximum texture size. So this is a good non-destructive way to basically just say, hey, when you get to packaging, I know the original texture is 4k, but let's say that the maximum texture size should be 2,048. Another quick tip. You should always be using power of 2 whenever possible. That helps with mipmap generation. One thing I didn't know for a while is it doesn't need to be square. It doesn't need to be 2,048 By 2,048. It can be 1,024 by 4,096, and Unreal Engine is still going to handle that fine. So if I go ahead and save that, should just take a second. And you'll see that in the editor, it's not going to say that the resolution has changed. So this is kind of something you have to keep track of. And device profiles, which we're not going to go into today, are a good way to basically set things like this up. So it knows when I'm targeting windows, use this max texture size is what it's called here. But it is a resolution and then different kinds of parameters for different other devices. So that's that. So the modeling tools, which it took me way too long to start using, are really helpful in Unreal Engine. They're not going to solve all your problems. They're not going to completely negate your need for other DCC tools. But if you are working in architecture, like I often do, and you end up with 3D models that come in and they are completely in the wrong place or the origin point is in a ridiculous place, then it can usually be enough to just use the modeling tools here to fix that. So if I go into modeling mode and I've got, say, this column here with the pivot points floating off to the side, I can go to x form. I can say, edit, pivot. Click there. And then I can move the pivot around manually. But there's also these very useful snapping sorts of things. So I can say bottom. And bottom is going to find exactly where the center is of that mesh. And that's great. And I can say accept and I'm done. And now if I press the end key, of course that's going to snap to the bottom. Some people think that has to do with the pivot point. Nothing to do with the pivot point. It has to do with collision. But yes, there's a quick tip that if you ever want something to just rest on the ground and you have an object that has collision, I've just flipped this. And so the pivot point's at the top. But if I press the end key, once again, it will go to the ground until collision is touching collision. So that's pretty helpful. Another thing I wanted to point out quickly about the modeling mode, besides actual modeling, which was a whole bunch of slides that I had to cut for this, is fixing bad UVs. So over here, for example, you've got an object and it comes in and you're like, ugh, what happened there? I'm not sure. You might want to go fix this back in the program it came from. But if you just want to see if you can handle it inside of Unreal Engine, we can go to the UVs selection area over here. And I'll usually start with auto UV. I'll see if that handles things OK. But we can already tell from the checkerboard pattern here it's getting it fine on some sides. But if I press accept, now it's still pretty messed up. So instead, the next step I would do is I would try project UVs. And if we try that one, we can actually get a projection type. So in this case, of course, box is going to make a lot of sense. But it's a little bit rotated and off to the side, even though it's doing a pretty good job here. We can actually do auto fit and auto fit align. And you'll see that that's pretty quickly giving us the kind of UV layout that we want. So again, it's not going to work for everything, but in certain situations, it's just going to save you time and headaches, which is exactly what we want. UV tools. Yeah. Here's a big one. I have made this mistake more times than I care to admit. Be careful about editing things that live in your Engine folder. If you're doing a source build of Unreal Engine and you're, I don't know, ILM and you're making Unreal Engine work with the Apple Vision Pro and you have a very custom build and you're intentionally editing a bunch of things in there, fantastic. If you are on a shared computer with your office and you all think that it's just a regular installation of Unreal, and then you go ahead and you do something like, I don't know, you open up-- that's actually not in the engine folder. But if we were to add in just a random cube, of course, from shapes cube, and I say, you know what? I don't want this cube to have collision. So you go ahead and you open up the static mesh there and you just double click on it and you're not looking at the fact that as you hover over it, it's telling you this lives in the Engine folder. And then you go and you try to remove collision. Guess what? All the speakers are going to come after me over here. If they try to use a cube in this installation of Unreal Engine, none of those cubes are going to have collision. So that is a mistake I've made a few times. If you want to edit something that lives in the Engine folder, the right way to do this is to actually get it out of the Engine folder. Don't move it. You want to copy it. So if I wanted to do something like what I was just attempting to do, I could grab cube and move it to content and I could say copy here and ideally put it in a mesh folder, something more sorted. And now I could then say, hey, don't use this cube. Use the other cube that has a star on it that tells me it hasn't been saved yet. And now that's there and that's all wonderful. So now if I want to go and edit it, we're OK, because it lives in the content folder. OK. By the way, if you make a mistake and you go through this and you're, ah, I removed collision and I saved everything and it's too late and you did not do the correct thing where you do what we just did, you can actually fix Unreal pretty easily by actually doing the dropdown in the launcher and you can do verify. It might take a little while, but that's where it's basically going to go through and systematically compare what you have in your local directory compared to what Unreal thinks you should have. And it will often fix those kinds of problems. Tape measure tool. This is one that became tremendously useful, again, for things like architecture. If you are in any of the orthographic views, which by the way, you can also get to by control dragging with the middle mouse button. And if I do it kind of at an angle, I'll go back to the perspective view. Any of these orthographic views, if I just use my pan, basically, my middle mouse, it will give me a measurement. Now, it doesn't do like anything that's super straight, and the snapping is still all based on what you have here, whatever kind of grid snapping you might have. But it's still really useful for quick things. If I just want to say, OK, these are about 500 centimeters apart. Please do remember centimeters is the unreal engine metric unit of choice. And then if you want to do a drag select, of course, that's very easy. In an orthographic viewport, you can just literally drag select. But if you've ever been in the perspective view and you're like, hey, I want to try to grab a bunch of the things in this general direction. Of course, if I try to do a regular kind of window style drag select, it's actually just moving this. So you actually want to use Control-Alt left click to do a drag select. And if you're on a Mac, which I've been doing more and more of lately, you're going to want to do Command-Option left mouse drag. Do Macs technically have left mouse? The mouse, et cetera. So that's a useful one that I again wish I learned sooner. That's the shortcuts I just mentioned. Adding game modes. This is one of my favorite ones. I have to say, this is kind of maybe the impetus for wanting to give this talk in the first place. So back when I started using Unreal Engine, maybe around in a serious way like 4.7, 4.8, I would often find myself in scenarios where I wanted to have a third person game mode and a first person game mode and a VR game mode and an automotive game mode. But you ran into a lot of issues when you would try to do that, because what would happen was this part was pretty much the same. You could go and you could add, you don't have to migrate anything, you can add some of the templates directly into the project. So if I go add feature or content pack, you see that we have a few different options here. And if I wanted to add, say, virtual reality, what would happen is, well, first of all this is helpful. It actually tells me the plugins I'm missing. So I'll enable that. It'll tell me to do an engine restart. No problem. That's fine. But all of the inputs that would be associated with these different game modes would actually need to kind of manually be sorted in the default input.ini file that lives in the config folder. So if you're trying to accommodate all these different game modes, that was a bit of a mess. But now, thanks to the enhanced input system, all of the inputs actually live as .uasset files. So like anything else in the unreal folder proper, you can get them to migrate and play nice to each other and they're all contextual. So you can actually jump between game modes pretty easily now. So I've added VR mode. Let's try adding one more. Let's add a first person mode. And so if I'm in my map and I'm just like, hey, this is a third person game, but I'm just curious how this works in first person. It's as easy, famous last words, as going into world settings. Let's talk that down here. And looking for that game mode override dropdown. So by default, right now it's third person. Let's say first person. I just brought this in. I haven't touched anything other than modifying this. And if I press play now, I am now able to move around in first person. And then if we want to go back to third person, simple as that. The only time this becomes a little bit trickier is when there's things going on with the player controller. So quick flyby of the player controller. I think of that as the soul. And then the pawns are the bodies the soul possesses. Very spooky. And so sometimes if the player controller has a lot of inputs and things like that there instead of at the pawn level, then if you bring in the automotive template, that becomes a little bit trickier. But in this case, this is very easy. I mean, let's see what happens if I move over to VR game mode. So I could go here and do VR preview. And then that's interesting. Huh. We're in VR mode right now. I wonder how I'm doing that. I wonder. That's pretty cool. I wonder if maybe in the presentation we'll find out how I am magically controlling something in VR without actually being in VR. Anyways, if we wanted to now make this at a global level, of course, we actually do want to change this over at maps and modes. So the default right now is game mode base, which is basically the version where you're just flying around kind of like in the editor. And if we say, you know what, I've decided this is a VR game now. I could now just make that the default and VR game mode is what happens. In general, just to think of this structurally in Unreal, if you are wanting to make something a default that needs to be overridden to change, you do it in the project settings. That's also true with things like post-processing settings, auto exposure, for example, bloom, lens flares. And then anything you're doing in, say, post-process volume or down here with game mode override, it's exactly that. It's an override that is saying, I don't care what the project settings say. We're going to do something different for this particular map. Cool. All right. Now we're going to go through some plug-ins. And this is the part where the presentation is most likely to fail. So bear with me here. There's a bunch of plug-ins in Unreal Engine that, forgive the pun, are very plug and play. And I don't think enough people use them. A lot of these you can almost literally just turn them on and start using them. One I discovered way too late in my career was the Variant Manager. So the power cords, if I was going to use a guitar playing analogy, coding to me was always the idea of just being able to turn things on and off. When I first started working in VR in real time engines a little over 10 years ago, the way that I really got my feet wet was like, OK, we have a bunch of different 3D objects, and we just want to say, I want this one on, now this one on, now this one on, now these two on. And so the coding I was doing to make that function, it worked, but it was a little bit janky. I'd be using things like I'd have an index and I'd be cycling through the index of the array of the thing that I'm trying to show. And then once we reach the end of the array, we need to cycle back to 0. And I started using modulus and other nodes like that. But the Variant Manager is a great out of the box way to set up a bunch of variants, as they're called, that you want to turn on and off. So let's take a quick look at that. And by the way, the design configurator templates, there's one for products, which is the guitar, there's one for architecture. There might even be one more. Actually gives you a very nice UI where you're able to click in a graphic way on these different variants and operate them in a packaged game or at runtime. But I'm just going to show you what this looks like as a very simple example down here. So we have the variant manager. So we've got-- I believe I just called it VM. Nope, Variant. Yeah, one of these. There's a Variant Manager demo here. So all I did is the plugin is enabled. I'm bringing this in. And for this, whenever you're using the Variant Manager, you have a level variant sets actor. And if I double click that and open it up, we now have the variant manager window. And this is just a very simple way that I was able to set up these different objects here. And you'll notice that if I actually click on each of these, we're an editor right now. I'm able to just turn one, two, three, whatever on and off. We can do this in play mode. We can access this in blueprints. And there's also this lovely auto capture feature. So if I then say, just like in sequencer, pay attention to what I'm about to do, because it's going to blow your mind. And then I start moving stuff around. You'll see that it's grabbing the blueprint and it's like, ah, something changed here. And so then when I'm done doing auto capture, then it will then-- it's recording what I've done. If I was changing not just the transform, but the material or other elements like that, then we'd see all of that changing. So yeah, in this case, we're not going to see anything cycling here because we only did this change on one of them. But it would be very easy to go down to the cube one. Again, do auto capture, bring this back down to 0. Or to use what we've learned so far, I can press the end key and snap it to the bottom and be done with auto capture. And now I have a way to cycle between these. Unless I made the mistake of not actually being in that particular variant when I did the auto capture. That's an easy mistake to make. You want to make sure that you are in that particular variant. So auto capture, click, and that's interesting. Oh, you know what? The end key might actually be making that stop, which is not something I've run into before. I think we're in a situation where too many hotkeys are doing the same thing. So I moved it down manually and now we can see that, yes, we're snapping it up and snapping it down. That's the Variant Manager. It's one of my favorites. Pixel streaming. So this is something I've been in love with for a long time, because I love Unreal Engine and I want to show everything I make in Unreal Engine to as many people as possible. But not everyone has a powerful enough computer to run Unreal Engine well. And pixel streaming, for those who don't know, is remote rendering. It allows you to say, hey, here's a computer that is running Unreal Engine really well and I want to share it with people. I want other people to be able to go into this computer and run this same experience. And this plug-in in unreal has gotten simpler and simpler and simpler to use. If you wanted to use a cloud service and you wanted to upload your Unreal Engine project to AWS or CoreWeave or Eagle 3D Streaming or Arcane Mirage, there's a bunch of them out there, all you need to do is enable the pixel streaming plug-in and package your project. Some services like you to package for Linux, which can get a little bit more complicated, but many support literally just a zip file full of windows with the pixel streaming plugin enabled. And then you can upload it and say, hey everyone, my favorite pixelstreamingthing.com it all works. But also there's a pretty cool editor workflow now where you can stream Unreal Engine directly from the editor and have everything working there. So once the pixel streaming plug-in is enabled, you get this dropdown. And if I were to say that I want to stream the full level editor, that would just be what's in here. Or if I say stream the full editor, I'm now saying, hey, remote support, I've got a weird thing going on in Unreal Engine and I don't know what remote desktop is or whatever. You can just go to this website and you now have access to my direct Unreal Engine streaming session. I'm belittling that notion of not knowing remote desktop, but it's actually really handy, because the only thing someone could access when doing this is Unreal Engine. They can't open up your config files or enter anything in the command prompt, for example. The command prompt of your computer. They could do it in Unreal. So if I say stream full editor. Pixel streaming, disabling setting, use less CPU and background for streaming performance. That's a good thing. I was going to manually disable, but now it just happened automatically. Anything that involves live link, anything that involves stuff happening outside of Unreal Engine, there is an editor preference setting that says less CPU in background. And this is absolutely one of those things that's great if you're on a lower end computer, because it means if Unreal Engine isn't front and center, it's going to do less work on the actual CPU while it goes. So unchecking that is going to make everything run smoother in a situation where you are talking to Unreal from somewhere else. So now that we're running, there's a couple of things I like about this. One thing that's really nice is just it tells me what my IPv4 address is. You don't have to press command prompt and go IP config and then scroll down and try to find the right address. It's right there. In this case, 192.168.12.44. And now if I were to open up anything that's on the same subnet, like a phone here. And I think I can actually show you what is on my phone to make this even more clear and useful. I can go into a browser and I could follow that exact address. And then all of a sudden, I am just from my phone inside Unreal Engine, and I can operate it and move around. Ideally, you're not trying to do a bunch of stuff in Unreal Engine from your phone, but if I was doing this on a laptop or something else, this would be a really easy way to pop into here. And then of course, if I were to change this over to if I just do stop streaming and then I stream just the level editor, it's just going to be what's inside of there. And if I refresh this, we'll see that we are now only seeing what's inside the level editor and not anything else. Now, it used to be very, very complicated. Not very, very complicated if you're a tech wizard. But it used to be difficult to set up pixel streaming so it was easy for other people to access your network. There was all sorts of crazy stuff with turn and stun servers and stuff like that. And the kind folks at TenserWorks, who are kind of in charge of the pixel streaming plug-in, have actually made it very easy now. And so there's a magical little setup over in the Engine folder. And I did mean to actually check where is Unreal Engine installed before I did this, but we'll find it. So when you package Unreal Engine with something like the pixel streaming plug-in, let's find Epic Games 5.4. If we go into the engine and plug-ins and we find pixel streaming. Oh boy, where is it? It might be in runtime. I'm just going to type in pixel streaming. There is an actual PowerShell command buried deep in here that actually helps with this. And you know what? I actually did give myself a note of how to find it. And this will actually pretty much automatically set up for you what you need in order to actually have this running remotely. So here we go. It is in plug-ins media. This entire folder that I'm about to show you gets copied whenever you package. And that's why this allows this to work up in the cloud. So pixel streaming, resources, web servers, platform, or signaling web servers, platform scripts, command. And then if you just wanted to run a local pixel streaming session on your network after you've packaged and all that, run local. That's all you need to do. And then you can have a package build and everyone can check out what you're doing. Once you add the launch parameters, which are I'll show you what this looks like, but ws:// IP address, colon, and then the port, which is usually 8888. But down here all the way at the bottom, we have start with turn signaling server. And if you run this in PowerShell, what this will actually do, and I'm a little bit afraid to do it on this computer, but it will actually open up everything needed to access your pixel streaming session from somewhere else. And I can demonstrate that very briefly, because I actually set this up on another computer where this is off the network here. And if I press Enter and load in, I'm actually going to see another game that is running all the way back in New York City. So pretty far away from Prague. And I am now just playing my fun little time dilation game via pixel streaming on a computer that's very far away. And now I don't have to pay for cloud services. So that's all very fun and great. OK, let's go to the next thing that is related to pixel streaming, but a little bit different. The virtual camera. The virtual camera is continually being overhauled, and it is ostensibly something that you would use for virtual production. But I use it for so many things. For anyone who doesn't know, and we're just going to actually open it up so I don't have to explain it as much, there is an app. I should show you what the app looks like. And what we can do is open this Unreal VCam app. And it's asking me to enter the local IPv4 address. And this is actually basically doing pixel streaming. So what's happening now is it's accessing the session. But in order for me to actually do anything with this and turn it into a proper camera, what we need to do is actually go ahead and add in a virtual cam. And this also used to be much more complicated. It's gotten way easier. But if I go to virtual production VCam actor, it's going to find a connection. And if it doesn't, I can just kind of pop out and pop back in. And so on my phone, let's try popping out and popping back in. Unreal VCam. Oh, and see, now this is interesting too. If you have a pixel streaming session already running, then because this is basically pixel streaming, it's like oh wait, do you want to stream the editor or do you want to use VCam? In this case, I want to use VCam. So hopefully this will connect. And then once it does, we should be able to actually start to operate a remote camera. Here we go. So it says AR tracking unavailable. But now it's found the floor. And yeah, sure, ICB effects are great if you're in an led volume and you want to be able to start to explore your environment that way. But this is such an easy way, just using a phone to start to operate a camera inside Unreal Engine. And there's touchpad controls. So if I want to kind of navigate around this way, I can. And I do this as a demo thing. I'll have a really cool Unreal Engine project, and I'll just let people walk around it this way. Especially for people who aren't going to put on a VR headset, I'll just tell them to hold this up close to their face. And it's a little bit like just walking around, getting a sense of the sequence of a project, how it feels to move from point A to point B. Because you're essentially creating this one to one relationship between what's in the real world and what's happening in the Unreal Engine project. And if you are ever doing anything with digital twins and you need there to be a meaningful relationship between real world objects and virtual objects, this is a really easy thing to do. And there's a ton of stuff on this interface here. This is another thing where there's a two hour course to go with it. But if I go and I press the red Record button in the upper right, I bet you can guess what that's going to do. So now I'm actually recording, recording, recording. Maybe I'm doing some walking around. Maybe I trip over the stairs and get a really nice Dutch angle. And then I fly around this way and up and down. And then when I'm done, I can hit that Record button again. And once I hit that, that has saved and that now lives in the project. And in fact, if I don't want to look at the recording I just made in Unreal Engine, I can even do it here. I can pull up the little menu on the side. I can review my recent recordings. I can click on this view. And now I'm no longer connected to the AR side of this. I can just hit Play and it's now going to play back the amazing cinematography that I just created. You can see I'm putting Roger Deakins to shame. So that now lives in the project the same way you'd record anything else. And you have a camera. Isn't that neat? Cool. And then you see the tape recorder came up and we can scrub through it in the editor and do whatever else we want to do there. Very quick introduction to the VCam. Cool. Anyone thinking like, oh, I wish I learned that sooner? That's the idea. I want you thinking that in your head. Controlling things remotely. This is another one. And you'll notice there's a bit of a trend here with this is also trying to make Unreal Engine more accessible to people who do not do a lot of things with Unreal Engine. I'm kind of combining two plug-ins here. There's a remote control API and there's OSC. And these are both good ways to basically give someone another device and be like, hey, there are very specific things you can do that are going to affect Unreal Engine, but you're not going to be overwhelmed by everything in Unreal Engine. So for example, we'll start with the remote control API. That is a plug-in that you enable over here in plug-ins. And you see we have remote control web interface and remote control API. You want both of those for the example I'm going to show you here. So in the content drawer, I've got a folder here in Wish I Learned called-- oh, that's weird. My mouse is offset. And that can happen sometimes with the VCam too. By the way, if you ever end a VCam session and everything's at a crazy, weird angle, first thing you want to do is try to actually delete the VCam actor if you can. It can make Unreal a little bit stable. But if you are at a really weird angle, I find that one of the easy ways to get out of it is actually down here and just saying create camera here and then pilot that camera. Control-Shift-P. And then once you eject from there, Unreal will go back to looking normal. Just a fun little FYI, if you ever come out of a VCam session and the whole world is wonky. Back to the remote control API. This is going to be a really quick way for me to access just very specific things. So kind of like what we saw with the variant manager with auto capture right here, we have a similar sort of thing here with the remote control preset where we can just go through a bunch of things in the project and anything in details panel that has this little symbol, this remote control thing to the side, which in Unreal Engine 5.3 and before was an eyeball. And then it also used to be on the left instead of the right. But we're in 5.4 right now. It's all over here. And we can start to say, hey, these are things that we might want to affect through a web browser. So basically, you set up whatever you want. You launch a web app. And then you have things like this, or we call it the conductor. And we could be doing this on my phone if I wanted to. And we can then start to modify things like in this case, the post-process volume. So you get some brilliant lighting design or whatever, and they don't know anything about Unreal Engine and they're working on a film or whatever. And you're letting them now start to control certain aspects of unreal engine using their finger on their phone, on an iPad, et cetera. But there's also a lot of other cool things in here too. If I go to the Design tab and I add a new section, there's a couple here that are set up for things like a sequencer, for example, or snapshots. Level snapshots, if you don't know, are very easy ways to change whatever you want in your project and basically do it as a save game the way you think of a video game. So I've moved a bunch of stuff and I don't want this to be a Variant Manager sort of thing. And so now over in the conductor, I want to make sure I'm in control mode. And I say Take Snapshot and I give it a useful name. And now I've basically saved everything in the editor. And you don't have to do this in the remote control setup. This is also just a feature that has a plug-in associated with it called level snapshots. And I'll move a couple more things around. And I could be changing materials and the time of day if that was something I wanted to do. Control-L and mouse move, by the way, to move the sun like that. And then back over here, I could go ahead and go back to the web app. Just opened a second one. You can actually have multiple people doing this at the same time, and they don't generally conflict with each other, which is nice. So I've got two snapshots now. And then again, think of them like game states. And the moment that I want to go back to the snapshot I had before, all I need to do is click on it. And I can just say Apply Snapshot. Apply Snapshot. And we probably can't see it very well over there. But yeah, stuff is moving around. OK. Boop, boop. There. Yeah. OK, so things are slightly different. Cool. All right. We're moving past that first section, and we're almost out of time. So you can see why this is going to be a multi-part series. We're probably not going to do Q&amp;A here. I will be very happy to talk to everyone outside, but let's see how much of this we can get through. Blueprints. I'll just kind of cruise through this as fast as I can. Components I feel like don't get used enough in Unreal Engine. It's a really easy way to say, hey, here are things that I think certain things should be able to do. The grab component in VR is a perfect example. Add that component to anything that you think should be grabbable. Over here, we've got some components. And if I were to go into play mode and also instead of default player start, use current camera location to actually start here, I could go selected viewport. And we can see here's a bunch of objects that just have very simple components that are making them do different things. And if I wanted to add more, I could stack them. We also are showing an example in the next slide of the collab viewer template, which is my probably favorite template that doesn't get utilized enough. Again, two hour course on that. But this is a great example of how components are just kind of living inside of the different pawn modes, fly mode, VR mode, desktop mode, and adding something to the viewer menu that everyone has access to is as easy as creating a new component and dragging it in there. So that's pretty cool. Breakpoints, print strings, instance debugging. I mentioned time dilation earlier a little bit. If you're trying to figure out why unreal engine is misbehaving at a certain point, one of the things you can do is just slow down time. Time dilation is set to like 0.1. But this one's a little bit better, because here you can actually say in your blueprint logic, you can right click something like this print string here and say, make this a break point. And that means that as Unreal Engine is executing the blueprint logic, it's going to get to that node and it's going to stop. And it's kind of a chance to take a breath and say, OK, what's going on? Is everything behaving as expected? You can see how variables have changed. And then where the red box is here, you can start to very methodically step through to the next thing, to the next thing, to the next thing. And it's great for debugging. And yes, follow the flow wherever it goes. And it's very useful. Sound effects. The only thing I want to mention here, because I need to play more with metasounds, but any time you feel like there's a sound effect that's too repetitive, we find that there's a great little tool called modulate inside of the sound editor if you're making a queue. And that just is a very easy way to say, I want a little bit of variation of pitch and volume right here. We can see that modulation area. You can also do things directly in blueprints, but I often will grab a sound effect I like, make a queue, play with pitch and volume a little bit, and now it can fire 1,000 times and it doesn't get too repetitive. Soft references. There's a lot of good talks on this, so I'm not going to say very much about this other than hard references are things that blow up your project and make it very big and make it hard for things to load. And you're filling up RAM. Soft object references are much more indirect and saying, hey, I know that I am eventually going to want to be using a sound, but I'm not doing a direct reference to a sound here. You'll also see in this example we're doing a cast. Casts can also be a little bit heavy. Ideally, you're doing something like a pure cast or using interfaces or event dispatchers, which are also in here. I have a very quick way to wrap up how to talk about event dispatchers and interfaces, which I'm very proud of this example. Event dispatchers are great if you want a bunch of things to just be paying attention to something. So let's say you have the sun sky blueprint, which has the whole time of year and the time of day, and you're saying spring has come and you are now doing an event that gets dispatched out to everyone who is subscribed to that event. All the animals of the forest and all the animals that care that spring has come now are going to wake up and say, aha. Now, the event dispatcher doesn't care who is subscribed to them. It's just the sun. It's millions of miles away and doing its thing. And so that's a really easy way to talk to a lot of actors and have all of them respond in a certain way. Interfaces are better if there needs to be much more direct relationships between actors. So to continue on with this example, all the animals wake up and now they all want to eat each other. So now you have an eating interface, and that eating interface is going to implement differently. You have bears that are eating capybaras and great white sharks that are eating bears or whatever. And it's all still using that same interface, but it's being implemented in different ways. And there's a fun example in this, but we don't have time for it. And yes, deep search. Just a really quick one. If you find the little find results here and you do find in all blueprints, if you're looking for anything in your project and you want to know, even if something is a print string or something, this will search through your entire project and help you dig up why do I have that weird print string or that weird sound effect that is doing things unexpectedly. Enabling input. Multigate is my favorite way to switch things outside of the variant manager. It does need to go in sequence, but it's a really good way to say, when I click this, do this, then do this, then do this, then do this. It's a little bit similar to something like the switch command. But multigate really wants to go either completely randomly or in a particular sequence. Switch is really useful, because you can do switch on int. You can do switch on a string. And that is a very particular thing where you say, yes, great white shark wants to now eat gorilla, capybara, or whatever the case may be. And you can be very specific with how that is registering and going through that flow control. This is a really fun one. Did you know you can access custom events and other things like that directly from the console command? So I'm not going to do it right now. But if I were to type in CE for Custom Event and then play sound here, I would actually be playing different sounds that live in the editor. I will do the KE surprise one, because it's kind of fun. This one is actually triggering something for all actors. And I'm just doing this in the editor. KE times surprise. We get everything happening here. And I do KE surprise. There we go. So it's triggering a sequence and it's making all sorts of stuff happen, all from the console command. And then something we definitely don't have time for today but I want to mention is there's so much you can do with launch parameters. And you can have Unreal Engine, a custom build that you made launch with all sorts of things that have nothing to do with Unreal Engine and everything to do with the particular things that you want to happen. Not just opening into a particular map, but certain variables having certain values and that stuff can all be really fun. Cool. We got like eight minutes left until this is officially over, so let's see how much we can cover. And there will definitely be a part two to this talk. Blueprint function libraries. If you have functions that you want to be reusable, maybe you want to migrate them from project to project and you want anything to be able to access them, instead of using a regular blueprint and a function in that blueprint, use a blueprint function library, because then you can just right click in any blueprint in the entire project. In this case, print, string, and play sound. And you'll be able to find it. Macros are great. They're kind of like functions, except unlike a function, they are able to do things that require time, like delay or load stream level or the timeline node, for example. And they also have multiple execution pins. So if your function isn't able to do the thing you want it to do, macro is usually a good fallback to see how things work. Someone also mentioned to me they had no idea that you could do input actions that have a modifier with them, like Shift-M. So just want to point that out. If you click on something where you've said make this input M, you can say Shift-Alt-Control, whatever, to be a little more specific about how it gets used. Really helpful for debug commands where you don't want people to accidentally do that. Interpolate to is one of my favorite nodes. We actually have a little dog in the project that's a cube that will follow you around. And basically all it's doing is trying to find where the player is at any given time. And it's just lerping into your position. So I also use this for things like the VR spectator camera where if I want the VR spectator camera to actually go and be a much more dampened view of what's happening in VR to make people feel less sick, I'll use interpolate to, to actually have the movement of that spectator camera be a softened version of what's actually happening inside the editor. So there's good boy. And my good boy follows me, and it's just a very simple set of three nodes in order for that to happen. But I use interpolate to for just about everything. It's a good one. Optimization real quick. Matt just gave a fantastic talk on optimization, so I'm not going to go through this too much. But simplifying materials is something that I didn't do enough early enough, especially because we do a lot with metahumans. And I have a whole talk on metahumans tomorrow where there's more about this sort of thing. But the metahuman base material is insane. If you're trying to make metahumans work on a mobile device, you need to go through and simplify that kind of stuff. And even texture maps that are unused and slots that are in there, they still have a non-zero value for what they do in terms of cost. So in this case, on the left here is kind of the default, very complicated metahuman material. And here's the simplified version we used for body of mine now out on the quest store. Hooray. And we have drastically simplified metahumans as part of building that experience. A bunch of stuff about performance. I'll just linger on these for a second for anyone who isn't going to go get the QR codes and just wants to see this in the recording on YouTube. But we have all sorts of different ways to find bottlenecks. I love stat unit. If you, by the way, are finding that you're having trouble knowing if your game is CPU bound or GPU bound, yes, there are things like game time is going to tell you that it is CPU bound. Draw time will tell you probably that you are GPU bound. But there's a command you can do, which I believe is disable rendering. And it will actually turn everything off. So basically now the GPU is doing nothing and that's a great way to see if you are actually CPU bound, because then you'll see if that number has changed at all. And if it doesn't, it might actually still be a GPU problem. And then there's a couple of tips here on if you found problems with GPU versus CPU. Sequencer stuff. I love material parameter collections. The event track is a really cool thing not enough people play with. It's basically like the level blueprint, but for sequencer in the same way the level blueprint allows you to drag objects into the level blueprint and then you actually have access to them directly instead of having to get actors of class or interfaces or event dispatchers. Here, you're actually able to reference things that are directly in the sequencer in a blueprint capacity, and you can do what are called triggers and repeaters. A trigger is a lot like a custom event. We've reached this point in the sequencer. Now do this. And we have repeater, which is a lot like event tick. So you're actually having something happen every frame as the sequencer is playing. Keep state is really useful. Just what you want to have happen when you get to the end of a sequencer. And you say I don't want it to reset back to where it was. I want it to stay exactly where it was there. Allow incompatible skeletons. If you've got, say, metahumans and mannequins and you haven't dealt with retargeting yet and you're not sure if you want to, although it's getting easier and easier and easier, there's actually a checkbox here if you're trying to give any character in Unreal an animation that isn't technically compatible with their skeleton. Because the mannequin and the metahuman skeletons are so close that oftentimes if you do this, for example, and then you can see all the mannequin animations, you can make them work with the metahuman quite handily. Virtual reality. Real quick, I mentioned the collab viewer template. I love it. Desktop VR and multiplayer and all sorts of stuff out of the box that works great and all sorts of animation tools. Last Unreal Fest, we had this talk about the Four Seasons project in Lake Austin, which is a 5000 square foot space. And we did all of our prototyping in the collab viewer template, because it allowed us to do local multiplayer and test all sorts of interfaces and commands and components that helped that project succeed. Emulating stereo. If you do not have a VR headset, you can actually see what the left and right eye are going to do by going into the editor preferences and finding playing standalone game. And there's a checkbox for emulate stereo, and it will give you a left and a right eye, which is great, because there are still certain features in Unreal like high quality, translucent reflections that if you have instant stereo on, it won't look the same in the left and the right eye. So you can see that obviously in VR, but you can also see it by just dividing out into a left and right eye. Also, if you are actually in VR, there is a console command called vr.spectator screen mode. And there's a few of these. But two will actually show you the real left and right eye. So that is super handy. XR Scribe. This is a really cool thing made by Victor Brodin that not enough people know about. It is a way to record something you've done in VR and then play it back. So if I were to go back over here, and you already saw me do this once, into something like the VR template, which is down here, because we added it. And I say, let's go into the maps for there. We're almost done. And I do save selected, because everything there was perfect and amazing. So this is a standard VR template. And I had Dante on my team, who has a VR headset more handily here than I do, go ahead and record something and then send me that .xrs file, which just lives in the saved folder. And we just have one line we need to have in the defaultengine.ini for XR Scribe mode being 1, which is playback. 0 is recording. So Dante did 0, recorded something, and now I have it set to 1 for playback. And now even though I don't have a VR headset here, I'm able to access VR preview. And now we're actually seeing Dante's playback. The problem here, though, for what just happened, and isn't going to make it an apples to apples thing, is I still have current camera locations. So if I go to default player start, I can actually get exactly what Dante just did when recording. And so we see teleport inputs are working. Also, not only can I see the first person perspective, I can go out to the spectator cam by pressing Tab. And I can watch this real time playback of exactly what was happening in VR, including grabbing things, moving things around. And now if I'm in an iterative workflow and I want to do things like, oh, what happens if I move exactly where this is or I add collisions in someplace? I can keep playing this back and I can see exactly how this is changing over time. And I say, oh no, something weird happened when he let go and it didn't throw properly. And I might mess with physics settings to see that work. And yeah, everything here is working. So it's a really cool way to iterate in VR fast, even if you don't have a VR headset. And last, almost last but not least, OpenXR is amazing. And I love that the implementation of OpenXR even for the Apple Vision Pro, which is not technically a member of the Khronos group or OpenXR, is all implemented in that kind of way. So I have hand tracking stuff that is using OpenXR that works with the same blueprint across Meta, Vive, Valve, Vario, Index, Pico. And I was so happy to find that when I started developing for the Apple Vision Pro, that same blueprint allowed me to do hand tracking in here and it just worked. And that's wonderful and it's super cool. So whenever you can, try to build things that are actually OpenXR based rather than specific to the Meta XR plug-in or Valve's plug-in, et cetera, because then it's going to work across all these different devices and that's lovely. Now, final tip and trick that probably wasn't super obvious to you now, but I was very happy with it, is there's another shortcut that has nothing to do with Unreal Engine, and it is called Alt-Escape. And that was actually how I was able to very quickly switch between things. It's basically Alt-Tab without actually bringing up any of the other windows you have. So nothing to do with Unreal, but I thought that was a pretty cool tip. So thank you so much to everyone who helped out with this. We have the Agile Lens team up top. Simon, Ryan, Chris, who have given so many of these tips in the past. And everyone on social media who responded to my question, what do you wish you learned sooner in Unreal Engine? And if you want to hear more tips like this, but very, very hyper specifically about metahumans, which were not really covered here, whole hour about that tomorrow. Same time, same bat channel, and thank you so much. [APPLAUSE] On time. Wow. It's on time. I know I rushed through it there at the end. And I want everyone to come say hi outside, and I'm happy to answer 1,000 questions, including about everything that didn't make the cut into the reduced version of this. So thanks, everyone.