Please welcome to the stage Dr. Science and co-director of Human Institute at Stanford University. Emily Chang. A.K.A. intelligence. That's the first question. myself godmother of anything, but when I pause and think about. called the godfathers of things, women, And so I accept it 100%. influential computer science artists of You have written hundreds and hundreds You were the creator of Image Net, which which was basically this database of Did you have any idea how influential it An image was conceived back in 2007 as Data's role in AI algorithms. had the conviction that big data would But I don't think I could have dreamed network and GPUs. And I cannot have dreamed the progress, You are in rooms where the people who this technology. Pichai, Satya Nadella, you are You are on task forces. who have the power about how they should Quick question, Emily. in the room of K 12 summer camps as well You know, our introduction to AA courses This technology, what it is, and how to thoughtful way. technology that is changing. going to, you know, accelerate cures for cancer, you know, map out our with us, but also recognize all the consequences and how to develop and I just think that more is of of balance, today's conversations, whether it's in And I don't know if you would call this A.I. on. AI generated data and synthetic data to How big a problem is this? Like, what's the next step here? running out of data is a very narrow It is. to these large language models that's from, you know, from websites, Reddit's, a handle of. let's just stay in this narrow lane. seeing that differentiated data were can models, whether it's, you know, in, you know, very different enterprise We're now running out of data. that we're still not have not even enter We have not taken advantage of the data, or education and all that. I don't think we're running out of data Do you think using AI generated data to does that take us further and further way? QUESTION It's a good question. For example, in my Stanford lab, we do a learning there. because we simply don't have enough collect human generated movements and And simulation is really, really Would that take us onto a dangerous I think. we can go down the dangerous path and Likewise, if we don't do it in a thoughtful way, of course it might take I mean, I don't need to even call it You know. Are there like entire dark web? simulation itself. You're getting into the hot and crowded You're starting something reportedly. No. We also we conducted a poll about trust Can we bring the results up of that The question was, how much do you trust securely? 0%. Not at all. who is who are doing the people in this The people in this room. If you had to rank the big A.I. And who do you trust the least? player. system we create together and in the together. I'm not going to be able to call out You know, of the United States. person. trust. We're trying at least the Stanford trying. You know, I get to ask this question a Do you still have hope in there? But but I, I do say my hope is not in And I'm not a delusional optimist. I'm complex. But the hope is in people is in our responsibility. We're moving. make this a trustworthy civilizational So there are so many risks that get actors, bias, like racial, all kinds of What is the thing that you worry about I worried about catastrophic social I also worry about the overhyping of I think that is blown out of control. just pondering about. about all this, but compared to the disruption of disinformation and or, you know, the kind of labor market these are true social risks that we have people's real life. campaign. what should not be open? I do believe in an open ecosystem, I think that the beauty of the past, you 100 years, especially in our country, is entrepreneurship and and exchange of And so it's important that we advocate What is the biggest thing in A.I. What should we be talking about? Oh, God, that's a long list, actually. imagine how we use this technology. I talk to. I talk to tourists, I talk to artists I There are so many ways we can imagine There's so many ways we can use this to I don't think we talk enough. it's also just a few people talking And then, you know, the media is I don't think I don't know what you're Yeah, my my hand was waving nicely. people who are actually out there in the trying to bring good to the world using Is there any one, any thing you want to on like anyone or any company just kind I know where you're getting. I would just say the B.S. over indexing and the the I'm sorry. Existential crisis. Yeah, exactly. I am concerned about the the some of the country, California state, or that is And it might come from a good place, but might even inadvertently criminalize thoughtful about how to evaluate and and about. We may we may overregulate in ways that ecosystem. where rubber meets the road, like health we should look at the proper guardrail. that? him. actually with President Biden. moonshot mentality to invest in public here in the heart of Silicon Valley. resources, both in terms of talent, data industry. Americans public sector academia is terms of resource. has 64. 64. And so we talk about resourcing our innovation engine of our country. scientific discoveries, and it produces evaluation and explanation of this So last question, and this is something lab and in general. color in this field who have their hand How serious is this risk and what could Yeah, well, Emily, I know you have been Look, there isn't enough. necessarily better. people of different diverse backgrounds But we're also seeing that the voices of that. here talking, but there are so many There are so many young women, people in backgrounds whose voices should be platform. really wasting human capital, right? innovators and technologists and Well, not giving them the voice, not not lifting them waste our collective I think godmother is a pretty good term. Thank you. All right. The godmother of.