Transcriber: Min Zhang So I'd like to start by giving I want you to choose between Investment A is an investment where Free and clear. Investment B is a lottery ticket, where you could earn $1 million but you'll earn nothing So this is a quantitative crowd. I'm going to help you by computing The expected value is $250,000, you get either a million or nothing. Higher expected return but higher risk. So by a show of hands, how many Okay, and how about B? Okay, let the record show that And a few hands here and there All right, now, let me ask you between two other choices. Investment decision C D is a lottery ticket where you will lose and nothing with 25% probability. Now, in this case, They're -$750,000. But in the case of D, You lose a million or nothing. I teach MBA students, and when I give them Their response is, "We want neither! No, thank you." But you can imagine a situation the lesser of two evils. So how many of you would pick Okay, how about D? Wow. Let the record show that the vast Now this is just a matter Doesn't seem like there's But let me show you Those of you who picked A and D, those two choices are equivalent to the single lottery ticket that gives and will cost you $760,000 How did I get that? Well, if you picked A, But if in addition to A, you also pick D, there's a 25% chance in which case you get But there is a 75% chance in which case you're left with -$760,000. So that's how I got Now the few of you that picked B and C, this is what you would have gotten. The exact same probabilities But look at this. When you win, you win 250, not 240. And when you lose, you lose 750, not 760. In other words, the choice that most is actually equivalent So by a show of hands, how many of you If you would see me afterwards, Now, this is a phenomenon that two famous deduced and called 'loss aversion'. They were doing it experimentally so the prizes were much smaller. I had to add a few extra zeros and I had to make it meaningful. It turns out that this is a phenomenon all of our human preferences, That's why it's called 'loss aversion'. And so financial economists have realized to essentially pump money by engaging in these transactions. If you think that this is imagine a multinational investment bank whose London office is faced and the Tokyo office is faced Locally, it doesn't seem like but the globally consolidated book We can create all sorts to pump money out of you using complicated And so this is not a good thing. And you want to understand It turns out that this is part that I wrote a paper about and we called it technically What happens is, when you're you tend to freak out and you'll take During the midst between the fourth quarter of 2008 the S&amp;P 500, US stock market dropped Your 401(k), if it was invested became a 201(k) during that time period. And investors freaked out, Now, that's not such a bad thing because And so you ended up avoiding In fact, five years after the financial and afterwards one of my "Professor Lo, I just want I really enjoyed your talk, and I want I pulled all of my clients' money because I wasn't sure when And I said, "Good for you. You saved your investors some money. What do you need advice from me for?" And he said, "Well, Do you think it's time to put Wow. So that's the problem. We are scared of losses, So what if we were to ask ChatGPT what we should do if we lost Well, if you do that, this is It's a long list, and some stay calm, avoid making (Laughter) but you go down the list and point No. 4: Really? After this loss, in the midst of an illiquid market? Or No. 5: Consider dollar-cost averaging, which means buying more You want all the investors Actually, if you gave that blanket advice to all your investors you could be prosecuted your client's particular needs. That's bad advice. What about ChatGPT-4? Now this gets really interesting. If you ask ChatGPT-4 you actually get a list of recommendations In fact, this list is better that my friends have gotten (Laughter) And that's interesting. So it raises the prospect, can we actually use large language models What if your financial advisor knew at all times, day or night, 24/7? What if your financial advisor every single piece of financial What if your financial advisor any time you're available? Never on hold. And what if your advisor looking out for your best interests only? That's the potential Now, rich people, they don't need this. The people that need the financial that financial advisors out there in having as clients, If we can solve this problem that would make a tremendous So, can large language models actually I'll explain what I mean Fortunately, I've been collaborating Jillian Ross, who's a PhD and Nina Gerszberg, And based upon the work that we're doing, So there are three parts I'm not going to talk about all three. The first part is, do you have The second part is, can you dispense But the third, and I think the ethical nature Can you get large language models Now it turns out that financial advice although it is an ideal testbed. We've got about 15,000 managing something like $114 trillion and there are a lot more people that need And bad advice can do a lot of harm, as well as disclose certain private So these issues are front and center, but for all sorts of other advice, virtually any type of human for some type of knowledge transfer. This is going to be relevant And the fact that we're focusing to narrow our focus so that we can come up that I'm about to ask. So, part three, can we engage that are ethical and trustworthy? It turns out that in the legal It's called 'fiduciary duty'. A fiduciary is an individual that ahead of their own. So, for example, your portfolio manager they are fiduciaries. They're supposed to be looking out for Can we get large language models Now it turns out that if you think that we've already imposed Virtually every financial a code of conduct and a set that their members have to abide by. They have to focus on the best And the question is, can we get It turns out that in computer science, there's a term for that Can you get an AI to be aligned Now there are many different So you have to ask, So we're going to focus on a couple. I don't have time to go But I'm going to give you a few we can tell if a large language I'm going to do this through a game. Economists have come up the nature of human interaction So let me tell you how it works. Suppose we have a proposer, let's say me, and the proposer's job is to propose how to divide up a certain amount of money that the proposer has So, my job is to propose to you a split And your decision is simply If you reject the proposal, But if you accept it, it is split according Okay? So, I offer you $5 out of $10. You say, "Yes, I accept." And in fact, the money But, if I offer you something else nobody gets the money. So we're going to play Okay? I need a volunteer. Okay, would you come (Applause) Now. We need money. So let's get Jillian, would you come up here? It's not totally frivolous, given that she's an expert She will be rolling in money soon. So, Jillian, I'm going to propose And the question is whether So I'm going to propose I give you $0.05. I accept. You accept? Excellent. And then I get the rest. You get $0.05 and then I can keep $9.95. No. Okay. Sorry. I guess I propose $4 to you. No. All right, end of the game. Thanks. Thank you very much, Fernando. (Laughter) (Applause) How do large language models behave? It turns out that most humans and it turns out that that's actually Large language models, not all of them are there yet, And through many other examples like this, we can actually map out the behavior and compare them to how humans engage in. This ultimately will allow us to shape fully trustworthy in ways that we are The way that we learn about that do unto others as others do unto you. And eventually, as they get older, of the Golden Rule in the business world, which is those who have the gold So with that, the question is, can we actually come up with large augment or replace And the answer is come back All right. Thank you very much. (Applause)