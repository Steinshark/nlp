We're going to be looking at something this already covered, because I was thinking about features of parallel programming and PLINQ and I to tell you what it's all about. So that's what very basics of how to do parallel programming. And at some of the more subtle features we have to at this application that I've written. So it's So what I've done is I've got an array of 100 to zero - but then I loop through up to the on each of those values 'i' calculate the factorial. 'Factorial' that uses Aggregate to multiply each it'd be one times two times three times four of other things I've done in there. One is factorials get very big very quickly; we don't put a cap on the value that doesn't matter because we can't calculate the factorial of zero mathematically is valid, it's one. But the cope with that. So that's why we just added 1 so So we'll loop through that, and then at the of all those 100 million calculations. So nothing it's going to be using a lot of processing we get the console popped up. But we also get on we're making for that. So there's that average thing. But once again, if we just take a look at very low percentage - 6% of all processors. this particular machine has 16 logical CPUs. we do a heavyweight processing job and we're not one of those CPUs. So if we look at that in can see we're getting ... well, it's using the do with things like garbage collection. But it's And so that's really the point of parallelization. because multi-threading can occur even if you've or 15 years ago - when it just uses what's known which thread is allowed access to the processor. Whereas here, what we're trying to do is, if we're doing a heavyweight job, we want to So it does involve multi-threading, but it also rather than just switching in on the same core, let's see what we can do to basically parallelize be to actually generate our own Tasks. So we could we could divide that work into 16 portions and should pretty much put those on a separate cores. much work for us to have to worry about. And also, because as a developer I know I'm on a it could be on a completely different machine with to make that assumption. So we'd have to do even to find out what's going on there. So it's much .NET system, run this in parallel as best there's a number of ways we can do that. So the for loop and then what I'm going to do is use So this is a for loop, but it's parallelized - not see what it's put in there for us with it's really 'results.Length', which is 100 million. I'm start going too fast for us to really see what's so it's going to loop through like a for loop in to give us the actual body of what's going on. So which is the parameter that's passed in and put that in there, then it's still going to and put those in there. But if we run you can see the processor is doing much, And we saw also that, even though we've got five quicker. And if we bring up the Task Manager, once then we can see we're getting a big peak on all that for us very well. Now, the exact details of But basically, in a pretty simple case like that, roughly chopped it into 16 parts and done Another thing you'll notice there, though, is if of it, but then at the very end, you can see we I'll just show you the image of that, so you there is although we have parallelized all of in a single processor. And we'll see a bit later on else in there, just so we can actually really is introduce in here another collection, and I'm going to have as a 'new' and then I'm going to So it comes from a separate namespace and as is just like the normal Dictionary that we get in safe. So with a normal Dictionary, if we started get into trouble if you've got any kind of clash. But in there, so we don't have to write our own locks a ConcurrentDictionary. And this is going to be and takes an 'int'. And what this is going loop has gone through on each thread. So if we we've got a method called 'AddOrUpdate'. And of the thread Id. So we can get hold of that that's going to be the key, and then we're going for the first time. And then we have a lambda that And so we're just going to return 'count + 1'. information in there that I'm not interested in that we can count those up. And then I'm going to say, 'Console.WriteLine'. threads used:'. And then I'm going to have just each of the items in the dictionary. And then we 'Thread' and then '{pair.Key}' because, remember, in up there. And then we'll say 'used' and then counting up, 'times'. Okay, so that's actually to add something to this ConcurrentDictionary happening. So if we run that one up, we can still probably doing a bit more because of adding to us the average, it says used 18 threads. And then And we can see them roughly the same kind of bit odd that we've used 18 threads even though it's not an exact one to one mapping between them. those threads were actually using the same core. exactly the same as the way it allocates cores. doing the sort of thing we want. So that's one way Another thing we can do is use 'Parallel.ForEach'. but I'll show you how we can do that. So And then what I'm going to do is, we will have a and then we can say 'Enumerable.Range'. So in factorial, in fact - and now we're and then it's going to have 'results.Length' give us an enumerable of 500,000,000 elements 1, 2, 3, all the way up to 499,999,999. So that's we can do the 'ForEach' on this. So now instead And actually, the autocompletion here has done that second parameter on the lamda, it's it's this thing called 'ParallelLoopState'. you don't get an index on a foreach. And in I'm also going to turn into a discard. And the problem is, because we just do something like 'results[i]'. So I'm on there. So what I'm going to do here is have And this is going to be of a type like I had a ConcurrentDictionary, another thread there. And so what we can do here is just say the 'value', we actually want to add, again, the And then let's also just keep track in the And then lastly, we just need to change that And then if we run that up ... and again, we using most of the processing power. There will with doing the same job with the 'For' and the but it's the sort of thing you might want to do loop is probably a bit faster, because we don't it's up to you to test on that. But again, we can we can see how it's used them. So that was our tools, but for slightly different situations nicely for us. We don't have to do very much to be a bit careful by using things like the but we've not had to worry about working out parts. We don't have to actually know how many That said the one that I would tend to use most easiest one to go with - is actually to use the we can do that, well, let's do this job just with do is comment that out. And then let's do the same 'var' and then we'll call these 'linqResults and then simply 'select'. And factorial calculation, change that to 'val'. And into there. So I can then wrap all of that up in because there's no keyword 'average' in LINQ, And then here, I can just take that and pop and thread counts as yet - we'll come on to that in very interesting because this is not yet PLINQ. because this is going to be much slower, I'm And if we look at that, then we can see we're at that roughly 6% - that 1/16 - and gave us the Let's just turn that into PLINQ. And that's really 500,000,000, because it's going to be a to get PLINQ is, on your data source - which okay. So as simple as that. That is how we tell it 'Parallel.For' - a fair bit of recoding, compared to PLINQ is as easy as that - bearing in mind, this to Objects - so where we're dealing with data and something like that, you can't parallelize that It's running on your database, which will do its worry about. So this is only LINQ to Objects. we can now see, we're back to where we were one go. Still, we're getting that result, can we just keep track of the threads? Well, because we've got to effectively introduce what because the LINQ query is just taking our incoming averaging them. So what we could do actually is to return a 'double' and it's going to be called which will again call 'val'. And what we could do, say that it returns 'val. And then if we take that then that will actually have no effect at all, it. So it will still be what is selected and then really nice thing that we can take our usage can pop it in there. So you can see we've got that nothing because it doesn't modify the value, it just the way. Not something I'd particularly recommend be confusing, if you don't realise what's going we're just trying to demonstrate the feature, I and run that one up ... can still see obviously, now we've got it that it's giving us that count. of thing in terms of distribution. So those were really, if you include the really bad way of just 'Parallel.For', we had the 'Parallel.ForEeach' to program, because it's just adding that one LINQ. One other thing though, just to point out with PLINQ, that we didn't get that little tail. being done without parallelization when we did it one up, and we take a look at the CPU, you can and it's high all the way and then it's finished. just go back to 'Parallel.For', let's say, then there is simply once we've gone 'AsParallel()' way through, unless we actually choose in a later video. But that means that average is So if we do that, let's change that one back to then we can see now it's starting out in the But then at the end, it drops off to that the Average. But all we need to do is in So that one will now force the Average LINQ extension method - to use it just as it did earlier on. So we can use it like that as well. not going to have that tail on the end. If we let But really that's starting to be quite the 'Parallel.For' works, because all of these just break it down into those 16 chunks, and an average is rather more complicated than that, from various bits and pieces. So it's doing some the subject of one of the later videos - how of thing. For now, we're just looking at the 'Parallel.ForEach' and PLINQ. So, hope do click like do subscribe, and I'll see you