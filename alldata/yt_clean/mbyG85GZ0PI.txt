ANNOUNCER: The following program YASER ABU-MOSTAFA: Welcome to machine audience as well. Let me start with an outline of the of today's lecture. As you see from the outline, the topics designates their main content, whether Machine learning is It goes from very abstract theory to And the inclusion of a topic in the machine learning. So some mathematics is useful because it and then some practical aspects are to deal with real learning systems. Now if you look at the topics, these for each lecture. They just highlight the main But there is a story line that goes the story line is like. It starts here with: what is learning? Can we learn? How to do it? How to do it well? And then the take-home lessons. There is a logical dependency that goes one exception to that One lecture, which is the third one, It's a practical topic, and the reason needed to give you some tools to play theoretical and conceptual aspects. If I waited until it belonged normally, linear models which is down there, the just too theoretical And as you see, if you look at the beginning and mostly blue in the end. So it starts building the And then it goes on to the Now, let me start today's lecture. And the subject of the lecture It's an introduction to And I will draw your attention which is this part. That's the logo of the course. And believe it or not, This is actually a technical in one of the lectures. I'm not going to tell you which one. So you can wait in anticipation until it a scientific figure that Now when we move to today's today about the following. Machine learning is a very broad one example that captures the It's a fun example about movies And then after that, I'm going to the practical learning problem, learning situations that And in abstracting them, we'll have the learning problem. And then we will get our first algorithm It's a very simple algorithm, but it role of an algorithm in this case. And we will survey the types of learning, are emphasizing in this course, And I will end up with a puzzle, a very a puzzle in more ways than OK, so let me start with an example. The example of machine learning that a viewer would rate a movie. Now that is an interesting problem, and watch movies, and very interesting for And indeed, a company which is Netflix by a mere 10%. So they make recommendations when you they think you will like, so they think And they had a system, and they So how much is a 10% improvement in It was actually $1 million that was actually managed to get So you ask yourself, 10% improvement that be worth a million dollars? It's because, if the recommendations on, you will pay more attention to the the movies that they recommend, and they more than the million dollars And this is very typical For example, machine learning has You can imagine that the minutest can make a lot of money. So the fact that you can actually push learning is a very attractive aspect of applications. So what did these guys do? They gave the data, and people started algorithms, until someone managed Now if you look at the problem of essence of machine learning, and the If you find these three components in you know that machine learning is What are the three? The first one is that If a pattern didn't exist, there So what is the pattern here? There is no question that the way they rated other movies, and is people rated that movie. We know that much. So there is a pattern However, we cannot really pin I cannot ask you to write a 17th-order rate movies. So the fact that there is a pattern, mathematically, is the reason why we For &quot;learning from data&quot;. We couldn't write down the system on our data in order to be able There is a missing component If you don't have that, We have to have data. We So if someone knocks on my door with application, and they tell me how application would be, and how much question I ask, what data do you have? If you data, we are in business. If you don't, you are out of luck. If you have these three components, apply machine learning. Now let me give you a solution to the getting a feel for it. So here is a system. Let me start to focus on part of it. We are going to describe a viewer you will. So if you look here for example, the Does the movie have a lot of comedy? From a viewer point of view, Here, do they like action? Do they prefer blockbusters, or And you can go on all the way, even to lead actor or not. Now you go to the content of the corresponding part. Does the movie have comedy? Does it have action? Is it a blockbuster? And so on. Now you compare the two, and you realize let's say you hate comedy and the then the chances are you're But if there is a match between so many number of factors here could be Then the chances are you'll And if there's a mismatch, the going to like the movie. So what do you do, you match the movie and the viewer contributions of them. And then as a result of that, you This is all good except for one problem, machine learning. In order to produce this thing, you have the content. You have to interview the viewer, And then after that, you combine a prediction for the rating. Now the idea of machine learning is that All you do is sit down and sip on your something to come up with So let's look at the So in the learning approach, we know different factors, and different So this vector will be different For example, one viewer will have a big will have a small blue content, And then, there is the movie. And a particular movie will have different And the way we said we are computing the and combining them and Now what machine learning will do is It starts from the rating, and then consistent with that rating. So think of it this way. You start, let's say, with So you take these guys, just random these guys, random numbers For every user and every movie, Obviously, there is no chance in the product between these factors that are looks like the rating that actually But what you do is you take a rating start nudging the factors ever so Make the direction of the inner product Now it looks like a hopeless thing. I all random, and I'm trying to What are the chances? Well the point is that you are going to a 100 million ratings. And you keep cycling through and over and over. And eventually, lo and behold, you meaningful in terms of the ratings. And if you get a user, a viewer here, the vector that resulted from that movie vector that resulted from that lo and behold, you get a rating which viewer rates the movie. That's the idea. Now this actually, the solution I solutions in the competition So this is for real, this Now with this example in mind, components of learning. So now I would like to abstract from the are the mathematical components that And I'm going to use a metaphor. I'm going to use a metaphor now from is a financial application. So the metaphor we are going to You apply for a credit card, and the a good idea to extend a credit From the bank's point of view, money, they are happy. If they are going to lose money, That's the only criterion they have. Now, very much like we didn't have a viewer will rate a movie, the bank deciding whether a person What they're going to do, they're going previous customers, and how their credit try to reverse-engineer the system, and they're going to apply it That's the deal. What are the components here? Let's look at it. First, you have the applicant And the applicant information-- you there is the age, the gender, how much owe, and all kinds of fields that are creditworthiness. Again, pretty much like we did in that these fields are related They don't necessarily uniquely And the bank doesn't want a sure bet. as reliable as possible. So they want to use that pattern, a good decision. And they take this input, and they want So let's formalize this. First, we are going to And the input is called And that input happens to be So we can think of it as component is the salary, years in the components are. You put it as a vector, and Then we get the output y. The output extend credit or not to extend And being a good or bad customer, that Now we have after that, The target function is a function set of all of these x's. So it is the set of vectors So it's a d-dimensional Euclidean And then the Y is the set of y's. Well, that's an easy one because accept or deny. And therefore this is just And this target function is the ideal don't know. In all of our endeavors in machine unknown to us. If it were known, nobody We just go ahead and implement it. But we need to learn it because So what are we going We are going to use data, examples. So the data in this case is based on The input, which is the information in which is how they turned This is not a question of prediction five years, they turned out So the bank says, if someone has credit because these guys And this one made us lose a lot of And the historical records-- there are All of this makes sense when you're those guys. Then you pretty much say, I will function is. So this is the data, and then you use records, in order to The hypothesis is the formal name we're to approximate the target function. So the hypothesis lives in the same you look at the value of g, it supposedly While f is unknown to us, actually we created it-- and the hope That's the goal of learning. So this notation will be our notation used to it. The target function is always f, the refer to as the final hypothesis will be that notation-- there are capital N And the output is always y. So this is the formula to be used. Now, let's put it in a diagram in order If you look at the diagram function and it is unknown-- that is the ideal approval which we will hoping to get to approximate. And we don't see it. We see it only through the eyes This is our vehicle of understanding Otherwise the target function is And eventually, we would like to The final hypothesis is the formula the approve or deny credit, with the hope Now what connects those two guys? This will be the learning algorithm. So the learning algorithm takes the hypothesis, as we described in the Now there is another component that So what the learning algorithm does, it model of formulas, a set of candidate And these we are going to call the from which we are going to So from this H comes a bunch of small candidates for being the And one of them will be picked by the be g, hopefully approximating f. Now if you look at this part of the training to the learning algorithm to natural, and nobody will But why do we have this Why not let the algorithm Just create the formula, without being formulas H. There are two reasons, and One of them is that there is no downside set in the formalization. And there is an upside. So let me describe why there is no is an upside. There is no downside for the simple view, that's what you do. You want to learn, you say I'm going I'm going to use a neural network. I'm going to use a support So you are already dictating If you happen to be a brave soul, and you all, very well, then your hypothesis hypotheses. Right? So there is no loss of generality So there is no downside. The upside is not obvious here, but it the theory. The hypothesis set will play a pivotal It will tell us: can we learn, and Therefore having it as an explicit will make the theory go through. So that's why we have this figure. Now, let me focus on the solution What do I mean by the If you look at this, the first part, expand it-- so the target function is Someone knocks on my door and says: That's the target function, I And by the way, here are I have no control over that, And would you please hand me That is what I'm going to give them at So all of that is completely dictated. Now let's look at the other part. The set that we talked about, These are things you choose, in And I would like to take a little bit and give you an example of them, so that the entire figure in your mind. From the target function, to the data hypothesis set, and the So, here is the hypothesis set. We chose the notation H for the symbol small h. So h is a function, pretty much g is just one of them So when we elect it, we call it g. If call it h. And then, when you put them together, the learning model. So if you're asked what is the learning actually choosing both a hypothesis We'll see the perceptron in a moment, perceptron model, and this would be the This could be neural network, and This could be support vector radial basis function version, and this So every time you have a model, there is an algorithm that will do the one of those guys. So this is the standard form for the solution. Now, let me go through a simple something to implement. So after the lecture, you can actually data if you want to. This is not a glorious model. It's it's a very clear model to pinpoint So here is the deal. You have an input, and the input d-dimensional vector-- and each of them for simplicity. So this belongs to the real numbers. And these are the attributes As we said, salary, years in So what does the perceptron model do? It does a very simple formula. It takes the attributes you have and So let's say the salary is important, salary will be big. Some other attribute is The chances are the w that Actually, outstanding If you owe a lot, that's not good. So the chances are the weight will debt, and so on. Now you add them together, and you add makes it a perceptron-- and you can look at this as Now you compare the credit If you exceed the threshold, they And if you don't, they So that is the formula they settle on. They have no idea, yet, what the w's and formula-- the analytic form that Now we take this and we put it We have to define a hypothesis h, hypothesis set that has all the functional form. So you can write it down as this. This is a little bit long, but there's This is your credit score, and this subtracting. If this quantity is positive, you belong approve credit. If it's negative, you belong here Well, the function that takes a real -1, is called the sign. So when you take the sign of this thing, -1, and this will give And that will be the form Now let's put it in color, and you choice of w_i and the threshold. These are the parameters that define x is an input that will be As far as we are concerned, when we are and outputs are already determined. These are the data set. But what we vary to get one hypothesis needs to vary in order to choose the which, in this case, are So let's look at it visually. Let's assume that the data with is linearly separable. Linearly separable in this case, for And if you look at the nine data customers and some of them And you would like now to apply the them correctly. You would like to get to this situation, is this purple line, separates the blue pink region, and indeed all the good customers belong to the other. So you have hope that a future customer, here, they will be classified If there is actually a simple linear But when you start, you start with will give you any line. So the purple line in both purple parameters there. One choice of these w's and the You change them, you get another line. So you can see that the learning parameters, and therefore moving the happy solution. Now we are going to have a simple Instead of calling it threshold, we're It was minus threshold. Absolutely nothing, all you need be minus the threshold. No big deal. So why do we do that? We do that because we are going to Remember that the input Now we're going to add x_0. This is not an attribute of an artificial constant we add, which Why are we doing this? Because when you do that, then all of Now you are summing from i equals So you added the zero term, It's the threshold which you multiplied by the 1. So indeed, this will be the formula So it looks better. And this is the standard notation And now we put it as a vector in this case you will be having an inner a column vector, and a vector x. So the vector w would be w_0, And x_0, x_1, x_2, et cetera. And you do the inner product by taking which is exactly the formula So now we are down to this formula Now that we have the hypothesis set, that goes with it. The hypothesis set tells you the Now we need the algorithm that is training data that you're going to use, of hypotheses, to bring the one that hypothesis that you give So this one is called the perceptron this function. What it does is the following. It takes the training data. That is always what a learning their starting point. So it takes existing customers, and hindsight-- that's what it uses-- and what does it do? It tries to make the w correct. So it really doesn't like at all So if a point is misclassified, the right job here. So what does it mean to be It means that when you apply your the w is the one that the algorithm apply it to this particular x. Then what happens? You get something that is not the It is misclassified. So what do we do when a point We have to do something. So what the algorithm does, it It changes the weight, which changes better on that particular point. And this is the formula that it does. So I'll explain it in a moment. Let me first try to explain the inner disagreement. If you have the vector x and the vector will be positive, and the sign If they are this way, the inner product will be -1. So being misclassified means that output should be -1, or it's this That's what makes it misclassified, So if you look here at this formula, it that depends on the misclassified Both in terms of the x_n and y_n. y_n is just +1 or -1. So here you are either adding a vector And we will see from this diagram that that you make the point more likely How is that? If y equals +1, as you see here, is misclassified, that Now when you modify this to w plus You add x to w, and when you add x to the red vector. And lo and behold, now the inner And in the other case when it's -1, were this way. They give you +1 when And when you apply the rule, since subtracting x. So you subtract x and get this guy, classification. So this is the intuition behind it. However, it is not the intuition There are a number of problems I just motivated that Whether or not it's a working Let's look at the iterations of Here is one iteration of PLA. So you look at this thing, and you have the purple line. This guy is blue in the red region. It means it's misclassified. So now you would like to adjust that purple line, such that the If you apply the learning rule, you'll this direction, which means that the classified after that iteration. There is a problem because, let's this guy in this direction. Well this one, I got it right, but this now is messed up. It moved to the blue region, right? And if you think about it, I'm trying messing up all other points, because consideration. Well, the good news for the perceptron learning algorithm is that all you need 2, 3, 4, et cetera, pick a misclassified And then apply the iteration to it. The iteration we just talked about, The top one. And that's it. If you do that, and the data was you will end up with the case that you You will get to something that This is not an obvious statement. It requires a proof. The proof is not that hard. But it gives us the simplest possible It's a linear model, and All you need to do is be very patient, a really long. At times it can be very long. But it eventually converges. That's the promise, as long as the data is So now we have one learning model, and previous customers and their credit perceptron learning algorithm, and come up can hand to the bank. Not clear at all that it will be good, historical records. Well, you may ask the question: if I mean that I'm getting future customers only thing that matters? The bank already knows what happened using the data to help you The formula will be good or not good to customer, and can predict the Well, that's a loaded question extreme detail, when we talk about That's why we have to develop So, that's it. And that is the perceptron Now let me go into the bigger picture about so far is one type of learning. It happens to be by far the most But there are other types of learning. So let's talk about the premise of types came about. That's what learning is about. This is the premise that is common would consider learning. You use a set of observations, an underlying process. In our case, the target function. You can see that this is And therefore, you can see that people and over, in so many disciplines. Can you think of a discipline, other than as its exclusive premise? Anybody have taken courses In statistics, that's what they do. The underlying process is And the observations are samples And you want to take the samples, and distribution is. And over and over, there are so many Now when we talk about different types and look at the world and say, this assumptions look different. What you do is, you take this premise And that calls for a certain amount If a particular set of assumptions takes mathematics and the algorithms you used it takes on a life of its own. And it develops its own math and a different type. So when I list the types, it's not itself, that these should be But for what it's worth, these First one is supervised learning, been talking about. And I will discuss it in detail, and tell And it is, by far, the concentration There is another one which is called unsupervised learning I will mention it briefly here, and then algorithm for unsupervised learning And the final type is reinforcement intriguing, and I will introduction in a moment. So let's take them one by one. Supervised learning. So what is supervised learning? Anytime you have the data that is explicitly given-- here is the user Here is the previous customer, and It's as if a supervisor is helping you the future ones. That's why it's called supervised. Let's take an example of coin contrast it with unsupervised Let's say you have a vending machine, the system able to So what do you do? You have physical measurements of the measure the size and mass Now the coins will be quarters, 25, 5, 1, and 10. And when you put the data in this So the quarters, for example, are And the dimes in the US currency happen so they are smallest here, and there in measurement, because of the exposure So let's say that this is your because things are colored. I gave you those and told you they So you use those in order to train able to classify a future one. For example, if we stick to the find separator lines like those. And those separator lines will from the 1 from the And once you have those, you can bid farewell to the data. And when you get a future coin that is is, when the vending machine is actually lie in one region or another, and you're So that is supervised learning. Now let's look at unsupervised For unsupervised learning, instead of having this form which is the target-- the correct output-- the customer and how they behaved we are going to have examples that have is laughable. I'm just going to tell you And I'm not going to tell you what I'm not going to tell you anything I'm just going to tell you, here Good luck, try to predict the credit. OK-- How in the world are we Let me show you that the situation That's what I'm going to achieve. I'm not going to tell you But let me show you that a situation Let's go for the coin example. For the coin example, we have If I didn't tell you what the would look like this. Right? You have the measurements, but you don't it-- you don't know. Now honestly, if you look at this something from this figure. Things tend to cluster together. So I may be able to classify those knowing what the categories are. That will be quite You still don't know whether it's But the data actually made you a significant step. You're going to be able to come And now, you are so close to So unlabeled data actually Obviously, I have seen the colored boundaries right because I still But if you look at the clusters and especially these guys might not They may look like one cluster. So it actually could be that this is learning, the number of clusters And then, what you do-- this is the output of your system. coins into types. I'm just going to call them type 3, type 4. I have no idea which belongs to which, a single example of a quarter, a dime, Whereas before, you had to have lots of exactly to put the boundary. And this is why a set like that, jungle, is actually useful. Let me give you another interesting where I give you the input without the a better situation to learn. Let's say that your company or your for a semester in Rio de Janeiro. So you're very excited, and you Portuguese, in order to be able to Not to worry, when you arrive, there Portuguese. But you have a month to go, yourself as much as possible. You look around, and you find that the station in Portuguese in your car. So what you do, you just turn And for an entire month, you're &quot;tudo bem&quot;, &quot;como vai&quot;, &quot;valeu&quot;, After a while, without knowing anything-- told you the meaning of any word-- you start to develop a model of You know what the idioms You are very eager to know -- what does that mean? You are ready to learn, and once fixed in your mind. Then when you go there, you will learn go through this experience. So you can think of unsupervised a way of getting a higher-level Whether it's extremely high level as attributes and you just tell me a label, representation than just the in your mind. Now let's talk about In this case, it's not as bad So again, without the benefit of the correct output. What you do is-- I will OK, thank you very much, What else? I'm going to give you some output. The correct output? No! Some output. OK, that's very nice, but doesn't It looks now like unsupervised learning, could give you some output. Here is a dime. Oh, it's a quarter. It's some output! Such output has no information. The information comes from the next one. I'm going to grade this output. So that is the information So I'm not explicitly giving you the I'm going to tell you how Reinforcement learning is interesting experience in learning. Think of a toddler, and a hot She is looking at it, and So she reaches to touch. Ouch! And she starts crying. The reward is very negative Now next time she looks at it, and she she doesn't touch it. But there is a certain level of pain, curiosity. And curiosity killed the cat. In tries again. Maybe now it's OK. And Ouch! Eventually from just the grade of the touch it, the toddler will learn not to coming out of them. So that is a case of The most important application, or one reinforcement learning, is So backgammon is one of the games, a system to learn it. So what you want, you want to take the roll the dice, and then you decide order to stand the best chance to win. That's the game. So the target function is the Now, if I have to generate those things learn, then I must be a pretty good So now it's a vicious cycle. Now, reinforcement learning What you're going to do, you computer choose any output. A crazy move, for all you care. And then see what happens eventually. So this computer is playing against them want to learn. And you make a move, and eventually So you propagate back the credit according to a very specific and moves that happened. Now you think that's completely hopeless, move that resulted in this, But always remember, that you are going Not you, the poor computer. You're sitting down sipping A computer is doing this, playing they keep playing and And in three hours of CPU time, you go hours, maybe three days of CPU time-- have a backgammon champion. Actually, that's true. The world champion, at some point, was I described. So it is actually a very attractive learning now, we have a target function That covers a lot of territory, We have data coming from I usually have that. And now we have the lazy We are going to sit down, and let the produce the system we want. Instead of studying the thing debugging-- I hate debugging. And then you go. No, The learning algorithm just works, And we get the check. So this is a pretty good deal. It actually is so good, it might So let's actually examine if So now I'm going to give you Humans are very good learners, right? So I'm now going to give you a learning described, a supervised And that supervised learning problem points mapped to +1, some And then I'm going to give you Your task is to look at the examples, the test point, and then decide what After that, I'm going to ask, who and who decided that the OK? It's clear what the deal is. And I would like our online audience And please text what the solution is. Just +1 or -1. Fair enough? Let's start the game. What is above the line are I put the input as a three-by-three to understand. But this is just really nine And they are ones and zeros, And for this input, this input, and this function is -1. For this input, this input, and this function is +1. Now this is your data set, this Now you should learn the function. And when you're done, could you please on this test point? Is it +1 or -1. I will give everybody 30 seconds Maybe we should have some OK, time's up. Your learning algorithm And now we apply it here, and I ask Thank you. Who says it's -1? Thank you. I see that the online audience MODERATOR: Yeah, the big PROFESSOR: But MODERATOR: Two -1's. PROFESSOR: Cool. I don't care if it's What I care about is that That is the essence of it. Why do I care? Because in reality, this I told you the target It could be anything, And now I give you the value of the Well, there are many functions that differently outside. For example, if you take the function is white, then this should If you take the function to be +1 let's see, I said it So the top one is black, So this would be -1. If it's symmetric, it would be +1. So this would be +1, because black, and also it is symmetric. Right? And you can find infinite And that problem is not restricted The question here is obvious. The function is unknown. You really mean unknown, right? Yes, I mean it. Unknown-- anything? Yes, I do. OK. You give me a finite sample, How in the world am I going to tell OK, that sounds about right. But we are in trouble, because that's If the goal was to memorize the examples memorizing, not learning. Learning is to figure out a pattern And now we realize that outside, Does this mean that learning Well, this is going to be Well, the good news is that learning And we are going to show that, without The target function will And we still mean unknown. And we will be able to learn. And that will be the subject Right now, we are going to go for to take the Q&amp;A. We'll start the Q&amp;A, and we will get from the online audience. And if you'd like to ask a question, let the room where the mic is, so that And we will alternate, if there are between campus and off campus. So let me start if there is MODERATOR: Yes, so the most common a set of points is linearly if they're not separable. PROFESSOR: The linear separability simplistic assumption, and doesn't And I chose it only because it goes with the perceptron learning algorithm. There are two ways to deal with the There are algorithms, and most case, and there's also a technique that week, which will take a set of points create a mapping that makes So there is a way to deal with it. However, the question how do you right way of doing it in practice is assume in general it's not It will hardly ever be, and therefore that case as well. There is a simple modification of the is called the pocket algorithm, that applies the same rule with a very case where the data is not separable. However, if you apply the perceptron to converge to a correct solution in the you apply it to data that is not Not only is it going not to converge, because it terminates when there are If there is a misclassified point, then So since the data is not linearly a point where all the points So this is not what is bothering us. What is bothering us is that, as you go go from a very good solution In the case of no linear separability. So it's not an algorithm that you terminate by force at an iteration. A modification of it can be used this we talk about linear regression MODERATOR: There's also a question of the perceptron change with the PROFESSOR: Badly! That's the answer. Let me put it this way. You can build pathological cases, where However, I did not give the perceptron lecture to tell you that this is need to learn. I gave it in the first lecture, algorithm I could give. By the end of this course, Perceptron? Never heard of it. So it will go out of contention, after we But as a method that can be used, it explained in five minutes MODERATOR: Regarding the items for must be a pattern. So can you be more specific about that? How do you know if there's a pattern? PROFESSOR: You don't. My answers seem to be very abrupt, When we get to the theory-- become very clear that there is function-- there is and whether we can learn it. It is very difficult for me to explain lecture to get there. But the essence of it is that you take algorithm, and there is something you tell you whether you learned or not. So in some cases, you're not In some cases, you'll be able to learn. And the key is that you're going running your algorithm. And I'm going to explain that So basically, I'm also resisting whether it's linearly separable, looking realize as we go through that it's What? That's what data is for, to look at. Bear with me. We will come to the level where we ask just looking at it and then saying: Let's pick the perceptron. That's bad practice, for reasons They will become obvious, once we So when someone knocks on my door with kinds of questions about the data-- not me, but about the general data that They can tell me this variable is they can give you all kinds of But I will try, as much as I can, to set that they gave me, lest I should and be disappointed when another You don't want to get too This will become very clear MODERATOR: In general about relate to other statistical, especially PROFESSOR: Statistics is, in learning where the target-- it's not a function in this case-- Statistics is a mathematical field. And therefore, you put the assumptions rigorously prove the results you have, For example, linear regression. When we talk about linear regression, it the results will apply to a wide range, assumptions. When you study linear regression under mathematics that goes with it, lot of purpose of the field. In general, machine learning tries to make most territory. These go together. So it is not a mathematical discipline, applied discipline. It spans both the mathematical, to actually go into territory where we still want to apply our techniques. So that is what characterizes And then there are other fields. you can find it under the name or statistical learning. Data mining has a huge intersection There are lots of disciplines around But the point is, the premise that you surprising that people at different times with its own jargon, to deal So what I'm giving you is machine that can be applied as widely as practical applications and You will see, here is a situation, I I have the data. How do I produce the target And then you apply machine learning. MODERATOR: Also, in a general Do machine learning algorithms perform or just local optimization methods? PROFESSOR: Obviously, Optimization is a tool So we will pick whatever optimization And sometimes, there is a very For example, in support vector programming. It happens to be the one But optimization is not something study for its own sake. They obviously study it to understand optimization method. Now, the question is alluding become clear when we talk about neural global minimum. And it is impossible to put this in details of neural networks, we get to that lecture. MODERATOR: Also, this is Is the hypothesis set, in a topological PROFESSOR: The hypothesis So it can be continuous, For example, in the next lecture I take a finite hypothesis set, in order In reality, almost all the hypothesis continuous and infinite. Very infinite! And the level of sophistication And nonetheless, we will be able to see comes from the theory, we'll be able to huge and complicated. There's a question from inside, yes? STUDENT: I think I understood, more or understand the second example So how do we collect our data? Should we give credit to everyone, or because we cannot determine we can't determine, should we give credit PROFESSOR: Correct. This is a good point. Every time lecture number comes to my mind. I know when I'm going So what you describe is And I will describe it in detail. But when you use the biased data, let's So it sees the people who applied and can actually predict what the credit credit history. They charged and repaid and maxed And then they decide: is this For those who were rejected, there's whether they were falsely rejected, customers or not. Nonetheless, if you take the customer decision on it, the boundary Actually, pretty decently, even for the usually are deeper into the boundary guys that you accepted, But the point is well taken. The data set in this case is not is a particular principle in learning sampling bias, that deals Another question from here? STUDENT: You explain that we need So how do you decide how much amount a particular problem, in order to be PROFESSOR: Good question. So let me tell you the theoretical, The theoretical answer is that this is that we're going to talk about. And in the theory, we are going And how much data. So all of this will be answered So this is the theoretical answer. The practical answer is: that's When someone knocks on your door: Here I tell him, I will give you just give me 2000. But I don't have 2000, I have 500. So now you go and you use your theory that it can work with the 500. There was one case-- I worked with data in different at some point, we had almost You were swimming in data. You wouldn't complain about data. Data was wonderful. And in another case, there were And you had to deal with Because if you use them the wrong way, an expression we will see, and And you will produce a system, and you whether it will perform well or not. And you cannot give this to the customer, back to you and say: what did you do!? So there is a question of, what what data size you have? But in practice, you really have no all the cases, almost all Yes? STUDENT: Another question I have So the larger the hypothesis set better fit the data. But that, as you were explaining, might when the new data point comes, So how do you decide PROFESSOR: You are asking all them are coming up. This is again part of the theory, As we mentioned, learning is about So you are using the data, not to the pattern is. And if you figure out a pattern that a reasonable pattern, then you will generalize outside. Now the problem is that, if I give you polynomial, you will fit the You will fit it so much with so many haven't learned anything. You just memorized it in a fancy way. You put it in a polynomial form, and information about the and then some. So you don't expect at all that And that intuitive observation talk about the theory. There will be a measurement of the measures the sophistication of it, sophistication, you need that amount any statement about generalization. So that is what the theory is about. STUDENT: Suppose, I mean, here had a data set and I came up with But won't it be also important to see, using that, what was the feedback? Are there techniques where you take correct your-- PROFESSOR: You are alluding But one of them would be validation, your solution. And this is an extremely established and that will be covered in Any questions from the online audience? MODERATOR: In practice, how many medium, and hard for PROFESSOR: The hard, in most people's mind before they computational time. If something takes a lot of time, If something can be computed quickly, For machine learning, the bottleneck computation time, even in The bottleneck for machine learning is data that you have seen. So to answer your question, the the computational behavior. We will be able to predict its number of dimensions and This will be given explicitly. And therefore, the perceptron algorithm in terms of generalization. If you actually can get away with generalizing are good because model, and therefore its ability to MODERATOR: Also, in the example you So can you use more multi-valued PROFESSOR: Correct. Remember when I told you that there is There was a logical sequence to the linear models and put it very early on, more sophisticated than perceptrons That happens to be for And obviously there are hypotheses that Y could be anything as well. MODERATOR: Another question is, in do you pick your learning algorithm, and what liberty do you have? PROFESSOR: The hypothesis set determining the generalization behavior The learning algorithm does play a role, as we will see in the discussion. So in general, the learning minimizing an error function. So you can think of the the algorithm do? It tries to minimize the That is your error function, and particular update rule. And in other cases, we'll see that we Now the minimization aspect is determine that this is indeed the minimize, then you go and minimize sophisticated optimization So the question now translates into function or error measure that And that will be covered also next week When I talk about error, we'll talk translates directly to the learning MODERATOR: Back to the perceptron. So what happens if your hypothesis PROFESSOR: So remember that compare with the threshold So I told you what happens if you are you're below threshold. So what happens if you're exactly Your score is exactly that. The informal answer is that it depends officer on that day. If they had a bad day, But the serious answer is that defining that point. You can define it as 0, In which case you are always making -1, when you should be. Or you could make it belong to the -1 category. There are ramifications for that are purely technical. Nothing conceptual comes out of them. That's why I decided not Because it clutters the main concept ramification. As far as you're concerned, the easiest output will be 0, and therefore you will whether it's +1 or -1. MODERATOR: Is there a kind of problem there's a huge amount of data? PROFESSOR: Correct. For example, if I go to my computer generator to generate the target over nothing I can give you will make So remember the three-- let me try to-- the essence of machine learning. The first one was, a pattern exists. If there's no pattern that exists, Let's say that it's like a baby, baby is just staring. There is nothing Once there is a pattern, you can see Now I can see what is going on. So whatever you are learning, Now, how to tell that there's that's a different question. But the main ingredient, there's a pattern. it down mathematically. If we can pin it down mathematically, the learning, then you Because you could just write the code. But fine. You can use learning in this case, but because it has certain errors Whereas if you have the mathematical you'll get the best possible solution. And the third one, you have data, So you have plenty of data, but the going to learn. And it's not like I have to answer each The theory will completely So there's a very good reason for going outline that are This is not for the sake of math. I don't like to do math I pick the math that is necessary And these will establish it, and they and going through. Because once you're done with them, you are the components that make learning of the questions that have been asked. MODERATOR: Historical question. So why is the perceptron often PROFESSOR: I will discuss this when you take a neuron and synapses, and gets to the neuron, you find that the signal coming to it, which is roughly a certain threshold. So that was the initial inspiration, and that: the brain does a pretty good function, we will get something good. But you mimic one neuron, and then you neural network that you And I will discuss the analogy with benefited from, when we talk that will be the more proper MODERATOR: Another question is, Bayesian hierarchical procedures PROFESSOR: OK. The choice of the hypothesis set and selection, and there's quite a bit of in model selection, when we In general, the word Bayesian was look at machine learning, there are differently. So for example, the Bayesian school completely on it. And then everything can be derived, principles. I will talk about that at the very And I will make a very specific point But what I'm talking about in the course most commonly useful methods That is my criterion for inclusion. So I will get to that In terms of a hierarchy, there are a number of hierarchical For example, structural risk There are methods of hierarchies, generalization. I may touch upon it, when I get But again, there's a lot of theory, learning written by someone from pure reading about a completely It's respectable stuff, but stuff that is practiced. So one of the things that I'm trying to components of machine learning, the understanding of the concept, and That is the criterion for inclusion. Any questions from the inside here? OK, we'll call it a day, and