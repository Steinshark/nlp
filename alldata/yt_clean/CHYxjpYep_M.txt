Despite having been a graphics programmer stepped into Horizon Forbidden West, I was How do games like this, or Assassin's Creed, worlds, HOW do they draw all of this without It's really interesting, because the techniques at this point. So the first method is relatively simple. Let's start with a world and populate it It doesn't really matter what that stuff Now, let's take a look from above, so let's view of what the player is seeing. So that's the player down there, and we box. This is called the view frustum, it's what And a view frustum is basically like a box. It's defined by 6 sides, you have the left left and right parts of your screen, you have top and bottom of your screen, and finally how close you can be to things before they see. Those 6 planes define everything that's This is called the viewing frustum. On top of that, each object in the scene can them, sphere's are popular because doing like distance calculations, those sorts of You can get a much tighter fit with a box the math tends to be a tiny bit more complex, on efficiency. Now that we have this idea of a viewing volume, then you're simply going to do an intersection you test whether their bounding volume intersects completely outside, that's discarded, because And everything that's inside or bordering, Remember this test needs to be conservative, that's totally ok, because that's better If we do that, here's our scene, everything red, while everything that's being kept And as an example, if our world happens to simple pass, we've whittled that number But frustum culling, as awesome as it is, Cities: Skylines 2 found out. Ignoring all the other problems with the game, they relied solely on frustum culling, which It's the first step, not the only step. You need to go further, and this is where Let's take this simple example of a camera Now we can easily discard what's blatantly So everything outside of the viewing frustum, with just the things inside the view frustum. Now imagine a big object here, near the camera, or anything big and solid. You can't see past this thing, so we can this object, and extend them beyond, forming inside of it is visible to you. So that's occlusion, but how do we calculate And most importantly, how do games manage Because this needs to be done near instantly. Let's start with a really simple idea, that from frustum culling, at least in this simple In frustum culling, we're getting rid of our view or our camera. Taking a superrrrrr simple approach to occlusion instead of getting rid of everything that's that's inside of it Inside outside, outside inside That in itself, isn't all that complex, the past have been shipped with this extremely Basically, all that it entails is that somebody software is, and they manually author occlusion So let's say that you have your object in rock or whatever, doesn't really matter Then an artist would secretly place a box, aren't visible to players, they're only Ideally, you'd place a box that fits pretty And you'd do this for every object in the it's big enough to be important, that sort Artists didn't have time to go and make on the ground, and you as an engine programmer data anyway. So how is it that you actually perform occlusion Buncha ways, it's not particularly complex. Let's draw a border, and this will be our screen, so we basically need to project the but it just means draw it on the screen. See this silhouette here? That's defined by at least 4 sides, and out of, forming a viewing frustum, same as Except in reverse. So now that you've got your data, your set first thing you're probably going to do make sure they're even relevant. This is where things get a little custom for to pick a bunch of them, how you pick them of tradeoffs, you need to decide how much it's just an instance of that. Pick too many, and you may just spend way Pick too few, and you may not cull enough. In practice, you may just do something super for the best, which according to their presentation The developers at Avalanche studios outlined box culling system, which they called BFBC no fancy structures, nothing. The very first game I worked on, Prototype, right, it's been so long since I looked So while those tree structures can be awesome hand written, SIMD brute force version may If you catch yourself wondering, wouldn't Watch my video "Memory, Cache Locality, Theoretically the tree should win, but a brute it on modern hardware. So once you've got something like that in scene, and bam, suddenly a lot of objects green anymore, they're yellow, which in It's not perfect, and some things can slip a situation that doesn't work the way we Like here we have 2 occluders, side by side, Since neither of these occluders fully occludes don't create a sort of union of occluders, gets flagged as drawn. So that's it, that's how modern games Well, you can use this approach if you need system. What it does do though, is it served as a of the other techniques. When you draw a scene, you don't only generate generate what's called a depth buffer, and What this does is keeps track of the depth us, and the GPU, to do a variety of things. For the gpu, it allows it to do things like discard things that aren't visible. If we didn't have a depth buffer, the scene through others, and then you'd have to resort entire scene in order to have any hope of With a depth buffer, now the GPU can simply against what's already there, and if it's For us, it's pretty interesting too, because of the scene available, we can create effects scene, or even cheat and make really cheap The interesting part, in the context of occlusion objects that aren't visible. If we already had a depth buffer drawn, let's and let's say that I can somehow magic one how useful would it be? The answer is of course, SUPER USEFUL. If we SOMEHOW had that, we'd be able to wanted to check if I can draw an object, we could take the screen space bounds of that, of the object's depth in the scene with If it's behind the values in the depth buffer, the gpu ever having done any work at all. In fact, we could go a step further, say I down sample it to form a mip chain, or hierarchy Well then, when we project the screen space the appropriate mip level so that we only and easier comparison. These are called hierarchical z buffers, or we'll be doing from this point forward. So remember, HZB refers to this hierarchy downsampled occlusion maps. But we have a chicken and egg situation here. All this depends on HAVING a depth buffer, the scene. But we need this to decide WHAT to render, Which is a bit of a problem, isn't it? Early GPU's were pretty restricted in what thing that wasn't easy was to read the depth data ourselves. One way around that is to not bother with I mean, Quake came out in 1996 and required with vastly more powerful hardware, you shouldn't really really quickly. And you can do all sorts of optimizations have to be perfect, it has to be good enough So one thing that you can do is instead of render to half resolution, or you can go even whatever works right And you can hand build your occluders still, software rasterizer is basically only responsible low poly even in the ps1 era. Now of course, doing it this way isn't perfect, the previous, box only method. But if you remember the example of the object Well, using this new approach of generating occluders is not only possible, but a natural here. We've got 2 occluders, side by side, and You also have a lot of flexibility in your window was now possible. There wasn't any good way to do that before, case, so this is huge progress. As we pan out, we can see that the window culling, which is amazing. The approach itself isn't that complex. The initial steps of this are really similar culling and such on the scene, and we also The new part is here, we have our new HZB, good enough and fast. Then you'd draw all of your occluders into and downsample that to form the hierarchy. Then you use that filled in hierarchy to manually not, and that's it. Conceptually, it's not super complex. So here we can see the HZB in action with In the top right corner, we've got on display that was being drawn out. We've also got a few more levels of the One of the really interesting things to take the lowest resolution, the bright or "far That's because we do this conservatively, away value. Now of course, doing it this way isn't perfect, the previous, box only method. Recall the example we looked at earlier, of which failed miserably because of the approach Well, using this new approach of generating occluders is not only possible, but a natural here. We've got 2 occluders, side by side, and In fact, we can change this up and now we up side by side, and the overall net effect Look at the object behind, it now stays yellow, Or even better yet, we can see that using and the technique just doesn't care at all, doesn't matter in the slightest. Here, we're using the infamous stanford The shape of your occluders no longer matters, this huge amount of flexibility that was lacking An example of a game that launched with this In their Siggraph 2011 talk, Guerrilla Games Now if you've never done any PS3 development, Broadband Engine, under the hood you had a had access to, I believe, 6 of the SPU's these stupidly powerful but difficult to use Anyway, programming for them was a pain, but patience, once you got them working, boy could So Killzone 3 generated their occlusion map lower resolution depth buffer, and some highly Battlefield 3 gave a really similar talk at where they went into detail on a really similar in so many EA games. But let's be real, GPU's are just wayyy the raw horsepower they have is absolutely And that gap is only growing every year, not Ideally then, what you want is that you want to know, which is exactly what started happening. We started getting support for things like just asking the GPU, hey how much did you The idea is pretty simple, you could draw occluders. Then once you've done that, you want to visible or not, so you take the bounding volumes GPU asking if they're visible or not. If they're not visible, you can ignore them, for real later. Articles like "Hardware Occlusion Queries GPU Gems series, that went into detail on general purpose occlusion culling systems. The team on Splinter Cell Conviction went visibility system in favour of a new one built The problem was that issuing a lot of these get the answer immediately. Both of these pose significant problems. If you want to cut down on queries, your first volumes. So given a group of objects, maybe query on CPU overhead. But that of course, runs head first into the answer immediately. So you can stall the GPU by just waiting for an awful idea. So let's not do that. If you want to cut down on queries, your first bounding volumes. So you'd have some sort of hierarchy of the bounding volume of all the children. So this root node, for example, is the bounding So given a node in the tree, you'd do a volume, saving you the cpu overhead of having If that query fails, the entire subtree isn't But that of course, runs head first into the answer immediately. So you could just stall and wait for the answer, You don't want the GPU or CPU just sitting So then you come up with various attempts proposing here, but ultimately, it's a whole well, which is why the Splinter Cell team and went in another direction. Late in the project, they pivoted away from getting a lot closer to what's in use today. They take their set of occluders, and remember geometry, and render them out to a depth buffer. Now they have a depth buffer, and they use what we showed before. So each level is half the resolution of the 4 texels from the higher resolution map that Then, they take everything they want to test point knows the screen space box extents of it's testing, and it's responsible for Then that final, single render target is read can see the results of their queries. And the awesome thing about this approach there's only this single stall at the end But in reality, renderers have a crapload can front-load this occlusion work early in your frame update as you can, then shove whatever GPU do it's thing, and then do your single end of the world. One set of problems that we'd like to get of authoring occlusion geometry, and having That's time being spent that could be spent One observation that you can make about any next, very little changes. In reality, to generate the current frame, a tiny bit. Objects might be moving around, but at 60fps, Same with the camera, that will have moved What if we could exploit this somehow? One attempt to exploit this temporal coherence Creed. Full disclosure, whether or not they came where I saw it talked about. Their approach seemed to be to take a bunch buffer. Then, they'd take last frame's depth buffer, those 2 together. Wait, what's reprojection? The idea isn't overly complex. If you know roughly where things were last things were moving, then you can re-project, be this frame. That's all. Anyway, so they describe using this approach HZB from that, and then doing their occlusion So that's really a neat approach. But unfortunately, quite difficult to manage the engine and implementation in order to The basic assumption, that stuff doesn't still good, but the technique wasn't quite So that leads us to more or less what's The basic idea is that all the stuff that very likely visible this frame, so take those occluders. So we draw all of those, and then we take So, if you're wondering, this doesn't an object was off screen before, and now is They should be occluding things, but that's That's ok, this approach is conservative, Like I said before, that's better than missing Secondly, because it was off-screen, and we even draw this new object. Well, that's a problem, so we need to move This approach is known as 2 pass occlusion It's right there in the name. It's not a mystery. In this 2nd pass, we're going to go over and we're going to re-test it against the So that big shiny new object that moved into That will obviously pass the test, and get And because nowadays we have compute shaders, for draw calls themselves, this entire pipeline, which is awesome. What does the future bring? I'm not sure, there's really exciting are now being broken apart and occlusion culled, have technology like Nanite from Unreal engine, detail system. Very cool stuff. Be under no illusions that this is a complete should give you a pretty decent overview of We haven't touched on things like precomputed the scene cheaper in general to render. I can take this scene, and with very little can suddenly render significantly faster. There's so much work that goes into modern the surface. Cheers