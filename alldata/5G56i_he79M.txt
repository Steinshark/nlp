so I I categorically would not trust this in any way shape or form but I think you know given enough time and enough driving I can get to a position where it could do something which I think could be you know borderline safe my dad lives in suffk in a place called halsworth my mom lives in Brentwood in Essex and this came about by the idea of is it possible for me to drive from suffk to Essex and by the time I get there if I've captured the right data if I went out for dinner with my mom could I come back and the car could learn to drive itself back so to Cave at this one of the biggest problems is data collection so how do you collect this data so the best way to do it is to get the acceleration steering angle and Brake data from the OBD2 port on certain cars but this requires a specific harness it's quite expensive it's about 15200 I didn't want to do that so how well can we do this on a budget so I skipped the acceleration braking and just focused on steering and I did that on budget with an uino board and a webcam and this computer down here which I SSH into to transfer the data in theory it would have worked so we would have gotten the results by the time I got back to the car and then we could have seen what happened um I thought this was going to be more straightforward than was it turned out to be a little bit tricky um but yes it works I think and you can be the judge of that you can see what happens in the end we have to um capture data on a budget so what we're going to do is we're going to use two things we use my well three things really we've got an uino board here which we'll speak a little bit about and we've got my laptop and we've got a webcam just a USB webcam I wrote some code for this uino and essentially have turned into a spirit level so what it does is it just monitors the angle that it's positioned at you can see the a know working here if we put it flat to the table It should read something close to zero and if we move it around and tip it you should be able to see the numbers going up and down so that's one part of it so what I did is I basically stuck that to the steering wheel of my car the back of it um so not affecting my driving safety conscious and all of that um and to caveat this we're doing on a budget so it it would only really work for 90° um and we'll get into that a little bit more later so basically 90° of steering angle mostly Motorway driving a-roads we're not going to need too much of that so I figured that was okay and then what we do is we um have a webcam that we put on the dashboard turns out the dashboard isn't the right place for this and we want to see that later just cuz it takes up a little bit too much of the view I wrote a python script and basically to take frames from the webcam and via the serial Port so this connection here uh the aino and the computer every time it took a image it would then get the correspond responding position of the uino board which was attached to the steering wheel are you using GPS or anything at this nope no GPS just vision and that was it so I started the drive with the laptop so I charged it up last about 80 minutes turns out 80 minutes was a lot of data the goal was to do this in real time so obviously this didn't happen this was a few days later so I had this data so these images and these labels and I had to make one correspond the other so how can I get a machine tell me for this given picture what's going on in this picture where should the steering wheel will be in this position we used our trusted neural networks for this so we've got loads and loads of pictures here with numbers like 0.1 0.6 minus 0.4 and zero so zero is dead straight so we've got these images and these corresponding labels and we have to tie the two together now one of the issues with this data set is that for most of the time a significant proportion of the time you're going to be um basically pointing straight forward not much is going to happen so you get a distribution like this if we have minus one here and we have one here we have a distribution which is very peaky around the zero so this is a bit problematic so for the really extreme angles I just chopped it off so we don't worry about this if anything happens here don't worry mainly Motorway driving not a problem and then for these numbers here so these labeles what we did is we actually squared the number to try and get this distribution a little bit flat because the problem is it's very hard to convince a neural network not just to pick zero here because zero is right so often how do you bias this to try and make it pay attention to what isn't zero so the goal was to basically flatten this distribution out by doing some mathematics essentially squaring the numbers so that it becomes a bit flatter so that the neural network can learn so that was the first problem we had to deal with but now the data or at least this side of the data the labels are um correctly pre-processed now we can get into how we design the the neural network to do this so there are many ways we could do this one of them is we could train our own network from scratch um but a better way just for Speed and ease is we're going to use the convolutional neural networks or particular ones that are pre-trained so these are designed to recognize objects and images so we spoken a little bit about them before is there a dog in this picture is there a cat is there a car bus so on and so forth and with in those networks there's there is a lot of functionality for detecting objects and things and where they are in an image okay and in in that instance it's tailored to just trying to work out if something is present so what we do is these neural networks are built up of layers so we have lots and lots of layers of a neural network so I use something called mobile net version 2 because it's quite good it's quite small um it does the job quite well and it trains pretty quickly CU it's say not too big so we've got mobile on it here and there's uh another layer here and what we do is just say great we like all the image processing that you do but what we're going to do is we're going to chop off the bottom part of your layers so you're not going to be doing any classification but the features of the image and everything you've seen will be in a slightly higher form above the outputs so we want all of that so we're just going to cut off the bottom layer so we can get rid of this here and then we can take this layer and then build our own custom layers here so we build two or three custom layers so convolutional neural network layers here and this will output a real number specifying what position it thinks a steering wheel should be in so this is perhaps turning the RO data of the images into something the computer can comprehend that then you can choose to do something different with yeah so what it's doing is it's to do this manually as in to hardcode everything we'd have to do an awful lot of image processing it's got that image processing inherently in it and we want that we don't care about the classification we don't care what's in there image we just care kind of where things are what's what's going to happen so this was the form of the network so um mobile net version 2 cut off the bottom layers append summer own and what that actually means is when all this is training because there was an awful lot of data here what actually happens is we don't have to train the whole network really we can just train our bottom layers which means it's a lot quicker we can get results faster and for someone who's got very little pay for these sort of things that's really really great took about about 12 hours to train so it had to be a really long lunch and you'd have to be coming back very late if you plan to do it all in one day but we we did get some results so I actually used this um another way which you could do this which I did is I used small videos instead of images and small videos I thought were great because it gives you an idea about the direction of travel over time so instead of an image you really don't know how fast you'll go in the image when you just see one thing but if you see several images you can work out sort of velocities and if you're accelerating decelerating and I created a much more complicated Network to analyze these didn't seem to work as well similar results but it just took a lot more training time um and it was overall uh just not a productive thing to be doing so single images just feeding in single images to the network seemed to be the most effective way does it work it definitely works would I trust it no but it's it's doing something slightly different so typical cars that do Lane keeping which is approximately what this is is they look at the lines on the road and try and identify where they are now we're not doing that directly we're just saying here's an image that we we give to the network which position should the steering wheel be in so in that sense so having driven cars that just do the lane detection and look for the lines um sometimes they get confused they get confused quite easily if the lines aren't particularly there with this the one thing about it is it should be robust it should robustly keep you on the road and robustly drive you into a hedge whenever it wants but it won't lose track of what's going it's always going to be trying to be engaged and driving when I was training the data I removed some sequences from the data set so we've got basically 10 second sequences and I think we've got 20 of them and I use that separately so once we've got the training data which is used to train the network and we've got the validation data which is used to understand when the network has finished training and we've got the test data to get a number out saying how good the Network's performing that number is actually a bit meaningless here because you don't really know what it means you only kind of know if it's working by uh applying it to some data it hasn't seen before because of authenticity we're going to be showing what the network saw the quality is rubbish when using um these pre-train neural networks uh they have a specific size of image that they take and it it's 244 by 244 and that's actually quite small so the video that we're going to see now detailing how well things worked um the image is the image quality is particularly low because that's the quality of the image uh the network CC I thought it would be disingenuous to Spruce it up and make it really clear uh because that's not really what the network saw so in this video we've got a blue square down at the bottom and this indicates to what extent we should be turning left versus turning right so obviously when the blue square is far over to left that means sort of a hard left and far over to the right means a means a hard right and we can we can now discuss how well you think it did so this is pulling away from a junction you can see that I think it's fair that we should be turning left there it's doing appropriately uh and then turning right now again we're quite happy with that there's a bit of a delay there where it wants to pull you into the Verge but aside from that it's definitely learning something appropriate towards driving this clip not too much interest in going here leading slightly to the right so one of the issues with this this is using the uino which is like a spirit level if the road is at an angle that's obviously not the best for perfect science but for this road a little bit to the right I think we're we're happy there and this this is a clip actually from halsworth so this is one of the very first ones and you can see turning to the left keeping it in the middle for this point and then slowly going towards the right I'm I'm quite happy with that I mean I don't I wouldn't trust it but you know it's um it's definitely learning something something appropriate well considering you're doing this as a bit of a side Hobby and there are there are teams of people in California devoting having just got back from San Francisco and seen actual driverless cars driving around the streets which is very strange yeah um yeah no this is good um yeah I think with you know a lot more time a lot better camera placement it will be interesting to see how good this could get but I was pleasantly surprised by the first attempt as say here this is just driving on the motorway there's not much to be doing for example here this is when we were talking about the bias of the numbers before pretty much if you don't know what to do keeping the steering wheel dead straight is a good guess for the neural network if this was kind of like in conjunction with other systems yeah then actually you could build something quite powerful exactly so if I did have the acceleration and Brak data I was thinking about this you could build separate networks for all of them and just having them running at the same time rather than having to put so much data into the network and doing a bit of multimod learning so with this we never actually know what it's doing or why it's doing what it's doing so interestingly I think a large part of this is it's learning to follow the car in front that's a very sensible thing to do so it'll be very interesting to see what it does when there's no traffic around I mean here's a clip now I I guess there is a car in in the far distance but it does seem to be it seems like a bit of a right turn there yeah that seems appropriate so it looks to be doing a little bit more than that but we never truly know so it could be looking for Road markings it could be looking for trees grass verges cars we'll never know so the only way to really test it is to kind of look at it and go yeah that's all right so I I categorically would not trust this in any way shape or form but I think you know given enough time and enough driving I can get to a position where it could do something which I think could be you know borderline safe um which is for a budget project with Nordo a laptop and a webcam and half the screen cut off through bad placement of the webcam I think that's pretty pretty optimistic who knows what next flying planes or something like that so if people wanted to have a play with the code that absolutely so um I like things like this because they are quite playful so all you really need are you need some images and some corresponding labels and I've uh I can link the uh I can put a link on to my personal website so you can see the GitHub repository on there so on the top right hand corner there's a GitHub and you can play around with this code I've got the uino code on there I've got the code to capture the images alongside the uino output through the series Port um that's for the data capture side and I've got the machine learning side of it as well um which you can use there um just for silly ideas and I do love a good silly idea if this worked appropriately there is no reason I could think as to why if you didn't strap a webcam to quite a powerful remote control cutter put it to dashboard height