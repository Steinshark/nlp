yeah we're a bit late to the party Google deep dream's been out for a while but it follows on nicely from on your network talks let's talk about how it works Google deep dream is a strange computer program that outputs kind of psychedelic trippy images this is one off the Google's gallery and it's some kind of strange what is it we don't know kind of strange there sort sort of Viaduct here and that looks like a fountain and some grass weird sort of artistic image but generated entirely by a computer now at the time this came out most people were having lots of fun playing with this and playing with online generators but no one you know really talked about deep down how it worked kind of looks like sort of digital Salvador darly doesn't it it does a bit yeah and I think we quite instinctively quite like the idea of that computers can do art in some way for what it's wor it's not quite art yet I don't think but we you know it's a bit of fun it also has some interesting implications as to what a new network is doing underneath um that we talked about a bit during the video where we looked into a network and sort of classifying digits this is a similar kind of thing where you can see that the lower level layers are doing some things and the higher level layers are doing other things so let's try and break down what it's doing and then we can see some fun images I ran myself now Google's Google net which is the name for Google's Network that they released in I think 2012 as part of the uh image net competition is quite complicated right they have these modules of groups of convolutional layers called Inception modules which is a very cool name for something which is probably not quite as cool as as that but it's a cool name the idea is you go deeper and deeper into the network and you get more and more powerful classification out of it okay but at its core it's still a classification Network so it's saying what is this a picture of it's a picture of a cat right 100% confident picture of a cat definitely right oh no it could be a dog right so um I'm what I'm going to do is I'm going to draw a network but I'm going to draw my sort of standard multi-layer Network it's got nothing to do with convolutions and nothing to do with Google net because it's easier to visualize um so I'm I'm oversimplifying it but on the other hand the same things apply to this small Network I'm going to draw as to the big Network so remember that we have some input neurons here and then we have some intermediate neurons and then finally our output neurons now if people think back to the videos we did on this this neuron here calculates a weighted sum of all of these neurons and this one calculates a weighted sum of all of these neurons so if we were going back to our house analogy right this one here could be number of Windows this could be square footage this could be if it's got pool or not right and this is taking some combination of those things and trying to start to work towards the price for a house and this one takes some combination of those combinations and starts working towards the price of a house now when we talked about convolutional networks these neurons are replaced with image convolutions like soble Ed detections and other things right where the actual convolutions themselves are learned so the early layers are going to be finding lines and corners and things like this later on we're going to start to find objects boxes circles things that have multiple lines and Corners as part of them and finally as a top we start to move towards actual objects we're trying to classify cats and dogs and bikes and then finally we get an output that lights up if it's a cat right that's the key I I mentioned this very briefly in in a video and I'm going to mention it again very briefly because back propagation is not for a computer file video there's a lot of detailed analysis of back propagation online for people who are interested in it right it's very mathematically complex it talks a lot about partial derivatives and multivar calculus and things like this we won't be doing any of that in this video so please don't turn it off right but the idea is that if we put an image in at this point we can calculate these weighted sums and we can propagate it through and get a value out that says how much of a cat is in this image is is essentially what we're doing when we actually want to train this network to do something what we do is we know we're looking for a cat so we try and change these weights to better predict it so we have something called a cost function here C and what we're trying to do is we're trying to work out how we affect C by changing this particular weight here so it's a relationship between the weights and the cost function now when we train a neural network what we do is we try and minimize this cost function so the cost function might be something like prediction accuracy or ukian distance or some sort of softmax right but the point is that this gives us a value of how good our guess is and then we alter all our weights going backwards to say let's just change these weights a bit so that that error goes down and we get a little bit closer to the right prediction right um so we go forward to get our predic we calculate the error and we propagate the eror backwards so that's all the background you really need to know how Google deep Dream works what Google deep dream does is forget the cost function completely we we've already trained the network what we want to do is maximize these values here or these values here so think about it if this is a picture of a cat right so I'm putting in a picture of a cat here then what's going to happen is it's going to c a weighted sum and then one of the C Neons is going to light up right but also if you think about this layer if we're working our way backwards it might be because this one lit up which is maybe there's ears and this one lit up which is maybe Paws and maybe this one lit up because here was a few lines in a row and this one is sort of furry texture or something you know and we're getting lower and lower level as we go through and and in the end it's because this one lit up which is edges and this one lit up which is Corners in a certain place the values in here influence the values here and here and here and here and then end up converging on our thing so what we want to do to make our Google deep VI images is change the image to make these bigger right so if this is the amount of ear in our image if we can just make that as big as possible we can say more ears please there's a bit of ear going on there but I want more I want more ears I want more paes I want more bits of cat so instead of minimizing this cost function we're maximizing the sum of these or squared sum of these let's not do any more maths right let's look at some pictures I have my landscape image now if it's looking very boring to you it's because I haven't passed this through Google deep dream yet right but what I do is I pass this input into the Google deep dream and for every area in the image it starts to light up some of these neurons because maybe although this isn't a picture of a cat maybe there are some kind of Catty features in it you know like the edge of a leaf might be kind of the same shape as an ear or this texture of this grass kind of the same texture as fur so some of the same neurons are going to light up right so what we do is we then try and make those bigger by altering our input image okay so just like we would try and train our Network to get better we train our image to get better to be more of these features now of course this network is trained on lots of things other than cats so anything that looks at all plausible it's going to try and maximize that effect so this is a picture I ran through it here okay we've done some strange things in the sky here we've got the kind of roofs of buildings appearing and then down here we've got some animals appearing and I don't know what that is some kind of dalc and then this weird animal here if we zoom in on that I means anybody's guess what kind of animal that is but this is what's so cool about Google D dreams you don't know what you're going to get and it's going to depend on your input image so you know the features that it found in the input image or that feature looks a bit like a bunch of lines which in turn look a bit like the edge of a of a cat's head make it look more like that and if you keep doing this process it starts to converge on weird animals that have interesting features so is that multiple iterations yes I think it does about uh 40 iterations by default so it um tweaks the weights of the image uh 40 times in actual fact Google deep dream does it at different scales as well but we I've sort of brushed over that because it's not hugely important but it runs a small version of image first makes it a bit bigger and runs it again makes it a bit bigger and runs it again um so you can then take this image and put it back into the front and make it more I want more of these weird shapes and weird animals so I take this image and I put it in and I get something that's really weird so it's the same but but just more of it it Bears no resemblance really I mean there's a tiny bit of tree left here but there's it Bears very little resemblance to our original image apart from this generic area of ground in the sky but on the other hand we've got all kinds of there's there's a weird car appearing here and some actual full ared buildings starting to appear because later on in this network some of these neurons are going to be representing building shapes and so it's trying to make it more building shape what's this for right why are we doing this I mean that's that's a question you'd have to ask Google because I'm not entirely sure but no it's there are two things it is fun right so mostly it's fun most people aren't interested in what new network is doing underneath they like cool trippy images um one of the problems with newal networks is that they are a blackbox so we we we design them with an architecture and then we run them and they get I don't know 80% accuracy on some task and that's very good and then we say no more about it we now have a program that can classify these things at 80% accuracy in many ways we don't really care about how it did it if it does it um but if we want to improve these things Beyond 80% and be on 90% and get them better and better it's a good idea to try and understand what's going going on underneath so there are some papers out there Google are working on it there are other papers as well that are trying to understand what it is that the lowest layers of a network are doing and the highest layers of a network are doing for different tasks intuitively the lowest layers are edges and things and as we go up hierarchical groups of these things so buildings and so on um so one thing you can do is you can instead of maximizing this layer which represents very high level objects we can maximize one of the layers down here which maximizes edges and things so here's a here's another picture of Google deep dream that I've maximized a lower layer okay so you can see that instead of starting to form objects it's now just starting to form patterns of lines and textures and that's because that's the only thing that's described at this lower level of a network so now we're on Van go impressionism right so yeah impressionism this is much better than I can paint as well the idea is that the lower layers of a network are doing things like this and the higher layers of a network are looking for more complex objects that's basically what an network does this network has been trained on somewhere around a thousand classes of objects so cats dogs bikes people buildings and so on this network that I showed at the beginning is trained only on buildings which is why many of the things that have been generated in it look like buildings often some of the objects you see start to look very similar so you've got a building here that looks like a building and another one that looks kind of similar with this with this Spike on and that's because the Network's been trained on certain objects and these objects get a good response and then it m maximizes those things so the question was then what if I want to generate an image that makes this look more like a cat specifically a cat rather than just cats and dogs and buildings and bikes and all these different things so what we do is we put a cat image into it into the network and we find out which of these light up for a cat specifically a cat right and then we instead of maximizing all of them we maximize only those ones okay so we're basically saying now more of it please but more of only the specific interesting cat ones right um I chose cat because people on the internet have a lot of pictures of cats they're very easy to obtain so I put in a picture here's some picture of some cats that I put in so when I put this into the image into the new network it's going to classify this as a cat or multiple cats and it's going to do that by finding combinations of features but look like cats so if I pin down the learning to do this I can start to make my image look more like a cat so you can see there's some eyes have appeared there's a kind of nose here that looks let's face it it's not really a cat but it's it's more of a cat than the landscape was it's a pretty weird image All Things Considered and this is at a high level if we do the same thing for a lower layer we can't get all that hierarchical sort of ears plus eyes plus nose we can only get the lowlevel things so we can say do this one which is almost entirely fur and eyes right so you can see that the clouds kind of look a bit like fur so it's made them look more like that and the eyes are all down here so this is a different kind of image that we produced by trying to make it look a bit like a cat but only only at a low level so you know what are the lowlevel features that make a cat okay how strange um and finally you can do it for people so I put in a picture of some people's faces and uh out we get is an incredibly weird picture of sort of weird hybrid baby things that kind of gives me nightmares You could argue in some ways we're getting intuition about what the lower levels do and what the higher levels do predominantly it's just for fun there are other papers that do outputting of network layers and trying to work out it is that each layer is doing but in this way it's just kind of generates cool images so if you want to use Google deep dream you just need an input image and maybe a reference image like a character to Target it towards but really you don't need much more than that and then you can just get going on it is is it a website or something is there so no so actually it's it's um python code that goes into Cafe which is a deep learning library um so that's how I generated these images uh people have obviously put a website front end on this so it's very easy to find websites that do the same thing but in actual fact it will just be running the source code back behind the scenes if you look through the source code it's actually not very long because this process of of back propagation is already coded up in these libraries so all you need to do is tell it instead of Maxim minimizing the C we want to maximize the value of these things and you just change a few numbers around and send it backwards through the network um it's you know not it it sounds complicated but really actually it isn't that complicated once you once you actually look at the code you can start to see this uh quite easily what we hear is is a piece of 160 m film you can see that actually you've got lots and lots of individual images and each of those images we refer to as a single phone and when you projected this film you literally sh