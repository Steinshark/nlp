how turbo repo is porting from go to rust or strategy for making updates and maintaining stability while we migrate languages okay we've read something earlier this year that was about how they they ported turbo and now they're doing this whole turbo repo business so let's see this all right we could we should recognize some of these people here let's go in a previous blog post with the one we've already read right uh we talked about why we are reporting uh turbo remember it was like rust makes developers happy when you have happy developers they tend to work better blah blah blah blah the high performance build system of uh javascript and typescript from go to rust now we're going to talk about how it's pretty exciting let's see the how let's see the nitty gritty today our reporting effort is in full swing moving more and more code to rust but when we were starting out we had to make sure that porting was feasible for us to accomplish a migration from one language to another is no small task and there's a lot of research to do up front uh to ensure that the end goal is attainable yes here's uh how we started the process validating our current porting strategy and made the call to port turbo repo rust i think that anything that involves a bunch of system calls i go on the fence of whether you should stick with rust or or or stick with go or go to rust honestly i think there's a lot of value and go in this and i don't think you're i don't think go and rust you're gonna experience a huge slowdown or difference in fact i think writing in rust you might even find yourself slowing down because you're just not good at writing it right i am very curious which is better right uh port versus full rewrite when we are planning our migration we briefly considered a full ground up rewrite but talking the idea through we realized it wouldn't fit our goals as well as an incremental port would what is an incremental port incremental porting moves code piece by piece running new and old code together at the same time roman writing pretty much uh the goal for the chunk of code uh being moved is to keep the behavior exactly the same as before it was ported yep you're just going piece by piece there's like a the first block is the hardest block because it has to do like the core work and then you slowly start unraveling that you know what i mean in our case this means we need to have our go code and rust code interoper inter-operating with each other we want to do simple translation explicitly avoiding making improvements or changing functionality while we're swapping out the languages for uh the slice of code that way we can do an intensive testing against both sets of code and complete the migration as quickly as possible why we didn't do a full rewrite full rewrites are very tempting they are so tempting and they seem like the best time plan every single time they are more simple to write and ship as you don't need to worry about the before and after code working together you also get a clean slate to write new and improved version without the warts and technical debt of the previous iteration however full rewrites also come with some serious downsides agreed completely agreed this is a great little this is a great chart honestly is that this is what your code did look like this is what it looks like now and you fundamentally changed pieces so it's like really hard to go one-to-one on how it's going to operate and everything first a full rewrite tends to require a complete halt to shipping new features otherwise you run the risk of chasing a moving target as the old code base grows while you catch up with your new code full rewrite also does not guarantee a better user experience often a rewrite ends up less than seamless and it's as it's not feasible for the new version to match the old one feature for feature edge case for edge case the surface area of the rewrite grows there's more room for error and as the users can end up frustrated with the breaking changes and missing features good reason not to do full rewrites i'm always very skeptical of full rewrites full rewrites are almost always a mistake almost a full rewrites also require building an entirely new code base which is a large quantity of the unused code in our experience unused code even when verified with tests can be a breeding ground for bugs we wanted to make sure that any new rust code was properly exercised as we moved through the porting effort this is good uh just delete all the old project remember the mistakes you didn't go and rewrite and rust we choose to port therefore we decided to port turbo repo to rust instead of doing a full rewrite the reporting didn't uh necessitate some trade-offs so we had to introduce a significant amount of complexity into our code base so that we could interrupt between go and rust this complexity meant slower developer velocity to start with but we look forward to workflow improvements going forward particularly when our porting effort has finished more importantly we know we could continue shipping features to turbo repo users while porting all things considered we determined that this was a reasonable compromise and a path we would take perfect i think this is really good honestly i think this is a really good reason to do that starting the port uh rewrite uh rust and go please yeah just switch it up just rewrite it just rewrite it already i we've already heard this song all right we choose to start by writing a small new turbo repo feature in rust this way we could add new functionality from the roadmap for our users integrating rust into the build process and interacting with the existing guild code as little as possible to reduce our initial complexity once we laid the groundwork we knew that we could slowly port more and more code to rust over time global turbo we decided to have our first rust feature be global turbo a feature that allows users to install turbo repo as globally available command on their machine okay a global installation of turbo will look for a locally installed turbo program in the rep in the suppository executed if it exists or otherwise fall back to a global turbo binary that way you could easily run turbo from anywhere in your uh suppository and keep and also keep a specific version of turbo pinned to your package json this is great that's uh this is a perfect way to do things beautiful beautiful uh let's see see apps web turbo app info uh turbo no local local found run run run run run beautiful this feature is implemented through what we called the rust shim a bit of rust code that wraps the existing go code the goad portion is compiled via seago as a c-static library and then linked to the rust binary luckily global turbo only requires a few features from the rest of turbo repos code such as a reading configuration and navigating the file system okay why not turbo in turbo pascal though it would have been the best uh this is where it gets uh uh [ __ ] okay okay okay cli parsing as we implemented global turbo we realized we needed to parse a few command line arguments like current working directory the argument for setting turbo's current working directory well clap come on get clapped kid after global turbo it uh it made sense to continue by porting the rest of the cli argument parser to rust to parse arguments we used clap let's go clap claps the best russ equivalent to the npm package of an npm package it's just so good though clap lets you define a data type with the arguments annotate a little bit of it and automatically create a parser let's go with the pieces in place we had to work on sending the args from rust entry points to the go code for better or worse c is the standard foreign function interface uh ffi let's see so we had the uc communicate between rust and go what do you mean do you see you have the right c for this you couldn't just directly call if you're doing a static link library i thought you're doing like a c build of the go i'm confused do they actually write c do they have like a bit of c in in betwixt go is in cabi compatible i don't know is it i thought it was because rust is c abi compatible there's like a little flag repercy or something like that that you can put on the top rust seago see the great equalizer makes everybody cry in segmentation fault uh we wanted to avoid having too many types in c as we weren't confident that we could write cross-platform c types that played well with both rust and go instead we decided to serialize our arguments to just on and send them to go as a string even though just on serialization does have some overhead we knew these argument structs would uh only be a few 100 bytes in size so the performance would be minimal yeah that's fine i'm surprised you know when i hear this i'm actually surprised they didn't uh just run the go program as a sub module and then allow standard in and just like right to standard in like do some basic ipc or something like that uh on this on rust side we used another cornerstone of crate of the rust ecosystem which allows you to by the way that's properly high i didn't know if you know that but to say saturday correctly you have to say it like that anyone that tries to give you some other way they're lying to you okay saturday and jay diesel would have solved this because tom's a genius let's just face it when which lets you serialize and deserialize data in various formats using some minimal annotation for the go side we were already we were already using in the code base so it was easy to receive suggests on string and just serialize into a ghost struct well plus go supports the chasson at a first-class citizen though heterogeneous lists are a bit odd ship it something i said pull the plug that usually means to kill it so that didn't make any sense by the way sorry for this like this light part i'm reworking the lights that's why i look a little green right now with these two features ported we were are we are ready to ship our first hybrid go release however before we could release we need to make sure the go rust binary worked in all the various contacts that turbo repos use like different operating systems and linux distros that we supported as we tested our code we started noticing some issues on a couple platforms windows difficulties you know the easiest way to get around windows difficulties is just don't support windows honestly boom first try classic windows issues ebn ebn every time i swear it is just the worst on windows there are two main tool chains microsoft's visual c plus plus msvc and minimalist gnu for windows mingui uh go only uses mingui but we we're using russ with msvc oh gosh this caused some runtime issues but luckily the solution was simple we moved rust tool chain to uh mingui next up we had some issues with pass windows has a couple concepts of past including what's called a universal naming convention young path really that's funny it has a windows has a couple concepts one of them is called universal naming convention is that not working or something for everybody is it not quite universal as promised when you ask windows to uh canonicalize a path resolving all sim links and normalized components in the past it gives you a unc path however despite its name unc paths are not supported everywhere classic windows w oh my goodness this is just like windows to a t what's that that's a gwid where's it supported on windows nobody else uses it everyone uses uuid we do global unique identifiers around here what's that universal naming conventions who uses it windows does universally available in windows sometimes not even windows itself oh yes not even windows uses it this caused a few bugs where we provided a unc path to get an invalid path here the solution was to use helpful rushcraft called dunce that lets you canonicalize a path and get non-unk path back handling the intricacies of this problem for us let's go alpine linux the second set of challenges came with alpine linux the one where you hate your life at versel we use alpine a common operating system for cloud computing to create lightweight containers for building your projects yeah it's fun until you have to use it uh alpine though does not come with a g lib c the de facto implementation of the c standard library this is a problem because many binaries assume glib a glitzy is installed and don't package it themselves there are some libraries that pave over this issue by using packages like uh g compat or lib c6 compat but they didn't end up working for us because the version of glibsy that rust requires was too modern uh for our supported targets when we tried to run the binary we'd get errors that required glibsy classic this is like such a classic as a result we just had to compile turbo repo as a fully static binary this meant we packaged our own c standard library implementation using muscle uh you can't a statically link uh glibsy due to licensing issue beautiful licensing isn't licensing just the best isn't just licensing just the best like to me if this is a thing that's available it just seems like your licensing sucks uh this seems to work just fine for both rust and go is it because glpsy is like uh under the license that requires you to also do the same licensing for your project isn't that like the required well not all open source is open source you know what i mean some open source is like a cancer and it spreads wild and fast whereas others aren't like that right and so this one is more like a virus type acting where it's like you do if you use me then you must be the same the same version of library we use right and so it spreads it's like rxjs it spreads spreads to the whole code base this seems to work just fine for both rust and go russ lets you set the c standard library in the target okay uh versus this and go does not use a c standard library by default however when we ran the statically linked live binary it would return a segmentation fault got him even worse would be inspect it with the debugger we find a corrupted stack and even worse the seg fault appeared to be coming from go runtime itself this makes me so sad to hear all right after searching we tracked down to a seven-year-old github issue which explained that go cannot be compiled as a c-static library with muscle uh this post a significant challenge as alpine linux is essentially essential platform for turbo repo and its users we had to go back to the drawing board and figure out how we could ship our go rust combination eventually after a ton of deliberation we came up with a solution we'd compile our go code and our rust code as two separate binaries the rust code would call the go code and pass the arg serialized to jason via the cli i feel like did i not say did i not did i not say a little ipc did i not say a little in and out give it the old in and out it called it uh it's not terrible it's actually not a bad idea okay i know this may seem hard but honestly when you're doing when you're doing roman writing like this where you're kind of writing two different environments just make it simple do the thing because you know that one part of this is gonna go away forever you know what i mean we knew that the args were small enough that they could be passed by a cli without too much of the performance hit and because we were using a serialization format the code changes were extremely small all we had to do was change how rust was sending the jeze on string to go with that we are able to get our first hybrid uh go rust release out the door the first version of turbo was shipped to you using these compilation strategies version one seven zero what we learned uh though this f let's see though this effort we or through this effort we learned a lot about moving from one language to another let's take note of what we found serialization is useful for ffi our first takeaway is that serialization formats are very useful for interoperability by serializing the json a format with robust support in both go and russ we were able to minimize our ffi surface area and avoid having a whole uh class of cross-platform issues so one thing i would have done differently than they did is i would not have used json i would have used something like protobufs and the reason why i would have used protobufs is that protobufs would have provided a universal um serialization format and deserializer serializer and so you kind of get one place to define your types and then your types are defined for both programs you don't have any of this like moving target type nonsense i i like you know what i mean that's just something that i i fully i'm like fully on board with is always if you have two different platforms you're using use a common type definition you know what i mean the moving target issue yeah exactly cross-language bugs uh when we had to switch from single linked binary to two binaries we were able to do so with relative ease because of our ffi surface area was so small okay um i i would say that i just i i don't know if i agree with this because i haven't done enough ffi to have a strong opinion about it but it seems like you were doomed before you started and i think you had some odd ffi stuff because you were dipping into c to call from rust to go i feel like something was wrong there just just like in general i'm not really sure what was happening but i just the engineers at purcell are very very smart so i'm just gonna assume whatever was the reasoning it was it was the correct reason right uh protobufs worked fine between rest and go exactly uh the trade-off here is that is that serialization and deserialization is slow you can only depend on this technique if either you know your serial serialized payloads will be small or you don't care about the performance hit to your use case yeah um porting takes preparation the second takeaway is that incremental porting is feasible but requires a lot of careful testing and strategizing agreed uh we ran into quite a few tricky bugs and we caught these issues through a lot of automated and manual testing right here okay check out their testing testing is also extremely important for nailing down the behavior of your code whether it's an exact edge case of cli parsing or the order in which configuration is loaded these exact details are not so crucial when you're writing your first implementation but they're absolutely paramount to avoid breaking changes during port or rewrite you should aim to write tests before you start reporting your code so you have a known specifications to work against okay so i would say this is the one time where i would agree with like tests before code and the reason why i say that is because you already have a working version right you've already figured it out and so to me this makes more sense but i would no actually i disagree with it now that i'm arguing this to myself out loud i can already feel myself disagreeing with this already which is that the reason why i don't agree with this is that when you're rewriting in a different language your structure and how you're doing it is so much different and what you don't want to do is mirror your current code base into a new language you want to write it with the idioms the canonicalization of that language not the language you're using and so if you don't if you don't if you try to write your test beforehand you may go in with the go knowledge of doing things versus going in with the rust knowledge so i i feel like i wouldn't i feel like you're you should have a set of uh of what's it called you should effectively have a set of integration end-to-end tests that you can prove work and then your tests are already written for this new this new one right so it's already existing um that's my personal feeling right you wouldn't want to input you wouldn't want to test against the uh the units level more like the end to end level if you don't embrace the language features why the hell are you using rewriting anyways exactly so it's not really tdd at that point all right cross compatibility is difficult the third takeaway is that cross-platform cross language release engineering is extremely challenging this is why i think a lot of people default to interpreted languages every platform language and compile that's also why people love go they love go because it just seems to work everywhere it's one of the most this is why go is just such a popular language is that it just works everywhere nicely every platform language and compiler has their own quirks that makes interoperability difficult and more things you have working together the more opportunities you have for new complications porting is worth it for us finally while porting from go to rust has been challenging it has been proven correct choice for us strategically even with our porting effort going on we've been able to ship new features handle bugs in our existing functionality and help keeping our users or and keep helping our users while we migrate it requires some extraordinary tricky debugging careful planning and rarest testing but we believe that it's been worth it try porta turbo repo try turbo repo whoa turbo repo saved this many hours of time for the product engineers and ci machines at for sale nice that's a lot of hours that's a lot that's a lot of hours even if it only equates to five seconds per build fine like when you have a build that goes from three seconds to 10 seconds like there is this point in time that's like the i just accidentally went on twitter time you know what i mean there's the i accidentally went on twitter time and that happens at around like what 15 seconds right so i totally am like i'm totally on board for the faster it gets oh anthony she was here to answer articles about this oh anthony i didn't realize you're here um i'm gonna keep spamming it well awesome i like to hear that it's 10 seconds for a user to switch tests yeah you got to be very careful well hey anthony i didn't even really uh stay tuned for the next article rewriting turbo repo and css now that's the article we want anthony that's the article um this is great mastodon oh gosh no this is not even a part of it i needed another mastodon server because apparently having interviewed at the nsa 13 years ago when i was an undergraduate means i'm banned from programming languages server fediverse are you okay people use massdot twitter's just read by a bunch of power hungry billionaires mastodon also it's just like okay what kind of bargain are you getting it why why i love reddit mods if i could have anything in my life it would be reddit mods running my social media site like that's what i've always wanted in life you should read the image you can no longer use your account and your profile and other data are no longer accessible you can still log in to request a backup of your data until the data is fully removed in about 30 days we will retain some basic data to prevent you from evading this uh suspension uh don't work for the nsa do not work for the [ __ ] nsa do not interview for the nsa do not entertain the possibility of working for the nsa i thought you were cool double exclamation point i saw you on pl twitter and thought you were a neat person why would you work for the effing nsa again why would you want a reddit mod controlling your social media site just letting you know why would you want that every time i think twitter couldn't get any worse i literally read this and go oh yeah twitter's pretty pretty freaking awesome