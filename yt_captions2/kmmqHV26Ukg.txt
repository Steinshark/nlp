hey a community spotlight outperforming rust dna sequencing parsing benchmarks by 50% with mojo okay look at this this is my guest blog by muhammad mauk mohammad uh is the creator of mojo fast trim a mojo community project mohammad received 100x benchmarks improvements over python and 50% improvement over the fastest implementation in rust by the way it's not surprising if you're doing dn dna stuff you know for a fact you know for a 100% fact that there's a for loop in there you can't you can't just be writing for loop in python okay you can't be writing four loops in python okay that's not that's not what python's for he learned the language quickly cool story bro and it only took 200 lines of code for the first implementation read on for details for the extra optimizations he's applied to beat the fastest existing benchmarks learned yeah learned is past tense it's past tense learning he learned it imagine showing something as fast but comparing it to python yeah dude python's crazy that's a crazy one the era of big data in bioinformatics the challenge of for bioinformatics in modern day are rooted in big data manipulation thousands of multi-million dollar dna sequence machines are working non-stop thousands of multi-million dollar that is like that's a crazy statement billions of dollars most people say billions but man this is thousands of multi-millions non-stop in fields of bio uh biotechnology medicine and biomed research the annual sequencing data size is expected to be up to 40 exabytes of raw sequences by 2025 that's 20x the data uploaded to youtube every year that's a lot of data that's a lot of data so this makes sense a 1% improvement is insane that's it's a lot that's a lot of data uh while most of the final analysis is carried out in high level languages like python and r the world of bioinformatics is powered by an underlying uh under layer of black magic highly optimized tools written in c c++ and java say what now that pre-process and summarize large amount of raw data java did some did someone just sneak in a garbage collected language uh this creates two world a two world problem or at least it's not a three body problem where bioin uh bioinformaticians uh who are not skilled in low-level languages are prohibited from understanding customizing and implementing low-level oper uh operations yeah uh i'm pretty sure if you're a bioinformatician which sounds like a madeup word you could probably learn a low-level language that's i mean literally smart people suffering from skill issues that's how i read that statement is literally just like due to skill issues in addition typical bioinformatic pipelines are a mixture of bash python scripts called into pre-compiled binaries along with analysis logic itself it's be it's becoming increasingly complex and frustrating for a new and experience bio bioinformaticians this is the same issue that a community ai is facing skill issues skill issues and tooling issues mojo one tool to rule them all i first heard about mojo from a demo video by jeremy harward its value offer is simple a pythonic language that allows the programmer that is a strange phrase that i just said a pythonic language by the way the idea that we're going that there is a class of languages called the pythonic languages i mean i've heard the term c-based or ml-based but i've never heard pythonic based that is like it's unique it's a unique way to describe a language uh that allows programmers to optimize a at a much lower level to unify the fragmentation in fields such as ai learning mojo was relatively easy for me coming from the python i got used to the extra syntax in only a few days i decided to try mojo in a serious project for low-level bioinformatic task the fast q parsing and quality trimming fast q is a basic format for most dna sequence operations incorporating both the geon the genomic sequence and confidence scores in the machine in each base call it is a simple format to parse with most records looking like this i i really do hope that he used a a regx to parse this you know what i mean you know what i mean yeah definitely 100 too soon too soon cloud flare still reeling uh however typical uncompressed files are one to 50 gigabytes uh an average sequence heavy study could generate uh north of a one terabyte for a single file performance is critical in parsing and data manipulation i tried to i tried to write a simple parser that would read a chunk of file as a string split the string on new line separators take four uh take each four lines validate that they are consistent and correct uh fast q record and return it rinse and repeat until reaching end of file okay seems reasonable on the first try mojo fast trim achieved 8x the performance of python's seek iio i was pleasantly surprised with the development time my code was still pythonic by the way if you use this word in a stack overflow question you will get more up votes just so you know i did try to farm credit one time concise at around 200 lines and using features the average python developer would understand in quality trimming where lowquality bases are removed from each read it achieves 50 to 80% % of the industry standard uh tool cat adept that was a surprising level of performance for development time i put into the project is x or why more pythonic idiomatic rust canonical javascript dude idiomatic i just hate that word it just makes me want to die uh going down the optimization rabbit hole uh the most powerful benefit of mo mojo is that it gives you access to low-level optimizations the nent state of mojo standard library meant that i had to write test and benchmark some functions from the ground up mojo's first class support of sim d nuts uh vectorization was really helpful and surprisingly intuitive nent yeah nent means like early on state right isn't that just means early uh especially of the process of organization just coming into existence or beginning to display signs of future potential nent it's what smart people say instead of early you know like like i would just say the early state of mojo but some people use the nent state of no because you are smarter if you use bigger words here is the implementation of the vectorized version of the function to find the index of a new line separated in mojo okay always in line all right do a little bit this love the dtype got to get that dtype uh in tensor t generic t chart int 10 start int zero int four i and range all right start in tensor char return okay i mean that's very simple code to i mean i can pretty much guess everything but i don't know what a tensor is i i i don't know what that data type is but okay simd vectorization all right all right oh gosh here we go all right same same same header simd width equals simd width of t length equals element start this align start math okay okay for record aligned with simd load okay we load it up we mask for this one and re uh mask reduce or all i i i don't know what those two mean but we're doing we're doing a little something in here tensor is a faty ml array okay okay interesting bit mask i know it's doing a bit mask but i don't know what it means to do the mask right i don't know how v equals char reduce or i don't know how this is a mask right i don't i i don't i don't there's some there's some operation here that is happening that i don't i don't know what it means you know what i mean like the equal sign is not just like a simple equal sign it's it it must do an equal sign across a vector is that what it's doing and if any of those a reduce or just simply means i assume to go across that vector and see if there if any of it's true right is that is that what it's doing yeah across all elements okay yeah got it got it okay the vectorization version loads 32 elements of int 8 and checks the presence of a new line uh separator using a few operations in the following graph you can see the effect of s vectorization it provides a 4x speed up with the average of 3.2 similarly uh simd storing and loading from tensors provid substantial performance gain nice this is good this is this i mean that looks great the nanc means that i think you're probably measuring it too explicitly this feels kind of uh dangerous anyways in addition i explored optimizations from cc++ implementations i was concerned that no explicit memory buffer was allocated for the loaded chunks but mojo compiler was already taking care of that and avoiding new memory allocations okay nice nice you like the white lines in the background yeah they're beautiful i like the white lines as well implementation of those optimizations resulted in 3x speed up and mojo fast trim was on average 24x more performant than python's se iio in addition due to the control over reference and value semantics in mojo i applied the fast parser version of the parser nice uh no memory copies are made during parsing and the individual reads are passed around references to the chunk uh to loaded chunk in memory this approach implemented in rust ne needletail parser although mojo is still very young language my implementation was 50% faster than rust implementation on apple silicon and 100x faster than seio i mean yeah he ran it once and that's that's cool i'm not going to lie to you you know do i i mean usually whenever you see local benchmarks you should just take this as a uh direction not necessarily truth right this sounds like a skill issue well i mean they're saying they used the exact same they used all the same techniques that uh oh my goodness how how how do i leave this i'm pressing escape help me i'm pressing escape help me uh contrl c control d uh okay we got it i had to click i had to just click it turns out um please don't make models that pop up like that okay that's really annoying just just don't do that don't don't don't do that okay stop being clever because you're not clever uh for python programmers wanting to write more performant code mojo is a great tool to try and easy to learn however the language and the ecosystem is still growing i had to use print to bugging to gain insight into the bugs i was encountering the debugger is still in preview and undocumented although they tell me it will be officially launching soon in conclusion i think mojo can be a radical change for a wide range of python trained scientists and researchers across many fields by the way this is i saw an article i saw let's see on twitter who said this um let's go uh luca what's his name luca who wrote the rust the rust in production book what's his last name luca what luca paul luca paul luca paul luca paul luca paul he said something that i thought was really interesting um this right here rust is the dark horse of ai a few are talking about it yet almost everyone is using it the efficiency and fearless concurrency do matter when processing data of pades uh i think this is where he's going to go wrong honestly uh what i mean by that is that if mojo is true i think mojo will win just hands down and the reason why mojo will win is because you don't change the paradigm of any already acclimated and proficient individual does that make sense you just have to learn a slight bit more and you get immediately amazing performance and if it even is remotely on par with rust like within a error rate which they will clearly calculate it just means that they're going to use they're going to just use that i saw that tweet this morning and and my my first thought was i wonder how this is like i wonder what's going to be going on with uh with mojo versus this i mean obviously luca is an extremely talented engineer i don't even know why i'm not following him very very talented engineer very great i love his book he has one of the best rust books i've ever read in my lifetime which is zero to production i'm look i'm shilling it he doesn't even know i'm shilling it great book honestly it's a great book uh so i mean i trust that he's he's very smart about his opinions but uh i just don't see uh rust tooling is far superior it it could very well be but you still got to you still have to make the assumption that if given a choice make your codee as fast and learn virtually nothing new or make your code as fast and learn an entire new everything what do you think people are going to pick you got to also remember that ai is like uh john carac just said this here john carac just said this uh john carac hero by the way great guy absolutely think he's one of just one of the best uh he just said it was like a big one here i retweeted it i retweeted it he twe dude the man tweets like i do can you just can you just shut up and let me find what you're trying to say so when he comes down to here working on ai i have literally written hund little literally hundreds of little experiments more individual programs than i had in prior two decades so he's working in ai and he's written more in the last little bit of time than he did in the two decades previously for these little tools and these little individual programs and so the reason why i bring this up is that if you want rust if you think rust is going to be the successful one the reality is that this is the primary moe of operation and so if mojo compiles fast and it looks like a language you're already familiar with and it is really close to being of the same speed i just i i just don't see how you're going to make the cell i just don't i just don't see how you're going to make that cell no cost of admission it wins yeah anyways science labs are not uh fo uh going to switch to rust quickly yeah because the problem is russ rust big sale which people often misunderstand is not fearless concurrency i do not think the currency is that great yes it's somewhat fearless but it's not fearless because it's just arc mutex everything or or or atomics or you have to protect it in a certain kind of way right the thing that's going to make it the thing that makes russ so good is that it has all this memory safety and when you're doing a bunch of this ml stuff i don't think memory safety is your chief concern it's just being able to process quick enough is your like a quick efficient easy experimentation and being able to process fast enough right like to me that's that's just says like that's that's not that's that's not necessarily a highly aligned rust or uh that it doesn't it doesn't feel like rust is highly aligned with what ml needs it's mostly aligned and it could get there rust has amazing macro system and it could most certainly get there but i'm not sure if it will get there in the sense that if it has mo like i just don't think it's like quite the right use case uh which is let's see hold on mojo uses mlir successor to llvm which is specifically optimized for ml tas so it makes sense it' be faster yeah this makes this also makes perfect sense it's a compiler and everything designed to be fast for this one task right anyways super cool uh i mean i thought this i i think this is really interesting i think people should think about this stuff a lot more um oh no uh they do no checks yeah but that's that's that's a benefit you can do no checks i'm the author of fastq parsing library uh let's see and the maintainer of the julia rex engine oh you got to like link me to the one that i i don't really want to do i have to read all this like hey i'm happy for you uh the thing is is that if you don't do any checks but your program runs successfully and correctly every time then i don't care if they are identical operations and at the end of the day they both do that then yeah all right the tldr tldr is that mojo implementation is fast because it essentially a meem char m cars four times per read uh to find a new line without any kind of validation or further checking uh the m car is manually implemented by loading simd vectors and comparing uh to a zero yeah to a 10 effectively and continuing uh if the result is all zeros this is not ser let's see this is not a serious fast cu parser it cuts so many corners that it uh doesn't really make it comparable to other parsers although i'm not crazy about needl tal's somewhat similar approach either okay i mean that's that's cool okay so reasonable can we all agree that that's that that that's a reasonable take so let let me ask you this one let's say that when it's all done it's all said and done mojo is within spitting de distance of rust do you think it's going to do you think it's going to be a problem i mean and also he and also the author did say that after finding the new lines he does a postline processing to validate it mojo is a stupid name mojo is a stupid name i'll give you that rust is also a stupid name because it's named after a fungus not the stuff on metal and everyone thinks it's named after the stuff on metal so i mean really if you think about it go is the only normally named language javascript is a stupid name julia doesn't make any sense okay i i am curious though i am curious what because you know how many times have you seen this by the way how many times have you seen effectively this where someone sells a faster version of something that's not fully complete right like so bun bun does this with their asnc handling in node there's a lot more hooks and stuff involved in async handling that bun simply doesn't have and then bun sells itself as being a faster version of node but it just simply doesn't do the same checks like this is a pretty this is a pretty old uh programmer pastime which is pretty interesting i implemented the same algorithm in less than 100 lines in julia and were 60% faster than the provided needletail benchmark beating mojo i'm confident it could be done in rust too interesting so julia is really trying to get in here isn't it a skill issue okay well i mean this is all interesting so it sounds like i mean it honestly sounds like we got julia in the mix julia is the one that does the full implementation and the rest cut corners yet they're still used and people accept them so i'm not i'm not perfectly i i don't understand this does that make sense i don't understand the fact that this needle tales has a similar approach and it's used like what's the what's the point what are these checks doing that uh these checks aren't doing that make it okay i don't i i don't quite get it it sounds like bioinformaticians aren't good developers who would have thought that julia yeah julia uh yeah chris lner has a respect for julia dude everyone that i know that does julia loves julia that's all i know anyways this is super interesting i mean it goes to show it dude we see this you see this over and over again that anytime you see a benchmark just be wary about it i mean i think that's the biggest takeaway when someone says something is 50% faster than another thing you got to remember that at the end of the day you can do any type of low-level operation in rust you can do the same low-level operations in c therefore there really shouldn't be a difference in speed unless if there's some sort of uh compiler like difference right or how it's being translated different right like that's they're all technically going down to like the same level where it doesn't make sense like you you can never say that go will be as fast as rust or javascript will be as fast as go or ruby is is neat like you can never say any of those things because they each have their own like kind of they each have their own bands of of runtime is saying 10x faster the most realistic estimate of every single case being 50% faster yeah that's the dax tweet i i believe that's the dax tweet or his co-founder tweet which is when something is when something is 10x faster you say it's 10x faster when something's 100x faster you say it's 10x faster when something is 50% faster you say it's 10x faster and if if something's half the speed you say it's 10x faster you just say universal as a developer you just say 10x faster yeah but goes pretty damn close to rust andy it's not damn close it's it's not for simple stuff sure but once you start getting into a bunch of object allocations and deallocations it is different it's it's it's it's different and that's fine right that's fine it's close it's very close i wouldn't say it's close enough that's that's a statement that has no meaning because you has to define you have to define the task in which you're doing something with anyways i like this article it was interesting good thought experiment good thing to remember i think is really cool to see where mojo is going to go i think everybody should be excited where mojo's going not necessarily the specifics we're seeing right now uh you know in the next five years will you just hear everybody talking about mo mojo you very well could like that very well could be the future is that mojo is the new one that everybody talks about or maybe they just call that python i don't know the name is the primagen