let's start we're starting this how i accidentally created j diesel of data pipelines and it's awesome okay for those that don't know it's from the daily wtf a man named tom a genius you wouldn't understand he created j diesel j diesel is an experience in which every svn commit is a function and a class is a construction of a series of svn commits and for you to be able to build the entire system and has to walk the entire svn think checking out each one and constructing the javascript class from a series of commits so that my friends is j diesel and comments are executed as code which i'm not even sure how is possible but anyways let's keep on going i ended up creating a data pipeline tool which everything is programmed in jon becoming the j diesel of data processing and i promise it's actually quite awesome okay so i'm super skeptical of this but i'm so excited about this and short answer i ju i just felt like it let's go that is good good answer because why not it's a crazy challenge after all however the motivation for such a system was based on some work at at avato uh where i was an ml engineer was notice the keyword was okay presented j diesel was an engineer responsible for creating ml models that operated on a batch and streaming data however we hadn't implemented any robust tools for creating data pipelines and i was let's see i was the only one tasked with addressing this issue this might have been the point where i should have opted for a well-known data processing tool like spark or flink but i came but then came the challenge of training serving skew and ml this skew occurs when a ml model trained on one machine runs on another potentially using a different programming language this means data transformations needed to be replicated for example a training job might process data in squeal and python while production might use scala and python replicating complex mathematical functions can quickly lead to slightly different results rendering the ml model ineffective or essentially useless welcome to costco forgot to turn off alerts hey thank you you're welcome i appreciate that appreciate that uh data transformation is hard kids something something hasal perer function oh camel therefore i needed a way to ensure that transformations were aligned on every machine regardless of the programming language or version they were running on this sounds like a hard problem this sounds like a hard problem okay okay the crazy idea let's hear about let's hear about jade diesel here this is where my i had my crazy idea a as each line of data transformation can be represented with very little information for instance if we want to multiply the amount column by 10 we can represent a multiply column with constant value transformation and provide the column name amount and value 10 the same concept applies to adding two columns we just need to know which two columns to use or for something more advanced like generating and embedding we need to know which embedding model to use and for which column i'm not happy right now it's just at this point we just wrote an interpreter we just wrote an interpreter at this point this is just an interpreter and the bik codes of jaon in this way each transformation would be technically agnostic and therefore sharable across machines with this in mind i needed a way to describe these transformation this led to the use of jon meaning we actually program etl pipelines by defining jessan and suddenly we ended up with jay's diesel pipelines name is fale transformation key sex equals value string value female depending on name sex from here on i feel like there's an austin powers joke every time i see the word sex i always go yes in my head just due to stupid austin power what was that austin powers one in 1999 or something like that when was that every single time from here on from here i could load the file into python and run my transformations with my processing engine of choice not bad from aligned import file source transformations equal await okay what is this this javascript is a weight a python feature as well is there a weight in python what the hell is this what language is this is this asing python okay i was about to say i keep like i keep looking at it and my brain keeps going this is python then i look at and go no this is not python and then my brain thinks about i go no this is py and then i just can't like i can't seem to like catch which one i'm looking at okay trans okay okay okay okay uh polar says python that's what i thought so that's that's what gave it away fully that because you could actually convince me that this is javascript with underscores right like you could convince me that this is javascript with underscores and i guess there's no conet here that can't be doing global variables that should have got that should have got me should have got me um anyways all right so let's look at this uh this is nim sir this is nim uh all right so we got some transformations we have the input data we transform it uh feature view titanic uh oh damn that that sounds like it's going down json was a bit too crazy really really you you ain't telling me that programming actions for a programming to take in j doesn't sound like it wouldn't get out of hand how are errors handled however programming directly in json is not practical it would lead to many frustrating formatting errors there was no linting uh to check that the file was semantically correct and no code completion to indicate which parameters should be set why mean you could write your own lsp for this if you got really excited about it but i still wouldn't suggest it therefore i also set up a python api providing site stroke type safe transformations code completion and then compiles everything toes on file feature view one hot in code what is that what is what kind of function's called one hot and code i must not know python dog is this like normal python do you call it some hot and coding what kind of encoding are we talking about let's make me horned up one hot program hot encode in your areas can sex hammer can i find hot and codes in my area notice that we are not referencing columns using strings but rather using the fields themselves that's kind of cool okay okay okay um uh this uh leads to to both code completion and type safety as lters can catch errors yeah it was better than what i thought another let's see although the json file contains a lot of information it is still just a file so what real use could it have however after let's see after some time i realized that its value depended on the context in which it was used isn't that all value now the file has like i mean real talk isn't that all value uh now the file has become my most valuable asset as it powered all the functions below data validation l data linear graphs view data lineage data cataloges you're welcome for that for this mute debug specific uh feature transformation view data catalog continuing pipeline from cach states incremental data marginal materialization warning about data migration conflicts i don't i mean i understand literally all these words individually like all of them i understand individually and yet somehow none of it i understood uh that is the only data engineering features and let's see that that is only the data engineering features not taking in account the ml ops features but there's so much more having a file that contains all these transformations input features etc is a technology agnostic way to lead to an or which has led to an incredibly flexible system it has enabled me to move much faster than i pre previously thought possible i do think this is pretty cool that you build your files via python i thought that that that's pretty clever can we agree that that's probably pretty dang clever right here i like this i like this i i i do like that that's super cool i you know i i love this i i love that you took a chance you built something you w weren't sure of and it it met a business problem now generally i'm very skeptical of a json file describing how a program should execute in general it is great until it is horrifying right can we all agree to that if you haven't had enough experience in the world this has like been a road that i have traveled down many times in which always has the same ending great until it's one of the worst decisions i have ever made in my entire lifetime so right now it sounds like you're loving it which i think is great and i think there are probably a set of problems in which json does work i mean hell your vs code configuration is all driven via json so i mean it can happen there there can be you know how things should behave with json but i think it's very difficult i think it's jmal is very difficult language to use and so this is super cool i i love this idea it's not j diesel though i will say this is not j diesel because remember one of the key ingredients of j diesel is that j diesel requires history to construct the item now if you would have had each data transformation as a git commit and then a series of git commits hashes as how you execute the data pipeline then my friend then my friend you have created g j diesel no comments though jay gson yeah jay getson yeah exactly it json is not great for programmatic stuff because in the end programmatic stuff always needs you to have like hey i want to add one well now you have to program in this feature in json to say hey add one that's why there's that that shout out in the beginning this constant ad add two columns subtract two columns subtract with constant like it just keeps on you know what i mean there's there's quite a bit yeah do a loop throw an error how should errors be handled should you retry specific errors right there's like there's a lot of stuff you have to consider whenever doing it but i love subtract pre-at but i do i mean i i just super stoked that he that he built this and it's and it's working and it's going great that is super cool you know because sometimes sometimes a novel approach to a problem can make a really great outcome because remember all of the things you hear as like the the de facto standards and everything at one point was a novel approach react was a novel approach to front-end development and it's now considered the deao standard to front-end development you know you got to take a risk every now and then uh lua is better uh is a better dsl i think lua is the best dsl if you were to create a dsl or you needed a way to execute stuff dynamically or be able to download scripts and be able to execute them on the fly i highly recommend considering lua embedding it's not extreme difficult yeah it's very very cool the name it's the j diesel then jen look at that i'm the day we we had it this was the closest we've come to j diesel and i i appre i appreciate that now let's get it let's let's get it into subversion specifically tortois svn let's make this happen i think we got something going here okay you're 99% way there let's make it a hundo okay we can make this a 100 a jen