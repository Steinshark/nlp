look at this we got ourselves another safer the search for an easier safe systems programming language we got something even better i've been involved in the rust project in some form or another since 2016 and it's language i'm very comfortable using many rose programmers could say the same but if we take a step back and we're honest with ourselves we admit that the road to getting to that level of comfort was difficult yes yes it is i was talking with someone last night uh one of the maintainers one of the core maintainers of tokyo and i'm telling you i think once you get to a certain level of of rust knowledge it feels easy you just forget how hard it is you know what i mean you forget exactly how hard it is to get to that level it's it's a lot it's a lot of work uh this is a very great statement uh i taught russ professionally for two years watching the faces of people trying to learn russ for the first time remind me just how hard this language is to learn after two years of that i want to answer a question i wasn't really or entirely sure had an answer is it possible to make an easy to use easy to learn easy to teach safe systems language could i put my career working on programming languages typescript rust nelle etc to use and find an easy solution changing how we think of memory in rust we can think of each piece of memory as having its own lifetime each of these lifetimes must be tracked sometimes leading to rather complex code complex error messages andor complex mental mode models of what is happening the complexity of course comes with the benefit of being highly precise about each and every piece of memory and its reclamation using rust struct node data data data uh uh uh you got to have some lifetimes you technically don't need three lifetimes you could have just had one rust developers will spot right away that this is an incomplete example we need two more things lifetime parameters and lifetime annotations so adding those we got that the concept uh account for this example ends up being pretty substantial counting them off we get lifetimes lifetime annotations lifetime parameters ownership and borrowing generics so this is generally like my my thing that i hate the most about rust is lifetimes and the reason why i hate this isn't the fact that you have to specify lifetimes the the act of specifying a lifetime does not bother me what bothers me is that lifetimes are a part of the type which means that if you go from not using lifetimes to using lifetimes you now have to take every method that uses these and you start lifetim lifetimes leak everywhere the second you go from nothing to something everything has to have it all at once it gets so dang cumbersome to where with it's like jsa sync functions like it except for with jsa sync functions they're not nearly as as annoying yes it's like a red it's a red blue function except for the only difference is that you can color your functions now with async and you can color your functions with lifetimes so you get like two right you get two different ways you can color which i think is very very frustrating when it comes to rust or getting good at rust uh when i showed the examples like this to my class when i taught rust i had to walk them through each of those concepts first before i could show the full example the question then is can we make this easier well hopefully uh i believe they call that garbage collection uh what if memory was grouped oh are we talking about arenas here uh what if instead of having to track every piece of memory's lifetime specifically we let groups of related allocations share a lifetime effectively this would mean that a data structure like a linked list would have a pointer pointing to the head which has a lifetime and then every node in the list you can reach from that head has the same lifetime i would assume the drawback is that you can't collect memory until you collect the list and so theoretically i would assume that at least and if you just keep on adding and removing and you have a long running uh linked list it would cause effectively infinite memory growth am i wrong on that it doesn't sound complicated it just sounds it sounds problematic isn't that just gc no gc is different because when you when you have no more pointers left to uh gc it it goes away you know what i mean it actually just completely goes away it says as long as it's reachable oh did i miss that effectively this would mean that a data structure like a linked list would have pointers pointing to the head objects let's see and then every noe in the list you can reach from the head has the same lifetime oh so they keep track of okay so it's like an rc they're almost rcing it then isn't that just an rc uh there are some benefits to this approach as well as some drawbacks let's take look at the benefits i mean that sounds like an rc because if you remove a node from the list i guess i can clean it up if yeah yeah yeah i'm curious about it just sounds like an rc benefits of grouped allocations exploring uh grouped allocations we notice some inter uh immediate benefits the first is that we could treat all userdefined values as pointers and these pointers could represent their own lifetimes without needing lifetime parameters this makes the code feel a bit lighter node node okay nice the postfix uh nolly operator crazy but okay i like it none okay since all users data uh is pointer we can use the name of the type to mean pointer to this structure of data the next thing we notice is that both lifetimes and inference for lifetimes become significantly simpler let's take a variation of the example all right do this new node we can infer that the allocation that creates new node has a lifetime let's see and what it is because this allocation never escapes the function that is it never leaves the function to any way then it can uh then it can call its lifetime local it almost sounds like we're getting like oam cuz o camel o camel has uh lifetimes attached to functions not attached to uh type which is really interesting which allows for some really interesting stuff and a lot simpler as we as we'll find out each of these lifetime possibilities is a readable name that we can show the user in error messages it also makes this significantly easier to teach let's take uh let's look at another example all right so we have stats which is just a struct an employee which is okay which is uh which has a stats object set stats new stats okay we create an employee we create stats we set a new stats and then we grab a stats age uh this is a bit longer of an example but let's focus on this function setting a new stats okay what is the lifetime of new stats allocation in this example we see uh we do see the new pointer escape the function via a parameter we can also give the uh give this a readable lifetime param employee in all we have three lifetimes and an allocation can have local pram x and return okay i think i see this i i'm trying to understand this one so is it saying that this lifetime right here is that you have a you have a lifetime that's local to this function which has a lifetime that's to this parameter which has a lifetime to any sort of return and this is like an implicit return because it's being set on the parameter so it has the parameter lifetime which has the local lifetime of this function is that what it's saying yeah is that am i i think i'm getting that i think i'm getting that correct right it's everything's a pointer right so everything's it's not pass this is not passed by copy this is passed by pointer right pass by reference and so this is a pointer which means that this thing now lives to this this containing it's kind of interesting okay i think i'm following this this is pretty interesting this is actually a pretty interesting idea another big advantage of grouping our allocations that we no longer have to worry about drop order uh this means that we can think of the whole thing as dropping all at once for large structures this can speed up over languages that require drop order additionally we get another major benefit we can create arbitrary data structures yeah there you go so we have a circular link list and just like that we've made a circular link list creating a similar example in rust is certainly more of a challenge ah certainly certainly more of a challenge but something fish is going on here to make the above work we started uh we are using shared mutable pointers this is explicitly forbidden in rust why is that okay here okay okay okay okay this is exciting oh weird instead of doing let you do mute oh is that mean this thing's this thing has a lifetime of mutability so weird syntax that's a weird syntax all right rust disallows having holding two mutable referen to the same memory location for good reasons well multiple reasons actually first having to having two copies of a mutable pointer where two separate threads each can hold a copy means that the possibility for eras condition yes this can leave us with incoherent data that's difficult to debug second if we let's see if these two multiple pointers are limited to the same thread we get what we might call spooky action at a distance the modification of one pointer is then visible to the holder of the other pointer which might be far away from the source of mutation i'm less concerned about this one honestly like this one type one in the chat if you like or dislike that one one in the chat like i don't really care about that one honestly i don't care that a that i find that to be one of the things about russ that aren't like i don't consider like fantastic one good for a hacker it's fine i mean i just don't think it's a big deal i think people make it all ones yeah it's pretty bad you think it's pretty bad why is it pretty bad to have two things be able to mut mutate something no i was joking sorry oh okay is this my life now every single time someone says something i want to hear something interesting but instead it's like no there's no race conditions that's not a race condition that only exist when it crosses threads this race conditions only only exist on uh on separate threads having writable access which is completely different that's completely different i think this this one is fine right if you have shared shared multiple pointers in the same thread for us reasonable used shared multiple mutable pointers let's see for for us to reasonably use shared uh mutable pointers we need it to tame both of these the first issue the race condition is easy enough yes i think russ does a great job on this one you can't share between threads without like an arc mutex or something you just prevent yourself from accidentally shooting yourself in the foot uh mutable pointers between threads this limits them to a single thread yep the second uh issue is decidedly harder there have been many attempts at ways of handling this through rules enforced by the type system in june we were trying something a bit different we let developers use shared mutable pointers but then offer a carrot to opt in to restrict uh restrictions around around using them oh i like this oh i like this a lot that's great i would love to see more of this where it's um where there's more opt in to safety as opposed to enforced safety that's one thing that i think makes zig so interesting which is is that you can you can not have to deal with options if you don't want to deal with options you can use options but you don't have to i like that so you can do it but it's incentivized not to well it's not that it's incentivized or not incentivized it's you simply get to make the choice unsafe by default i think i think unsafe by default is better i mean it's the same principle behind cona ultimately right and we like cons we do like cons sharing mutable state across threads is the path to hell yeah this this i'm fine with like hey we don't we don't allow you to share a mutable state across threads i think that that's more fine you can share mutex as across threads i think that that is honestly more more fine the problem with a shared mutable pointers is when you hold on to a pointer to a ve element and then uh reallocate then you have essentially to uh a use after free no that's not it at all that's not it at all because you have this you have a vc and then you have a vc two and they both are stack pointers right they both have to have something that you can point to and that's i mean you just have to solve that problem i'm not exactly sure how to solve it but they need to both have pointers to the same locations you just have to pass this little thing by reference right whatever this thing that points to that the fat pointer has to be passed by reference right and that's that you don't have to worry about it whatever that is right i i'm not convinced that that's a big problem uh sometimes for data parallelism it's nice to have shared mutable data across threats this is also true sometimes you can just have shared mutable data across threads it's it's fine it's fine i know that you can't do everything and then i i obviously oversimplify that answer but you get the idea you don't have to have it all right in traditional encapsulation programers uh make a kind of best effort to hide implementation details from the world around them keeping private state private grants the benefit of better code reuse ease of updating implementation details and more but as often is the case if the kind of rule isn't enforced over time apis get designed where internal implementation details leak out there was that thing uh what is it harms her herens hein herens law which is internal details get leaked out of any sufficient old api as it is and people rely on very specific quirky behavior no matter what you do uh something uh very interesting happens if we don't allow this to happen if an encapsulation can be checked by the compiler then the compiler enforces that no private details leak we have what you might call full encapsulation these kind of encapsulator encapsulations wouldn't allow any aling of pointers into them they have their internal pointers fully isolated from the rest of the program once we have this the new capabilities start opening up we can fence off shared mutable pointers making it possible to create single owner uh encapsulation that can be sent safely between threads really i'm curious how that works we can keep uh we can we can lean uh people in the right direction of cleaner api design now that we have a truly let's see now that we have truly oh my goodness now that we have a way to truly keep private implement implementation details private we can handle some drawbacks of grouped allocations all right i i don't really understand this part i'm a little bit confused on this this this so-called super private allocation because i don't see how full allocation and privacy allows for you to send things between threads i i don't i don't quite get that uh i don't really know where that's going but it sounds interesting he's back at netflix i'm not at netflix ex to doubt like yeah that's where i'm at right interior mutability yes h okay let's see this uh if we go back to our earlier example and look carefully we'll notice something okay what is it the question is what what happened to the new uh stats allocation i assum it gets set to the employee remembering that uh that june is a let's see is a systems language we can't say the garbage collector handled it because we have no garbage collector nor can we say the ref count hit zero so we reclaimed it as we don't use ref count as a systems language we can't uh allow hidden or difficult to predict overhead to happen okay yeah so what did happen to this first one right here right notice that we change it what did happen to that one that was my question which is if you have all of your allocations up to the top one and you have a linked list that's growing and shrinking how do you not have memory go to infinity okay so we're actually at the problem in which i specifically stated earlier i'm very curious about that it's not actually leaked either as even the memory it occupied will be reclaimed once the entire group is reclaimed for all intent uh intents and purposes though let's see for all intents and purposes i'm not sure what that means though it's lost to the user until the group is no longer live it's a kind of memory bloat that happens if we group allocations yes this is what i was talking about to handle this we need uh we need this we need some way of recycling that memory i say recycling specifically because june we can free memory as the group is treated together as a single entity where the allocations in the group are freed at once if we instead recycle the memory we can reuse the same memory while the group is live interesting so it actually it keeps cached memory around so like you did a linked list allocation and actually will keep the memory around safe memory recycling that's crazy so you have to do some sort of zeroing that should be done by a library not the language why not isn't this just an arena with bump allocation it effectively is but on a per object level hm i i'm i'm in brazil i'm in brazil right now that's why i have a crappy mic is i just have a gorilla setup microphone that works good enough for this situation i'm streaming off linux which is not like a great experience so you know that's what's happening right now all right so this is interesting all right safe memory recycling uh using the idea of full encapsulation from earlier we can create a fenced in sets of pointers that we know aren't shared with the rest of the world once we have them it is let's see it's possible to track the pointers inside these pointers can get copy count so we know how many copies are live at any point in time not to similar to ref count though it let's see though it has no automatic reclamation okay so it's rc just without the reclamation okay once we have a copy count for each internal pointer we give the developers a built-in recycle command this actually seems super cool this actually i i i know this sounds odd but to me this sounds super cool this sounds like it effectively like memory pooling is like built into the language recycling would start at a given pointer and would uh check the pointers reachable from it each pointer uh it finds can uh can recycle would go to the safe free list you might wonder why not just do this automatically there's so uh there are a couple reasons the operation is linear time based on your transitively reached pointers this means you may incur a noticeable overhead when recycling because of the first pointer it's important to make places where this occurs visibly or make this occurs visible okay this kind of sounds like a manual garbage collection it does you're right my collaborator june or jane calls this semi-automatic memory reclamation my reading skills today are just terrible i'm not exactly sure why i didn't get enough sleep last night my dyslexia is going wild so sorry if if you're having a hard time following but okay this is such a cool idea that you can do garbage it's like it's like you have a garbage collector but the garbage collector is like on a per object basis all things cause performance overheads everything's a a performance overhead the problem isn't any of this right it's like an rc except for you get to call recycle on it i think we we are the garbage cors i knew it i was right all along you're blonde that mustache is fake too yes it is i thought the the gc was automatic by the language itself so this isn't this one you effectively that's what i'm hearing you kind of say when it needs to do the reclamation on a per object level basis which is very interesting you ask once and when you ask you get a kind of highly focused mark and sweep for that single pointer see that's super cool a highly focused mark and sweep this is very interesting uh this feature is not yet in the reference compiler we're hoping to implement it in the coming weeks more work ahead this is actually super cool we have uh we have a way of simplifying lifetimes making the readable code that people from various languages should be able to understand and use and we can give a clear easy to understand lifetime errors when they arise i like this i actually really think this is i think this is a i've been a language that is that is like rust and go together this feels like this actually feels like the the a true rust and go baby right here this feels great having safe uh memory recycling gives us a way to keep groups and still offer things like delete in a linked list abstraction it's convenient but not so automatic that we lose the visibility into the cost of memory management that said there are still some challenges ahead that will need to uh uh to be solved in the language design and tooling for example how do you know when a program is bloating memory we'll need some way of doing memory when the program is running to detect this and warn the developer yeah that's cool that that makes sense you'd need ways to kind of show i guess you could i mean if you have a bunch of zero zero counted references but you have all these memories because they haven't been recycled that would be i assume like you can kind of show like you're growing a bunch without ever recycling it's interesting i see this as a more incremental prototyp friendly way of development i agree this is super cool i think this is great i think this is fant fantastic i actually really like this yeah i like all of this this is this is really good relationship to rust june has a real opportunity to be a good compliment to rust rust focus on embedded and systems development is its core strength i don't think rust on embedded is a core strength i think rust with embedded is kind of interesting or extremely difficult or kind of incorrect i think zig is the better language for embedded but for systems level i think it makes sense but i'm still not convinced i i always go back and forth on this is rust even the right abstraction have we over have we overshot the rust the rust abstraction all right i got to be right back i got to pee i got to pee too much coffee and water all right what made it what made you change a mind on rust uh yeah it's just that i i recognize the pain with rust and i recognize that it's an extremely hard sell uh just because there's a lot of people who just don't want to put up with it simple as that there's plenty of people that just they don't want that they would rather take the sometimes things that go wrong with programming as opposed to the on always safe mechanisms at all points right it's just a trade-off and people don't want to do that yeah go is so much better for most use cases this is true this is why this people feel this way very very much did you wash your hands hell yeah brother girl i actually watch i wash the wang too got it right in the sink you know what i mean i think some people just they just don't want to have to deal with that and that's okay i think that that is perfectly reasonable it takes a special kind of person that really really loves rust that just really really loves that experience but the thing is is that most people just aren't going to really like that i like russ specifically because it is so strict yeah exactly and some people just really love that experience some people really love the type system of rust and that's what i fell in love with was the type system of rust the borrow checking and lifetime annotation i didn't actually ever fall in love with that i found that be largely inconvenient whereas i found the other side to be really nice and so i think that that's kind of what happens is that people have two types that they fall under and i think most people love the type system more than the other side that's my guess but real talk i think this is actually super super cool let's look at this thing for a little second i want i wanted to look at this uh op has for decades been the way many applications are written it's not without its flaws and many op languages allow programmers to freely break rules of thumb like the liskov substitution principle or to create a mess with interwoven code between parent and child classes that's difficult to main m we're currently investigating other ways of making code reuse easier more modular and more composable we're not quite ready to talk about this though we hope to soon okay well i really hope i mean my one thing i really hope is that they use this notions of trait objects and trait extensions being able to take like to take an iterator and add new methods to it so you can have your iterators right i think that that is super cool and i really hope that that is in this language cuz i think that that is one of the best things again the type system of rust super incredible it's that's the reason why i like rust is purely because of that man it's so good anyways there you go that's how i feel the name is the primen