this was an amazing talk with casey moratory we went deep into how the cpu works he even got out his whiteboard and he was writing things down it was absolutely incredible so please enjoy this thing what is this thing i don't know what you call this thing but it was amazing that's what it was so today we're going to be going over why x86 needs to die and i'm going to be joined with uh joined by casey mortor casey can you tell us a little bit about you uh sure uh i'm i'm fairly ancient probably relative to most of the people on the stream uh i've been programming since uh professionally programming since 1995 uh and i've been in the game industry for basically all of that why are we freezing why the original thing we're going to talk about was the m2 exploit then this yx city6 needs to die is also kind of something i wanted to talk about oh hold on my friend um we had a start okay so this is the second time this has happened while using ping so i'm not sure if this is a ping problem or what um so i want you to try this one more time if you freeze again we got to move over to discord but effective just said i've been programming for 1995 or since 1996 and i've been in the games industry and then you pretty much froze at that point just saying i've been in the game industry based with that whole time and uh i'm actually currently doing a programming sort of uh a performance programming course on substack that i do and that's why this sort of stuff like x86 architecture microarchitecture things was something that i wanted to talk about i also want to talk about the m2 exploit like i said but uh you weren't around for that one because i think that was also a pretty interesting one as well uh in the news recently uh but this one was also kind of making the rounds yeah this one was big enough that i saw a counter article that was like y x86 doesn't need to die and often you don't see like article en counter articles on the internet that's that means this thing had to reach a pretty high you know it it must have ruffled enough feathers to get people this excited uh yeah it was i i'm assuming you're referring to the one on chips and cheese i think so yeah i just got linked it today uh chips and cheese is actually great uh if for folks who don't know chips and cheese it's a really cool blog where they basically post like microarchitecture analysis stuff where they'll go over like okay you know you want to know about qualcomm snapdragon well here's like what we've sort of been reverse engineering or what they've said in their slides or whatever about how the architecture works and this and that so for people who are interested in like how the hardware works it's a really great blog and they did a complete response to this shortly after it was out and it's good uh i would highly encourage people to read it um i realize that that these days reading is not a thing that people do as much but if you do read that's why read that's why i literally read fulltime on the internet for people you're their reader i am their reader i am their screen reader and i also have dyslexia which means that sometimes i'll start reading and then i just have to like stop and just take a moment cuz i fall apart and i'm like okay guys i can't read for like 3 minutes i need just like to breathe out for a second well that's even more embarrassing for them it's like he's doing your reading for you and it's harder for him than it would be for you and you're not even doing your reading like what is your excuse you don't have one right you don't have one well there are excuses that i do in forum i guess that's your excuses well i don't know it already is there some dyslexic guy on the internet reads it for me so i don't bother what's my why would i bother yeah come on it's the day and age of productivity casey okay all right so i'm just going to start reading through this and then you can kind of like kind of take some bits and pieces and say okay let's talk about this because the reality is is that i i mean i program in lua and go sometimes in rust like i'm not a uh i i would not put myself as any form of expert in in any of these discussions i am i have no delusions of grandeur so this is just not my area so it's good to have you on here that you can kind of talk about what's going on in any of the any of the places that i'm missing uh absolutely and also i don't know if you uh if it's too long to do i don't know if you've got sections you want to read or what uh i don't know how you do stuff on here because so i'll it looks really small it's just a bunch of comments mostly like this is i mean this is like pretty typical reading here it's probably like what two pages go all right as i'm sure many of you know x86 architecture has been around for quite some time it has its roots in intel's early 8086 processor the first in its family indeed even the original 886 inherits a small amount of architectural structure from intel's 8-bit predecessors dating all the way back to the 8008 but the 886 evolved into the'6 the 286 386 486 and then got and then they got names pentium which would have have been the 586 oh man oh i i didn't even know that okay well hey guess what's kind of exciting about this yeah uh this is the so far i don't think anyone would have any problem with the article all of that's true and for those of you in the chat if there's any folks who ever read assembly language this is actually the reason that the register names on x64 these days are so weird if you look at the register names uh if you know what that sort of stuff is in uh x64 right because cpus they have these register names which is how the lowlevel part you know how it works xa or something eax that kind of stuff yeah so if you ever wonder where that comes from it's because of this lineage so the register names for the uh the second eight general purpose registers the x64 makes sense they're r8 r9 r10 r1 r12 r13 r14 r15 makes perfect sense that's what a programmer would do right why aren't the first ones r0 r1 r2 r3 r4 right well the reason is because the original uh 80 uh the original 8000 the the original 8,000 series they started out with four registers a b c and d that's why it's aex is it's a extended yes it would went from a to ax to eax to rax when they went from 8 to 16 to 32 to 64 bit so all of those first eight registers the abc uh d ones and then the like source pointer des pointer there's there's a sp uh si etc so that's where this comes from anyway oh no that's that's actually super interesting okay so that's why so if you're on an 8bit one it would have been a if you're on 16 you're on ax and then if you're on 32 you're on aex being like oh we've really we're like we're the vi we're the extensions of this all we're the viagra of this all and then it's like oh no we're on 64 so they're like rax right is that what they did just kept on going yes it was it was a a goes to ax which has two parts a and ah for low and high for the high low right then ax went to eax which you could still address the other one so if you typed ax you still got the bottom 16 bits but if you got eax you got all 32 and you got the bottom 16 bits which would be in the most significant bit position because it's little indian other way around so on little indian the bottom bits are the least significant that the first the ones that you see on the on the right side of the number sorry the the front the front 16 the first 16 bits if you had 32 bits the the most significant set of bits are actually the least significant values right yeah i i guess i don't know how you want to describe it but the i i'm very bad at describing indians okay here we go in my head so if you you had a you had a uh a l and ah is that what it was because this would be little indian on this side right is that what it was trying to be written traditionally we would flip them because the least significant ones are on the right side and the most so so the h would be the you'd switch a an ah in that diagram okay yes but this but is that how it is sorry i we're super digressing but let's just keep going because i find this really interesting because network order would be this right you have your most significant bits on this side your least significant bits on this side but in intel land this is over here and this is over here right in memory order yes yes but when you write like a register out right you extend it to the 32 bits so we write it the other way but yes in memory order it would be al a exactly the way you draw it the first time which is why ian flips them right little endian you have to draw two diagrams one for the register one for memory uh bigan is the same diagram yes i i i live in big indian but i've been bitten by little indian many of times in my life everything is little indian now on the hardware side but because a lot of stuff came from big edian architectures like you said network order right uh it's flipped around on the wire so i only know things as network order and so it's it's because i you know i don't go to i don't go to the machine level so everything is network order in my brain and so it's always just super difficult to map around yep they just wanted to make it hard for you i talked to an intel guy once and he his argument was that uh we just drew our stacks from the top down and so it made more sense going this way and where other companies drew their stacks from the bottom up and that was his argument for why little indian existed he was some guy with like 20 patents and i was interviewing back there like 15 years ago and any there's a better argument if you want to hear it yeah i do actually want to hear this uh suppose that you have the address of something in memory yeah so you're like just this this particular bite position yeah in little indian that address will stay the same no matter how big the value was if it was eight bits it's that address if it's 16 bits it's that address if it's you know etc etc in big indian you're supposed to be pointing to the most significant thing so if you make the value larger right the thing goes in the other the thing grows in the other direction so if you wanted to change from going from a high one to a low one you'd have to move the pointer i think i'm too stupid to understand that but i trust you i trust you at this point all right all right along the way new instructions were added but the core of the x86 instruction set was retained and a lot of the effort was spent making the same instructions faster and faster this has become so extreme that even though the e or the 886 and modern zeon processors can both run a command common subset of code the two cpus architecturally look about as far apart as they could possibly as they could possibly felt like there should be another word there so here we are today and even the highest end x86 cpu still support the archaic 8086 real mode where the cpu can address memory directly without any redirection having this level of backwards compatibility can cause problems especially with respect to multitasking and memory protection but it was a feature of the previous chips so it's a feature of the current x86 design and there's more so i' jump in there and say i just don't really know what this person is talking about here um since i can't quite tell what they're trying to argue i'm i don't want to argue against it too stringently but what i would point out is uh there's some weirdness there so it's true that x86 cpus support 886 real mode uh and what this means is so if you imagine back in the day uh all home computers pretty much and of course the ibm pc as well and so on none of those computers even had what we would traditionally refer to nowadays as a memory management unit or memory management features the idea that you have sort of virtual address spaces for processes and those address spaces don't necessarily directly mapped to physical ram and so that you can do things like swap processes in and out or check to see if a particular process should read some certain memory in the old days it was just like okay all processes if there even are multiple processes on this thing which you know isn't necessarily even something that was supported depending on what period you're talking about they they can just read memory it's like i read memory i get that physical set of bits back um so what it seems like the person saying is like oh well they still support this mode and that seems like a really big burden or something but i don't know any hardware company that's ever thought this was a big deal it's just some stuff that's stuck over in micro code that you only ever hit if you need it and direct physical addressing to to ram there you don't have to do anything additional really for that like if you wanted to complain about this you might complain about having to have more segment registers or something there are some things you could pick to complain but the fact that they chose that makes me i'm worrying that this person doesn't really know what they're talking about because it doesn't make sense for example suppose you were just like oh i got to emulate direct memory addressing on this machine that has indirect memory addressing well just fill the indirect tables with direct addresses done like like what the pro like you didn't have to add hardware to do that it's the other way around you have to add hardware for ind direction you have to add hardware for for direct so it just it sounds weird off the bat that like that was their lead in anyway okay yeah and i think that so for me me being more of a layman i think the reason why this is a good argument is that me i'm like oh man it's there's a lot of legacy and backwards you know backwards compatibility i know about software and backwards compatibility makes things worse right like generally as a programmer it makes everything worse in fact that was one of the big arguments why like if you remember the bun and node performance fiasco uh one of the big arguments was that node has to support all these things whereas bun comes in and just says i don't support any of that crap i just do i do what's the current thing that's what i support and so they were just they you know they claimed that as part of the reason why they were faster imag that's how like me as a layman reads this is like oh it could be better if they just didn't support uh backwards compatibility hardware wi guys imagine something slightly different imagine that someone just reimplemented nodejs on top of bun so anytime they could just call the fast versions they did and anytime they couldn't they run some slow emulation and then they just give you both of those things that's more what x64 is it's like look we've got the fast thing and then we've also got this 886 real mode that's super slow but that's okay because you're only going to run applications from like 1997 on it anyway so who cares right i it's not it's earlier than that like 199 right or something i don't know what the earliest time you would still be using real mode is probably even the 80s really so you know it's really not like that it's not like oh it's the nodejs legacy runtime so okay okay i think it's time to put a lot of the legacy of the 886 to rest and let the modern processors run free all right some key terms to understand my next arguments you need to understand the very basics of a few concepts modern x86 is to use the proper terminology a cisk super scalar out of order von newman architecture with speculative execution what does that all mean well i do know that von newman plays a critical role in three body problem so must be an important fow you know i know that much uh he invents the von numan architecture have you read uh three body problem i have not read the three body problem but as far as i am aware kind of in the like uh secondary like the the feels sense of things yeah uh v noyman is like widely considered to be sort of like the greatest soft like computer science person and very multiple other things of all time he's just everyone thought the guy was like kind of just next level right he probably is from the future trying to describe to us things that things that will happen there is a famous biography of him called the man from the future lit did you know that no i did not know that uh whenever someone's so far ahead of things sometimes you're just like am i like witnessing a glitch here uh but uh okay so if you haven't read a three body problem uh there's this you probably actually really enjoyed midway through the book uh they describe this thing where they actually take people and each person holds a flag and they actually create a computer and horses are the bus speed and they bust instructions they have uh people that hold flags in one position they're like cold storage and they have like this whole like thing where they do you know like they do it all it's super super cool and then you know and then they're all soldiers and if any soldier messed up they'd get killed like it was really really cool and they actually process the three body problem and then determine the future it's pretty cool it's it's it's super super cool uh anyways the von newman architectures are cpus where both program and data exist in the same address space this is basic basic ability to run programs from the same memory in which regular data is stored there is no logical distinction between program and data memory is this like a lisp argument did von newman accidentally make lisp arguments uh that's a super nerdy joke sorry about that super scaler cpu cores are capable of running more than one instruction per clock cycle this means that an x86 cpu running at 3 gws is actually running more than 3 billion instructions per second on average this goes hand inand with the outof order nature of modern x86 the cpu can simply run an instructions in different order than they are presented if doing so would be faster can you give me like a brief this sounds like this sounds like where the m1 or the m2 bug is can you can you give us like a brief understanding of what this what they're trying to say here i i can um so again another paragraph that makes me nervous about like the way this guy is explaining things uh just it it scares me a little right uh that kind of sounds a little bit like a word salad to me uh where they didn't quite get what they're talking about so they may be trying to write it for people like me the technical person that's not technical at this level i don't know because i feel like that explanation is only going to confuse you more right you came into speculative fetching i don't know i have no idea so um i mean do you want me to draw a diagram i don't know how how hardcore we should get here i i can if we want to i'm not sure how about you start with the you start with your own word salad and if we need the meat we'll get the board out here's my word here's my word salad so a modern cpu you can think of as there is a language and this is really important to understand why i think this article is probably not very accurate or isn't a good representation of if if x86 dis does need to die this is not a very good argument that they're presenting can i ar can i can i break you for one second everyone wants to see uh the the whiteboard if you can change your camera if you have obs set up and you want to go full screen here i i am i am willing to get like you're full screen right now if you want to swap over to your desktop we can make it happen we have an actual white p we're going so you're gonna have to tell me can you hear me from here yes yes we can that is fantastic okay can you see me drawing oh my goodness yes we can let me turn off let me turn off that there we go let's go let's go so when you take a program doesn't matter what it is anything you're programming in you said like you're like i program in i program in this or whatever whatever that is at the end of the day everything gets sent down to the cpu as machine code and that machine code is fairly simple it's basically something that can be described as like some bits that tell you what it's supposed to do in very simple terms so like a really simple thing would be like an ad there's going to be a bit pattern that says add right yeah then there's going to be some information that's what are the operands and there's either like one two or three rarely four even three is somewhat rare so you'd have something like ad one of those registers we're talking about which is like a name you know something like rax like you said and then maybe another register or possibly even what we call an immediate which is some values right all of these are bit encoded they're all encoded as bits in machine code in the memory of the computer and the processor is fetching those bit codes right yes and so just to clarify this is one of the first big revolutions which was going from machine code to some sort of name for each one of these machine codes so i don't have to know what rax is i can name it something that i can remember as a human yes and so the assembly language was the first step of that it's a little bit easier than toggling in actual binary codes which they used to do right yeah and then then from there there were people like grace hopper was famous for this for example who advocated for like they should be more human readable and that's sort of why we got to where we are today where it's people were like let's stop having to actually put in every single instruction let's try to say things that are closer to what we mean and build up higher level primitives right and so nowadays we don't think about this as much but this is what's actually happening in the computer no computer can execute lua it's executing instructions that are made to do what the lua told you to do right yeah so just to be clear about what happens and where this uh information kind of in the article feels a little off when they described it in that that sentence they used a bunch of words there super scaler etc etc those all sound like aming like science fiction terms for me i don't understand it we can talk about what those are if we want to in a little bit let me just tell you what actually happens so what actually happens is the instruction that's going to happen it gets decoded from that like when the cpu is is reading these instructions it gets decoded that bit pattern turns into something we call micro ops so basically this ad that you are sending down as like i want to do this it doesn't necessarily translate to just one thing the machine does this is something that the the i i don't know if the article ever addresses but so an instruction that you encode actually can become mic multiple what we call micro ops and those micro ops are the actual things that the cpu can do so for example let's suppose that this ad in x86 and x64 you can do this had a memory address there was some memory address here that it was going to fetch and what this ad was going to encode is fetch this memory address like go out get this from a cach or from memory right get this address add it to rax and write it back to rax that's what this thing is doing right and i to spare your viewers hours of content here i won't explain what this means like we won't go into what registers are necessarily right but um if it wants to do that it's got multiple things it has to do for at a minimum it's got go fetch this memory and then it's got to perform an ad so that might become multiple micro ops like one of the micro ops might be to fetch something for memory another one might be to do the ad the actual addition so a single instruction doesn't mean i'm just going to do this this one thing it actually means potentially do multiple things does that make sense so far yeah that makes perfect sense because whenever you have to it's i mean it's just like if you're programming if if some expression do this like you know that there's actually a go-to in there there's going to be a jump if it's not like there's a lot of things that happen when we write so this is not this is completely reasonable that we just continue to abstract and make more concise things yes and people think oh well this makes x86 like this just to forecast some of the arguments they're like well that's ridiculous okay you're already breaking things out into smaller pieces obviously x86 is stupid because why didn't it just encode the little pieces this was true from the very first x86 the very first x86 had micro ops this isn't new they didn't accidentally screw this up that's been true forever and also not only was that true forever but all modern processors do this even things like arm have exactly this thing si risk things people call risk they all have internal ops they do and instructions that are more complicated than those ops potentially not always right like sometimes they map one to one other times they take more the reason for that and again i'm kind of jumping ahead here but it's just coming up as we're talking about it the reason for this makes perfect sense what are you trying to do with this program you're trying to as compactly as possible to take the least am amount of memory and the least about of amount of bus bandwidth and cash space to transfer that memory into the cpu and use it you're trying to represent your intentions as compactly as possible so this is not and never was supposed to be a one-o-one mapping between what is in the instruction set and what goes on in the computer it's supposed to be the most compact representation we could think of for that and that is where this article gets yeah that's where this article i think really falls apart is that it's not supposed to map one to one and even risk people don't think that anymore that's not how they're going to implement a chip so there are some things we can talk about we'll talk about those maybe towards the end about why there are x86 things that maybe aren't great that it would be nice if we fixed but i feel like the article proceeds from the incorrect premise anyway now just to finish up what we why we came to the board they said a bunch of other things super scaler out of order etc well if you think about how these things actually end up happening in uh the the cpu one of the things they mentioned was pipelining and pipelining is when you want to start doing these micro ops i mean we've already had pip pipelining even before then because the act of turning this into micro ops so getting it decoding it turning it into which micro ops are supposed to happen all of that happens in stages because they're trying to crank the clock rate really high they want to run these things at really high clock rates and there's a limit to how much they can do inside one of those clocks right yeah so they're trying to crank that clock really high and so what they do is they overlap they take and they say well if we had to do an ad instruction in one clock cycle it we'd have to clock this machine pretty low so instead what we're going to do is we're going to overlap the stages of fetching it decod coding it turning it into those you know micro ops executing doing the ad on the micro ops getting the values writing them back we do each of those in stages so instead of one clock cycle it maybe takes a total of n clock cycles where i don't actually know the total pipeline depth maybe 14 clock cycles or something like that to do an instruction even though it appears to the user that it only takes one why because they're pipeline so let's say this is 14 cycles worth of length i start my ad and it has to go through 14 cycles to complete let's say right yeah well when it goes in on clock cycle one right here it starts it starts being fetched or decoded or whatever it goes to the next clock cycle it starts the next piece of work it has to do on the ad when it moves out of that first bucket another ad can be put in so the ads are moving through this long pipeline all together so if i put one ad in every clock cycle i'll get one ad out every clock cycle so it appears to the user of the machine that it only takes one cycle to do an ad even though it took many cycles to do one of those particular ads does that make sense this makes a lot of sense so this is just a way because we've hit an upper limit on how we can effectively shove things through so we have to just get more clever so if we can have a wider highway if you will we can get more cars through that is that a very layman way to say it the most layman way i could think of it is uh i' i've said this before your washer and dryer if any of you have a washer and dryer at home that like washes and dries clothes i i yeah well we have a washer and then a dryer we have several of them okay think of it this way if you didn't have a washer and dryer suppose you just had a unit that washed and dried clothes right a washer dryer you have a wd right mass washing it took two hours to do a load of laundry right takes two hours takes two hours to do a load of laundry washes and dries it for you now i have a washer and a dryer two separate ones like you have takes one hour to wash one hour to dry right which one of these is faster at doing laundry well naively you might say it doesn't matter uh like i put it in the washer dryer it takes two hours i put it in the washer wait an hour put it in the dryer 1 hour same time two hours right mhm wrong if i use the washer dryer i put a load into the wash at 1 hour after that hour is up i put it into the dryer how long did that load take 2 hours but while that load was in the dryer and you know this intuitively because i know you've done this you put a second load into the washer yeah so to do two loads of laundry it won't take four hours it'll take three right we all know this intuitively why pipelining that's pipelining okay pipelining is you break up the stages of the work into smaller chunks because once the first chunk is done you can start a new load going in okay this makes perfect sense that's what this diagram is so that's pipeline okay okay pipelining or the other two out of order out of order just means well we take all these micro ops and we look at which ones we can do at any given time we don't do them in order if they don't depend on each other that's all out of order means so the processor looks at a bunch at a time and finally super scaler just means it's trying to execute more than one of these at a time okay if it can that's it very fancy terms this makes a lot of sense all right should i say i guess i stay up here but i come back you can sit down you can sit down you can do whatever you want i can make you small again um if you can make it so that you can kind of go in and out easily you may want to do that okay all right it's just right behind me now yeah that's that's okay i think i think people are just fine with the bright because uh cuz that was awesome and everyone's very happy about that everyone feels like they just got smarter none of us are actually smarter in chat we just feel we all feel like we got smarter you don't give yourself enough credit prime i don't know about that uh you you don't worry you got enough credit okay you got the street cred we'll give that to you um all right this was awesome okay so let's keep on going let me let me pull this back up really quickly there we go all right uh finally there's a speculative keyword causing all this trouble speculative execution is to run instructions in a branching path despite it not being clear whether set instruction should be run in the first place think of it as running the code in an if statement before knowing whether the condition for said if statement is true and reverting the state of the world if the condition turns out to be false this is inherently risky territory because of side channel attacks so this is like the fundamental uh thing that that is how uh the m2 attack worked right you'd speculatively load some bits of your crypto stuff and with enough xoring you could kind of eventually steal someone's private keys right um it's it's actually more closely what he's describing here is it's um more like spectre and meltdown the m2 bug is actually part of the prefetcher which is a memory act up we're losing you again hold on we lost you again dang it we lost you again hold on hold on i feel like i know if i if i leave you up if i it seems like if i leave you running and i have your video on and i actually keep it in pin on then you run better so i i almost feel like i have to keep you running in both places it might be yeah there might be some sort of optimization some would say going on yeah or prioritization of in the browser or something right like where it's yeah this is technically an embedded browser right now i'm watching on it just seems like whatever's happening if you're not on there it breaks down elsewhere well uh all i was saying is that it uh just to distinguish between the two spectre and meltdown are are were more more about speculative execution paths like if statements the m2 bug it doesn't have anything to do with an if statement that one's just in the memory prefetcher so that was why it was so novel is because it's like doesn't actually matter whether you have speculative whether you have branches branch free code will still be hit by the m2 okay you can talk about that sometime too if you want but yes okay because that's what they were talking about with that constant time programming or whatever it is is it y is that what this is and all the fetching and all that i understood the exor part and that's about it so okay got xor is really cool the fact that it has memory is mind-blowing all right what is x86 really here you can see a block diagram of the microarchitectures of two seemingly completely unrelated cpus don't let the looks deceive you the zen 4 cpu still supports real mode it can still run 8086 programs the 8086 is much simpler cpu it takes multiple clock cycles to run instructions there's an x-ray there uh anywhere from 2 to over 80 one cycle is required per bite of instruction and one or more cycles for the calculations there is also no concept of super scaler or out of order here everything takes a predetermined amount of time and happens strictly in order okay so these must be the two different ones this is the old one going on right here i don't really i mean i'm not really sure what i'm looking at going on here but okay this is probably not easy to look at i think they cut and pasted from the 886 manual uh that diagram from the 886 manual yeah yeah there's just some arrows and it looks like there's probably text here let me turn off uh let me turn off it might help me to turn off dark readers for a second well the bottom those are just it's just there's the segment registers in the upper left there's the reg the bottom right there's the prefetch uh okay sorry uh yeah there's there's a probably a prefetch queue i think in the i can't actually see but it doesn't that diagram is useless it's it's a useless diagram i don't know why it's on there okay i have no idea what's happening here and this also i have no idea what's like this just says a lot of stuff sk the bottom right again this is just why i don't understand why like i i get nervous about whoever wrote this article the upper left is not a diagram that actually shows the execution method of the 8086 it's not the same as the diagram in the lower right which is showing basically like how the execution the front end and the back end fr front end on the top back end on the bottom for the zen 4 so it's like again like highly questionable article but continue okay okay by contrast zen4 is a monster not only does it have all four alus it has three agus as well agu what's that address generation unit so it's basically a thing that is um how should i put this so when you need to access memory uh the you need to be able to figure out where you're getting the memory from and that typically is a like there's a thing called an effective address calculation where it's basically like take this pointer and add this much to it and then figure out where that actually is in you know in memory and so on that so the number of agus you have determines how many memory fetches you could issue per cycle right okay so if you have three agus you could fetch you could do three reads in one cycle you could issue them they don't ne complete but you can issue them okay yes all right some some of you may have heard of the arithm arithmetic and logic unit before but address generation unit is less welln i should have just let them tell me all of this means that zen4 can under perfect conditions perform 4 alu operations and three load/store operations per clock cycle this makes zen4 a factor of two to 10 times faster than the 8086 at the same clock speed if you factor in clock speed 2 it becomes closer to roughly 5 to seven orders of magnitude despite that the zen4 cpu still support the original 8086 instructions so told me yeah so how i read this is from what you've told me this doesn't this argument doesn't have to do with this argument you are 100% correct yes so just so to put this in perspective right there are so many things missing from this alu doesn't really mean anything it's just a way of saying there's a part of the chip that can do some computations yeah it can add and such but we don't even know which such so when we say alu we mean ah it's this part of the thing over here that can do a certain set of operations on modern cpus there's a list of which operations it can do it's like this particular one can do a multiply an integer multiply this other one can't it can only do an exor or whatever right oh so they actually do alus that are uh hyper optimized for specific operations yeah actually uh do you want to see uh so i can i can show you i i don't know how far in the weeds you want to get here prime but if i if i drive you towards a website for a second can you open up a tab and go to a place called uops doino uops doino this ain't porn right oh it's wicked porn it's porn for for for microarchitecture people and click on the thing that says table on the on the button bar and then open table uh just click on table an open table i already did now open table all right yeah um so if you type something in for for example add just type in add to the search box in the left corner right what you will see is a list of all the permutations the ways that ad can be so for example if you look at ad there'll be an ad uh like r32 or something or r64 what those sorts things that'd be like 64-bit register to another like add r32 r32 would be like add a 32bit register to another 30 bit register that one you got your pointer on just a minute ago add r32 to m32 that 3it mation memory like once you learn to read this you can just know what these things are they're not like cryptic or anything it's like oh okay i get it right yeah yeah over in the column that says ports you see that let just make sure let's see which one's ports it's the ports way over here on this side yep yeah it's one says like one times p blah blah blah yes yes so the p and then the bunch of numbers p 0156 yeah the 0156 those are which numerical alus in the system can do that operation so they're basically saying okay if you want to do like for example you have your mouse uh mouse over one now at m64 plus an i8 which means 64-bit memory location added to an 8 bit immediate value so i want to take this address and i want to add this number between 0 and 255 to it right yeah but that string of gobble gs says is we're going to do one micro op on one of those ports 0 one five or six one micro op on the next port which is two or three one micro op on four or nine and one micro op on seven or eight so what that's telling you is which of the quote unquote alus ports is a more generic term that could include also the agu so the address generation unit part the two different kinds it's telling you which of those can handle each of the micro ops generated from this instruction so like i said instructions generate multiple micro ops those micro ops can only execute on certain ports quote unquote which is some kind of unit in the processor and these are them so if you can't just say alu now let me show you why the ad that's doing a pure register to memory uh register to uh register or register to uh value so you look at add r16 to i6 just below you there that's adding a 16bit register to a 16bit immediate it just says it can be on port 01 five or six and it's one micro op so just one thing any of those four ports can do it so that means right i'm sorry i'm going through this stuff so fast can i can i interrupt you for a quick second just so i can kind of speak from like my my experience here so what that says to me is that each one of these operations is effectively operating over a 16bit range because if you have a 64 and a 64 you have four operations right that'd be 64 bits so it'd be four * 16 that's why this thing can operate in a single place and 0156 these must operate in a specific specific memory bucket range uh no so uh you know what i'm going to just pop back to the board real quick okay sorry this is very interesting but i you know this is again way out of my depth but that's kind of how i read it i could see that these things each are operating on 16 bits but i don't quite understand i'm sorry i'm going so fast uh i just don't want to i don't know how much time you've got so just that's all we'll do we could do one more board time i think everybody enjoys board time so no one's going to be upset at you for doing board time okay okay um so you'll just have to forgive me not knowing what's happening no no one knows this stuff it's it's like it's it's uh it's just not known these days right so that's not you that's everybody uh so one of the reasons that i teach this stuff or try to is because it's like good to know because it's like demystifying it's like oh i i get it like i know how the computer actually does this stuff now right so those micro ops like i said there was like an ad or something like that and let's take the the case that we were looking at before where it said the ad was port like what was 1056 or something like that yep one z56 b what that means what that's telling you is there's only one of them in that list right you there was others that had plus dot dot dot dot each thing separated by a plus is a micro op so okay if there were four of them it just needed it meant it needed four micro ops so there were four things the cpu would have to do this ad the one that i think we were r16 i6 that was what we said yep that means that means a 16 bit register plus an a 16bit immediate that would be something of the form add um ax we talked about that before so a 16bit register y and then a 16bit value like 1,25 let's say right six you can encode that in 16bits this is a 16bit register that could be an ad r16 i16 it only needs one micro op it can go on any of these four ports what does that mean well micro ops all pile into a thing that's a and there can be multiple of these on a chip but they pound a thing called a schedule and the has all of those things we were talking about alus and agus different ports that we call them p for port that can do stuff this is telling you that ports z one five and six all have an ad unit on them a integer ad unit so 0 one two 3 four five and six all of these have ad units these two three and four do not so when the computer is trying to execute your ad instruction it has on any given cycle four places it can put it which means it can do up to four ads per cycle because if it had four of those to do it has four things that can do it if you want to do a fifth ad on that cycle you can't the fifth ad stalls waiting for the other four because they have to go in here first then on the next cycle once those ads are moving through it can put it in one of those port reports does that make more sense yeah so micro ops pour into the schuler they sit there they wait this is the out of order part right they wait until there's available execution resources to execute them and their dependencies have been satisfied like you' imagine if this register was still getting produced by some other instruction it would have to wait till it was finished they all pile in here then they all execute out uh when you know when there's ports available for them to be executed i assume the schuler is just literally just a series of x amount of cues where each instruction can fall into these cues and it hopefully does the best ordering possible and that's that it it never is going to do the best ting possible like you're try you're trying like you said but it's you know it's a lot of times it doesn't matter that much because they're simple but yeah if you give it something tricky it's not it doesn't there's not room on the chip in such a high performance part to have some incredibly complex like tree analysis right so it's just doing its best like with some heuristics yeah nice yes okay and q q management is extremely hard for anyone that's never attempted to do q management it's like a virtually impossible problem and it has all these dependencies like i said like oh i can't schedule this instruction until it's ready and all that until the the inputs for it are ready and uh so anyway that's it and then the the if you have more p's it doesn't mean it's doing more bits what it means is that it's doing more things so the reason that you saw more ports on that other ad is because it involved a memory location so it needed to use other ports to generate the address and do the fetch so that's why you get more micro ops sometimes is there's more parts to the instruction that makes sense that makes sense because a register is already a it's like an already specified kind of named location and an i16 is a constant so that makes sense that i can kind of just do it once versus a read load from memory then get those things and then write it back out to memory yep yep so anyway back to our article the reason that i you have your old camera on you got to swap swap scenes thank you for reminding me yeah i would have gone all day with that okay um so going back to the article the reason that i was like it's kind of weird is because like alus are not directly comparable like you know a a modern alu is way more powerful than the 86's alu was right yeah so it's like it doesn't make sense to compare them in the way they're comparing them and they're they're this is in a section where the person's trying to make a uh comparison to show a large multiple well why didn't you use the fact that like the the integer mul multiply in x86 was like a series of alu ops that ran one after the other it took like 80 cycles or more like we can do those now in like four cycles or something on a on a or less on um depending on what you're talking about through per latency on a on an x64 right so it's yeah it's just weird yeah okay that that's very good okay so this is some good context to be able to understand why this is a uh an unusual argument shall we say for this type of thing it's weird yeah yeah so the 8086 instr instruction set is not the only instruction set that modern x86 supports there are dozens of instruction sets from the well-known floating point ss avx and other vector extensions to the obscure pae for 32-bit x86 to have wider addresses and vgf or is a gif vjf for interruptions in virtualizations according to stefan uh huel there may be as many as 3,600 instructions that's more than 20 times as many instructions as risk 5 has uh even if you count all the most common risk five extensions uh quick question um in my head my normal thought would be that the amount of instructions matter do they matter at all uh they m matter very little uh which is i think again why this heading your section where the problem lies and then talking about something that really isn't a problem uh or isn't the m problem if for this type of argument is weird so the first of all cpus are divided uh into two parts now well there many parts and the part that does the instruction fetch and decode right that generates those micro ops is basically completely independent of the back end to the extent that it matters so when you talk about adding more instructions you're not talking about anything that affects the actual execution engine of the cpu you're really not talking at all you're just talking about how many different permutations of input bit patterns you plan to turn into micro ops that's all you're talking about right okay okay does it matter a little bit yes because uh if you have lots of instructions the decoder has to be able to process all of those but if that's your concern what you're really concerned about is not the number of instructions it's how specific are their permutations because like if you just had a very simple bit pattern that you have to decode right then it's trivial to support lots of instructions you just go like okay it just does these little things and that says which uops to do and i'm done right and that part of the chip is tiny even if it supports lots of different instruction permutations now he will mention that in the article in a second here but it's weird to not lead with that the number of instructions just isn't that big a deal anyway continue these instructions come at a cost take for example one of uh x86 oddball instructions mpsa dbw this instruction is 6 to seven bytes long and compares how different a 4 byte sequence is in multiple positions of an 11 by sequence okay it's a feel oddly specific there must have been a problem there doing so takes at least 19 additions but the cpu runs it in just two clock cycles the first problem is the length the combination of the 6 to 11 byte instruction length and no alignment required makes fetching the instruction a lot more expensive to do this instruction also comes in a variant that accesses memory which complicates decoding of the instruction finally this instruction is still supported by modern cpus despite how rare it is to see it being used all that uses up valuable space in cutting edge x 86 cpus which it doesn't right like yeah we kind of learned that there's like the separate decoder which just i assume has that it's just like you get this and it comes out with the micro ops so x86 and x64 both support memory operands that's the thing where i said like okay you can do an ad and you can specify memory location right m 64s m364 is and m8s and 256s if you're talking about bigger registers whatever it is right you can do those ops and you can support a memory address so the fact that this one instruction has that is irrelevant to the architecture because all the instructions have that so you wouldn't go like oh let me talk about that in the conscious instruction as far as the instruction being an oddball instruction the reason these instructions exist is because they were trying to accelerate certain critical features like video decompression or compression or ai processing intel doesn't throw instructions into the instruction set for their health they do it because they have specific customers who benefit greatly from having these instruction and that's why they're there it's also why risk 5 doesn't have these instructions because hey news flash nobody used risk 5 for high performance applications so they haven't had to deal with all of these specific cases where they need to be the fastest person on this benchmark if they had you better believe they would have some extension called risk five video decompression or whatever where they add this exact instruction or something like that right so it's like again it's just it's a mess of an argument in my opinion okay okay okay that actually does make a lot of sense in risk architectures like myips arm and risk 5 the implementation of instructions is all hardware there are dedicated logic gates for running certain instructions the 8086 is also also started this way which would be an expensive joke if that was still the case that's where micro code comes in you see okay stop let me stop you're right there okay so this is just the person just doesn't know because you discussed that earlier about like ads being multiple instructions and micro codes and all that that they just don't know there are only a very small and they're not the ones you think uh set of instructions on the 886 that aren't micro coded nearly every instruction nearly every single instruction is micro coded on an 886 so common misconception that the 886 was simple and what nope it was micro coded and every instruction was micro coded and if someday you want to do that on stream prime i can walk you through the micro code because we know what it is now they reverse engineered from die shots and we now know exactly what the micro code is for every 8 8086 instruction to be real i'm i'm just g i'm just going to say something i i don't want you to judge me i won't i still don't understand why they use the term die okay i don't know what that means and like my brain can't make sense of it i've never even done i've never done anything beyond microprocessors and so i've never got into that level of hardware engineering and so i don't know what it means i know what memory maps are don't know what that is so uh when i say you don't give yourself enough credit prime i'm just going to say it right now i have no idea why it's called a die let's go i really don't i can tell you what it is i can tell you what it is i don't know why they call it a d i've never thought about that so when you manufacture chips right they're made using this lithographic process where you shoot photons at a piece of a wafer of silicon right classic yeah it's this big circle of silicon if you could probably find an image of someone holding there's always a circle someone's holding it with like like gloves on in every single ai article trying to bait you into clicking on this rainbow sheet of circle yeah and that giant disc has tons of little squares stamped on it which are the cpus right and when you cut one of those out that's the die that's what you call the d like that piece right there is called to die i guess and now that you're you're making me self-conscious cuz i'm like why the heck is it called a die i have no idea now i'm going to have to go ask a hardware guy i'm going to be like dude like why is it called a die i'm so ignorant people are saying die casting it's die casting yeah i know it's just in my head i'm just like man there's some crazy liquid that they're spraying on on wafers and i have no idea what's happening it's making making electronics this is crazy so yeah i'm sorry i don't know is it is it because it's diecast is it from the word diecast is that it's from the word d it must be from the word diecast i have no idea i only know about the ancient the ancient uh uh molding process using clay and iron so i have no i i can't go any further than that all right cpus those were fortunately it can get worse let's get back to those pesky keywords speculative and out of order modern x86 runs instructions out of order too for example to do math while waiting for a memory access sounds good let's assume for a moment that's all there is to it when faced with a divide that uses the value of racks followed by the way racks 64-bit register right followed by a multiple or a mult mully that overwrites racks the multiply must logically run after the divide even though the result of the multiply does not depend on the divide that's where register renaming comes in when a register renaming both can run simultaneously because the racks that the divide sees in the different physical registers than the racks that is multiply that the multiplier writes to i kind of read that poorly my i'm kicking in with the dyslexia here for a second but okay so this s like i mean everything that's currently described sounds good like okay going to optimize it because we know that you don't overlap okay this sounds good y this acceleration leaves us with two problems determining which instructions depend on which others and scheduling them optimally to run the code as fast as possible these problems depend on the particular instructions being run and their solution logic gets more complicated the more instructions exist the x86 oh no okay go on why why not because there it's just micro ops so those complex instructions like what an instruction does can be entirely boiled down to which registers does it modify as far as the concerned the doesn't care it could it could be doing the world's most it could be calculating all the digits of pi and you know going to infinity the infinite digit of pi which will take the depth of the universe and it will grab the last digit of pi when we finally figure out it's not really infinite after all and putting that in register we don't even know anything about that operation to know which registers are affected so the schuer doesn't care how complex the instruction is it just needs to know does this overwrite the destination or not that's all it needs to know that makes perfect sense because if you're scheduling a bunch of you don't care how the the the food is made you just need to know that you have enough pots you can put it into right and that's all you really care about okay so i have no idea what you're talking about here i have no idea okay okay that that makes a ton of sense the x86 instruction and coding format is so complex an entire wikip page wikipage oh my goodness wiki page is needed to serve as a tldr meanwhile risk 5 needs only two tables to describe the encoding of all standard instructions needless to say this puts x86 at an advantage in terms of decoding logic complexity i i guess you could somewhat argue that if there's more things that there is some level of decoding logic logic complexity that's more than risk five but it sounds like it's not really mattering in the end it it's true like so again this is why i say like this i i really question the person who wrote it and whether they understood exactly what was going on here because that part is correct the decode logic on x86 and x64 is more complicated but it has nothing to do with whether the instructions themselves are harder to schedule or have their dependencies figured out those are completely separate and completely unrelated like they wouldn't even affect each other like to even make the argument that those affected each other you have to get kind of nuts right because the thing thats can i interrupt with the argument for it being slower or worse would that come from the fact that decoding takes longer than the actual execution is that like kind of like this principal argument that's really coming behind this because if the decoder can always run faster right like this is just like video if your decoder can run faster than your actual renderer you'll never worry but if your decoder runs slower than your renderer you'll always have dropped frames and so is that kind of like this idea that the decoding logic is so complex that it's actually slowing everything down because the decoding is slower than the execution um so the this is why like because we're at the end here i don't know if you want to pause one second just read the end because i'm not sure that the end makes sense but that is what i was going to say is the the the one thing that is worth talking about is decoding complexity and so we should just do that at the end as our final thing because that that is a valid point that is not made well in this article and it's and they don't explain to you the actual thing that matters anyway okay okay over time the other in let's see other instruction sets like arm have been eating at x86 market share arm is completely dominant in smartphones and single board computers it is growing in the server market and it even become the b primary cpu architecture in apple's devices since 2020 risk 5 is also progressively getting more popular becoming the most widely adopted royalty-free instruction set to date risk 5 is currently most used in microcontrollers but is slowly growing towards higher powered platforms like single board computers and even desktop computers ris 5 being as free as it is it is also becoming the architecture of choice for today's computer science classes and this will only make it more popular over time why because of its simplicity uh but it's not right that's it's not why it's popular it's popular cuz it's free full st yes well also just because you know one doesn't mean you can't learn another i don't think there's any risk to intel in this like let's pretend intel never would want to change for whatever reason i don't i i obviously don't understand that but i don't think that that's like somehow an inherent wall garden that is big enough for them to have to change and also arm would be a better comparator to risk five and it's like look arm is is equally simple more or less like when you actually if you actually extended risk five out to be able to do all the things that arm does they wouldn't look all that different right so it's like where's the argument like i don't the argument for risk five adoption is pretty much just that it's free there's your argument okay yeah i mean that can be a good that can be a good argument yeah it certainly can be i'm not suggesting that it won't get a lot of adoption specifically because of that but that's the argument it has nothing to do with its simplicity all right conclusion the x86 architecture has been around for a long time a 46 year long time in this time it's grown from the simple days of early microprocessors to the incredibly complex monolith of computing we have today this this evol evolution has taken its toll though by restricting one of the biggest cpu platforms to the roots of a relatively ancient instruction set which doesn't even benefit from small code size like it did 46 years ago the complexities of super scaler speculative and outof order execution are heavy burdens on an instruction set that is already very complex by definition and the risk 5 shaped grim reapers named arm and risk five are slowly catching up i'm trying to read this as dramatically as possible don't get me wrong i don't hate x86 and i'm not saying it has to die today but one thing is clear the days of x86 are numbered so in that conclusion before we go on to the thing about the decoding which i do want to talk about which i think makes a good closing so you can see why i'm nervous about the person who wrote this article in this conclusion it sounds like and maybe i'm mischaracterizing them but just when you read that paragraph i'm just saying what it sounds like they're saying it sounds like they're saying that the x64 instruction set somehow is the only one that requires super scaler pipelined out of order execution right i mean am i wrong prime i mean that's how i would read it this is precisely is that these things come with this more complex one oras these ones are much more simple all but all of these architectures use that there are no modern chips that aren't this thing except for like really crappy like little super low power devices no one is talking about no phone on the planet that anyone uses or cares about isn't already on arm and doing all three of those things out of order super scaler pipeline next to they're all doing it so it just it sounds like the person just has no idea what they're talking about when they say stuff like that i'm like what do you mean like what's going on so that's why it's really frustrating you see this art i think that's why also chips and cheese wrote the thing right after like what is this person saying it doesn't make any sense right um so anyway that i i'm going to be real with you i i like i said from the very beginning i think this article is directed towards normies like me where like when i read this i come away with a conclusion and it it may be completely wrong or right it it doesn't matter because i i can't technically argue against it but i understand a lot of the underlying things like legacy typically makes things really hard more is typically more hard than less when you don't do a bunch of these really complicated things you can do really simple things right like all of that sounds very reasonable to me uh and you know like i said unfortunately at least for the uh the thrust of the article is it's just really not that true but let's talk about the one part of it that is true yeah theing complexity logic that was right here let's talk about that so a lot of people i think mistakenly think of decoding complexity as being something that's like cisk versus risk right but really they're sort of separate you could imagine taking cuz risk is reduced instruction set computer just means not very many instructions right the instructions do simple things and you're supposed to do multiple of them to do a complex thing okay makes sense well i could create the world's worst encoding for your 32 instruction computer that would take hours to decode instructions right yes yes i see i see the argument yes they're two separate things there's how well did you structure the decode bit patterns to be friendly to modern cpus and then there's how simple is the thing and this person is conflating those two things which often does happen but it's important to separate them because the actual thing that's not so great about x86 or x64 now is that there are a few inherited aspects of how things are encoded that make them less desirable from a decode standpoint and when i say from a decode standpoint what i mean is as you correctly surm earlier prime if i want to execute seven instructions per clock cycle in my total throughput when i measure it i'd better be able to decode seven instructions per clock cycle yeah so if actually it's very hard for me to make a chip front end that can hit that sustained rate because i've chosen poorly how my instructions are encoded um you could imagine and this is not that far from the actual problems in x86 imagine if i sent my instruction stream down zipped it's a zip file right now i have to decompress the instruction set and as i decompress it i can't figure out what like the next three instructions are all at once i have to like decompress each bit like first to find it out and then i can look at what they are right modern things would much prefer to be able to decode all like several instructions at one time right they wanted to code seven at a time eight at time later it'll be more and so making bad decisions about that can put a lot more stress because now they have to be like okay we're going have to have two stages one that like decodes blocks and unzips them and then there's another stage that does eight at a time and we'll try to have the unzipper be on this really fast like separate thick right and you hit these bottlenecks of like we can't just make this thing wider we can't just do more at a time because it's all dependent on each other x86 has some nasty elements like that and that is the thing you would actually want to fix you could keep the exact same instruction set there are some other things like flags you might want to change but and whether shifts modify flags there's all these like minutia we could change to fix things a little but you could keep the exact same instruction set and fix the in that decoding aspect and then all of the problems we're talking about the article pretty much go away so again there is a problem there that would be nice to fix it's not any of the things they're really talking about okay okay and and that last one actually makes the most amount of sense which is really like you have a drive force and whatever is the slowest part of this sequence will always be the slowest part of the entire thing and so if decoding logic truly is the driving force then that is going to be the slowest thing and then that's going to cause your that's where your bottlenecks at but that doesn't sound like it it technically is the case today so therefore we're we're safe but does that does that come to a point where it can be it it like i said the article there is an another article you could write that is right about this right and that article would basically be like look we could be decoding a lot more instructions per second uh for x64 with a lot less silicon if we made these changes and by the way i believe intel has proposed some things like this like they it's not like people know that this is a thing like they know that there are some encoding screw-ups that are due to legacy and so there are some things you would want to fix there where it's like here's a way we could redo this encoding to just be a little friendlier on decode and then these problems go away so as it is right now they're spending more dice space to use your favorite term again that neither of us knows what it means shooting photons shooting shooting light at a dis at a disc uh more of the space on that cpu is taken up by decode logic than probably should be yes that's probably true right now and it creates more of a struggle for x64 vendors uh amd and intel it creates more of a struggle for them they have sp matters an incredible amount a micrometer makes like a huge difference when it comes to this stuff because you can put something else in there yeah we we use that space for more you whatever else more cash more whatever we you know and so it does matter and it does create practical problems where you know there and re engineering time there's a bunch of engineers who are spending their time figuring out how to decode instructions faster if it was simpler they could have been spending their time operting something else right so it all it there is a germ of truth to it is i guess what i want to get at and that it's not so it's not totally uh there is there isn't a good article there there is a good article you could have wr written about this topic okay so it is there is a really good nugget of truth within this because i don't like that like entirely just on something there is a very good point which is that this is a serious problem but the framing and everything about it they they missed most of the time they have a worse batting average than your hall of fame uh batter for baseball right which is like what. three right so yeah not that high yeah yeah not that high you're not you're not winning out there okay no okay so they win about the same rate as i win in the stock market so good job they did it all right well hey this is this was a great time thanks casey for being on here this was super informative and people i mean i don't think i've seen uh people this excited about uh uh cpus in a while cpu minutia yeah cpu minutia sounds actually very very exciting can we get a bunch of claps here yeah and also go follow casey on twitter chips and thank you very much everyone yeah i love talking about cpus so it's my pleasure well let's let's do another thing maybe i'll try to find some time maybe uh cuz i don't know if you know this i'm now full full time uh maybe i'll try to find uh or when i say fulltime i'm now funemployed i no longer have a job uh but maybe i'll try to find some time to uh create that 8bit uh there's like an 8bit computer tutorial maybe i'll try to go through that and then we can kind of talk about some of like how does the next steps happen how did people go through something more advanced maybe or maybe there's something we can kind of come together with with that makes a lot of sense yeah anything you want i you know i love the show that's why i always say anytime yeah yeah no we i think everyone loves you more than me so you can most certainly come on any day of the week you just let me know you pick an article you pick something get on in here all right well and ask the chat tell if if the chat likes this they can tell you what they want us to talk about i'm happy to talk about whatever obviously i only really know microarchitecture performance kinds of stuff so you game engine stuff you can always talk about i do i know some game engine stuff too there's spacetime db coming up there's there's a lot there's a lot of cool stuff right any anytime prime i love the love the show uh like i said and so anytime all right awesome go follow him on twitter and then you also have some uh you you release some some videos and stuff like that too well where where can people find that oh well i there is a like a paid thing i do that's this kind of stuff it's computer enhance docomo when whe they're like enhance that quadrant like that kind of thing yeah all right let me let me make sure okay cool there we go that's it let's go all right i'll make sure i i'll i i should make sure this happens sometimes you know i don't actually i don't actually end up putting the links in my in my videos sometimes so i will try to remember to put the links but for those that are still watching computer enhanced. i'm just happy to be on the stream prime i don't it's totally fine yeah i just like i just like doing it i like doing the stream so thanks so much for having me and thanks everyone for watching and i will see you guys next time yeah yeah