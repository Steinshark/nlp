today i'm going to make myself obsolete i'm going to build a code explaining tool that also creates speech that way you can just use an ai to explain code to you and listen and then you don't have to watch my videos anymore isn't that great except that well i won't have an income source anymore to fix that i asked all of you what type of online course you'd be most interested in there were a ton of response has got some really useful feedback thank you so much so i'm going to go ahead and launch a course on software architecture this year i'm going to do something really special for this course just wait and see if you want to stay up to date on what's happening and be part of the first group that gets access to the course you can sign off free at ion.com architect you most certainly heard about chat gpt and open ai by now if you haven't where have you been sounds like a really calm place anyway everybody on the internet on youtube is talking about it i also have to oblige and do a couple of videos about chat tv and openai so that's what i'm going to do today the fun part of this is that it's actually incredibly simple to build so what i'm going to do today is build a simple app where you can input some code and then you can let the app explain it to you and use text-to-speech system to generate audio that explains to you using different voices before i start building this the app needs a name so i'm going to call it the arjun code explainer your personal code explanation assistance that is always by your side and explains code to you in a smooth but commanding voice let's dive in and i'm going to show you two things one is how can you use the openai api to get it to explain code to you and the second thing is how we can use text-to-speech tools to transform that text that we get back from open ai into audio so you can listen to it while you're doing something else so the example application that i made consists of three parts there's an app which is built using streamlit which is really useful application i didn't really cover that on my channel yet if you want me to do that let me know in the comments then we have an explainer dot pi file which contains all the interactions with the open ai api and finally i have a text-to-speech script that interacts with a text-to-speech service i'll go through each of them in this video and once you're done watching this video you can actually get this code from the gitro power story that i've put in the description and then you don't have to watch any of my videos anymore so and then finally i can take a very long break anyway so the first thing that i'm going to show you is the streamlit app so what streamer does is it allows you to really easily create a web-based interface that works on top of your script and that's what i did here so we have a couple of functions like displaying a header so you see it's actually really straightforward you just have an image title text some warning dialog we have display widgets which shows a file uploader so if you wanted to explain text and you want to read it from a file you can drag drop the file on top of that file uploader plus text area so it basically has all of these standard things that you need in a user interface and then i have a couple of extra functions that help me with dealing with the data so there's one where i retrieve the content from the file that's been uploaded there's one where i extract the code from the file so either it gets it from the uploaded script or it gets it from the code that you pasted into the text area then i've function for choosing the voice so i'm using the text-to-speech servers to give me the available names and finally i have main function that displays the header you allows you to choose the voice extracts the code and then show some spinners while it's waiting for the response and if text to speech is enabled i've temporarily disabled it because i had some issues with getting access to the service then it's going to convert that text to an mp3 file and then you can also play that mp3 file in the web-based interface the way it's set up is not perfect in terms of software design for example it would be nice to take all of these texts and move them out of the code so you could also translate it into other languages for example but i kept it really simple in this case because i just want to show you how easy it is to set this up so this is basically the whole setup of the app and then we have two other files so there's explainer so the explainer script is the part that interacts with the open ai api and that's also really easy first step that you need to do is you have to make sure you get an api key because the api key allows you access to the open ai api you can get this api key by signing up at the open ai developers page and then generate a key and then you can use that key here so what i did i won't show you this file because of course it contains my api keys but i created dot end file that contains both the openai api key and it also contains the api key i need for the text-to-speech service and then i'm using an app.pi i'm using dot n and the load.nf function so that loads those things from the dot end file and turns them into environment variables and then i can access them in the explainer script and later on i'll show you also in the text of suite script so we have the openai api key and then finally the only thing that we really need to do is use openai dot chat completion so that's part of this openai package and basically send the information with a couple of settings so one setting is the model you can choose which model you want to use i'm using gpt 3.5 turbo in this case and then you can send it messages so one is for example you can supply it with a context so in this case i'm telling it hey you are a developer because i wanted to respond in a way that makes sense to developers and then finally i can also ask it the actual question so that's the whole interface to open ai it's one function really simple and then i have a couple of extra functions so one is a function that gives me the content so if i have to respond from sending the question to open ai well it's a json structure so we need to navigate through the structure to extract what we actually need so that's what this function does then i have a helper function that actually does this it calls this send question function and then retrieves the answer so that does both of these things and i'm providing it with a question and with code so what i do in this case i have retrieve code language the question is explain in one word what language this code is written in and i have also a code explanation which is explain to me what this code base does in one paragraph i should probably fix the typo here otherwise we will get maybe a weird response so you also see that where i'm being pretty specific about the kind of answer i expect from openai so i want to know in one word what language the code is written in and also in this case i wanted to explain what the code pest does in one paragraph so we sort of limited in terms of how precise and how extensive it's going to be and basically that is that's the only thing you need to do in order to interact with the open ai api so you can definitely imagine how easy it is to integrate this into your own tools because it's just really a few basic simple steps if you go back to the app you see that i simply import the retrieve code explanation and retrieve code language and then i use it in the application and now since we're using streamlit it's also really easy to run this app locally the only thing you need to do is you call streamlit run app.pi so now you see it starts at streamlit and it gives me a local url which i can use in the browser to view the actual application and this is what that actually looks like so i have a nice logo that's my new logo by the way i hope you like it and we're calling this the aar john gold explainer and there's a couple of really simple things so just some description a warning and you can pick a voice so i'll talk about that later and then we have the drag and drop section here where you can upload your script or you can simply write some code here so let's see how this works so i'm going to write some code so for example um let's see very advanced code this and then i'm doing command enter so now it's going to send it to the openai api and it has given me a response so there we have language python and we have an explanation and what's fun about streamlit is that it can accept markdown so doing these kinds of things displaying code also in the code format makes it really easy to read so this is what we get from the open ai api to make this a bit more interesting let's try this with slightly more complicated code so here i have an example of a class that was part of some of my older videos i'm not even sure what i was trying to explain here but it's really simple it's a customer that has an id a name and an email address and it sends a welcome email when you create this customer so let me copy this code and see what openai comes up with in terms of the explanation so i'm going to replace the code here and i'm going to press command enter and now it's going to send it again once more to the open ai api and this is what we get so language is still python good i'm really happy to hear that and then we have the explanation and it still does it in one paragraph so the explanation looks pretty good this is exactly what the customer class does and as you can see it's nothing more than simply doing few api requests that's really all there is to it now let's make this a bit more interesting by also adding text to speech because if you really want to replace me it's not just about generating text to explain code it's also about having the audio of somebody with a very soothing smooth voice to also explain the code to you so text to speech dot pi does exactly that in this case i'm using the requests package because there is no specific library for the api that i'm using the one that i'm using today but there is a couple of other options as well is the 11 labs text-to-speech servers and this is the api url again i'm getting the api key from the dot n file just like i did with the openai example and then a few helpers from that make it a bit easier so for example there is a function that helps me get the voice ids so when you look at this application you see that i have a drop down here where i can select the voices and i got these voices from the 11 labs api if you have a paid account you can also train your custom voices and then you can actually get my voice and make it even closer towards i'm doing on the youtube channel but for now let's just use some of the existing voices because the process is exactly the same so other than that i have a few helper functions like saving binary to mp3 so of course we're getting we're going to get a response from the text to speech servers and we're going to store that as an mp3 file so we can play it back in the interface then the main function that converts text to mp3 is this function and again this is actually really simple really straightforward the only thing we need to do is we need to structure our api calls we need to create the urls that we're going to use and also interact with this speech service so the first part is getting the voice id so i select the name of the voice in the app and then this allows me to get the actual id that we need to use when we do the api call this by the way we can also do this once this mapping so you don't have to do it every time you convert text to mp3 but for simplicity i left it as part of this functions then we can create the payload so of course there is a message that we want to convert to mp3 and then there are some settings for example how stable the voice is and finally that's the part that interacts with the api so i've wrapped this in a while loop because i've noticed api is not always very responsive can we get slow sometimes so we want to make sure that if we don't get a response that the application doesn't completely block or something and finally if we did get a result from this text-to-speech api then i call the save binary to mp3 function that's also right here and again that's also really simple it just opens a file name it gets the binary content and then simply write that to the file now in the app what i did is i import this text-to-speech library here and then i'm using it in the main function so here for example i call comfort text to mp3 for language and i do the same thing for the explanation itself so i'll convert both of those things and if we have text to speech enabled then i'm going to show an audio player here of the language and the explanation so in order to activate text to speech let's change this to true and i'm also going to restart the streamlit app and now back to the ai code explainer and let's try something so first i'm going to select the voice and i'm going to select i don't know arnold let's see this code is written in python i'm going to use something else this time so this is another example of validating a credit card and let me paste that code right in here and then let's see if this works so we did get the language and the explanation from the openai api but it's still using a previously generated version of the audio that was used for the explanation so i can still show it it's going to be slightly different but you're going to get the idea python there python and i also like how who is this this is arnold i also like his tone of voice when explaining the code this code implements a function called validate underscore card which receives a customer object as an argument and returns a boolean value indicating whether the customer's credit card is valid or not based based on the loon algorithm it's really like authoritative you know disco defines a function called validate underscore card i really like that a lot i should maybe do that more in my videos i feel like i'm too friendly maybe i should be less friendly in my videos anyway as you can see this is really easy to set up assuming that the text-to-speech part actually works which i'm still fighting a bit with but it's really fun to play around with these tools and see how we can use them to make better nicer python applications so like i said all the code for this is available in a guitar story link is in the description of this video so feel free to play around with it take parts of the code that you want to use in your own application and see if you can come up with something really interesting now interacting with these apis in itself is nice because you then you can make it part of your code but another way that you can use these ai tools is by using them as a chatting agent to help you clarify your thoughts for example you can use it to help you with designing your software you can use it to learn about features of let's say the python language you can use to learn about how apis work and let it give you examples of how to do things so that's all very useful but you do need to think about how you write your questions properly i mean one example that shows how important it is to ask the right question is how i actually phrase my questions here so here i asked to explain in one word or here i ask it to explain to me what the code base does in one paragraph so providing those sort of precise instructions are really important and there's a couple of other things you can do as well if you want to learn more about that i did a video about that recently you can watch that right here i'll be back next week with a new video thanks for watching and take care