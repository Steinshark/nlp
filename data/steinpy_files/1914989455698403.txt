from torchvision.datasets import CIFAR10, CIFAR100 
from torchvision import transforms
from torch.utils.data import DataLoader
import torch 
from matplotlib import pyplot as plt 


#ok that sounds great
class ConvBlock(torch.nn.Module):

    def __init__(self,n_ch):
        super(ConvBlock,self).__init__()

        self.block  = torch.nn.Sequential(
            torch.nn.Conv2d(n_ch,n_ch,3,1,1,bias=False),
            torch.nn.BatchNorm2d(n_ch),
            torch.nn.PReLU(n_ch),

            torch.nn.Conv2d(n_ch,n_ch,3,1,1,bias=False),
            torch.nn.BatchNorm2d(n_ch),
            torch.nn.PReLU(n_ch)).cuda()
    
    def forward(self,x:torch.Tensor) -> torch.Tensor:
        return self.block(x)


class MModel(torch.nn.Module):

    def __init__(self,n_ch):

        super(MModel,self).__init__()
        bias = False

        self.m1 = torch.nn.Sequential(
            torch.nn.Conv2d(3,n_ch,3,1,1,bias=bias),
            torch.nn.BatchNorm2d(n_ch),
            torch.nn.PReLU(n_ch)).cuda()
        
        self.b1     = ConvBlock(n_ch)
        self.b2     = ConvBlock(n_ch)
        self.b3     = ConvBlock(n_ch)
        self.b4     = ConvBlock(n_ch)
        self.b5     = ConvBlock(n_ch)
        self.b6     = ConvBlock(n_ch)
        # self.b7     = ConvBlock(n_ch)
        # self.b8     = ConvBlock(n_ch)

        self.head   = torch.nn.Sequential(
            torch.nn.Conv2d(n_ch,n_ch*2,5,2,2,bias=True),
            torch.nn.BatchNorm2d(n_ch*2),
            torch.nn.PReLU(n_ch*2),
            torch.nn.Conv2d(n_ch*2,n_ch*4,5,2,2,bias=True),
            torch.nn.BatchNorm2d(n_ch*4),
            torch.nn.PReLU(n_ch*4),
            torch.nn.Conv2d(n_ch*4,n_ch*8,(8,8),1,0),

            torch.nn.Flatten(start_dim=1),
            torch.nn.PReLU(),

            torch.nn.Linear(n_ch*8,10),
            torch.nn.Softmax(dim=1)
        ).cuda()

    def forward(self,x:torch.Tensor) -> torch.Tensor:
        x           = self.m1(x)
        x           = self.b1(x) + x 
        x           = self.b2(x) + x 
        x           = self.b3(x) + x 
        x           = self.b4(x) + x 
        x           = self.b5(x) + x 
        x           = self.b6(x) + x 
        # x           = self.b7(x) + x 
        # x           = self.b8(x) + x 
        return self.head(x) 


def accuracy(preds,labels):
    _,preds     = torch.max(preds,dim=1)
    return (torch.sum((preds == labels)) / len(preds)).detach().cpu()

def run_train(bs,n_ch,betas,lr,wd,p,var,n_ep=16):
    torch.manual_seed(512)
    
    title   = f"bs:{bs}-ch:{n_ch}-betas:{betas}-lr:{lr}-wd:{wd}-p:{p}-var:{var}"
    accuracies      = []
    bias            = False 
    model           = MModel(n_ch)
    print(f"n params is {sum(p.numel() for p in model.parameters())/1_000_000}M params")
    #input(out)
    #optimizer       = torch.optim.SGD(model.parameters(),lr=lr,momentum=mom,nesterov=nest)
    optimizer       = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=wd,betas=betas)
    loss            = torch.nn.CrossEntropyLoss()

    shuffle         = True 
    tforms          = transforms.Compose([transforms.ToTensor()])#,transforms.Normalize((.48,.45,40),(var,var,var))])
    data_train      = CIFAR10("/home/steinshark/Downloads/datasets/cifar10",train=True,download=True,transform=tforms)
    data_test       = CIFAR10("/home/steinshark/Downloads/datasets/cifar10",train=False,download=True,transform=tforms)
    load_train      = DataLoader(data_train,batch_size=bs,shuffle=shuffle)
    load_test       = DataLoader(data_test,batch_size=bs,shuffle=False)
    classes         = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

    #16,2,.9,

    print(f"SERIES {title}")
    for epoch in range(n_ep):
        train_losses    = []
        accr            = [] 
        model.train()
        for i,batch in enumerate(load_train):

            #Clear grad
            for p in model.parameters():
                p.grad  = None 

            img,img_class   = batch 
            img             = img.cuda()
            img_class       = img_class.cuda()
            output_vals     = model(img)
            err             = loss(output_vals,img_class)
            train_losses.append(err.mean().item())
            err.backward()

            accr.append(accuracy(output_vals,img_class)*100)

            optimizer.step()
        
        print(f"\tTrain accur: {sum(accr)/len(accr):.2f}\t",end="")
        
        accs            = [] 
        model.eval()
        with torch.no_grad():
            for j, batch in enumerate(load_test):
                img,img_class   = batch 
                img             = img.cuda()
                img_class       = img_class.cuda()
                outs            = model(img)

                accs.append(accuracy(outs,img_class)*100)
        accuracies.append(sum(accs)/len(accs))
        print(f"\tTest accur: {accuracies[-1]:.2f}%")
    print(f"\n")
    return title,accuracies
########################################################
#                   SETTINGS
########################################################



series   = {}
for bs in [8,64,128]:
    for n_ch in [32]:
        for betas in [(.9,.99),(.5,.9)]:
            for lr in [.0001,.001]:
                for wd in [.1,.001]:
                    for p in [.5]:
                        for var in [.15]:
                            key,val         = run_train(bs,n_ch,betas,lr,wd,p,var,n_ep=8)
                            series[key]     = val 


for i,key in enumerate(series):
    plt.plot(series[key],label=f"{key}")
plt.legend()
plt.show()



