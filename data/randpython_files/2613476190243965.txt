import chess
import torch
import math 
import random
import copy
import chess_utils
import numpy 

class Node:

    #Class variables 
    #   c is the factor relating to exploration tendency
    moves       = {}
    DEVICE      = torch.device("cuda" if torch.cuda.is_available() else "cpu") 
    c           = torch.tensor(3,device=DEVICE)


    def __init__(self,move:chess.Move,parent,init_p:float|torch.Tensor,depth,turn:bool):

        #Game related vars
        self.move               = move 
        self.turn               = torch.tensor(1,device=self.DEVICE) if turn else torch.tensor(-1,device=self.DEVICE) 
        if turn:
            self.op             = self.maximize
            self.top_score      = torch.tensor(-1_000_000,device=self.DEVICE)
        else:
            self.op             = self.minimize
            self.top_score      = torch.tensor(1_000_000,device=self.DEVICE)
        self.depth              = depth                         #depth from root node

        #Node related vars
        self.parent:Node   = parent
        self.children           = []

        #Scores and such 
        self.n_visits           = torch.tensor(0,device=self.DEVICE).half() 
        #self.cum_score          = torch.tensor(0,device=self.DEVICE) 
        self.init_p             = init_p

        #Game stats from here 
        self.n_wins             = torch.tensor([0],device=self.DEVICE).half() 
        self.n_losses           = torch.tensor([0],device=self.DEVICE).half()
        self.n_draws            = torch.tensor([0],device=self.DEVICE).half() 

        self.cumulative_score   = torch.tensor([0],device=self.DEVICE).half()

    
    def is_leaf(self):
        return not bool(self.children)
    
    def maximize(self,x,y):
        return x > y 
    
    def minimize(self,x,y):
        return x < y
    
    def pick_best_child(self,board):
        #turn    = board.turn
        #input(f"turn is {turn}, nodeturn is {self.turn}")
        # if not self.children:
        #     return False 
        
        #Find top node 
        top_node    = None

        #node,score  = []
        best_score  = self.top_score
        for package in [(node,node.get_score()) for node in self.children]:
            curnode,score  = package

            if self.op(score,best_score):
                best_score      = score 
                top_node        = curnode 
        
        #print(f"best {top_node.move} was found with score {top_node.get_score()}")
        # if top_node is None:
        #     print(f"board is\n{board}")
        #     print(f"node was None on {self}")
        #     for node in self.children:
        #         node_score  = node.get_score(debug=True)
        #         print(f"\tsc:{node.move} -> {node_score}")


        #         if operation(node_score,top_score):
        #             top_score   = node_score 
        #             top_node    = node 


        return top_node
       
            
    def get_visits(self):
        return self.n_draws + self.n
    
    
    def get_q_score(self):
        return self.cumulative_score / (self.n_visits + 1)


    def get_u_score(self):
        return self.c * self.init_p * (torch.sqrt(self.parent.n_visits) / (1+self.n_visits))


    #   Score is an absolute evaluated regardless of player perspective 
    #       Black advantage == -1 
    #       White advantage == 1 
    #   Evaluation is done by the node in its own perspective when picking a next move 
    def get_score(self,debug=False):
        if not self.parent:
            return -1
        #Algorithm to determine search probability 

        #Must be inversely related to n_visits and proportional to prob and proportional to cum_score 
        
        #UPDATE LATER 
        #q_score                 = (self.n_wins-self.n_losses) / (self.n_visits+1)

        # q_score                 = self.cumulative_score / (self.n_visits + 1)

        # u_score                 = self.c * self.init_p * (math.sqrt(self.parent.n_visits) / (1+self.n_visits))

        # if self.turn == 1:
        #     u_score *= -1
        return self.get_q_score() + -1*self.turn*self.get_u_score()
        #return q_score + u_score


    def get_score_str(self):
        return f"{self.get_score():.3f}"
    

    def run_rollout(self,board:chess.Board,model:torch.nn.Module,lookup_dict,max_moves=200,mode='network'):
        board_fen   = board.fen()
        board_key   = " ".join(board_fen.split(" ")[:3])
        if board_key in lookup_dict:
            return lookup_dict[board_key]
        else:
            if mode == "network":
                with torch.no_grad():
                    board_repr              = chess_utils.batched_fen_to_tensor([board_fen]).to(self.DEVICE,non_blocking=True).half()
                    probs,model_v           = model.forward(board_repr)
                    lookup_dict[board_key]  = (probs,model_v)
                    #input(f"returning on rollout: {model_v}")
                    return probs,model_v
            
            elif mode == "rollout":
                #Keep track of n_moves to pop
                n_moves             = 0 

                #Play moves until gameover
                avail_moves         = list(board.generate_legal_moves())
                while avail_moves and not (board.is_stalemate() or board.is_insufficient_material()) and n_moves < max_moves:
                    #Pick a random move
                    #Get fen list
                    fen_list        = []
                    move_list       = []
                    for move in avail_moves:
                        board.push(move) 
                        fen_list.append(board.fen())
                        move_list.append(move)
                        board.pop()
                    
                    model_inputs    = chess_utils.batched_fen_to_tensor(fen_list).to(self.DEVICE)
                    model_eval      = model.forward(model_inputs)
                    top_i           = torch.topk(model_eval,k=1,largest=board.turn,dim=0)
                    board.push(move_list[top_i[1]])
                    n_moves += 1
                    avail_moves = list(board.generate_legal_moves())
                
                #Observe game output 
                outcome_string  = board.result()
                if outcome_string == "1/2-1/2" or outcome_string == "*":
                    rollout_result  = 0

                elif outcome_string == "1-0" or outcome_string == "0-1":
                    rollout_result  = 1 if (((self.turn == 1) and outcome_string == "1-0") or ((self.turn == -1) and outcome_string == "0-1")) else -1  
                else:
                    input(f"weird result: {outcome_string}")
                #Undo rollout 
                for _ in range(n_moves):
                    board.pop()
                
                return rollout_result
        

    def expand(self,board:chess.Board,depth:int,chess_model:torch.nn.Module,rollout_model:torch.nn.Module,max_depth:int,lookup_dict={}):

        #Check end state 
        if board.is_game_over() or board.ply() > max_depth:
            result  = board.result()
            if result == "1/2-1/2" or result == "*":
                return 0
            elif result == "0-1":
                return -1 
            elif result == "1-0":
                return 1 
            else:
                input(f"weird result: {result}")

        #Run "rollout"
        
        probabilities,rollout_val   = self.run_rollout(board,chess_model,lookup_dict,mode='network')
        #print(f"\texpanding node: board pos evals {rollout_val.item():.3f} from pers: {board.turn}")

        #Populate children nodes
        with torch.no_grad():
            probabilities           = probabilities[0]
            
            #Add children
            self.children           = [Node(move,self,probabilities[chess_utils.MOVE_TO_I[move]],depth+1,not board.turn) for move in board.generate_legal_moves()]
            revized_probs           = [c.init_p for c in self.children]            

            # #Perform softmax on legal moves only
            if len(revized_probs) == 1:
                self.children[0].init_p = 1 
                return rollout_val
            else:
                max_val     = max(revized_probs)    
                #print(f"\t\ttop prob was {max_val:.3f}")
                shifted     = [math.e**(x-max_val) for x in revized_probs]
                shifted_sum = sum(shifted)
                probs       = [shifted_x / shifted_sum for shifted_x in shifted]
                #print(f"\t\tadjusted is {[str(p.item())[:5] for p in probs]}")

                for prob,node in zip(probs,self.children):
                    node.init_p     = prob
                return rollout_val


    def bubble_up(self,outcome):

        #print(f"cumscore = {self.cumulative_score.shape}, outcome = {outcome.shape}")
        self.cumulative_score += outcome.flatten(start_dim=0)
        
        self.n_visits += 1

        if not self.parent is None:
            self.parent.bubble_up(outcome)


    def data_repr(self):
        return f"{self.move} vis:{self.n_visits},pvis:{self.parent.n_visits if self.parent else 0},win:{self.n_wins},p:{self.init_p:.2f},scr:{self.get_score_str()}"
    

    def traverse_to_child(self,move:chess.Move):
        for child in self.children:
            if child.move == move:
                return child
        return -1 
    

    def __repr__(self):
        if self.parent == None:
            return "root"
        return str(self.parent) + " -> " + str(self.move)

if __name__ == '__main__':

    board   = chess.Board()
    root    = Node(None,None,0,board.turn)


    #ALGORITHM - Get to leaf 
    curnode     = root
    print(f"is leaf = {curnode.is_leaf()}")
    while not curnode.is_leaf():
        curnode     = curnode.pick_best_child()
    
    print(f"root is {curnode}")
    print(f"board is\n{board}")
    root.expand(board)

    print(f"is leaf = {curnode.is_leaf()}")